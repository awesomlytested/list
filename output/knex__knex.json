{"repo":"knex/knex","url":"https://github.com/knex/knex","branch":"master","configs":[{"package":"knex","lang":"js","dir":"test","framework":"mocha","pattern":"**/*[._-]{test,spec,unittest,unit}.{ts,js}"}],"tests":[{"name":"Prints help","suites":["help"],"updatePoint":{"line":11,"column":17,"index":202},"line":11,"code":"  it('Prints help', () => {\n    return execCommand(`node ${KNEX} --help`, {\n      expectedOutput: {\n        expectedText: 'Usage',\n        exactlyTimes: 1\n      }\n    });\n  });","file":"cli/help.spec.js","skipped":false,"dir":"test"},{"name":"Prints help using -h flag","suites":["help"],"updatePoint":{"line":19,"column":31,"index":393},"line":19,"code":"  it('Prints help using -h flag', () => {\n    return execCommand(`node ${KNEX} -h`, {\n      expectedOutput: {\n        expectedText: 'Usage',\n        exactlyTimes: 1\n      }\n    });\n  });","file":"cli/help.spec.js","skipped":false,"dir":"test"},{"name":"Prints help when no arguments are given","suites":["help"],"updatePoint":{"line":27,"column":45,"index":594},"line":27,"code":"  it('Prints help when no arguments are given', () => {\n    return execCommand(`node ${KNEX}`, {\n      expectedErrorMessage: 'Usage: cli [options] [command]'\n    });\n  });","file":"cli/help.spec.js","skipped":false,"dir":"test"},{"name":"Does not print help when argument is given","suites":["help"],"updatePoint":{"line":32,"column":48,"index":769},"line":32,"code":"  it('Does not print help when argument is given', () => {\n    return execCommand(`node ${KNEX} -V`, {\n      notExpectedOutput: 'Usage'\n    });\n  });","file":"cli/help.spec.js","skipped":false,"dir":"test"},{"name":"Resolves default knexfile in working directory correctly","suites":["knexfile","knexfile resolution","--cwd is NOT specified","and --knexfile is also NOT specified"],"updatePoint":{"line":34,"column":68,"index":883},"line":34,"code":"        it('Resolves default knexfile in working directory correctly', () => {\n          const path = process.cwd() + '/knexfile.js';\n          fileHelper.createFile(path, `\nmodule.exports = {\n  client: 'sqlite3',\n  connection: {\n    filename: __dirname + '/test/jake-util/test.sqlite3',\n  },\n  migrations: {\n    directory: __dirname + '/test//jake-util/knexfile_migrations',\n  },\n};\n        `, {\n            isPathAbsolute: true\n          });\n          return execCommand(`node ${KNEX} migrate:latest --knexpath=../knex.js`, {\n            expectedOutput: 'Batch 1 run: 1 migrations'\n          });\n        });","file":"cli/knexfile-test.spec.js","skipped":false,"dir":"test"},{"name":"Run migrations with knexfile passed","suites":["knexfile","knexfile resolution","--cwd is NOT specified","but --knexfile is specified"],"updatePoint":{"line":55,"column":47,"index":1541},"line":55,"code":"        it('Run migrations with knexfile passed', () => {\n          return execCommand(`node ${KNEX} migrate:latest --knexfile=test/jake-util/knexfile/knexfile.js --knexpath=../knex.js`, {\n            expectedOutput: 'Batch 1 run: 1 migrations'\n          });\n        });","file":"cli/knexfile-test.spec.js","skipped":false,"dir":"test"},{"name":"Run migrations with knexfile returning function passed","suites":["knexfile","knexfile resolution","--cwd is NOT specified","but --knexfile is specified"],"updatePoint":{"line":60,"column":66,"index":1831},"line":60,"code":"        it('Run migrations with knexfile returning function passed', () => {\n          return execCommand(`node ${KNEX} migrate:latest --knexfile=test/jake-util/knexfile/knexfile_func.js --knexpath=../knex.js`, {\n            expectedOutput: 'Batch 1 run: 1 migrations'\n          });\n        });","file":"cli/knexfile-test.spec.js","skipped":false,"dir":"test"},{"name":"Run migrations with knexfile with async passed","suites":["knexfile","knexfile resolution","--cwd is NOT specified","but --knexfile is specified"],"updatePoint":{"line":65,"column":58,"index":2118},"line":65,"code":"        it('Run migrations with knexfile with async passed', () => {\n          return execCommand(`node ${KNEX} migrate:latest --knexfile=test/jake-util/knexfile/knexfile_async.js --knexpath=../knex.js`, {\n            expectedOutput: 'Batch 1 run: 1 migrations'\n          });\n        });","file":"cli/knexfile-test.spec.js","skipped":false,"dir":"test"},{"name":"Run migrations with knexfile with promise passed","suites":["knexfile","knexfile resolution","--cwd is NOT specified","but --knexfile is specified"],"updatePoint":{"line":70,"column":60,"index":2408},"line":70,"code":"        it('Run migrations with knexfile with promise passed', () => {\n          return execCommand(`node ${KNEX} migrate:latest --knexfile=test/jake-util/knexfile/knexfile_promise.js --knexpath=../knex.js`, {\n            expectedOutput: 'Batch 1 run: 1 migrations'\n          });\n        });","file":"cli/knexfile-test.spec.js","skipped":false,"dir":"test"},{"name":"changes the process's cwd to the directory that contains the knexfile","suites":["knexfile","knexfile resolution","--cwd is NOT specified","but --knexfile is specified"],"updatePoint":{"line":75,"column":81,"index":2721},"line":75,"code":"        it(\"changes the process's cwd to the directory that contains the knexfile\", () => {\n          const knexfile = 'test/jake-util/knexfile-relative/knexfile.js';\n          const expectedCWD = tildify(path.resolve(path.dirname(knexfile)));\n          return execCommand(`node ${KNEX} migrate:latest --knexfile=test/jake-util/knexfile-relative/knexfile.js --knexpath=../knex.js`, {\n            expectedOutput: `Working directory changed to ${color.magenta(expectedCWD)}`\n          });\n        }); // This addresses the issue that was reported here:","file":"cli/knexfile-test.spec.js","skipped":false,"dir":"test"},{"name":"changes the process's cwd to the directory that contains the knexfile before opening the knexfile","suites":["knexfile","knexfile resolution","--cwd is NOT specified","but --knexfile is specified","and the knexfile itself resolves paths relative to process.cwd()"],"updatePoint":{"line":87,"column":111,"index":3477},"line":87,"code":"          it(\"changes the process's cwd to the directory that contains the knexfile before opening the knexfile\", () => {\n            const knexfile = 'test/jake-util/knexfile-relative/knexfile.js';\n            const expectedCWD = tildify(path.resolve(path.dirname(knexfile)));\n            return execCommand(`node ${KNEX} migrate:latest --knexfile=test/jake-util/knexfile-relative/knexfile-with-resolve.js --knexpath=../knex.js`, {\n              expectedOutput: `Working directory changed to ${color.magenta(expectedCWD)}`\n            });\n          });","file":"cli/knexfile-test.spec.js","skipped":false,"dir":"test"},{"name":"Resolves migrations relatively to knexfile","suites":["knexfile","knexfile resolution","--cwd is NOT specified","but --knexfile is specified","and the knexfile itself resolves paths relative to process.cwd()"],"updatePoint":{"line":97,"column":54,"index":4100},"line":97,"code":"        it('Resolves migrations relatively to knexfile', () => {\n          return execCommand(`node ${KNEX} migrate:latest --knexfile=test/jake-util/knexfile-relative/knexfile.js --knexpath=../knex.js`, {\n            expectedOutput: 'Batch 1 run: 2 migrations'\n          });\n        });","file":"cli/knexfile-test.spec.js","skipped":false,"dir":"test"},{"name":"Throws informative error when no knexfile is found","suites":["knexfile","knexfile resolution","--cwd is NOT specified","but --knexfile is specified","and the knexfile itself resolves paths relative to process.cwd()"],"updatePoint":{"line":102,"column":62,"index":4395},"line":102,"code":"        it('Throws informative error when no knexfile is found', () => {\n          return execCommand(`node ${KNEX} migrate:latest --knexpath=../knex.js`, {\n            expectedErrorMessage: 'No configuration file found'\n          });\n        });","file":"cli/knexfile-test.spec.js","skipped":false,"dir":"test"},{"name":"resolves --knexfile relative to --cwd","suites":["knexfile","knexfile resolution","--cwd is specified","and --knexfile is also specified","and --knexfile is a relative path"],"updatePoint":{"line":112,"column":51,"index":4828},"line":112,"code":"          it('resolves --knexfile relative to --cwd', function () {\n            return execCommand(`node ${KNEX} migrate:latest --cwd=test/jake-util/knexfile --knexfile=knexfile.js`, {\n              expectedOutput: 'Batch 1 run: 1 migrations'\n            });\n          });","file":"cli/knexfile-test.spec.js","skipped":false,"dir":"test"},{"name":"uses the indicated knexfile","suites":["knexfile","knexfile resolution","--cwd is specified","and --knexfile is also specified","and --knexfile is an absolute path"],"updatePoint":{"line":119,"column":41,"index":5171},"line":119,"code":"          it('uses the indicated knexfile', function () {\n            // Notice: the Knexfile is using Typescript.  This means that Knex\n            // is pre-loading the appropriate Typescript modules before loading\n            // the Knexfile.\n            const knexfile = path.resolve('test/jake-util/knexfile-ts/custom-config.ts');\n            return execCommand(`node ${KNEX} migrate:latest --cwd=test/jake-util/knexfile --knexfile=${knexfile}`, {\n              expectedOutput: 'Batch 1 run: 4 migrations'\n            });\n          });","file":"cli/knexfile-test.spec.js","skipped":false,"dir":"test"},{"name":"resolves knexfile relative to the specified cwd","suites":["knexfile","knexfile resolution","--cwd is specified","but --knexfile is NOT specified"],"updatePoint":{"line":131,"column":59,"index":5815},"line":131,"code":"        it('resolves knexfile relative to the specified cwd', () => {\n          return execCommand(`node ${KNEX} migrate:latest --cwd=test/jake-util/knexfile`, {\n            expectedOutput: 'Batch 1 run: 1 migrations'\n          });\n        });","file":"cli/knexfile-test.spec.js","skipped":false,"dir":"test"},{"name":"works correctly with migrationSource specified","suites":["knexfile","knexfile supports custom migrationSource"],"updatePoint":{"line":140,"column":54,"index":6141},"line":140,"code":"    it('works correctly with migrationSource specified', () => {\n      return execCommand(`node ${KNEX} migrate:latest --knexfile=test/jake-util/knexfile-custom-migration-source/knexfile.js --knexpath=../knex.js`, {\n        expectedOutput: 'Batch 1 run: 2 migrations'\n      }).then(() => execCommand(`node ${KNEX} migrate:rollback --all --knexfile=test/jake-util/knexfile-custom-migration-source/knexfile.js --knexpath=../knex.js`, {\n        expectedOutput: 'Batch 1 rolled back: 2 migrations'\n      }));\n    });","file":"cli/knexfile-test.spec.js","skipped":false,"dir":"test"},{"name":"ignores migrationSource if migration directory is specified","suites":["knexfile","knexfile supports custom migrationSource"],"updatePoint":{"line":147,"column":67,"index":6667},"line":147,"code":"    it('ignores migrationSource if migration directory is specified', () => {\n      return execCommand(`node ${KNEX} migrate:latest --knexfile=test/jake-util/knexfile-custom-migration-source/knexfile-with-directory.js --knexpath=../knex.js`, {\n        expectedOutput: ['Batch 1 run: 1 migrations', 'FS-related option specified for migration configuration. This resets migrationSource to default FsMigrations']\n      });\n    });","file":"cli/knexfile-test.spec.js","skipped":false,"dir":"test"},{"name":"Create new migration auto-creating migration directory when it does not exist","suites":["migrate:make","-x option: make migration using a specific extension"],"updatePoint":{"line":42,"column":85,"index":865},"line":42,"code":"    it('Create new migration auto-creating migration directory when it does not exist', async () => {\n      const tmpDir = await createTemp();\n      const migrationsDirectory = path.join(tmpDir, 'abc/xyz/temp/migrations');\n      const knexfileContents = `\n        module.exports = {\n          client: 'sqlite3',\n          connection: {\n            filename: __dirname + '/test/jake-util/test.sqlite3',\n          },\n          migrations: {\n            directory: '${migrationsDirectory}',\n          },\n        };`;\n      fileHelper.createFile(path.join(process.cwd(), 'knexfile.js'), knexfileContents, {\n        isPathAbsolute: true\n      });\n      await execCommand(`node ${KNEX} migrate:make somename --knexpath=../knex.js`, {\n        expectedOutput: 'Created Migration'\n      });\n      expect(fs.existsSync(migrationsDirectory)).to.equal(true);\n      expect(fileHelper.fileGlobExists(`${migrationsDirectory}/*_somename.js`)).to.equal(1);\n    });","file":"cli/migrate-make.spec.js","skipped":false,"dir":"test"},{"name":"Create new migration without knexfile passed or existing in default location","suites":["migrate:make","-x option: make migration using a specific extension"],"updatePoint":{"line":64,"column":84,"index":1812},"line":64,"code":"    it('Create new migration without knexfile passed or existing in default location', () => {\n      return execCommand(`node ${KNEX} migrate:make somename --knexpath=../knex.js`, {\n        expectedErrorMessage: 'Failed to resolve config file, knex cannot determine where to generate migrations'\n      });\n    });","file":"cli/migrate-make.spec.js","skipped":false,"dir":"test"},{"name":"Create new migration with js knexfile passed","suites":["migrate:make","-x option: make migration using a specific extension"],"updatePoint":{"line":69,"column":52,"index":2094},"line":69,"code":"    it('Create new migration with js knexfile passed', async () => {\n      fileHelper.registerGlobForCleanup('test/jake-util/knexfile_migrations/*_somename.js');\n      await execCommand(`node ${KNEX} migrate:make somename --knexfile=test/jake-util/knexfile/knexfile.js --knexpath=../knex.js`, {\n        expectedOutput: 'Created Migration'\n      });\n      const fileCount = fileHelper.fileGlobExists('test/jake-util/knexfile_migrations/*_somename.js');\n      expect(fileCount).to.equal(1);\n    });","file":"cli/migrate-make.spec.js","skipped":false,"dir":"test"},{"name":"Create new migration with ts knexfile passed","suites":["migrate:make","-x option: make migration using a specific extension"],"updatePoint":{"line":77,"column":52,"index":2591},"line":77,"code":"    it('Create new migration with ts knexfile passed', async () => {\n      fileHelper.registerGlobForCleanup('test/jake-util/knexfile_migrations/*_somename.ts');\n      await execCommand(`node ${KNEX} migrate:make somename --knexfile=test/jake-util/knexfile-ts/knexfile.ts --knexpath=../knex.js`, {\n        expectedOutput: 'Created Migration'\n      });\n      const fileCount = fileHelper.fileGlobExists('test/jake-util/knexfile_migrations/*_somename.ts');\n      expect(fileCount).to.equal(1);\n    });","file":"cli/migrate-make.spec.js","skipped":false,"dir":"test"},{"name":"Create new migration with default knexfile","suites":["migrate:make","-x option: make migration using a specific extension"],"updatePoint":{"line":85,"column":50,"index":3089},"line":85,"code":"    it('Create new migration with default knexfile', () => {\n      fileHelper.registerGlobForCleanup('test/jake-util/knexfile_migrations/*_somename.js');\n      fileHelper.createFile(process.cwd() + '/knexfile.js', `\nmodule.exports = {\n  client: 'sqlite3',\n  connection: {\n    filename: __dirname + '/test/jake-util/test.sqlite3',\n  },\n  migrations: {\n    directory: __dirname + '/test/jake-util/knexfile_migrations',\n  },\n};    \n    `, {\n        isPathAbsolute: true\n      });\n      return execCommand(`node ${KNEX} migrate:make somename --knexpath=../knex.js`, {\n        expectedOutput: 'Created Migration'\n      });\n    });","file":"cli/migrate-make.spec.js","skipped":false,"dir":"test"},{"name":"Create new migration with default ts knexfile","suites":["migrate:make","-x option: make migration using a specific extension"],"updatePoint":{"line":104,"column":53,"index":3718},"line":104,"code":"    it('Create new migration with default ts knexfile', async () => {\n      fileHelper.registerGlobForCleanup('test/jake-util/knexfile_migrations/*_somename1.ts');\n      const filePath = path.join(process.cwd(), '/knexfile.ts');\n      fileHelper.createFile(filePath, `\nmodule.exports = {\n  client: 'sqlite3',\n  connection: {\n    filename: __dirname + '/test/jake-util/test.sqlite3',\n  },\n  migrations: {\n    directory: __dirname + '/test/jake-util/knexfile_migrations',\n  },\n};    \n    `, {\n        isPathAbsolute: true\n      });\n      await execCommand(`node ${KNEX} migrate:make somename1 --knexpath=../knex.js`, {\n        expectedOutput: 'Created Migration'\n      });\n      const fileCount = fileHelper.fileGlobExists('test/jake-util/knexfile_migrations/*_somename1.ts');\n      expect(fileCount).to.equal(1);\n    });","file":"cli/migrate-make.spec.js","skipped":false,"dir":"test"},{"name":"Create new migration with default ts knexfile when knexfile has per-env configurations","suites":["migrate:make","-x option: make migration using a specific extension"],"updatePoint":{"line":126,"column":94,"index":4579},"line":126,"code":"    it('Create new migration with default ts knexfile when knexfile has per-env configurations', async () => {\n      fileHelper.registerGlobForCleanup('test/jake-util/knexfile_migrations/*_somename2.ts');\n      const filePath = path.join(process.cwd(), '/knexfile.ts');\n      fileHelper.createFile(filePath, `\nmodule.exports = {\n  development: {\n    client: 'sqlite3',\n    connection: {\n      filename: __dirname + '/test/jake-util/test.sqlite3',\n    },\n    migrations: {\n      directory: __dirname + '/test/jake-util/knexfile_migrations',\n    }\n  }\n};    \n    `, {\n        isPathAbsolute: true\n      });\n      await execCommand(`node ${KNEX} migrate:make somename2 --knexpath=../knex.js`, {\n        expectedOutput: 'Created Migration'\n      });\n      const fileCount = fileHelper.fileGlobExists('test/jake-util/knexfile_migrations/*_somename2.ts');\n      expect(fileCount).to.equal(1);\n    });","file":"cli/migrate-make.spec.js","skipped":false,"dir":"test"},{"name":"Create new migration with ts extension using -x switch","suites":["migrate:make","-x option: make migration using a specific extension"],"updatePoint":{"line":150,"column":62,"index":5442},"line":150,"code":"    it('Create new migration with ts extension using -x switch', async () => {\n      fileHelper.registerGlobForCleanup('test/jake-util/knexfile_migrations/*_somename.ts');\n      await execCommand(`node ${KNEX} migrate:make somename -x ts --knexfile=test/jake-util/knexfile/knexfile.js --knexpath=../knex.js`, {\n        expectedOutput: 'Created Migration'\n      });\n      const fileCount = fileHelper.fileGlobExists('test/jake-util/knexfile_migrations/*_somename.ts');\n      expect(fileCount).to.equal(1);\n    });","file":"cli/migrate-make.spec.js","skipped":false,"dir":"test"},{"name":"Create new migration with ts extension using \"extension\" knexfile param","suites":["migrate:make","-x option: make migration using a specific extension"],"updatePoint":{"line":158,"column":79,"index":5972},"line":158,"code":"    it('Create new migration with ts extension using \"extension\" knexfile param', async () => {\n      fileHelper.registerGlobForCleanup('test/jake-util/knexfile_migrations/*_somename.ts');\n      fileHelper.createFile(process.cwd() + '/knexfile.js', `\nmodule.exports = {\n  client: 'sqlite3',\n  connection: {\n    filename: __dirname + '/test/jake-util/test.sqlite3',\n  },\n  migrations: {\n    extension: 'ts',\n    directory: __dirname + '/test/jake-util/knexfile_migrations',\n  },\n};    \n    `, {\n        isPathAbsolute: true\n      });\n      await execCommand(`node ${KNEX} migrate:make somename --knexpath=../knex.js`, {\n        expectedOutput: 'Created Migration'\n      });\n      const fileCount = fileHelper.fileGlobExists('test/jake-util/knexfile_migrations/*_somename.ts');\n      expect(fileCount).to.equal(1);\n    });","file":"cli/migrate-make.spec.js","skipped":false,"dir":"test"},{"name":"Create new migration with ts extension using environment \"extension\" knexfile param","suites":["migrate:make","-x option: make migration using a specific extension"],"updatePoint":{"line":180,"column":91,"index":6805},"line":180,"code":"    it('Create new migration with ts extension using environment \"extension\" knexfile param', async () => {\n      fileHelper.registerGlobForCleanup('test/jake-util/knexfile_migrations/*_somename.ts');\n      fileHelper.createFile(process.cwd() + '/knexfile.js', `\nmodule.exports = {\ndevelopment: {\n  client: 'sqlite3',\n  connection: {\n    filename: __dirname + '/test/jake-util/test.sqlite3',\n  },\n  migrations: {\n    extension: 'ts',\n    directory: __dirname + '/test/jake-util/knexfile_migrations',\n  },\n  }\n};    \n    `, {\n        isPathAbsolute: true\n      });\n      await execCommand(`node ${KNEX} migrate:make somename --knexpath=../knex.js`, {\n        expectedOutput: 'Created Migration'\n      });\n      const fileCount = fileHelper.fileGlobExists('test/jake-util/knexfile_migrations/*_somename.ts');\n      expect(fileCount).to.equal(1);\n    });","file":"cli/migrate-make.spec.js","skipped":false,"dir":"test"},{"name":"Create a new migration using --stub </file/path> relative to the knexfile","suites":["migrate:make","--stub option: make migration using specific stub file"],"updatePoint":{"line":219,"column":81,"index":7992},"line":219,"code":"    it('Create a new migration using --stub </file/path> relative to the knexfile', async () => {\n      const {\n        migrationGlobPath\n      } = migrationStubOptionSetup(fileHelper);\n      const stubPath = 'test/jake-util/migration-stubs/table.stub';\n      await execCommand(`node ${KNEX} migrate:make somename --stub ${stubPath} --knexpath=../knex.js`, {\n        expectedOutput: 'Created Migration'\n      });\n      const fileCount = fileHelper.fileGlobExists('test/jake-util/knexfile_migrations/*_somename.js');\n      expect(fileCount).to.equal(1);\n      expectContentMatchesStub(stubPath, migrationGlobPath, fileHelper);\n    });","file":"cli/migrate-make.spec.js","skipped":false,"dir":"test"},{"name":"Create a new migration with stub parameter in knexfile","suites":["migrate:make","--stub option: make migration using specific stub file"],"updatePoint":{"line":231,"column":62,"index":8607},"line":231,"code":"    it('Create a new migration with stub parameter in knexfile', async () => {\n      const migrationGlobPath = 'test/jake-util/knexfile-stubs/*_somename.js';\n      fileHelper.registerGlobForCleanup(migrationGlobPath);\n      await execCommand(`node ${KNEX} migrate:make somename --knexfile=test/jake-util/knexfile-stubs/knexfile.js --knexpath=../knex.js`, {\n        expectedOutput: 'Created Migration'\n      });\n      const fileCount = fileHelper.fileGlobExists('test/jake-util/knexfile-stubs/*_somename.js');\n      const stubName = 'table.stub';\n      const stubPath = `test/jake-util/knexfile-stubs/${stubName}`;\n      expect(fileCount).to.equal(1);\n      expectContentMatchesStub(stubPath, migrationGlobPath, fileHelper);\n    });","file":"cli/migrate-make.spec.js","skipped":false,"dir":"test"},{"name":"Create a new migration with --stub <name> in config.migrations.directory","suites":["migrate:make","--stub option: make migration using specific stub file"],"updatePoint":{"line":243,"column":80,"index":9357},"line":243,"code":"    it('Create a new migration with --stub <name> in config.migrations.directory', async () => {\n      const {\n        migrationGlobPath\n      } = migrationStubOptionSetup(fileHelper);\n      const stubName = 'table-foreign.stub';\n      const stubPath = `test/jake-util/knexfile_migrations/${stubName}`;\n      await execCommand(`node ${KNEX} migrate:make somename --stub ${stubName} --knexpath=../knex.js`, {\n        expectedOutput: 'Created Migration'\n      });\n      const fileCount = fileHelper.fileGlobExists('test/jake-util/knexfile_migrations/*_somename.js');\n      expect(fileCount).to.equal(1);\n      expectContentMatchesStub(stubPath, migrationGlobPath, fileHelper);\n    });","file":"cli/migrate-make.spec.js","skipped":false,"dir":"test"},{"name":"Create a new migration with --stub <name> when file does not exist","suites":["migrate:make","--stub option: make migration using specific stub file"],"updatePoint":{"line":256,"column":74,"index":10034},"line":256,"code":"    it('Create a new migration with --stub <name> when file does not exist', async () => {\n      migrationStubOptionSetup(fileHelper);\n      const stubName = 'non-existat.stub';\n      await execCommand(`node ${KNEX} migrate:make somename --stub ${stubName} --knexpath=../knex.js`, {\n        expectedErrorMessage: 'ENOENT:'\n      });\n    });","file":"cli/migrate-make.spec.js","skipped":false,"dir":"test"},{"name":"Create a new migration with --stub </file/path> when file does not exist","suites":["migrate:make","--stub option: make migration using specific stub file"],"updatePoint":{"line":263,"column":80,"index":10381},"line":263,"code":"    it('Create a new migration with --stub </file/path> when file does not exist', async () => {\n      migrationStubOptionSetup(fileHelper);\n      const stubPath = '/path/non-existat.stub';\n      await execCommand(`node ${KNEX} migrate:make somename --stub ${stubPath} --knexpath=../knex.js`, {\n        expectedErrorMessage: 'ENOENT:'\n      });\n    });","file":"cli/migrate-make.spec.js","skipped":false,"dir":"test"},{"name":"Create a new migration with --stub <name> when config.migrations.directory not defined","suites":["migrate:make","--stub option: make migration using specific stub file"],"updatePoint":{"line":270,"column":94,"index":10748},"line":270,"code":"    it('Create a new migration with --stub <name> when config.migrations.directory not defined', async () => {\n      fileHelper.createFile(process.cwd() + '/knexfile.js', `\n  module.exports = {\n    development: {\n      client: 'sqlite3',\n      connection: {\n        filename: __dirname + '/test/jake-util/test.sqlite3',\n      },\n      migrations: {\n        // directory not defined\n      },\n    }\n  };\n      `, {\n        isPathAbsolute: true\n      });\n      const stubName = 'table-foreign.stub';\n      await execCommand(`node ${KNEX} migrate:make somename --stub ${stubName} --knexpath=../knex.js`, {\n        expectedErrorMessage: 'config.migrations.directory in knexfile must be defined'\n      });\n    });","file":"cli/migrate-make.spec.js","skipped":false,"dir":"test"},{"name":"should create row in lock table if none exists","suites":["migrate:unlock"],"updatePoint":{"line":48,"column":52,"index":1174},"line":48,"code":"  it('should create row in lock table if none exists', async () => {\n    // Purge the lock table to ensure none exists\n    await new Promise((resolve, reject) => {\n      db.run('DELETE FROM knex_migrations_lock', err => err ? reject(err) : resolve());\n    });\n    await runUnlockCommand();\n    await verifyMigrationsUnlocked();\n  });","file":"cli/migrate-unlock.spec.js","skipped":false,"dir":"test"},{"name":"should restore lock table to one row with is_locked=0 if multiple rows exist","suites":["migrate:unlock"],"updatePoint":{"line":56,"column":82,"index":1538},"line":56,"code":"  it('should restore lock table to one row with is_locked=0 if multiple rows exist', async () => {\n    // Seed multiple rows into the lock table\n    await new Promise((resolve, reject) => {\n      db.run('INSERT INTO knex_migrations_lock(is_locked) VALUES (?),(?),(?)', [1, 0, 1], err => {\n        err ? reject(err) : resolve();\n      });\n    });\n    await runUnlockCommand();\n    await verifyMigrationsUnlocked();\n  });","file":"cli/migrate-unlock.spec.js","skipped":false,"dir":"test"},{"name":"Run migrations","suites":["migrate:latest"],"updatePoint":{"line":35,"column":20,"index":692},"line":35,"code":"  it('Run migrations', async () => {\n    fileHelper.createFile('migrations/000_create_rule_table.js', `\n            exports.up = (knex)=> knex.schema.createTable('rules', (table)=> {\n                table.string('name');\n            });\n            exports.down = (knex)=> knex.schema.dropTable('rules');\n        `, {\n      willBeCleanedUp: true,\n      isPathAbsolute: false\n    });\n    expect(fileHelper.fileExists(dbPath)).to.equal(false);\n    await execCommand(`node ${KNEX} migrate:latest \\\n                 --client=sqlite3 --connection=${dbPath} \\\n                 --migrations-directory=${rootDir}/migrations \\\n                 create_rule_table`);\n    expect(fileHelper.fileExists(dbPath)).to.equal(true);\n    const db = await new sqlite3.Database(dbPath);\n    const getPromise = new Promise((resolve, reject) => {\n      db.get('SELECT name FROM knex_migrations', {}, (err, row) => {\n        if (err) {\n          reject(err);\n        }\n\n        resolve(row);\n      });\n    });\n    const row = await getPromise;\n    expect(row.name).to.equal('000_create_rule_table.js');\n    db.close();\n  });","file":"cli/migrate.spec.js","skipped":false,"dir":"test"},{"name":"Creates new seed auto-creating seed directory when it does not exist","suites":["seed:make","-x option: make seed using a specific extension"],"updatePoint":{"line":44,"column":76,"index":932},"line":44,"code":"    it('Creates new seed auto-creating seed directory when it does not exist', async () => {\n      const tmpDir = await createTemp();\n      const seedsDirectory = path.join(tmpDir, 'abc/xyz/temp/seeds');\n      const knexfileContents = `\n        module.exports = {\n          client: 'sqlite3',\n          connection: {\n            filename: __dirname + '/test/jake-util/test.sqlite3',\n          },\n          seeds: {\n            directory: '${seedsDirectory}',\n          },\n        };`;\n      fileHelper.createFile(path.join(process.cwd(), 'knexfile.js'), knexfileContents, {\n        isPathAbsolute: true\n      });\n      await execCommand(`${NODE} ${KNEX} seed:make somename --knexpath=../knex.js`, {\n        expectedOutput: 'Created seed file'\n      });\n      expect(fs.existsSync(`${seedsDirectory}/somename.js`)).to.equal(true);\n    });","file":"cli/seed-make.spec.js","skipped":false,"dir":"test"},{"name":"Creates new seed with js knexfile passed","suites":["seed:make","-x option: make seed using a specific extension"],"updatePoint":{"line":65,"column":48,"index":1742},"line":65,"code":"    it('Creates new seed with js knexfile passed', async () => {\n      fileHelper.registerGlobForCleanup('test/jake-util/knexfile_seeds/somename.js');\n      await execCommand(`${NODE} ${KNEX} seed:make somename --knexfile=test/jake-util/knexfile/knexfile.js --knexpath=../knex.js`, {\n        expectedOutput: 'Created seed file'\n      });\n      const fileCount = fileHelper.fileGlobExists('test/jake-util/knexfile_seeds/somename.js');\n      expect(fileCount).to.equal(1);\n    });","file":"cli/seed-make.spec.js","skipped":false,"dir":"test"},{"name":"Creates new seed with ts knexfile passed","suites":["seed:make","-x option: make seed using a specific extension"],"updatePoint":{"line":73,"column":48,"index":2221},"line":73,"code":"    it('Creates new seed with ts knexfile passed', async () => {\n      fileHelper.registerGlobForCleanup('test/jake-util/knexfile_seeds/somename.ts');\n      await execCommand(`${NODE} ${KNEX} seed:make somename --knexfile=test/jake-util/knexfile-ts/knexfile.ts --knexpath=../knex.js`, {\n        expectedOutput: 'Created seed file'\n      });\n      const fileCount = fileHelper.fileGlobExists('test/jake-util/knexfile_seeds/somename.ts');\n      expect(fileCount).to.equal(1);\n    });","file":"cli/seed-make.spec.js","skipped":false,"dir":"test"},{"name":"Creates new seed with default knexfile","suites":["seed:make","-x option: make seed using a specific extension"],"updatePoint":{"line":81,"column":46,"index":2701},"line":81,"code":"    it('Creates new seed with default knexfile', async () => {\n      fileHelper.registerGlobForCleanup('test/jake-util/knexfile_seeds/somename.js');\n      fileHelper.createFile(process.cwd() + '/knexfile.js', `\nmodule.exports = {\n  client: 'sqlite3',\n  connection: {\n    filename: __dirname + '/test/jake-util/test.sqlite3',\n  },\n  seeds: {\n    directory: __dirname + '/test/jake-util/knexfile_seeds',\n  },\n};\n    `, {\n        isPathAbsolute: true\n      });\n      await execCommand(`${NODE} ${KNEX} seed:make somename --knexpath=../knex.js`, {\n        expectedOutput: 'Created seed file'\n      });\n      const fileCount = fileHelper.fileGlobExists('test/jake-util/knexfile_seeds/somename.js');\n      expect(fileCount).to.equal(1);\n    });","file":"cli/seed-make.spec.js","skipped":false,"dir":"test"},{"name":"Creates new seed with default ts knexfile","suites":["seed:make","-x option: make seed using a specific extension"],"updatePoint":{"line":102,"column":49,"index":3443},"line":102,"code":"    it('Creates new seed with default ts knexfile', async () => {\n      fileHelper.registerGlobForCleanup('test/jake-util/knexfile_seeds/somename.ts');\n      fileHelper.createFile(process.cwd() + '/knexfile.ts', `\nmodule.exports = {\n  client: 'sqlite3',\n  connection: {\n    filename: __dirname + '/test/jake-util/test.sqlite3',\n  },\n  seeds: {\n    directory: __dirname + '/test/jake-util/knexfile_seeds',\n  },\n};\n    `, {\n        isPathAbsolute: true\n      });\n      await execCommand(`${NODE} ${KNEX} seed:make somename --knexpath=../knex.js`, {\n        expectedOutput: 'Created seed file'\n      });\n      const fileCount = fileHelper.fileGlobExists('test/jake-util/knexfile_seeds/somename.ts');\n      expect(fileCount).to.equal(1);\n    });","file":"cli/seed-make.spec.js","skipped":false,"dir":"test"},{"name":"Creates new seed with ts extension using -x switch","suites":["seed:make","-x option: make seed using a specific extension"],"updatePoint":{"line":123,"column":58,"index":4194},"line":123,"code":"    it('Creates new seed with ts extension using -x switch', async () => {\n      fileHelper.registerGlobForCleanup('test/jake-util/knexfile_seeds/somename.ts');\n      await execCommand(`${NODE} ${KNEX} seed:make somename -x ts --knexfile=test/jake-util/knexfile/knexfile.js --knexpath=../knex.js`, {\n        expectedOutput: 'Created seed file'\n      });\n      const fileCount = fileHelper.fileGlobExists('test/jake-util/knexfile_seeds/somename.ts');\n      expect(fileCount).to.equal(1);\n    });","file":"cli/seed-make.spec.js","skipped":false,"dir":"test"},{"name":"Creates new seed with ts extension using \"extension\" knexfile param","suites":["seed:make","-x option: make seed using a specific extension"],"updatePoint":{"line":131,"column":75,"index":4706},"line":131,"code":"    it('Creates new seed with ts extension using \"extension\" knexfile param', async () => {\n      fileHelper.registerGlobForCleanup('test/jake-util/knexfile_seeds/somename.ts');\n      fileHelper.createFile(process.cwd() + '/knexfile.js', `\nmodule.exports = {\n  client: 'sqlite3',\n  connection: {\n    filename: __dirname + '/test/jake-util/test.sqlite3',\n  },\n  seeds: {\n    extension: 'ts',\n    directory: __dirname + '/test/jake-util/knexfile_seeds',\n  },\n};\n    `, {\n        isPathAbsolute: true\n      });\n      await execCommand(`${NODE} ${KNEX} seed:make somename --knexpath=../knex.js`, {\n        expectedOutput: 'Created seed file'\n      });\n      const fileCount = fileHelper.fileGlobExists('test/jake-util/knexfile_seeds/somename.ts');\n      expect(fileCount).to.equal(1);\n    });","file":"cli/seed-make.spec.js","skipped":false,"dir":"test"},{"name":"Creates new seed with ts extension using environment \"extension\" knexfile param","suites":["seed:make","-x option: make seed using a specific extension"],"updatePoint":{"line":153,"column":87,"index":5507},"line":153,"code":"    it('Creates new seed with ts extension using environment \"extension\" knexfile param', async () => {\n      fileHelper.registerGlobForCleanup('test/jake-util/knexfile_seeds/somename.ts');\n      fileHelper.createFile(process.cwd() + '/knexfile.js', `\nmodule.exports = {\ndevelopment: {\n  client: 'sqlite3',\n  connection: {\n    filename: __dirname + '/test/jake-util/test.sqlite3',\n  },\n  seeds: {\n    extension: 'ts',\n    directory: __dirname + '/test/jake-util/knexfile_seeds',\n  },\n  }\n};\n    `, {\n        isPathAbsolute: true\n      });\n      await execCommand(`${NODE} ${KNEX} seed:make somename --knexpath=../knex.js`, {\n        expectedOutput: 'Created seed file'\n      });\n      const fileCount = fileHelper.fileGlobExists('test/jake-util/knexfile_seeds/somename.ts');\n      expect(fileCount).to.equal(1);\n    });","file":"cli/seed-make.spec.js","skipped":false,"dir":"test"},{"name":"Creates a new seed using --stub </file/path> relative to the knexfile","suites":["seed:make","--stub option: make seed using specific stub file"],"updatePoint":{"line":192,"column":77,"index":6657},"line":192,"code":"    it('Creates a new seed using --stub </file/path> relative to the knexfile', async () => {\n      const {\n        seedGlobPath\n      } = seedStubOptionSetup(fileHelper);\n      const stubPath = 'test/jake-util/knexfile-stubs/seed.stub';\n      await execCommand(`${NODE} ${KNEX} seed:make somename --stub ${stubPath} --knexpath=../knex.js`, {\n        expectedOutput: 'Created seed file'\n      });\n      const fileCount = fileHelper.fileGlobExists('test/jake-util/knexfile_seeds/somename.js');\n      expect(fileCount).to.equal(1);\n      expectContentMatchesStub(stubPath, seedGlobPath, fileHelper);\n    });","file":"cli/seed-make.spec.js","skipped":false,"dir":"test"},{"name":"Creates a new seed with stub parameter in knexfile","suites":["seed:make","--stub option: make seed using specific stub file"],"updatePoint":{"line":204,"column":58,"index":7244},"line":204,"code":"    it('Creates a new seed with stub parameter in knexfile', async () => {\n      const seedGlobPath = 'test/jake-util/knexfile-stubs/somename.js';\n      fileHelper.registerGlobForCleanup(seedGlobPath);\n      await execCommand(`${NODE} ${KNEX} seed:make somename --knexfile=test/jake-util/knexfile-stubs/knexfile.js --knexpath=../knex.js`, {\n        expectedOutput: 'Created seed file'\n      });\n      const fileCount = fileHelper.fileGlobExists('test/jake-util/knexfile-stubs/somename.js');\n      const stubName = 'seed.stub';\n      const stubPath = `test/jake-util/knexfile-stubs/${stubName}`;\n      expect(fileCount).to.equal(1);\n      expectContentMatchesStub(stubPath, seedGlobPath, fileHelper);\n    });","file":"cli/seed-make.spec.js","skipped":false,"dir":"test"},{"name":"Creates a new seed with --stub <name> in config.seeds.directory","suites":["seed:make","--stub option: make seed using specific stub file"],"updatePoint":{"line":216,"column":71,"index":7965},"line":216,"code":"    it('Creates a new seed with --stub <name> in config.seeds.directory', async () => {\n      const {\n        seedGlobPath\n      } = seedStubOptionSetup(fileHelper);\n      const stubName = 'seed2.stub';\n      const stubPath = `test/jake-util/knexfile_seeds/${stubName}`;\n      await execCommand(`${NODE} ${KNEX} seed:make somename --stub ${stubName} --knexpath=../knex.js`, {\n        expectedOutput: 'Created seed file'\n      });\n      const fileCount = fileHelper.fileGlobExists('test/jake-util/knexfile_seeds/somename.js');\n      expect(fileCount).to.equal(1);\n      expectContentMatchesStub(stubPath, seedGlobPath, fileHelper);\n    });","file":"cli/seed-make.spec.js","skipped":false,"dir":"test"},{"name":"fails to create a new seed with --stub <name> when file does not exist","suites":["seed:make","--stub option: make seed using specific stub file"],"updatePoint":{"line":229,"column":78,"index":8611},"line":229,"code":"    it('fails to create a new seed with --stub <name> when file does not exist', async () => {\n      seedStubOptionSetup(fileHelper);\n      const stubName = 'non-existat.stub';\n      await execCommand(`${NODE} ${KNEX} seed:make somename --stub ${stubName} --knexpath=../knex.js`, {\n        expectedErrorMessage: 'ENOENT:'\n      });\n    });","file":"cli/seed-make.spec.js","skipped":false,"dir":"test"},{"name":"fails to create a new seed with --stub </file/path> when file does not exist","suites":["seed:make","--stub option: make seed using specific stub file"],"updatePoint":{"line":236,"column":84,"index":8957},"line":236,"code":"    it('fails to create a new seed with --stub </file/path> when file does not exist', async () => {\n      seedStubOptionSetup(fileHelper);\n      const stubPath = '/path/non-existat.stub';\n      await execCommand(`${NODE} ${KNEX} seed:make somename --stub ${stubPath} --knexpath=../knex.js`, {\n        expectedErrorMessage: 'ENOENT:'\n      });\n    });","file":"cli/seed-make.spec.js","skipped":false,"dir":"test"},{"name":"fails to create a seed with --stub <name> when config.seeds.directory not defined","suites":["seed:make","--stub option: make seed using specific stub file"],"updatePoint":{"line":243,"column":89,"index":9314},"line":243,"code":"    it('fails to create a seed with --stub <name> when config.seeds.directory not defined', async () => {\n      fileHelper.createFile(process.cwd() + '/knexfile.js', `\n  module.exports = {\n    development: {\n      client: 'sqlite3',\n      connection: {\n        filename: __dirname + '/test/jake-util/test.sqlite3',\n      },\n      seeds: {\n        // directory not defined\n      },\n    }\n  };\n      `, {\n        isPathAbsolute: true\n      });\n      const stubName = 'table-foreign.stub';\n      await execCommand(`${NODE} ${KNEX} seed:make somename --stub ${stubName} --knexpath=../knex.js`, {\n        expectedErrorMessage: 'config.seeds.directory in knexfile must be defined'\n      });\n    });","file":"cli/seed-make.spec.js","skipped":false,"dir":"test"},{"name":"Creates a new seed using --timestamp-filename-prefix CLI flag","suites":["seed:make","--timestamp-filename-prefix option: make seed with timestamp filename prefix"],"updatePoint":{"line":276,"column":69,"index":10283},"line":276,"code":"    it('Creates a new seed using --timestamp-filename-prefix CLI flag', async () => {\n      const seedGlobPath = `${process.cwd()}/seeds/*_somename.js`;\n      fileHelper.registerGlobForCleanup(seedGlobPath);\n      await execCommand(`${NODE} ${KNEX} seed:make somename --timestamp-filename-prefix --knexpath=../knex.js`, {\n        expectedOutput: 'Created seed file'\n      });\n      const fileCount = fileHelper.fileGlobExists(seedGlobPath);\n      expect(fileCount).to.equal(1);\n    });","file":"cli/seed-make.spec.js","skipped":false,"dir":"test"},{"name":"Creates a new seed using timestampFilenamePrefix parameter in knexfile","suites":["seed:make","--timestamp-filename-prefix option: make seed with timestamp filename prefix"],"updatePoint":{"line":285,"column":78,"index":10778},"line":285,"code":"    it('Creates a new seed using timestampFilenamePrefix parameter in knexfile', async () => {\n      const seedsDirectory = `${process.cwd()}/seeds`;\n      const seedGlobPath = `${seedsDirectory}/*_somename.js`;\n      fileHelper.registerGlobForCleanup(seedGlobPath);\n      const knexfileContents = `\n        module.exports = {\n          client: 'sqlite3',\n          connection: {\n            filename: __dirname + '/test/jake-util/test.sqlite3',\n          },\n          seeds: {\n            directory: '${seedsDirectory}',\n            timestampFilenamePrefix: true\n          },\n        };`;\n      fileHelper.createFile(path.join(process.cwd(), 'knexfile.js'), knexfileContents, {\n        isPathAbsolute: true\n      });\n      await execCommand(`${NODE} ${KNEX} seed:make somename --knexpath=../knex.js`, {\n        expectedOutput: 'Created seed file'\n      });\n      const fileCount = fileHelper.fileGlobExists(seedGlobPath);\n      expect(fileCount).to.equal(1);\n    });","file":"cli/seed-make.spec.js","skipped":false,"dir":"test"},{"name":"prints non verbose logs","suites":["seed:run"],"updatePoint":{"line":14,"column":29,"index":283},"line":14,"code":"  it('prints non verbose logs', () => {\n    return execCommand(`node ${KNEX} seed:run --knexfile=test/jake-util/seeds-knexfile.js`, {\n      expectedOutput: 'Ran 2 seed files',\n      notExpectedOutput: ['first.js', 'second.js']\n    });\n  });","file":"cli/seed.spec.js","skipped":false,"dir":"test"},{"name":"find files not recursively by default","suites":["seed:run"],"updatePoint":{"line":20,"column":43,"index":538},"line":20,"code":"  it('find files not recursively by default', () => {\n    return execCommand(`node ${KNEX} seed:run --knexfile=test/jake-util/seeds-knexfile-directories.js`, {\n      expectedOutput: 'Ran 2 seed files',\n      notExpectedOutput: ['before-second.js', 'second.js']\n    });\n  });","file":"cli/seed.spec.js","skipped":false,"dir":"test"},{"name":"find files recursively if option is set","suites":["seed:run"],"updatePoint":{"line":26,"column":45,"index":815},"line":26,"code":"  it('find files recursively if option is set', () => {\n    return execCommand(`node ${KNEX} seed:run --knexfile=test/jake-util/seeds-knexfile-directories-recursive.js`, {\n      expectedOutput: 'Ran 3 seed files',\n      notExpectedOutput: ['first.js', 'second.js', 'before-second.js']\n    });\n  });","file":"cli/seed.spec.js","skipped":false,"dir":"test"},{"name":"find files not recursively by default and print verbose logs","suites":["seed:run"],"updatePoint":{"line":32,"column":66,"index":1135},"line":32,"code":"  it('find files not recursively by default and print verbose logs', () => {\n    return execCommand(`node ${KNEX} seed:run --knexfile=test/jake-util/seeds-knexfile-directories.js --verbose`, {\n      expectedOutput: ['Ran 2 seed files', 'before-second.js', 'second.js']\n    });\n  });","file":"cli/seed.spec.js","skipped":false,"dir":"test"},{"name":"find recursively files if option recursive is set and print verbose logs","suites":["seed:run"],"updatePoint":{"line":37,"column":78,"index":1430},"line":37,"code":"  it('find recursively files if option recursive is set and print verbose logs', () => {\n    return execCommand(`node ${KNEX} seed:run --knexfile=test/jake-util/seeds-knexfile-directories-recursive.js --verbose`, {\n      expectedOutput: ['Ran 3 seed files', 'first.js', 'second.js', 'before-second.js']\n    });\n  });","file":"cli/seed.spec.js","skipped":false,"dir":"test"},{"name":"supports async configuration","suites":["seed:run"],"updatePoint":{"line":42,"column":34,"index":1703},"line":42,"code":"  it('supports async configuration', () => {\n    return execCommand(`node ${KNEX} seed:run --knexfile=test/jake-util/seeds-knexfile-async.js`, {\n      expectedOutput: 'Ran 2 seed files',\n      notExpectedOutput: ['first.js', 'second.js']\n    });\n  });","file":"cli/seed.spec.js","skipped":false,"dir":"test"},{"name":"prints verbose logs","suites":["seed:run"],"updatePoint":{"line":48,"column":25,"index":1946},"line":48,"code":"  it('prints verbose logs', () => {\n    return execCommand(`node ${KNEX} seed:run --knexfile=test/jake-util/seeds-knexfile.js --verbose`, {\n      expectedOutput: ['Ran 2 seed files', 'first.js', 'second.js']\n    });\n  });","file":"cli/seed.spec.js","skipped":false,"dir":"test"},{"name":"runs specific file","suites":["seed:run"],"updatePoint":{"line":53,"column":24,"index":2167},"line":53,"code":"  it('runs specific file', () => {\n    return execCommand(`node ${KNEX} seed:run --knexfile=test/jake-util/seeds-knexfile.js --specific=second.js`, {\n      expectedOutput: 'Ran 1 seed files',\n      notExpectedOutput: ['first.js', 'second.js']\n    });\n  });","file":"cli/seed.spec.js","skipped":false,"dir":"test"},{"name":"handles non existing specific seed file errors correctly","suites":["seed:run"],"updatePoint":{"line":59,"column":62,"index":2462},"line":59,"code":"  it('handles non existing specific seed file errors correctly', () => {\n    return execCommand(`node ${KNEX} seed:run --knexfile=test/jake-util/seeds-knexfile.js --specific=intentionally-non-existing-404-seed.js`, {\n      expectedErrorMessage: ['Invalid argument provided', 'does not exist']\n    });\n  });","file":"cli/seed.spec.js","skipped":false,"dir":"test"},{"name":"runs specific file in a recursive folder","suites":["seed:run"],"updatePoint":{"line":64,"column":46,"index":2753},"line":64,"code":"  it('runs specific file in a recursive folder', () => {\n    return execCommand(`node ${KNEX} seed:run --knexfile=test/jake-util/seeds-knexfile-directories.js --specific=second.js`, {\n      expectedOutput: 'Ran 1 seed files',\n      notExpectedOutput: ['first.js', 'second.js']\n    });\n  });","file":"cli/seed.spec.js","skipped":false,"dir":"test"},{"name":"handles seeding errors correctly","suites":["seed:run"],"updatePoint":{"line":70,"column":38,"index":3036},"line":70,"code":"  it('handles seeding errors correctly', () => {\n    return execCommand(`node ${KNEX} seed:run --knexfile=test/jake-util/seeds-error-knexfile.js`, {\n      expectedErrorMessage: ['Error while executing', 'seeds.js', 'Boom']\n    });\n  });","file":"cli/seed.spec.js","skipped":false,"dir":"test"},{"name":"Print correct knex CLI version","suites":["version"],"updatePoint":{"line":13,"column":36,"index":266},"line":13,"code":"  it('Print correct knex CLI version', () => {\n    const expectedKnexCliVersion = cliPkg.version;\n    return execCommand(`node ${KNEX} --version`, {\n      expectedOutput: expectedKnexCliVersion\n    });\n  });","file":"cli/version.spec.js","skipped":false,"dir":"test"},{"name":"Print correct knex CLI version using -V flag","suites":["version"],"updatePoint":{"line":19,"column":50,"index":488},"line":19,"code":"  it('Print correct knex CLI version using -V flag', () => {\n    const expectedKnexCliVersion = cliPkg.version;\n    return execCommand(`node ${KNEX} -V`, {\n      expectedOutput: expectedKnexCliVersion\n    });\n  });","file":"cli/version.spec.js","skipped":false,"dir":"test"},{"name":"select empty table","suites":["CockroachDB dialect","Upsert into query with unique"],"updatePoint":{"line":30,"column":30,"index":740},"line":30,"code":"        it('select empty table', async () => {\n          const results = await knex('test').select();\n          expect(results).is.empty;\n        });","file":"integration2/dialects/cockroachdb.spec.js","skipped":false,"dir":"test"},{"name":"upsert id=1 with result insert","suites":["CockroachDB dialect","Upsert into query with unique"],"updatePoint":{"line":34,"column":42,"index":902},"line":34,"code":"        it('upsert id=1 with result insert', async () => {\n          const results = await knex('test').upsert({\n            id: 1,\n            balance: 10\n          });\n          expect(results.command).to.eql('INSERT');\n          expect(results.rowCount).to.eql(1);\n        });","file":"integration2/dialects/cockroachdb.spec.js","skipped":false,"dir":"test"},{"name":"select rows","suites":["CockroachDB dialect","Upsert into query with unique"],"updatePoint":{"line":42,"column":23,"index":1163},"line":42,"code":"        it('select rows', async () => {\n          const results = await knex('test').select();\n          expect(results).to.eql([{\n            id: '1',\n            balance: '10.00',\n            name: null\n          }]);\n        });","file":"integration2/dialects/cockroachdb.spec.js","skipped":false,"dir":"test"},{"name":"upsert id=1 with result update balance","suites":["CockroachDB dialect","Upsert into query with unique"],"updatePoint":{"line":50,"column":50,"index":1422},"line":50,"code":"        it('upsert id=1 with result update balance', async () => {\n          const results = await knex('test').upsert({\n            id: 1,\n            balance: 5\n          });\n          expect(results.command).to.eql('INSERT');\n          expect(results.rowCount).to.eql(1);\n        });","file":"integration2/dialects/cockroachdb.spec.js","skipped":false,"dir":"test"},{"name":"select rows","suites":["CockroachDB dialect","Upsert into query with unique"],"updatePoint":{"line":58,"column":23,"index":1682},"line":58,"code":"        it('select rows', async () => {\n          const results = await knex('test').select();\n          expect(results.length).to.eql(1);\n          expect(results).to.eql([{\n            id: '1',\n            balance: '5.00',\n            name: null\n          }]);\n        });","file":"integration2/dialects/cockroachdb.spec.js","skipped":false,"dir":"test"},{"name":"can change the default value","suites":["MSSQL dialect","column default handling","changing default value"],"updatePoint":{"line":55,"column":42,"index":1608},"line":55,"code":"          it('can change the default value', async () => {\n            await knex.schema.alterTable('test', function () {\n              this.string('name').defaultTo('test2').alter();\n            });\n            const {\n              definition\n            } = await fetchDefaultConstraint(knex, 'test', 'name');\n            expect(definition).to.equal(\"('test2')\");\n          });","file":"integration2/dialects/mssql.spec.js","skipped":false,"dir":"test"},{"name":"names default constraint","suites":["MSSQL dialect","column default handling","changing default value"],"updatePoint":{"line":65,"column":36,"index":1995},"line":65,"code":"        it('names default constraint', async () => {\n          await knex.schema.alterTable('test', function () {\n            this.string('name').defaultTo('knex');\n          });\n          const {\n            name\n          } = await fetchDefaultConstraint(knex, 'test', 'name');\n          expect(name).to.equal('test_name_default');\n        });","file":"integration2/dialects/mssql.spec.js","skipped":false,"dir":"test"},{"name":"names default constraint with supplied name","suites":["MSSQL dialect","column default handling","changing default value"],"updatePoint":{"line":74,"column":55,"index":2360},"line":74,"code":"        it('names default constraint with supplied name', async () => {\n          const constraintName = 'DF_test_name';\n          await knex.schema.alterTable('test', function () {\n            this.string('name').defaultTo('knex', {\n              constraintName\n            });\n          });\n          const {\n            name\n          } = await fetchDefaultConstraint(knex, 'test', 'name');\n          expect(name).to.equal('DF_test_name');\n        });","file":"integration2/dialects/mssql.spec.js","skipped":false,"dir":"test"},{"name":"doesn't name default constraint","suites":["MSSQL dialect","column default handling","changing default value"],"updatePoint":{"line":86,"column":43,"index":2803},"line":86,"code":"        it(\"doesn't name default constraint\", async () => {\n          const constraintName = '';\n          await knex.schema.alterTable('test', function () {\n            this.string('name').defaultTo('knex', {\n              constraintName\n            });\n          });\n          const {\n            name\n          } = await fetchDefaultConstraint(knex, 'test', 'name'); // this is the default patten used by mssql if no constraint is defined\n\n          expect(name).to.match(/^DF__test__name__[0-9A-Z]+$/);\n        });","file":"integration2/dialects/mssql.spec.js","skipped":false,"dir":"test"},{"name":"supports table comments of max 7500 bytes","suites":["MSSQL dialect","comment limits"],"updatePoint":{"line":109,"column":53,"index":3749},"line":109,"code":"        it('supports table comments of max 7500 bytes', async () => {\n          // 0 works\n          await expect(comment(knex, 'add', byteCount0, tableTarget)).to.eventually.be.fulfilled; // 7500 works\n\n          await expect(comment(knex, 'update', byteCount7500, tableTarget)).to.eventually.be.fulfilled; // Over 7500 fails\n\n          await expect(comment(knex, 'update', byteCountOver7500, tableTarget)).to.eventually.be.rejectedWith('The size associated with an extended property cannot be more than 7,500 bytes.');\n        });","file":"integration2/dialects/mssql.spec.js","skipped":false,"dir":"test"},{"name":"supports column comments of max 7500 bytes","suites":["MSSQL dialect","comment limits"],"updatePoint":{"line":120,"column":54,"index":4368},"line":120,"code":"        it('supports column comments of max 7500 bytes', async () => {\n          // 0 works\n          await expect(comment(knex, 'add', byteCount0, columnTarget)).to.eventually.be.fulfilled; // 7500 works\n\n          await expect(comment(knex, 'update', byteCount7500, columnTarget)).to.eventually.be.fulfilled; // Over 7500 fails\n\n          await expect(comment(knex, 'update', byteCountOver7500, columnTarget)).to.eventually.be.rejectedWith('The size associated with an extended property cannot be more than 7,500 bytes.');\n        }); // Characters in the supplementary plane need 4 bytes in UTF-16.","file":"integration2/dialects/mssql.spec.js","skipped":false,"dir":"test"},{"name":"worst-case allows at most  characters with string length  in an nvarchar","suites":["MSSQL dialect","comment limits"],"updatePoint":{"line":131,"column":96,"index":5163},"line":131,"code":"        it(`worst-case allows at most ${N} characters with string length ${2 * N} in an nvarchar`, async () => {\n          const astralPlaneCharacter = '\\u{1D306}';\n          const worstCaseComment = astralPlaneCharacter.repeat(N); // This works out because characters outside the BMP are counted as having length 2 by JavaScript's string.\n\n          expect(worstCaseComment).to.have.property('length', 2 * N); // This length is the \"shortest (in string.length), longest (in byte length)\" comment that will fit.\n          // Thus, for anything larger than 7500/2, we need to warn that the comment might be too many bytes.\n\n          const asNvarcharLiteral = text => `N'${text}'`;\n\n          await expect(comment(knex, 'add', asNvarcharLiteral(worstCaseComment), columnTarget)).to.eventually.be.fulfilled; // One more JS char (2 more bytes) is too much!\n\n          const oneMoreCharIsTooMuch = 'X' + worstCaseComment;\n          expect(oneMoreCharIsTooMuch).to.have.property('length', 2 * N + 1);\n          await expect(comment(knex, 'update', asNvarcharLiteral(oneMoreCharIsTooMuch), columnTarget)).to.eventually.be.rejectedWith('The size associated with an extended property cannot be more than 7,500 bytes.');\n        });","file":"integration2/dialects/mssql.spec.js","skipped":false,"dir":"test"},{"name":"accepts indexName in options object","suites":["MSSQL dialect","unique table index with options object"],"updatePoint":{"line":158,"column":47,"index":6760},"line":158,"code":"        it('accepts indexName in options object', async () => {\n          const indexName = `AK_${tableName}_x_y`;\n          await knex.schema.alterTable(tableName, function () {\n            this.unique(['x', 'y'], {\n              indexName\n            });\n          });\n          await expect(knex.insert([{\n            x: 1,\n            y: 1\n          }, {\n            x: 1,\n            y: 1\n          }]).into(tableName)).to.eventually.be.rejectedWith(new RegExp(indexName));\n        });","file":"integration2/dialects/mssql.spec.js","skipped":false,"dir":"test"},{"name":"accepts indexName and constraint in options object","suites":["MSSQL dialect","unique table constraint with options object"],"updatePoint":{"line":185,"column":62,"index":7698},"line":185,"code":"        it('accepts indexName and constraint in options object', async () => {\n          const indexName = `UK_${tableName}_x_y`;\n          await knex.schema.alterTable(tableName, function () {\n            this.unique(['x', 'y'], {\n              indexName: indexName,\n              useConstraint: true\n            });\n          });\n          await expect(knex.insert([{\n            x: 1,\n            y: 1\n          }, {\n            x: 1,\n            y: 1\n          }]).into(tableName)).to.eventually.be.rejectedWith(new RegExp(indexName));\n        });","file":"integration2/dialects/mssql.spec.js","skipped":false,"dir":"test"},{"name":"attaches table comments","suites":["MSSQL dialect","comment support"],"updatePoint":{"line":225,"column":35,"index":9257},"line":225,"code":"        it('attaches table comments', async () => {\n          const commentText = await commentFor(knex, {\n            schemaName,\n            tableName\n          });\n          expect(commentText).to.equal(tableComment);\n        });","file":"integration2/dialects/mssql.spec.js","skipped":false,"dir":"test"},{"name":"attaches column comments","suites":["MSSQL dialect","comment support"],"updatePoint":{"line":232,"column":36,"index":9491},"line":232,"code":"        it('attaches column comments', async () => {\n          const commentText = await commentFor(knex, {\n            schemaName,\n            tableName,\n            columnName\n          });\n          expect(commentText).to.equal(columnComment);\n        });","file":"integration2/dialects/mssql.spec.js","skipped":false,"dir":"test"},{"name":"updates table comments","suites":["MSSQL dialect","comment support"],"updatePoint":{"line":240,"column":34,"index":9748},"line":240,"code":"        it('updates table comments', async () => {\n          const updatedTableComment = 'updated table comment';\n          await knex.schema.alterTable(tableName, function () {\n            this.comment(updatedTableComment);\n          });\n          const commentText = await commentFor(knex, {\n            schemaName,\n            tableName\n          });\n          expect(commentText).to.equal(updatedTableComment);\n        });","file":"integration2/dialects/mssql.spec.js","skipped":false,"dir":"test"},{"name":"updates column comments","suites":["MSSQL dialect","comment support"],"updatePoint":{"line":251,"column":35,"index":10176},"line":251,"code":"        it('updates column comments', async () => {\n          const updatedColumnComment = 'updated column comment';\n          await knex.schema.alterTable(tableName, function () {\n            this.string(columnName).comment(updatedColumnComment).alter();\n          });\n          const commentText = await commentFor(knex, {\n            schemaName,\n            tableName,\n            columnName\n          });\n          expect(commentText).to.equal(updatedColumnComment);\n        });","file":"integration2/dialects/mssql.spec.js","skipped":false,"dir":"test"},{"name":"adds column comments when altering and no pre-existing comment","suites":["MSSQL dialect","comment support"],"updatePoint":{"line":263,"column":74,"index":10698},"line":263,"code":"        it('adds column comments when altering and no pre-existing comment', async () => {\n          const expectedComment = 'well it has a comment now';\n          await knex.schema.alterTable(tableName, function () {\n            this.string(columnWithoutComment).comment(expectedComment).alter();\n          });\n          const commentText = await commentFor(knex, {\n            schemaName,\n            tableName,\n            columnName: columnWithoutComment\n          });\n          expect(commentText).to.equal(expectedComment);\n        });","file":"integration2/dialects/mssql.spec.js","skipped":false,"dir":"test"},{"name":"adds table comments when updating and no pre-existing comment","suites":["MSSQL dialect","comment support"],"updatePoint":{"line":275,"column":73,"index":11239},"line":275,"code":"        it('adds table comments when updating and no pre-existing comment', async () => {\n          const tableName = tableWithoutComment;\n          const expectedComment = 'comment';\n          await knex.schema.alterTable(tableName, function () {\n            this.comment(expectedComment);\n          });\n          const commentText = await commentFor(knex, {\n            schemaName,\n            tableName\n          });\n          expect(commentText).to.equal(expectedComment);\n        });","file":"integration2/dialects/mssql.spec.js","skipped":false,"dir":"test"},{"name":"uses correct port for connecting","suites":["MySQL dialect","Connection configuration"],"updatePoint":{"line":32,"column":44,"index":747},"line":32,"code":"        it('uses correct port for connecting', async () => {\n          try {\n            await knex.schema.raw('SELECT 1 as 1');\n            throw new Error('Should not reach here');\n          } catch (err) {\n            expect(err.message).to.eql('connect ECONNREFUSED 127.0.0.1:601');\n          }\n        });","file":"integration2/dialects/mysql2.spec.js","skipped":false,"dir":"test"},{"name":"it connects when using string profile for SSL","suites":["MySQL dialect","Connection configuration"," - connection string with string SSL profile"],"updatePoint":{"line":51,"column":59,"index":1525},"line":51,"code":"          it('it connects when using string profile for SSL', async () => {\n            try {\n              await knex.schema.raw(\"SHOW STATUS LIKE 'Ssl_cipher'\");\n            } catch (err) {\n              expect(err.message).to.eq(\"Unknown SSL profile 'Knex Test'\");\n            }\n          });","file":"integration2/dialects/mysql2.spec.js","skipped":false,"dir":"test"},{"name":"it connects when using JSON query strings for SSL","suites":["MySQL dialect","Connection configuration"," - connection string with JSON"],"updatePoint":{"line":69,"column":63,"index":2232},"line":69,"code":"          it('it connects when using JSON query strings for SSL', async () => {\n            const result = await knex.schema.raw(\"SHOW STATUS LIKE 'Ssl_cipher'\");\n            expect(result[0][0].Value).not.to.be.empty;\n          });","file":"integration2/dialects/mysql2.spec.js","skipped":false,"dir":"test"},{"name":"works correctly when called multiple times","suites":["knex","destroy"],"updatePoint":{"line":17,"column":54,"index":393},"line":17,"code":"        it('works correctly when called multiple times', async () => {\n          await knex.destroy();\n          await knex.destroy();\n        });","file":"integration2/knex.spec.js","skipped":false,"dir":"test"},{"name":"should not fail on null default for timestamp","suites":["Migrations","knex.migrate"],"updatePoint":{"line":73,"column":57,"index":1740},"line":73,"code":"        it('should not fail on null default for timestamp', async () => {\n          try {\n            await knex.schema.dropTableIfExists('null_date');\n            await knex.migrate.latest({\n              directory: 'test/integration2/migrate/null_timestamp_default'\n            });\n            await knex.into('null_date').insert({\n              dummy: 'cannot insert empty object'\n            });\n            const rows = await knex('null_date').first();\n            expect(rows.deleted_at).to.equal(null);\n          } finally {\n            await knex.migrate.rollback({\n              directory: 'test/integration2/migrate/null_timestamp_default'\n            });\n          }\n        });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should not fail drop-and-recreate-column operation when using promise chain","suites":["Migrations","knex.migrate"],"updatePoint":{"line":90,"column":87,"index":2460},"line":90,"code":"        it('should not fail drop-and-recreate-column operation when using promise chain', () => {\n          return knex.migrate.latest({\n            directory: 'test/integration2/migrate/drop-and-recreate'\n          }).then(() => {\n            return knex.migrate.rollback({\n              directory: 'test/integration2/migrate/drop-and-recreate'\n            });\n          });\n        });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should not fail drop-and-recreate-column operation when using promise chain and schema","suites":["Migrations","knex.migrate"],"updatePoint":{"line":101,"column":100,"index":2896},"line":101,"code":"          it('should not fail drop-and-recreate-column operation when using promise chain and schema', () => {\n            return knex.migrate.latest({\n              directory: 'test/integration2/migrate/drop-and-recreate-with-schema'\n            }).then(() => {\n              return knex.migrate.rollback({\n                directory: 'test/integration2/migrate/drop-and-recreate-with-schema'\n              });\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should not fail rename-and-drop-column with multiline sql from legacy db","suites":["Migrations","knex.migrate"],"updatePoint":{"line":113,"column":86,"index":3364},"line":113,"code":"          it('should not fail rename-and-drop-column with multiline sql from legacy db', async () => {\n            const knexConfig = _.extend({}, config.sqlite3, {\n              connection: {\n                filename: __dirname + '/../../multilineCreateMaster.sqlite3'\n              },\n              migrations: {\n                directory: 'test/integration2/migrate/rename-and-drop-column-with-multiline-sql-from-legacy-db'\n              }\n            });\n\n            const knexInstance = knexLib(knexConfig);\n            const db = logger(knexInstance);\n            await db.migrate.latest();\n            await db.migrate.rollback();\n            await knexInstance.destroy();\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should not fail drop-and-recreate-column operation when using async/await","suites":["Migrations","knex.migrate"],"updatePoint":{"line":131,"column":85,"index":4069},"line":131,"code":"        it('should not fail drop-and-recreate-column operation when using async/await', () => {\n          return knex.migrate.latest({\n            directory: 'test/integration2/migrate/async-await-drop-and-recreate'\n          }).then(() => {\n            return knex.migrate.rollback({\n              directory: 'test/integration2/migrate/async-await-drop-and-recreate'\n            });\n          });\n        });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should not fail drop-and-recreate-column operation when using async/await and schema","suites":["Migrations","knex.migrate"],"updatePoint":{"line":142,"column":98,"index":4527},"line":142,"code":"          it('should not fail drop-and-recreate-column operation when using async/await and schema', () => {\n            return knex.migrate.latest({\n              directory: 'test/integration2/migrate/async-await-drop-and-recreate-with-schema'\n            }).then(() => {\n              return knex.migrate.rollback({\n                directory: 'test/integration2/migrate/async-await-drop-and-recreate-with-schema'\n              });\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should create a new migration file with the create method","suites":["Migrations","knex.migrate"],"updatePoint":{"line":153,"column":69,"index":4972},"line":153,"code":"        it('should create a new migration file with the create method', function () {\n          return knex.migrate.make('test').then(function (name) {\n            name = path.basename(name);\n            expect(name.split('_')[0]).to.have.length(14);\n            expect(name.split('_')[1].split('.')[0]).to.equal('test');\n          });\n        });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should list the current migration state with the currentVersion method","suites":["Migrations","knex.migrate"],"updatePoint":{"line":160,"column":82,"index":5333},"line":160,"code":"        it('should list the current migration state with the currentVersion method', function () {\n          return knex.migrate.currentVersion().then(function (version) {\n            equal(version, 'none');\n          });\n        });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should create a migrations lock table","suites":["Migrations","knex.migrate","knex.migrate.status"],"updatePoint":{"line":178,"column":51,"index":6070},"line":178,"code":"          it('should create a migrations lock table', function () {\n            return knex.schema.hasTable('knex_migrations_lock').then(function (exists) {\n              expect(exists).to.equal(true);\n              return knex.schema.hasColumn('knex_migrations_lock', 'is_locked').then(function (exists) {\n                expect(exists).to.equal(true);\n              });\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should return 0 if code matches DB","suites":["Migrations","knex.migrate","knex.migrate.status"],"updatePoint":{"line":186,"column":48,"index":6469},"line":186,"code":"          it('should return 0 if code matches DB', function () {\n            return knex.migrate.status({\n              directory: 'test/integration2/migrate/test'\n            }).then(function (migrationLevel) {\n              expect(migrationLevel).to.equal(0);\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should return a negative number if the DB is behind","suites":["Migrations","knex.migrate","knex.migrate.status"],"updatePoint":{"line":193,"column":65,"index":6778},"line":193,"code":"          it('should return a negative number if the DB is behind', function () {\n            return knex.migrate.rollback({\n              directory: 'test/integration2/migrate/test'\n            }).then(function () {\n              return knex.migrate.status({\n                directory: 'test/integration2/migrate/test'\n              }).then(function (migrationLevel) {\n                expect(migrationLevel).to.equal(-2);\n              });\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should return a positive number if the DB is ahead","suites":["Migrations","knex.migrate","knex.migrate.status"],"updatePoint":{"line":204,"column":64,"index":7248},"line":204,"code":"          it('should return a positive number if the DB is ahead', async () => {\n            const [migration1, migration2, migration3] = await Promise.all([knex('knex_migrations').returning('id').insert({\n              name: 'foobar',\n              batch: 5,\n              migration_time: new Date()\n            }), knex('knex_migrations').returning('id').insert({\n              name: 'foobar',\n              batch: 5,\n              migration_time: new Date()\n            }), knex('knex_migrations').returning('id').insert({\n              name: 'foobarbaz',\n              batch: 6,\n              migration_time: new Date()\n            })]);\n            return knex.migrate.status({\n              directory: 'test/integration2/migrate/test'\n            }).then(function (migrationLevel) {\n              expect(migrationLevel).to.equal(3);\n            }).then(function () {\n              // Cleanup the added migrations\n              if (isRedshift(knex)) {\n                return knex('knex_migrations').where('name', 'like', '%foobar%').del();\n              }\n\n              return knex('knex_migrations').where('id', !isNaN(migration1[0]) ? migration1[0] : migration1[0].id).orWhere('id', !isNaN(migration2[0]) ? migration2[0] : migration2[0].id).orWhere('id', !isNaN(migration3[0]) ? migration3[0] : migration3[0].id).del();\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should remove the record in the lock table once finished","suites":["Migrations","knex.migrate","knex.migrate.latest"],"updatePoint":{"line":238,"column":70,"index":8838},"line":238,"code":"          it('should remove the record in the lock table once finished', function () {\n            return knex('knex_migrations_lock').select('*').then(function (data) {\n              expect(data[0]).to.have.property('is_locked');\n              expect(Number.parseInt(data[0].is_locked)).to.not.be.ok;\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should throw error if the migrations are already running","suites":["Migrations","knex.migrate","knex.migrate.latest"],"updatePoint":{"line":244,"column":70,"index":9170},"line":244,"code":"          it('should throw error if the migrations are already running', function () {\n            return knex('knex_migrations_lock').update({\n              is_locked: 1\n            }).then(function () {\n              return knex.migrate.latest({\n                directory: 'test/integration2/migrate/test'\n              }).then(function () {\n                throw new Error('then should not execute');\n              });\n            }).catch(function (error) {\n              expect(error).to.have.property('message', 'Migration table is already locked');\n              return knex('knex_migrations_lock').select('*');\n            }).then(function (data) {\n              assertNumber(knex, data[0].is_locked, 1); // Clean up lock for other tests\n\n              return knex('knex_migrations_lock').update({\n                is_locked: 0\n              });\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should work with concurent calls to _lockMigrations","suites":["Migrations","knex.migrate","knex.migrate.latest"],"updatePoint":{"line":264,"column":65,"index":10048},"line":264,"code":"          it('should work with concurent calls to _lockMigrations', async function () {\n            if (isSQLite(knex)) {\n              // sqlite doesn't support concurrency\n              this.skip();\n              return;\n            }\n\n            const migrator = knex.migrate;\n\n            try {\n              // Start two transactions and call _lockMigrations in each of them.\n              // Simulate a race condition by waiting until both are started before\n              // attempting to commit either one. Exactly one should succeed.\n              //\n              // Both orderings are legitimate, but in practice the first transaction\n              // to start will be the one that succeeds in all currently supported\n              // databases (CockroachDB 1.x is an example of a database where the\n              // second transaction would win, but this changed in 2.0). This test\n              // assumes the first transaction wins, but could be refactored to support\n              // both orderings if desired.\n              const trx1 = await knex.transaction();\n              await migrator._lockMigrations(trx1);\n              const trx2 = await knex.transaction(); // trx1 has a pending write lock, so the second call to _lockMigrations\n              // will block (unless we're on a DB that resolves the transaction in\n              // the other order as mentioned above).\n              // Save the promise, then wait a short time to ensure it's had time\n              // to start its query and get blocked.\n\n              const trx2Promise = migrator._lockMigrations(trx2);\n\n              await delay(100);\n              const isTrx2PromisePending = await Promise.race([delay(10).then(() => true), trx2Promise.catch(() => {}).then(() => false)]);\n\n              if (!isTrx2PromisePending) {\n                throw new Error('expected trx2 to be pending');\n              }\n\n              await trx1.commit(); // trx1 has completed and unblocked trx2, which should now fail.\n\n              try {\n                await trx2Promise;\n                throw new Error('expected trx2 to fail');\n              } catch (error) {\n                expect(error).to.have.property('message').that.includes('already locked');\n                await trx2.rollback();\n              }\n            } finally {\n              // Clean up after ourselves (I'm not sure why the before() at the\n              // top of this file isn't doing it, but if this test fails without\n              // this call it tends to cause cascading failures).\n              await migrator._freeLock();\n            }\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should report failing migration","suites":["Migrations","knex.migrate","knex.migrate.latest"],"updatePoint":{"line":317,"column":45,"index":12635},"line":317,"code":"          it('should report failing migration', function () {\n            const migrator = knex.migrate;\n            return migrator.latest({\n              directory: 'test/integration2/migrate/test_with_invalid'\n            }).then(function () {\n              throw new Error('then should not execute');\n            }).catch(function (error) {\n              // This will fail because of the invalid migration\n              expect(error).to.have.property('message').that.includes('unknown_table');\n              expect(migrator).to.have.property('_activeMigration').to.have.property('fileName', '20150109002832_invalid_migration.js');\n            }).then(function (data) {\n              // Clean up lock for other tests\n              // TODO: Remove this code to reproduce https://github.com/tgriesser/knex/issues/2925\n              // It is only relevant for Oracle, most likely there is a bug somewhere that needs fixing\n              return knex('knex_migrations_lock').update({\n                is_locked: 0\n              });\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should release lock if non-locking related error is thrown","suites":["Migrations","knex.migrate","knex.migrate.latest"],"updatePoint":{"line":336,"column":72,"index":13721},"line":336,"code":"          it('should release lock if non-locking related error is thrown', function () {\n            return knex('knex_migrations_lock').select('*').then(function (data) {\n              expect(Number.parseInt(data[0].is_locked)).to.not.be.ok;\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should run all migration files in the specified directory","suites":["Migrations","knex.migrate","knex.migrate.latest"],"updatePoint":{"line":341,"column":71,"index":13993},"line":341,"code":"          it('should run all migration files in the specified directory', function () {\n            return knex('knex_migrations').select('*').then(function (data) {\n              expect(data.length).to.equal(2);\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should run the migrations from oldest to newest","suites":["Migrations","knex.migrate","knex.migrate.latest"],"updatePoint":{"line":346,"column":61,"index":14226},"line":346,"code":"          it('should run the migrations from oldest to newest', function () {\n            if (isOracle(knex)) {\n              return knex('knex_migrations').orderBy('migration_time', 'asc').select('*').then(function (data) {\n                expect(path.basename(data[0].name)).to.equal('20131019235242_migration_1.js');\n                expect(path.basename(data[1].name)).to.equal('20131019235306_migration_2.js');\n              });\n            } else {\n              return knex('knex_migrations').orderBy('id', 'asc').select('*').then(function (data) {\n                expect(path.basename(data[0].name)).to.equal('20131019235242_migration_1.js');\n                expect(path.basename(data[1].name)).to.equal('20131019235306_migration_2.js');\n              });\n            }\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should create all specified tables and columns","suites":["Migrations","knex.migrate","knex.migrate.latest"],"updatePoint":{"line":359,"column":60,"index":15016},"line":359,"code":"          it('should create all specified tables and columns', function () {\n            // Map the table names to promises that evaluate chai expectations to\n            // confirm that the table exists and the 'id' and 'name' columns exist\n            // within the table\n            return Promise.all(tables.map(function (table) {\n              return knex.schema.hasTable(table).then(function (exists) {\n                expect(exists).to.equal(true);\n\n                if (exists) {\n                  return Promise.all([knex.schema.hasColumn(table, 'id').then(function (exists) {\n                    expect(exists).to.equal(true);\n                  }), knex.schema.hasColumn(table, 'name').then(function (exists) {\n                    expect(exists).to.equal(true);\n                  })]);\n                }\n              });\n            }));\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should create tables specified in both directories","suites":["Migrations","knex.migrate","knex.migrate.latest - multiple directories"],"updatePoint":{"line":389,"column":64,"index":16348},"line":389,"code":"          it('should create tables specified in both directories', () => {\n            // Map the table names to promises that evaluate chai expectations to\n            // confirm that the table exists\n            const expectedTables = ['migration_test_1', 'migration_test_2', 'migration_test_2_1', 'migration_test_3', 'migration_test_4', 'migration_test_4_1'];\n            return Promise.all(expectedTables.map(function (table) {\n              return knex.schema.hasTable(table).then(function (exists) {\n                expect(exists).to.equal(true);\n              });\n            }));\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should delete the most recent batch from the migration log","suites":["Migrations","knex.migrate","knex.migrate.rollback"],"updatePoint":{"line":401,"column":72,"index":17026},"line":401,"code":"          it('should delete the most recent batch from the migration log', function () {\n            return knex.migrate.rollback({\n              directory: 'test/integration2/migrate/test'\n            }).then(([batchNo, log]) => {\n              assertNumber(knex, batchNo, 1);\n              expect(log).to.have.length(2);\n              expect(log[0]).to.contain(batchNo);\n              return knex('knex_migrations').select('*').then(function (data) {\n                expect(data.length).to.equal(0);\n              });\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should drop tables as specified in the batch","suites":["Migrations","knex.migrate","knex.migrate.rollback"],"updatePoint":{"line":413,"column":58,"index":17562},"line":413,"code":"          it('should drop tables as specified in the batch', function () {\n            return Promise.all(tables.map(function (table) {\n              return knex.schema.hasTable(table).then(function (exists) {\n                expect(!!exists).to.equal(false);\n              });\n            }));\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should delete all batches from the migration log","suites":["Migrations","knex.migrate","knex.migrate.rollback - all"],"updatePoint":{"line":431,"column":62,"index":18291},"line":431,"code":"          it('should delete all batches from the migration log', () => {\n            return knex.migrate.rollback({\n              directory: ['test/integration2/migrate/test', 'test/integration2/migrate/test2']\n            }, true).then(([batchNo, log]) => {\n              assertNumber(knex, batchNo, 2);\n              expect(log).to.have.length(4);\n              return knex('knex_migrations').select('*').then(function (data) {\n                expect(data.length).to.equal(0);\n              });\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should drop tables as specified in the batch","suites":["Migrations","knex.migrate","knex.migrate.rollback - all"],"updatePoint":{"line":442,"column":58,"index":18814},"line":442,"code":"          it('should drop tables as specified in the batch', () => {\n            return Promise.all(tables.map(function (table) {\n              return knex.schema.hasTable(table).then(function (exists) {\n                expect(!!exists).to.equal(false);\n              });\n            }));\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should only rollback migrations that have been completed and in reverse chronological order","suites":["Migrations","knex.migrate","knex.migrate.rollback - all"],"updatePoint":{"line":456,"column":105,"index":19388},"line":456,"code":"          it('should only rollback migrations that have been completed and in reverse chronological order', () => {\n            return knex.migrate.rollback({\n              directory: ['test/integration2/migrate/test', 'test/integration2/migrate/test2']\n            }, true).then(([batchNo, log]) => {\n              assertNumber(knex, batchNo, 1);\n              expect(log).to.have.length(2);\n              fs.readdirSync('test/integration2/migrate/test').reverse().forEach((fileName, index) => {\n                expect(fileName).to.equal(log[index]);\n              });\n              return knex('knex_migrations').select('*').then(function (data) {\n                expect(data.length).to.equal(0);\n              });\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should drop tables as specified in the batch","suites":["Migrations","knex.migrate","knex.migrate.rollback - all"],"updatePoint":{"line":470,"column":58,"index":20088},"line":470,"code":"          it('should drop tables as specified in the batch', () => {\n            return Promise.all(tables.map(function (table) {\n              return knex.schema.hasTable(table).then(function (exists) {\n                expect(!!exists).to.equal(false);\n              });\n            }));\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should only run the first migration if no migrations have run","suites":["Migrations","knex.migrate","knex.migrate.up"],"updatePoint":{"line":484,"column":75,"index":20629},"line":484,"code":"          it('should only run the first migration if no migrations have run', function () {\n            return knex.migrate.up({\n              directory: 'test/integration2/migrate/test'\n            }).then(() => {\n              return knex('knex_migrations').select('*').then(function (data) {\n                expect(data).to.have.length(1);\n                expect(path.basename(data[0].name)).to.equal('20131019235242_migration_1.js');\n              });\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should only run the next migration that has not yet run if other migrations have already run","suites":["Migrations","knex.migrate","knex.migrate.up"],"updatePoint":{"line":494,"column":106,"index":21146},"line":494,"code":"          it('should only run the next migration that has not yet run if other migrations have already run', function () {\n            return knex.migrate.up({\n              directory: 'test/integration2/migrate/test'\n            }).then(() => {\n              return knex.migrate.up({\n                directory: 'test/integration2/migrate/test'\n              }).then(() => {\n                return knex('knex_migrations').select('*').then(function (data) {\n                  expect(data).to.have.length(2);\n                  expect(path.basename(data[0].name)).to.equal('20131019235242_migration_1.js');\n                  expect(path.basename(data[1].name)).to.equal('20131019235306_migration_2.js');\n                });\n              });\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should not error if all migrations have already been run","suites":["Migrations","knex.migrate","knex.migrate.up"],"updatePoint":{"line":509,"column":70,"index":21879},"line":509,"code":"          it('should not error if all migrations have already been run', function () {\n            return knex.migrate.latest({\n              directory: 'test/integration2/migrate/test'\n            }).then(() => {\n              return knex.migrate.up({\n                directory: 'test/integration2/migrate/test'\n              }).then(data => {\n                expect(data).to.be.an('array');\n              });\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should drop a column with a default constraint (mssql)","suites":["Migrations","knex.migrate","knex.migrate.up"],"updatePoint":{"line":520,"column":68,"index":22318},"line":520,"code":"          it('should drop a column with a default constraint (mssql)', async () => {\n            await knex.migrate.latest({\n              directory: 'test/integration2/migrate/drop-with-default-constraint'\n            });\n            await knex.migrate.rollback({\n              directory: 'test/integration2/migrate/drop-with-default-constraint'\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should partially run","suites":["Migrations","knex.migrate","knex.migrate.up","with transactions disabled"],"updatePoint":{"line":543,"column":36,"index":23282},"line":543,"code":"            it('should partially run', async () => {\n              await expect(knex.migrate.up({\n                directory: 'test/integration2/migrate/test_single_per_migration_trx_disabled',\n                name: 'up.js'\n              })).to.eventually.be.rejected;\n              const {\n                value\n              } = await knex.table('test_transactions').select('value').first();\n              assertNumber(knex, value, 1); // updated by migration before error\n            });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should only undo the last migration that was run if all migrations have run","suites":["Migrations","knex.migrate","knex.migrate.down","with transactions enabled"],"updatePoint":{"line":567,"column":91,"index":24312},"line":567,"code":"            it('should only undo the last migration that was run if all migrations have run', async () => {\n              await knex.migrate.down({\n                directory: ['test/integration2/migrate/test']\n              });\n              const data = await knex('knex_migrations').select('*');\n              expect(data).to.have.length(1);\n              expect(path.basename(data[0].name)).to.equal('20131019235242_migration_1.js');\n            });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should only undo the last migration that was run if there are other migrations that have not yet run","suites":["Migrations","knex.migrate","knex.migrate.down","with transactions enabled"],"updatePoint":{"line":575,"column":116,"index":24790},"line":575,"code":"            it('should only undo the last migration that was run if there are other migrations that have not yet run', async () => {\n              await knex.migrate.down({\n                directory: ['test/integration2/migrate/test']\n              });\n              await knex.migrate.down({\n                directory: ['test/integration2/migrate/test']\n              });\n              const data = await knex('knex_migrations').select('*');\n              expect(data).to.have.length(0);\n            });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should not error if all migrations have already been undone","suites":["Migrations","knex.migrate","knex.migrate.down","with transactions enabled"],"updatePoint":{"line":585,"column":75,"index":25254},"line":585,"code":"            it('should not error if all migrations have already been undone', async () => {\n              await knex.migrate.rollback({\n                directory: ['test/integration2/migrate/test']\n              }, true);\n              const data = await knex.migrate.down({\n                directory: ['test/integration2/migrate/test']\n              });\n              expect(data).to.be.an('array');\n            });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should partially run","suites":["Migrations","knex.migrate","knex.migrate.down","with transactions disabled"],"updatePoint":{"line":610,"column":36,"index":26274},"line":610,"code":"            it('should partially run', async () => {\n              await knex.migrate.up({\n                directory: 'test/integration2/migrate/test_single_per_migration_trx_disabled',\n                name: 'down.js'\n              });\n              await expect(knex.migrate.down({\n                directory: 'test/integration2/migrate/test_single_per_migration_trx_disabled',\n                name: 'down.js'\n              })).to.eventually.be.rejected;\n              const {\n                value\n              } = await knex.table('test_transactions').select('value').first();\n              assertNumber(knex, value, -1); // updated by migration before error\n            });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"as an array of arrays of pending and completed migrations","suites":["Migrations","knex.migrate","knex.migrate.list","should list pending and completed migrations"],"updatePoint":{"line":635,"column":73,"index":27452},"line":635,"code":"            it('as an array of arrays of pending and completed migrations', async () => {\n              const listedMigrations = await knex.migrate.list(knexConfig);\n              expect(listedMigrations).to.have.lengthOf(2);\n              expect(listedMigrations[0]).to.be.an.instanceof(Array);\n              expect(listedMigrations[1]).to.be.an.instanceof(Array);\n            });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"in the right quantity","suites":["Migrations","knex.migrate","knex.migrate.list","should list pending and completed migrations"],"updatePoint":{"line":641,"column":37,"index":27798},"line":641,"code":"            it('in the right quantity', async () => {\n              let [completed, pending] = await knex.migrate.list(knexConfig);\n              expect(completed).to.have.lengthOf(0);\n              expect(pending).to.have.lengthOf(2);\n              await knex.migrate.latest(knexConfig);\n              [completed, pending] = await knex.migrate.list(knexConfig);\n              expect(completed).to.have.lengthOf(2);\n              expect(pending).to.have.lengthOf(0);\n            });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"with the right object structure for pending migrations","suites":["Migrations","knex.migrate","knex.migrate.list","should list pending and completed migrations"],"updatePoint":{"line":650,"column":70,"index":28314},"line":650,"code":"            it('with the right object structure for pending migrations', async () => {\n              const [completed, pending] = await knex.migrate.list(knexConfig);\n              expect(completed).to.deep.equal([]);\n              expect(pending).to.deep.equal(availableMigrations.map(migration => ({\n                file: migration,\n                directory: knexConfig.directory[0]\n              })));\n            });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"with the right object structure for completed migrations","suites":["Migrations","knex.migrate","knex.migrate.list","should list pending and completed migrations"],"updatePoint":{"line":658,"column":72,"index":28738},"line":658,"code":"            it('with the right object structure for completed migrations', async () => {\n              await knex.migrate.latest(knexConfig);\n              const [completed, pending] = await knex.migrate.list(knexConfig);\n              expect(completed).to.deep.equal(availableMigrations.map(migration => ({\n                name: migration\n              })));\n              expect(pending).to.deep.equal([]);\n            });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"is able to run two migrations in parallel (if no implicit DDL commits)","suites":["Migrations","knex.migrate.latest in parallel"],"updatePoint":{"line":680,"column":84,"index":29582},"line":680,"code":"          it('is able to run two migrations in parallel (if no implicit DDL commits)', function () {\n            return Promise.all([knex.migrate.latest({\n              directory: 'test/integration2/migrate/test'\n            }), knex.migrate.latest({\n              directory: 'test/integration2/migrate/test'\n            })]).then(function () {\n              return knex('knex_migrations').select('*').then(function (data) {\n                expect(data.length).to.equal(2);\n              });\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"is not able to run two migrations in parallel when transactions are disabled","suites":["Migrations","knex.migrate.latest in parallel"],"line":706,"code":"        it.skip('is not able to run two migrations in parallel when transactions are disabled', function () {","file":"integration2/migrate/migration-integration.spec.js","skipped":true,"dir":"test"},{"name":"should create column even in invalid migration","suites":["Migrations","knex.migrate (transactions disabled)","knex.migrate.latest (all transactions disabled)"],"updatePoint":{"line":739,"column":60,"index":32282},"line":739,"code":"          it('should create column even in invalid migration', function () {\n            return knex.schema.hasColumn('migration_test_1', 'transaction').then(function (exists) {\n              expect(exists).to.equal(true);\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should run all working migration files in the specified directory","suites":["Migrations","knex.migrate (transactions disabled)","knex.migrate.latest (per-migration transaction disabled)"],"updatePoint":{"line":756,"column":79,"index":33040},"line":756,"code":"          it('should run all working migration files in the specified directory', function () {\n            return knex('knex_migrations').select('*').then(function (data) {\n              expect(data.length).to.equal(1);\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should create column in invalid migration with transaction disabled","suites":["Migrations","knex.migrate (transactions disabled)","knex.migrate.latest (per-migration transaction disabled)"],"updatePoint":{"line":761,"column":81,"index":33293},"line":761,"code":"          it('should create column in invalid migration with transaction disabled', function () {\n            return knex.schema.hasColumn('migration_test_trx_1', 'transaction').then(function (exists) {\n              expect(exists).to.equal(true);\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should run all working migration files in the specified directory","suites":["Migrations","knex.migrate (transactions disabled)","knex.migrate.latest (per-migration transaction enabled)"],"updatePoint":{"line":779,"column":79,"index":34108},"line":779,"code":"          it('should run all working migration files in the specified directory', function () {\n            return knex('knex_migrations').select('*').then(function (data) {\n              expect(data.length).to.equal(1);\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should not create column for invalid migration with transaction enabled","suites":["Migrations","knex.migrate (transactions disabled)","knex.migrate.latest (per-migration transaction enabled)"],"updatePoint":{"line":784,"column":85,"index":34365},"line":784,"code":"          it('should not create column for invalid migration with transaction enabled', function () {\n            return knex.schema.hasColumn('migration_test_trx_1', 'transaction').then(function (exists) {\n              // MySQL / Oracle commit transactions implicit for most common\n              // migration statements (e.g. CREATE TABLE, ALTER TABLE, DROP TABLE),\n              // so we need to check for dialect\n              if (isMysql(knex) || isOracle(knex)) {\n                expect(exists).to.equal(true);\n              } else {\n                expect(exists).to.equal(false);\n              }\n            });\n          });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should create changelog in the correct schema without transactions","suites":["Migrations","knex.migrate (transactions disabled)","knex.migrate.latest with specific changelog schema"],"updatePoint":{"line":811,"column":82,"index":35544},"line":811,"code":"            it('should create changelog in the correct schema without transactions', function (done) {\n              knex.migrate.latest({\n                directory: 'test/integration2/migrate/test',\n                disableTransactions: true,\n                schemaName: 'testschema'\n              }).then(() => {\n                return knex('testschema.knex_migrations').select('*').then(function (data) {\n                  expect(data.length).to.equal(2);\n                  done();\n                });\n              });\n            });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should create changelog in the correct schema with transactions","suites":["Migrations","knex.migrate (transactions disabled)","knex.migrate.latest with specific changelog schema"],"updatePoint":{"line":823,"column":79,"index":36079},"line":823,"code":"            it('should create changelog in the correct schema with transactions', function (done) {\n              knex.migrate.latest({\n                directory: 'test/integration2/migrate/test',\n                disableTransactions: false,\n                schemaName: 'testschema'\n              }).then(() => {\n                return knex('testschema.knex_migrations').select('*').then(function (data) {\n                  expect(data.length).to.equal(2);\n                  done();\n                });\n              });\n            });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"can accept a custom migration source","suites":["Migrations","migrationSource config"],"updatePoint":{"line":870,"column":48,"index":37516},"line":870,"code":"        it('can accept a custom migration source', function () {\n          return knex.schema.hasColumn('migration_source_test_1', 'name').then(function (exists) {\n            expect(exists).to.equal(true);\n          });\n        });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"can accept a custom migration source","suites":["Migrations","migrationSource config as class"],"updatePoint":{"line":919,"column":48,"index":38831},"line":919,"code":"        it('can accept a custom migration source', function () {\n          return knex.schema.hasColumn('migration_source_test_1', 'name').then(function (exists) {\n            expect(exists).to.equal(true);\n          });\n        });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"does not reset a custom migration source","suites":["Migrations","migrationSource config as class for migrate:make"],"updatePoint":{"line":941,"column":52,"index":39438},"line":941,"code":"        it('does not reset a custom migration source', async () => {\n          const oldLogger = knex.client.logger;\n          const warnMessages = [];\n          knex.client.logger = {\n            warn: msg => {\n              warnMessages.push(msg);\n            }\n          };\n          const migrationSource = new MigrationSource();\n          const fileHelper = new FileTestHelper();\n          await knex.migrate.make('testMigration', {\n            migrationSource\n          });\n          fileHelper.deleteFileGlob(`test/integration2/migrate/migration/*testMigration.js`);\n          knex.client.logger = oldLogger;\n          expect(warnMessages.length).equal(0);\n        });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should create all specified tables and columns","suites":["Migrations","knex.migrate.latest with custom config parameter for table name"],"updatePoint":{"line":967,"column":58,"index":40457},"line":967,"code":"        it('should create all specified tables and columns', function () {\n          const tables = ['migration_test_1', 'migration_test_2', 'migration_test_2_1a'];\n          return Promise.all(tables.map(function (table) {\n            return knex.schema.hasTable(table).then(function (exists) {\n              expect(exists).to.equal(true);\n\n              if (exists) {\n                return Promise.all([knex.schema.hasColumn(table, 'id').then(function (exists) {\n                  expect(exists).to.equal(true);\n                }), knex.schema.hasColumn(table, 'name').then(function (exists) {\n                  expect(exists).to.equal(true);\n                })]);\n              }\n            });\n          }));\n        });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should not create unexpected tables","suites":["Migrations","knex.migrate.latest with custom config parameter for table name"],"updatePoint":{"line":983,"column":47,"index":41173},"line":983,"code":"        it('should not create unexpected tables', function () {\n          const table = 'migration_test_2_1';\n          return knex.schema.hasTable(table).then(function (exists) {\n            expect(exists).to.equal(false);\n          });\n        });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should not fail if there is a missing migration","suites":["Migrations","knex.migrate.latest with disableValidateMigrationList"],"updatePoint":{"line":998,"column":59,"index":41763},"line":998,"code":"        it('should not fail if there is a missing migration', async () => {\n          try {\n            await knex.migrate.latest({\n              directory: 'test/integration2/migrate/test'\n            });\n            await knex.migrate.latest({\n              directory: 'test/integration2/migrate/test_with_missing_first_migration',\n              disableMigrationsListValidation: true\n            });\n          } finally {\n            await knex.migrate.rollback({\n              directory: 'test/integration2/migrate/test'\n            });\n          }\n        });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should insert is_locked value to 1 if lock table not exists","suites":["Migrations","Test lock row"],"updatePoint":{"line":1018,"column":71,"index":42500},"line":1018,"code":"        it('should insert is_locked value to 1 if lock table not exists', async () => {\n          const result = await ensureTable('test', undefined, knex);\n          expect(!!(result || result.length)).is.true;\n          const data = await knex('test_lock').select('*');\n          expect(data[0]).to.have.property('is_locked');\n          expect(Number.parseInt(data[0].is_locked)).to.not.be.ok;\n        });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should is_locked value still be 1 if row already exists","suites":["Migrations","Test lock row"],"updatePoint":{"line":1025,"column":67,"index":42904},"line":1025,"code":"        it('should is_locked value still be 1 if row already exists', async () => {\n          await knex.schema.createTable('test_lock', t => {\n            t.increments('index').primary();\n            t.integer('is_locked');\n          });\n          await knex('test_lock').insert({\n            is_locked: 1\n          });\n          const result = await ensureTable('test', undefined, knex);\n          expect(result).to.false;\n          const data = await knex('test_lock').select('*');\n          expect(data[0]).to.have.property('is_locked');\n          expect(Number.parseInt(data[0].is_locked)).to.be.ok;\n        });","file":"integration2/migrate/migration-integration.spec.js","skipped":false,"dir":"test"},{"name":"should handle simple inserts","suites":["Inserts"],"updatePoint":{"line":66,"column":38,"index":1405},"line":66,"code":"      it('should handle simple inserts', function () {\n        return knex('accounts').insert({\n          first_name: 'Test',\n          last_name: 'User',\n          email: 'test1@example.com',\n          logins: 1,\n          about: 'Lorem ipsum Dolore labore incididunt enim.',\n          created_at: TEST_TIMESTAMP,\n          updated_at: TEST_TIMESTAMP\n        }, 'id').testSql(function (tester) {\n          tester('mysql', 'insert into `accounts` (`about`, `created_at`, `email`, `first_name`, `last_name`, `logins`, `updated_at`) values (?, ?, ?, ?, ?, ?, ?)', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test1@example.com', 'Test', 'User', 1, TEST_TIMESTAMP], [1]);\n          tester('pg', 'insert into \"accounts\" (\"about\", \"created_at\", \"email\", \"first_name\", \"last_name\", \"logins\", \"updated_at\") values (?, ?, ?, ?, ?, ?, ?) returning \"id\"', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test1@example.com', 'Test', 'User', 1, TEST_TIMESTAMP], [{\n            id: '1'\n          }]);\n          tester('pg-redshift', 'insert into \"accounts\" (\"about\", \"created_at\", \"email\", \"first_name\", \"last_name\", \"logins\", \"updated_at\") values (?, ?, ?, ?, ?, ?, ?)', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test1@example.com', 'Test', 'User', 1, TEST_TIMESTAMP], 1);\n          tester('sqlite3', 'insert into `accounts` (`about`, `created_at`, `email`, `first_name`, `last_name`, `logins`, `updated_at`) values (?, ?, ?, ?, ?, ?, ?) returning `id`', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test1@example.com', 'Test', 'User', 1, TEST_TIMESTAMP], [1]);\n          tester('oracledb', 'insert into \"accounts\" (\"about\", \"created_at\", \"email\", \"first_name\", \"last_name\", \"logins\", \"updated_at\") values (?, ?, ?, ?, ?, ?, ?) returning \"id\" into ?', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test1@example.com', 'Test', 'User', 1, TEST_TIMESTAMP, function (v) {\n            return v.toString() === '[object ReturningHelper:id]';\n          }], [{\n            id: 1\n          }]);\n          tester('mssql', 'insert into [accounts] ([about], [created_at], [email], [first_name], [last_name], [logins], [updated_at]) output inserted.[id] values (?, ?, ?, ?, ?, ?, ?)', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test1@example.com', 'Test', 'User', 1, TEST_TIMESTAMP], [{\n            id: '1'\n          }]);\n        });\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"should handle multi inserts","suites":["Inserts"],"updatePoint":{"line":92,"column":37,"index":3837},"line":92,"code":"      it('should handle multi inserts', function () {\n        return knex('accounts').insert([{\n          first_name: 'Test',\n          last_name: 'User',\n          email: 'test2@example.com',\n          logins: 1,\n          about: 'Lorem ipsum Dolore labore incididunt enim.',\n          created_at: TEST_TIMESTAMP,\n          updated_at: TEST_TIMESTAMP\n        }, {\n          first_name: 'Test',\n          last_name: 'User',\n          email: 'test3@example.com',\n          about: 'Lorem ipsum Dolore labore incididunt enim.',\n          logins: 2,\n          created_at: TEST_TIMESTAMP,\n          updated_at: TEST_TIMESTAMP\n        }], 'id').testSql(function (tester) {\n          tester('mysql', 'insert into `accounts` (`about`, `created_at`, `email`, `first_name`, `last_name`, `logins`, `updated_at`) values (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?)', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test2@example.com', 'Test', 'User', 1, TEST_TIMESTAMP, 'Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test3@example.com', 'Test', 'User', 2, TEST_TIMESTAMP], [1]);\n          tester('pg', 'insert into \"accounts\" (\"about\", \"created_at\", \"email\", \"first_name\", \"last_name\", \"logins\", \"updated_at\") values (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?) returning \"id\"', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test2@example.com', 'Test', 'User', 1, TEST_TIMESTAMP, 'Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test3@example.com', 'Test', 'User', 2, TEST_TIMESTAMP], [{\n            id: '1'\n          }, {\n            id: '2'\n          }]);\n          tester('pg-redshift', 'insert into \"accounts\" (\"about\", \"created_at\", \"email\", \"first_name\", \"last_name\", \"logins\", \"updated_at\") values (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?)', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test2@example.com', 'Test', 'User', 1, TEST_TIMESTAMP, 'Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test3@example.com', 'Test', 'User', 2, TEST_TIMESTAMP], 2);\n          tester('sqlite3', 'insert into `accounts` (`about`, `created_at`, `email`, `first_name`, `last_name`, `logins`, `updated_at`) select ? as `about`, ? as `created_at`, ? as `email`, ? as `first_name`, ? as `last_name`, ? as `logins`, ? as `updated_at` union all select ? as `about`, ? as `created_at`, ? as `email`, ? as `first_name`, ? as `last_name`, ? as `logins`, ? as `updated_at` returning `id`', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test2@example.com', 'Test', 'User', 1, TEST_TIMESTAMP, 'Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test3@example.com', 'Test', 'User', 2, TEST_TIMESTAMP], [2]);\n          tester('oracledb', 'begin execute immediate \\'insert into \"accounts\" (\"about\", \"created_at\", \"email\", \"first_name\", \"last_name\", \"logins\", \"updated_at\") values (:1, :2, :3, :4, :5, :6, :7) returning \"id\" into :8\\' using ?, ?, ?, ?, ?, ?, ?, out ?; execute immediate \\'insert into \"accounts\" (\"about\", \"created_at\", \"email\", \"first_name\", \"last_name\", \"logins\", \"updated_at\") values (:1, :2, :3, :4, :5, :6, :7) returning \"id\" into :8\\' using ?, ?, ?, ?, ?, ?, ?, out ?;end;', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test2@example.com', 'Test', 'User', 1, TEST_TIMESTAMP, function (v) {\n            return v.toString() === '[object ReturningHelper:id]';\n          }, 'Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test3@example.com', 'Test', 'User', 2, TEST_TIMESTAMP, function (v) {\n            return v.toString() === '[object ReturningHelper:id]';\n          }], [{\n            id: 1\n          }, {\n            id: 2\n          }]);\n          tester('mssql', 'insert into [accounts] ([about], [created_at], [email], [first_name], [last_name], [logins], [updated_at]) output inserted.[id] values (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?)', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test2@example.com', 'Test', 'User', 1, TEST_TIMESTAMP, 'Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test3@example.com', 'Test', 'User', 2, TEST_TIMESTAMP], [{\n            id: '1'\n          }, {\n            id: '2'\n          }]);\n        });\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"should allow for using the `asCallback` interface","suites":["Inserts"],"updatePoint":{"line":134,"column":59,"index":8085},"line":134,"code":"      it('should allow for using the `asCallback` interface', function (ok) {\n        knex('test_table_two').insert([{\n          account_id: 1,\n          details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.',\n          status: 0\n        }, {\n          account_id: 2,\n          details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.',\n          status: 1\n        }, {\n          account_id: 3,\n          details: '',\n          status: 1\n        }], 'id').testSql(function (tester) {\n          tester('oracledb', 'begin execute immediate \\'insert into \"test_table_two\" (\"account_id\", \"details\", \"status\") values (:1, :2, :3) returning \"id\" into :4\\' using ?, ?, ?, out ?; execute immediate \\'insert into \"test_table_two\" (\"account_id\", \"details\", \"status\") values (:1, :2, :3) returning \"id\" into :4\\' using ?, ?, ?, out ?; execute immediate \\'insert into \"test_table_two\" (\"account_id\", \"details\", \"status\") values (:1, :2, :3) returning \"id\" into :4\\' using ?, ?, ?, out ?;end;', [1, 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.', 0, function (v) {\n            return v.toString() === '[object ReturningHelper:id]';\n          }, 2, 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.', 1, function (v) {\n            return v.toString() === '[object ReturningHelper:id]';\n          }, 3, '', 1, function (v) {\n            return v.toString() === '[object ReturningHelper:id]';\n          }], ['1', '2', '3']);\n        }).asCallback(function (err) {\n          if (err) return ok(err);\n          ok();\n        });\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"should take hashes passed into insert and keep them in the correct order","suites":["Inserts"],"updatePoint":{"line":160,"column":82,"index":9984},"line":160,"code":"      it('should take hashes passed into insert and keep them in the correct order', function () {\n        return knex('accounts').insert([{\n          first_name: 'Test',\n          last_name: 'User',\n          email: 'test4@example.com',\n          about: 'Lorem ipsum Dolore labore incididunt enim.',\n          logins: 2,\n          created_at: TEST_TIMESTAMP,\n          updated_at: TEST_TIMESTAMP\n        }, {\n          first_name: 'Test',\n          about: 'Lorem ipsum Dolore labore incididunt enim.',\n          logins: 2,\n          created_at: TEST_TIMESTAMP,\n          updated_at: TEST_TIMESTAMP,\n          last_name: 'User',\n          email: 'test5@example.com'\n        }], 'id').testSql(function (tester) {\n          tester('mysql', 'insert into `accounts` (`about`, `created_at`, `email`, `first_name`, `last_name`, `logins`, `updated_at`) values (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?)', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test4@example.com', 'Test', 'User', 2, TEST_TIMESTAMP, 'Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test5@example.com', 'Test', 'User', 2, TEST_TIMESTAMP], [1]);\n          tester('pg', 'insert into \"accounts\" (\"about\", \"created_at\", \"email\", \"first_name\", \"last_name\", \"logins\", \"updated_at\") values (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?) returning \"id\"', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test4@example.com', 'Test', 'User', 2, TEST_TIMESTAMP, 'Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test5@example.com', 'Test', 'User', 2, TEST_TIMESTAMP], [{\n            id: '1'\n          }, {\n            id: '2'\n          }]);\n          tester('pg-redshift', 'insert into \"accounts\" (\"about\", \"created_at\", \"email\", \"first_name\", \"last_name\", \"logins\", \"updated_at\") values (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?)', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test4@example.com', 'Test', 'User', 2, TEST_TIMESTAMP, 'Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test5@example.com', 'Test', 'User', 2, TEST_TIMESTAMP], 2);\n          tester('sqlite3', 'insert into `accounts` (`about`, `created_at`, `email`, `first_name`, `last_name`, `logins`, `updated_at`) select ? as `about`, ? as `created_at`, ? as `email`, ? as `first_name`, ? as `last_name`, ? as `logins`, ? as `updated_at` union all select ? as `about`, ? as `created_at`, ? as `email`, ? as `first_name`, ? as `last_name`, ? as `logins`, ? as `updated_at` returning `id`', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test4@example.com', 'Test', 'User', 2, TEST_TIMESTAMP, 'Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test5@example.com', 'Test', 'User', 2, TEST_TIMESTAMP], [2]);\n          tester('oracledb', 'begin execute immediate \\'insert into \"accounts\" (\"about\", \"created_at\", \"email\", \"first_name\", \"last_name\", \"logins\", \"updated_at\") values (:1, :2, :3, :4, :5, :6, :7) returning \"id\" into :8\\' using ?, ?, ?, ?, ?, ?, ?, out ?; execute immediate \\'insert into \"accounts\" (\"about\", \"created_at\", \"email\", \"first_name\", \"last_name\", \"logins\", \"updated_at\") values (:1, :2, :3, :4, :5, :6, :7) returning \"id\" into :8\\' using ?, ?, ?, ?, ?, ?, ?, out ?;end;', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test4@example.com', 'Test', 'User', 2, TEST_TIMESTAMP, function (v) {\n            return v.toString() === '[object ReturningHelper:id]';\n          }, 'Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test5@example.com', 'Test', 'User', 2, TEST_TIMESTAMP, function (v) {\n            return v.toString() === '[object ReturningHelper:id]';\n          }], [{\n            id: 1\n          }, {\n            id: 2\n          }]);\n          tester('mssql', 'insert into [accounts] ([about], [created_at], [email], [first_name], [last_name], [logins], [updated_at]) output inserted.[id] values (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?)', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test4@example.com', 'Test', 'User', 2, TEST_TIMESTAMP, 'Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test5@example.com', 'Test', 'User', 2, TEST_TIMESTAMP], [{\n            id: '1'\n          }, {\n            id: '2'\n          }]);\n        });\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"will fail when multiple inserts are made into a unique column","suites":["Inserts"],"updatePoint":{"line":202,"column":71,"index":14244},"line":202,"code":"      it('will fail when multiple inserts are made into a unique column', async function () {\n        if (isRedshift(knex)) {\n          return this.skip();\n        }\n\n        await knex('accounts').where('id', '>', 1).orWhere('x', 2).insert({\n          first_name: 'Test',\n          last_name: 'User',\n          email: 'test5@example.com',\n          about: 'Lorem ipsum Dolore labore incididunt enim.',\n          logins: 2,\n          created_at: TEST_TIMESTAMP,\n          updated_at: TEST_TIMESTAMP\n        }, 'id');\n        await knex('accounts').where('id', '>', 1).orWhere('x', 2).insert({\n          first_name: 'Test',\n          last_name: 'User',\n          email: 'test5@example.com',\n          about: 'Lorem ipsum Dolore labore incididunt enim.',\n          logins: 2,\n          created_at: TEST_TIMESTAMP,\n          updated_at: TEST_TIMESTAMP\n        }, 'id').testSql(function (tester) {\n          tester('mysql', 'insert into `accounts` (`about`, `created_at`, `email`, `first_name`, `last_name`, `logins`, `updated_at`) values (?, ?, ?, ?, ?, ?, ?)', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test5@example.com', 'Test', 'User', 2, TEST_TIMESTAMP]);\n          tester('pg', 'insert into \"accounts\" (\"about\", \"created_at\", \"email\", \"first_name\", \"last_name\", \"logins\", \"updated_at\") values (?, ?, ?, ?, ?, ?, ?) returning \"id\"', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test5@example.com', 'Test', 'User', 2, TEST_TIMESTAMP]);\n          tester('sqlite3', 'insert into `accounts` (`about`, `created_at`, `email`, `first_name`, `last_name`, `logins`, `updated_at`) values (?, ?, ?, ?, ?, ?, ?) returning `id`', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test5@example.com', 'Test', 'User', 2, TEST_TIMESTAMP]);\n          tester('oracledb', 'insert into \"accounts\" (\"about\", \"created_at\", \"email\", \"first_name\", \"last_name\", \"logins\", \"updated_at\") values (?, ?, ?, ?, ?, ?, ?) returning \"id\" into ?', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test5@example.com', 'Test', 'User', 2, TEST_TIMESTAMP, function (v) {\n            return v.toString() === '[object ReturningHelper:id]';\n          }]);\n          tester('mssql', 'insert into [accounts] ([about], [created_at], [email], [first_name], [last_name], [logins], [updated_at]) output inserted.[id] values (?, ?, ?, ?, ?, ?, ?)', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test5@example.com', 'Test', 'User', 2, TEST_TIMESTAMP]);\n        }).then(function () {\n          throw new Error('There should be a fail when multi-insert are made in unique col.');\n        }, function () {});\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"should drop any where clause bindings","suites":["Inserts"],"updatePoint":{"line":236,"column":47,"index":16877},"line":236,"code":"      it('should drop any where clause bindings', function () {\n        return knex('accounts').where('id', '>', 1).orWhere('x', 2).insert({\n          first_name: 'Test',\n          last_name: 'User',\n          email: 'test6@example.com',\n          about: 'Lorem ipsum Dolore labore incididunt enim.',\n          logins: 2,\n          created_at: TEST_TIMESTAMP,\n          updated_at: TEST_TIMESTAMP\n        }, 'id').testSql(function (tester) {\n          tester('mysql', 'insert into `accounts` (`about`, `created_at`, `email`, `first_name`, `last_name`, `logins`, `updated_at`) values (?, ?, ?, ?, ?, ?, ?)', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test6@example.com', 'Test', 'User', 2, TEST_TIMESTAMP], [1]);\n          tester('pg', 'insert into \"accounts\" (\"about\", \"created_at\", \"email\", \"first_name\", \"last_name\", \"logins\", \"updated_at\") values (?, ?, ?, ?, ?, ?, ?) returning \"id\"', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test6@example.com', 'Test', 'User', 2, TEST_TIMESTAMP], [{\n            id: '1'\n          }]);\n          tester('pg-redshift', 'insert into \"accounts\" (\"about\", \"created_at\", \"email\", \"first_name\", \"last_name\", \"logins\", \"updated_at\") values (?, ?, ?, ?, ?, ?, ?)', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test6@example.com', 'Test', 'User', 2, TEST_TIMESTAMP], 1);\n          tester('sqlite3', 'insert into `accounts` (`about`, `created_at`, `email`, `first_name`, `last_name`, `logins`, `updated_at`) values (?, ?, ?, ?, ?, ?, ?) returning `id`', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test6@example.com', 'Test', 'User', 2, TEST_TIMESTAMP], [1]);\n          tester('oracledb', 'insert into \"accounts\" (\"about\", \"created_at\", \"email\", \"first_name\", \"last_name\", \"logins\", \"updated_at\") values (?, ?, ?, ?, ?, ?, ?) returning \"id\" into ?', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test6@example.com', 'Test', 'User', 2, TEST_TIMESTAMP, function (v) {\n            return v.toString() === '[object ReturningHelper:id]';\n          }], [[{\n            id: 1\n          }]]);\n          tester('mssql', 'insert into [accounts] ([about], [created_at], [email], [first_name], [last_name], [logins], [updated_at]) output inserted.[id] values (?, ?, ?, ?, ?, ?, ?)', ['Lorem ipsum Dolore labore incididunt enim.', TEST_TIMESTAMP, 'test6@example.com', 'Test', 'User', 2, TEST_TIMESTAMP], [{\n            id: '1'\n          }]);\n        });\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"should not allow inserting invalid values into enum fields","suites":["Inserts"],"updatePoint":{"line":262,"column":68,"index":19378},"line":262,"code":"      it('should not allow inserting invalid values into enum fields', function () {\n        return knex('datatype_test').insert({\n          enum_value: 'd'\n        }).testSql(function (tester) {\n          tester('mysql', 'insert into `datatype_test` (`enum_value`) values (?)', ['d']);\n          tester('pg', 'insert into \"datatype_test\" (\"enum_value\") values (?)', ['d']);\n          tester('pg-redshift', 'insert into \"datatype_test\" (\"enum_value\") values (?)', ['d']);\n          tester('sqlite3', 'insert into `datatype_test` (`enum_value`) values (?)', ['d'], [1]);\n          tester('oracledb', 'insert into \"datatype_test\" (\"enum_value\") values (?)', ['d']);\n          tester('mssql', 'insert into [datatype_test] ([enum_value]) values (?)', ['d']);\n        }).then(function () {\n          // No errors happen in sqlite3, which doesn't have native support\n          // for the enum type.\n          if (!isSQLite(knex)) {\n            throw new Error('There should be an error for invalid enum inserts');\n          }\n        }, function () {});\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"should not allow invalid uuids in postgresql","suites":["Inserts"],"updatePoint":{"line":280,"column":54,"index":20422},"line":280,"code":"      it('should not allow invalid uuids in postgresql', function () {\n        return knex('datatype_test').insert({\n          enum_value: 'c',\n          uuid: 'c39d8fcf-68a0-4902-b192-1ebb6310d9ad'\n        }).then(function () {\n          return knex('datatype_test').insert({\n            enum_value: 'c',\n            uuid: 'test'\n          });\n        }).then(function () {\n          // No errors happen in sqlite3 or mysql, which don't have native support\n          // for the uuid type.\n          if (isPostgreSQL(knex) || isMssql(knex)) {\n            throw new Error('There should be an error in postgresql for uuids');\n          }\n        }, function () {});\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"should not mutate the array passed in","suites":["Inserts"],"updatePoint":{"line":297,"column":47,"index":21089},"line":297,"code":"      it('should not mutate the array passed in', function () {\n        const a = {\n          enum_value: 'a',\n          uuid: '00419fc1-7eed-442c-9c01-cf757e74b8f0'\n        };\n        const b = {\n          enum_value: 'c',\n          uuid: '13ac5acd-c5d7-41a0-8db0-dacf64d0e4e2'\n        };\n        const x = [a, b];\n        return knex('datatype_test').insert(x).then(function () {\n          expect(x).to.eql([a, b]);\n        });\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"should throw an error if the array passed in is empty","suites":["Inserts"],"updatePoint":{"line":311,"column":63,"index":21545},"line":311,"code":"      it('should throw an error if the array passed in is empty', async function () {\n        await expect(knex('account').insert([])).to.be.rejectedWith(Error, 'The query is empty');\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"should handle empty inserts","suites":["Inserts"],"updatePoint":{"line":314,"column":37,"index":21713},"line":314,"code":"      it('should handle empty inserts', function () {\n        return knex.schema.createTable('test_default_table', function (qb) {\n          qb.increments().primary();\n          qb.string('string').defaultTo('hello');\n          qb.tinyint('tinyint').defaultTo(0);\n          qb.text('text').nullable();\n        }).then(function () {\n          return knex('test_default_table').insert({}, 'id').testSql(function (tester) {\n            tester('mysql', 'insert into `test_default_table` () values ()', [], [1]);\n            tester('pg', 'insert into \"test_default_table\" default values returning \"id\"', [], [{\n              id: 1\n            }]);\n            tester('pg-redshift', 'insert into \"test_default_table\" default values', [], 1);\n            tester('sqlite3', 'insert into `test_default_table` default values', [], [1]);\n            tester('oracledb', 'insert into \"test_default_table\" (\"id\") values (default) returning \"id\" into ?', [function (v) {\n              return v.toString() === '[object ReturningHelper:id]';\n            }], [{\n              id: 1\n            }]);\n            tester('mssql', 'insert into [test_default_table] output inserted.[id] default values', [], [{\n              id: 1\n            }]);\n          });\n        });\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"should handle empty arrays inserts","suites":["Inserts"],"updatePoint":{"line":339,"column":44,"index":22981},"line":339,"code":"      it('should handle empty arrays inserts', function () {\n        return knex.schema.createTable('test_default_table2', function (qb) {\n          qb.increments().primary();\n          qb.string('string').defaultTo('hello');\n          qb.tinyint('tinyint').defaultTo(0);\n          qb.text('text').nullable();\n        }).then(function () {\n          return knex('test_default_table2').insert([{}], 'id').testSql(function (tester) {\n            tester('mysql', 'insert into `test_default_table2` () values ()', [], [1]);\n            tester('pg', 'insert into \"test_default_table2\" default values returning \"id\"', [], [{\n              id: 1\n            }]);\n            tester('pg-redshift', 'insert into \"test_default_table2\" default values', [], 1);\n            tester('sqlite3', 'insert into `test_default_table2` default values', [], [1]);\n            tester('oracledb', 'insert into \"test_default_table2\" (\"id\") values (default) returning \"id\" into ?', [function (v) {\n              return v.toString() === '[object ReturningHelper:id]';\n            }], [{\n              id: 1\n            }]);\n            tester('mssql', 'insert into [test_default_table2] output inserted.[id] default values', [], [{\n              id: 1\n            }]);\n          });\n        });\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"should take an array of columns to return in oracle or postgres","suites":["Inserts"],"updatePoint":{"line":364,"column":73,"index":24288},"line":364,"code":"      it('should take an array of columns to return in oracle or postgres', function () {\n        const insertData = {\n          account_id: 10,\n          details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.',\n          status: 0\n        };\n        return knex('test_table_two').insert(insertData, ['account_id', 'details']).testSql(function (tester) {\n          tester('mysql', 'insert into `test_table_two` (`account_id`, `details`, `status`) values (?, ?, ?)', [10, 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.', 0], [1]);\n          tester('pg', 'insert into \"test_table_two\" (\"account_id\", \"details\", \"status\") values (?, ?, ?) returning \"account_id\", \"details\"', [10, 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.', 0], [{\n            account_id: 10,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }]);\n          tester('pg-redshift', 'insert into \"test_table_two\" (\"account_id\", \"details\", \"status\") values (?, ?, ?)', [10, 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.', 0], 1);\n          tester('sqlite3', 'insert into `test_table_two` (`account_id`, `details`, `status`) values (?, ?, ?) returning `account_id`, `details`', [10, 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.', 0], [1]);\n          tester('oracledb', `insert into \"test_table_two\" (\"account_id\", \"details\", \"status\") values (?, ?, ?) returning \"account_id\",\"details\" into ?,?`, [10, 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.', 0, function (v) {\n            return v.toString() === '[object ReturningHelper:account_id]';\n          }, function (v) {\n            return v.toString() === '[object ReturningHelper:details]';\n          }], [{\n            account_id: '10',\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }]);\n          tester('mssql', 'insert into [test_table_two] ([account_id], [details], [status]) output inserted.[account_id], inserted.[details] values (?, ?, ?)', [10, 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.', 0], [{\n            account_id: 10,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }]);\n        }).then(function (rows) {\n          if (isRedshift(knex)) {\n            return expect(rows).to.equal(1);\n          }\n\n          expect(rows.length).to.equal(1);\n\n          if (isPostgreSQL(knex)) {\n            expect(_.keys(rows[0]).length).to.equal(2);\n            expect(rows[0].account_id).to.equal(insertData.account_id);\n            expect(rows[0].details).to.equal(insertData.details);\n          }\n        });\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"should allow a * for returning in postgres and oracle","suites":["Inserts"],"updatePoint":{"line":404,"column":63,"index":27705},"line":404,"code":"      it('should allow a * for returning in postgres and oracle', function () {\n        if (isRedshift(knex)) {\n          return this.skip();\n        }\n\n        const insertData = {\n          account_id: 10,\n          details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.',\n          status: 0\n        };\n        const returningColumn = '*';\n        return knex('test_table_two').insert(insertData, returningColumn).testSql(function (tester) {\n          tester(['pg'], 'insert into \"test_table_two\" (\"account_id\", \"details\", \"status\") values (?, ?, ?) returning *', [10, 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.', 0], [{\n            id: 1,\n            account_id: 10,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.',\n            status: 0\n          }]);\n          tester('oracledb', 'insert into \"test_table_two\" (\"account_id\", \"details\", \"status\") values (?, ?, ?) returning \"ROWID\" into ?', [10, 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.', 0, function (v) {\n            return v.toString() === '[object ReturningHelper:ROWID]';\n          }], [{\n            id: 1,\n            account_id: 10,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.',\n            status: 0\n          }]);\n          tester('mssql', 'insert into [test_table_two] ([account_id], [details], [status]) output inserted.* values (?, ?, ?)', [10, 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.', 0], [{\n            id: 1,\n            account_id: 10,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.',\n            status: 0\n          }]);\n        }).then(function (rows) {\n          expect(rows.length).to.equal(1);\n\n          if (isPgBased(knex)) {\n            expect(_.keys(rows[0]).length).to.equal(4);\n            assertNumber(knex, rows[0].account_id, insertData.account_id);\n            expect(rows[0].details).to.equal(insertData.details);\n            expect(rows[0].status).to.equal(insertData.status);\n          }\n        });\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"#757 - knex.batchInsert(tableName, bulk, chunkSize)","suites":["Inserts","batchInsert"],"updatePoint":{"line":471,"column":63,"index":31076},"line":471,"code":"        it('#757 - knex.batchInsert(tableName, bulk, chunkSize)', async function () {\n          this.timeout(30000);\n          const result = await knex.batchInsert('BatchInsert', items, 30).returning(['Col1', 'Col2']); //Returning only supported by some dialects.\n\n          if (isPostgreSQL(knex) || isOracle(knex)) {\n            result.forEach(function (item) {\n              expect(item.Col1).to.equal(fiftyLengthString);\n              expect(item.Col2).to.equal(fiftyLengthString);\n            });\n          }\n\n          const selectResult = await knex('BatchInsert').select();\n          const count = selectResult.length;\n          expect(count).to.equal(amountOfItems);\n        });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"#1880 - Duplicate keys in batchInsert should not throw unhandled exception","suites":["Inserts","batchInsert"],"updatePoint":{"line":486,"column":86,"index":31788},"line":486,"code":"        it('#1880 - Duplicate keys in batchInsert should not throw unhandled exception', async function () {\n          if (isRedshift(knex)) {\n            return this.skip();\n          }\n\n          this.timeout(10000);\n          const fn = sinon.stub();\n          process.on('unhandledRejection', fn);\n          await knex.schema.dropTableIfExists('batchInsertDuplicateKey').then(function () {\n            return knex.schema.createTable('batchInsertDuplicateKey', function (table) {\n              table.string('col');\n              table.primary('col');\n            });\n          }).then(function () {\n            const rows = [{\n              col: 'a'\n            }, {\n              col: 'a'\n            }];\n            return knex.batchInsert('batchInsertDuplicateKey', rows, rows.length);\n          }).then(function () {\n            expect.fail('Should not reach this point');\n          }).catch(function (error) {\n            //Should reach this point before timeout of 10s\n            expect(error.message.toLowerCase()).to.include('batchinsertduplicatekey');\n          });\n          expect(fn).have.not.been.called;\n          process.removeListener('unhandledRejection', fn);\n        });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"knex.batchInsert with specified transaction","suites":["Inserts","batchInsert"],"updatePoint":{"line":515,"column":55,"index":32951},"line":515,"code":"        it('knex.batchInsert with specified transaction', function () {\n          return knex.transaction(function (tr) {\n            knex.batchInsert('BatchInsert', items, 30).returning(['Col1', 'Col2']).transacting(tr).then(tr.commit).catch(tr.rollback);\n          });\n        });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"transaction.batchInsert using specified transaction","suites":["Inserts","batchInsert"],"updatePoint":{"line":520,"column":63,"index":33242},"line":520,"code":"        it('transaction.batchInsert using specified transaction', function () {\n          return knex.transaction(function (tr) {\n            return tr.batchInsert('BatchInsert', items, 30).returning(['Col1', 'Col2']);\n          });\n        });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"should validate batchInsert batchSize parameter","suites":["Inserts","batchInsert"],"updatePoint":{"line":526,"column":57,"index":33491},"line":526,"code":"      it('should validate batchInsert batchSize parameter', function () {\n        //Should not throw, batchSize default\n        return knex.batchInsert('test', []).then(function () {\n          //Should throw, null not valid\n          return knex.batchInsert('test', [], null);\n        }).catch(function (error) {\n          expect(error.message).to.equal('Invalid chunkSize: null'); //Should throw, 0 is not a valid chunkSize\n\n          return knex.batchInsert('test', [], 0);\n        }).catch(function (error) {\n          expect(error.message).to.equal('Invalid chunkSize: 0'); //Also faulty\n\n          return knex.batchInsert('test', [], 'still no good');\n        }).catch(function (error) {\n          expect(error.message).to.equal('Invalid chunkSize: still no good');\n          return true;\n        });\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"should replace undefined keys in multi insert with DEFAULT","suites":["Inserts","batchInsert"],"updatePoint":{"line":544,"column":68,"index":34318},"line":544,"code":"      it('should replace undefined keys in multi insert with DEFAULT', function () {\n        if (isSQLite(knex)) {\n          return true;\n        }\n\n        return knex('accounts').insert([{\n          last_name: 'First Item',\n          email: 'single-test1@example.com',\n          about: 'Lorem ipsum Dolore labore incididunt enim.',\n          created_at: new Date(),\n          updated_at: new Date()\n        }, {\n          last_name: 'Second Item',\n          email: 'double-test1@example.com',\n          logins: 2,\n          created_at: new Date(),\n          updated_at: new Date()\n        }], '*').then(function () {\n          return knex('accounts').whereIn('email', ['single-test1@example.com', 'double-test1@example.com']).orderBy('email', 'desc');\n        }).then(function (results) {\n          assertNumber(knex, results[0].logins, 1);\n          expect(results[1].about).to.equal(null); // cleanup to prevent needs for too much changes to other tests\n\n          return knex('accounts').delete().whereIn('id', results.map(function (row) {\n            return row.id;\n          }));\n        });\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"will silently do nothing when multiple inserts are made into a unique column and ignore is specified","suites":["Inserts","batchInsert"],"updatePoint":{"line":572,"column":110,"index":35469},"line":572,"code":"      it('will silently do nothing when multiple inserts are made into a unique column and ignore is specified', async function () {\n        if (isRedshift(knex)) {\n          return this.skip();\n        } // Setup: Create table with unique email column\n\n\n        await knex.schema.dropTableIfExists('upsert_tests');\n        await knex.schema.createTable('upsert_tests', table => {\n          table.string('name');\n          table.string('email');\n          table.unique('email');\n        }); // Setup: Create row to conflict against\n\n        await knex('upsert_tests').insert({\n          email: 'ignoretest1@example.com',\n          name: 'BEFORE'\n        }); // Test: Insert..ignore with same email as existing row\n\n        try {\n          await knex('upsert_tests').insert({\n            email: 'ignoretest1@example.com',\n            name: 'AFTER'\n          }, 'email').onConflict('email').ignore().testSql(function (tester) {\n            tester('mysql', 'insert ignore into `upsert_tests` (`email`, `name`) values (?, ?)', ['ignoretest1@example.com', 'AFTER']);\n            tester('pg', 'insert into \"upsert_tests\" (\"email\", \"name\") values (?, ?) on conflict (\"email\") do nothing returning \"email\"', ['ignoretest1@example.com', 'AFTER']);\n            tester('sqlite3', 'insert into `upsert_tests` (`email`, `name`) values (?, ?) on conflict (`email`) do nothing returning `email`', ['ignoretest1@example.com', 'AFTER']);\n          });\n        } catch (err) {\n          if (isOracle(knex) || isMssql(knex)) {\n            expect(err).to.be.an('error');\n            if (err.message.includes('.onConflict() is not supported for')) return;\n          }\n\n          throw err;\n        } // Assert: there is still only 1 row, and that it HAS NOT been updated\n\n\n        const rows = await knex('upsert_tests').where({\n          email: 'ignoretest1@example.com'\n        }).select();\n        expect(rows.length).to.equal(1);\n        expect(rows[0].name).to.equal('BEFORE');\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"will still silently do nothing when multiple inserts are made into a unique column and ignore is specified with no columns","suites":["Inserts","batchInsert"],"updatePoint":{"line":615,"column":132,"index":37463},"line":615,"code":"      it('will still silently do nothing when multiple inserts are made into a unique column and ignore is specified with no columns', async function () {\n        if (isRedshift(knex)) {\n          return this.skip();\n        } // Setup: Create table with unique email column\n\n\n        await knex.schema.dropTableIfExists('upsert_tests');\n        await knex.schema.createTable('upsert_tests', table => {\n          table.string('name');\n          table.string('email');\n          table.unique('email');\n        }); // Setup: Create row to conflict against\n\n        await knex('upsert_tests').insert({\n          email: 'ignoretest1@example.com',\n          name: 'BEFORE'\n        }); // Test: Insert..ignore with same email as existing row\n\n        try {\n          await knex('upsert_tests').insert({\n            email: 'ignoretest1@example.com',\n            name: 'AFTER'\n          }, 'email').onConflict().ignore().testSql(function (tester) {\n            tester('mysql', 'insert ignore into `upsert_tests` (`email`, `name`) values (?, ?)', ['ignoretest1@example.com', 'AFTER']);\n            tester('pg', 'insert into \"upsert_tests\" (\"email\", \"name\") values (?, ?) on conflict do nothing returning \"email\"', ['ignoretest1@example.com', 'AFTER']);\n            tester('sqlite3', 'insert into `upsert_tests` (`email`, `name`) values (?, ?) on conflict do nothing returning `email`', ['ignoretest1@example.com', 'AFTER']);\n          });\n        } catch (err) {\n          if (isOracle(knex) || isMssql(knex)) {\n            expect(err).to.be.an('error');\n            if (err.message.includes('.onConflict() is not supported for')) return;\n          }\n\n          throw err;\n        } // Assert: there is still only 1 row, and that it HAS NOT been updated\n\n\n        const rows = await knex('upsert_tests').where({\n          email: 'ignoretest1@example.com'\n        }).select();\n        expect(rows.length).to.equal(1);\n        expect(rows[0].name).to.equal('BEFORE');\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"will silently do nothing when multiple inserts are made into a composite unique column and ignore is specified","suites":["Inserts","batchInsert"],"updatePoint":{"line":658,"column":120,"index":39418},"line":658,"code":"      it('will silently do nothing when multiple inserts are made into a composite unique column and ignore is specified', async function () {\n        if (isRedshift(knex)) {\n          return this.skip();\n        } // Setup: Create table with unique email column\n\n\n        await knex.schema.dropTableIfExists('upsert_composite_key_tests');\n        await knex.schema.createTable('upsert_composite_key_tests', table => {\n          table.string('name');\n          table.string('email');\n          table.string('org');\n          table.unique(['org', 'email']);\n        }); // Setup: Create row to conflict against\n\n        await knex('upsert_composite_key_tests').insert({\n          org: 'acme-inc',\n          email: 'ignoretest1@example.com',\n          name: 'BEFORE'\n        }); // Test: Insert..ignore with same email as existing row\n\n        try {\n          await knex('upsert_composite_key_tests').insert({\n            org: 'acme-inc',\n            email: 'ignoretest1@example.com',\n            name: 'AFTER'\n          }, 'email').onConflict(['org', 'email']).ignore().testSql(function (tester) {\n            tester('mysql', 'insert ignore into `upsert_composite_key_tests` (`email`, `name`, `org`) values (?, ?, ?)', ['ignoretest1@example.com', 'AFTER', 'acme-inc']);\n            tester('pg', 'insert into \"upsert_composite_key_tests\" (\"email\", \"name\", \"org\") values (?, ?, ?) on conflict (\"org\", \"email\") do nothing returning \"email\"', ['ignoretest1@example.com', 'AFTER', 'acme-inc']);\n            tester('sqlite3', 'insert into `upsert_composite_key_tests` (`email`, `name`, `org`) values (?, ?, ?) on conflict (`org`, `email`) do nothing returning `email`', ['ignoretest1@example.com', 'AFTER', 'acme-inc']);\n          });\n        } catch (err) {\n          if (isOracle(knex) || isMssql(knex)) {\n            expect(err).to.be.an('error');\n            if (err.message.includes('.onConflict() is not supported for')) return;\n          }\n\n          throw err;\n        } // Assert: there is still only 1 row, and that it HAS NOT been updated\n\n\n        const rows = await knex('upsert_composite_key_tests').where({\n          email: 'ignoretest1@example.com'\n        }).select();\n        expect(rows.length).to.equal(1);\n        expect(rows[0].name).to.equal('BEFORE');\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"updates columns when inserting a duplicate key to unique column and merge is specified","suites":["Inserts","batchInsert"],"updatePoint":{"line":704,"column":96,"index":41673},"line":704,"code":"      it('updates columns when inserting a duplicate key to unique column and merge is specified', async function () {\n        if (isRedshift(knex)) {\n          return this.skip();\n        } // Setup: Create table with unique email column\n\n\n        await knex.schema.dropTableIfExists('upsert_tests');\n        await knex.schema.createTable('upsert_tests', table => {\n          table.string('name');\n          table.string('email');\n          table.unique('email');\n        }); // Setup: Create row to conflict against\n\n        await knex('upsert_tests').insert({\n          email: 'mergetest1@example.com',\n          name: 'BEFORE'\n        }); // Perform insert..merge (upsert)\n\n        try {\n          await knex('upsert_tests').insert({\n            email: 'mergetest1@example.com',\n            name: 'AFTER'\n          }, 'email').onConflict('email').merge().testSql(function (tester) {\n            tester('mysql', 'insert into `upsert_tests` (`email`, `name`) values (?, ?) on duplicate key update `email` = values(`email`), `name` = values(`name`)', ['mergetest1@example.com', 'AFTER']);\n            tester('pg', 'insert into \"upsert_tests\" (\"email\", \"name\") values (?, ?) on conflict (\"email\") do update set \"email\" = excluded.\"email\", \"name\" = excluded.\"name\" returning \"email\"', ['mergetest1@example.com', 'AFTER']);\n            tester('sqlite3', 'insert into `upsert_tests` (`email`, `name`) values (?, ?) on conflict (`email`) do update set `email` = excluded.`email`, `name` = excluded.`name` returning `email`', ['mergetest1@example.com', 'AFTER']);\n          });\n        } catch (err) {\n          if (isOracle(knex) || isMssql(knex)) {\n            expect(err).to.be.an('error');\n            if (err.message.includes('.onConflict() is not supported for')) return;\n          }\n\n          throw err;\n        } // Check that row HAS been updated\n\n\n        const rows = await knex('upsert_tests').where({\n          email: 'mergetest1@example.com'\n        }).select();\n        expect(rows.length).to.equal(1);\n        expect(rows[0].name).to.equal('AFTER');\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"conditionally updates rows when inserting a duplicate key to unique column and merge with where clause matching row(s) is specified","suites":["Inserts","batchInsert"],"updatePoint":{"line":747,"column":141,"index":43790},"line":747,"code":"      it('conditionally updates rows when inserting a duplicate key to unique column and merge with where clause matching row(s) is specified', async function () {\n        if (isRedshift(knex)) {\n          return this.skip();\n        } // Setup: Create table with unique email column\n\n\n        await knex.schema.dropTableIfExists('upsert_tests');\n        await knex.schema.createTable('upsert_tests', table => {\n          table.string('name');\n          table.string('email');\n          table.string('role');\n          table.unique('email');\n        }); // Setup: Create row to conflict against\n\n        await knex('upsert_tests').insert({\n          email: 'mergetest1@example.com',\n          role: 'tester',\n          name: 'BEFORE'\n        }); // Perform insert..merge (upsert)\n\n        try {\n          await knex('upsert_tests').insert({\n            email: 'mergetest1@example.com',\n            name: 'AFTER'\n          }, 'email').onConflict('email').merge().where('upsert_tests.role', 'tester').testSql(function (tester) {\n            tester('pg', 'insert into \"upsert_tests\" (\"email\", \"name\") values (?, ?) on conflict (\"email\") do update set \"email\" = excluded.\"email\", \"name\" = excluded.\"name\" where \"upsert_tests\".\"role\" = ? returning \"email\"', ['mergetest1@example.com', 'AFTER', 'tester']);\n            tester('sqlite3', 'insert into `upsert_tests` (`email`, `name`) values (?, ?) on conflict (`email`) do update set `email` = excluded.`email`, `name` = excluded.`name` where `upsert_tests`.`role` = ? returning `email`', ['mergetest1@example.com', 'AFTER', 'tester']);\n          });\n        } catch (err) {\n          if (isOracle(knex) || isMssql(knex)) {\n            expect(err).to.be.an('error');\n            if (err.message.includes('.onConflict() is not supported for')) return;\n          }\n\n          if (isMysql(knex)) {\n            expect(err).to.be.an('error');\n            if (err.message.includes('.onConflict().merge().where() is not supported for')) return;\n          }\n\n          throw err;\n        } // Check that row HAS been updated\n\n\n        const rows = await knex('upsert_tests').where({\n          email: 'mergetest1@example.com'\n        }).select();\n        expect(rows.length).to.equal(1);\n        expect(rows[0].name).to.equal('AFTER');\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"will silently do nothing when inserting a duplicate key to unique column and merge with where clause matching no rows is specified","suites":["Inserts","batchInsert"],"updatePoint":{"line":796,"column":140,"index":46069},"line":796,"code":"      it('will silently do nothing when inserting a duplicate key to unique column and merge with where clause matching no rows is specified', async function () {\n        if (isRedshift(knex)) {\n          return this.skip();\n        } // Setup: Create table with unique email column\n\n\n        await knex.schema.dropTableIfExists('upsert_tests');\n        await knex.schema.createTable('upsert_tests', table => {\n          table.string('name');\n          table.string('email');\n          table.string('role');\n          table.unique('email');\n        }); // Setup: Create row to conflict against\n\n        await knex('upsert_tests').insert({\n          email: 'mergetest1@example.com',\n          role: 'tester',\n          name: 'BEFORE'\n        }); // Perform insert..merge (upsert)\n\n        try {\n          await knex('upsert_tests').insert({\n            email: 'mergetest1@example.com',\n            name: 'AFTER'\n          }, 'email').onConflict('email').merge().where('upsert_tests.role', 'fake-role').testSql(function (tester) {\n            tester('pg', 'insert into \"upsert_tests\" (\"email\", \"name\") values (?, ?) on conflict (\"email\") do update set \"email\" = excluded.\"email\", \"name\" = excluded.\"name\" where \"upsert_tests\".\"role\" = ? returning \"email\"', ['mergetest1@example.com', 'AFTER', 'fake-role']);\n            tester('sqlite3', 'insert into `upsert_tests` (`email`, `name`) values (?, ?) on conflict (`email`) do update set `email` = excluded.`email`, `name` = excluded.`name` where `upsert_tests`.`role` = ? returning `email`', ['mergetest1@example.com', 'AFTER', 'fake-role']);\n          });\n        } catch (err) {\n          if (isOracle(knex) || isMssql(knex)) {\n            expect(err).to.be.an('error');\n            if (err.message.includes('.onConflict() is not supported for')) return;\n          }\n\n          if (isMysql(knex)) {\n            expect(err).to.be.an('error');\n            if (err.message.includes('.onConflict().merge().where() is not supported for')) return;\n          }\n\n          throw err;\n        } // Check that row HAS NOT been updated\n\n\n        const rows = await knex('upsert_tests').where({\n          email: 'mergetest1@example.com'\n        }).select();\n        expect(rows.length).to.equal(1);\n        expect(rows[0].name).to.equal('BEFORE');\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"updates all columns with raw value when inserting a duplicate key to unique column and merge is specified","suites":["Inserts","batchInsert"],"updatePoint":{"line":845,"column":115,"index":48337},"line":845,"code":"      it('updates all columns with raw value when inserting a duplicate key to unique column and merge is specified', async function () {\n        if (isRedshift(knex)) {\n          return this.skip();\n        } // Setup: Create table with unique email column\n\n\n        await knex.schema.dropTableIfExists('upsert_tests');\n        await knex.schema.createTable('upsert_tests', table => {\n          table.string('name');\n          table.string('email');\n          table.unique('email');\n        }); // Setup: Create row to conflict against\n\n        await knex('upsert_tests').insert([{\n          email: 'mergesource@example.com',\n          name: 'SOURCE'\n        }, {\n          email: 'mergedest@example.com',\n          name: 'DEST'\n        }]); // Perform insert..merge (upsert)\n\n        try {\n          await knex('upsert_tests').insert({\n            email: 'mergedest@example.com',\n            name: knex.raw(\"(SELECT name FROM (SELECT * FROM upsert_tests) AS t WHERE email = 'mergesource@example.com')\")\n          }, 'email').onConflict('email').merge().testSql(function (tester) {\n            tester('mysql', \"insert into `upsert_tests` (`email`, `name`) values (?, (SELECT name FROM (SELECT * FROM upsert_tests) AS t WHERE email = 'mergesource@example.com')) on duplicate key update `email` = values(`email`), `name` = values(`name`)\", ['mergedest@example.com']);\n            tester('pg', 'insert into \"upsert_tests\" (\"email\", \"name\") values (?, (SELECT name FROM (SELECT * FROM upsert_tests) AS t WHERE email = \\'mergesource@example.com\\')) on conflict (\"email\") do update set \"email\" = excluded.\"email\", \"name\" = excluded.\"name\" returning \"email\"', ['mergedest@example.com']);\n            tester('sqlite3', \"insert into `upsert_tests` (`email`, `name`) values (?, (SELECT name FROM (SELECT * FROM upsert_tests) AS t WHERE email = 'mergesource@example.com')) on conflict (`email`) do update set `email` = excluded.`email`, `name` = excluded.`name` returning `email`\", ['mergedest@example.com']);\n          });\n        } catch (err) {\n          if (isOracle(knex) || isMssql(knex)) {\n            expect(err).to.be.an('error');\n            if (err.message.includes('.onConflict() is not supported for')) return;\n          }\n\n          throw err;\n        } // Check that row HAS been updated\n\n\n        const rows = await knex('upsert_tests').where({\n          email: 'mergedest@example.com'\n        }).select();\n        expect(rows.length).to.equal(1);\n        expect(rows[0].name).to.equal('SOURCE');\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"updates columns with raw value when inserting a duplicate key to unique column and merge with update data is specified","suites":["Inserts","batchInsert"],"updatePoint":{"line":891,"column":128,"index":50863},"line":891,"code":"      it('updates columns with raw value when inserting a duplicate key to unique column and merge with update data is specified', async function () {\n        if (isRedshift(knex)) {\n          return this.skip();\n        } // Setup table for testing knex.raw with\n\n\n        await knex.schema.dropTableIfExists('upsert_value_source');\n        await knex.schema.createTable('upsert_value_source', table => {\n          table.string('name');\n        });\n        await knex('upsert_value_source').insert([{\n          name: 'SOURCE'\n        }]); // Setup: Create table with unique email column\n\n        await knex.schema.dropTableIfExists('upsert_tests');\n        await knex.schema.createTable('upsert_tests', table => {\n          table.string('name');\n          table.string('email');\n          table.unique('email');\n        }); // Setup: Create row to conflict against\n\n        await knex('upsert_tests').insert([{\n          email: 'mergedest@example.com',\n          name: 'DEST'\n        }]); // Perform insert..merge (upsert)\n\n        try {\n          await knex('upsert_tests').insert({\n            email: 'mergedest@example.com',\n            name: 'SHOULD NOT BE USED'\n          }, 'email').onConflict('email').merge({\n            name: knex.raw('(SELECT name FROM upsert_value_source)')\n          }).testSql(function (tester) {\n            tester('mysql', 'insert into `upsert_tests` (`email`, `name`) values (?, ?) on duplicate key update `name` = (SELECT name FROM upsert_value_source)', ['mergedest@example.com', 'SHOULD NOT BE USED']);\n            tester('pg', 'insert into \"upsert_tests\" (\"email\", \"name\") values (?, ?) on conflict (\"email\") do update set \"name\" = (SELECT name FROM upsert_value_source) returning \"email\"', ['mergedest@example.com', 'SHOULD NOT BE USED']);\n            tester('sqlite3', 'insert into `upsert_tests` (`email`, `name`) values (?, ?) on conflict (`email`) do update set `name` = (SELECT name FROM upsert_value_source) returning `email`', ['mergedest@example.com', 'SHOULD NOT BE USED']);\n          });\n        } catch (err) {\n          if (isOracle(knex) || isMssql(knex)) {\n            expect(err).to.be.an('error');\n            if (err.message.includes('.onConflict() is not supported for')) return;\n          }\n\n          throw err;\n        } // Check that row HAS been updated\n\n\n        const rows = await knex('upsert_tests').where({\n          email: 'mergedest@example.com'\n        }).select();\n        expect(rows.length).to.equal(1);\n        expect(rows[0].name).to.equal('SOURCE');\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"updates specified columns with insert value when inserting a duplicate key to unique column and merge with update columns is specified","suites":["Inserts","batchInsert"],"updatePoint":{"line":944,"column":144,"index":53415},"line":944,"code":"      it('updates specified columns with insert value when inserting a duplicate key to unique column and merge with update columns is specified', async function () {\n        if (isRedshift(knex)) {\n          return this.skip();\n        } // Setup table for testing knex.raw with\n\n\n        await knex.schema.dropTableIfExists('upsert_value_source');\n        await knex.schema.createTable('upsert_value_source', table => {\n          table.string('name');\n        });\n        await knex('upsert_value_source').insert([{\n          name: 'SOURCE'\n        }]); // Setup: Create table with unique email column\n\n        await knex.schema.dropTableIfExists('upsert_tests');\n        await knex.schema.createTable('upsert_tests', table => {\n          table.string('name');\n          table.string('email');\n          table.unique('email');\n        }); // Setup: Create row to conflict against\n\n        await knex('upsert_tests').insert([{\n          email: 'mergedest@example.com',\n          name: 'DEST'\n        }]); // Perform insert..merge (upsert)\n\n        try {\n          await knex('upsert_tests').insert({\n            email: 'mergedest@example.com',\n            name: 'SHOULD BE USED'\n          }, 'email').onConflict('email').merge(['name']).testSql(function (tester) {\n            tester('mysql', 'insert into `upsert_tests` (`email`, `name`) values (?, ?) on duplicate key update `name` = values(`name`)', ['mergedest@example.com', 'SHOULD BE USED']);\n            tester('pg', 'insert into \"upsert_tests\" (\"email\", \"name\") values (?, ?) on conflict (\"email\") do update set \"name\" = excluded.\"name\" returning \"email\"', ['mergedest@example.com', 'SHOULD BE USED']);\n            tester('sqlite3', 'insert into `upsert_tests` (`email`, `name`) values (?, ?) on conflict (`email`) do update set `name` = excluded.`name` returning `email`', ['mergedest@example.com', 'SHOULD BE USED']);\n          });\n        } catch (err) {\n          if (isOracle(knex) || isMssql(knex)) {\n            expect(err).to.be.an('error');\n            if (err.message.includes('.onConflict() is not supported for')) return;\n          }\n\n          throw err;\n        } // Check that row HAS been updated\n\n\n        const rows = await knex('upsert_tests').where({\n          email: 'mergedest@example.com'\n        }).select();\n        expect(rows.length).to.equal(1);\n        expect(rows[0].name).to.equal('SHOULD BE USED');\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"updates and inserts columns when inserting multiple rows merge is specified","suites":["Inserts","batchInsert"],"updatePoint":{"line":995,"column":85,"index":55756},"line":995,"code":"      it('updates and inserts columns when inserting multiple rows merge is specified', async function () {\n        if (isRedshift(knex)) {\n          return this.skip();\n        } // Setup: Create table with unique email column\n\n\n        await knex.schema.dropTableIfExists('upsert_tests');\n        await knex.schema.createTable('upsert_tests', table => {\n          table.string('name');\n          table.string('email');\n          table.unique('email');\n        }); // Setup: Create row to conflict against\n\n        await knex('upsert_tests').insert([{\n          email: 'one@example.com',\n          name: 'BEFORE'\n        }, {\n          email: 'two@example.com',\n          name: 'BEFORE'\n        }]); // Perform insert..merge (upsert)\n\n        try {\n          await knex('upsert_tests').insert([{\n            email: 'two@example.com',\n            name: 'AFTER'\n          }, {\n            email: 'three@example.com',\n            name: 'AFTER'\n          }], 'email').onConflict('email').merge().testSql(function (tester) {\n            tester('mysql', 'insert into `upsert_tests` (`email`, `name`) values (?, ?), (?, ?) on duplicate key update `email` = values(`email`), `name` = values(`name`)', ['two@example.com', 'AFTER', 'three@example.com', 'AFTER']);\n            tester('pg', 'insert into \"upsert_tests\" (\"email\", \"name\") values (?, ?), (?, ?) on conflict (\"email\") do update set \"email\" = excluded.\"email\", \"name\" = excluded.\"name\" returning \"email\"', ['two@example.com', 'AFTER', 'three@example.com', 'AFTER']);\n            tester('sqlite3', 'insert into `upsert_tests` (`email`, `name`) select ? as `email`, ? as `name` union all select ? as `email`, ? as `name` where true on conflict (`email`) do update set `email` = excluded.`email`, `name` = excluded.`name` returning `email`', ['two@example.com', 'AFTER', 'three@example.com', 'AFTER']);\n          });\n        } catch (err) {\n          if (isOracle(knex) || isMssql(knex)) {\n            expect(err).to.be.an('error');\n            if (err.message.includes('.onConflict() is not supported for')) return;\n          }\n\n          throw err;\n        } // Check that row HAS been updated\n\n\n        const rows = await knex('upsert_tests').select();\n        expect(rows.length).to.equal(3);\n        const row1 = rows.find(row => row.email === 'one@example.com');\n        expect(row1 && row1.name).to.equal('BEFORE');\n        const row2 = rows.find(row => row.email === 'two@example.com');\n        expect(row2 && row2.name).to.equal('AFTER');\n        const row3 = rows.find(row => row.email === 'three@example.com');\n        expect(row3 && row3.name).to.equal('AFTER');\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"update values on conflit with \"where\" condition and partial unique index #4590","suites":["Inserts","batchInsert"],"updatePoint":{"line":1047,"column":88,"index":58392},"line":1047,"code":"      it('update values on conflit with \"where\" condition and partial unique index #4590', async function () {\n        if (!isPostgreSQL(knex) && !isSQLite(knex)) {\n          return this.skip();\n        }\n\n        await knex.schema.dropTableIfExists('upsert_tests');\n        await knex.schema.createTable('upsert_tests', table => {\n          table.string('name');\n          table.string('type');\n          table.string('email');\n        });\n        await knex.raw('create unique index email_type1 ' + 'on upsert_tests(email) ' + \"where type = 'type1'\");\n        await knex('upsert_tests').insert([{\n          email: 'one@example.com',\n          name: 'BEFORE',\n          type: 'type1'\n        }, {\n          email: 'two@example.com',\n          name: 'BEFORE',\n          type: 'type1'\n        }, {\n          email: 'two@example.com',\n          name: 'BEFORE',\n          type: 'type2'\n        }]); // Perform insert..merge (upsert)\n\n        try {\n          await knex('upsert_tests').insert([{\n            email: 'one@example.com',\n            name: 'AFTER',\n            type: 'type1'\n          }, {\n            email: 'two@example.com',\n            name: 'AFTER',\n            type: 'type1'\n          }, {\n            email: 'three@example.com',\n            name: 'AFTER',\n            type: 'type1'\n          }]).onConflict(knex.raw(\"(email) where type = 'type1'\")).merge().testSql(function (tester) {\n            tester('mysql', 'insert into `upsert_tests` (`email`, `name`) values (?, ?), (?, ?) on duplicate key update `email` = values(`email`), `name` = values(`name`)', ['two@example.com', 'AFTER', 'three@example.com', 'AFTER']);\n            tester('pg', 'insert into \"upsert_tests\" (\"email\", \"name\", \"type\") values (?, ?, ?), (?, ?, ?), (?, ?, ?) on conflict (email) where type = \\'type1\\' do update set \"email\" = excluded.\"email\", \"name\" = excluded.\"name\", \"type\" = excluded.\"type\"', ['one@example.com', 'AFTER', 'type1', 'two@example.com', 'AFTER', 'type1', 'three@example.com', 'AFTER', 'type1']);\n            tester('sqlite3', 'insert into `upsert_tests` (`email`, `name`, `type`) select ? as `email`, ? as `name`, ? as `type` union all select ? as `email`, ? as `name`, ? as `type` union all select ? as `email`, ? as `name`, ? as `type` where true ' + \"on conflict (email) where type = 'type1' do update set `email` = excluded.`email`, `name` = excluded.`name`, `type` = excluded.`type`\", ['one@example.com', 'AFTER', 'type1', 'two@example.com', 'AFTER', 'type1', 'three@example.com', 'AFTER', 'type1']);\n          });\n        } catch (err) {\n          if (isOracle(knex) || isMssql(knex)) {\n            expect(err).to.be.an('error');\n            if (err.message.includes('.onConflict() is not supported for')) return;\n          }\n\n          throw err;\n        } // Check that row HAS been updated\n\n\n        const rows = await knex('upsert_tests').select().orderBy(['email', 'name']);\n        expect(rows.length).to.equal(4);\n        expect(rows).to.eql([{\n          email: 'one@example.com',\n          name: 'AFTER',\n          type: 'type1'\n        }, // type1 => updated\n        {\n          email: 'three@example.com',\n          name: 'AFTER',\n          type: 'type1'\n        }, {\n          email: 'two@example.com',\n          name: 'AFTER',\n          type: 'type1'\n        }, // type1 => updated\n        {\n          email: 'two@example.com',\n          name: 'BEFORE',\n          type: 'type2'\n        } // type2 => not updated\n        ]);\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"#1423 should replace undefined keys in single insert with DEFAULT also in transacting query","suites":["Inserts","batchInsert"],"updatePoint":{"line":1124,"column":101,"index":61867},"line":1124,"code":"      it('#1423 should replace undefined keys in single insert with DEFAULT also in transacting query', function () {\n        if (isSQLite(knex)) {\n          return true;\n        }\n\n        return knex.transaction(function (trx) {\n          return trx('accounts').insert({\n            last_name: 'First Item',\n            email: 'findme@example.com',\n            logins: undefined,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: new Date(),\n            updated_at: new Date()\n          }).then(function (results) {\n            return trx('accounts').where('email', 'findme@example.com');\n          }).then(function (results) {\n            assertNumber(knex, results[0].logins, 1); // cleanup to prevent needs for too much changes to other tests\n\n            return trx('accounts').delete().where('id', results[0].id);\n          });\n        });\n      });","file":"integration2/query/insert/inserts.spec.js","skipped":false,"dir":"test"},{"name":"inserts entries with delayed checks correctly","suites":["Insert","onConflict deferred"],"updatePoint":{"line":47,"column":57,"index":1645},"line":47,"code":"        it('inserts entries with delayed checks correctly', async function () {\n          for (let i = 0; i < 10; i++) {\n            await knex.transaction(async function (txn) {\n              await txn.table('table_a').insert({\n                id: i,\n                b_id: i,\n                value: i\n              }).onConflict('id').merge();\n              await txn.table('table_b').insert({\n                id: i,\n                a_id: i,\n                value: i\n              }).onConflict('id').merge();\n            });\n          }\n        });","file":"integration2/query/insert/on-conflict-deferred.spec.js","skipped":false,"dir":"test"},{"name":"inserts large amount of entries correctly","suites":["Insert","onConflict merge"],"updatePoint":{"line":32,"column":53,"index":836},"line":32,"code":"        it('inserts large amount of entries correctly', async function () {\n          if (!isMysql(knex) && !isPostgreSQL(knex) && !isCockroachDB(knex)) {\n            return this.skip();\n          }\n\n          const rows = []; // There seems to be a 32-bit limit for amount of values passed in pg (https://github.com/brianc/node-postgres/issues/581)\n          // Cannot go any higher with bindings currently\n\n          for (let i = 0; i < 32767; i++) {\n            rows.push({\n              id: i,\n              value: i\n            });\n          }\n\n          await knex.table('merge_table').insert(rows).onConflict('id').merge();\n        });","file":"integration2/query/insert/on-conflict-merge.spec.js","skipped":false,"dir":"test"},{"name":"inserts large amount of entries correctly (raw)","suites":["Insert","onConflict merge"],"updatePoint":{"line":49,"column":59,"index":1485},"line":49,"code":"        it('inserts large amount of entries correctly (raw)', async function () {\n          if (!isPostgreSQL(knex) && !isCockroachDB(knex)) {\n            return this.skip();\n          }\n\n          const rows = [];\n\n          for (let i = 0; i < 32768; i++) {\n            rows.push({\n              id: i,\n              value: i\n            });\n          }\n\n          await knex.raw(knex.table('merge_table').insert(rows).toQuery() + ' ON CONFLICT (id) DO UPDATE SET ' + Object.keys(rows[0]).map(field => `${field}=EXCLUDED.${field}`).join(', '));\n        });","file":"integration2/query/insert/on-conflict-merge.spec.js","skipped":false,"dir":"test"},{"name":"should process normal response","suites":["Additional","Custom response processing"],"updatePoint":{"line":80,"column":42,"index":1939},"line":80,"code":"        it('should process normal response', () => {\n          return knex('accounts').limit(1).then(res => {\n            expect(res.callCount).to.equal(1);\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should pass query context to the custom handler","suites":["Additional","Custom response processing"],"updatePoint":{"line":85,"column":59,"index":2139},"line":85,"code":"        it('should pass query context to the custom handler', () => {\n          return knex('accounts').queryContext('the context').limit(1).then(res => {\n            expect(res.queryContext).to.equal('the context');\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should process raw response","suites":["Additional","Custom response processing"],"updatePoint":{"line":90,"column":39,"index":2362},"line":90,"code":"        it('should process raw response', () => {\n          return knex.raw('select * from ??', ['accounts']).then(res => {\n            expect(res.callCount).to.equal(1);\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should pass query context for raw responses","suites":["Additional","Custom response processing"],"updatePoint":{"line":95,"column":55,"index":2575},"line":95,"code":"        it('should pass query context for raw responses', () => {\n          return knex.raw('select * from ??', ['accounts']).queryContext('the context').then(res => {\n            expect(res.queryContext).to.equal('the context');\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should process response done in transaction","suites":["Additional","Custom response processing"],"updatePoint":{"line":100,"column":55,"index":2831},"line":100,"code":"        it('should process response done in transaction', () => {\n          return knex.transaction(trx => {\n            return trx('accounts').limit(1).then(res => {\n              expect(res.callCount).to.equal(1);\n              return res;\n            });\n          }).then(res => {\n            expect(res.callCount).to.equal(1);\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should pass query context for responses from transactions","suites":["Additional","Custom response processing"],"updatePoint":{"line":110,"column":69,"index":3203},"line":110,"code":"        it('should pass query context for responses from transactions', () => {\n          return knex.transaction(trx => {\n            return trx('accounts').queryContext('the context').limit(1).then(res => {\n              expect(res.queryContext).to.equal('the context');\n              return res;\n            });\n          }).then(res => {\n            expect(res.queryContext).to.equal('the context');\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should handle error correctly in a stream","suites":["Additional","Custom response processing"],"updatePoint":{"line":120,"column":53,"index":3617},"line":120,"code":"        it('should handle error correctly in a stream', done => {\n          const stream = knex('wrongtable').limit(1).stream();\n          stream.on('error', () => {\n            done();\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should process response done through a stream","suites":["Additional","Custom response processing"],"updatePoint":{"line":126,"column":57,"index":3833},"line":126,"code":"        it('should process response done through a stream', done => {\n          knex('accounts').truncate().then(() => {\n            return insertAccounts(knex, 'accounts');\n          }).then(() => {\n            let response;\n            const stream = knex('accounts').limit(1).stream();\n            stream.on('data', res => {\n              response = res;\n            });\n            stream.on('finish', () => {\n              expect(response.callCount).to.equal(1);\n              done();\n            });\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should pass query context for responses through a stream","suites":["Additional","Custom response processing"],"updatePoint":{"line":141,"column":68,"index":4376},"line":141,"code":"        it('should pass query context for responses through a stream', done => {\n          let response;\n          const stream = knex('accounts').queryContext('the context').limit(1).stream();\n          stream.on('data', res => {\n            response = res;\n          });\n          stream.on('finish', () => {\n            expect(response.queryContext).to.equal('the context');\n            done();\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should process response for each row done through a stream","suites":["Additional","Custom response processing"],"updatePoint":{"line":152,"column":70,"index":4802},"line":152,"code":"        it('should process response for each row done through a stream', done => {\n          const stream = knex('accounts').limit(5).stream();\n          let count = 0;\n          stream.on('data', () => count++);\n          stream.on('finish', () => {\n            expect(count).to.equal(5);\n            done();\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should work using camelCased table name","suites":["Additional","columnInfo with wrapIdentifier and postProcessResponse"],"updatePoint":{"line":178,"column":51,"index":5749},"line":178,"code":"        it('should work using camelCased table name', () => {\n          return knex('testTableTwo').columnInfo().then(res => {\n            expect(Object.keys(res)).to.have.all.members(['id', 'accountId', 'details', 'status']);\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should work using snake_cased table name","suites":["Additional","columnInfo with wrapIdentifier and postProcessResponse"],"updatePoint":{"line":183,"column":52,"index":6003},"line":183,"code":"        it('should work using snake_cased table name', () => {\n          return knex('test_table_two').columnInfo().then(res => {\n            expect(Object.keys(res)).to.have.all.members(['id', 'accountId', 'details', 'status']);\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should return the correct column when a single property is given to returning","suites":["Additional","returning with wrapIdentifier and postProcessResponse` (TODO: fix to work on all possible dialects)"],"updatePoint":{"line":220,"column":89,"index":7554},"line":220,"code":"        it('should return the correct column when a single property is given to returning', () => {\n          if (!isPostgreSQL(knex) && !isMssql(knex) && !isBetterSQLite3(knex)) {\n            return;\n          }\n\n          return knex('accounts_foo').insert({\n            balance_foo: 123\n          }).returning('balance_foo').then(res => {\n            expect(res).to.eql([{\n              balance_foo: 123\n            }]);\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should return the correct columns when multiple properties are given to returning","suites":["Additional","returning with wrapIdentifier and postProcessResponse` (TODO: fix to work on all possible dialects)"],"updatePoint":{"line":233,"column":93,"index":8008},"line":233,"code":"        it('should return the correct columns when multiple properties are given to returning', () => {\n          if (!isPostgreSQL(knex) && !isMssql(knex) && !isBetterSQLite3(knex)) {\n            return;\n          }\n\n          return knex('accounts_foo').insert({\n            balance_foo: 123,\n            email_foo: 'foo@bar.com'\n          }).returning(['balance_foo', 'email_foo']).then(res => {\n            expect(res).to.eql([{\n              balance_foo: 123,\n              email_foo: 'foo@bar.com'\n            }]);\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should truncate a table with truncate","suites":["Additional","other operations"],"updatePoint":{"line":250,"column":49,"index":8564},"line":250,"code":"        it('should truncate a table with truncate', function () {\n          return knex('test_table_two').truncate().testSql(function (tester) {\n            tester('mysql', 'truncate `test_table_two`');\n            tester('pg', 'truncate \"test_table_two\" restart identity');\n            tester('pgnative', 'truncate \"test_table_two\" restart identity');\n            tester('pg-redshift', 'truncate \"test_table_two\"');\n            tester('sqlite3', 'delete from `test_table_two`');\n            tester('oracledb', 'truncate table \"test_table_two\"');\n            tester('mssql', 'truncate table [test_table_two]');\n          }).then(() => {\n            return knex('test_table_two').select('*').then(resp => {\n              expect(resp).to.have.length(0);\n            });\n          }).then(() => {\n            // Insert new data after truncate and make sure ids restart at 1.\n            // This doesn't currently work on oracle, where the created sequence\n            // needs to be manually reset.\n            // On redshift, one would need to create an entirely new table and do\n            //  `insert into ... (select ...); alter table rename...`\n            if (isOracle(knex) || isRedshift(knex)) {\n              return;\n            }\n\n            return knex('test_table_two').insert({\n              status: 1\n            }).then(res => {\n              return knex('test_table_two').select('id').first().then(res => {\n                expect(res).to.be.an('object');\n\n                if (!isCockroachDB(knex)) {\n                  expect(res.id).to.equal(1);\n                }\n              });\n            });\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should allow raw queries directly with `knex.raw`","suites":["Additional","other operations"],"updatePoint":{"line":286,"column":61,"index":10215},"line":286,"code":"        it('should allow raw queries directly with `knex.raw`', function () {\n          const tables = {\n            [drivers.MySQL]: 'SHOW TABLES',\n            [drivers.MySQL2]: 'SHOW TABLES',\n            [drivers.CockroachDB]: \"SELECT table_name FROM information_schema.tables WHERE table_schema='public'\",\n            [drivers.PostgreSQL]: \"SELECT table_name FROM information_schema.tables WHERE table_schema='public'\",\n            [drivers.PgNative]: \"SELECT table_name FROM information_schema.tables WHERE table_schema='public'\",\n            [drivers.Redshift]: \"SELECT table_name FROM information_schema.tables WHERE table_schema='public'\",\n            [drivers.BetterSQLite3]: \"SELECT name FROM sqlite_master WHERE type='table';\",\n            [drivers.SQLite]: \"SELECT name FROM sqlite_master WHERE type='table';\",\n            [drivers.Oracle]: 'select TABLE_NAME from USER_TABLES',\n            [drivers.MsSQL]: \"SELECT table_name FROM INFORMATION_SCHEMA.TABLES WHERE table_schema='dbo'\"\n          };\n          return knex.raw(tables[knex.client.driverName]).testSql(function (tester) {\n            tester(knex.client.driverName, tables[knex.client.driverName]);\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should allow using the primary table as a raw statement","suites":["Additional","other operations"],"updatePoint":{"line":303,"column":67,"index":11417},"line":303,"code":"        it('should allow using the primary table as a raw statement', function () {\n          expect(knex(knex.raw('raw_table_name')).toQuery()).to.equal('select * from raw_table_name');\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should allow using .fn-methods to create raw statements","suites":["Additional","other operations"],"updatePoint":{"line":306,"column":67,"index":11616},"line":306,"code":"        it('should allow using .fn-methods to create raw statements', function () {\n          expect(knex.fn.now().prototype === knex.raw().prototype);\n          expect(knex.fn.now().toQuery()).to.equal('CURRENT_TIMESTAMP');\n          expect(knex.fn.now(6).toQuery()).to.equal('CURRENT_TIMESTAMP(6)');\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should allow using .fn-methods to convert uuid to binary","suites":["Additional","other operations"],"updatePoint":{"line":311,"column":68,"index":11931},"line":311,"code":"        it('should allow using .fn-methods to convert uuid to binary', function () {\n          const originalUuid = '6c825dc9-c98f-37ab-b01b-416294811a84';\n          const binary = knex.fn.uuidToBin(originalUuid);\n          const uuid = knex.fn.binToUuid(binary);\n          expect(uuid).to.equal(originalUuid);\n          const binaryUnorder = knex.fn.uuidToBin(originalUuid, false);\n          const uuidUnorder = knex.fn.binToUuid(binaryUnorder, false);\n          expect(uuidUnorder).to.equal(originalUuid);\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should insert binary uuid and retrieve it with not ordered uuid data","suites":["Additional","other operations"],"updatePoint":{"line":320,"column":80,"index":12463},"line":320,"code":"        it('should insert binary uuid and retrieve it with not ordered uuid data', async () => {\n          await knex.schema.dropTableIfExists('uuid_table');\n          await knex.schema.createTable('uuid_table', t => {\n            t.uuid('uuid_col_binary', {\n              useBinaryUuid: true\n            });\n          });\n          const originalUuid = '3f06af63-a93c-11e4-9797-00505690773f';\n          let uuidToInsert;\n\n          if (isPostgreSQL(knex) || isCockroachDB(knex)) {\n            uuidToInsert = originalUuid;\n          } else {\n            uuidToInsert = knex.fn.uuidToBin(originalUuid, false);\n          }\n\n          await knex('uuid_table').insert({\n            uuid_col_binary: uuidToInsert\n          });\n          const uuid = await knex('uuid_table').select('uuid_col_binary');\n          let expectedUuid;\n\n          if (isPostgreSQL(knex) || isCockroachDB(knex)) {\n            expectedUuid = uuid[0].uuid_col_binary;\n          } else {\n            expectedUuid = knex.fn.binToUuid(uuid[0].uuid_col_binary, false);\n          }\n\n          expect(expectedUuid).to.equal(originalUuid);\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should insert binary uuid and retrieve it","suites":["Additional","other operations"],"updatePoint":{"line":350,"column":53,"index":13550},"line":350,"code":"        it('should insert binary uuid and retrieve it', async () => {\n          await knex.schema.dropTableIfExists('uuid_table');\n          await knex.schema.createTable('uuid_table', t => {\n            t.uuid('uuid_col_binary', {\n              useBinaryUuid: true\n            });\n          });\n          const originalUuid = '3f06af63-a93c-11e4-9797-00505690773f';\n          let uuidToInsert;\n\n          if (isPostgreSQL(knex) || isCockroachDB(knex)) {\n            uuidToInsert = originalUuid;\n          } else {\n            uuidToInsert = knex.fn.uuidToBin(originalUuid);\n          }\n\n          await knex('uuid_table').insert({\n            uuid_col_binary: uuidToInsert\n          });\n          const uuid = await knex('uuid_table').select('uuid_col_binary');\n          let expectedUuid;\n\n          if (isPostgreSQL(knex) || isCockroachDB(knex)) {\n            expectedUuid = uuid[0].uuid_col_binary;\n          } else {\n            expectedUuid = knex.fn.binToUuid(uuid[0].uuid_col_binary);\n          }\n\n          expect(expectedUuid).to.equal(originalUuid);\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"#2184 - should properly escape table name for SQLite columnInfo","suites":["Additional","other operations"],"updatePoint":{"line":380,"column":75,"index":14645},"line":380,"code":"        it('#2184 - should properly escape table name for SQLite columnInfo', function () {\n          if (!isSQLite(knex)) {\n            return this.skip();\n          }\n\n          return knex.schema.dropTableIfExists('group').then(function () {\n            return knex.schema.createTable('group', function (table) {\n              table.integer('foo');\n            });\n          }).then(function () {\n            return knex('group').columnInfo();\n          }).then(function (columnInfo) {\n            expect(columnInfo).to.deep.equal({\n              foo: {\n                type: 'integer',\n                maxLength: null,\n                nullable: true,\n                defaultValue: null\n              }\n            });\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"create stored procedure","suites":["Additional","other operations","test oracle stored procedures"],"updatePoint":{"line":407,"column":39,"index":15503},"line":407,"code":"            it('create stored procedure', function () {\n              return knex.raw(`\n            CREATE OR REPLACE PROCEDURE SYSTEM.multiply (X IN NUMBER, Y IN NUMBER, OUTPUT OUT NUMBER)\n              IS\n              BEGIN\n                OUTPUT := X * Y;\n              END;`).then(function (result) {\n                expect(result).to.be.an('array');\n              });\n            });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"get outbound values from stored procedure","suites":["Additional","other operations","test oracle stored procedures"],"updatePoint":{"line":417,"column":57,"index":15911},"line":417,"code":"            it('get outbound values from stored procedure', function () {\n              const bindVars = {\n                x: 6,\n                y: 7,\n                output: {\n                  dir: oracledb.BIND_OUT\n                }\n              };\n              return knex.raw('BEGIN SYSTEM.MULTIPLY(:x, :y, :output); END;', bindVars).then(function (result) {\n                expect(result[0]).to.be.ok;\n                expect(result[0]).to.equal('42');\n              });\n            });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"drop stored procedure","suites":["Additional","other operations","test oracle stored procedures"],"updatePoint":{"line":430,"column":37,"index":16385},"line":430,"code":"            it('drop stored procedure', function () {\n              const bindVars = {\n                x: 6,\n                y: 7\n              };\n              return knex.raw('drop procedure SYSTEM.MULTIPLY', bindVars).then(function (result) {\n                expect(result).to.be.ok;\n                expect(result).to.be.an('array');\n              });\n            });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should allow renaming a column","suites":["Additional","other operations","test oracle stored procedures"],"updatePoint":{"line":443,"column":42,"index":16786},"line":443,"code":"        it('should allow renaming a column', async function () {\n          let countColumn;\n\n          if (isOracle(knex)) {\n            countColumn = 'COUNT(*)';\n          } else if (isMssql(knex)) {\n            countColumn = '';\n          } else {\n            countColumn = 'count(*)';\n          }\n\n          await dropTables(knex);\n          await createAccounts(knex, false, false);\n          await createTestTableTwo(knex);\n          const inserts = [];\n\n          _.times(40, function (i) {\n            inserts.push({\n              email: 'email' + i,\n              first_name: 'Test',\n              last_name: 'Data'\n            });\n          });\n\n          await knex('accounts').insert(inserts);\n          let aboutCol;\n\n          if (isMysql(knex)) {\n            const metadata = await knex.raw('SHOW FULL COLUMNS FROM accounts'); // Store the column metadata\n\n            aboutCol = metadata[0].filter(t => t.Field === 'about')[0];\n            delete aboutCol.Field;\n          }\n\n          const count = (await knex.count('*').from('accounts'))[0][countColumn];\n          await knex.schema.table('accounts', function (t) {\n            t.renameColumn('about', 'about_col');\n          }).testSql(function (tester) {\n            tester('mysql', ['show full fields from `accounts` where field = ?']);\n            tester('pg', ['alter table \"accounts\" rename \"about\" to \"about_col\"']);\n            tester('pgnative', ['alter table \"accounts\" rename \"about\" to \"about_col\"']);\n            tester('pg-redshift', ['alter table \"accounts\" rename \"about\" to \"about_col\"']);\n            tester('sqlite3', ['alter table `accounts` rename `about` to `about_col`']);\n            tester('oracledb', ['DECLARE PK_NAME VARCHAR(200); IS_AUTOINC NUMBER := 0; BEGIN  EXECUTE IMMEDIATE (\\'ALTER TABLE \"accounts\" RENAME COLUMN \"about\" TO \"about_col\"\\');  SELECT COUNT(*) INTO IS_AUTOINC from \"USER_TRIGGERS\" where trigger_name = \\'accounts_autoinc_trg\\';  IF (IS_AUTOINC > 0) THEN    SELECT cols.column_name INTO PK_NAME    FROM all_constraints cons, all_cons_columns cols    WHERE cons.constraint_type = \\'P\\'    AND cons.constraint_name = cols.constraint_name    AND cons.owner = cols.owner    AND cols.table_name = \\'accounts\\';    IF (\\'about_col\\' = PK_NAME) THEN      EXECUTE IMMEDIATE (\\'DROP TRIGGER \"accounts_autoinc_trg\"\\');      EXECUTE IMMEDIATE (\\'create or replace trigger \"accounts_autoinc_trg\"      BEFORE INSERT on \"accounts\" for each row        declare        checking number := 1;        begin          if (:new.\"about_col\" is null) then            while checking >= 1 loop              select \"accounts_seq\".nextval into :new.\"about_col\" from dual;              select count(\"about_col\") into checking from \"accounts\"              where \"about_col\" = :new.\"about_col\";            end loop;          end if;        end;\\');    end if;  end if;END;']);\n            tester('mssql', [\"exec sp_rename ?, ?, 'COLUMN'\"]);\n          });\n\n          if (isMysql(knex)) {\n            const values = await knex.raw('SHOW FULL COLUMNS FROM accounts');\n            const newAboutCol = values[0].filter(t => t.Field === 'about_col')[0]; // Check if all metadata excepted the Field name (DEFAULT, COLLATION, EXTRA, etc.) are preserved after rename.\n\n            delete newAboutCol.Field;\n            expect(aboutCol).to.eql(newAboutCol);\n          }\n\n          const countAfterRename = (await knex.count('*').from('accounts'))[0][countColumn];\n          expect(countAfterRename).to.equal(count);\n          await knex.schema.table('accounts', function (t) {\n            t.renameColumn('about_col', 'about');\n          });\n          const countOrigin = (await knex.count('*').from('accounts'))[0][countColumn];\n          expect(countOrigin).to.equal(count);\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should allow dropping a column","suites":["Additional","other operations","test oracle stored procedures"],"updatePoint":{"line":506,"column":42,"index":20547},"line":506,"code":"        it('should allow dropping a column', async function () {\n          let countColumn;\n\n          if (isOracle(knex)) {\n            countColumn = 'COUNT(*)';\n          } else if (isMssql(knex)) {\n            countColumn = '';\n          } else {\n            countColumn = 'count(*)';\n          }\n\n          let count;\n          await knex.count('*').from('accounts').then(function (resp) {\n            count = resp[0][countColumn];\n          }).then(function () {\n            return knex.schema.table('accounts', function (t) {\n              t.dropColumn('first_name');\n            }).testSql(function (tester) {\n              tester('mysql', ['alter table `accounts` drop `first_name`']);\n              tester('pg', ['alter table \"accounts\" drop column \"first_name\"']);\n              tester('pgnative', ['alter table \"accounts\" drop column \"first_name\"']);\n              tester('pg-redshift', ['alter table \"accounts\" drop column \"first_name\"']);\n              tester('sqlite3', ['PRAGMA table_info(`accounts`)']);\n              tester('oracledb', ['alter table \"accounts\" drop (\"first_name\")']); //tester('oracledb', ['alter table \"accounts\" drop (\"first_name\")']);\n\n              tester('mssql', [\"\\n              DECLARE @constraint varchar(100) = (SELECT default_constraints.name\\n                                                  FROM sys.all_columns\\n                                                  INNER JOIN sys.tables\\n                                                    ON all_columns.object_id = tables.object_id\\n                                                  INNER JOIN sys.schemas\\n                                                    ON tables.schema_id = schemas.schema_id\\n                                                  INNER JOIN sys.default_constraints\\n                                                    ON all_columns.default_object_id = default_constraints.object_id\\n                                                  WHERE schemas.name = 'dbo'\\n                                                  AND tables.name = 'accounts'\\n                                                  AND all_columns.name = 'first_name')\\n\\n              IF @constraint IS NOT NULL EXEC('ALTER TABLE accounts DROP CONSTRAINT ' + @constraint)\", 'ALTER TABLE [accounts] DROP COLUMN [first_name]']);\n            });\n          }).then(function () {\n            return knex.select('*').from('accounts').first();\n          }).then(function (resp) {\n            expect(_.keys(resp).sort()).to.eql(['about', 'balance', 'created_at', 'email', 'id', 'last_name', 'logins', 'phone', 'updated_at']);\n          }).then(function () {\n            return knex.count('*').from('accounts');\n          }).then(function (resp) {\n            expect(resp[0][countColumn]).to.equal(count);\n          });\n          await dropTables(knex);\n          await createAccounts(knex, false, false);\n          await createTestTableTwo(knex);\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":".timeout() should throw TimeoutError","suites":["Additional","timeouts"],"updatePoint":{"line":548,"column":48,"index":23529},"line":548,"code":"        it('.timeout() should throw TimeoutError', async function () {\n          const driverName = knex.client.driverName;\n\n          if (isSQLite(knex)) {\n            return this.skip();\n          } //TODO -- No built-in support for sleeps\n\n\n          if (isRedshift(knex)) {\n            return this.skip();\n          }\n\n          const testQueries = {\n            [drivers.CockroachDB]: function () {\n              return knex.raw('SELECT pg_sleep(1)');\n            },\n            [drivers.PostgreSQL]: function () {\n              return knex.raw('SELECT pg_sleep(1)');\n            },\n            [drivers.PgNative]: function () {\n              return knex.raw('SELECT pg_sleep(1)');\n            },\n            [drivers.MySQL]: function () {\n              return knex.raw('SELECT SLEEP(1)');\n            },\n            [drivers.MySQL2]: function () {\n              return knex.raw('SELECT SLEEP(1)');\n            },\n            [drivers.MsSQL]: function () {\n              return knex.raw(\"WAITFOR DELAY '00:00:01'\");\n            },\n            [drivers.Oracle]: function () {\n              return knex.raw('begin dbms_lock.sleep(1); end;');\n            }\n          };\n\n          if (!Object.prototype.hasOwnProperty.call(testQueries, driverName)) {\n            throw new Error('Missing test query for driver: ' + driverName);\n          }\n\n          const query = testQueries[driverName]();\n          await query.timeout(200).then(function () {\n            expect(true).to.equal(false);\n          }).catch(function (error) {\n            expect(_.pick(error, 'timeout', 'name', 'message')).to.deep.equal({\n              timeout: 200,\n              name: 'KnexTimeoutError',\n              message: 'Defined query timeout of 200ms exceeded when running query.'\n            });\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":".timeout(ms, {cancel: true}) should throw TimeoutError and cancel slow query","suites":["Additional","timeouts"],"updatePoint":{"line":599,"column":88,"index":25372},"line":599,"code":"        it('.timeout(ms, {cancel: true}) should throw TimeoutError and cancel slow query', async function () {\n          if (isSQLite(knex) || isCockroachDB(knex)) {\n            return this.skip();\n          } //TODO -- No built-in support for sleeps\n\n\n          if (isRedshift(knex)) {\n            return this.skip();\n          } // There's unexpected behavior caused by knex releasing a connection back\n          // to the pool because of a timeout when a long query is still running.\n          // A subsequent query will acquire the connection (still in-use) and hang\n          // until the first query finishes. Setting a sleep time longer than the\n          // mocha timeout exposes this behavior.\n\n\n          const testQueries = {\n            [drivers.PostgreSQL]: function () {\n              return knex.raw('SELECT pg_sleep(10)');\n            },\n            [drivers.CockroachDB]: function () {\n              return knex.raw('SELECT pg_sleep(10)');\n            },\n            [drivers.PgNative]: function () {\n              return knex.raw('SELECT pg_sleep(10)');\n            },\n            [drivers.MySQL]: function () {\n              return knex.raw('SELECT SLEEP(10)');\n            },\n            [drivers.MySQL2]: function () {\n              return knex.raw('SELECT SLEEP(10)');\n            },\n            [drivers.MsSQL]: function () {\n              return knex.raw(\"WAITFOR DELAY '00:00:10'\");\n            },\n            [drivers.Oracle]: function () {\n              return knex.raw('begin dbms_lock.sleep(10); end;');\n            }\n          };\n          const driverName = knex.client.driverName;\n\n          if (!Object.prototype.hasOwnProperty.call(testQueries, driverName)) {\n            throw new Error('Missing test query for driverName: ' + driverName);\n          }\n\n          const query = testQueries[driverName]();\n\n          function addTimeout() {\n            return query.timeout(200, {\n              cancel: true\n            });\n          } // Only mysql/postgres query cancelling supported for now\n\n\n          if (!isMysql(knex) && !isPgBased(knex)) {\n            expect(addTimeout).to.throw('Query cancelling not supported for this dialect');\n            return; // TODO: Use `this.skip()` here?\n          }\n\n          const getProcessesQueries = {\n            [drivers.CockroachDB]: function () {\n              return knex.raw('SELECT * FROM [SHOW CLUSTER STATEMENTS]');\n            },\n            [drivers.PostgreSQL]: function () {\n              return knex.raw('SELECT * from pg_stat_activity');\n            },\n            [drivers.PgNative]: function () {\n              return knex.raw('SELECT * from pg_stat_activity');\n            },\n            [drivers.MySQL]: function () {\n              return knex.raw('SHOW PROCESSLIST');\n            },\n            [drivers.MySQL2]: function () {\n              return knex.raw('SHOW PROCESSLIST');\n            }\n          };\n\n          if (!Object.prototype.hasOwnProperty.call(getProcessesQueries, driverName)) {\n            throw new Error('Missing test query for driverName: ' + driverName);\n          }\n\n          const getProcessesQuery = getProcessesQueries[driverName]();\n\n          try {\n            await addTimeout();\n            expect(true).to.equal(false);\n          } catch (error) {\n            expect(_.pick(error, 'timeout', 'name', 'message')).to.deep.equal({\n              timeout: 200,\n              name: 'KnexTimeoutError',\n              message: 'Defined query timeout of 200ms exceeded when running query.'\n            }); // Ensure sleep command is removed.\n            // This query will hang if a connection gets released back to the pool\n            // too early.\n            // 50ms delay since killing query doesn't seem to have immediate effect to the process listing\n\n            await delay(50);\n            const results = await getProcessesQuery;\n            let processes;\n            let sleepProcess;\n\n            if (isPgBased(knex)) {\n              processes = results.rows;\n              sleepProcess = _.find(processes, {\n                query: query.toString()\n              });\n            } else {\n              processes = results[0];\n              sleepProcess = _.find(processes, {\n                Info: 'SELECT SLEEP(10)'\n              });\n            }\n\n            expect(sleepProcess).to.equal(undefined);\n          }\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":".timeout(ms, {cancel: true}) should throw TimeoutError and cancel slow query in transaction","suites":["Additional","timeouts"],"updatePoint":{"line":714,"column":103,"index":29746},"line":714,"code":"        it('.timeout(ms, {cancel: true}) should throw TimeoutError and cancel slow query in transaction', async function () {\n          if (isSQLite(knex) || isCockroachDB(knex)) {\n            return this.skip();\n          } //TODO -- No built-in support for sleeps\n\n\n          if (isRedshift(knex)) {\n            return this.skip();\n          } // There's unexpected behavior caused by knex releasing a connection back\n          // to the pool because of a timeout when a long query is still running.\n          // A subsequent query will acquire the connection (still in-use) and hang\n          // until the first query finishes. Setting a sleep time longer than the\n          // mocha timeout exposes this behavior.\n\n\n          const testQueries = {\n            [drivers.CockroachDB]: function () {\n              return 'SELECT pg_sleep(10)';\n            },\n            [drivers.PostgreSQL]: function () {\n              return 'SELECT pg_sleep(10)';\n            },\n            [drivers.PgNative]: function () {\n              return 'SELECT pg_sleep(10)';\n            },\n            [drivers.MySQL]: function () {\n              return 'SELECT SLEEP(10)';\n            },\n            [drivers.MySQL2]: function () {\n              return 'SELECT SLEEP(10)';\n            },\n            [drivers.MsSQL]: function () {\n              return \"WAITFOR DELAY '00:00:10'\";\n            },\n            [drivers.Oracle]: function () {\n              return 'begin dbms_lock.sleep(10); end;';\n            }\n          };\n          const driverName = knex.client.driverName;\n\n          if (!Object.prototype.hasOwnProperty.call(testQueries, driverName)) {\n            throw new Error('Missing test query for driverName: ' + driverName);\n          }\n\n          const query = testQueries[driverName]();\n\n          function addTimeout() {\n            return knex.raw(query).timeout(200, {\n              cancel: true\n            });\n          } // Only mysql/postgres query cancelling supported for now\n\n\n          if (!isMysql(knex) && !isPgBased(knex)) {\n            expect(addTimeout).to.throw('Query cancelling not supported for this dialect');\n            return; // TODO: Use `this.skip()` here?\n          }\n\n          const getProcessesQueries = {\n            [drivers.CockroachDB]: function () {\n              return knex.raw('SELECT * FROM [SHOW CLUSTER STATEMENTS]');\n            },\n            [drivers.PostgreSQL]: function () {\n              return knex.raw('SELECT * from pg_stat_activity');\n            },\n            [drivers.PgNative]: function () {\n              return knex.raw('SELECT * from pg_stat_activity');\n            },\n            [drivers.MySQL]: function () {\n              return knex.raw('SHOW PROCESSLIST');\n            },\n            [drivers.MySQL2]: function () {\n              return knex.raw('SHOW PROCESSLIST');\n            }\n          };\n\n          if (!Object.prototype.hasOwnProperty.call(getProcessesQueries, driverName)) {\n            throw new Error('Missing test query for driverName: ' + driverName);\n          }\n\n          const getProcessesQuery = getProcessesQueries[driverName]();\n          await knex.transaction(trx => addTimeout().transacting(trx)).then(function () {\n            expect(true).to.equal(false);\n          }).catch(async function (error) {\n            expect(_.pick(error, 'timeout', 'name', 'message')).to.deep.equal({\n              timeout: 200,\n              name: 'KnexTimeoutError',\n              message: 'Defined query timeout of 200ms exceeded when running query.'\n            }); // Ensure sleep command is removed.\n            // This query will hang if a connection gets released back to the pool\n            // too early.\n            // 50ms delay since killing query doesn't seem to have immediate effect to the process listing\n\n            await delay(50);\n            const results = await getProcessesQuery;\n            let processes;\n            let sleepProcess;\n\n            if (_.startsWith(driverName, 'pg')) {\n              processes = results.rows;\n              sleepProcess = _.find(processes, {\n                query: query.toString()\n              });\n            } else {\n              processes = results[0];\n              sleepProcess = _.find(processes, {\n                Info: 'SELECT SLEEP(10)'\n              });\n            }\n\n            expect(sleepProcess).to.equal(undefined);\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":".timeout(ms, {cancel: true}) should cancel slow query even if connection pool is exhausted","suites":["Additional","timeouts"],"updatePoint":{"line":827,"column":102,"index":34133},"line":827,"code":"        it('.timeout(ms, {cancel: true}) should cancel slow query even if connection pool is exhausted', async function () {\n          // Only mysql/postgres query cancelling supported for now\n          if (isCockroachDB(knex) || !isMysql(knex) && !isPgBased(knex)) {\n            return this.skip();\n          } // To make this test easier, I'm changing the pool settings to max 1.\n          // Also setting acquireTimeoutMillis to lower as not to wait the default time\n\n\n          const knexConfig = _.cloneDeep(knex.client.config);\n\n          knexConfig.pool.min = 0;\n          knexConfig.pool.max = 1;\n          knexConfig.pool.acquireTimeoutMillis = 100;\n          const knexDb = new Knex(knexConfig);\n          const testQueries = {\n            [drivers.CockroachDB]: function () {\n              return knexDb.raw('SELECT pg_sleep(10)');\n            },\n            [drivers.PostgreSQL]: function () {\n              return knexDb.raw('SELECT pg_sleep(10)');\n            },\n            [drivers.PgNative]: function () {\n              return knexDb.raw('SELECT pg_sleep(10)');\n            },\n            [drivers.MySQL]: function () {\n              return knexDb.raw('SELECT SLEEP(10)');\n            },\n            [drivers.MySQL2]: function () {\n              return knexDb.raw('SELECT SLEEP(10)');\n            },\n            [drivers.MsSQL]: function () {\n              return knexDb.raw(\"WAITFOR DELAY '00:00:10'\");\n            },\n            [drivers.Oracle]: function () {\n              return knexDb.raw('begin dbms_lock.sleep(10); end;');\n            }\n          };\n          const driverName = knex.client.driverName;\n\n          if (!Object.prototype.hasOwnProperty.call(testQueries, driverName)) {\n            throw new Error('Missing test query for dialect: ' + driverName);\n          }\n\n          const query = testQueries[driverName](); // We must use the original knex instance without the exhausted pool to list running queries\n\n          const getProcessesForDriver = {\n            [drivers.CockroachDB]: async () => {\n              const results = await knex.raw('SELECT * FROM [SHOW CLUSTER STATEMENTS]');\n              return _.map(_.filter(results.rows, {\n                state: 'active'\n              }), 'query');\n            },\n            [drivers.PostgreSQL]: async () => {\n              const results = await knex.raw('SELECT * from pg_stat_activity');\n              return _.map(_.filter(results.rows, {\n                state: 'active'\n              }), 'query');\n            },\n            [drivers.PgNative]: async () => {\n              const results = await knex.raw('SELECT * from pg_stat_activity');\n              return _.map(_.filter(results.rows, {\n                state: 'active'\n              }), 'query');\n            },\n            [drivers.MySQL]: async () => {\n              const results = await knex.raw('SHOW PROCESSLIST');\n              return _.map(results[0], 'Info');\n            },\n            [drivers.MySQL2]: async () => {\n              const results = await knex.raw('SHOW PROCESSLIST');\n              return _.map(results[0], 'Info');\n            }\n          };\n\n          if (!Object.prototype.hasOwnProperty.call(getProcessesForDriver, driverName)) {\n            throw new Error('Missing test query for driverName: ' + driverName);\n          }\n\n          const getProcesses = getProcessesForDriver[driverName];\n\n          try {\n            const promise = query.timeout(50, {\n              cancel: true\n            }).then(_.identity);\n            await delay(15);\n            const processesBeforeTimeout = await getProcesses();\n            expect(processesBeforeTimeout).to.include(query.toString());\n            await expect(promise).to.eventually.be.rejected.and.to.deep.include({\n              timeout: 50,\n              name: 'KnexTimeoutError',\n              message: 'Defined query timeout of 50ms exceeded when running query.'\n            });\n            const processesAfterTimeout = await getProcesses();\n            expect(processesAfterTimeout).to.not.include(query.toString());\n          } finally {\n            await knexDb.destroy();\n          }\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":".timeout(ms, {cancel: true}) should release connections after failing if connection cancellation throws an error","suites":["Additional","timeouts"],"updatePoint":{"line":925,"column":124,"index":38286},"line":925,"code":"        it('.timeout(ms, {cancel: true}) should release connections after failing if connection cancellation throws an error', async function () {\n          // Only mysql/postgres query cancelling supported for now\n          if (isCockroachDB(knex) || !isPgBased(knex) && !isMysql(knex)) {\n            return this.skip();\n          } // To make this test easier, I'm changing the pool settings to max 1.\n          // Also setting acquireTimeoutMillis to lower as not to wait the default time\n\n\n          const knexConfig = _.cloneDeep(knex.client.config);\n\n          knexConfig.pool.min = 0;\n          knexConfig.pool.max = 2;\n          knexConfig.pool.acquireTimeoutMillis = 100;\n          const rawTestQueries = {\n            [drivers.CockroachDB]: sleepSeconds => `SELECT pg_sleep(${sleepSeconds})`,\n            [drivers.PostgreSQL]: sleepSeconds => `SELECT pg_sleep(${sleepSeconds})`,\n            [drivers.PgNative]: sleepSeconds => `SELECT pg_sleep(${sleepSeconds})`,\n            [drivers.MySQL]: sleepSeconds => `SELECT SLEEP(${sleepSeconds})`,\n            [drivers.MySQL2]: sleepSeconds => `SELECT SLEEP(${sleepSeconds})`\n          };\n          const driverName = knex.client.driverName;\n\n          if (!Object.prototype.hasOwnProperty.call(rawTestQueries, driverName)) {\n            throw new Error('Missing test query for driverName: ' + driverName);\n          }\n\n          const knexDb = new Knex(knexConfig);\n\n          const getTestQuery = (sleepSeconds = 10) => {\n            const rawTestQuery = rawTestQueries[driverName](sleepSeconds);\n            return knexDb.raw(rawTestQuery);\n          };\n\n          const knexPrototype = Object.getPrototypeOf(knexDb.client);\n          const originalWrappedCancelQueryCall = knexPrototype._wrappedCancelQueryCall;\n\n          knexPrototype._wrappedCancelQueryCall = (conn, connectionToKill) => {\n            if (isPgNative(knex) || isCockroachDB(knex) || isMysql(knex)) {\n              throw new Error('END THIS');\n            } else {\n              return knexPrototype.query(conn, {\n                method: 'raw',\n                sql: 'TestError'\n              });\n            }\n          };\n\n          const queryTimeout = 10;\n          const secondQueryTimeout = 11;\n\n          try {\n            await expect(getTestQuery().timeout(queryTimeout, {\n              cancel: true\n            })).to.be.eventually.rejected.and.deep.include({\n              timeout: queryTimeout,\n              name: isCockroachDB(knex) || isMysql(knex) || isPgNative(knex) ? 'Error' : 'error',\n              message: `After query timeout of ${queryTimeout}ms exceeded, cancelling of query failed.`\n            });\n            knexPrototype._wrappedCancelQueryCall = originalWrappedCancelQueryCall;\n\n            try {\n              await getTestQuery().timeout(secondQueryTimeout, {\n                cancel: true\n              });\n            } catch (err) {\n              console.log(err);\n            }\n\n            await expect(getTestQuery().timeout(secondQueryTimeout, {\n              cancel: true\n            })).to.be.eventually.rejected.and.deep.include({\n              timeout: secondQueryTimeout,\n              name: 'KnexTimeoutError',\n              message: `Defined query timeout of ${secondQueryTimeout}ms exceeded when running query.`\n            });\n          } finally {\n            await knexDb.destroy();\n          }\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"Event: query-response","suites":["Additional","Events"],"updatePoint":{"line":1006,"column":33,"index":41619},"line":1006,"code":"        it('Event: query-response', function () {\n          let queryCount = 0;\n\n          const onQueryResponse = function (response, obj, builder) {\n            queryCount++;\n            expect(response).to.be.an('array');\n            expect(obj).to.be.an('object');\n            expect(obj.__knexUid).to.be.a('string');\n            expect(obj.__knexQueryUid).to.be.a('string');\n            expect(builder).to.be.an('object');\n          };\n\n          knex.on('query-response', onQueryResponse);\n          return knex('accounts').select().on('query-response', onQueryResponse).then(function () {\n            return knex.transaction(function (tr) {\n              return tr('accounts').select().on('query-response', onQueryResponse); //Transactions should emit the event as well\n            });\n          }).then(function () {\n            knex.removeListener('query-response', onQueryResponse);\n            expect(queryCount).to.equal(4);\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"Event: preserves listeners on a copy with user params","suites":["Additional","Events"],"updatePoint":{"line":1028,"column":65,"index":42614},"line":1028,"code":"        it('Event: preserves listeners on a copy with user params', function () {\n          let queryCount = 0;\n\n          const onQueryResponse = function (response, obj, builder) {\n            queryCount++;\n            expect(response).to.be.an('array');\n            expect(obj).to.be.an('object');\n            expect(obj.__knexUid).to.be.a('string');\n            expect(obj.__knexQueryUid).to.be.a('string');\n            expect(builder).to.be.an('object');\n          };\n\n          knex.on('query-response', onQueryResponse);\n          const knexCopy = knex.withUserParams({});\n          return knexCopy('accounts').select().on('query-response', onQueryResponse).then(function () {\n            return knexCopy.transaction(function (tr) {\n              return tr('accounts').select().on('query-response', onQueryResponse); //Transactions should emit the event as well\n            });\n          }).then(function () {\n            expect(Object.keys(knex._events).length).to.equal(1);\n            expect(Object.keys(knexCopy._events).length).to.equal(1);\n            knex.removeListener('query-response', onQueryResponse);\n            expect(Object.keys(knex._events).length).to.equal(0);\n            expect(queryCount).to.equal(4);\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"Event: query-error","suites":["Additional","Events"],"updatePoint":{"line":1054,"column":30,"index":43836},"line":1054,"code":"        it('Event: query-error', function () {\n          let queryCountKnex = 0;\n          let queryCountBuilder = 0;\n\n          const onQueryErrorKnex = function (error, obj) {\n            queryCountKnex++;\n            expect(obj).to.be.an('object');\n            expect(obj.__knexUid).to.be.a('string');\n            expect(obj.__knexQueryUid).to.be.a('string');\n            expect(error).to.be.an('error');\n          };\n\n          const onQueryErrorBuilder = function (error, obj) {\n            queryCountBuilder++;\n            expect(obj).to.be.an('object');\n            expect(obj.__knexUid).to.be.a('string');\n            expect(obj.__knexQueryUid).to.be.a('string');\n            expect(error).to.be.an('error');\n          };\n\n          knex.on('query-error', onQueryErrorKnex);\n          return knex.raw('Broken query').on('query-error', onQueryErrorBuilder).then(function () {\n            expect(true).to.equal(false); //Should not be resolved\n          }).catch(function () {\n            knex.removeListener('query-error', onQueryErrorKnex);\n            knex.removeListener('query-error', onQueryErrorBuilder);\n            expect(queryCountBuilder).to.equal(1);\n            expect(queryCountKnex).to.equal(1);\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"Event: start","suites":["Additional","Events"],"updatePoint":{"line":1084,"column":24,"index":45073},"line":1084,"code":"        it('Event: start', function () {\n          return knex('accounts').insert({\n            last_name: 'Start event test'\n          }).then(function () {\n            const queryBuilder = knex('accounts').select();\n            queryBuilder.on('start', function (builder) {\n              //Alter builder prior to compilation\n              //Select only one row\n              builder.where('last_name', 'Start event test').first();\n            });\n            return queryBuilder;\n          }).then(function (row) {\n            expect(row).to.exist;\n            expect(row.last_name).to.equal('Start event test');\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"Event 'query' should not emit native sql string","suites":["Additional","Events"],"updatePoint":{"line":1100,"column":59,"index":45749},"line":1100,"code":"        it(\"Event 'query' should not emit native sql string\", function () {\n          const builder = knex('accounts').where('id', 1).select();\n          builder.on('query', function (obj) {\n            const native = builder.toSQL().toNative().sql;\n            const sql = builder.toSQL().sql; //Only assert if they diff to begin with.\n            //IE Maria does not diff\n\n            if (native !== sql) {\n              expect(obj.sql).to.not.equal(builder.toSQL().toNative().sql);\n              expect(obj.sql).to.equal(builder.toSQL().sql);\n            }\n          });\n          return builder;\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should capture stack trace on raw query","suites":["Additional","async stack traces"],"updatePoint":{"line":1122,"column":51,"index":46591},"line":1122,"code":"        it('should capture stack trace on raw query', () => {\n          return knex.raw('select * from some_nonexisten_table').catch(err => {\n            expect(err.stack.split('\\n')[2]).to.match(/at Object\\.raw \\(/); // the index 2 might need adjustment if the code is refactored\n\n            expect(typeof err.originalStack).to.equal('string');\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should capture stack trace on schema builder","suites":["Additional","async stack traces"],"updatePoint":{"line":1129,"column":56,"index":46969},"line":1129,"code":"        it('should capture stack trace on schema builder', () => {\n          return knex.schema.renameTable('some_nonexisten_table', 'whatever').catch(err => {\n            expect(err.stack.split('\\n')[1]).to.match(/client\\.schemaBuilder/); // the index 1 might need adjustment if the code is refactored\n\n            expect(typeof err.originalStack).to.equal('string');\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"Overwrite knex.logger functions using config","suites":["Additional","misc"],"updatePoint":{"line":1138,"column":56,"index":47405},"line":1138,"code":"        it('Overwrite knex.logger functions using config', async () => {\n          const knexConfig = { ...knex.client.config\n          };\n          let callCount = 0;\n\n          const assertCall = function (expectedMessage, message) {\n            expect(message).to.equal(expectedMessage);\n            callCount++;\n          };\n\n          knexConfig.log = {\n            warn: assertCall.bind(null, 'test'),\n            error: assertCall.bind(null, 'test'),\n            debug: assertCall.bind(null, 'test'),\n            deprecate: assertCall.bind(null, 'test is deprecated, please use test2')\n          }; //Sqlite warning message\n\n          knexConfig.useNullAsDefault = true;\n          const knexDb = new Knex(knexConfig);\n          knexDb.client.logger.warn('test');\n          knexDb.client.logger.error('test');\n          knexDb.client.logger.debug('test');\n          knexDb.client.logger.deprecate('test', 'test2');\n          expect(callCount).to.equal(4);\n          await knexDb.destroy();\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should allow destroying the pool with knex.destroy","suites":["Additional","misc"],"updatePoint":{"line":1164,"column":62,"index":48419},"line":1164,"code":"        it('should allow destroying the pool with knex.destroy', async function () {\n          const knexConfig = { ...knex.client.config\n          };\n          const knexDb = new Knex(knexConfig);\n          const spy = sinon.spy(knexDb.client.pool, 'destroy');\n          await knexDb.destroy();\n          expect(spy).to.have.callCount(1);\n          expect(knexDb.client.pool).to.equal(undefined);\n          await knexDb.destroy();\n          expect(spy).to.have.callCount(1);\n          spy.restore();\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"should allow initialize the pool with knex.initialize","suites":["Additional","misc"],"updatePoint":{"line":1176,"column":65,"index":48935},"line":1176,"code":"        it('should allow initialize the pool with knex.initialize', async function () {\n          const knexConfig = { ...knex.client.config\n          };\n          const knexDb = new Knex(knexConfig);\n          await knexDb.destroy();\n          expect(knexDb.client.pool).to.equal(undefined);\n          knexDb.initialize();\n          expect(knexDb.client.pool.destroyed).to.equal(false);\n          const waitForDestroy = knexDb.destroy();\n          expect(knexDb.client.pool.destroyed).to.equal(true);\n          return waitForDestroy.then(() => {\n            expect(knexDb.client.pool).to.equal(undefined);\n            knexDb.initialize();\n            expect(knexDb.client.pool.destroyed).to.equal(false);\n          });\n        });","file":"integration2/query/misc/additional.spec.js","skipped":false,"dir":"test"},{"name":"Works correctly with array param","suites":["First"],"updatePoint":{"line":38,"column":42,"index":982},"line":38,"code":"      it('Works correctly with array param', async () => {\n        const result = await knex(tblName).first([colName, col2Name]);\n        expect(result).to.deep.equal({\n          test_col: '1',\n          test_col2: '2'\n        });\n      });","file":"integration2/query/select/first.spec.js","skipped":false,"dir":"test"},{"name":"selects rows using basic text matching","suites":["Selects","FTS queries"],"updatePoint":{"line":30,"column":50,"index":815},"line":30,"code":"        it('selects rows using basic text matching', async () => {\n          await knex('fts_products').insert([{\n            name: 'Red flannel shirt'\n          }, {\n            name: 'Blue flannel shirt'\n          }, {\n            name: 'Red polo shirt'\n          }, {\n            name: 'Blue polo shirt'\n          }, {\n            name: 'Red hooded jacket'\n          }, {\n            name: 'Blue hooded jacket'\n          }]);\n          const matchingRows = await knex.select('*').from('fts_products').where('name', 'match', 'red shirt');\n          expect(matchingRows).to.eql([{\n            name: 'Red flannel shirt'\n          }, {\n            name: 'Red polo shirt'\n          }]);\n        });","file":"integration2/query/select/fts.spec.js","skipped":false,"dir":"test"},{"name":"uses inner join by default","suites":["Joins"],"updatePoint":{"line":60,"column":36,"index":1234},"line":60,"code":"      it('uses inner join by default', function () {\n        return knex('accounts').join('test_table_two', 'accounts.id', '=', 'test_table_two.account_id').select('accounts.*', 'test_table_two.details').orderBy('accounts.id').testSql(function (tester) {\n          tester('mysql', 'select `accounts`.*, `test_table_two`.`details` from `accounts` inner join `test_table_two` on `accounts`.`id` = `test_table_two`.`account_id` order by `accounts`.`id` asc', [], [{\n            id: 1,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test1@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: 2,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test2@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: 3,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test3@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: ''\n          }]);\n          tester('pg', 'select \"accounts\".*, \"test_table_two\".\"details\" from \"accounts\" inner join \"test_table_two\" on \"accounts\".\"id\" = \"test_table_two\".\"account_id\" order by \"accounts\".\"id\" asc', [], [{\n            id: '1',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test1@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: '2',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test2@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: '3',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test3@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: ''\n          }]);\n          tester('pg-redshift', 'select \"accounts\".*, \"test_table_two\".\"details\" from \"accounts\" inner join \"test_table_two\" on \"accounts\".\"id\" = \"test_table_two\".\"account_id\" order by \"accounts\".\"id\" asc', [], [{\n            id: '1',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test1@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: '2',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test2@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: '3',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test3@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: ''\n          }]);\n          tester('sqlite3', 'select `accounts`.*, `test_table_two`.`details` from `accounts` inner join `test_table_two` on `accounts`.`id` = `test_table_two`.`account_id` order by `accounts`.`id` asc', [], [{\n            id: 1,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test1@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: 2,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test2@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: 3,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test3@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: ''\n          }]);\n          tester('oracledb', 'select \"accounts\".*, \"test_table_two\".\"details\" from \"accounts\" inner join \"test_table_two\" on \"accounts\".\"id\" = \"test_table_two\".\"account_id\" order by \"accounts\".\"id\" asc', [], [{\n            id: 1,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test1@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: 2,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test2@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: 3,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test3@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: null // Oracle implicitly converted '' to NULL\n\n          }]);\n          tester('mssql', 'select [accounts].*, [test_table_two].[details] from [accounts] inner join [test_table_two] on [accounts].[id] = [test_table_two].[account_id] order by [accounts].[id] asc', [], [{\n            id: '1',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test1@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: '2',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test2@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: '3',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test3@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: ''\n          }]);\n        });\n      });","file":"integration2/query/select/joins.spec.js","skipped":false,"dir":"test"},{"name":"has a leftJoin method parameter to specify the join type","suites":["Joins"],"updatePoint":{"line":287,"column":66,"index":11272},"line":287,"code":"      it('has a leftJoin method parameter to specify the join type', function () {\n        return knex('accounts').leftJoin('test_table_two', 'accounts.id', '=', 'test_table_two.account_id').select('accounts.*', 'test_table_two.details').orderBy('accounts.id').testSql(function (tester) {\n          tester('mysql', 'select `accounts`.*, `test_table_two`.`details` from `accounts` left join `test_table_two` on `accounts`.`id` = `test_table_two`.`account_id` order by `accounts`.`id` asc', [], [{\n            id: 1,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test1@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: 2,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test2@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: 3,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test3@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: ''\n          }, {\n            id: 4,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test4@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: null\n          }, {\n            id: 5,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test5@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: null\n          }, {\n            id: 6,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test6@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: null\n          }]);\n          tester('pg', 'select \"accounts\".*, \"test_table_two\".\"details\" from \"accounts\" left join \"test_table_two\" on \"accounts\".\"id\" = \"test_table_two\".\"account_id\" order by \"accounts\".\"id\" asc', [], [{\n            id: '1',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test1@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: '2',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test2@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: '3',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test3@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: ''\n          }, {\n            id: '4',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test4@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: null\n          }, {\n            id: '5',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test5@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: null\n          }, {\n            id: '6',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test6@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: null\n          }]);\n          tester('pg-redshift', 'select \"accounts\".*, \"test_table_two\".\"details\" from \"accounts\" left join \"test_table_two\" on \"accounts\".\"id\" = \"test_table_two\".\"account_id\" order by \"accounts\".\"id\" asc', [], [{\n            id: '1',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test1@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: '2',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test2@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: '3',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test3@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: ''\n          }, {\n            id: '4',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test4@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: null\n          }, {\n            id: '5',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test5@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: null\n          }, {\n            id: '6',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test6@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: null\n          }]);\n          tester('sqlite3', 'select `accounts`.*, `test_table_two`.`details` from `accounts` left join `test_table_two` on `accounts`.`id` = `test_table_two`.`account_id` order by `accounts`.`id` asc', [], [{\n            id: 1,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test1@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: 2,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test2@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: 3,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test3@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: ''\n          }, {\n            id: 4,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test4@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: null\n          }, {\n            id: 5,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test5@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: null\n          }, {\n            id: 6,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test6@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: null\n          }]);\n          tester('oracledb', 'select \"accounts\".*, \"test_table_two\".\"details\" from \"accounts\" left join \"test_table_two\" on \"accounts\".\"id\" = \"test_table_two\".\"account_id\" order by \"accounts\".\"id\" asc', [], [{\n            id: 1,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test1@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: 2,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test2@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: 3,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test3@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: null // Oracle implicitly converted '' to NULL\n\n          }, {\n            id: 4,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test4@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: null\n          }, {\n            id: 5,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test5@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: null\n          }, {\n            id: 6,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test6@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: null\n          }]);\n          tester('mssql', 'select [accounts].*, [test_table_two].[details] from [accounts] left join [test_table_two] on [accounts].[id] = [test_table_two].[account_id] order by [accounts].[id] asc', [], [{\n            id: '1',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test1@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: '2',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test2@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.'\n          }, {\n            id: '3',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test3@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: ''\n          }, {\n            id: '4',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test4@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: null\n          }, {\n            id: '5',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test5@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: null\n          }, {\n            id: '6',\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test6@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            details: null\n          }]);\n        });\n      });","file":"integration2/query/select/joins.spec.js","skipped":false,"dir":"test"},{"name":"accepts a callback as the second argument for advanced joins","suites":["Joins"],"updatePoint":{"line":730,"column":70,"index":28170},"line":730,"code":"      it('accepts a callback as the second argument for advanced joins', function () {\n        return knex('accounts').leftJoin('test_table_two', function (join) {\n          join.on('accounts.id', '=', 'test_table_two.account_id');\n          join.orOn('accounts.email', '=', 'test_table_two.details');\n        }).select().orderBy('accounts.id').testSql(function (tester) {\n          tester('mysql', 'select * from `accounts` left join `test_table_two` on `accounts`.`id` = `test_table_two`.`account_id` or `accounts`.`email` = `test_table_two`.`details` order by `accounts`.`id` asc', [], [{\n            id: 1,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test1@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: 1,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.',\n            status: 0\n          }, {\n            id: 2,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test2@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: 2,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.',\n            status: 1\n          }, {\n            id: 3,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test3@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: 3,\n            details: '',\n            status: 1\n          }, {\n            id: null,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test4@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: null,\n            details: null,\n            status: null\n          }, {\n            id: null,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test5@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: null,\n            details: null,\n            status: null\n          }, {\n            id: null,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test6@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: null,\n            details: null,\n            status: null\n          }]);\n          tester('pg', 'select * from \"accounts\" left join \"test_table_two\" on \"accounts\".\"id\" = \"test_table_two\".\"account_id\" or \"accounts\".\"email\" = \"test_table_two\".\"details\" order by \"accounts\".\"id\" asc', [], [{\n            id: 1,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test1@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: 1,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.',\n            status: 0\n          }, {\n            id: 2,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test2@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: 2,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.',\n            status: 1\n          }, {\n            id: 3,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test3@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: 3,\n            details: '',\n            status: 1\n          }, {\n            id: null,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test4@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: null,\n            details: null,\n            status: null\n          }, {\n            id: null,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test5@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: null,\n            details: null,\n            status: null\n          }, {\n            id: null,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test6@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: null,\n            details: null,\n            status: null\n          }]);\n          tester('pg-redshift', 'select * from \"accounts\" left join \"test_table_two\" on \"accounts\".\"id\" = \"test_table_two\".\"account_id\" or \"accounts\".\"email\" = \"test_table_two\".\"details\" order by \"accounts\".\"id\" asc', [], [{\n            id: 1,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test1@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: 1,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.',\n            status: 0\n          }, {\n            id: 2,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test2@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: 2,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.',\n            status: 1\n          }, {\n            id: 3,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test3@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: 3,\n            details: '',\n            status: 1\n          }, {\n            id: null,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test4@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: null,\n            details: null,\n            status: null\n          }, {\n            id: null,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test5@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: null,\n            details: null,\n            status: null\n          }, {\n            id: null,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test6@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: null,\n            details: null,\n            status: null\n          }]);\n          tester('sqlite3', 'select * from `accounts` left join `test_table_two` on `accounts`.`id` = `test_table_two`.`account_id` or `accounts`.`email` = `test_table_two`.`details` order by `accounts`.`id` asc', [], [{\n            id: 1,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test1@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: 1,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.',\n            status: 0\n          }, {\n            id: 2,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test2@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: 2,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.',\n            status: 1\n          }, {\n            id: 3,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test3@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: 3,\n            details: '',\n            status: 1\n          }, {\n            id: null,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test4@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: null,\n            details: null,\n            status: null\n          }, {\n            id: null,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test5@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: null,\n            details: null,\n            status: null\n          }, {\n            id: null,\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test6@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: null,\n            details: null,\n            status: null\n          }]);\n          tester('mssql', 'select * from [accounts] left join [test_table_two] on [accounts].[id] = [test_table_two].[account_id] or [accounts].[email] = [test_table_two].[details] order by [accounts].[id] asc', [], [{\n            id: ['1', 1],\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test1@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: 1,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.',\n            status: 0\n          }, {\n            id: ['2', 2],\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test2@example.com',\n            logins: 1,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: 2,\n            details: 'Lorem ipsum Minim nostrud Excepteur consectetur enim ut qui sint in veniam in nulla anim do cillum sunt voluptate Duis non incididunt.',\n            status: 1\n          }, {\n            id: ['3', 3],\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test3@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: 3,\n            details: '',\n            status: 1\n          }, {\n            id: ['4', null],\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test4@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: null,\n            details: null,\n            status: null\n          }, {\n            id: ['5', null],\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test5@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: null,\n            details: null,\n            status: null\n          }, {\n            id: ['6', null],\n            first_name: 'Test',\n            last_name: 'User',\n            email: 'test6@example.com',\n            logins: 2,\n            balance: 0,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null,\n            account_id: null,\n            details: null,\n            status: null\n          }]);\n        });\n      });","file":"integration2/query/select/joins.spec.js","skipped":false,"dir":"test"},{"name":"supports join aliases","suites":["Joins"],"updatePoint":{"line":1162,"column":31,"index":44013},"line":1162,"code":"      it('supports join aliases', function () {\n        //Expected output: all pairs of account emails, excluding pairs where the emails are the same.\n        return knex('accounts').join('accounts as a2', 'a2.email', '<>', 'accounts.email').select(['accounts.email as e1', 'a2.email as e2']).where('a2.email', 'test2@example.com').orderBy('e1').limit(5).testSql(function (tester) {\n          tester('mysql', 'select `accounts`.`email` as `e1`, `a2`.`email` as `e2` from `accounts` inner join `accounts` as `a2` on `a2`.`email` <> `accounts`.`email` where `a2`.`email` = ? order by `e1` asc limit ?', ['test2@example.com', 5], [{\n            e1: 'test1@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test3@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test4@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test5@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test6@example.com',\n            e2: 'test2@example.com'\n          }]);\n          tester('pg', 'select \"accounts\".\"email\" as \"e1\", \"a2\".\"email\" as \"e2\" from \"accounts\" inner join \"accounts\" as \"a2\" on \"a2\".\"email\" <> \"accounts\".\"email\" where \"a2\".\"email\" = ? order by \"e1\" asc limit ?', ['test2@example.com', 5], [{\n            e1: 'test1@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test3@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test4@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test5@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test6@example.com',\n            e2: 'test2@example.com'\n          }]);\n          tester('pg-redshift', 'select \"accounts\".\"email\" as \"e1\", \"a2\".\"email\" as \"e2\" from \"accounts\" inner join \"accounts\" as \"a2\" on \"a2\".\"email\" <> \"accounts\".\"email\" where \"a2\".\"email\" = ? order by \"e1\" asc limit ?', ['test2@example.com', 5], [{\n            e1: 'test1@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test3@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test4@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test5@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test6@example.com',\n            e2: 'test2@example.com'\n          }]);\n          tester('sqlite3', 'select `accounts`.`email` as `e1`, `a2`.`email` as `e2` from `accounts` inner join `accounts` as `a2` on `a2`.`email` <> `accounts`.`email` where `a2`.`email` = ? order by `e1` asc limit ?', ['test2@example.com', 5], [{\n            e1: 'test1@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test3@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test4@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test5@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test6@example.com',\n            e2: 'test2@example.com'\n          }]);\n          tester('oracledb', 'select * from (select \"accounts\".\"email\" \"e1\", \"a2\".\"email\" \"e2\" from \"accounts\" inner join \"accounts\" \"a2\" on \"a2\".\"email\" <> \"accounts\".\"email\" where \"a2\".\"email\" = ? order by \"e1\" asc) where rownum <= ?', ['test2@example.com', 5], [{\n            e1: 'test1@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test3@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test4@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test5@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test6@example.com',\n            e2: 'test2@example.com'\n          }]);\n          tester('mssql', 'select top (?) [accounts].[email] as [e1], [a2].[email] as [e2] from [accounts] inner join [accounts] as [a2] on [a2].[email] <> [accounts].[email] where [a2].[email] = ? order by [e1] asc', [5, 'test2@example.com'], [{\n            e1: 'test1@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test3@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test4@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test5@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test6@example.com',\n            e2: 'test2@example.com'\n          }]);\n        });\n      });","file":"integration2/query/select/joins.spec.js","skipped":false,"dir":"test"},{"name":"supports join aliases with advanced joins","suites":["Joins"],"updatePoint":{"line":1263,"column":51,"index":48585},"line":1263,"code":"      it('supports join aliases with advanced joins', function () {\n        //Expected output: all pairs of account emails, excluding pairs where the emails are the same.\n        //But also include the case where the emails are the same, for account 2.\n        return knex('accounts').join('accounts as a2', function () {\n          this.on('accounts.email', '<>', 'a2.email').orOn('accounts.id', '=', 2);\n        }).where('a2.email', 'test2@example.com').select(['accounts.email as e1', 'a2.email as e2']).limit(5).orderBy('e1').testSql(function (tester) {\n          tester('mysql', 'select `accounts`.`email` as `e1`, `a2`.`email` as `e2` from `accounts` inner join `accounts` as `a2` on `accounts`.`email` <> `a2`.`email` or `accounts`.`id` = 2 where `a2`.`email` = ? order by `e1` asc limit ?', ['test2@example.com', 5], [{\n            e1: 'test1@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test2@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test3@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test4@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test5@example.com',\n            e2: 'test2@example.com'\n          }]);\n          tester('pg', 'select \"accounts\".\"email\" as \"e1\", \"a2\".\"email\" as \"e2\" from \"accounts\" inner join \"accounts\" as \"a2\" on \"accounts\".\"email\" <> \"a2\".\"email\" or \"accounts\".\"id\" = 2 where \"a2\".\"email\" = ? order by \"e1\" asc limit ?', ['test2@example.com', 5], [{\n            e1: 'test1@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test2@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test3@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test4@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test5@example.com',\n            e2: 'test2@example.com'\n          }]);\n          tester('pg-redshift', 'select \"accounts\".\"email\" as \"e1\", \"a2\".\"email\" as \"e2\" from \"accounts\" inner join \"accounts\" as \"a2\" on \"accounts\".\"email\" <> \"a2\".\"email\" or \"accounts\".\"id\" = 2 where \"a2\".\"email\" = ? order by \"e1\" asc limit ?', ['test2@example.com', 5], [{\n            e1: 'test1@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test2@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test3@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test4@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test5@example.com',\n            e2: 'test2@example.com'\n          }]);\n          tester('sqlite3', 'select `accounts`.`email` as `e1`, `a2`.`email` as `e2` from `accounts` inner join `accounts` as `a2` on `accounts`.`email` <> `a2`.`email` or `accounts`.`id` = 2 where `a2`.`email` = ? order by `e1` asc limit ?', ['test2@example.com', 5], [{\n            e1: 'test1@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test2@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test3@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test4@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test5@example.com',\n            e2: 'test2@example.com'\n          }]);\n          tester('oracledb', 'select * from (select \"accounts\".\"email\" \"e1\", \"a2\".\"email\" \"e2\" from \"accounts\" inner join \"accounts\" \"a2\" on \"accounts\".\"email\" <> \"a2\".\"email\" or \"accounts\".\"id\" = 2 where \"a2\".\"email\" = ? order by \"e1\" asc) where rownum <= ?', ['test2@example.com', 5], [{\n            e1: 'test1@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test2@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test3@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test4@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test5@example.com',\n            e2: 'test2@example.com'\n          }]);\n          tester('mssql', 'select top (?) [accounts].[email] as [e1], [a2].[email] as [e2] from [accounts] inner join [accounts] as [a2] on [accounts].[email] <> [a2].[email] or [accounts].[id] = 2 where [a2].[email] = ? order by [e1] asc', [5, 'test2@example.com'], [{\n            e1: 'test1@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test2@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test3@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test4@example.com',\n            e2: 'test2@example.com'\n          }, {\n            e1: 'test5@example.com',\n            e2: 'test2@example.com'\n          }]);\n        });\n      });","file":"integration2/query/select/joins.spec.js","skipped":false,"dir":"test"},{"name":"supports cross join without arguments","suites":["Joins"],"updatePoint":{"line":1367,"column":47,"index":53445},"line":1367,"code":"      it('supports cross join without arguments', function () {\n        return knex.select('account_id').from('accounts').crossJoin('test_table_two').orderBy('account_id').testSql(function (tester) {\n          tester('mysql', 'select `account_id` from `accounts` cross join `test_table_two` order by `account_id` asc', [], function (res) {\n            return res.length === 18;\n          });\n          tester('pg', 'select \"account_id\" from \"accounts\" cross join \"test_table_two\" order by \"account_id\" asc', [], function (res) {\n            return res.length === 18;\n          });\n          tester('pg-redshift', 'select \"account_id\" from \"accounts\" cross join \"test_table_two\" order by \"account_id\" asc', [], function (res) {\n            // redshift, not supporting insert...returning, had to fake 6 of these in previous tests\n            return res.length === 12;\n          });\n          tester('oracledb', 'select \"account_id\" from \"accounts\" cross join \"test_table_two\" order by \"account_id\" asc', [], function (res) {\n            return res.length === 18;\n          });\n          tester('sqlite3', 'select `account_id` from `accounts` cross join `test_table_two` order by `account_id` asc', [], function (res) {\n            return res.length === 18;\n          });\n          tester('mssql', 'select [account_id] from [accounts] cross join [test_table_two] order by [account_id] asc', [], function (res) {\n            return res.length === 18;\n          });\n        });\n      });","file":"integration2/query/select/joins.spec.js","skipped":false,"dir":"test"},{"name":"left join with subquery in on clause, #","suites":["Joins"],"updatePoint":{"line":1390,"column":49,"index":54930},"line":1390,"code":"      it('left join with subquery in on clause, #', function () {\n        return knex.select('account_id').from('accounts').leftJoin('test_table_two', j => j.on('accounts.id', '=', knex('test_table_two').select('id').limit(1))).testSql(function (tester) {\n          tester('mysql', 'select `account_id` from `accounts` left join `test_table_two` on `accounts`.`id` = (select `id` from `test_table_two` limit ?)', [1], function (res) {\n            return res.length === 8;\n          });\n          tester('pg', 'select \"account_id\" from \"accounts\" left join \"test_table_two\" on \"accounts\".\"id\" = (select \"id\" from \"test_table_two\" limit ?)', [1], function (res) {\n            return res.length === 8;\n          });\n          tester('pg-redshift', 'select \"account_id\" from \"accounts\" left join \"test_table_two\" on \"accounts\".\"id\" = (select \"id\" from \"test_table_two\" limit ?)', [1], function (res) {\n            return res.length === 8;\n          });\n          tester('oracledb', 'select \"account_id\" from \"accounts\" left join \"test_table_two\" on \"accounts\".\"id\" = (select * from (select \"id\" from \"test_table_two\") where rownum <= ?)', [1], function (res) {\n            return res.length === 8;\n          });\n          tester('sqlite3', 'select `account_id` from `accounts` left join `test_table_two` on `accounts`.`id` = (select `id` from `test_table_two` limit ?)', [1], function (res) {\n            return res.length === 8;\n          });\n          tester('mssql', 'select [account_id] from [accounts] left join [test_table_two] on [accounts].[id] = (select top (?) [id] from [test_table_two])', [1], function (res) {\n            return res.length === 8;\n          });\n        });\n      });","file":"integration2/query/select/joins.spec.js","skipped":false,"dir":"test"},{"name":"supports joins with overlapping column names","suites":["Joins"],"updatePoint":{"line":1412,"column":54,"index":56627},"line":1412,"code":"      it('supports joins with overlapping column names', function () {\n        if (isOracle(knex)) {\n          return this.skip();\n        }\n\n        return knex('accounts as a1').leftJoin('accounts as a2', function () {\n          this.on('a1.email', '<>', 'a2.email');\n        }).orderBy('a2.id', 'asc').select(['a1.email', 'a2.email']).where(knex.raw('a1.id = 1')).options({\n          nestTables: true,\n          rowMode: 'array'\n        }).limit(2).testSql(function (tester) {\n          tester('mysql', 'select `a1`.`email`, `a2`.`email` from `accounts` as `a1` left join `accounts` as `a2` on `a1`.`email` <> `a2`.`email` where a1.id = 1 order by `a2`.`id` asc limit ?', [2], [{\n            a1: {\n              email: 'test1@example.com'\n            },\n            a2: {\n              email: 'test2@example.com'\n            }\n          }, {\n            a1: {\n              email: 'test1@example.com'\n            },\n            a2: {\n              email: 'test3@example.com'\n            }\n          }]);\n          tester('pg', 'select \"a1\".\"email\", \"a2\".\"email\" from \"accounts\" as \"a1\" left join \"accounts\" as \"a2\" on \"a1\".\"email\" <> \"a2\".\"email\" where a1.id = 1 order by \"a2\".\"id\" asc limit ?', [2], [{\n            0: 'test1@example.com',\n            1: 'test2@example.com'\n          }, {\n            0: 'test1@example.com',\n            1: 'test3@example.com'\n          }]);\n          tester('pg-redshift', 'select \"a1\".\"email\", \"a2\".\"email\" from \"accounts\" as \"a1\" left join \"accounts\" as \"a2\" on \"a1\".\"email\" <> \"a2\".\"email\" where a1.id = 1 order by \"a2\".\"id\" asc limit ?', [2], [{\n            0: 'test1@example.com',\n            1: 'test2@example.com'\n          }, {\n            0: 'test1@example.com',\n            1: 'test3@example.com'\n          }]);\n          tester('sqlite3', 'select `a1`.`email`, `a2`.`email` from `accounts` as `a1` left join `accounts` as `a2` on `a1`.`email` <> `a2`.`email` where a1.id = 1 order by `a2`.`id` asc limit ?', [2], [{\n            email: 'test2@example.com'\n          }, {\n            email: 'test3@example.com'\n          }]);\n          tester('mssql', 'select top (?) [a1].[email], [a2].[email] from [accounts] as [a1] left join [accounts] as [a2] on [a1].[email] <> [a2].[email] where a1.id = 1 order by [a2].[id] asc', [2], [{\n            email: ['test1@example.com', 'test2@example.com']\n          }, {\n            email: ['test1@example.com', 'test3@example.com']\n          }]);\n        });\n      });","file":"integration2/query/select/joins.spec.js","skipped":false,"dir":"test"},{"name":"Can use .using()","suites":["Joins"],"updatePoint":{"line":1464,"column":26,"index":59051},"line":1464,"code":"      it('Can use .using()', async function () {\n        if (isMssql(knex)) {\n          return this.skip();\n        }\n\n        const joinName = 'accounts_join_test';\n        await knex.schema.dropTableIfExists(joinName);\n        await knex.schema.createTable(joinName, table => {\n          table.bigint('id');\n          table.string('email');\n          table.integer('testcolumn');\n        });\n        const test3 = await knex('accounts').select().where({\n          email: 'test3@example.com'\n        }).first();\n        await knex(joinName).insert([{\n          id: test3.id,\n          email: 'test3@example.com',\n          testcolumn: 50\n        }, {\n          id: test3.id,\n          email: 'random@email.com',\n          testcolumn: 70\n        }]);\n        const rows = await knex('accounts').join(joinName, builder => builder.using(['id', 'email']));\n        expect(rows.length).to.equal(1);\n        assertNumber(knex, rows[0].testcolumn, 50);\n        const rows2 = await knex('accounts').join(joinName, builder => builder.using(['id'])).orderBy('testcolumn');\n        expect(rows2.length).to.equal(2);\n        assertNumber(knex, rows2[0].testcolumn, 50);\n        assertNumber(knex, rows2[1].testcolumn, 70);\n      });","file":"integration2/query/select/joins.spec.js","skipped":false,"dir":"test"},{"name":"join on json path value","suites":["Joins","json joins"],"updatePoint":{"line":1509,"column":35,"index":60753},"line":1509,"code":"        it('join on json path value', async () => {\n          const result = await knex('cities').select('cities.name as cityName', 'country.name as countryName').join('country', function () {\n            this.onJsonPathEquals('temperature', '$.desc', 'climate', '$.type');\n          });\n          expect(result).to.eql([{\n            cityName: 'Paris',\n            countryName: 'France'\n          }, {\n            cityName: 'Milan',\n            countryName: 'Italy'\n          }]);\n        });","file":"integration2/query/select/joins.spec.js","skipped":false,"dir":"test"},{"name":"Throws an error if used before before \"first\"","suites":["Pluck"],"updatePoint":{"line":29,"column":55,"index":727},"line":29,"code":"      it('Throws an error if used before before \"first\"', async () => {\n        expect(() => {\n          knex(tblName).pluck(colName).first();\n        }).to.throw(Error, 'Cannot chain .first() on \"pluck\" query');\n      });","file":"integration2/query/select/pluck.spec.js","skipped":false,"dir":"test"},{"name":"Throws an error if used before after \"first\"","suites":["Pluck"],"updatePoint":{"line":34,"column":54,"index":949},"line":34,"code":"      it('Throws an error if used before after \"first\"', () => {\n        expect(() => {\n          knex(tblName).first().pluck(colName);\n        }).to.throw(Error, 'Cannot chain .pluck() on \"first\" query');\n      });","file":"integration2/query/select/pluck.spec.js","skipped":false,"dir":"test"},{"name":"runs with no conditions","suites":["Selects"],"updatePoint":{"line":73,"column":33,"index":1634},"line":73,"code":"      it('runs with no conditions', function () {\n        return knex('accounts').select();\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"returns an array of a single column with `pluck`","suites":["Selects"],"updatePoint":{"line":76,"column":58,"index":1761},"line":76,"code":"      it('returns an array of a single column with `pluck`', async () => {\n        return knex.pluck('id').orderBy('id').from('accounts').testSql(function (tester) {\n          tester('mysql', 'select `id` from `accounts` order by `id` asc', [], [1, 2, 3, 4, 5, 6]);\n          tester('pg', 'select \"id\" from \"accounts\" order by \"id\" asc', [], ['1', '2', '3', '4', '5', '6']);\n          tester('pgnative', 'select \"id\" from \"accounts\" order by \"id\" asc', [], ['1', '2', '3', '4', '5', '6']);\n          tester('pg-redshift', 'select \"id\" from \"accounts\" order by \"id\" asc', [], ['1', '2', '3', '4', '5', '6']);\n          tester('sqlite3', 'select `id` from `accounts` order by `id` asc', [], [1, 2, 3, 4, 5, 6]);\n          tester('oracledb', 'select \"id\" from \"accounts\" order by \"id\" asc', [], [1, 2, 3, 4, 5, 6]);\n          tester('mssql', 'select [id] from [accounts] order by [id] asc', [], ['1', '2', '3', '4', '5', '6']);\n        });\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"can pluck a qualified column name, #1619","suites":["Selects"],"updatePoint":{"line":87,"column":50,"index":2700},"line":87,"code":"      it('can pluck a qualified column name, #1619', function () {\n        return knex.pluck('accounts.id').from('accounts').orderBy('accounts.id').testSql(function (tester) {\n          tester('mysql', 'select `accounts`.`id` from `accounts` order by `accounts`.`id` asc', [], [1, 2, 3, 4, 5, 6]);\n          tester('pg', 'select \"accounts\".\"id\" from \"accounts\" order by \"accounts\".\"id\" asc', [], ['1', '2', '3', '4', '5', '6']);\n          tester('pgnative', 'select \"accounts\".\"id\" from \"accounts\" order by \"accounts\".\"id\" asc', [], ['1', '2', '3', '4', '5', '6']);\n          tester('pg-redshift', 'select \"accounts\".\"id\" from \"accounts\" order by \"accounts\".\"id\" asc', [], ['1', '2', '3', '4', '5', '6']);\n          tester('sqlite3', 'select `accounts`.`id` from `accounts` order by `accounts`.`id` asc', [], [1, 2, 3, 4, 5, 6]);\n          tester('oracledb', 'select \"accounts\".\"id\" from \"accounts\" order by \"accounts\".\"id\" asc', [], [1, 2, 3, 4, 5, 6]);\n          tester('mssql', 'select [accounts].[id] from [accounts] order by [accounts].[id] asc', [], ['1', '2', '3', '4', '5', '6']);\n        });\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"starts selecting at offset","suites":["Selects"],"updatePoint":{"line":98,"column":36,"index":3797},"line":98,"code":"      it('starts selecting at offset', function () {\n        return knex.pluck('id').orderBy('id').from('accounts').offset(2).testSql(function (tester) {\n          tester('mysql', 'select `id` from `accounts` order by `id` asc limit 18446744073709551615 offset ?', [2], [3, 4, 5, 6]);\n          tester('pg', 'select \"id\" from \"accounts\" order by \"id\" asc offset ?', [2], ['3', '4', '5', '6']);\n          tester('pgnative', 'select \"id\" from \"accounts\" order by \"id\" asc offset ?', [2], ['3', '4', '5', '6']);\n          tester('pg-redshift', 'select \"id\" from \"accounts\" order by \"id\" asc offset ?', [2], ['3', '4', '5', '6']);\n          tester('sqlite3', 'select `id` from `accounts` order by `id` asc limit ? offset ?', [-1, 2], [3, 4, 5, 6]);\n          tester('oracledb', 'select * from (select row_.*, ROWNUM rownum_ from (select \"id\" from \"accounts\" order by \"id\" asc) row_ where rownum <= ?) where rownum_ > ?', [10000000000002, 2], [3, 4, 5, 6]);\n          tester('mssql', 'select [id] from [accounts] order by [id] asc offset ? rows', [2], ['3', '4', '5', '6']);\n        });\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"#4335 - should throw an error when negative offset provided","suites":["Selects"],"updatePoint":{"line":109,"column":69,"index":4922},"line":109,"code":"      it('#4335 - should throw an error when negative offset provided', function (ok) {\n        try {\n          knex.from('accounts').limit(20).offset(-20);\n          throw new Error('no error was thrown for negative offset!');\n        } catch (error) {\n          if (error.message === 'A non-negative integer must be provided to offset.') {\n            ok();\n          } else {\n            throw error;\n          }\n        }\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"#4199 - adheres to hint comments","suites":["Selects"],"updatePoint":{"line":121,"column":42,"index":5331},"line":121,"code":"      it('#4199 - adheres to hint comments', async function () {\n        const expectedErrors = {\n          mysql: {\n            code: 'ER_QUERY_TIMEOUT',\n            errno: 3024,\n            sqlMessage: 'Query execution was interrupted, maximum statement execution time exceeded'\n          },\n          mysql2: {\n            errno: 3024,\n            sqlMessage: 'Query execution was interrupted, maximum statement execution time exceeded'\n          }\n        };\n\n        if (!expectedErrors[knex.client.driverName]) {\n          return this.skip();\n        }\n\n        const baseQuery = knex('accounts').select('id', knex.raw('sleep(0.1)')).limit(2);\n        await expect(baseQuery.clone()).to.eventually.be.fulfilled.and.to.have.lengthOf(2);\n        await expect(baseQuery.clone().hintComment('max_execution_time(10)')).to.eventually.be.rejected.and.to.deep.include(expectedErrors[knex.client.driverName]);\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"#4199 - ignores invalid hint comments","suites":["Selects"],"updatePoint":{"line":142,"column":47,"index":6253},"line":142,"code":"      it('#4199 - ignores invalid hint comments', async function () {\n        return knex.select('id').orderBy('id').from('accounts').hintComment('invalid()').testSql(function (tester) {\n          tester('mysql', 'select /*+ invalid() */ `id` from `accounts` order by `id` asc', [], [{\n            id: 1\n          }, {\n            id: 2\n          }, {\n            id: 3\n          }, {\n            id: 4\n          }, {\n            id: 5\n          }, {\n            id: 6\n          }]);\n          tester('pg', 'select /*+ invalid() */ \"id\" from \"accounts\" order by \"id\" asc', [], [{\n            id: '1'\n          }, {\n            id: '2'\n          }, {\n            id: '3'\n          }, {\n            id: '4'\n          }, {\n            id: '5'\n          }, {\n            id: '6'\n          }]);\n          tester('pgnative', 'select /*+ invalid() */ \"id\" from \"accounts\" order by \"id\" asc', [], [{\n            id: '1'\n          }, {\n            id: '2'\n          }, {\n            id: '3'\n          }, {\n            id: '4'\n          }, {\n            id: '5'\n          }, {\n            id: '6'\n          }]);\n          tester('pg-redshift', 'select /*+ invalid() */ \"id\" from \"accounts\" order by \"id\" asc', [], [{\n            id: '1'\n          }, {\n            id: '2'\n          }, {\n            id: '3'\n          }, {\n            id: '4'\n          }, {\n            id: '5'\n          }, {\n            id: '6'\n          }]);\n          tester('sqlite3', 'select /*+ invalid() */ `id` from `accounts` order by `id` asc', [], [{\n            id: 1\n          }, {\n            id: 2\n          }, {\n            id: 3\n          }, {\n            id: 4\n          }, {\n            id: 5\n          }, {\n            id: 6\n          }]);\n          tester('oracledb', 'select /*+ invalid() */ \"id\" from \"accounts\" order by \"id\" asc', [], [{\n            id: 1\n          }, {\n            id: 2\n          }, {\n            id: 3\n          }, {\n            id: 4\n          }, {\n            id: 5\n          }, {\n            id: 6\n          }]);\n          tester('mssql', 'select /*+ invalid() */ [id] from [accounts] order by [id] asc', [], [{\n            id: '1'\n          }, {\n            id: '2'\n          }, {\n            id: '3'\n          }, {\n            id: '4'\n          }, {\n            id: '5'\n          }, {\n            id: '6'\n          }]);\n        });\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"returns a single entry with first","suites":["Selects"],"updatePoint":{"line":237,"column":43,"index":8596},"line":237,"code":"      it('returns a single entry with first', function () {\n        return knex.first('id', 'first_name').orderBy('id').from('accounts').testSql(function (tester) {\n          tester('mysql', 'select `id`, `first_name` from `accounts` order by `id` asc limit ?', [1], {\n            id: 1,\n            first_name: 'Test'\n          });\n          tester('pg', 'select \"id\", \"first_name\" from \"accounts\" order by \"id\" asc limit ?', [1], {\n            id: '1',\n            first_name: 'Test'\n          });\n          tester('pgnative', 'select \"id\", \"first_name\" from \"accounts\" order by \"id\" asc limit ?', [1], {\n            id: '1',\n            first_name: 'Test'\n          });\n          tester('pg-redshift', 'select \"id\", \"first_name\" from \"accounts\" order by \"id\" asc limit ?', [1], {\n            id: '1',\n            first_name: 'Test'\n          });\n          tester('sqlite3', 'select `id`, `first_name` from `accounts` order by `id` asc limit ?', [1], {\n            id: 1,\n            first_name: 'Test'\n          });\n          tester('oracledb', 'select * from (select \"id\", \"first_name\" from \"accounts\" order by \"id\" asc) where rownum <= ?', [1], {\n            id: 1,\n            first_name: 'Test'\n          });\n          tester('mssql', 'select top (?) [id], [first_name] from [accounts] order by [id] asc', [1], {\n            id: '1',\n            first_name: 'Test'\n          });\n        });\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"allows you to stream","suites":["Selects"],"updatePoint":{"line":269,"column":30,"index":9991},"line":269,"code":"      it('allows you to stream', function () {\n        if (isPgNative(knex)) {\n          return this.skip();\n        }\n\n        let count = 0;\n        return knex('accounts').stream(function (rowStream) {\n          rowStream.on('data', function () {\n            count++;\n          });\n        }).then(function () {\n          assert(count === 6, 'Six rows should have been streamed');\n        });\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"returns a stream if not passed a function","suites":["Selects"],"updatePoint":{"line":283,"column":51,"index":10418},"line":283,"code":"      it('returns a stream if not passed a function', function (done) {\n        if (isPgNative(knex)) {\n          return this.skip();\n        }\n\n        let count = 0;\n        const stream = knex('accounts').stream();\n        stream.on('data', function () {\n          count++;\n          if (count === 6) done();\n        });\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"allows you to stream with mysql dialect options","suites":["Selects"],"updatePoint":{"line":295,"column":57,"index":10758},"line":295,"code":"      it('allows you to stream with mysql dialect options', function () {\n        if (!isMysql(knex)) {\n          return this.skip();\n        }\n\n        const rows = [];\n        return knex('accounts').options({\n          typeCast(field, next) {\n            let val;\n\n            if (field.type === 'VAR_STRING') {\n              val = field.string();\n              return val == null ? val : val.toUpperCase();\n            }\n\n            return next();\n          }\n\n        }).stream(function (rowStream) {\n          rowStream.on('data', function (row) {\n            rows.push(row);\n          });\n        }).then(function () {\n          expect(rows).to.have.lengthOf(6);\n          rows.forEach(row => {\n            ['first_name', 'last_name', 'email'].forEach(field => expect(row[field]).to.equal(row[field].toUpperCase()));\n          });\n        });\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"emits error on the stream, if not passed a function, and connecting fails","suites":["Selects"],"updatePoint":{"line":324,"column":83,"index":11645},"line":324,"code":"      it('emits error on the stream, if not passed a function, and connecting fails', function () {\n        const expected = new Error();\n        const original = Runner.prototype.ensureConnection;\n\n        Runner.prototype.ensureConnection = function () {\n          return Promise.reject(expected);\n        };\n\n        const restore = () => {\n          Runner.prototype.ensureConnection = original;\n        };\n\n        const promise = new Promise((resolve, reject) => {\n          const timeout = setTimeout(() => {\n            reject(new Error('Timeout'));\n          }, 5000);\n          const stream = knex('accounts').stream();\n          stream.on('error', function (actual) {\n            clearTimeout(timeout);\n\n            if (actual === expected) {\n              resolve();\n            } else {\n              reject(new Error('Stream emitted unexpected error'));\n            }\n          });\n        });\n        promise.then(restore, restore);\n        return promise;\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"emits error on the stream, if not passed a function, and query fails","suites":["Selects"],"updatePoint":{"line":354,"column":78,"index":12622},"line":354,"code":"      it('emits error on the stream, if not passed a function, and query fails', function (done) {\n        const stream = knex('accounts').select('invalid_field').stream();\n        stream.on('error', function (err) {\n          assert(err instanceof Error);\n          done();\n        });\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"emits error if not passed a function and the query has wrong bindings","suites":["Selects"],"updatePoint":{"line":361,"column":79,"index":12920},"line":361,"code":"      it('emits error if not passed a function and the query has wrong bindings', function (done) {\n        const stream = knex('accounts').whereRaw('id = ? and first_name = ?', ['2']).stream();\n        stream.on('error', function (err) {\n          assert(err instanceof Error);\n          done();\n        });\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"properly escapes postgres queries on streaming","suites":["Selects"],"updatePoint":{"line":368,"column":56,"index":13216},"line":368,"code":"      it('properly escapes postgres queries on streaming', async function () {\n        const result = await knex('accounts').select();\n        let count = 0;\n        await knex('accounts').where('id', result[0].id).stream(function (rowStream) {\n          rowStream.on('data', function () {\n            count++;\n          });\n        });\n        assert(count === 1, 'One row should have been streamed');\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"throws errors on the asCallback if uncaught in the last block","suites":["Selects"],"updatePoint":{"line":378,"column":71,"index":13644},"line":378,"code":"      it('throws errors on the asCallback if uncaught in the last block', function (ok) {\n        const listeners = process.listeners('uncaughtException');\n        process.removeAllListeners('uncaughtException');\n        process.on('uncaughtException', function () {\n          process.removeAllListeners('uncaughtException');\n\n          for (let i = 0, l = listeners.length; i < l; i++) {\n            process.on('uncaughtException', listeners[i]);\n          }\n\n          ok();\n        });\n        knex('accounts').select().asCallback(function () {\n          this.undefinedVar.test;\n        });\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"uses \"orderBy\"","suites":["Selects"],"updatePoint":{"line":394,"column":24,"index":14201},"line":394,"code":"      it('uses \"orderBy\"', function () {\n        return knex('accounts').pluck('id').orderBy('id', 'desc').testSql(function (tester) {\n          tester('oracledb', 'select \"id\" from \"accounts\" order by \"id\" desc', [], [6, 5, 4, 3, 2, 1]);\n          tester('mssql', 'select [id] from [accounts] order by [id] desc', [], ['6', '5', '4', '3', '2', '1']);\n        });\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"order by with null","suites":["Selects"],"updatePoint":{"line":400,"column":28,"index":14579},"line":400,"code":"      it('order by with null', async () => {\n        await knex.schema.dropTableIfExists('OrderByNullTest').createTable('OrderByNullTest', function (table) {\n          table.increments('id').primary();\n          table.string('null_col').nullable().defaultTo(null); // string col to have some order of records with nulls\n\n          table.string('string_col');\n        });\n        await knex('OrderByNullTest').insert([{\n          null_col: 'test',\n          string_col: 'a'\n        }, {\n          null_col: null,\n          string_col: 'b'\n        }, {\n          null_col: 'test2',\n          string_col: 'c'\n        }, {\n          null_col: null,\n          string_col: 'd'\n        }]);\n        await knex('OrderByNullTest').pluck('id').orderBy([{\n          column: 'null_col',\n          order: 'asc',\n          nulls: 'first'\n        }, {\n          column: 'string_col'\n        }]).testSql(function (tester) {\n          tester('mysql', 'select `id` from `OrderByNullTest` order by (`null_col` is not null) asc, `string_col` asc', [], [2, 4, 1, 3]);\n          tester('pg', 'select \"id\" from \"OrderByNullTest\" order by \"null_col\" asc nulls first, \"string_col\" asc', [], [2, 4, 1, 3]);\n          tester('pgnative', 'select \"id\" from \"OrderByNullTest\" order by \"null_col\" asc nulls first, \"string_col\" asc', [], [2, 4, 1, 3]);\n          tester('pg-redshift', 'select \"id\" from \"OrderByNullTest\" order by \"null_col\" asc nulls first, \"string_col\" asc', [], ['2', '4', '1', '3']);\n          tester('sqlite3', 'select `id` from `OrderByNullTest` order by (`null_col` is not null) asc, `string_col` asc', [], [2, 4, 1, 3]);\n          tester('oracledb', 'select \"id\" from \"OrderByNullTest\" order by \"null_col\" asc nulls first, \"string_col\" asc', [], [2, 4, 1, 3]);\n          tester('mssql', 'select [id] from [OrderByNullTest] order by IIF([null_col] is null,0,1) asc, [string_col] asc', [], [2, 4, 1, 3]);\n        });\n        await knex('OrderByNullTest').pluck('id').orderBy([{\n          column: 'null_col',\n          order: 'asc',\n          nulls: 'last'\n        }, {\n          column: 'string_col'\n        }]).testSql(function (tester) {\n          tester('mysql', 'select `id` from `OrderByNullTest` order by (`null_col` is null) asc, `string_col` asc', [], [1, 3, 2, 4]);\n          tester('pg', 'select \"id\" from \"OrderByNullTest\" order by \"null_col\" asc nulls last, \"string_col\" asc', [], [1, 3, 2, 4]);\n          tester('pgnative', 'select \"id\" from \"OrderByNullTest\" order by \"null_col\" asc nulls last, \"string_col\" asc', [], [1, 3, 2, 4]);\n          tester('pg-redshift', 'select \"id\" from \"OrderByNullTest\" order by \"null_col\" asc nulls last, \"string_col\" asc', [], ['1', '3', '2', '4']);\n          tester('sqlite3', 'select `id` from `OrderByNullTest` order by (`null_col` is null) asc, `string_col` asc', [], [1, 3, 2, 4]);\n          tester('oracledb', 'select \"id\" from \"OrderByNullTest\" order by \"null_col\" asc nulls last, \"string_col\" asc', [], [1, 3, 2, 4]);\n          tester('mssql', 'select [id] from [OrderByNullTest] order by IIF([null_col] is null,1,0) asc, [string_col] asc', [], [1, 3, 2, 4]);\n        });\n        await knex.schema.dropTable('OrderByNullTest');\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"#1276 - Dates NULL should be returned as NULL, not as new Date(null)","suites":["Selects"],"updatePoint":{"line":452,"column":78,"index":17812},"line":452,"code":"      it('#1276 - Dates NULL should be returned as NULL, not as new Date(null)', function () {\n        return knex.schema.dropTableIfExists('DatesTest').createTable('DatesTest', function (table) {\n          table.increments('id').primary();\n          table.dateTime('dateTimeCol');\n          table.timestamp('timeStampCol').nullable().defaultTo(null); // MySQL defaults TIMESTAMP columns to current timestamp\n\n          table.date('dateCol');\n          table.time('timeCol');\n        }).then(function () {\n          return knex('DatesTest').insert([{\n            dateTimeCol: null,\n            timeStampCol: null,\n            dateCol: null,\n            timeCol: null\n          }]);\n        }).then(function () {\n          return knex('DatesTest').select();\n        }).then(function (rows) {\n          expect(rows[0].dateTimeCol).to.equal(null);\n          expect(rows[0].timeStampCol).to.equal(null);\n          expect(rows[0].dateCol).to.equal(null);\n          expect(rows[0].timeCol).to.equal(null);\n        });\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"has a \"distinct\" clause","suites":["Selects"],"updatePoint":{"line":476,"column":33,"index":18789},"line":476,"code":"      it('has a \"distinct\" clause', function () {\n        return Promise.all([knex('accounts').select().distinct('email').where('logins', 2).orderBy('email'), knex('accounts').distinct('email').select().orderBy('email')]);\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"supports \"distinct on\"","suites":["Selects"],"updatePoint":{"line":479,"column":32,"index":19021},"line":479,"code":"      it('supports \"distinct on\"', async function () {\n        const builder = knex('accounts').select('email', 'logins').distinctOn('id').orderBy('id');\n\n        if (!isPgBased(knex)) {\n          let error;\n\n          try {\n            await builder;\n          } catch (e) {\n            error = e;\n          }\n\n          expect(error.message).to.eql('.distinctOn() is currently only supported on PostgreSQL');\n          return;\n        }\n\n        return builder.testSql(function (tester) {\n          tester('pg', 'select distinct on (\"id\") \"email\", \"logins\" from \"accounts\" order by \"id\" asc', [], [{\n            email: 'test1@example.com',\n            logins: 1\n          }, {\n            email: 'test2@example.com',\n            logins: 1\n          }, {\n            email: 'test3@example.com',\n            logins: 2\n          }, {\n            email: 'test4@example.com',\n            logins: 2\n          }, {\n            email: 'test5@example.com',\n            logins: 2\n          }, {\n            email: 'test6@example.com',\n            logins: 2\n          }]);\n          tester('pgnative', 'select distinct on (\"id\") \"email\", \"logins\" from \"accounts\" order by \"id\" asc', [], [{\n            email: 'test1@example.com',\n            logins: 1\n          }, {\n            email: 'test2@example.com',\n            logins: 1\n          }, {\n            email: 'test3@example.com',\n            logins: 2\n          }, {\n            email: 'test4@example.com',\n            logins: 2\n          }, {\n            email: 'test5@example.com',\n            logins: 2\n          }, {\n            email: 'test6@example.com',\n            logins: 2\n          }]);\n        });\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"supports recursive CTEs","suites":["Selects","recursive CTE support"],"updatePoint":{"line":562,"column":35,"index":21542},"line":562,"code":"        it('supports recursive CTEs', async function () {\n          const results = await knex.withRecursive('family', ['name', 'parentName'], qb => {\n            qb.select('name', 'parentName').from('rcte').where({\n              name: 'grandchild'\n            }).unionAll(qb => qb.select('rcte.name', 'rcte.parentName').from('rcte').join('family', knex.ref('family.parentName'), knex.ref('rcte.name')));\n          }).select('name').from('family');\n          const names = results.map(({\n            name\n          }) => name);\n          expect(names).to.have.length('parent child grandchild'.split(' ').length);\n          expect(names).to.contain('parent');\n          expect(names).not.to.contain('nope');\n        });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"always returns the response object from raw","suites":["Selects","recursive CTE support"],"updatePoint":{"line":576,"column":53,"index":22289},"line":576,"code":"      it('always returns the response object from raw', function () {\n        if (isPostgreSQL(knex)) {\n          return knex.raw('select id from accounts').then(function (resp) {\n            assert(Array.isArray(resp.rows) === true);\n          });\n        }\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"properly escapes identifiers, #737","suites":["Selects","recursive CTE support"],"updatePoint":{"line":583,"column":44,"index":22549},"line":583,"code":"      it('properly escapes identifiers, #737', function () {\n        if (isPostgreSQL(knex)) {\n          const query = knex.select('id\",\"name').from('test').toSQL();\n          assert(query.sql === 'select \"id\"\",\"\"name\" from \"test\"');\n        }\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"knex.ref() as column in .select()","suites":["Selects","recursive CTE support"],"updatePoint":{"line":589,"column":43,"index":22802},"line":589,"code":"      it('knex.ref() as column in .select()', async function () {\n        const result = await knex('accounts').select();\n        const row = await knex('accounts').select([knex.ref('accounts.id').as('userid')]).select(['accounts.id']).where(knex.ref('accounts.id'), result[0].id).first();\n        expect(String(row.userid)).to.equal(String(result[0].id));\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"select forUpdate().first() bug in oracle (--------- TODO: FIX)","suites":["Selects","recursive CTE support"],"line":594,"code":"      it.skip('select forUpdate().first() bug in oracle (--------- TODO: FIX)', function () {","file":"integration2/query/select/selects.spec.js","skipped":true,"dir":"test"},{"name":"select for update locks selected row","suites":["Selects","recursive CTE support"],"updatePoint":{"line":597,"column":46,"index":23344},"line":597,"code":"      it('select for update locks selected row', function () {\n        if (isSQLite(knex)) {\n          return this.skip();\n        }\n\n        return knex('test_default_table').insert({\n          string: 'making sure there is a row to lock'\n        }).then(() => {\n          return knex.transaction(trx => {\n            // select all from test table and lock\n            return trx('test_default_table').forUpdate().then(res => {\n              // try to select stuff from table in other connection should just hang...\n              return knex('test_default_table').forUpdate().timeout(100);\n            });\n          }).then(res => {\n            expect('Second query should have timed out').to.be.false;\n          }).catch(err => {\n            expect(err.message).to.be.contain('Defined query timeout of 100ms exceeded when running query');\n          });\n        });\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"select for update locks only some tables, #2834","suites":["Selects","recursive CTE support"],"updatePoint":{"line":618,"column":57,"index":24232},"line":618,"code":"      it('select for update locks only some tables, #2834', function () {\n        if (!isPostgreSQL(knex)) {\n          return this.skip();\n        }\n\n        return knex('test_default_table').insert({\n          string: 'making sure there is a row to lock',\n          tinyint: 1\n        }).then(() => {\n          return knex('test_default_table2').insert({\n            string: 'making sure there is a row to lock',\n            tinyint: 1\n          }).then(() => {\n            return knex.transaction(trx => {\n              // select all from two test tables and lock only one table\n              return trx('test_default_table').innerJoin('test_default_table2', 'test_default_table.tinyint', 'test_default_table2.tinyint').forUpdate('test_default_table').then(res => {\n                // try to select stuff from unlocked table should not hang...\n                return knex('test_default_table2').forUpdate().timeout(150);\n              }).then(res => {\n                // try to select stuff from table in other connection should just hang...\n                return knex('test_default_table').forUpdate().timeout(100);\n              });\n            }).then(res => {\n              expect('Second query should have timed out').to.be.false;\n            }).catch(err => {\n              expect(err.message).to.be.contain('Defined query timeout of 100ms exceeded when running query');\n            });\n          });\n        });\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"select for no key update doesnt stop other transactions from inserting into tables that have a foreign key relationship","suites":["Selects","recursive CTE support"],"updatePoint":{"line":648,"column":129,"index":25736},"line":648,"code":"      it('select for no key update doesnt stop other transactions from inserting into tables that have a foreign key relationship', async function () {\n        if (!isPostgreSQL(knex)) {\n          return this.skip();\n        }\n\n        await createParentAndChildTables(knex);\n        return knex('parent').insert({\n          id: 1\n        }).then(() => {\n          return knex('child').insert({\n            id: 1,\n            parent_id: 1\n          }).then(() => {\n            return knex.transaction(trx => {\n              // select all from the parent table in the for no key update mode\n              return trx('parent').forNoKeyUpdate().then(res => {\n                // Insert should into the child table not hang\n                return knex('child').insert({\n                  id: 2,\n                  parent_id: 1\n                }).timeout(150);\n              });\n            });\n          });\n        });\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"select for key share blocks select for update but not select for no key update","suites":["Selects","recursive CTE support"],"updatePoint":{"line":674,"column":88,"index":26619},"line":674,"code":"      it('select for key share blocks select for update but not select for no key update', async function () {\n        if (!isPostgreSQL(knex)) {\n          return this.skip();\n        }\n\n        return knex('test_default_table').insert({\n          string: 'making sure there is a row to lock'\n        }).then(() => {\n          return knex.transaction(trx => {\n            // select all from test table and lock\n            return trx('test_default_table').forKeyShare().then(res => {\n              // trying to select stuff from table in other connection should succeed with for no key update\n              return knex('test_default_table').forNoKeyUpdate().timeout(200);\n            }).then(res => {\n              // trying to select stuff from table in other connection should hang with for update\n              return knex('test_default_table').forUpdate().timeout(100);\n            });\n          }).then(res => {\n            expect('Second query should have timed out').to.be.false;\n          }).catch(err => {\n            expect(err.message).to.be.contain('Defined query timeout of 100ms exceeded when running query');\n          });\n        });\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"select for share prevents updating in other transaction","suites":["Selects","recursive CTE support"],"updatePoint":{"line":698,"column":65,"index":27756},"line":698,"code":"      it('select for share prevents updating in other transaction', function () {\n        // Query cancellation is not yet implemented for CockroachDB\n        if (isSQLite(knex) || isOracle(knex) || isCockroachDB(knex)) {\n          return this.skip();\n        }\n\n        return knex('test_default_table').insert({\n          string: 'making sure there is a row to lock'\n        }).then(() => {\n          return knex.transaction(trx => {\n            // select all from test table and lock\n            return trx('test_default_table').forShare().then(res => {\n              // try to update row that was selected for share should just hang...\n              return knex.transaction(trx2 => {\n                return trx2('test_default_table').update({\n                  string: 'foo'\n                }).timeout(100);\n              });\n            });\n          }).then(res => {\n            expect('Second query should have timed out').to.be.false;\n          }).catch(err => {\n            // mssql fails because it tries to rollback at the same time when update query is running\n            // hopefully for share really works though...\n            if (isMssql(knex)) {\n              expect(err.message).to.be.contain(\"Can't rollback transaction. There is a request in progress\");\n            } else {\n              expect(err.message).to.be.contain('Defined query timeout of 100ms exceeded when running query');\n            }\n          });\n        });\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"forUpdate().skipLocked() with order by should return the first non-locked row","suites":["Selects","recursive CTE support"],"updatePoint":{"line":730,"column":87,"index":29235},"line":730,"code":"      it('forUpdate().skipLocked() with order by should return the first non-locked row', async function () {\n        // Note: this test doesn't work properly on MySQL - see https://bugs.mysql.com/bug.php?id=67745\n        if (!isPostgreSQL(knex)) {\n          return this.skip();\n        }\n\n        const rowName = 'row for skipLocked() test #1';\n        await knex('test_default_table').delete().where({\n          string: rowName\n        });\n        await knex('test_default_table').insert([{\n          string: rowName,\n          tinyint: 1\n        }, {\n          string: rowName,\n          tinyint: 2\n        }]);\n        const res = await knex.transaction(async trx => {\n          // lock the first row in the test\n          await trx('test_default_table').where({\n            string: rowName\n          }).orderBy('tinyint', 'asc').forUpdate().first(); // try to lock the next available row from outside of the transaction\n\n          return await knex('test_default_table').where({\n            string: rowName\n          }).orderBy('tinyint', 'asc').forUpdate().skipLocked().first();\n        }); // assert that we got the second row because the first one was locked\n\n        expect(res.tinyint).to.equal(2);\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"forUpdate().skipLocked() should return an empty set when all rows are locked","suites":["Selects","recursive CTE support"],"updatePoint":{"line":760,"column":86,"index":30453},"line":760,"code":"      it('forUpdate().skipLocked() should return an empty set when all rows are locked', async function () {\n        if (!isPostgreSQL(knex) && !isMysql(knex)) {\n          return this.skip();\n        }\n\n        const rowName = 'row for skipLocked() test #2';\n        await knex('test_default_table').delete().where({\n          string: rowName\n        });\n        await knex('test_default_table').insert([{\n          string: rowName,\n          tinyint: 1\n        }, {\n          string: rowName,\n          tinyint: 2\n        }]);\n        const res = await knex.transaction(async trx => {\n          // lock all of the test rows\n          await trx('test_default_table').where({\n            string: rowName\n          }).forUpdate(); // try to aquire the lock on one more row (which isn't available) from another transaction\n\n          return await knex('test_default_table').where({\n            string: rowName\n          }).forUpdate().skipLocked().first();\n        });\n        expect(res).to.be.undefined;\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"forUpdate().noWait() should throw an error immediately when a row is locked","suites":["Selects","recursive CTE support"],"updatePoint":{"line":788,"column":85,"index":31465},"line":788,"code":"      it('forUpdate().noWait() should throw an error immediately when a row is locked', async function () {\n        if (!isPostgreSQL(knex) && !isMysql(knex)) {\n          return this.skip();\n        }\n\n        const rowName = 'row for noWait() test';\n        await knex('test_default_table').delete().where({\n          string: rowName\n        });\n        await knex('test_default_table').insert([{\n          string: rowName,\n          tinyint: 1\n        }, {\n          string: rowName,\n          tinyint: 2\n        }]);\n\n        try {\n          await knex.transaction(async trx => {\n            // select and lock the first row from this test\n            // note: MySQL may lock both rows depending on how the results are fetched\n            await trx('test_default_table').where({\n              string: rowName\n            }).orderBy('tinyint', 'asc').forUpdate().first(); // try to lock it again (it should fail here)\n\n            await knex('test_default_table').where({\n              string: rowName\n            }).orderBy('tinyint', 'asc').forUpdate().noWait().first();\n          }); // fail the test if the query finishes with no errors\n\n          throw new Error('The query should have been cancelled when trying to select a locked row with .noWait()');\n        } catch (err) {\n          // check if we got the correct error from each db\n          if (isPostgreSQL(knex)) {\n            expect(err.message).to.contain('could not obtain lock on row');\n          } else if (isMysql(knex)) {\n            // mysql\n            expect(err.message).to.contain('lock(s) could not be acquired immediately'); // mariadb\n            // TODO: detect if test is being run on mysql or mariadb to check for the correct error message\n            // expect(err.message).to.contain('Lock wait timeout exceeded');\n          } else {\n            // unsupported database\n            throw err;\n          }\n        }\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"select from subquery","suites":["Selects","recursive CTE support"],"updatePoint":{"line":834,"column":30,"index":33321},"line":834,"code":"      it('select from subquery', async function () {\n        const result = await knex('accounts').select().orderBy('id');\n        const subquery = knex.from('accounts').whereBetween('id', [result[0].id, result[2].id]);\n        return knex.pluck('id').orderBy('id').from(subquery).then(rows => {\n          expect(knex.client.driverName).to.oneOf(['sqlite3', 'oracledb', 'cockroachdb', 'better-sqlite3']);\n\n          if (knex.client.driverName !== 'cockroachdb') {\n            assertNumberArrayStrict(knex, rows, [result[0].id, result[1].id, result[2].id]);\n          } else {\n            expect(rows.length).to.equal(3);\n          }\n        }, e => {\n          if (isMysql(knex)) {\n            expect(e.errno).to.equal(1248);\n          } else if (isPostgreSQL(knex)) {\n            expect(e.message).to.contain('must have an alias');\n          } else if (isMssql(knex)) {\n            expect(e.message).to.contain(\"Incorrect syntax near the keyword 'order'\");\n          } else {\n            throw e;\n          }\n        });\n      });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"with","suites":["Selects","\"with\" tests"],"updatePoint":{"line":866,"column":16,"index":34657},"line":866,"code":"        it('with', async () => {\n          const withQuery = await knex.with('t', knex('with_table')).from('t').first();\n          assertNumber(knex, withQuery.test, 1);\n        });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"with materialized","suites":["Selects","\"with\" tests"],"updatePoint":{"line":870,"column":29,"index":34852},"line":870,"code":"        it('with materialized', async function () {\n          if (!isPostgreSQL(knex) && !isSQLite(knex)) {\n            return this.skip();\n          }\n\n          const materialized = await knex('t').withMaterialized('t', knex('with_table')).first();\n          assertNumber(knex, materialized.test, 1);\n        });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"with not materialized","suites":["Selects","\"with\" tests"],"updatePoint":{"line":878,"column":33,"index":35171},"line":878,"code":"        it('with not materialized', async function () {\n          if (!isPostgreSQL(knex) && !isSQLite(knex)) {\n            return this.skip();\n          }\n\n          const notMaterialized = await knex('t').withNotMaterialized('t', knex('with_table')).first();\n          assertNumber(knex, notMaterialized.test, 1);\n        });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"json extract","suites":["Selects","json selections"],"updatePoint":{"line":896,"column":24,"index":35800},"line":896,"code":"        it('json extract', async () => {\n          const res = await knex.jsonExtract('descriptions', '$.short', 'shortDescription').from('cities');\n          expect(res).to.eql([{\n            shortDescription: 'beautiful city'\n          }, {\n            shortDescription: 'large city'\n          }, {\n            shortDescription: 'cold city'\n          }]);\n        });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"json multiple extract","suites":["Selects","json selections"],"updatePoint":{"line":906,"column":33,"index":36179},"line":906,"code":"        it('json multiple extract', async () => {\n          const res = await knex.jsonExtract([['descriptions', '$.short', 'shortDescription'], ['population', '$.current.value', 'currentPop'], ['statistics', '$.roads.min', 'minRoads'], ['statistics', '$.hotYears[0]', 'firstHotYear']]).from('cities');\n          assertJsonEquals([res[0], res[1]], [{\n            shortDescription: 'beautiful city',\n            currentPop: 10000000,\n            minRoads: 1234,\n            firstHotYear: null\n          }, {\n            shortDescription: 'large city',\n            currentPop: 1500000,\n            minRoads: 1455,\n            firstHotYear: 2012\n          }]);\n        });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"json set","suites":["Selects","json selections"],"updatePoint":{"line":920,"column":20,"index":36836},"line":920,"code":"        it('json set', async function () {\n          // jsonSet is only for Oracle21c\n          if (isOracle(knex)) {\n            this.skip();\n          }\n\n          const res = await knex.jsonSet('population', '$.minMax.max', '999999999', 'maxUpdated').from('cities');\n          assertJsonEquals([res[0].maxUpdated, res[1].maxUpdated], [{\n            current: {\n              value: 10000000\n            },\n            minMax: {\n              min: 50000,\n              max: '999999999'\n            }\n          }, {\n            current: {\n              value: 1500000\n            },\n            minMax: {\n              min: 44000,\n              max: '999999999'\n            }\n          }]);\n        });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"json insert","suites":["Selects","json selections"],"updatePoint":{"line":945,"column":23,"index":37542},"line":945,"code":"        it('json insert', async function () {\n          // jsonInsert is only for Oracle21c\n          if (isOracle(knex)) {\n            this.skip();\n          }\n\n          const res = await knex.jsonInsert('population', '$.year2021', '747477', 'popIn2021Added').from('cities');\n          assertJsonEquals([res[0].popIn2021Added, res[1].popIn2021Added], [{\n            current: {\n              value: 10000000\n            },\n            minMax: {\n              min: 50000,\n              max: 12000000\n            },\n            year2021: '747477'\n          }, {\n            current: {\n              value: 1500000\n            },\n            minMax: {\n              min: 44000,\n              max: 1200000\n            },\n            year2021: '747477'\n          }]);\n        });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"json remove","suites":["Selects","json selections"],"updatePoint":{"line":972,"column":23,"index":38318},"line":972,"code":"        it('json remove', async function () {\n          // jsonRemove is only for Oracle21c\n          if (isOracle(knex)) {\n            this.skip();\n          }\n\n          const res = await knex.jsonRemove('population', '$.minMax.min', 'popMinRemoved').from('cities');\n          assertJsonEquals([res[0].popMinRemoved, res[1].popMinRemoved], [{\n            current: {\n              value: 10000000\n            },\n            minMax: {\n              max: 12000000\n            }\n          }, {\n            current: {\n              value: 1500000\n            },\n            minMax: {\n              max: 1200000\n            }\n          }]);\n        });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"json insert then extract","suites":["Selects","json selections"],"updatePoint":{"line":995,"column":36,"index":38980},"line":995,"code":"        it('json insert then extract', async function () {\n          if (isOracle(knex)) {\n            this.skip();\n          }\n\n          const res = await knex.jsonExtract(knex.jsonInsert('population', '$.test', '1234'), '$.test', 'insertExtract').from('cities');\n          assertJsonEquals([res[0], res[1]], [{\n            insertExtract: '1234'\n          }, {\n            insertExtract: '1234'\n          }]);\n        });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"json remove then extract","suites":["Selects","json selections"],"updatePoint":{"line":1007,"column":36,"index":39404},"line":1007,"code":"        it('json remove then extract', async function () {\n          if (isOracle(knex)) {\n            this.skip();\n          }\n\n          await knex.jsonExtract(knex.jsonRemove('population', '$.minMax.min'), '$.minMax.max', 'maxPop').from('cities').testSql(function (tester) {\n            tester('mysql', 'select json_unquote(json_extract(json_remove(`population`,?), ?)) as `maxPop` from `cities`', ['$.minMax.min', '$.minMax.max'], [{\n              maxPop: '12000000'\n            }, {\n              maxPop: '1200000'\n            }, {\n              maxPop: '1450000'\n            }]);\n            tester('pg', 'select jsonb_path_query(\"population\" #- ?, ?) as \"maxPop\" from \"cities\"', ['{minMax,min}', '$.minMax.max'], [{\n              maxPop: 12000000\n            }, {\n              maxPop: 1200000\n            }, {\n              maxPop: 1450000\n            }]);\n            tester('pgnative', 'select jsonb_path_query(\"population\" #- ?, ?) as \"maxPop\" from \"cities\"', ['{minMax,min}', '$.minMax.max'], [{\n              maxPop: 12000000\n            }, {\n              maxPop: 1200000\n            }, {\n              maxPop: 1450000\n            }]);\n            tester('pg-redshift', 'select jsonb_path_query(\"population\" #- ?, ?) as \"maxPop\" from \"cities\"', ['{minMax,min}', '$.minMax.max'], [{\n              maxPop: '12000000'\n            }, {\n              maxPop: 1200000\n            }, {\n              maxPop: 1450000\n            }]);\n            tester('sqlite3', 'select json_extract(json_remove(`population`,?), ?) as `maxPop` from `cities`', ['$.minMax.min', '$.minMax.max'], [{\n              maxPop: 12000000\n            }, {\n              maxPop: 1200000\n            }, {\n              maxPop: 1450000\n            }]);\n            tester('mssql', 'select JSON_VALUE(JSON_MODIFY([population],?, NULL), ?) as [maxPop] from [cities]', ['$.minMax.min', '$.minMax.max'], [{\n              maxPop: '12000000'\n            }, {\n              maxPop: '1200000'\n            }, {\n              maxPop: '1450000'\n            }]);\n          });\n        });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"json remove, set then extract","suites":["Selects","json selections"],"updatePoint":{"line":1057,"column":41,"index":41463},"line":1057,"code":"        it('json remove, set then extract', async function () {\n          if (isOracle(knex)) {\n            this.skip();\n          }\n\n          const res = await knex.jsonExtract([[knex.jsonRemove('population', '$.minMax.min'), '$.minMax', 'withoutMin'], [knex.jsonRemove('population', '$.minMax.max'), '$.minMax', 'withoutMax'], [knex.jsonSet('population', '$.current.value', '1234'), '$.current', 'currentModified']], false).from('cities');\n          assertJsonEquals(res[0].currentModified, {\n            value: '1234'\n          });\n          assertJsonEquals(res[0].withoutMax, {\n            min: 50000\n          });\n          assertJsonEquals(res[0].withoutMin, {\n            max: 12000000\n          });\n          assertJsonEquals(res[1].currentModified, {\n            value: '1234'\n          });\n          assertJsonEquals(res[1].withoutMax, {\n            min: 44000\n          });\n          assertJsonEquals(res[1].withoutMin, {\n            max: 1200000\n          });\n          assertJsonEquals(res[2].currentModified, {\n            value: 1234\n          });\n          assertJsonEquals(res[2].withoutMax, {\n            min: 44000\n          });\n          assertJsonEquals(res[2].withoutMin, {\n            max: 1450000\n          });\n        });","file":"integration2/query/select/selects.spec.js","skipped":false,"dir":"test"},{"name":"handles unions with a callback","suites":["unions"],"updatePoint":{"line":63,"column":40,"index":1578},"line":63,"code":"      it('handles unions with a callback', function () {\n        return knex('accounts').select(unionCols).where('id', '=', 1).union(function () {\n          this.select(unionCols).from('accounts').where('id', 2);\n        });\n      });","file":"integration2/query/select/unions.spec.js","skipped":false,"dir":"test"},{"name":"handles unions with an array of callbacks","suites":["unions"],"updatePoint":{"line":68,"column":51,"index":1824},"line":68,"code":"      it('handles unions with an array of callbacks', function () {\n        return knex('accounts').select(unionCols).where('id', '=', 1).union([function () {\n          this.select(unionCols).from('accounts').where('id', 2);\n        }, function () {\n          this.select(unionCols).from('accounts').where('id', 3);\n        }]);\n      });","file":"integration2/query/select/unions.spec.js","skipped":false,"dir":"test"},{"name":"handles unions with a list of callbacks","suites":["unions"],"updatePoint":{"line":75,"column":49,"index":2161},"line":75,"code":"      it('handles unions with a list of callbacks', function () {\n        return knex('accounts').select(unionCols).where('id', '=', 1).union(function () {\n          this.select(unionCols).from('accounts').where('id', 2);\n        }, function () {\n          this.select(unionCols).from('accounts').where('id', 3);\n        });\n      });","file":"integration2/query/select/unions.spec.js","skipped":false,"dir":"test"},{"name":"handles unions with an array of builders","suites":["unions"],"updatePoint":{"line":82,"column":50,"index":2497},"line":82,"code":"      it('handles unions with an array of builders', function () {\n        return knex('accounts').select(unionCols).where('id', '=', 1).union([knex.select(unionCols).from('accounts').where('id', 2), knex.select(unionCols).from('accounts').where('id', 3)]);\n      });","file":"integration2/query/select/unions.spec.js","skipped":false,"dir":"test"},{"name":"handles unions with a list of builders","suites":["unions"],"updatePoint":{"line":85,"column":48,"index":2763},"line":85,"code":"      it('handles unions with a list of builders', function () {\n        return knex('accounts').select(unionCols).where('id', '=', 1).union(knex.select(unionCols).from('accounts').where('id', 2), knex.select(unionCols).from('accounts').where('id', 3));\n      });","file":"integration2/query/select/unions.spec.js","skipped":false,"dir":"test"},{"name":"handles unions with a raw query","suites":["unions"],"updatePoint":{"line":88,"column":41,"index":3020},"line":88,"code":"      it('handles unions with a raw query', function () {\n        return knex('union_raw_test').select('*').where('id', '=', 1).union(knex.raw('select * from ?? where ?? = ?', ['union_raw_test', 'id', 2]));\n      });","file":"integration2/query/select/unions.spec.js","skipped":false,"dir":"test"},{"name":"handles unions with an array raw queries","suites":["unions"],"updatePoint":{"line":91,"column":50,"index":3246},"line":91,"code":"      it('handles unions with an array raw queries', function () {\n        return knex('union_raw_test').select('*').where('id', '=', 1).union([knex.raw('select * from ?? where ?? = ?', ['union_raw_test', 'id', 2]), knex.raw('select * from ?? where ?? = ?', ['union_raw_test', 'id', 3])]);\n      });","file":"integration2/query/select/unions.spec.js","skipped":false,"dir":"test"},{"name":"handles unions with a list of raw queries","suites":["unions"],"updatePoint":{"line":94,"column":51,"index":3547},"line":94,"code":"      it('handles unions with a list of raw queries', function () {\n        return knex('union_raw_test').select('*').where('id', '=', 1).union(knex.raw('select * from ?? where ?? = ?', ['union_raw_test', 'id', 2]), knex.raw('select * from ?? where ?? = ?', ['union_raw_test', 'id', 3]));\n      });","file":"integration2/query/select/unions.spec.js","skipped":false,"dir":"test"},{"name":"handles intersects with a callback","suites":["unions","intersects"],"updatePoint":{"line":137,"column":46,"index":4921},"line":137,"code":"        it('handles intersects with a callback', async function () {\n          if (!isPgBased(knex) && !isMssql(knex) && !isOracle(knex) && !isSQLite(knex)) {\n            return this.skip();\n          }\n\n          await knex('intersect_test').select('*').where('test_col_1', '=', 1).intersect(function () {\n            this.select('*').from('intersect_test').where('test_col_2', 2);\n          }).then(function (result) {\n            expect(result.length).to.equal(3);\n            assertNumberArray(knex, result.map(r => r.id), [1, 4, 5]);\n          });\n        });","file":"integration2/query/select/unions.spec.js","skipped":false,"dir":"test"},{"name":"handles intersects with an array of callbacks","suites":["unions","intersects"],"updatePoint":{"line":149,"column":57,"index":5497},"line":149,"code":"        it('handles intersects with an array of callbacks', async function () {\n          if (!isPgBased(knex) && !isMssql(knex) && !isOracle(knex) && !isSQLite(knex)) {\n            return this.skip();\n          }\n\n          await knex('intersect_test').select('*').where('test_col_1', '=', 1).intersect([function () {\n            this.select('*').from('intersect_test').where('test_col_2', 2);\n          }, function () {\n            this.select('*').from('intersect_test').where('test_col_3', 1);\n          }]).then(function (result) {\n            expect(result.length).to.equal(2);\n            assertNumberArray(knex, result.map(r => r.id), [1, 5]);\n          });\n        });","file":"integration2/query/select/unions.spec.js","skipped":false,"dir":"test"},{"name":"handles intersects with a list of callbacks","suites":["unions","intersects"],"updatePoint":{"line":163,"column":55,"index":6173},"line":163,"code":"        it('handles intersects with a list of callbacks', async function () {\n          if (!isPgBased(knex) && !isMssql(knex) && !isOracle(knex) && !isSQLite(knex)) {\n            return this.skip();\n          }\n\n          await knex('intersect_test').select('*').where('test_col_1', '=', 1).intersect(function () {\n            this.select('*').from('intersect_test').where('test_col_2', 2);\n          }, function () {\n            this.select('*').from('intersect_test').where('test_col_3', 1);\n          }).then(function (result) {\n            expect(result.length).to.equal(2);\n            assertNumberArray(knex, result.map(r => r.id), [1, 5]);\n          });\n        });","file":"integration2/query/select/unions.spec.js","skipped":false,"dir":"test"},{"name":"handles intersects with an array of builders","suites":["unions","intersects"],"updatePoint":{"line":177,"column":56,"index":6848},"line":177,"code":"        it('handles intersects with an array of builders', async function () {\n          if (!isPgBased(knex) && !isMssql(knex) && !isOracle(knex) && !isSQLite(knex)) {\n            return this.skip();\n          }\n\n          await knex('intersect_test').select('*').where('test_col_1', '=', 1).intersect([knex.select('*').from('intersect_test').where('test_col_2', 2), knex.select('*').from('intersect_test').where('test_col_3', 1)]).then(function (result) {\n            expect(result.length).to.equal(2);\n            assertNumberArray(knex, result.map(r => r.id), [1, 5]);\n          });\n        });","file":"integration2/query/select/unions.spec.js","skipped":false,"dir":"test"},{"name":"handles intersects with a list of builders","suites":["unions","intersects"],"updatePoint":{"line":187,"column":54,"index":7445},"line":187,"code":"        it('handles intersects with a list of builders', async function () {\n          if (!isPgBased(knex) && !isMssql(knex) && !isOracle(knex) && !isSQLite(knex)) {\n            return this.skip();\n          }\n\n          await knex('intersect_test').select('*').where('test_col_1', '=', 1).intersect(knex.select('*').from('intersect_test').where('test_col_2', 2), knex.select('*').from('intersect_test').where('test_col_3', 1)).then(function (result) {\n            expect(result.length).to.equal(2);\n            assertNumberArray(knex, result.map(r => r.id), [1, 5]);\n          });\n        });","file":"integration2/query/select/unions.spec.js","skipped":false,"dir":"test"},{"name":"handles intersects with a raw query","suites":["unions","intersects"],"updatePoint":{"line":197,"column":47,"index":8033},"line":197,"code":"        it('handles intersects with a raw query', async function () {\n          if (!isPgBased(knex) && !isMssql(knex) && !isOracle(knex) && !isSQLite(knex)) {\n            return this.skip();\n          }\n\n          await knex('intersect_test').select('*').where('test_col_1', '=', 2).intersect(knex.raw('select * from ?? where ?? = ?', ['intersect_test', 'test_col_2', 3])).then(function (result) {\n            expect(result.length).to.equal(2);\n            assertNumberArray(knex, result.map(r => r.id), [2, 3]);\n          });\n        });","file":"integration2/query/select/unions.spec.js","skipped":false,"dir":"test"},{"name":"handles intersects with an array raw queries","suites":["unions","intersects"],"updatePoint":{"line":207,"column":56,"index":8582},"line":207,"code":"        it('handles intersects with an array raw queries', async function () {\n          if (!isPgBased(knex) && !isMssql(knex) && !isOracle(knex) && !isSQLite(knex)) {\n            return this.skip();\n          }\n\n          await knex('intersect_test').select('*').where('test_col_1', '=', 1).intersect([knex.raw('select * from ?? where ?? = ?', ['intersect_test', 'test_col_2', 2]), knex.raw('select * from ?? where ?? = ?', ['intersect_test', 'test_col_3', 1])]).then(function (result) {\n            expect(result.length).to.equal(2);\n            assertNumberArray(knex, result.map(r => r.id), [1, 5]);\n          });\n        });","file":"integration2/query/select/unions.spec.js","skipped":false,"dir":"test"},{"name":"handles intersects with a list of raw queries","suites":["unions","intersects"],"updatePoint":{"line":217,"column":57,"index":9214},"line":217,"code":"        it('handles intersects with a list of raw queries', async function () {\n          if (!isPgBased(knex) && !isMssql(knex) && !isOracle(knex) && !isSQLite(knex)) {\n            return this.skip();\n          }\n\n          await knex('intersect_test').select('*').where('test_col_1', '=', 1).intersect(knex.raw('select * from ?? where ?? = ?', ['intersect_test', 'test_col_2', 2]), knex.raw('select * from ?? where ?? = ?', ['intersect_test', 'test_col_3', 1])).then(function (result) {\n            expect(result.length).to.equal(2);\n            assertNumberArray(knex, result.map(r => r.id), [1, 5]);\n          });\n        });","file":"integration2/query/select/unions.spec.js","skipped":false,"dir":"test"},{"name":"allows key, value","suites":["Where","simple \"where\" cases"],"updatePoint":{"line":71,"column":29,"index":1517},"line":71,"code":"        it('allows key, value', function () {\n          return knex('accounts').where('id', 1).select('first_name', 'last_name').testSql(function (tester) {\n            tester(['mysql', 'sqlite3'], 'select `first_name`, `last_name` from `accounts` where `id` = ?', [1], [{\n              first_name: 'Test',\n              last_name: 'User'\n            }]);\n            tester(['pg', 'pgnative', 'pg-redshift', 'oracledb'], 'select \"first_name\", \"last_name\" from \"accounts\" where \"id\" = ?', [1], [{\n              first_name: 'Test',\n              last_name: 'User'\n            }]);\n            tester('mssql', 'select [first_name], [last_name] from [accounts] where [id] = ?', [1], [{\n              first_name: 'Test',\n              last_name: 'User'\n            }]);\n          });\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"allows key, operator, value","suites":["Where","simple \"where\" cases"],"updatePoint":{"line":87,"column":39,"index":2319},"line":87,"code":"        it('allows key, operator, value', function () {\n          return knex('accounts').where('id', 1).select('first_name', 'last_name').testSql(function (tester) {\n            tester(['mysql', 'sqlite3'], 'select `first_name`, `last_name` from `accounts` where `id` = ?', [1], [{\n              first_name: 'Test',\n              last_name: 'User'\n            }]);\n            tester(['pg', 'pgnative', 'pg-redshift', 'oracledb'], 'select \"first_name\", \"last_name\" from \"accounts\" where \"id\" = ?', [1], [{\n              first_name: 'Test',\n              last_name: 'User'\n            }]);\n            tester('mssql', 'select [first_name], [last_name] from [accounts] where [id] = ?', [1], [{\n              first_name: 'Test',\n              last_name: 'User'\n            }]);\n          });\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"allows selecting columns with an array","suites":["Where","simple \"where\" cases"],"updatePoint":{"line":103,"column":50,"index":3132},"line":103,"code":"        it('allows selecting columns with an array', function () {\n          return knex('accounts').where('id', '>', 1).select(['email', 'logins']).testSql(function (tester) {\n            tester(['mysql', 'sqlite3'], 'select `email`, `logins` from `accounts` where `id` > ?', [1]);\n            tester(['pg', 'pgnative', 'pg-redshift', 'oracledb'], 'select \"email\", \"logins\" from \"accounts\" where \"id\" > ?', [1]);\n            tester('mssql', 'select [email], [logins] from [accounts] where [id] > ?', [1]);\n          });\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"allows a hash of where attrs","suites":["Where","simple \"where\" cases"],"updatePoint":{"line":110,"column":40,"index":3655},"line":110,"code":"        it('allows a hash of where attrs', function () {\n          return knex('accounts').where({\n            id: 1\n          }).select('*').testSql(function (tester) {\n            tester(['mysql', 'sqlite3'], 'select * from `accounts` where `id` = ?', [1], [{\n              id: 1,\n              first_name: 'Test',\n              last_name: 'User',\n              email: 'test1@example.com',\n              logins: 1,\n              balance: 0,\n              about: 'Lorem ipsum Dolore labore incididunt enim.',\n              created_at: TEST_TIMESTAMP,\n              updated_at: TEST_TIMESTAMP,\n              phone: null\n            }]);\n            tester(['pg', 'pgnative', 'pg-redshift', 'oracledb'], 'select * from \"accounts\" where \"id\" = ?', [1], [{\n              id: '1',\n              first_name: 'Test',\n              last_name: 'User',\n              email: 'test1@example.com',\n              logins: 1,\n              balance: 0,\n              about: 'Lorem ipsum Dolore labore incididunt enim.',\n              created_at: TEST_TIMESTAMP,\n              updated_at: TEST_TIMESTAMP,\n              phone: null\n            }]);\n            tester('mssql', 'select * from [accounts] where [id] = ?', [1], [{\n              id: '1',\n              first_name: 'Test',\n              last_name: 'User',\n              email: 'test1@example.com',\n              logins: 1,\n              balance: 0,\n              about: 'Lorem ipsum Dolore labore incididunt enim.',\n              created_at: TEST_TIMESTAMP,\n              updated_at: TEST_TIMESTAMP,\n              phone: null\n            }]);\n          });\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"allows where id: undefined or id: null as a where null clause","suites":["Where","simple \"where\" cases"],"updatePoint":{"line":152,"column":73,"index":5301},"line":152,"code":"        it('allows where id: undefined or id: null as a where null clause', function () {\n          return knex('accounts').where({\n            id: null\n          }).select('first_name', 'email').testSql(function (tester) {\n            tester(['mysql', 'sqlite3'], 'select `first_name`, `email` from `accounts` where `id` is null', [], []);\n            tester(['pg', 'pgnative', 'pg-redshift', 'oracledb', 'cockroachdb'], 'select \"first_name\", \"email\" from \"accounts\" where \"id\" is null', [], []);\n            tester('mssql', 'select [first_name], [email] from [accounts] where [id] is null', [], []);\n          });\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"allows where id = 0","suites":["Where","simple \"where\" cases"],"updatePoint":{"line":161,"column":31,"index":5887},"line":161,"code":"        it('allows where id = 0', function () {\n          return knex('accounts').where({\n            id: 0\n          }).select().testSql(function (tester) {\n            tester(['mysql', 'sqlite3'], 'select * from `accounts` where `id` = ?', [0], []);\n            tester(['pg', 'pgnative', 'pg-redshift', 'oracledb', 'cockroachdb'], 'select * from \"accounts\" where \"id\" = ?', [0], []);\n            tester('mssql', 'select * from [accounts] where [id] = ?', [0], []);\n          });\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"does \"orWhere\" cases","suites":["Where","simple \"where\" cases"],"updatePoint":{"line":171,"column":30,"index":6389},"line":171,"code":"      it('does \"orWhere\" cases', function () {\n        return knex('accounts').where('id', 1).orWhere('id', '>', 2).select('first_name', 'last_name');\n      });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"does \"andWhere\" cases","suites":["Where","simple \"where\" cases"],"updatePoint":{"line":174,"column":31,"index":6551},"line":174,"code":"      it('does \"andWhere\" cases', function () {\n        return knex('accounts').select('first_name', 'last_name', 'about').where('id', 1).andWhere('email', 'test1@example.com');\n      });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"takes a function to wrap nested where statements","suites":["Where","simple \"where\" cases"],"updatePoint":{"line":177,"column":58,"index":6766},"line":177,"code":"      it('takes a function to wrap nested where statements', function () {\n        return Promise.all([knex('accounts').where(function () {\n          this.where('id', 2);\n          this.orWhere('id', 3);\n        }).select('*')]);\n      });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"handles \"where in\" cases","suites":["Where","simple \"where\" cases"],"updatePoint":{"line":183,"column":34,"index":6982},"line":183,"code":"      it('handles \"where in\" cases', function () {\n        return Promise.all([knex('accounts').whereIn('id', [1, 2, 3]).select()]);\n      });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"handles \"or where in\" cases","suites":["Where","simple \"where\" cases"],"updatePoint":{"line":186,"column":37,"index":7128},"line":186,"code":"      it('handles \"or where in\" cases', function () {\n        return knex('accounts').where('email', 'test1@example.com').orWhereIn('id', [2, 3, 4]).select();\n      });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"handles multi-column \"where in\" cases","suites":["Where","simple \"where\" cases"],"updatePoint":{"line":189,"column":47,"index":7307},"line":189,"code":"      it('handles multi-column \"where in\" cases', async function () {\n        await knex('composite_key_test').insert([{\n          column_a: 1,\n          column_b: 1,\n          details: 'One, One, One',\n          status: 1\n        }, {\n          column_a: 1,\n          column_b: 2,\n          details: 'One, Two, Zero',\n          status: 0\n        }, {\n          column_a: 2,\n          column_b: 2,\n          details: 'Two, Two, Zero',\n          status: 0\n        }]);\n\n        if (!isMssql(knex)) {\n          await knex('composite_key_test').whereIn(['column_a', 'column_b'], [[1, 1], [1, 2]]).orderBy('status', 'desc').select().testSql(function (tester) {\n            tester('mysql', 'select * from `composite_key_test` where (`column_a`, `column_b`) in ((?, ?), (?, ?)) order by `status` desc', [1, 1, 1, 2], [{\n              column_a: 1,\n              column_b: 1,\n              details: 'One, One, One',\n              status: 1\n            }, {\n              column_a: 1,\n              column_b: 2,\n              details: 'One, Two, Zero',\n              status: 0\n            }]);\n            tester('sqlite3', 'select * from `composite_key_test` where (`column_a`, `column_b`) in ( values (?, ?), (?, ?)) order by `status` desc', [1, 1, 1, 2], [{\n              column_a: 1,\n              column_b: 1,\n              details: 'One, One, One',\n              status: 1\n            }, {\n              column_a: 1,\n              column_b: 2,\n              details: 'One, Two, Zero',\n              status: 0\n            }]);\n            tester(['pg', 'pgnative', 'pg-redshift', 'oracledb'], 'select * from \"composite_key_test\" where (\"column_a\", \"column_b\") in ((?, ?), (?, ?)) order by \"status\" desc', [1, 1, 1, 2], [{\n              column_a: 1,\n              column_b: 1,\n              details: 'One, One, One',\n              status: 1\n            }, {\n              column_a: 1,\n              column_b: 2,\n              details: 'One, Two, Zero',\n              status: 0\n            }]);\n            tester('cockroachdb', 'select * from \"composite_key_test\" where (\"column_a\", \"column_b\") in ((?, ?), (?, ?)) order by \"status\" desc', [1, 1, 1, 2], [{\n              column_a: '1',\n              column_b: '1',\n              details: 'One, One, One',\n              status: 1\n            }, {\n              column_a: '1',\n              column_b: '2',\n              details: 'One, Two, Zero',\n              status: 0\n            }]);\n          });\n        }\n      });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"handles multi-column \"where in\" cases with where","suites":["Where","simple \"where\" cases"],"updatePoint":{"line":256,"column":58,"index":9783},"line":256,"code":"      it('handles multi-column \"where in\" cases with where', function () {\n        if (!isSQLite(knex) && !isMssql(knex)) {\n          return knex('composite_key_test').where('status', 1).whereIn(['column_a', 'column_b'], [[1, 1], [1, 2]]).select().testSql(function (tester) {\n            tester('mysql', 'select * from `composite_key_test` where `status` = ? and (`column_a`, `column_b`) in ((?, ?), (?, ?))', [1, 1, 1, 1, 2], [{\n              column_a: 1,\n              column_b: 1,\n              details: 'One, One, One',\n              status: 1\n            }]);\n            tester(['pg', 'pgnative', 'pg-redshift', 'oracledb'], 'select * from \"composite_key_test\" where \"status\" = ? and (\"column_a\", \"column_b\") in ((?, ?), (?, ?))', [1, 1, 1, 1, 2], [{\n              column_a: 1,\n              column_b: 1,\n              details: 'One, One, One',\n              status: 1\n            }]);\n            tester('cockroachdb', 'select * from \"composite_key_test\" where \"status\" = ? and (\"column_a\", \"column_b\") in ((?, ?), (?, ?))', [1, 1, 1, 1, 2], [{\n              column_a: '1',\n              column_b: '1',\n              details: 'One, One, One',\n              status: 1\n            }]);\n          });\n        }\n      });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"handles \"where exists\"","suites":["Where","simple \"where\" cases"],"updatePoint":{"line":280,"column":32,"index":10982},"line":280,"code":"      it('handles \"where exists\"', function () {\n        return knex('accounts').whereExists(function () {\n          this.select('id').from('test_table_two').where({\n            id: 1\n          });\n        }).select();\n      });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"handles \"where between\"","suites":["Where","simple \"where\" cases"],"updatePoint":{"line":287,"column":33,"index":11212},"line":287,"code":"      it('handles \"where between\"', function () {\n        return knex('accounts').whereBetween('id', [1, 100]).select();\n      });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"handles \"or where between\"","suites":["Where","simple \"where\" cases"],"updatePoint":{"line":290,"column":36,"index":11346},"line":290,"code":"      it('handles \"or where between\"', function () {\n        return knex('accounts').whereBetween('id', [1, 100]).orWhereBetween('id', [200, 300]).select();\n      });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"does where(raw)","suites":["Where","simple \"where\" cases"],"updatePoint":{"line":293,"column":25,"index":11502},"line":293,"code":"      it('does where(raw)', function () {\n        if (isOracle(knex)) {\n          // special case for oracle\n          return knex('accounts').whereExists(function () {\n            this.select(knex.raw(1)).from('test_table_two').where(knex.raw('\"test_table_two\".\"account_id\" = \"accounts\".\"id\"'));\n          }).select();\n        } else {\n          return knex('accounts').whereExists(function () {\n            this.select(knex.raw(1)).from('test_table_two').where(knex.raw('test_table_two.account_id = accounts.id'));\n          }).select();\n        }\n      });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"does sub-selects","suites":["Where","simple \"where\" cases"],"updatePoint":{"line":305,"column":26,"index":12063},"line":305,"code":"      it('does sub-selects', function () {\n        return knex('accounts').whereIn('id', function () {\n          this.select('account_id').from('test_table_two').where('status', 1);\n        }).select('first_name', 'last_name');\n      });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"supports the <> operator","suites":["Where","simple \"where\" cases"],"updatePoint":{"line":310,"column":34,"index":12309},"line":310,"code":"      it('supports the <> operator', function () {\n        return knex('accounts').where('id', '<>', 2).select('email', 'logins');\n      });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"Allows for knex.Raw passed to the `where` clause","suites":["Where","simple \"where\" cases"],"updatePoint":{"line":313,"column":58,"index":12474},"line":313,"code":"      it('Allows for knex.Raw passed to the `where` clause', function () {\n        if (isOracle(knex)) {\n          return knex('accounts').where(knex.raw('\"id\" = 2')).select('email', 'logins');\n        } else {\n          return knex('accounts').where(knex.raw('id = 2')).select('email', 'logins');\n        }\n      });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"finds data using whereILike","suites":["Where","where like"],"updatePoint":{"line":326,"column":39,"index":12978},"line":326,"code":"        it('finds data using whereILike', async () => {\n          const result = await knex('accounts').select('*').whereILike('email', 'test1%');\n          expect(result[0].email).to.equal('test1@example.com');\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"finds data using whereILike when different case sensitivity","suites":["Where","where like"],"updatePoint":{"line":330,"column":71,"index":13234},"line":330,"code":"        it('finds data using whereILike when different case sensitivity', async () => {\n          const result = await knex('accounts').whereILike('email', 'TEST1%');\n          expect(result[0].email).to.equal('test1@example.com');\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"finds data using whereLike","suites":["Where","where like"],"updatePoint":{"line":334,"column":38,"index":13445},"line":334,"code":"        it('finds data using whereLike', async () => {\n          const result = await knex('accounts').select('*').whereLike('email', 'test1%');\n          expect(result[0].email).to.equal('test1@example.com');\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"finds data using orWhereLike","suites":["Where","where like"],"updatePoint":{"line":338,"column":40,"index":13669},"line":338,"code":"        it('finds data using orWhereLike', async () => {\n          const result = await knex('accounts').select('*').whereLike('email', 'test1%').orWhereLike('email', 'test2%');\n          expect(result[0].email).to.equal('test1@example.com');\n          expect(result[1].email).to.equal('test2@example.com');\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"finds data using andWhereLike","suites":["Where","where like"],"updatePoint":{"line":343,"column":41,"index":13990},"line":343,"code":"        it('finds data using andWhereLike', async () => {\n          const result = await knex('accounts').select('*').whereLike('first_name', 'Te%').andWhereLike('email', '%example.com');\n          expect(result.length).to.equal(6);\n          expect(result[0].email).to.equal('test1@example.com');\n          expect(result[1].email).to.equal('test2@example.com');\n          expect(result[2].email).to.equal('test3@example.com');\n          expect(result[3].email).to.equal('test4@example.com');\n          expect(result[4].email).to.equal('test5@example.com');\n          expect(result[5].email).to.equal('test6@example.com');\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"finds data using orWhereILike","suites":["Where","where like"],"updatePoint":{"line":353,"column":41,"index":14625},"line":353,"code":"        it('finds data using orWhereILike', async () => {\n          const result = await knex('accounts').select('*').whereILike('email', 'TEST1%').orWhereILike('email', 'TeSt2%');\n          expect(result[0].email).to.equal('test1@example.com');\n          expect(result[1].email).to.equal('test2@example.com');\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"finds data using andWhereILike","suites":["Where","where like"],"updatePoint":{"line":358,"column":42,"index":14949},"line":358,"code":"        it('finds data using andWhereILike', async () => {\n          const result = await knex('accounts').select('*').whereILike('first_name', 'te%').andWhereILike('email', '%examPle.COm');\n          expect(result.length).to.equal(6);\n          expect(result[0].email).to.equal('test1@example.com');\n          expect(result[1].email).to.equal('test2@example.com');\n          expect(result[2].email).to.equal('test3@example.com');\n          expect(result[3].email).to.equal('test4@example.com');\n          expect(result[4].email).to.equal('test5@example.com');\n          expect(result[5].email).to.equal('test6@example.com');\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"doesn't find data using whereLike when different case sensitivity","suites":["Where","where like"],"updatePoint":{"line":368,"column":77,"index":15622},"line":368,"code":"        it(\"doesn't find data using whereLike when different case sensitivity\", async () => {\n          const result = await knex('accounts').whereLike('email', 'Test1%');\n          expect(result).to.deep.equal([]);\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"Retains array bindings, #228","suites":["Where","where like"],"updatePoint":{"line":373,"column":38,"index":15821},"line":373,"code":"      it('Retains array bindings, #228', function () {\n        const raw = knex.raw('select * from table t where t.id = ANY( ?::int[] )', [[1, 2, 3]]);\n        const raw2 = knex.raw('select \"stored_procedure\"(?, ?, ?)', [1, 2, ['a', 'b', 'c']]);\n        const expected1 = [[1, 2, 3]];\n        const expected2 = [1, 2, ['a', 'b', 'c']];\n        expect(raw.toSQL().bindings).to.eql(knex.client.prepBindings(expected1));\n        expect(raw2.toSQL().bindings).to.eql(knex.client.prepBindings(expected2)); //Also expect raw's bindings to not have been modified by calling .toSQL() (preserving original bindings)\n\n        expect(raw.bindings).to.eql(expected1);\n        expect(raw2.bindings).to.eql(expected2);\n      });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"where json object","suites":["Where","json wheres"],"updatePoint":{"line":393,"column":29,"index":16823},"line":393,"code":"        it('where json object', async () => {\n          const result = await knex('cities').select('name').whereJsonObject('descriptions', {\n            type: 'bigcity',\n            short: 'beautiful city',\n            long: 'beautiful and dirty city'\n          });\n          expect(result[0]).to.eql({\n            name: 'Paris'\n          });\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"where json object with string object","suites":["Where","json wheres"],"updatePoint":{"line":403,"column":48,"index":17197},"line":403,"code":"        it('where json object with string object', async () => {\n          const result = await knex('cities').select('name').whereJsonObject('descriptions', `{\n              \"type\": \"bigcity\",\n              \"short\": \"beautiful city\",\n              \"long\": \"beautiful and dirty city\"\n            }`);\n          expect(result[0]).to.eql({\n            name: 'Paris'\n          });\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"where not json object","suites":["Where","json wheres"],"updatePoint":{"line":413,"column":33,"index":17572},"line":413,"code":"        it('where not json object', async () => {\n          const result = await knex('cities').select('name').whereNotJsonObject('descriptions', {\n            type: 'bigcity',\n            short: 'beautiful city',\n            long: 'beautiful and dirty city'\n          });\n          expect(result.length).to.equal(2);\n          assertJsonEquals(result, [{\n            name: 'Milan'\n          }, {\n            name: 'Oslo'\n          }]);\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"where json path greater than numeric","suites":["Where","json wheres"],"updatePoint":{"line":426,"column":48,"index":18036},"line":426,"code":"        it('where json path greater than numeric', async () => {\n          const result = await knex('cities').select('name').whereJsonPath('statistics', '$.roads.min', '>', 1000);\n          expect(result[0]).to.eql({\n            name: 'Paris'\n          });\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"where json path equal numeric","suites":["Where","json wheres"],"updatePoint":{"line":432,"column":41,"index":18299},"line":432,"code":"        it('where json path equal numeric', async () => {\n          const result = await knex('cities').select('name').whereJsonPath('statistics', '$.roads.min', '=', 1455);\n          expect(result[0]).to.eql({\n            name: 'Milan'\n          });\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"where and or where json path equal numeric","suites":["Where","json wheres"],"updatePoint":{"line":438,"column":54,"index":18575},"line":438,"code":"        it('where and or where json path equal numeric', async () => {\n          const result = await knex('cities').select('name').whereJsonPath('statistics', '$.roads.min', '=', 1455).orWhereJsonPath('statistics', '$.roads.min', '=', 1655);\n          expect(result[0]).to.eql({\n            name: 'Milan'\n          });\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"where json path equal string starting with number","suites":["Where","json wheres"],"updatePoint":{"line":444,"column":61,"index":18914},"line":444,"code":"        it('where json path equal string starting with number', async () => {\n          const result = await knex('cities').select('name').whereJsonPath('statistics', '$.statisticId', '=', '6qITEHRUNJ4bdAmA0lk82');\n          expect(result[0]).to.eql({\n            name: 'Paris'\n          });\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"where multiple json path","suites":["Where","json wheres"],"updatePoint":{"line":450,"column":36,"index":19193},"line":450,"code":"        it('where multiple json path', async () => {\n          const result = await knex('cities').select('name').whereJsonPath('statistics', '$.roads.min', '<', 2000).andWhereJsonPath('temperature', '$.desc', '=', 'cold');\n          expect(result.length).to.equal(1);\n          assertJsonEquals(result, [{\n            name: 'Paris'\n          }]);\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"where json superset of","suites":["Where","json wheres"],"updatePoint":{"line":457,"column":34,"index":19551},"line":457,"code":"        it('where json superset of', async function () {\n          if (!(isPostgreSQL(knex) || isMysql(knex))) {\n            this.skip();\n          }\n\n          const result = await knex('cities').select('name') // where descriptions json object contains type : 'bigcity'\n          .whereJsonSupersetOf('descriptions', {\n            type: 'bigcity'\n          });\n          expect(result.length).to.equal(2);\n          assertJsonEquals(result, [{\n            name: 'Paris'\n          }, {\n            name: 'Milan'\n          }]);\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"where json superset of with string","suites":["Where","json wheres"],"updatePoint":{"line":473,"column":46,"index":20103},"line":473,"code":"        it('where json superset of with string', async function () {\n          if (!(isPostgreSQL(knex) || isMysql(knex))) {\n            this.skip();\n          }\n\n          const result = await knex('cities').select('name').whereJsonSupersetOf('descriptions', '{\"type\": \"bigcity\"}');\n          expect(result.length).to.equal(2);\n          assertJsonEquals(result, [{\n            name: 'Paris'\n          }, {\n            name: 'Milan'\n          }]);\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"where json subset of","suites":["Where","json wheres"],"updatePoint":{"line":486,"column":32,"index":20550},"line":486,"code":"        it('where json subset of', async function () {\n          if (!(isPostgreSQL(knex) || isMysql(knex))) {\n            this.skip();\n          }\n\n          const result = await knex('cities').select('name') // where temperature json object is included in given object\n          .whereJsonSubsetOf('temperature', {\n            desc: 'cold',\n            desc2: 'very cold'\n          });\n          expect(result.length).to.equal(1);\n          assertJsonEquals(result, [{\n            name: 'Paris' // contains only desc: 'cold' but it's matched\n\n          }]);\n        });","file":"integration2/query/select/where.spec.js","skipped":false,"dir":"test"},{"name":"should handle updates","suites":["Updates"],"updatePoint":{"line":53,"column":31,"index":1167},"line":53,"code":"      it('should handle updates', function () {\n        return knex('accounts').where('id', 1).update({\n          first_name: 'User',\n          last_name: 'Test',\n          email: 'test100@example.com'\n        }).testSql(function (tester) {\n          tester('mysql', 'update `accounts` set `first_name` = ?, `last_name` = ?, `email` = ? where `id` = ?', ['User', 'Test', 'test100@example.com', 1], 1);\n          tester('pg', 'update \"accounts\" set \"first_name\" = ?, \"last_name\" = ?, \"email\" = ? where \"id\" = ?', ['User', 'Test', 'test100@example.com', 1], 1);\n          tester('pg-redshift', 'update \"accounts\" set \"first_name\" = ?, \"last_name\" = ?, \"email\" = ? where \"id\" = ?', ['User', 'Test', 'test100@example.com', 1], 1);\n          tester('sqlite3', 'update `accounts` set `first_name` = ?, `last_name` = ?, `email` = ? where `id` = ?', ['User', 'Test', 'test100@example.com', 1], 1);\n          tester('mssql', 'update [accounts] set [first_name] = ?, [last_name] = ?, [email] = ? where [id] = ?;select @@rowcount', ['User', 'Test', 'test100@example.com', 1], 1);\n        });\n      });","file":"integration2/query/update/updates.spec.js","skipped":false,"dir":"test"},{"name":"should allow for null updates","suites":["Updates"],"updatePoint":{"line":66,"column":39,"index":2266},"line":66,"code":"      it('should allow for null updates', function () {\n        return knex('accounts').where('id', 1000).update({\n          email: 'test100@example.com',\n          first_name: null,\n          last_name: 'Test'\n        }).testSql(function (tester) {\n          tester('mysql', 'update `accounts` set `email` = ?, `first_name` = ?, `last_name` = ? where `id` = ?', ['test100@example.com', null, 'Test', 1000], 0);\n          tester('mssql', 'update [accounts] set [email] = ?, [first_name] = ?, [last_name] = ? where [id] = ?;select @@rowcount', ['test100@example.com', null, 'Test', 1000], 0);\n        });\n      });","file":"integration2/query/update/updates.spec.js","skipped":false,"dir":"test"},{"name":"should immediately return updated value for other connections when updating row to DB returns","suites":["Updates"],"updatePoint":{"line":76,"column":103,"index":2944},"line":76,"code":"      it('should immediately return updated value for other connections when updating row to DB returns', function () {\n        return knex('accounts').then(res => {\n          function runTest() {\n            return Promise.all(res.map(origRow => {\n              return Promise.resolve().then(() => {\n                return knex.transaction(trx => trx('accounts').where('id', origRow.id).update({\n                  balance: 654\n                }));\n              }).then(() => {\n                return knex('accounts').where('id', origRow.id).then(res => res[0]);\n              }).then(updatedRow => {\n                expect(updatedRow.balance).to.equal(654);\n                return knex.transaction(trx => trx('accounts').where('id', origRow.id).update({\n                  balance: origRow.balance\n                }));\n              }).then(() => {\n                return knex('accounts').where('id', origRow.id).then(res => res[0]);\n              }).then(updatedRow => {\n                expect(updatedRow.balance).to.equal(origRow.balance);\n              });\n            }));\n          } // run few times to try to catch the problem\n\n\n          return runTest().then(() => runTest()).then(() => runTest()).then(() => runTest()).then(() => runTest()).then(() => runTest()).then(() => runTest()).then(() => runTest()).then(() => runTest()).then(() => runTest()).then(() => runTest()).then(() => runTest()).then(() => runTest()).then(() => runTest()).then(() => runTest()).then(() => runTest()).then(() => runTest()).then(() => runTest()).then(() => runTest());\n        });\n      });","file":"integration2/query/update/updates.spec.js","skipped":false,"dir":"test"},{"name":"should increment a value","suites":["Updates"],"updatePoint":{"line":103,"column":34,"index":4458},"line":103,"code":"      it('should increment a value', function () {\n        return knex('accounts').select('logins').where('id', accountId1).then(function (accounts) {\n          return knex('accounts').where('id', accountId1).increment('logins').then(function (rowsAffected) {\n            expect(rowsAffected).to.equal(1);\n            return knex('accounts').select('logins').where('id', accountId1);\n          }).then(function (accounts2) {\n            assertNumber(knex, accounts2[0].logins, parseInt(accounts[0].logins) + 1);\n          });\n        });\n      });","file":"integration2/query/update/updates.spec.js","skipped":false,"dir":"test"},{"name":"should increment a negative value","suites":["Updates"],"updatePoint":{"line":113,"column":43,"index":5015},"line":113,"code":"      it('should increment a negative value', function () {\n        return knex('accounts').select('logins').where('id', accountId1).then(function (accounts) {\n          return knex('accounts').where('id', accountId1).increment('logins', -2).then(function (rowsAffected) {\n            expect(rowsAffected).to.equal(1);\n            return knex('accounts').select('logins').where('id', accountId1);\n          }).then(function (accounts2) {\n            assertNumber(knex, accounts2[0].logins, accounts[0].logins - 2);\n          });\n        });\n      });","file":"integration2/query/update/updates.spec.js","skipped":false,"dir":"test"},{"name":"should increment a float value","suites":["Updates"],"updatePoint":{"line":123,"column":40,"index":5563},"line":123,"code":"      it('should increment a float value', function () {\n        return knex('accounts').select('balance').where('id', accountId1).then(function (accounts) {\n          return knex('accounts').where('id', accountId1).increment('balance', 22.53).then(function (rowsAffected) {\n            expect(rowsAffected).to.equal(1);\n            return knex('accounts').select('balance').where('id', accountId1);\n          }).then(function (accounts2) {\n            expect(accounts[0].balance + 22.53).to.be.closeTo(accounts2[0].balance, 0.001);\n          });\n        });\n      });","file":"integration2/query/update/updates.spec.js","skipped":false,"dir":"test"},{"name":"should decrement a value","suites":["Updates"],"updatePoint":{"line":133,"column":34,"index":6126},"line":133,"code":"      it('should decrement a value', function () {\n        return knex('accounts').select('logins').where('id', accountId1).then(function (accounts) {\n          return knex('accounts').where('id', accountId1).decrement('logins').then(function (rowsAffected) {\n            expect(rowsAffected).to.equal(1);\n            return knex('accounts').select('logins').where('id', accountId1);\n          }).then(function (accounts2) {\n            assertNumber(knex, accounts2[0].logins, accounts[0].logins - 1);\n          });\n        });\n      });","file":"integration2/query/update/updates.spec.js","skipped":false,"dir":"test"},{"name":"should decrement a negative value","suites":["Updates"],"updatePoint":{"line":143,"column":43,"index":6673},"line":143,"code":"      it('should decrement a negative value', function () {\n        return knex('accounts').select('logins').where('id', accountId1).then(function (accounts) {\n          return knex('accounts').where('id', accountId1).decrement('logins', -2).then(function (rowsAffected) {\n            expect(rowsAffected).to.equal(1);\n            return knex('accounts').select('logins').where('id', accountId1);\n          }).then(function (accounts2) {\n            assertNumber(knex, accounts2[0].logins, parseInt(accounts[0].logins) + 2);\n          });\n        });\n      });","file":"integration2/query/update/updates.spec.js","skipped":false,"dir":"test"},{"name":"should decrement a float value","suites":["Updates"],"updatePoint":{"line":153,"column":40,"index":7231},"line":153,"code":"      it('should decrement a float value', async function () {\n        return knex('accounts').select('balance').where('id', accountId1).then(function (accounts) {\n          return knex('accounts').where('id', accountId1).decrement('balance', 10.29).then(function (rowsAffected) {\n            expect(rowsAffected).to.equal(1);\n            return knex('accounts').select('balance').where('id', accountId1);\n          }).then(function (accounts2) {\n            expect(accounts[0].balance - 10.29).to.be.closeTo(accounts2[0].balance, 0.001);\n          });\n        });\n      });","file":"integration2/query/update/updates.spec.js","skipped":false,"dir":"test"},{"name":"should allow returning for updates","suites":["Updates"],"updatePoint":{"line":163,"column":44,"index":7810},"line":163,"code":"      it('should allow returning for updates', async function () {\n        await knex('accounts').where('id', accountId1).update({\n          balance: 12.240000000000002\n        });\n        await knex('accounts').where('id', accountId1).update({\n          email: 'test100@example.com',\n          first_name: 'UpdatedUser',\n          last_name: 'UpdatedTest'\n        }, '*').testSql(function (tester) {\n          tester('mysql', 'update `accounts` set `email` = ?, `first_name` = ?, `last_name` = ? where `id` = ?', ['test100@example.com', 'UpdatedUser', 'UpdatedTest', 1], 1);\n          tester('pg', 'update \"accounts\" set \"email\" = ?, \"first_name\" = ?, \"last_name\" = ? where \"id\" = ? returning *', ['test100@example.com', 'UpdatedUser', 'UpdatedTest', '1'], [{\n            id: '1',\n            first_name: 'UpdatedUser',\n            last_name: 'UpdatedTest',\n            email: 'test100@example.com',\n            logins: 1,\n            balance: 12.24,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null\n          }]);\n          tester('cockroachdb', 'update \"accounts\" set \"email\" = ?, \"first_name\" = ?, \"last_name\" = ? where \"id\" = ? returning *', ['test100@example.com', 'UpdatedUser', 'UpdatedTest', accountId1], [{\n            id: accountId1,\n            first_name: 'UpdatedUser',\n            last_name: 'UpdatedTest',\n            email: 'test100@example.com',\n            logins: '1',\n            balance: 12.24,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null\n          }]);\n          tester('pg-redshift', 'update \"accounts\" set \"email\" = ?, \"first_name\" = ?, \"last_name\" = ? where \"id\" = ?', ['test100@example.com', 'UpdatedUser', 'UpdatedTest', 1], 1);\n          tester('sqlite3', 'update `accounts` set `email` = ?, `first_name` = ?, `last_name` = ? where `id` = ?', ['test100@example.com', 'UpdatedUser', 'UpdatedTest', 1], 1);\n          tester('oracledb', 'update \"accounts\" set \"email\" = ?, \"first_name\" = ?, \"last_name\" = ? where \"id\" = ? returning \"ROWID\" into ?', ['test100@example.com', 'UpdatedUser', 'UpdatedTest', 1, v => v.toString() === '[object ReturningHelper:ROWID]'], 1);\n          tester('mssql', 'update [accounts] set [email] = ?, [first_name] = ?, [last_name] = ? output inserted.* where [id] = ?', ['test100@example.com', 'UpdatedUser', 'UpdatedTest', '1'], [{\n            id: '1',\n            first_name: 'UpdatedUser',\n            last_name: 'UpdatedTest',\n            email: 'test100@example.com',\n            logins: 1,\n            balance: 12.240000000000002,\n            about: 'Lorem ipsum Dolore labore incididunt enim.',\n            created_at: TEST_TIMESTAMP,\n            updated_at: TEST_TIMESTAMP,\n            phone: null\n          }]);\n        });\n      });","file":"integration2/query/update/updates.spec.js","skipped":false,"dir":"test"},{"name":"with update query","suites":["Updates"],"updatePoint":{"line":214,"column":27,"index":10735},"line":214,"code":"      it('with update query', async function () {\n        await knex.with('withClause', function () {\n          this.select('last_name').from('accounts').where('email', '=', 'test1@example.com');\n        }).update({\n          last_name: 'olivier'\n        }).where('last_name', '=', 'User').from('accounts');\n        const results = await knex('accounts').from('accounts').where('email', '=', 'test1@example.com');\n        expect(results[0].last_name).to.equal('olivier');\n      });","file":"integration2/query/update/updates.spec.js","skipped":false,"dir":"test"},{"name":"alter table add indexes","suites":["Schema","Alter","indexes and unique keys"],"updatePoint":{"line":53,"column":37,"index":1655},"line":53,"code":"          it('alter table add indexes', async function () {\n            if (!isMysql(knex)) {\n              this.skip();\n            }\n\n            await knex.schema.alterTable('alter_table', table => {\n              table.index(['column_string', 'column_datetime'], 'idx_1', {\n                indexType: 'FULLTEXT',\n                storageEngineIndexType: 'BTREE'\n              });\n              table.unique('column_notNullable', {\n                indexName: 'idx_2',\n                storageEngineIndexType: 'HASH'\n              });\n            }).testSql(tester => {\n              tester('mysql', ['alter table `alter_table` add FULLTEXT index `idx_1`(`column_string`, `column_datetime`) using BTREE', 'alter table `alter_table` add unique `idx_2`(`column_notNullable`) using HASH']);\n            });\n          });","file":"integration2/schema/alter.spec.js","skipped":false,"dir":"test"},{"name":"alters the type of columns","suites":["Schema","Alter","alterColumns"],"updatePoint":{"line":73,"column":40,"index":2529},"line":73,"code":"          it('alters the type of columns', async () => {\n            await knex.schema.alterTable('alter_table', table => {\n              table.string('column_integer').alter();\n              table.integer('column_string').alter();\n              table.date('column_datetime').alter();\n            });\n            const item_one = (await knex('alter_table'))[0];\n            const tableAfter = (await knex.raw(QUERY_TABLE))[0].sql;\n            expect(item_one.column_integer).to.be.a('string');\n            expect(item_one.column_string).to.be.a('number');\n            expect(item_one.column_datetime).to.be.a('number');\n            expect(tableAfter).to.equal(\"CREATE TABLE \\\"alter_table\\\" (`column_integer` varchar(255), `column_string` integer, `column_datetime` date, `column_defaultTo` integer DEFAULT '0', `column_notNullable` varchar(255) NOT NULL, `column_defaultToAndNotNullable` datetime NOT NULL DEFAULT '0', `column_nullable` boolean NULL)\");\n          });","file":"integration2/schema/alter.spec.js","skipped":false,"dir":"test"},{"name":"adds default and not null constraints","suites":["Schema","Alter","alterColumns"],"updatePoint":{"line":86,"column":51,"index":3508},"line":86,"code":"          it('adds default and not null constraints', async () => {\n            await knex.schema.alterTable('alter_table', table => {\n              table.integer('column_integer').defaultTo(0).alter();\n              table.string('column_string').notNullable().alter();\n              table.dateTime('column_datetime').defaultTo(0).notNullable().alter();\n            });\n            await knex('alter_table').insert({\n              column_string: '1',\n              column_notNullable: 'text'\n            });\n            const item_two = (await knex('alter_table'))[1];\n            const tableAfter = (await knex.raw(QUERY_TABLE))[0].sql;\n            expect(item_two.column_integer).to.equal(0);\n            expect(item_two.column_datetime).to.equal(0);\n            await expect(knex('alter_table').insert({\n              column_notNullable: 'text'\n            })).to.be.rejectedWith(Error, \"insert into `alter_table` (`column_notNullable`) values ('text') - SQLITE_CONSTRAINT_NOTNULL: NOT NULL constraint failed: alter_table.column_string\");\n            expect(tableAfter).to.equal(\"CREATE TABLE \\\"alter_table\\\" (`column_integer` integer DEFAULT '0', `column_string` varchar(255) NOT NULL, `column_datetime` datetime NOT NULL DEFAULT '0', `column_defaultTo` integer DEFAULT '0', `column_notNullable` varchar(255) NOT NULL, `column_defaultToAndNotNullable` datetime NOT NULL DEFAULT '0', `column_nullable` boolean NULL)\");\n          });","file":"integration2/schema/alter.spec.js","skipped":false,"dir":"test"},{"name":"removes not specified default and not null constraints","suites":["Schema","Alter","alterColumns"],"updatePoint":{"line":105,"column":68,"index":4961},"line":105,"code":"          it('removes not specified default and not null constraints', async () => {\n            await knex.schema.alterTable('alter_table', table => {\n              table.integer('column_defaultTo').alter();\n              table.string('column_notNullable').alter();\n              table.dateTime('column_defaultToAndNotNullable').alter();\n            });\n            await knex('alter_table').insert({});\n            const item_two = (await knex('alter_table'))[1];\n            const tableAfter = (await knex.raw(QUERY_TABLE))[0].sql;\n            expect(item_two.column_defaultTo).to.be.null;\n            expect(item_two.column_notNullable).to.be.null;\n            expect(item_two.column_defaultToAndNotNullable).to.be.null;\n            expect(tableAfter).to.equal('CREATE TABLE \"alter_table\" (`column_integer` integer, `column_string` varchar(255), `column_datetime` datetime, `column_defaultTo` integer, `column_notNullable` varchar(255), `column_defaultToAndNotNullable` datetime, `column_nullable` boolean NULL)');\n          });","file":"integration2/schema/alter.spec.js","skipped":false,"dir":"test"},{"name":"removes an existing null constraint if a not null constraint is added to a column","suites":["Schema","Alter","alterColumns"],"updatePoint":{"line":119,"column":95,"index":6021},"line":119,"code":"          it('removes an existing null constraint if a not null constraint is added to a column', async () => {\n            await knex.schema.alterTable('alter_table', table => {\n              table.boolean('column_nullable').notNullable().alter();\n            });\n            const tableAfter = (await knex.raw(QUERY_TABLE))[0].sql;\n            await expect(knex('alter_table').insert({\n              column_notNullable: 'text'\n            })).to.be.rejectedWith(Error, \"insert into `alter_table` (`column_notNullable`) values ('text') - SQLITE_CONSTRAINT_NOTNULL: NOT NULL constraint failed: alter_table.column_nullable\");\n            expect(tableAfter).to.equal(\"CREATE TABLE \\\"alter_table\\\" (`column_integer` integer, `column_string` varchar(255), `column_datetime` datetime, `column_defaultTo` integer DEFAULT '0', `column_notNullable` varchar(255) NOT NULL, `column_defaultToAndNotNullable` datetime NOT NULL DEFAULT '0', `column_nullable` boolean NOT NULL)\");\n          });","file":"integration2/schema/alter.spec.js","skipped":false,"dir":"test"},{"name":"generates correct SQL commands when altering columns","suites":["Schema","Alter","alterColumns"],"updatePoint":{"line":129,"column":66,"index":6973},"line":129,"code":"          it('generates correct SQL commands when altering columns', async () => {\n            const builder = knex.schema.alterTable('alter_table', table => {\n              table.string('column_integer').alter();\n            });\n            const queries = await builder.generateDdlCommands();\n            expect(queries.sql).to.deep.equal([\"CREATE TABLE `_knex_temp_alter111` (`column_integer` varchar(255), `column_string` varchar(255), `column_datetime` datetime, `column_defaultTo` integer DEFAULT '0', `column_notNullable` varchar(255) NOT NULL, `column_defaultToAndNotNullable` datetime NOT NULL DEFAULT '0', `column_nullable` boolean NULL)\", 'INSERT INTO \"_knex_temp_alter111\" SELECT * FROM \"alter_table\";', 'DROP TABLE \"alter_table\"', 'ALTER TABLE \"_knex_temp_alter111\" RENAME TO \"alter_table\"']);\n          });","file":"integration2/schema/alter.spec.js","skipped":false,"dir":"test"},{"name":"create table with raw check on table","suites":["Checks"],"updatePoint":{"line":58,"column":46,"index":1499},"line":58,"code":"      it('create table with raw check on table', async () => {\n        await knex.schema.dropTableIfExists('check_test');\n        await knex.schema.createTable('check_test', function (table) {\n          table.string('col1');\n          table.string('col2');\n          table.check('?? = ??', ['col1', 'col2']);\n        }).testSql(tester => {\n          tester(['pg', 'pg-redshift', 'cockroachdb'], ['create table \"check_test\" (\"col1\" varchar(255), \"col2\" varchar(255), check (\"col1\" = \"col2\"))']);\n          tester(['oracledb'], ['create table \"check_test\" (\"name\" varchar2(255) check (\"name\" LIKE \\'%val%\\'))']);\n          tester('mysql', ['create table `check_test` (`col1` varchar(255), `col2` varchar(255), check (`col1` = `col2`)) default character set utf8']);\n          tester('sqlite3', ['create table `check_test` (`col1` varchar(255), `col2` varchar(255), check (`col1` = `col2`))']);\n          tester('mssql', ['CREATE TABLE [check_test] ([col1] nvarchar(255), [col2] nvarchar(255), check ([col1] = [col2]))']);\n        });\n        await checkTest({\n          col1: 'test',\n          col2: 'test'\n        }, {\n          col1: 'test',\n          col2: 'test2'\n        });\n      });","file":"integration2/schema/checks.spec.js","skipped":false,"dir":"test"},{"name":"create table with numeric positive check","suites":["Checks"],"updatePoint":{"line":79,"column":50,"index":2691},"line":79,"code":"      it('create table with numeric positive check', async () => {\n        await knex.schema.dropTableIfExists('check_test');\n        await knex.schema.createTable('check_test', function (table) {\n          table.integer('price').checkPositive();\n        }).testSql(tester => {\n          tester(['pg', 'pg-redshift', 'cockroachdb', 'oracledb'], ['create table \"check_test\" (\"price\" integer check (\"price\" > 0))']);\n          tester('mysql', ['create table `check_test` (`price` int check (`price` > 0)) default character set utf8']);\n          tester('sqlite3', ['create table `check_test` (`price` integer check (`price` > 0))']);\n          tester('mssql', ['CREATE TABLE [check_test] ([price] int check ([price] > 0))']);\n        });\n        await checkTest({\n          price: 10\n        }, {\n          price: -5\n        });\n      });","file":"integration2/schema/checks.spec.js","skipped":false,"dir":"test"},{"name":"create table with numeric negative check","suites":["Checks"],"updatePoint":{"line":95,"column":50,"index":3528},"line":95,"code":"      it('create table with numeric negative check', async () => {\n        await knex.schema.dropTableIfExists('check_test');\n        await knex.schema.createTable('check_test', function (table) {\n          table.integer('price').checkNegative();\n        }).testSql(tester => {\n          tester(['pg', 'pg-redshift', 'cockroachdb', 'oracledb'], ['create table \"check_test\" (\"price\" integer check (\"price\" < 0))']);\n          tester('mysql', ['create table `check_test` (`price` int check (`price` < 0)) default character set utf8']);\n          tester('sqlite3', ['create table `check_test` (`price` integer check (`price` < 0))']);\n          tester('mssql', ['CREATE TABLE [check_test] ([price] int check ([price] < 0))']);\n        });\n        await checkTest({\n          price: -5\n        }, {\n          price: 10\n        });\n      });","file":"integration2/schema/checks.spec.js","skipped":false,"dir":"test"},{"name":"create table with check in","suites":["Checks"],"updatePoint":{"line":111,"column":36,"index":4351},"line":111,"code":"      it('create table with check in', async () => {\n        await knex.schema.dropTableIfExists('check_test');\n        await knex.schema.createTable('check_test', function (table) {\n          table.string('animal').checkIn(['dog', 'cat']);\n        }).testSql(tester => {\n          tester(['pg', 'pg-redshift', 'cockroachdb'], ['create table \"check_test\" (\"animal\" varchar(255) check (\"animal\" in (\\'dog\\',\\'cat\\')))']);\n          tester('oracledb', ['create table \"check_test\" (\"animal\" varchar2(255) check (\"animal\" in (\\'dog\\', \\'cat\\')))']);\n          tester('mysql', [\"create table `check_test` (`animal` varchar(255) check (`animal` in ('dog','cat'))) default character set utf8\"]);\n          tester('sqlite3', [\"create table `check_test` (`animal` varchar(255) check (`animal` in ('dog','cat')))\"]);\n          tester('mssql', [\"CREATE TABLE [check_test] ([animal] nvarchar(255) check ([animal] in ('dog','cat')))\"]);\n        });\n        await checkTest({\n          animal: 'dog'\n        }, {\n          animal: 'pig'\n        });\n        await checkTest({\n          animal: 'cat'\n        }, {\n          animal: 'pig'\n        });\n      });","file":"integration2/schema/checks.spec.js","skipped":false,"dir":"test"},{"name":"create table with check not in","suites":["Checks"],"updatePoint":{"line":133,"column":40,"index":5499},"line":133,"code":"      it('create table with check not in', async () => {\n        await knex.schema.dropTableIfExists('check_test');\n        await knex.schema.createTable('check_test', function (table) {\n          table.string('animal').checkNotIn(['dog', 'cat']);\n        }).testSql(tester => {\n          tester(['pg', 'pg-redshift', 'cockroachdb'], ['create table \"check_test\" (\"animal\" varchar(255) check (\"animal\" not in (\\'dog\\',\\'cat\\')))']);\n          tester('oracledb', ['create table \"check_test\" (\"animal\" varchar2(255) check (\"animal\" not in (\\'dog\\',\\'cat\\')))']);\n          tester('mysql', [\"create table `check_test` (`animal` varchar(255) check (`animal` not in ('dog','cat'))) default character set utf8\"]);\n          tester('sqlite3', [\"create table `check_test` (`animal` varchar(255) check (`animal` not in ('dog','cat')))\"]);\n          tester('mssql', [\"CREATE TABLE [check_test] ([animal] nvarchar(255) check ([animal] not in ('dog','cat')))\"]);\n        });\n        await checkTest({\n          animal: 'pg'\n        }, {\n          animal: 'cat'\n        });\n        await checkTest({\n          animal: 'mammoth'\n        }, {\n          animal: 'cat'\n        });\n      });","file":"integration2/schema/checks.spec.js","skipped":false,"dir":"test"},{"name":"create table with check between","suites":["Checks"],"updatePoint":{"line":155,"column":41,"index":6673},"line":155,"code":"      it('create table with check between', async () => {\n        await knex.schema.dropTableIfExists('check_test');\n        await knex.schema.createTable('check_test', function (table) {\n          table.integer('price').checkBetween([10, 20]);\n        }).testSql(tester => {\n          tester(['pg', 'pg-redshift', 'cockroachdb', 'oracledb'], ['create table \"check_test\" (\"price\" integer check (\"price\" between 10 and 20))']);\n          tester('mysql', ['create table `check_test` (`price` int check (`price` between 10 and 20)) default character set utf8']);\n          tester('sqlite3', ['create table `check_test` (`price` integer check (`price` between 10 and 20))']);\n          tester('mssql', ['CREATE TABLE [check_test] ([price] int check ([price] between 10 and 20))']);\n        });\n        await checkTest({\n          price: 10\n        }, {\n          price: 25\n        });\n      });","file":"integration2/schema/checks.spec.js","skipped":false,"dir":"test"},{"name":"create table with check between with multiple intervals","suites":["Checks"],"updatePoint":{"line":171,"column":65,"index":7588},"line":171,"code":"      it('create table with check between with multiple intervals', async () => {\n        await knex.schema.dropTableIfExists('check_test');\n        await knex.schema.createTable('check_test', function (table) {\n          table.integer('price').checkBetween([[10, 20], [30, 40]]);\n        }).testSql(tester => {\n          tester(['pg', 'pg-redshift', 'cockroachdb', 'oracledb'], ['create table \"check_test\" (\"price\" integer check (\"price\" between 10 and 20 or \"price\" between 30 and 40))']);\n          tester('mysql', ['create table `check_test` (`price` int check (`price` between 10 and 20 or `price` between 30 and 40)) default character set utf8']);\n          tester('sqlite3', ['create table `check_test` (`price` integer check (`price` between 10 and 20 or `price` between 30 and 40))']);\n          tester('mssql', ['CREATE TABLE [check_test] ([price] int check ([price] between 10 and 20 or [price] between 30 and 40))']);\n        });\n        await checkTest({\n          price: 15\n        }, {\n          price: 25\n        });\n        await checkTest({\n          price: 35\n        }, {\n          price: 45\n        });\n      });","file":"integration2/schema/checks.spec.js","skipped":false,"dir":"test"},{"name":"create table with check length","suites":["Checks"],"updatePoint":{"line":192,"column":40,"index":8697},"line":192,"code":"      it('create table with check length', async () => {\n        await knex.schema.dropTableIfExists('check_test');\n        await knex.schema.createTable('check_test', function (table) {\n          table.string('year').checkLength('=', 4);\n        }).testSql(tester => {\n          tester(['pg', 'pg-redshift', 'cockroachdb'], ['create table \"check_test\" (\"year\" varchar(255) check (length(\"year\") = 4))']);\n          tester('oracledb', ['create table \"check_test\" (\"year\" varchar2(255) check (length(\"year\") = 4))']);\n          tester('mysql', ['create table `check_test` (`year` varchar(255) check (length(`year`) = 4)) default character set utf8']);\n          tester('sqlite3', ['create table `check_test` (`year` varchar(255) check (length(`year`) = 4))']);\n          tester('mssql', ['CREATE TABLE [check_test] ([year] nvarchar(255) check (LEN([year]) = 4))']);\n        });\n        await checkTest({\n          year: '2021'\n        }, {\n          year: '21'\n        });\n      });","file":"integration2/schema/checks.spec.js","skipped":false,"dir":"test"},{"name":"create table with check regex","suites":["Checks"],"updatePoint":{"line":209,"column":39,"index":9678},"line":209,"code":"      it('create table with check regex', async function () {\n        if (isMssql(knex) || isSQLite(knex)) {\n          this.skip();\n        }\n\n        await knex.schema.dropTableIfExists('check_test');\n        await knex.schema.createTable('check_test', function (table) {\n          table.string('date').checkRegex('[0-9]{2}-[0-9]{2}-[0-9]{4}');\n        }).testSql(tester => {\n          tester(['pg', 'pg-redshift', 'cockroachdb'], ['create table \"check_test\" (\"date\" varchar(255) check (\"date\" ~ \\'[0-9]{2}-[0-9]{2}-[0-9]{4}\\'))']);\n          tester('oracledb', ['create table \"check_test\" (\"date\" varchar2(255) check (REGEXP_LIKE(\"date\",\\'[0-9]{2}-[0-9]{2}-[0-9]{4}\\')))']);\n          tester('mysql', [\"create table `check_test` (`date` varchar(255) check (`date` REGEXP '[0-9]{2}-[0-9]{2}-[0-9]{4}')) default character set utf8\"]);\n        });\n        await checkTest({\n          date: '01-02-2021'\n        }, {\n          date: '01/02/2021'\n        });\n        await checkTest({\n          date: '01-02-2021'\n        }, {\n          date: '01-02-221'\n        });\n      });","file":"integration2/schema/checks.spec.js","skipped":false,"dir":"test"},{"name":"drop checks","suites":["Checks"],"updatePoint":{"line":233,"column":21,"index":10734},"line":233,"code":"      it('drop checks', async function () {\n        if (isSQLite(knex)) {\n          this.skip();\n        }\n\n        await knex.schema.dropTableIfExists('check_test');\n        await knex.schema.createTable('check_test', function (table) {\n          table.integer('price').checkPositive('price_pos_check');\n        });\n        await checkTest({\n          price: 10\n        }, {\n          price: -5\n        });\n        await knex.schema.table('check_test', function (table) {\n          table.dropChecks('price_pos_check');\n        }).testSql(tester => {\n          tester(['pg', 'pg-redshift', 'cockroachdb', 'oracledb'], ['alter table \"check_test\" drop constraint price_pos_check']);\n          tester('mysql', ['alter table `check_test` drop constraint price_pos_check']);\n        }); // Now, insert negative value work.\n\n        expect(await knex('check_test').insert([{\n          price: -5\n        }])).to.not.throw;\n      });","file":"integration2/schema/checks.spec.js","skipped":false,"dir":"test"},{"name":"create table with custom check","suites":["Checks"],"updatePoint":{"line":258,"column":40,"index":11679},"line":258,"code":"      it('create table with custom check', async function () {\n        await knex.schema.dropTableIfExists('check_test');\n        await knex.schema.createTable('check_test', table => {\n          table.integer('price_min');\n          table.integer('price_max');\n          table.check('?? < ??', ['price_min', 'price_max'], 'price_min_lower_max').check('?? > 5', ['price_min']);\n        }).testSql(tester => {\n          tester(['pg', 'pg-redshift', 'cockroachdb'], ['create table \"check_test\" (\"price_min\" integer, \"price_max\" integer, constraint price_min_lower_max check (\"price_min\" < \"price_max\"), check (\"price_min\" > 5))']);\n          tester('oracledb', ['create table \"check_test\" (\"price_min\" integer, \"price_max\" integer, constraint price_min_lower_max check (\"price_min\" < \"price_max\"), check (\"price_min\" > 5))']);\n          tester('mysql', ['create table `check_test` (`price_min` int, `price_max` int, constraint price_min_lower_max check (`price_min` < `price_max`), check (`price_min` > 5)) default character set utf8']);\n          tester('mssql', ['CREATE TABLE [check_test] ([price_min] int, [price_max] int, constraint price_min_lower_max check ([price_min] < [price_max]), check ([price_min] > 5))']);\n        });\n        await checkTest({\n          price_min: 10,\n          price_max: 20\n        }, {\n          price_min: 10,\n          price_max: 5\n        });\n        await checkTest({\n          price_min: 10,\n          price_max: 20\n        }, {\n          price_min: 0,\n          price_max: 5\n        });\n      });","file":"integration2/schema/checks.spec.js","skipped":false,"dir":"test"},{"name":"create table with checks then alter","suites":["Checks"],"updatePoint":{"line":285,"column":45,"index":13220},"line":285,"code":"      it('create table with checks then alter', async function () {\n        if (isSQLite(knex)) {\n          this.skip();\n        }\n\n        await knex.schema.dropTableIfExists('check_test');\n        await knex.schema.createTable('check_test', table => {\n          table.integer('price');\n        });\n        expect(await knex('check_test').insert([{\n          price: -5\n        }])).to.not.throw; // Alter table with check constraint fail, we have row that violated the constraint\n\n        let error;\n\n        try {\n          await knex.schema.table('check_test', table => {\n            table.integer('price').checkPositive().alter();\n          });\n        } catch (e) {\n          error = e;\n        }\n\n        expect(error.message).to.not.undefined; // empty the table to add the constraint\n\n        await knex('check_test').truncate();\n        await knex.schema.table('check_test', table => {\n          table.integer('price').checkPositive().alter();\n        }).testSql(tester => {\n          tester(['pg', 'pg-redshift'], ['alter table \"check_test\" alter column \"price\" drop default', 'alter table \"check_test\" alter column \"price\" drop not null', 'alter table \"check_test\" alter column \"price\" type integer using (\"price\"::integer)', 'alter table \"check_test\" add constraint check_test_price_1 check(\"price\" > 0)']);\n          tester('cockroachdb', ['SET enable_experimental_alter_column_type_general = true', 'alter table \"check_test\" alter column \"price\" drop default', 'alter table \"check_test\" alter column \"price\" drop not null', 'alter table \"check_test\" alter column \"price\" type integer using (\"price\"::integer)', 'alter table \"check_test\" add constraint check_test_price_1 check(\"price\" > 0)']);\n          tester('oracledb', ['alter table \"check_test\" modify \"price\" integer', 'alter table \"check_test\" add constraint check_test_price_1 check(\"price\" > 0)']);\n          tester('mysql', ['alter table `check_test` modify `price` int', 'alter table `check_test` add constraint check_test_price_1 check(`price` > 0)']);\n        });\n        await checkTest({\n          price: 10\n        }, {\n          price: -10\n        });\n      });","file":"integration2/schema/checks.spec.js","skipped":false,"dir":"test"},{"name":"Creates native enums","suites":["Schema","native enum columns"],"updatePoint":{"line":56,"column":32,"index":1575},"line":56,"code":"        it('Creates native enums', async () => {\n          for (const enumColumn of enumColumns) {\n            const res = await knex.select('data_type', 'udt_name').from('information_schema.columns').where({\n              table_name: tblName,\n              column_name: enumColumn.column\n            });\n            expect(res[0].data_type).to.equal('USER-DEFINED');\n            expect(res[0].udt_name).to.equal(enumColumn.typeName);\n          }\n        });","file":"integration2/schema/enum-native.spec.js","skipped":false,"dir":"test"},{"name":"Allows altering native enums","suites":["Schema","native enum columns","Altering"],"updatePoint":{"line":78,"column":42,"index":2523},"line":78,"code":"          it('Allows altering native enums', async () => {\n            await knex.schema.alterTable(tblName, table => {\n              table.enum(enumColumn, ['altered', 'values'], {\n                useNative: true,\n                enumName: enumTypeName\n              }).alter();\n            });\n            const res = await knex.select('data_type', 'udt_name').from('information_schema.columns').where({\n              table_name: tblName,\n              column_name: enumColumn\n            });\n            expect(res[0].data_type).to.equal('USER-DEFINED');\n            expect(res[0].udt_name).to.equal(enumTypeName);\n          });","file":"integration2/schema/enum-native.spec.js","skipped":false,"dir":"test"},{"name":"generates correct SQL for the new foreign key operation","suites":["Schema","Foreign keys","createForeignKey"],"updatePoint":{"line":53,"column":69,"index":1743},"line":53,"code":"          it('generates correct SQL for the new foreign key operation', async () => {\n            await knex('foreign_keys_table_two').insert({});\n            await knex('foreign_keys_table_three').insert({});\n            await knex('foreign_keys_table_one').insert({\n              fkey_two: 1,\n              fkey_three: 1\n            });\n            await knex('foreign_keys_table_one').insert({\n              fkey_two: 1,\n              fkey_three: 1\n            });\n            const builder = knex.schema.alterTable('foreign_keys_table_one', table => {\n              table.foreign('fkey_three').references('foreign_keys_table_three.id').withKeyName('fk_fkey_threeee');\n            });\n            const queries = await builder.generateDdlCommands();\n\n            if (isSQLite(knex)) {\n              expect(queries.sql).to.eql(['CREATE TABLE `_knex_temp_alter111` (`id` integer PRIMARY KEY AUTOINCREMENT NOT NULL, `fkey_two` integer NOT NULL, `fkey_three` integer NOT NULL, CONSTRAINT `fk_fkey_threeee` FOREIGN KEY (`fkey_three`) REFERENCES `foreign_keys_table_three` (`id`))', 'INSERT INTO \"_knex_temp_alter111\" SELECT * FROM \"foreign_keys_table_one\";', 'DROP TABLE \"foreign_keys_table_one\"', 'ALTER TABLE \"_knex_temp_alter111\" RENAME TO \"foreign_keys_table_one\"']);\n            }\n\n            if (isPostgreSQL(knex)) {\n              expect(queries.sql).to.eql([{\n                bindings: [],\n                sql: 'alter table \"foreign_keys_table_one\" add constraint \"fk_fkey_threeee\" foreign key (\"fkey_three\") references \"foreign_keys_table_three\" (\"id\")'\n              }]);\n            }\n          });","file":"integration2/schema/foreign-keys.spec.js","skipped":false,"dir":"test"},{"name":"generates correct SQL for the new foreign key operation with an on delete clause","suites":["Schema","Foreign keys","createForeignKey"],"updatePoint":{"line":80,"column":94,"index":3377},"line":80,"code":"          it('generates correct SQL for the new foreign key operation with an on delete clause', async () => {\n            if (!isSQLite(knex)) {\n              return;\n            }\n\n            const builder = knex.schema.alterTable('foreign_keys_table_one', table => {\n              table.foreign('fkey_three').references('foreign_keys_table_three.id').withKeyName('fk_fkey_threeee').onDelete('CASCADE');\n            });\n            const queries = await builder.generateDdlCommands();\n            expect(queries.sql).to.eql(['CREATE TABLE `_knex_temp_alter111` (`id` integer PRIMARY KEY AUTOINCREMENT NOT NULL, `fkey_two` integer NOT NULL, `fkey_three` integer NOT NULL, CONSTRAINT `fk_fkey_threeee` FOREIGN KEY (`fkey_three`) REFERENCES `foreign_keys_table_three` (`id`) ON DELETE CASCADE)', 'INSERT INTO \"_knex_temp_alter111\" SELECT * FROM \"foreign_keys_table_one\";', 'DROP TABLE \"foreign_keys_table_one\"', 'ALTER TABLE \"_knex_temp_alter111\" RENAME TO \"foreign_keys_table_one\"']);\n          });","file":"integration2/schema/foreign-keys.spec.js","skipped":false,"dir":"test"},{"name":"generates correct SQL for the new foreign key operation with an on update clause","suites":["Schema","Foreign keys","createForeignKey"],"updatePoint":{"line":91,"column":94,"index":4377},"line":91,"code":"          it('generates correct SQL for the new foreign key operation with an on update clause', async () => {\n            if (!isSQLite(knex)) {\n              return;\n            }\n\n            const builder = knex.schema.alterTable('foreign_keys_table_one', table => {\n              table.foreign('fkey_three').references('foreign_keys_table_three.id').withKeyName('fk_fkey_threeee').onUpdate('CASCADE');\n            });\n            const queries = await builder.generateDdlCommands();\n            expect(queries.sql).to.eql(['CREATE TABLE `_knex_temp_alter111` (`id` integer PRIMARY KEY AUTOINCREMENT NOT NULL, `fkey_two` integer NOT NULL, `fkey_three` integer NOT NULL, CONSTRAINT `fk_fkey_threeee` FOREIGN KEY (`fkey_three`) REFERENCES `foreign_keys_table_three` (`id`) ON UPDATE CASCADE)', 'INSERT INTO \"_knex_temp_alter111\" SELECT * FROM \"foreign_keys_table_one\";', 'DROP TABLE \"foreign_keys_table_one\"', 'ALTER TABLE \"_knex_temp_alter111\" RENAME TO \"foreign_keys_table_one\"']);\n          });","file":"integration2/schema/foreign-keys.spec.js","skipped":false,"dir":"test"},{"name":"creates new foreign key","suites":["Schema","Foreign keys","createForeignKey"],"updatePoint":{"line":102,"column":37,"index":5320},"line":102,"code":"          it('creates new foreign key', async () => {\n            await knex('foreign_keys_table_two').insert({});\n            await knex('foreign_keys_table_three').insert({});\n            const rowsTwo = await knex('foreign_keys_table_two').select();\n            const rowsThree = await knex('foreign_keys_table_three').select();\n            const idTwo = rowsTwo[0].id;\n            const idThree = rowsThree[0].id;\n            await knex('foreign_keys_table_one').insert({\n              fkey_two: idTwo,\n              fkey_three: idThree\n            });\n            await knex('foreign_keys_table_one').insert({\n              fkey_two: idTwo,\n              fkey_three: idThree\n            });\n            const rowsOne = await knex('foreign_keys_table_one').select();\n            const idOne1 = rowsOne[0].id;\n            const idOne2 = rowsOne[1].id;\n            await knex.schema.alterTable('foreign_keys_table_one', table => {\n              table.foreign('fkey_three').references('foreign_keys_table_three.id').withKeyName('fk_fkey_threeee');\n            });\n            const existingRows = await knex('foreign_keys_table_one').select();\n            expect(existingRows).to.eql([{\n              fkey_three: idThree,\n              fkey_two: idTwo,\n              id: idOne1\n            }, {\n              fkey_three: idThree,\n              fkey_two: idTwo,\n              id: idOne2\n            }]);\n            await knex('foreign_keys_table_two').insert({});\n            await knex('foreign_keys_table_three').insert({});\n            await knex('foreign_keys_table_one').insert({\n              fkey_two: idTwo,\n              fkey_three: idThree\n            });\n\n            try {\n              await knex('foreign_keys_table_one').insert({\n                fkey_two: 9999,\n                fkey_three: 99\n              });\n              throw new Error(\"Shouldn't reach this\");\n            } catch (err) {\n              if (isBetterSQLite3(knex)) {\n                expect(err.message).to.equal(`insert into \\`foreign_keys_table_one\\` (\\`fkey_three\\`, \\`fkey_two\\`) values (99, 9999) - FOREIGN KEY constraint failed`);\n              } else if (isSQLite(knex)) {\n                expect(err.message).to.equal(`insert into \\`foreign_keys_table_one\\` (\\`fkey_three\\`, \\`fkey_two\\`) values (99, 9999) - SQLITE_CONSTRAINT_FOREIGNKEY: FOREIGN KEY constraint failed`);\n              }\n\n              if (isPostgreSQL(knex)) {\n                expect(err.message).to.equal(`insert into \"foreign_keys_table_one\" (\"fkey_three\", \"fkey_two\") values ($1, $2) - insert or update on table \"foreign_keys_table_one\" violates foreign key constraint \"fk_fkey_threeee\"`);\n              }\n\n              if (isCockroachDB(knex)) {\n                expect(err.message).to.equal(`insert into \"foreign_keys_table_one\" (\"fkey_three\", \"fkey_two\") values ($1, $2) - insert on table \"foreign_keys_table_one\" violates foreign key constraint \"fk_fkey_threeee\"`);\n              }\n\n              expect(err.message).to.include('constraint');\n            }\n          });","file":"integration2/schema/foreign-keys.spec.js","skipped":false,"dir":"test"},{"name":"can add a new column with a foreign key constraint","suites":["Schema","Foreign keys","createForeignKey"],"updatePoint":{"line":164,"column":64,"index":8385},"line":164,"code":"          it('can add a new column with a foreign key constraint', async () => {\n            await knex.schema.alterTable('foreign_keys_table_one', table => {\n              table.integer('fkey_new').unsigned().notNull().references('foreign_keys_table_two.id');\n            });\n            await knex('foreign_keys_table_two').insert({});\n            await knex('foreign_keys_table_three').insert({});\n            await expect(knex('foreign_keys_table_one').insert({\n              fkey_two: 1,\n              fkey_three: 1,\n              fkey_new: 2\n            })).to.be.eventually.rejected;\n          });","file":"integration2/schema/foreign-keys.spec.js","skipped":false,"dir":"test"},{"name":"can drop added foreign keys in sqlite after a table rebuild","suites":["Schema","Foreign keys","createForeignKey"],"updatePoint":{"line":176,"column":73,"index":8999},"line":176,"code":"          it('can drop added foreign keys in sqlite after a table rebuild', async () => {\n            if (!isSQLite(knex)) {\n              return;\n            }\n\n            await knex.schema.alterTable('foreign_keys_table_one', table => {\n              table.foreign('fkey_three').references('foreign_keys_table_three.id');\n            });\n            await knex.schema.alterTable('foreign_keys_table_one', table => {\n              // In sqlite this rebuilds a new foreign_keys_table_one table\n              table.foreign('fkey_two').references('foreign_keys_table_two.id');\n            });\n            await knex.schema.alterTable('foreign_keys_table_one', table => {\n              table.dropForeign('fkey_three');\n            });\n            const fks = await knex.raw(`PRAGMA foreign_key_list('foreign_keys_table_one');`);\n            expect(fks.length).to.equal(1);\n          });","file":"integration2/schema/foreign-keys.spec.js","skipped":false,"dir":"test"},{"name":"can alter a table in sqlite while another table has a foreign key constraint on this table","suites":["Schema","Foreign keys","createForeignKey"],"updatePoint":{"line":194,"column":104,"index":9915},"line":194,"code":"          it('can alter a table in sqlite while another table has a foreign key constraint on this table', async () => {\n            if (!isSQLite(knex)) {\n              return;\n            }\n\n            await knex.schema.alterTable('foreign_keys_table_two', table => {\n              table.integer('alter_column');\n            });\n            await knex.schema.alterTable('foreign_keys_table_one', table => {\n              table.foreign('fkey_two').references('foreign_keys_table_two.id');\n            });\n            await knex('foreign_keys_table_two').insert({\n              alter_column: 1\n            });\n            await knex('foreign_keys_table_one').insert({\n              fkey_two: 1,\n              fkey_three: 1\n            });\n            await expect(knex.schema.alterTable('foreign_keys_table_two', table => {\n              table.dropColumn('alter_column');\n            })).to.not.be.eventually.rejected;\n          });","file":"integration2/schema/foreign-keys.spec.js","skipped":false,"dir":"test"},{"name":"correctly drops foreign key","suites":["Schema","Foreign keys","Schema (Foreign keys)","drop foreign key"],"updatePoint":{"line":239,"column":43,"index":12073},"line":239,"code":"            it('correctly drops foreign key', async () => {\n              await knex('foreign_keys_table_two').insert({});\n              await knex('foreign_keys_table_three').insert({});\n              await knex('foreign_keys_table_four').insert({\n                col1: 'a',\n                col2: 'b'\n              });\n              const tableTwoEntry = await knex('foreign_keys_table_two').select();\n              const tableThreeEntry = await knex('foreign_keys_table_three').select();\n              await knex('foreign_keys_table_one').insert({\n                fkey_two: tableTwoEntry[0].id,\n                fkey_three: tableThreeEntry[0].id,\n                fkey_four_part1: 'a',\n                fkey_four_part2: 'b'\n              });\n\n              try {\n                await knex('foreign_keys_table_one').insert({\n                  fkey_two: 9999,\n                  fkey_three: 99,\n                  fkey_four_part1: 'a',\n                  fkey_four_part2: 'b'\n                });\n                throw new Error(\"Shouldn't reach this\");\n              } catch (err) {\n                if (isBetterSQLite3(knex)) {\n                  expect(err.message).to.equal(`insert into \\`foreign_keys_table_one\\` (\\`fkey_four_part1\\`, \\`fkey_four_part2\\`, \\`fkey_three\\`, \\`fkey_two\\`) values ('a', 'b', 99, 9999) - FOREIGN KEY constraint failed`);\n                } else if (isSQLite(knex)) {\n                  expect(err.message).to.equal(`insert into \\`foreign_keys_table_one\\` (\\`fkey_four_part1\\`, \\`fkey_four_part2\\`, \\`fkey_three\\`, \\`fkey_two\\`) values ('a', 'b', 99, 9999) - SQLITE_CONSTRAINT_FOREIGNKEY: FOREIGN KEY constraint failed`);\n                }\n\n                if (isPostgreSQL(knex)) {\n                  expect(err.message).to.equal(`insert into \"foreign_keys_table_one\" (\"fkey_four_part1\", \"fkey_four_part2\", \"fkey_three\", \"fkey_two\") values ($1, $2, $3, $4) - insert or update on table \"foreign_keys_table_one\" violates foreign key constraint \"foreign_keys_table_one_fkey_two_foreign\"`);\n                }\n\n                if (isCockroachDB(knex)) {\n                  expect(err.message).to.equal(`insert into \"foreign_keys_table_one\" (\"fkey_four_part1\", \"fkey_four_part2\", \"fkey_three\", \"fkey_two\") values ($1, $2, $3, $4) - insert on table \"foreign_keys_table_one\" violates foreign key constraint \"foreign_keys_table_one_fkey_two_foreign\"`);\n                }\n\n                expect(err.message).to.include('constraint');\n              }\n\n              await knex.schema.alterTable('foreign_keys_table_one', table => {\n                table.dropForeign(['fkey_two']);\n                table.dropForeign([], 'fk_fkey_threeee');\n                table.dropForeign(['fkey_four_part1', 'fkey_four_part2']);\n              });\n              await knex('foreign_keys_table_one').insert({\n                fkey_two: 999,\n                fkey_three: 999,\n                fkey_four_part1: 'e',\n                fkey_four_part2: 'f'\n              });\n            });","file":"integration2/schema/foreign-keys.spec.js","skipped":false,"dir":"test"},{"name":"Creates POINT column for supported databases","suites":["Schema","geometry columns"],"updatePoint":{"line":31,"column":56,"index":689},"line":31,"code":"        it('Creates POINT column for supported databases', async function () {\n          if (isCockroachDB(knex) || isMssql(knex)) {\n            return this.skip();\n          }\n\n          await knex.schema.createTable(tblName, table => {\n            table.point('pointColumn');\n          });\n\n          if (isPostgreSQL(knex)) {\n            await knex(tblName).insert({\n              pointColumn: '2, 3'\n            });\n            const result = await knex(tblName).select('*');\n            expect(result).to.eql([{\n              pointColumn: {\n                x: 2,\n                y: 3\n              }\n            }]);\n          }\n        });","file":"integration2/schema/geometry-columns.spec.js","skipped":false,"dir":"test"},{"name":"Creates GEOMETRY column for supported databases","suites":["Schema","geometry columns"],"updatePoint":{"line":53,"column":59,"index":1338},"line":53,"code":"        it('Creates GEOMETRY column for supported databases', async function () {\n          if (isPgBased(knex)) {\n            return this.skip();\n          }\n\n          await knex.schema.createTable(tblName, table => {\n            table.geometry('geometryColumn');\n          });\n\n          if (isPostgreSQL(knex)) {\n            await knex(tblName).insert({\n              geometryColumn: '2, 3'\n            });\n            const result = await knex(tblName).select('*');\n            expect(result).to.eql([{\n              geometryColumn: {\n                x: 2,\n                y: 3\n              }\n            }]);\n          }\n\n          if (isSQLite(knex)) {\n            await knex(tblName).insert({\n              geometryColumn: '2, 3'\n            });\n            const result = await knex(tblName).select('*');\n            expect(result).to.eql([{\n              geometryColumn: '2, 3'\n            }]);\n          }\n\n          if (isMssql(knex)) {\n            await knex(tblName).insert({\n              geometryColumn: knex.raw('geometry::Point(1, 10, 0)')\n            });\n            const result = await knex(tblName).select('*');\n            const geoData = result[0].geometryColumn;\n            expect(geoData.length).to.equal(22);\n          }\n        });","file":"integration2/schema/geometry-columns.spec.js","skipped":false,"dir":"test"},{"name":"Creates GEOGRAPHY column for supported databases","suites":["Schema","geometry columns"],"updatePoint":{"line":94,"column":60,"index":2601},"line":94,"code":"        it('Creates GEOGRAPHY column for supported databases', async function () {\n          if (!isSQLite(knex) && !isMssql(knex)) {\n            return this.skip();\n          }\n\n          await knex.schema.createTable(tblName, table => {\n            table.geography('geoColumn');\n          });\n\n          if (isSQLite(knex)) {\n            await knex(tblName).insert({\n              geoColumn: '2, 3'\n            });\n            const result = await knex(tblName).select('*');\n            expect(result).to.eql([{\n              geoColumn: '2, 3'\n            }]);\n          }\n\n          if (isMssql(knex)) {\n            await knex(tblName).insert({\n              geoColumn: knex.raw(\"geography::STGeomFromText('LINESTRING(-122.360 47.656, -122.343 47.656 )', 4326)\")\n            });\n            const result = await knex(tblName).select('*');\n            const geoData = result[0].geoColumn;\n            expect(geoData.length).to.equal(38);\n          }\n        });","file":"integration2/schema/geometry-columns.spec.js","skipped":false,"dir":"test"},{"name":"recreates indices after dropping a column without an index","suites":["Schema","Index","dropColumn"],"updatePoint":{"line":84,"column":72,"index":2979},"line":84,"code":"          it('recreates indices after dropping a column without an index', async () => {\n            const indicesOneBefore = await knex.raw(QUERY_TABLE_ONE_INDICES);\n            const indicesTwoBefore = await knex.raw(QUERY_TABLE_TWO_INDICES);\n            await knex.schema.alterTable('index_table_one', table => {\n              table.dropColumn('column_four');\n            });\n            await knex.schema.alterTable('index_table_two', table => {\n              table.dropColumn('column_four');\n            });\n            const indicesOneAfter = await knex.raw(QUERY_TABLE_ONE_INDICES);\n            const indicesTwoAfter = await knex.raw(QUERY_TABLE_TWO_INDICES);\n            expect(indicesOneAfter).to.deep.have.same.members(indicesOneBefore);\n            expect(indicesTwoAfter).to.deep.have.same.members(indicesTwoBefore);\n          });","file":"integration2/schema/index.spec.js","skipped":false,"dir":"test"},{"name":"drops indices when the corresponding column is dropped","suites":["Schema","Index","dropColumn"],"updatePoint":{"line":98,"column":68,"index":3818},"line":98,"code":"          it('drops indices when the corresponding column is dropped', async () => {\n            const indicesOneBefore = await knex.raw(QUERY_TABLE_ONE_INDICES);\n            const indicesTwoBefore = await knex.raw(QUERY_TABLE_TWO_INDICES);\n            const indicesOneBeforeWithoutIndex = indicesOneBefore.filter(index => index.name !== 'index_table_one_column_one_index');\n            const indicesTwoBeforeWithoutIndex = indicesTwoBefore.filter(index => index.name !== 'index_table_two_column_one_unique');\n            await knex.schema.alterTable('index_table_one', table => {\n              table.dropColumn('column_one');\n            });\n            await knex.schema.alterTable('index_table_two', table => {\n              table.dropColumn('column_one');\n            });\n            const indicesOneAfter = await knex.raw(QUERY_TABLE_ONE_INDICES);\n            const indicesTwoAfter = await knex.raw(QUERY_TABLE_TWO_INDICES);\n            expect(indicesOneAfter).to.deep.have.same.members(indicesOneBeforeWithoutIndex);\n            expect(indicesTwoAfter).to.deep.have.same.members(indicesTwoBeforeWithoutIndex);\n          });","file":"integration2/schema/index.spec.js","skipped":false,"dir":"test"},{"name":"alters composite indices when one of the corresponding columns is dropped","suites":["Schema","Index","dropColumn"],"updatePoint":{"line":114,"column":87,"index":4967},"line":114,"code":"          it('alters composite indices when one of the corresponding columns is dropped', async () => {\n            const indicesOneBeforeWithoutIndex = [{\n              type: 'index',\n              name: 'sqlite_autoindex_index_table_one_1',\n              tbl_name: 'index_table_one',\n              sql: null\n            }, {\n              type: 'index',\n              name: 'index_table_one_column_one_index',\n              tbl_name: 'index_table_one',\n              sql: 'CREATE INDEX `index_table_one_column_one_index` on `index_table_one` (`column_one`)'\n            }, {\n              type: 'index',\n              name: 'index_table_one_column_two_column_three_index',\n              tbl_name: 'index_table_one',\n              sql: 'CREATE INDEX `index_table_one_column_two_column_three_index` on `index_table_one` (`column_three`)'\n            }];\n            const indicesTwoBeforeWithoutIndex = [{\n              type: 'index',\n              name: 'index_table_two_column_one_unique',\n              tbl_name: 'index_table_two',\n              sql: 'CREATE UNIQUE INDEX `index_table_two_column_one_unique` on `index_table_two` (`column_one`)'\n            }, {\n              type: 'index',\n              name: 'index_table_two_column_two_column_three_unique',\n              tbl_name: 'index_table_two',\n              sql: 'CREATE UNIQUE INDEX `index_table_two_column_two_column_three_unique` on `index_table_two` (`column_three`)'\n            }];\n            await knex.schema.alterTable('index_table_one', table => {\n              table.dropColumn('column_two');\n            });\n            await knex.schema.alterTable('index_table_two', table => {\n              table.dropColumn('column_two');\n            });\n            const indicesOneAfter = await knex.raw(QUERY_TABLE_ONE_INDICES);\n            const indicesTwoAfter = await knex.raw(QUERY_TABLE_TWO_INDICES);\n            expect(indicesOneAfter).to.deep.have.same.members(indicesOneBeforeWithoutIndex);\n            expect(indicesTwoAfter).to.deep.have.same.members(indicesTwoBeforeWithoutIndex);\n          });","file":"integration2/schema/index.spec.js","skipped":false,"dir":"test"},{"name":"recreates indices after altering a column","suites":["Schema","Index","alterColumns"],"updatePoint":{"line":155,"column":55,"index":7059},"line":155,"code":"          it('recreates indices after altering a column', async () => {\n            const indicesBefore = await knex.raw(QUERY_TABLE_ONE_INDICES);\n            await knex.schema.alterTable('index_table_one', table => {\n              table.string('column_one').alter();\n            });\n            const indicesAfter = await knex.raw(QUERY_TABLE_ONE_INDICES);\n            expect(indicesAfter).to.deep.have.same.members(indicesBefore);\n          });","file":"integration2/schema/index.spec.js","skipped":false,"dir":"test"},{"name":"recreates indices after dropping a foreign key","suites":["Schema","Index","dropForeign"],"updatePoint":{"line":165,"column":60,"index":7563},"line":165,"code":"          it('recreates indices after dropping a foreign key', async () => {\n            const indicesBefore = await knex.raw(QUERY_TABLE_ONE_INDICES);\n            await knex.schema.alterTable('index_table_one', table => {\n              table.dropForeign('id_three');\n            });\n            const indicesAfter = await knex.raw(QUERY_TABLE_ONE_INDICES);\n            expect(indicesAfter).to.deep.have.same.members(indicesBefore);\n          });","file":"integration2/schema/index.spec.js","skipped":false,"dir":"test"},{"name":"recreates indices after dropping a primary key","suites":["Schema","Index","dropPrimary"],"updatePoint":{"line":175,"column":60,"index":8062},"line":175,"code":"          it('recreates indices after dropping a primary key', async () => {\n            const indicesBefore = await knex.raw(QUERY_TABLE_ONE_INDICES);\n            const indicesBeforeWithoutPrimary = indicesBefore.filter(index => index.sql !== null);\n            await knex.schema.alterTable('index_table_one', table => {\n              table.dropPrimary();\n            });\n            const indicesAfter = await knex.raw(QUERY_TABLE_ONE_INDICES);\n            expect(indicesAfter).to.deep.have.same.members(indicesBeforeWithoutPrimary);\n          });","file":"integration2/schema/index.spec.js","skipped":false,"dir":"test"},{"name":"recreates indices after adding a foreign key","suites":["Schema","Index","foreign"],"updatePoint":{"line":186,"column":58,"index":8658},"line":186,"code":"          it('recreates indices after adding a foreign key', async () => {\n            const indicesBefore = await knex.raw(QUERY_TABLE_TWO_INDICES);\n            await knex.schema.alterTable('index_table_two', table => {\n              table.foreign('no_id_three').references('id').inTable('index_table_three');\n            });\n            const indicesAfter = await knex.raw(QUERY_TABLE_TWO_INDICES);\n            expect(indicesAfter).to.deep.have.same.members(indicesBefore);\n          });","file":"integration2/schema/index.spec.js","skipped":false,"dir":"test"},{"name":"recreates indices after adding a primary key","suites":["Schema","Index","primary"],"updatePoint":{"line":196,"column":58,"index":9196},"line":196,"code":"          it('recreates indices after adding a primary key', async () => {\n            const indicesBefore = await knex.raw(QUERY_TABLE_TWO_INDICES);\n            await knex.schema.alterTable('index_table_two', table => {\n              table.primary('no_id');\n            });\n            const indicesAfter = await knex.raw(QUERY_TABLE_TWO_INDICES);\n            const indicesAfterWithoutPrimary = indicesAfter.filter(index => index.sql !== null);\n            expect(indicesAfterWithoutPrimary).to.deep.have.same.members(indicesBefore);\n          });","file":"integration2/schema/index.spec.js","skipped":false,"dir":"test"},{"name":"JSONB falls back to JSON for unsupported drivers","suites":["Schema","json columns"],"updatePoint":{"line":29,"column":60,"index":882},"line":29,"code":"        it('JSONB falls back to JSON for unsupported drivers', async () => {\n          let res;\n\n          switch (db) {\n            case 'sqlite3':\n              res = await knex.schema.raw(`PRAGMA table_info(${tblName})`);\n              expect(res.find(c => c.name === colName).type).to.equal('json');\n              break;\n\n            case 'postgres':\n              res = await knex.select('data_type').from('information_schema.columns').where({\n                table_name: tblName,\n                column_name: colName\n              });\n              expect(res[0].data_type).to.equal('jsonb');\n              break;\n\n            case 'mysql':\n            case 'mysql2':\n              res = await knex.select('DATA_TYPE').from('INFORMATION_SCHEMA.COLUMNS').where({\n                table_name: tblName,\n                column_name: colName\n              });\n              expect(res[0].DATA_TYPE).to.equal('json');\n              break;\n          }\n        });","file":"integration2/schema/jsonb.spec.js","skipped":false,"dir":"test"},{"name":"throws an error if client does not support createSchema","suites":["Schema (misc)","errors for unsupported dialects"],"updatePoint":{"line":70,"column":67,"index":1351},"line":70,"code":"        it('throws an error if client does not support createSchema', async function () {\n          if (isPgBased(knex)) {\n            return this.skip();\n          }\n\n          let error;\n\n          try {\n            await knex.schema.createSchema('test');\n          } catch (e) {\n            error = e;\n          }\n\n          expect(error.message).to.equal('createSchema is not supported for this dialect (only PostgreSQL supports it currently).');\n        });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"throws an error if client does not support createSchemaIfNotExists","suites":["Schema (misc)","errors for unsupported dialects"],"updatePoint":{"line":85,"column":78,"index":1825},"line":85,"code":"        it('throws an error if client does not support createSchemaIfNotExists', async function () {\n          if (isPgBased(knex)) {\n            return this.skip();\n          }\n\n          let error;\n\n          try {\n            await knex.schema.createSchemaIfNotExists('test');\n          } catch (e) {\n            error = e;\n          }\n\n          expect(error.message).to.equal('createSchemaIfNotExists is not supported for this dialect (only PostgreSQL supports it currently).');\n        });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"throws an error if client does not support dropSchema","suites":["Schema (misc)","errors for unsupported dialects"],"updatePoint":{"line":100,"column":65,"index":2308},"line":100,"code":"        it('throws an error if client does not support dropSchema', async function () {\n          if (isPgBased(knex)) {\n            return this.skip();\n          }\n\n          let error;\n\n          try {\n            await knex.schema.dropSchema('test');\n          } catch (e) {\n            error = e;\n          }\n\n          expect(error.message).to.equal('dropSchema is not supported for this dialect (only PostgreSQL supports it currently).');\n        });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"throws an error if client does not support dropSchemaIfExists","suites":["Schema (misc)","errors for unsupported dialects"],"updatePoint":{"line":115,"column":73,"index":2773},"line":115,"code":"        it('throws an error if client does not support dropSchemaIfExists', async function () {\n          if (isPgBased(knex)) {\n            return this.skip();\n          }\n\n          let error;\n\n          try {\n            await knex.schema.dropSchemaIfExists('test');\n          } catch (e) {\n            error = e;\n          }\n\n          expect(error.message).to.equal('dropSchemaIfExists is not supported for this dialect (only PostgreSQL supports it currently).');\n        });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"has a dropSchema/dropSchemaIfExists method","suites":["Schema (misc)","dropSchema"],"updatePoint":{"line":132,"column":54,"index":3282},"line":132,"code":"        it('has a dropSchema/dropSchemaIfExists method', async function () {\n          if (!isPgBased(knex)) {\n            return this.skip();\n          }\n\n          this.timeout(process.env.KNEX_TEST_TIMEOUT || 30000);\n          const dbDropSchema = ['pg', 'cockroachdb'];\n\n          function checkSchemaNotExists(schemaName) {\n            knex.raw('SELECT schema_name FROM information_schema.schemata WHERE schema_name = ?', [schemaName]).then(res => {\n              expect(res[0]).to.not.equal(schemaName);\n            });\n          } // Drop schema cascade = false tests.\n\n\n          await knex.schema.createSchema('schema').then(() => {\n            knex.schema.dropSchema('schema').testSql(tester => {\n              tester(dbDropSchema, ['drop schema \"schema\"']);\n            }).then(() => {\n              checkSchemaNotExists('schema');\n            });\n          });\n          await knex.schema.createSchema('schema_2').then(() => {\n            knex.schema.dropSchemaIfExists('schema_2').testSql(tester => {\n              tester(dbDropSchema, ['drop schema if exists \"schema_2\"']);\n            }).then(() => {\n              checkSchemaNotExists('schema_2');\n            });\n          }); // Drop schema cascade = true tests\n\n          await knex.schema.createSchema('schema_cascade_1').then(() => {\n            knex.schema.withSchema('schema_cascade_1').createTable('table_cascade_1', () => {}) // created to check if cascade works.\n            .then(() => {\n              knex.schema.dropSchema('schema_cascade_1', true).testSql(tester => {\n                tester(dbDropSchema, ['drop schema \"schema_cascade_1\" cascade']);\n              }).then(() => {\n                checkSchemaNotExists('schema_cascade_1');\n                knex.schema.withSchema('schema_cascade_1').hasTable('table_cascade_1').then(exists => expect(exists).to.equal(false));\n              });\n            });\n          });\n          await knex.schema.createSchema('schema_cascade_2').then(() => {\n            knex.schema.withSchema('schema_cascade_2').createTable('table_cascade_2', () => {}) // created to check if cascade works.\n            .then(() => {\n              knex.schema.dropSchemaIfExists('schema_cascade_2', true).testSql(tester => {\n                tester(dbDropSchema, ['drop schema if exists \"schema_cascade_2\" cascade']);\n              }).then(() => {\n                checkSchemaNotExists('schema_cascade_2');\n                knex.schema.withSchema('schema_cascade_2').hasTable('table_cascade_2').then(exists => expect(exists).to.equal(false));\n              });\n            });\n          });\n        });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"has a dropTableIfExists method","suites":["Schema (misc)","dropTable"],"updatePoint":{"line":187,"column":42,"index":5917},"line":187,"code":"        it('has a dropTableIfExists method', function () {\n          this.timeout(process.env.KNEX_TEST_TIMEOUT || 30000);\n          return Promise.all([knex.schema.dropTableIfExists('test_foreign_table_two').testSql(tester => {\n            tester(['pg', 'cockroachdb'], ['drop table if exists \"test_foreign_table_two\"']);\n            tester(['pg-redshift'], ['drop table if exists \"test_foreign_table_two\"']);\n            tester(['sqlite3', 'mysql'], ['drop table if exists `test_foreign_table_two`']);\n            tester('oracledb', ['begin execute immediate \\'drop table \"test_foreign_table_two\"\\'; exception when others then if sqlcode != -942 then raise; end if; end;', 'begin execute immediate \\'drop sequence \"test_foreign_table_two_seq\"\\'; exception when others then if sqlcode != -2289 then raise; end if; end;']);\n            tester('mssql', [\"if object_id('[test_foreign_table_two]', 'U') is not null DROP TABLE [test_foreign_table_two]\"]);\n          }), knex.schema.dropTableIfExists('test_table_one').dropTableIfExists('catch_test').dropTableIfExists('test_table_two').dropTableIfExists('test_table_three').dropTableIfExists('test_table_four').dropTableIfExists('datatype_test').dropTableIfExists('composite_key_test').dropTableIfExists('charset_collate_test').dropTableIfExists('accounts').dropTableIfExists('migration_test_1').dropTableIfExists('migration_test_2').dropTableIfExists('migration_test_2_1').dropTableIfExists('test_default_table').dropTableIfExists('test_default_table2').dropTableIfExists('test_default_table3').dropTableIfExists('knex_migrations').dropTableIfExists('knex_migrations_lock').dropTableIfExists('bool_test').dropTableIfExists('10_test_table').dropTableIfExists('rename_column_foreign_test').dropTableIfExists('rename_column_test').dropTableIfExists('renamecoltest').dropTableIfExists('should_not_be_run').dropTableIfExists('invalid_inTable_param_test').dropTableIfExists('primarytest').dropTableIfExists('increments_columns_1_test').dropTableIfExists('increments_columns_2_test')]);\n        });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"copy table","suites":["Schema (misc)","createTable","like another table"],"updatePoint":{"line":211,"column":24,"index":8462},"line":211,"code":"          it('copy table', async () => {\n            await knex.schema.createTableLike('table_copied', 'table_to_copy').testSql(tester => {\n              tester('mysql', ['create table `table_copied` like `table_to_copy`']);\n              tester(['pg', 'cockroachdb'], ['create table \"table_copied\" (like \"table_to_copy\" including all)']);\n              tester('pg-redshift', ['create table \"table_copied\" (like \"table_to_copy\")']);\n              tester('sqlite3', ['create table `table_copied` as select * from `table_to_copy` where 0=1']);\n              tester('oracledb', ['create table \"table_copied\" as (select * from \"table_to_copy\" where 0=1)']);\n              tester('mssql', ['SELECT * INTO [table_copied] FROM [table_to_copy] WHERE 0=1']);\n            });\n            expect(await knex.schema.hasTable('table_copied')).to.equal(true);\n            await knex('table_copied').columnInfo().then(res => {\n              expect(Object.keys(res)).to.have.all.members(['id', 'data']);\n            });\n          });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"copy table with additionnal column","suites":["Schema (misc)","createTable","like another table"],"updatePoint":{"line":225,"column":48,"index":9503},"line":225,"code":"          it('copy table with additionnal column', async () => {\n            await knex.schema.dropTableIfExists('table_copied');\n            await knex.schema.createTableLike('table_copied', 'table_to_copy', function (table) {\n              table.text('add_col');\n              table.integer('add_num_col');\n            }).testSql(tester => {\n              tester('mysql', ['create table `table_copied` like `table_to_copy`', 'alter table `table_copied` add `add_col` text, add `add_num_col` int']);\n              tester(['pg', 'cockroachdb'], ['create table \"table_copied\" (like \"table_to_copy\" including all, \"add_col\" text, \"add_num_col\" integer)']);\n              tester('pg-redshift', ['create table \"table_copied\" (like \"table_to_copy\")', 'alter table \"table_copied\" add column \"add_col\" varchar(max)', 'alter table \"table_copied\" add column \"add_num_col\" integer']);\n              tester('sqlite3', ['create table `table_copied` as select * from `table_to_copy` where 0=1', 'alter table `table_copied` add column `add_col` text', 'alter table `table_copied` add column `add_num_col` integer']);\n              tester('oracledb', ['create table \"table_copied\" as (select * from \"table_to_copy\" where 0=1)', 'alter table \"table_copied\" add (\"add_col\" clob, \"add_num_col\" integer)']);\n              tester('mssql', ['SELECT * INTO [table_copied] FROM [table_to_copy] WHERE 0=1', 'ALTER TABLE [table_copied] ADD [add_col] nvarchar(max), [add_num_col] int']);\n            });\n            expect(await knex.schema.hasTable('table_copied')).to.equal(true);\n            await knex('table_copied').columnInfo().then(res => {\n              expect(Object.keys(res)).to.have.all.members(['id', 'data', 'add_col', 'add_num_col']);\n            });\n          });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"#2210 - creates an incrementing column with a comment","suites":["Schema (misc)","createTable","increments types - postgres"],"updatePoint":{"line":257,"column":67,"index":11889},"line":257,"code":"          it('#2210 - creates an incrementing column with a comment', function () {\n            if (!isPgBased(knex)) {\n              return this.skip();\n            }\n\n            const table_name = 'increments_columns_1_test';\n            const expected_column = 'id';\n            const expected_comment = 'comment_1';\n            return knex.raw('SELECT c.oid FROM pg_catalog.pg_class c WHERE c.relname = ?', [table_name]).then(res => {\n              const column_oid = res.rows[0].oid;\n              return knex.raw('SELECT pg_catalog.col_description(?,?);', [column_oid, '1']).then(_res => {\n                const comment = _res.rows[0].col_description;\n                return knex.raw('select column_name from INFORMATION_SCHEMA.COLUMNS where table_name = ?;', table_name).then(res => {\n                  const column_name = res.rows[0].column_name;\n                  expect(column_name).to.equal(expected_column);\n                  expect(comment).to.equal(expected_comment);\n                });\n              });\n            });\n          });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"#2210 - creates an incrementing column with a specified name and comment","suites":["Schema (misc)","createTable","increments types - postgres"],"updatePoint":{"line":277,"column":86,"index":12959},"line":277,"code":"          it('#2210 - creates an incrementing column with a specified name and comment', function () {\n            if (!isPgBased(knex)) {\n              return this.skip();\n            }\n\n            const table_name = 'increments_columns_2_test';\n            const expected_column = 'named_2';\n            const expected_comment = 'comment_2';\n            return knex.raw('SELECT c.oid FROM pg_catalog.pg_class c WHERE c.relname = ?', [table_name]).then(res => {\n              const column_oid = res.rows[0].oid;\n              return knex.raw('SELECT pg_catalog.col_description(?,?);', [column_oid, '1']).then(_res => {\n                const comment = _res.rows[0].col_description;\n                return knex.raw('select column_name from INFORMATION_SCHEMA.COLUMNS where table_name = ?;', table_name).then(res => {\n                  const column_name = res.rows[0].column_name;\n                  expect(column_name).to.equal(expected_column);\n                  expect(comment).to.equal(expected_comment);\n                });\n              });\n            });\n          });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"#2210 - creates an incrementing column with a comment","suites":["Schema (misc)","createTable","increments types - mysql"],"updatePoint":{"line":305,"column":67,"index":14532},"line":305,"code":"          it('#2210 - creates an incrementing column with a comment', function () {\n            if (!isMysql(knex)) {\n              return this.skip();\n            }\n\n            const table_name = 'increments_columns_1_test';\n            const expected_column = 'id';\n            const expected_comment = 'comment_1';\n            const query = `\n                  SELECT COLUMN_COMMENT\n                  FROM INFORMATION_SCHEMA.COLUMNS\n                  WHERE TABLE_NAME = ?\n                    AND COLUMN_NAME = ?\n                `;\n            return knex.raw(query, [table_name, expected_column]).then(res => {\n              const comment = res[0][0].COLUMN_COMMENT;\n              expect(comment).to.equal(expected_comment);\n            });\n          });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"#2210 - creates an incrementing column with a specified name and comment","suites":["Schema (misc)","createTable","increments types - mysql"],"updatePoint":{"line":324,"column":86,"index":15310},"line":324,"code":"          it('#2210 - creates an incrementing column with a specified name and comment', function () {\n            if (!isMysql(knex)) {\n              return this.skip();\n            }\n\n            const table_name = 'increments_columns_2_test';\n            const expected_column = 'named_2';\n            const expected_comment = 'comment_2';\n            const query = `\n                  SELECT COLUMN_COMMENT\n                  FROM INFORMATION_SCHEMA.COLUMNS\n                  WHERE TABLE_NAME = ?\n                    AND COLUMN_NAME = ?\n                `;\n            return knex.raw(query, [table_name, expected_column]).then(res => {\n              const comment = res[0][0].COLUMN_COMMENT;\n              expect(comment).to.equal(expected_comment);\n            });\n          });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"uses native type with schema","suites":["Schema (misc)","createTable","enum - postgres"],"updatePoint":{"line":350,"column":42,"index":16355},"line":350,"code":"          it('uses native type with schema', function () {\n            if (!isPgBased(knex)) {\n              return this.skip();\n            }\n\n            return knex.schema.createSchemaIfNotExists('test').then(() => {\n              return knex.schema.withSchema('test').createTable('native_enum_test', table => {\n                table.enum('foo_column', ['a', 'b', 'c'], {\n                  useNative: true,\n                  enumName: 'foo_type',\n                  schema: true\n                }).notNull();\n                table.uuid('id').notNull();\n              }).testSql(tester => {\n                tester(['pg', 'cockroachdb'], [\"create type \\\"test\\\".\\\"foo_type\\\" as enum ('a', 'b', 'c')\", 'create table \"test\".\"native_enum_test\" (\"foo_column\" \"test\".\"foo_type\" not null, \"id\" uuid not null)']);\n              });\n            });\n          });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"uses native type when useNative is specified","suites":["Schema (misc)","createTable","enum - postgres"],"updatePoint":{"line":368,"column":58,"index":17225},"line":368,"code":"          it('uses native type when useNative is specified', function () {\n            if (!isPgBased(knex)) {\n              return this.skip();\n            }\n\n            return knex.schema.createTable('native_enum_test', table => {\n              table.enum('foo_column', ['a', 'b', 'c'], {\n                useNative: true,\n                enumName: 'foo_type'\n              }).notNull();\n              table.uuid('id').notNull();\n            }).testSql(tester => {\n              tester(['pg', 'cockroachdb'], [\"create type \\\"foo_type\\\" as enum ('a', 'b', 'c')\", 'create table \"native_enum_test\" (\"foo_column\" \"foo_type\" not null, \"id\" uuid not null)']);\n            });\n          });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"uses an existing native type when useNative and existingType are specified","suites":["Schema (misc)","createTable","enum - postgres"],"updatePoint":{"line":383,"column":88,"index":17941},"line":383,"code":"          it('uses an existing native type when useNative and existingType are specified', function () {\n            if (!isPgBased(knex)) {\n              return this.skip();\n            }\n\n            return knex.raw(\"create type \\\"foo_type\\\" as enum ('a', 'b', 'c')\").then(() => {\n              return knex.schema.createTable('native_enum_test', table => {\n                table.enum('foo_column', null, {\n                  useNative: true,\n                  enumName: 'foo_type',\n                  existingType: true\n                }).notNull();\n                table.uuid('id').notNull();\n              }).testSql(tester => {\n                tester(['pg', 'cockroachdb'], ['create table \"native_enum_test\" (\"foo_column\" \"foo_type\" not null, \"id\" uuid not null)']);\n              });\n            });\n          });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"Callback function must be supplied","suites":["Schema (misc)","createTable","enum - postgres"],"updatePoint":{"line":402,"column":46,"index":18729},"line":402,"code":"        it('Callback function must be supplied', () => {\n          expect(() => {\n            knex.schema.createTable('callback_must_be_supplied').toString();\n          }).to.throw(TypeError);\n          expect(() => {\n            knex.schema.createTable('callback_must_be_supplied', () => {}).toString();\n          }).to.not.throw(TypeError);\n        });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"is possible to chain .catch","suites":["Schema (misc)","createTable","enum - postgres"],"updatePoint":{"line":410,"column":39,"index":19077},"line":410,"code":"        it('is possible to chain .catch', () => knex.schema.createTable('catch_test', t => {\n          t.increments();\n        }).catch(e => {\n          throw e;\n        }));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"accepts the table name, and a \"container\" function","suites":["Schema (misc)","createTable","enum - postgres"],"updatePoint":{"line":415,"column":62,"index":19275},"line":415,"code":"        it('accepts the table name, and a \"container\" function', () => knex.schema.createTable('test_table_one', table => {\n          if (isMysql(knex)) table.engine('InnoDB');\n          table.comment('A table comment.');\n          table.bigIncrements('id');\n          table.string('first_name').index();\n          table.string('last_name');\n          table.string('email').unique().nullable();\n          table.integer('logins').defaultTo(1).index().comment();\n          table.float('balance').defaultTo(0);\n\n          if (isOracle(knex)) {\n            // use string instead to force varchar2 to avoid later problems with join and union\n            table.string('about', 4000).comment('A comment.');\n          } else {\n            table.text('about').comment('A comment.');\n          }\n\n          table.timestamps();\n        }).testSql(tester => {\n          tester('mysql', [\"create table `test_table_one` (`id` bigint unsigned not null auto_increment primary key, `first_name` varchar(255), `last_name` varchar(255), `email` varchar(255) null, `logins` int default '1', `balance` float(8, 2) default '0', `about` text comment 'A comment.', `created_at` datetime, `updated_at` datetime) default character set utf8 engine = InnoDB comment = 'A table comment.'\", 'alter table `test_table_one` add index `test_table_one_first_name_index`(`first_name`)', 'alter table `test_table_one` add unique `test_table_one_email_unique`(`email`)', 'alter table `test_table_one` add index `test_table_one_logins_index`(`logins`)']);\n          tester(['pg', 'cockroachdb'], ['create table \"test_table_one\" (\"id\" bigserial primary key, \"first_name\" varchar(255), \"last_name\" varchar(255), \"email\" varchar(255) null, \"logins\" integer default \\'1\\', \"balance\" real default \\'0\\', \"about\" text, \"created_at\" timestamptz, \"updated_at\" timestamptz)', 'comment on table \"test_table_one\" is \\'A table comment.\\'', 'comment on column \"test_table_one\".\"logins\" is NULL', 'comment on column \"test_table_one\".\"about\" is \\'A comment.\\'', 'create index \"test_table_one_first_name_index\" on \"test_table_one\" (\"first_name\")', 'alter table \"test_table_one\" add constraint \"test_table_one_email_unique\" unique (\"email\")', 'create index \"test_table_one_logins_index\" on \"test_table_one\" (\"logins\")']);\n          tester('pg-redshift', ['create table \"test_table_one\" (\"id\" bigint identity(1,1) primary key not null, \"first_name\" varchar(255), \"last_name\" varchar(255), \"email\" varchar(255) null, \"logins\" integer default \\'1\\', \"balance\" real default \\'0\\', \"about\" varchar(max), \"created_at\" timestamptz, \"updated_at\" timestamptz)', 'comment on table \"test_table_one\" is \\'A table comment.\\'', 'comment on column \"test_table_one\".\"logins\" is NULL', 'comment on column \"test_table_one\".\"about\" is \\'A comment.\\'', 'alter table \"test_table_one\" add constraint \"test_table_one_email_unique\" unique (\"email\")']);\n          tester('sqlite3', [\"create table `test_table_one` (`id` integer not null primary key autoincrement, `first_name` varchar(255), `last_name` varchar(255), `email` varchar(255) null, `logins` integer default '1', `balance` float default '0', `about` text, `created_at` datetime, `updated_at` datetime)\", 'create index `test_table_one_first_name_index` on `test_table_one` (`first_name`)', 'create unique index `test_table_one_email_unique` on `test_table_one` (`email`)', 'create index `test_table_one_logins_index` on `test_table_one` (`logins`)']);\n          tester('oracledb', [`create table \"test_table_one\" (\"id\" number(20, 0) not null primary key, \"first_name\" varchar2(255), \"last_name\" varchar2(255), \"email\" varchar2(255) null, \"logins\" integer default '1', \"balance\" float default '0', \"about\" varchar2(4000), \"created_at\" timestamp with local time zone, \"updated_at\" timestamp with local time zone)`, 'comment on table \"test_table_one\" is \\'A table comment.\\'', `DECLARE PK_NAME VARCHAR(200); BEGIN  EXECUTE IMMEDIATE ('CREATE SEQUENCE \"test_table_one_seq\"');  SELECT cols.column_name INTO PK_NAME  FROM all_constraints cons, all_cons_columns cols  WHERE cons.constraint_type = 'P'  AND cons.constraint_name = cols.constraint_name  AND cons.owner = cols.owner  AND cols.table_name = 'test_table_one';  execute immediate ('create or replace trigger \"test_table_one_autoinc_trg\"  BEFORE INSERT on \"test_table_one\"  for each row  declare  checking number := 1;  begin    if (:new.\"' || PK_NAME || '\" is null) then      while checking >= 1 loop        select \"test_table_one_seq\".nextval into :new.\"' || PK_NAME || '\" from dual;        select count(\"' || PK_NAME || '\") into checking from \"test_table_one\"        where \"' || PK_NAME || '\" = :new.\"' || PK_NAME || '\";      end loop;    end if;  end;'); END;`, 'comment on column \"test_table_one\".\"logins\" is \\'\\'', 'comment on column \"test_table_one\".\"about\" is \\'A comment.\\'', 'create index \"NkZo/dGRI9O73/NE2fHo+35d4jk\" on \"test_table_one\" (\"first_name\")', 'alter table \"test_table_one\" add constraint \"test_table_one_email_unique\" unique (\"email\")', 'create index \"test_table_one_logins_index\" on \"test_table_one\" (\"logins\")']);\n          tester('mssql', [\"CREATE TABLE [test_table_one] ([id] bigint identity(1,1) not null primary key, [first_name] nvarchar(255), [last_name] nvarchar(255), [email] nvarchar(255) null, [logins] int CONSTRAINT [test_table_one_logins_default] DEFAULT '1', [balance] float CONSTRAINT [test_table_one_balance_default] DEFAULT '0', [about] nvarchar(max), [created_at] datetime2, [updated_at] datetime2)\", \"IF EXISTS(SELECT * FROM sys.fn_listextendedproperty(N'MS_Description', N'Schema', N'dbo', N'Table', N'test_table_one', NULL, NULL))\\n  EXEC sys.sp_updateextendedproperty N'MS_Description', N'A table comment.', N'Schema', N'dbo', N'Table', N'test_table_one'\\nELSE\\n  EXEC sys.sp_addextendedproperty N'MS_Description', N'A table comment.', N'Schema', N'dbo', N'Table', N'test_table_one'\", \"IF EXISTS(SELECT * FROM sys.fn_listextendedproperty(N'MS_Description', N'Schema', N'dbo', N'Table', N'test_table_one', N'Column', N'about'))\\n  EXEC sys.sp_updateextendedproperty N'MS_Description', N'A comment.', N'Schema', N'dbo', N'Table', N'test_table_one', N'Column', N'about'\\nELSE\\n  EXEC sys.sp_addextendedproperty N'MS_Description', N'A comment.', N'Schema', N'dbo', N'Table', N'test_table_one', N'Column', N'about'\", 'CREATE INDEX [test_table_one_first_name_index] ON [test_table_one] ([first_name])', 'CREATE UNIQUE INDEX [test_table_one_email_unique] ON [test_table_one] ([email]) WHERE [email] IS NOT NULL', 'CREATE INDEX [test_table_one_logins_index] ON [test_table_one] ([logins])']);\n        }));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"create table with timestamps options","suites":["Schema (misc)","createTable","enum - postgres"],"updatePoint":{"line":441,"column":48,"index":25836},"line":441,"code":"        it('create table with timestamps options', async () => {\n          await knex.schema.createTable('test_table_timestamp', table => {\n            if (isMysql(knex)) table.engine('InnoDB');\n            table.bigIncrements('id');\n            table.timestamps({\n              useTimestamps: false,\n              defaultToNow: true,\n              useCamelCase: true\n            });\n          }).testSql(tester => {\n            tester('mysql', ['create table `test_table_timestamp` (`id` bigint unsigned not null auto_increment primary key, `createdAt` datetime not null default CURRENT_TIMESTAMP, `updatedAt` datetime not null default CURRENT_TIMESTAMP) default character set utf8 engine = InnoDB']);\n            tester(['pg', 'cockroachdb'], ['create table \"test_table_timestamp\" (\"id\" bigserial primary key, \"createdAt\" timestamptz not null default CURRENT_TIMESTAMP, \"updatedAt\" timestamptz not null default CURRENT_TIMESTAMP)']);\n            tester('pg-redshift', ['create table \"test_table_timestamp\" (\"id\" bigint identity(1,1) primary key not null, \"createdAt\" timestamptz not null default CURRENT_TIMESTAMP, \"updatedAt\" timestamptz not null default CURRENT_TIMESTAMP)']);\n            tester('sqlite3', ['create table `test_table_timestamp` (`id` integer not null primary key autoincrement, `createdAt` datetime not null default CURRENT_TIMESTAMP, `updatedAt` datetime not null default CURRENT_TIMESTAMP)']);\n            tester('oracledb', [`create table \"test_table_timestamp\" (\"id\" number(20, 0) not null primary key, \"createdAt\" timestamp with local time zone default CURRENT_TIMESTAMP not null, \"updatedAt\" timestamp with local time zone default CURRENT_TIMESTAMP not null)`, `DECLARE PK_NAME VARCHAR(200); BEGIN  EXECUTE IMMEDIATE ('CREATE SEQUENCE \"test_table_timestamp_seq\"');  SELECT cols.column_name INTO PK_NAME  FROM all_constraints cons, all_cons_columns cols  WHERE cons.constraint_typ` + `e = 'P'  AND cons.constraint_name = cols.constraint_name  AND cons.owner = cols.owner  AND cols.table_name = 'test_table_timestamp';  execute immediate ('create or replace trigger \"gT8ntVvbOANQHra05aYo1kc6cCI\"  BEFORE INSERT on` + ` \"test_table_timestamp\"  for each row  declare  checking number := 1;  begin    if (:new.\"' || PK_NAME || '\" is null) then      while checking >= 1 loop        select \"test_table_timestamp_seq\".nextval into :new.\"' || PK_N` + `AME || '\" from dual;        select count(\"' || PK_NAME || '\") into checking from \"test_table_timestamp\"        where \"' || PK_NAME || '\" = :new.\"' || PK_NAME || '\";      end loop;    end if;  end;'); END;`]);\n            tester('mssql', ['CREATE TABLE [test_table_timestamp] ([id] bigint identity(1,1) not null primary key, [createdAt] datetime2 not null CONSTRAINT [test_table_timestamp_createdat_default] DEFAULT CURRENT_TIMESTAMP, [updatedAt] datetime2 not null CONSTRAINT [test_table_timestamp_updatedat_default] DEFAULT CURRENT_TIMESTAMP)']);\n          });\n          await knex.schema.dropTableIfExists('test_table_timestamp');\n        });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"is possible to set the db engine with the table.engine","suites":["Schema (misc)","createTable","enum - postgres"],"updatePoint":{"line":460,"column":66,"index":28869},"line":460,"code":"        it('is possible to set the db engine with the table.engine', () => knex.schema.createTable('test_table_two', table => {\n          if (isMysql(knex)) {\n            table.engine('InnoDB');\n          }\n\n          table.increments();\n          table.integer('account_id');\n\n          if (isOracle(knex)) {\n            // use string instead to force varchar2 to avoid later problems with join and union\n            // e.g. where email (varchar2) = details (clob) does not work\n            table.string('details', 4000);\n          } else {\n            table.text('details');\n          }\n\n          table.tinyint('status');\n        }).testSql(tester => {\n          tester('mysql', ['create table `test_table_two` (`id` int unsigned not null auto_increment primary key, `account_id` int, `details` text, `status` tinyint) default character set utf8 engine = InnoDB']);\n        }));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"sets default values with defaultTo","suites":["Schema (misc)","createTable","enum - postgres"],"updatePoint":{"line":480,"column":46,"index":29731},"line":480,"code":"        it('sets default values with defaultTo', async () => {\n          await knex.schema.dropTableIfExists('test_table_three');\n          const defaultMetadata = {\n            a: 10\n          };\n          const defaultDetails = {\n            b: {\n              d: 20\n            }\n          };\n          await knex.schema.createTable('test_table_three', table => {\n            if (isMysql(knex)) {\n              table.engine('InnoDB');\n            }\n\n            table.integer('main').notNullable().primary();\n            table.text('paragraph').defaultTo('Lorem ipsum Qui quis qui in.');\n            table.json('metadata').defaultTo(defaultMetadata);\n\n            if (isPgBased(knex)) {\n              table.jsonb('details').defaultTo(defaultDetails);\n            }\n          }).testSql(tester => {\n            tester('mysql', ['create table `test_table_three` (`main` int not null, `paragraph` text, `metadata` json default (\\'{\"a\":10}\\'), primary key (`main`)) default character set utf8 engine = InnoDB']);\n            tester(['pg', 'cockroachdb'], ['create table \"test_table_three\" (\"main\" integer not null, \"paragraph\" text default \\'Lorem ipsum Qui quis qui in.\\', \"metadata\" json default \\'{\"a\":10}\\', \"details\" jsonb default \\'{\"b\":{\"d\":20}}\\')', 'alter table \"test_table_three\" add constraint \"test_table_three_pkey\" primary key (\"main\")']);\n            tester('pg-redshift', ['create table \"test_table_three\" (\"main\" integer not null, \"paragraph\" varchar(max) default \\'Lorem ipsum Qui quis qui in.\\',  \"metadata\" json default \\'{\"a\":10}\\', \"details\" jsonb default \\'{\"b\":{\"d\":20}}\\')', 'alter table \"test_table_three\" add constraint \"test_table_three_pkey\" primary key (\"main\")']);\n            tester('sqlite3', [\"create table `test_table_three` (`main` integer not null, `paragraph` text default 'Lorem ipsum Qui quis qui in.', `metadata` json default '{\\\"a\\\":10}', primary key (`main`))\"]);\n            tester('oracledb', ['create table \"test_table_three\" (\"main\" integer not null, \"paragraph\" clob default \\'Lorem ipsum Qui quis qui in.\\', \"metadata\" clob default \\'{\"a\":10}\\')', 'alter table \"test_table_three\" add constraint \"test_table_three_pkey\" primary key (\"main\")']);\n            tester('mssql', [\"CREATE TABLE [test_table_three] ([main] int not null, [paragraph] nvarchar(max) CONSTRAINT [test_table_three_paragraph_default] DEFAULT 'Lorem ipsum Qui quis qui in.', [metadata] nvarchar(max) CONSTRAINT [test_table_three_metadata_default] DEFAULT '{\\\"a\\\":10}', CONSTRAINT [test_table_three_pkey] PRIMARY KEY ([main]))\"]);\n          }).then(() => knex('test_table_three').insert([{\n            main: 1\n          }])).then(() => knex('test_table_three').where({\n            main: 1\n          }).first()).then(result => {\n            assertNumber(knex, result.main, 1);\n\n            if (!isMysql(knex)) {\n              // MySQL doesn't support default values in text columns\n              expect(result.paragraph).to.eql('Lorem ipsum Qui quis qui in.');\n              return;\n            }\n\n            if (isPgBased(knex)) {\n              expect(result.metadata).to.eql(defaultMetadata);\n              expect(result.details).to.eql(defaultDetails);\n            } else if (isString(result.metadata)) {\n              expect(JSON.parse(result.metadata)).to.eql(defaultMetadata);\n            } else {\n              expect(result.metadata).to.eql(defaultMetadata);\n            }\n          });\n        });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"handles numeric length correctly","suites":["Schema (misc)","createTable","enum - postgres"],"updatePoint":{"line":532,"column":44,"index":33150},"line":532,"code":"        it('handles numeric length correctly', () => knex.schema.createTable('test_table_numerics', table => {\n          if (isMysql(knex)) {\n            table.engine('InnoDB');\n          }\n\n          table.integer('integer_column', 5);\n          table.tinyint('tinyint_column', 5);\n          table.smallint('smallint_column');\n          table.mediumint('mediumint_column');\n          table.bigint('bigint_column');\n        }).testSql(tester => {\n          tester('mysql', ['create table `test_table_numerics` (`integer_column` int(5), `tinyint_column` tinyint(5), `smallint_column` smallint, `mediumint_column` mediumint, `bigint_column` bigint) default character set utf8 engine = InnoDB']);\n          tester(['pg', 'cockroachdb'], ['create table \"test_table_numerics\" (\"integer_column\" integer, \"tinyint_column\" smallint, \"smallint_column\" smallint, \"mediumint_column\" integer, \"bigint_column\" bigint)']);\n          tester('sqlite3', ['create table `test_table_numerics` (`integer_column` integer, `tinyint_column` tinyint, `smallint_column` integer, `mediumint_column` integer, `bigint_column` bigint)']);\n          tester('mssql', ['CREATE TABLE [test_table_numerics] ([integer_column] int, [tinyint_column] tinyint, [smallint_column] smallint, [mediumint_column] int, [bigint_column] bigint)']);\n        }).then(() => knex.schema.dropTable('test_table_numerics')));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"supports the enum and uuid columns","suites":["Schema (misc)","createTable","enum - postgres"],"updatePoint":{"line":548,"column":46,"index":34524},"line":548,"code":"        it('supports the enum and uuid columns', () => {\n          // NB: redshift does not...\n          return knex.schema.createTable('datatype_test', table => {\n            table.enum('enum_value', ['a', 'b', 'c']);\n            table.uuid('uuid').notNull();\n          }).testSql(tester => {\n            tester('mysql', [\"create table `datatype_test` (`enum_value` enum('a', 'b', 'c'), `uuid` char(36) not null) default character set utf8\"]);\n            tester(['pg', 'cockroachdb'], ['create table \"datatype_test\" (\"enum_value\" text check (\"enum_value\" in (\\'a\\', \\'b\\', \\'c\\')), \"uuid\" uuid not null)']);\n            tester('sqlite3', [\"create table `datatype_test` (`enum_value` text check (`enum_value` in ('a', 'b', 'c')), `uuid` char(36) not null)\"]);\n            tester('oracledb', ['create table \"datatype_test\" (\"enum_value\" varchar2(1) check (\"enum_value\" in (\\'a\\', \\'b\\', \\'c\\')), \"uuid\" char(36) not null)']);\n            tester('mssql', ['CREATE TABLE [datatype_test] ([enum_value] nvarchar(100), [uuid] uniqueidentifier not null)']);\n          });\n        }); // Depends on previous test","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"gets the columnInfo","suites":["Schema (misc)","createTable","enum - postgres"],"updatePoint":{"line":562,"column":31,"index":35616},"line":562,"code":"        it('gets the columnInfo', function () {\n          return knex('datatype_test').columnInfo().testSql(function (tester) {\n            tester('mysql', 'select * from information_schema.columns where table_name = ? and table_schema = ?', null, {\n              enum_value: {\n                defaultValue: null,\n                maxLength: 1,\n                nullable: true,\n                type: 'enum'\n              },\n              uuid: {\n                defaultValue: null,\n                maxLength: 36,\n                nullable: false,\n                type: 'char'\n              }\n            });\n            tester('pg', 'select * from information_schema.columns where table_name = ? and table_catalog = current_database() and table_schema = current_schema()', null, {\n              enum_value: {\n                defaultValue: null,\n                maxLength: null,\n                nullable: true,\n                type: 'text'\n              },\n              uuid: {\n                defaultValue: null,\n                maxLength: null,\n                nullable: false,\n                type: 'uuid'\n              }\n            });\n            tester('pgnative', 'select * from information_schema.columns where table_name = ? and table_catalog = current_database() and table_schema = current_schema()', null, {\n              enum_value: {\n                defaultValue: null,\n                maxLength: null,\n                nullable: true,\n                type: 'text'\n              },\n              uuid: {\n                defaultValue: null,\n                maxLength: null,\n                nullable: false,\n                type: 'uuid'\n              }\n            });\n            tester('pg-redshift', 'select * from information_schema.columns where table_name = ? and table_catalog = ? and table_schema = current_schema()', null, {\n              enum_value: {\n                defaultValue: null,\n                maxLength: 255,\n                nullable: true,\n                type: 'character varying'\n              },\n              uuid: {\n                defaultValue: null,\n                maxLength: 36,\n                nullable: false,\n                type: 'character'\n              }\n            });\n            tester('sqlite3', 'PRAGMA table_info(`datatype_test`)', [], {\n              enum_value: {\n                defaultValue: null,\n                maxLength: null,\n                nullable: true,\n                type: 'text'\n              },\n              uuid: {\n                defaultValue: null,\n                maxLength: '36',\n                nullable: false,\n                type: 'char'\n              }\n            });\n            tester('oracledb', \"select * from xmltable( '/ROWSET/ROW'\\n      passing dbms_xmlgen.getXMLType('\\n      select char_col_decl_length, column_name, data_type, data_default, nullable\\n      from all_tab_columns where table_name = ''datatype_test'' ')\\n      columns\\n      CHAR_COL_DECL_LENGTH number, COLUMN_NAME varchar2(200), DATA_TYPE varchar2(106),\\n      DATA_DEFAULT clob, NULLABLE varchar2(1))\", [], {\n              enum_value: {\n                defaultValue: null,\n                nullable: true,\n                maxLength: 1,\n                type: 'VARCHAR2'\n              },\n              uuid: {\n                defaultValue: null,\n                nullable: false,\n                maxLength: 36,\n                type: 'CHAR'\n              }\n            });\n            tester('mssql', \"select [COLUMN_NAME], [COLUMN_DEFAULT], [DATA_TYPE], [CHARACTER_MAXIMUM_LENGTH], [IS_NULLABLE] from INFORMATION_SCHEMA.COLUMNS where table_name = ? and table_catalog = ? and table_schema = 'dbo'\", ['datatype_test', 'knex_test'], {\n              enum_value: {\n                defaultValue: null,\n                maxLength: 100,\n                nullable: true,\n                type: 'nvarchar'\n              },\n              uuid: {\n                defaultValue: null,\n                maxLength: null,\n                nullable: false,\n                type: 'uniqueidentifier'\n              }\n            });\n          });\n        });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"gets the columnInfo with columntype","suites":["Schema (misc)","createTable","enum - postgres"],"updatePoint":{"line":664,"column":47,"index":39723},"line":664,"code":"        it('gets the columnInfo with columntype', function () {\n          return knex('datatype_test').columnInfo('uuid').testSql(function (tester) {\n            tester('mysql', 'select * from information_schema.columns where table_name = ? and table_schema = ?', null, {\n              defaultValue: null,\n              maxLength: 36,\n              nullable: false,\n              type: 'char'\n            });\n            tester('pg', 'select * from information_schema.columns where table_name = ? and table_catalog = current_database() and table_schema = current_schema()', null, {\n              defaultValue: null,\n              maxLength: null,\n              nullable: false,\n              type: 'uuid'\n            });\n            tester('pgnative', 'select * from information_schema.columns where table_name = ? and table_catalog = current_database() and table_schema = current_schema()', null, {\n              defaultValue: null,\n              maxLength: null,\n              nullable: false,\n              type: 'uuid'\n            });\n            tester('pg-redshift', 'select * from information_schema.columns where table_name = ? and table_catalog = ? and table_schema = current_schema()', null, {\n              defaultValue: null,\n              maxLength: 36,\n              nullable: false,\n              type: 'character'\n            });\n            tester('sqlite3', 'PRAGMA table_info(`datatype_test`)', [], {\n              defaultValue: null,\n              maxLength: '36',\n              nullable: false,\n              type: 'char'\n            });\n            tester('oracledb', \"select * from xmltable( '/ROWSET/ROW'\\n      passing dbms_xmlgen.getXMLType('\\n      select char_col_decl_length, column_name, data_type, data_default, nullable\\n      from all_tab_columns where table_name = ''datatype_test'' ')\\n      columns\\n      CHAR_COL_DECL_LENGTH number, COLUMN_NAME varchar2(200), DATA_TYPE varchar2(106),\\n      DATA_DEFAULT clob, NULLABLE varchar2(1))\", [], {\n              defaultValue: null,\n              maxLength: 36,\n              nullable: false,\n              type: 'CHAR'\n            });\n            tester('mssql', \"select [COLUMN_NAME], [COLUMN_DEFAULT], [DATA_TYPE], [CHARACTER_MAXIMUM_LENGTH], [IS_NULLABLE] from INFORMATION_SCHEMA.COLUMNS where table_name = ? and table_catalog = ? and table_schema = 'dbo'\", null, {\n              defaultValue: null,\n              maxLength: null,\n              nullable: false,\n              type: 'uniqueidentifier'\n            });\n          });\n        });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"allows for setting foreign keys on schema creation","suites":["Schema (misc)","createTable","enum - postgres"],"updatePoint":{"line":710,"column":62,"index":42265},"line":710,"code":"        it('allows for setting foreign keys on schema creation', () => knex.schema.createTable('test_foreign_table_two', table => {\n          table.increments();\n          table.integer('fkey_two').unsigned().references('id').inTable('test_table_two');\n          table.integer('fkey_three').unsigned().references('id').inTable('test_table_two').withKeyName('fk_fkey_three');\n          table.integer('fkey_four').unsigned();\n          table.foreign('fkey_four', 'fk_fkey_four').references('test_table_two.id');\n        }).testSql(tester => {\n          tester('mysql', ['create table `test_foreign_table_two` (`id` int unsigned not null auto_increment primary key, `fkey_two` int unsigned, `fkey_three` int unsigned, `fkey_four` int unsigned) default character set utf8', 'alter table `test_foreign_table_two` add constraint `test_foreign_table_two_fkey_two_foreign` foreign key (`fkey_two`) references `test_table_two` (`id`)', 'alter table `test_foreign_table_two` add constraint `fk_fkey_three` foreign key (`fkey_three`) references `test_table_two` (`id`)', 'alter table `test_foreign_table_two` add constraint `fk_fkey_four` foreign key (`fkey_four`) references `test_table_two` (`id`)']);\n          tester(['pg', 'cockroachdb'], ['create table \"test_foreign_table_two\" (\"id\" serial primary key, \"fkey_two\" integer, \"fkey_three\" integer, \"fkey_four\" integer)', 'alter table \"test_foreign_table_two\" add constraint \"test_foreign_table_two_fkey_two_foreign\" foreign key (\"fkey_two\") references \"test_table_two\" (\"id\")', 'alter table \"test_foreign_table_two\" add constraint \"fk_fkey_three\" foreign key (\"fkey_three\") references \"test_table_two\" (\"id\")', 'alter table \"test_foreign_table_two\" add constraint \"fk_fkey_four\" foreign key (\"fkey_four\") references \"test_table_two\" (\"id\")']);\n          tester('pg-redshift', ['create table \"test_foreign_table_two\" (\"id\" integer identity(1,1) primary key not null, \"fkey_two\" integer, \"fkey_three\" integer, \"fkey_four\" integer)', 'alter table \"test_foreign_table_two\" add constraint \"test_foreign_table_two_fkey_two_foreign\" foreign key (\"fkey_two\") references \"test_table_two\" (\"id\")', 'alter table \"test_foreign_table_two\" add constraint \"fk_fkey_three\" foreign key (\"fkey_three\") references \"test_table_two\" (\"id\")', 'alter table \"test_foreign_table_two\" add constraint \"fk_fkey_four\" foreign key (\"fkey_four\") references \"test_table_two\" (\"id\")']);\n          tester('sqlite3', ['create table `test_foreign_table_two` (`id` integer not null primary key autoincrement, `fkey_two` integer, `fkey_three` integer, `fkey_four` integer, ' + 'foreign key(`fkey_two`) references `test_table_two`(`id`), ' + 'constraint `fk_fkey_three` foreign key(`fkey_three`) references `test_table_two`(`id`), ' + 'constraint `fk_fkey_four` foreign key(`fkey_four`) references `test_table_two`(`id`))']);\n          tester('oracledb', ['create table \"test_foreign_table_two\" (\"id\" integer not null primary key, \"fkey_two\" integer, \"fkey_three\" integer, \"fkey_four\" integer)', 'DECLARE PK_NAME VARCHAR(200); BEGIN  EXECUTE IMMEDIATE (\\'CREATE SEQUENCE \"test_foreign_table_two_seq\"\\');  SELECT cols.column_name INTO PK_NAME  FROM all_constraints cons, all_cons_columns cols  WHERE cons.constraint_type = \\'P\\'  AND cons.constraint_name = cols.constraint_name  AND cons.owner = cols.owner  AND cols.table_name = \\'test_foreign_table_two\\';  execute immediate (\\'create or replace trigger \"m6uvAnbUQqcHvfWTN5IAjip1/vk\"  BEFORE INSERT on \"test_foreign_table_two\"  for each row  declare  checking number := 1;  begin    if (:new.\"\\' || PK_NAME || \\'\" is null) then      while checking >= 1 loop        select \"test_foreign_table_two_seq\".nextval into :new.\"\\' || PK_NAME || \\'\" from dual;        select count(\"\\' || PK_NAME || \\'\") into checking from \"test_foreign_table_two\"        where \"\\' || PK_NAME || \\'\" = :new.\"\\' || PK_NAME || \\'\";      end loop;    end if;  end;\\'); END;', 'alter table \"test_foreign_table_two\" add constraint \"q7TfvbIx3HUQbh+l+e5N+J+Guag\" foreign key (\"fkey_two\") references \"test_table_two\" (\"id\")', 'alter table \"test_foreign_table_two\" add constraint \"fk_fkey_three\" foreign key (\"fkey_three\") references \"test_table_two\" (\"id\")', 'alter table \"test_foreign_table_two\" add constraint \"fk_fkey_four\" foreign key (\"fkey_four\") references \"test_table_two\" (\"id\")']);\n          tester('mssql', ['CREATE TABLE [test_foreign_table_two] ([id] int identity(1,1) not null primary key, [fkey_two] int, [fkey_three] int, [fkey_four] int, ' + 'CONSTRAINT [test_foreign_table_two_fkey_two_foreign] FOREIGN KEY ([fkey_two]) REFERENCES [test_table_two] ([id]), ' + 'CONSTRAINT [fk_fkey_three] FOREIGN KEY ([fkey_three]) REFERENCES [test_table_two] ([id]), ' + 'CONSTRAINT [fk_fkey_four] FOREIGN KEY ([fkey_four]) REFERENCES [test_table_two] ([id]))']);\n        }));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"rejects setting foreign key where tableName is not typeof === string","suites":["Schema (misc)","createTable","enum - postgres"],"updatePoint":{"line":724,"column":80,"index":47083},"line":724,"code":"        it('rejects setting foreign key where tableName is not typeof === string', () => {\n          const builder = knex.schema.createTable('invalid_inTable_param_test', table => {\n            const createInvalidUndefinedInTableSchema = () => {\n              table.increments('id').references('id').inTable();\n            };\n\n            const createInvalidObjectInTableSchema = () => {\n              table.integer('another_id').references('id').inTable({\n                tableName: 'this_should_fail'\n              });\n            };\n\n            expect(createInvalidUndefinedInTableSchema).to.throw(TypeError);\n            expect(createInvalidObjectInTableSchema).to.throw(TypeError);\n            table.integer('yet_another_id').references('id').inTable({\n              tableName: 'this_should_fail_too'\n            });\n          });\n          expect(() => builder.toSQL()).to.throw(TypeError);\n        });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"allows for composite keys","suites":["Schema (misc)","createTable","enum - postgres"],"updatePoint":{"line":744,"column":37,"index":47950},"line":744,"code":"        it('allows for composite keys', () => knex.schema.createTable('composite_key_test', table => {\n          table.integer('column_a');\n          table.integer('column_b');\n          table.text('details');\n          table.tinyint('status');\n          table.unique(['column_a', 'column_b']);\n        }).testSql(tester => {\n          tester('mysql', ['create table `composite_key_test` (`column_a` int, `column_b` int, `details` text, `status` tinyint) default character set utf8', 'alter table `composite_key_test` add unique `composite_key_test_column_a_column_b_unique`(`column_a`, `column_b`)']);\n          tester(['pg', 'cockroachdb'], ['create table \"composite_key_test\" (\"column_a\" integer, \"column_b\" integer, \"details\" text, \"status\" smallint)', 'alter table \"composite_key_test\" add constraint \"composite_key_test_column_a_column_b_unique\" unique (\"column_a\", \"column_b\")']);\n          tester('pg-redshift', ['create table \"composite_key_test\" (\"column_a\" integer, \"column_b\" integer, \"details\" varchar(max), \"status\" smallint)', 'alter table \"composite_key_test\" add constraint \"composite_key_test_column_a_column_b_unique\" unique (\"column_a\", \"column_b\")']);\n          tester('sqlite3', ['create table `composite_key_test` (`column_a` integer, `column_b` integer, `details` text, `status` tinyint)', 'create unique index `composite_key_test_column_a_column_b_unique` on `composite_key_test` (`column_a`, `column_b`)']);\n          tester('oracledb', ['create table \"composite_key_test\" (\"column_a\" integer, \"column_b\" integer, \"details\" clob, \"status\" smallint)', 'alter table \"composite_key_test\" add constraint \"zYmMt0VQwlLZ20XnrMicXZ0ufZk\" unique (\"column_a\", \"column_b\")']);\n          tester('mssql', ['CREATE TABLE [composite_key_test] ([column_a] int, [column_b] int, [details] nvarchar(max), [status] tinyint)', 'CREATE UNIQUE INDEX [composite_key_test_column_a_column_b_unique] ON [composite_key_test] ([column_a], [column_b]) WHERE [column_a] IS NOT NULL AND [column_b] IS NOT NULL']);\n        }).then(() => knex('composite_key_test').insert([{\n          column_a: 1,\n          column_b: 1,\n          details: 'One, One, One',\n          status: 1\n        }, {\n          column_a: 1,\n          column_b: 2,\n          details: 'One, Two, Zero',\n          status: 0\n        }, {\n          column_a: 1,\n          column_b: 3,\n          details: 'One, Three, Zero',\n          status: 0\n        }])));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"is possible to set the table collation with table.charset and table.collate","suites":["Schema (misc)","createTable","enum - postgres"],"updatePoint":{"line":773,"column":87,"index":50418},"line":773,"code":"        it('is possible to set the table collation with table.charset and table.collate', () => knex.schema.createTable('charset_collate_test', table => {\n          if (isMysql(knex)) {\n            table.charset('latin1');\n            table.collate('latin1_general_ci');\n            table.engine('InnoDB');\n          }\n\n          table.increments();\n          table.integer('account_id');\n          table.text('details');\n          table.tinyint('status');\n        }).testSql(tester => {\n          tester('mysql', ['create table `charset_collate_test` (`id` int unsigned not null auto_increment primary key, `account_id` int, `details` text, `status` tinyint) default character set latin1 collate latin1_general_ci engine = InnoDB']);\n          tester(['pg', 'cockroachdb'], ['create table \"charset_collate_test\" (\"id\" serial primary key, \"account_id\" integer, \"details\" text, \"status\" smallint)']);\n          tester('pg-redshift', ['create table \"charset_collate_test\" (\"id\" integer identity(1,1) primary key not null, \"account_id\" integer, \"details\" varchar(max), \"status\" smallint)']);\n          tester('sqlite3', ['create table `charset_collate_test` (`id` integer not null primary key autoincrement, `account_id` integer, `details` text, `status` tinyint)']);\n          tester('oracledb', ['create table \"charset_collate_test\" (\"id\" integer not null primary key, \"account_id\" integer, \"details\" clob, \"status\" smallint)', 'DECLARE PK_NAME VARCHAR(200); BEGIN  EXECUTE IMMEDIATE (\\'CREATE SEQUENCE \"charset_collate_test_seq\"\\');  SELECT cols.column_name INTO PK_NAME  FROM all_constraints cons, all_cons_columns cols  WHERE cons.constraint_type = \\'P\\'  AND cons.constraint_name = cols.constraint_name  AND cons.owner = cols.owner  AND cols.table_name = \\'charset_collate_test\\';  execute immediate (\\'create or replace trigger \"x9C3VzXH9urIKnTjm32JM7OvYYQ\"  BEFORE INSERT on \"charset_collate_test\"  for each row  declare  checking number := 1;  begin    if (:new.\"\\' || PK_NAME || \\'\" is null) then      while checking >= 1 loop        select \"charset_collate_test_seq\".nextval into :new.\"\\' || PK_NAME || \\'\" from dual;        select count(\"\\' || PK_NAME || \\'\") into checking from \"charset_collate_test\"        where \"\\' || PK_NAME || \\'\" = :new.\"\\' || PK_NAME || \\'\";      end loop;    end if;  end;\\'); END;']);\n          tester('mssql', ['CREATE TABLE [charset_collate_test] ([id] int identity(1,1) not null primary key, [account_id] int, [details] nvarchar(max), [status] tinyint)']);\n        }));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"sets booleans & defaults correctly","suites":["Schema (misc)","createTable","enum - postgres"],"updatePoint":{"line":792,"column":46,"index":52886},"line":792,"code":"        it('sets booleans & defaults correctly', () => knex.schema.createTable('bool_test', table => {\n          table.bool('one');\n          table.bool('two').defaultTo(false);\n          table.bool('three').defaultTo(true);\n          table.bool('four').defaultTo('true');\n          table.bool('five').defaultTo('false');\n        }).testSql(tester => {\n          tester('mysql', [\"create table `bool_test` (`one` boolean, `two` boolean default '0', `three` boolean default '1', `four` boolean default '1', `five` boolean default '0') default character set utf8\"]);\n          tester(['pg', 'cockroachdb'], ['create table \"bool_test\" (\"one\" boolean, \"two\" boolean default \\'0\\', \"three\" boolean default \\'1\\', \"four\" boolean default \\'1\\', \"five\" boolean default \\'0\\')']);\n          tester('pg-redshift', ['create table \"bool_test\" (\"one\" boolean, \"two\" boolean default \\'0\\', \"three\" boolean default \\'1\\', \"four\" boolean default \\'1\\', \"five\" boolean default \\'0\\')']);\n          tester('better-sqlite3', [\"create table `bool_test` (`one` boolean, `two` boolean default '0', `three` boolean default '1', `four` boolean default '1', `five` boolean default '0')\"]);\n          tester('sqlite3', [\"create table `bool_test` (`one` boolean, `two` boolean default '0', `three` boolean default '1', `four` boolean default '1', `five` boolean default '0')\"]);\n          tester('oracledb', [\"create table \\\"bool_test\\\" (\\\"one\\\" number(1, 0) check (\\\"one\\\" in ('0', '1')), \\\"two\\\" number(1, 0) default '0' check (\\\"two\\\" in ('0', '1')), \\\"three\\\" number(1, 0) default '1' check (\\\"three\\\" in ('0', '1')), \\\"four\\\" number(1, 0) default '1' check (\\\"four\\\" in ('0', '1')), \\\"five\\\" number(1, 0) default '0' check (\\\"five\\\" in ('0', '1')))\"]);\n          tester('mssql', [\"CREATE TABLE [bool_test] ([one] bit, [two] bit CONSTRAINT [bool_test_two_default] DEFAULT '0', [three] bit CONSTRAINT [bool_test_three_default] DEFAULT '1', [four] bit CONSTRAINT [bool_test_four_default] DEFAULT '1', [five] bit CONSTRAINT [bool_test_five_default] DEFAULT '0')\"]);\n        }).then(() => knex.insert({\n          one: false\n        }).into('bool_test')));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"accepts table names starting with numeric values","suites":["Schema (misc)","createTable","enum - postgres"],"updatePoint":{"line":809,"column":60,"index":55029},"line":809,"code":"        it('accepts table names starting with numeric values', () => knex.schema.createTable('10_test_table', table => {\n          table.bigIncrements('id');\n          table.string('first_name').index();\n          table.string('last_name');\n          table.string('email').unique().nullable();\n          table.integer('logins').defaultTo(1).index().comment();\n        }).testSql(tester => {\n          tester('mysql', [\"create table `10_test_table` (`id` bigint unsigned not null auto_increment primary key, `first_name` varchar(255), `last_name` varchar(255), `email` varchar(255) null, `logins` int default '1') default character set utf8\", 'alter table `10_test_table` add index `10_test_table_first_name_index`(`first_name`)', 'alter table `10_test_table` add unique `10_test_table_email_unique`(`email`)', 'alter table `10_test_table` add index `10_test_table_logins_index`(`logins`)']);\n          tester(['pg', 'cockroachdb'], ['create table \"10_test_table\" (\"id\" bigserial primary key, \"first_name\" varchar(255), \"last_name\" varchar(255), \"email\" varchar(255) null, \"logins\" integer default \\'1\\')', 'comment on column \"10_test_table\".\"logins\" is NULL', 'create index \"10_test_table_first_name_index\" on \"10_test_table\" (\"first_name\")', 'alter table \"10_test_table\" add constraint \"10_test_table_email_unique\" unique (\"email\")', 'create index \"10_test_table_logins_index\" on \"10_test_table\" (\"logins\")']);\n          tester('sqlite3', [\"create table `10_test_table` (`id` integer not null primary key autoincrement, `first_name` varchar(255), `last_name` varchar(255), `email` varchar(255) null, `logins` integer default '1')\", 'create index `10_test_table_first_name_index` on `10_test_table` (`first_name`)', 'create unique index `10_test_table_email_unique` on `10_test_table` (`email`)', 'create index `10_test_table_logins_index` on `10_test_table` (`logins`)']);\n          tester('oracledb', ['create table \"10_test_table\" (\"id\" number(20, 0) not null primary key, \"first_name\" varchar2(255), \"last_name\" varchar2(255), \"email\" varchar2(255) null, \"logins\" integer default \\'1\\')', 'DECLARE PK_NAME VARCHAR(200); BEGIN  EXECUTE IMMEDIATE (\\'CREATE SEQUENCE \"10_test_table_seq\"\\');  SELECT cols.column_name INTO PK_NAME  FROM all_constraints cons, all_cons_columns cols  WHERE cons.constraint_type = \\'P\\'  AND cons.constraint_name = cols.constraint_name  AND cons.owner = cols.owner  AND cols.table_name = \\'10_test_table\\';  execute immediate (\\'create or replace trigger \"10_test_table_autoinc_trg\"  BEFORE INSERT on \"10_test_table\"  for each row  declare  checking number := 1;  begin    if (:new.\"\\' || PK_NAME || \\'\" is null) then      while checking >= 1 loop        select \"10_test_table_seq\".nextval into :new.\"\\' || PK_NAME || \\'\" from dual;        select count(\"\\' || PK_NAME || \\'\") into checking from \"10_test_table\"        where \"\\' || PK_NAME || \\'\" = :new.\"\\' || PK_NAME || \\'\";      end loop;    end if;  end;\\'); END;', 'comment on column \"10_test_table\".\"logins\" is \\'\\'', 'create index \"10_test_table_first_name_index\" on \"10_test_table\" (\"first_name\")', 'alter table \"10_test_table\" add constraint \"10_test_table_email_unique\" unique (\"email\")', 'create index \"10_test_table_logins_index\" on \"10_test_table\" (\"logins\")']);\n        }));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"test boolean type with sqlite3 and better sqlite3 #4955","suites":["Schema (misc)","createTable","enum - postgres"],"updatePoint":{"line":821,"column":67,"index":58303},"line":821,"code":"        it('test boolean type with sqlite3 and better sqlite3 #4955', async function () {\n          if (!isSQLite(knex)) {\n            this.skip();\n          }\n\n          await knex.schema.dropTableIfExists('test').createTable('test', table => {\n            table.boolean('value').notNullable();\n          });\n          await knex('test').insert([{\n            value: true\n          }, {\n            value: false\n          }]);\n          const data = await knex('test').select();\n          expect(data[0].value).to.eq(1);\n          expect(data[1].value).to.eq(0);\n        });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"Callback function must be supplied","suites":["Schema (misc)","table"],"updatePoint":{"line":840,"column":46,"index":58900},"line":840,"code":"        it('Callback function must be supplied', () => {\n          expect(() => {\n            knex.schema.createTable('callback_must_be_supplied').toString();\n          }).to.throw(TypeError);\n          expect(() => {\n            knex.schema.createTable('callback_must_be_supplied', () => {}).toString();\n          }).to.not.throw(TypeError);\n        });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"allows adding a field","suites":["Schema (misc)","table"],"updatePoint":{"line":848,"column":33,"index":59242},"line":848,"code":"        it('allows adding a field', () => knex.schema.table('test_table_two', t => {\n          t.json('json_data', true);\n        }));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"allows adding multiple columns at once","suites":["Schema (misc)","table"],"updatePoint":{"line":851,"column":50,"index":59394},"line":851,"code":"        it('allows adding multiple columns at once', function () {\n          if (isRedshift(knex)) {\n            return this.skip();\n          }\n\n          return knex.schema.table('test_table_two', t => {\n            t.string('one');\n            t.string('two');\n            t.string('three');\n          }).then(() => knex.schema.table('test_table_two', t => {\n            t.dropColumn('one');\n            t.dropColumn('two');\n            t.dropColumn('three');\n          }));\n        });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"handles creating numeric columns with specified length correctly","suites":["Schema (misc)","table"],"updatePoint":{"line":866,"column":76,"index":59910},"line":866,"code":"        it('handles creating numeric columns with specified length correctly', () => knex.schema.createTable('test_table_numerics2', table => {\n          table.integer('integer_column', 5);\n          table.tinyint('tinyint_column', 5);\n          table.smallint('smallint_column', 5);\n          table.mediumint('mediumint_column', 5);\n          table.bigint('bigint_column', 5);\n        }).then(() => knex.schema.dropTable('test_table_numerics2')));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"allows alter column syntax","suites":["Schema (misc)","table"],"updatePoint":{"line":873,"column":38,"index":60321},"line":873,"code":"        it('allows alter column syntax', async () => {\n          if (isSQLite(knex) || isRedshift(knex) || isMssql(knex) || isOracle(knex) || isCockroachDB(knex)) {\n            return;\n          }\n\n          await knex.schema.table('test_table_two', t => {\n            t.integer('remove_not_null').notNull().defaultTo(1);\n            t.string('remove_default').notNull().defaultTo(1);\n            t.dateTime('datetime_to_date').notNull().defaultTo(knex.fn.now());\n          });\n          await knex.schema.table('test_table_two', t => {\n            t.integer('remove_not_null').defaultTo(1).alter();\n            t.integer('remove_default').notNull().alter();\n            t.date('datetime_to_date').alter();\n          });\n          const info = await knex('test_table_two').columnInfo();\n          expect(info.remove_not_null.nullable).to.equal(true);\n          expect(info.remove_not_null.defaultValue).to.not.equal(null);\n          expect(info.remove_default.nullable).to.equal(false);\n          expect(info.remove_default.defaultValue).to.equal(null);\n          expect(info.remove_default.type).to.contains('int');\n          await knex.schema.table('test_table_two', t => {\n            t.dropColumn('remove_default');\n            t.dropColumn('remove_not_null');\n            t.dropColumn('datetime_to_date');\n          });\n        });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"allows adding a field with custom collation after another field","suites":["Schema (misc)","table"],"updatePoint":{"line":900,"column":75,"index":61695},"line":900,"code":"        it('allows adding a field with custom collation after another field', () => knex.schema.table('test_table_two', t => {\n          t.string('ref_column').after('json_data');\n        }).then(() => knex.schema.table('test_table_two', t => {\n          t.string('after_column').after('ref_column').collate('utf8_bin');\n        })).then(() => knex.schema.table('test_table_two', t => {\n          t.dropColumn('ref_column');\n          t.dropColumn('after_column');\n        })));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"allows adding a field with custom collation first","suites":["Schema (misc)","table"],"updatePoint":{"line":908,"column":61,"index":62160},"line":908,"code":"        it('allows adding a field with custom collation first', () => knex.schema.table('test_table_two', t => {\n          t.string('first_column').first().collate('utf8_bin');\n        }).then(() => knex.schema.table('test_table_two', t => {\n          t.dropColumn('first_column');\n        })));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"allows changing a field","suites":["Schema (misc)","table"],"updatePoint":{"line":913,"column":35,"index":62430},"line":913,"code":"        it('allows changing a field', () => knex.schema.table('test_table_one', t => {\n          t.string('phone').nullable();\n        }));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"allows dropping a unique index","suites":["Schema (misc)","table"],"updatePoint":{"line":916,"column":42,"index":62577},"line":916,"code":"        it('allows dropping a unique index', () => knex.schema.table('composite_key_test', t => {\n          t.dropUnique(['column_a', 'column_b']);\n        }));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"allows dropping a index","suites":["Schema (misc)","table"],"updatePoint":{"line":919,"column":35,"index":62731},"line":919,"code":"        it('allows dropping a index', () => knex.schema.table('test_table_one', t => {\n          t.dropIndex('first_name');\n        }));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"allows creating indexes with predicate","suites":["Schema (misc)","table","supports partial indexes - postgres, sqlite, and mssql"],"updatePoint":{"line":923,"column":52,"index":62974},"line":923,"code":"          it('allows creating indexes with predicate', async function () {\n            if (!(isPostgreSQL(knex) || isMssql(knex) || isSQLite(knex))) {\n              return this.skip();\n            }\n\n            await knex.schema.table('test_table_one', function (t) {\n              t.index('first_name', 'first_name_idx', {\n                predicate: knex.whereRaw(\"first_name = 'brandon'\")\n              });\n              t.index('phone', 'phone_idx', {\n                predicate: knex.whereNotNull('phone')\n              });\n            });\n          });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"actually stores the predicate in the Postgres server","suites":["Schema (misc)","table","supports partial indexes - postgres, sqlite, and mssql"],"updatePoint":{"line":937,"column":66,"index":63546},"line":937,"code":"          it('actually stores the predicate in the Postgres server', async function () {\n            if (!isPostgreSQL(knex)) {\n              return this.skip();\n            }\n\n            await knex.schema.table('test_table_one', function (t) {\n              t.index('phone', 'phone_idx_2', {\n                predicate: knex.whereNotNull('phone')\n              });\n            });\n            const results = await knex.from('pg_class').innerJoin('pg_index', 'pg_index.indexrelid', 'pg_class.oid').where({\n              relname: 'phone_idx_2',\n              indisvalid: true\n            }).whereNotNull('indpred');\n            expect(results).to.not.be.empty;\n          });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"checks whether a table exists","suites":["Schema (misc)","hasTable"],"updatePoint":{"line":956,"column":41,"index":64253},"line":956,"code":"        it('checks whether a table exists', () => knex.schema.hasTable('test_table_two').then(resp => {\n          expect(resp).to.equal(true);\n        }));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"should be false if a table does not exists","suites":["Schema (misc)","hasTable"],"updatePoint":{"line":959,"column":54,"index":64422},"line":959,"code":"        it('should be false if a table does not exists', () => knex.schema.hasTable('this_table_is_fake').then(resp => {\n          expect(resp).to.equal(false);\n        }));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"should be false whether a parameter is not specified","suites":["Schema (misc)","hasTable"],"updatePoint":{"line":962,"column":64,"index":64606},"line":962,"code":"        it('should be false whether a parameter is not specified', () => knex.schema.hasTable('').then(resp => {\n          expect(resp).to.equal(false);\n        }));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"should not parse table name if wrapIdentifier is not specified","suites":["Schema (misc)","hasTable","sqlite only"],"updatePoint":{"line":966,"column":76,"index":64824},"line":966,"code":"          it('should not parse table name if wrapIdentifier is not specified', async function () {\n            if (!isSQLite(knex)) {\n              return this.skip();\n            }\n\n            knex.client.config.wrapIdentifier = null;\n            const resp = await knex.schema.hasTable('testTableTwo');\n            expect(resp).to.be.false;\n          });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"should parse table name if wrapIdentifier is specified","suites":["Schema (misc)","hasTable","sqlite only"],"updatePoint":{"line":975,"column":68,"index":65174},"line":975,"code":"          it('should parse table name if wrapIdentifier is specified', async function () {\n            if (!isSQLite(knex)) {\n              return this.skip();\n            }\n\n            knex.client.config.wrapIdentifier = (value, origImpl, queryContext) => origImpl(_.snakeCase(value));\n\n            const resp = await knex.schema.hasTable('testTableTwo');\n            expect(resp).to.be.true;\n          });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"renames the table from one to another","suites":["Schema (misc)","renameTable"],"updatePoint":{"line":988,"column":49,"index":65624},"line":988,"code":"        it('renames the table from one to another', () => knex.schema.renameTable('test_table_one', 'accounts'));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"should drop a table","suites":["Schema (misc)","dropTable"],"updatePoint":{"line":991,"column":31,"index":65766},"line":991,"code":"        it('should drop a table', () => knex.schema.dropTable('test_table_three').then(() => {\n          // Drop this here so we don't have foreign key constraints...\n          return knex.schema.dropTable('test_foreign_table_two');\n        }));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"checks whether a column exists, resolving with a boolean","suites":["Schema (misc)","hasColumn","without processors"],"updatePoint":{"line":998,"column":70,"index":66144},"line":998,"code":"          it('checks whether a column exists, resolving with a boolean', () => knex.schema.hasColumn('accounts', 'first_name').then(exists => {\n            expect(exists).to.equal(true);\n          }));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"checks whether a column exists without being case sensitive, resolving with a boolean","suites":["Schema (misc)","hasColumn","without processors","sqlite only"],"updatePoint":{"line":1002,"column":101,"index":66419},"line":1002,"code":"            it('checks whether a column exists without being case sensitive, resolving with a boolean', async function () {\n              if (!isSQLite(knex)) {\n                return this.skip();\n              }\n\n              const exists = await knex.schema.hasColumn('accounts', 'FIRST_NAME');\n              expect(exists).to.equal(true);\n            });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"checks whether a column exists, resolving with a boolean","suites":["Schema (misc)","hasColumn","using processorss","sqlite and pg only"],"updatePoint":{"line":1022,"column":72,"index":67222},"line":1022,"code":"            it('checks whether a column exists, resolving with a boolean', async function () {\n              if (!isSQLite(knex) && !isPgBased(knex)) {\n                return this.skip();\n              }\n\n              const exists = await knex.schema.hasColumn('accounts', 'firstName');\n              expect(exists).to.equal(false);\n            });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"should columns order be correctly with after and first","suites":["Schema (misc)","addColumn","mysql only"],"updatePoint":{"line":1054,"column":68,"index":68604},"line":1054,"code":"          it('should columns order be correctly with after and first', function () {\n            if (!isMysql(knex)) {\n              return this.skip();\n            }\n\n            return knex.raw('SHOW CREATE TABLE `add_column_test_mysql`').then(schema => {\n              // .columnInfo() keys does not guaranteed fields order.\n              const fields = schema[0][0]['Create Table'].split('\\n').filter(e => e.trim().indexOf('`field_') === 0).map(e => e.trim()).map(e => e.slice(1, e.slice(1).indexOf('`') + 1)); // Fields order\n\n              expect(fields[0]).to.equal('field_first');\n              expect(fields[1]).to.equal('field_foo');\n              expect(fields[2]).to.equal('field_after_foo');\n              expect(fields[3]).to.equal('field_bar');\n              expect(fields[4]).to.equal('field_nondefault_increments'); // .columnInfo() does not included fields comment.\n\n              const comments = schema[0][0]['Create Table'].split('\\n').filter(e => e.trim().indexOf('`field_') === 0).map(e => e.slice(e.indexOf(\"'\")).trim()).map(e => e.slice(1, e.slice(1).indexOf(\"'\") + 1)); // Fields comment\n\n              expect(comments[0]).to.equal('First');\n              expect(comments[1]).to.equal('foo');\n              expect(comments[2]).to.equal('After');\n              expect(comments[3]).to.equal('bar');\n              expect(comments[4]).to.equal('Comment on increment col');\n            });\n          });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"renames the column","suites":["Schema (misc)","renameColumn","without mappers"],"updatePoint":{"line":1097,"column":32,"index":70994},"line":1097,"code":"          it('renames the column', async () => {\n            await knex.schema.table('rename_column_test', tbl => tbl.renameColumn('id_test', 'id'));\n            const exists = await knex.schema.hasColumn('rename_column_test', 'id');\n            expect(exists).to.equal(true);\n          });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"successfully renames a column referenced in a foreign key","suites":["Schema (misc)","renameColumn","without mappers"],"updatePoint":{"line":1102,"column":71,"index":71324},"line":1102,"code":"          it('successfully renames a column referenced in a foreign key', () => knex.schema.table('rename_column_test', tbl => {\n            tbl.renameColumn('parent_id_test', 'parent_id');\n          }));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"successfully renames a column referenced by another table","suites":["Schema (misc)","renameColumn","without mappers"],"updatePoint":{"line":1105,"column":71,"index":71529},"line":1105,"code":"          it('successfully renames a column referenced by another table', () => knex.schema.table('rename_column_test', tbl => {\n            tbl.renameColumn('id', 'id_new');\n          }));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"#933 - .renameColumn should not drop null or default value","suites":["Schema (misc)","renameColumn","without mappers"],"updatePoint":{"line":1108,"column":72,"index":71720},"line":1108,"code":"          it('#933 - .renameColumn should not drop null or default value', () => {\n            const tableName = 'rename_col_test';\n            return knex.transaction(tr => {\n              const getColInfo = () => tr(tableName).columnInfo();\n\n              return getColInfo().then(colInfo => {\n                expect(String(colInfo.colnameint.defaultValue)).to.contain('1'); // Using contain because of different response per dialect.\n                // IE mysql 'knex', postgres 'knex::character varying'\n\n                expect(colInfo.colnamestring.defaultValue).to.contain('knex');\n                expect(colInfo.colnamestring.nullable).to.equal(false);\n                return tr.schema.table(tableName, table => {\n                  table.renameColumn('colnameint', 'colnameintchanged');\n                  table.renameColumn('colnamestring', 'colnamestringchanged');\n                });\n              }).then(getColInfo).then(columnInfo => {\n                expect(String(columnInfo.colnameintchanged.defaultValue)).to.contain('1');\n                expect(columnInfo.colnamestringchanged.defaultValue).to.contain('knex');\n                expect(columnInfo.colnamestringchanged.nullable).to.equal(false);\n              });\n            });\n          });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"#2767 - .renameColumn should not drop the auto incremental","suites":["Schema (misc)","renameColumn","without mappers"],"updatePoint":{"line":1130,"column":72,"index":72978},"line":1130,"code":"          it('#2767 - .renameColumn should not drop the auto incremental', async () => {\n            const tableName = 'rename_column_test';\n\n            if (isMssql(knex)) {\n              const res = await knex.raw(`select COLUMNPROPERTY(object_id(TABLE_SCHEMA + '.' + TABLE_NAME), COLUMN_NAME,\n                                             'IsIdentity') as Ident\n                       from INFORMATION_SCHEMA.COLUMNS\n                       where TABLE_NAME = ?\n                         AND COLUMN_NAME = ?;`, [tableName, 'id_new']);\n              const autoinc = res[0].Ident;\n              expect(autoinc).to.equal(1);\n            } else if (isMysql(knex)) {\n              const res = await knex.raw(`show fields from ${tableName}`);\n              const autoinc = res[0][0].Extra;\n              expect(autoinc).to.equal('auto_increment');\n            } else if (isPostgreSQL(knex)) {\n              const res = await knex.raw(`select pg_get_serial_sequence(table_name, column_name) as ident\n                       from INFORMATION_SCHEMA.COLUMNS\n                       where table_name = ?\n                         AND column_name = ?;`, [tableName, 'id_new']);\n              const autoinc = !!res.rows[0].ident;\n              expect(autoinc).to.equal(true);\n            } else if (isBetterSQLite3(knex)) {\n              const res = await knex.raw(`SELECT 'is-autoincrement' as ident\n                       FROM sqlite_master\n                       WHERE tbl_name = ? AND sql LIKE '%AUTOINCREMENT%'`, [tableName]);\n              const autoinc = !!res[0].ident;\n              expect(autoinc).to.equal(true);\n            } else if (isSQLite(knex)) {\n              const res = await knex.raw(`SELECT \"is-autoincrement\" as ident\n                       FROM sqlite_master\n                       WHERE tbl_name = ? AND sql LIKE \"%AUTOINCREMENT%\"`, [tableName]);\n              const autoinc = !!res[0].ident;\n              expect(autoinc).to.equal(true);\n            }\n          });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"drops the column when spelled ''","suites":["Schema (misc)","dropColumn","using wrapIdentifier and postProcessResponse"],"updatePoint":{"line":1195,"column":63,"index":76213},"line":1195,"code":"              it(`drops the column when spelled '${columnName}'`, () => knex.schema.table(tableName, tbl => tbl.dropColumn(columnName)).then(() => knex.schema.hasColumn(tableName, 'field_foo')).then(exists => {\n                expect(exists).to.equal(false);\n              }));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"drops the column","suites":["Schema (misc)","dropColumn","when table is created using raw create table"],"updatePoint":{"line":1229,"column":32,"index":78055},"line":1229,"code":"            it('drops the column', async () => {\n              await dropCol('i0');\n              expect(await hasCol('i0')).to.equal(false); // Constraint i0 should be unaffected:\n\n              expect(await getCreateTableExpr()).to.equal('CREATE TABLE \"TEST\" (`i1` integer, `i2` integer, `i3` integer, `i4` ' + 'integer, `I5` integer, UNIQUE (`i4`, `i5`), CONSTRAINT `i0` PRIMARY ' + 'KEY (`i3`, `i4`), UNIQUE (`i2`), FOREIGN KEY (`i1`) REFERENCES `bar` ' + '(`i3`))');\n              await dropCol('i1');\n              expect(await hasCol('i1')).to.equal(false); // Foreign key on i1 should also be dropped:\n\n              expect(await getCreateTableExpr()).to.equal('CREATE TABLE \"TEST\" (`i2` integer, `i3` integer, `i4` integer, `I5` integer, ' + 'UNIQUE (`i4`, `i5`), CONSTRAINT `i0` PRIMARY KEY (`i3`, `i4`), UNIQUE (`i2`))');\n              await dropCol('i2');\n              expect(await hasCol('i2')).to.equal(false);\n              expect(await getCreateTableExpr()).to.equal('CREATE TABLE \"TEST\" (`i3` integer, `i4` integer, `I5` integer, ' + 'UNIQUE (`i4`, `i5`), CONSTRAINT `i0` PRIMARY KEY (`i3`, `i4`))');\n              await dropCol('i3');\n              expect(await hasCol('i3')).to.equal(false);\n              expect(await getCreateTableExpr()).to.equal('CREATE TABLE \"TEST\" (`i4` integer, `I5` integer, UNIQUE (`i4`, `i5`))');\n              await dropCol('i4');\n              expect(await hasCol('i4')).to.equal(false);\n              expect(await getCreateTableExpr()).to.equal('CREATE TABLE \"TEST\" (`I5` integer)');\n              let lastColDeletionError;\n              await knex.schema.alterTable('TEST', tbl => tbl.dropColumn('i5')).catch(e => {\n                lastColDeletionError = e;\n              });\n              expect(lastColDeletionError.message).to.eql('Unable to drop last column from table');\n            });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"should not find non-existent tables","suites":["Schema (misc)","withSchema","mssql only"],"updatePoint":{"line":1292,"column":49,"index":81298},"line":1292,"code":"          it('should not find non-existent tables', () => checkTable(testSchemaName, 'test', false).then(() => checkTable(defaultSchemaName, 'test', false)));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"should create and drop tables","suites":["Schema (misc)","withSchema","mssql only"],"updatePoint":{"line":1293,"column":43,"index":81451},"line":1293,"code":"          it('should create and drop tables', () => createTable(testSchemaName, 'test').then(() => checkColumn(testSchemaName, 'test')).then(() => checkTable(testSchemaName, 'test', true)).then(() => checkTable(defaultSchemaName, 'test', false)).then(() => knex.schema.withSchema(testSchemaName).dropTableIfExists('test')).then(() => checkTable(testSchemaName, 'test', false)));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"should rename tables","suites":["Schema (misc)","withSchema","mssql only"],"updatePoint":{"line":1294,"column":34,"index":81821},"line":1294,"code":"          it('should rename tables', () => createTable(testSchemaName, 'test').then(() => renameTable(testSchemaName, 'test', 'test2')).then(() => checkColumn(testSchemaName, 'test2')).then(() => checkTable(defaultSchemaName, 'test2', false)).then(() => checkTable(testSchemaName, 'test', false)).then(() => checkTable(testSchemaName, 'test2', true)).then(() => knex.schema.withSchema(testSchemaName).dropTableIfExists('test2')));","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"should get columnInfo from a case-sensitive database","suites":["Schema (misc)","withSchema","mssql only","case-sensitive collation support"],"updatePoint":{"line":1331,"column":68,"index":83763},"line":1331,"code":"            it('should get columnInfo from a case-sensitive database', async () => {\n              const info = await k(tableName).columnInfo();\n              expect(info).not.to.equal(undefined);\n            });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"should warn attempting to create primary from nonexistent columns","suites":["Schema (misc)","withSchema","mssql only","case-sensitive collation support"],"updatePoint":{"line":1338,"column":75,"index":84019},"line":1338,"code":"      it('should warn attempting to create primary from nonexistent columns', function () {\n        // Redshift only\n        if (!isRedshift(knex)) {\n          return this.skip();\n        }\n\n        const tableName = 'no_test_column';\n        const constraintName = 'testconstraintname';\n        return knex.transaction(tr => tr.schema.dropTableIfExists(tableName).then(() => tr.schema.createTable(tableName, t => {\n          t.string('test_zero').notNullable();\n          t.string('test_one').notNullable();\n        })).then(() => tr.schema.table(tableName, u => {\n          u.primary(['test_one', 'test_two'], constraintName);\n        })).then(() => {\n          throw new Error('should have failed');\n        }).catch(err => {\n          expect(err.code).to.equal('42703');\n          expect(err.message).to.equal(`alter table \"${tableName}\"\n                      add constraint \"${constraintName}\" primary key (\"test_one\", \"test_two\") - column \"test_two\" named in key does not exist`);\n        }).then(res => knex.schema.dropTableIfExists(tableName)));\n      }); //Unit tests checks SQL -- This will test running those queries, no hard assertions here.","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"#1430 - .primary() & .dropPrimary() same for all dialects","suites":["Schema (misc)","withSchema","mssql only","case-sensitive collation support"],"updatePoint":{"line":1360,"column":67,"index":85166},"line":1360,"code":"      it('#1430 - .primary() & .dropPrimary() same for all dialects', async function () {\n        if (isSQLite(knex)) {\n          return this.skip();\n        }\n\n        const constraintName = 'testconstraintname';\n        const tableName = 'primarytest';\n        await knex.schema.dropTableIfExists(tableName);\n        await knex.transaction(async tr => {\n          await tr.schema.createTable(tableName, table => {\n            table.string('test').primary(constraintName).notNull();\n            table.string('test2').notNullable();\n          });\n          await tr.schema.table(tableName, table => {\n            table.dropPrimary(constraintName);\n          });\n          await tr.schema.table(tableName, table => {\n            table.primary(['test', 'test2'], constraintName);\n          });\n        });\n      });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"should return empty resultset when referencing an existent column","suites":["Schema (misc)","invalid field","sqlite3 only"],"updatePoint":{"line":1389,"column":79,"index":86347},"line":1389,"code":"          it('should return empty resultset when referencing an existent column', function () {\n            if (!isSQLite(knex)) {\n              return this.skip();\n            }\n\n            return knex(tableName).select().where(fieldName, 'something').then(rows => {\n              expect(rows.length).to.equal(0);\n            });\n          });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"should throw when referencing a non-existent column","suites":["Schema (misc)","invalid field","sqlite3 only"],"updatePoint":{"line":1398,"column":65,"index":86679},"line":1398,"code":"          it('should throw when referencing a non-existent column', function () {\n            if (!isSQLite(knex)) {\n              return this.skip();\n            }\n\n            return knex(tableName).select().where(fieldName + 'foo', 'something').then(() => {\n              throw new Error('should have failed');\n            }).catch(err => {\n              expect(err.code).to.equal('SQLITE_ERROR');\n            });\n          });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"properly executes any ddl command when the table name is a substring of \"CREATE TABLE\"","suites":["Schema (misc)","sqlite ddl"],"updatePoint":{"line":1432,"column":98,"index":87711},"line":1432,"code":"        it('properly executes any ddl command when the table name is a substring of \"CREATE TABLE\"', async () => {\n          if (!isSQLite(knex)) {\n            return;\n          }\n\n          await expect(knex.schema.alterTable('CREATE TABLE', table => {\n            table.string('alter_column').alter();\n          })).to.not.be.eventually.rejected;\n        });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"supports named primary keys","suites":["Schema (misc)","sqlite ddl"],"updatePoint":{"line":1442,"column":37,"index":88021},"line":1442,"code":"      it('supports named primary keys', async () => {\n        const constraintName = 'pk-test';\n        const tableName = 'namedpk';\n        const expectedRes = [{\n          type: 'table',\n          name: tableName,\n          tbl_name: tableName,\n          sql: 'CREATE TABLE `' + tableName + '` (`test` varchar(255) not null, `test2` varchar(255) not null, constraint `' + constraintName + '` primary key (`test`))'\n        }];\n        await knex.transaction(tr => tr.schema.dropTableIfExists(tableName).then(() => tr.schema.createTable(tableName, table => {\n          table.string('test').primary(constraintName).notNull();\n          table.string('test2').notNull();\n        })).then(() => {\n          if (/sqlite/i.test(knex.client.dialect)) {\n            //For SQLite inspect metadata to make sure the constraint exists\n            return tr.select('type', 'name', 'tbl_name', 'sql').from('sqlite_master').where({\n              type: 'table',\n              name: tableName\n            }).then(value => {\n              expect(value).to.deep.have.same.members(expectedRes, 'Constraint \"' + constraintName + '\" not correctly created.');\n              return Promise.resolve();\n            });\n          } else {\n            return tr.schema.table(tableName, table => {\n              // CockroachDB requires primary column to exist\n              if (!isCockroachDB(knex)) {\n                // For everything else just drop the constraint by name to check existence\n                table.dropPrimary(constraintName);\n              }\n            });\n          }\n        }).then(() => tr.schema.dropTableIfExists(tableName)).then(() => tr.schema.createTable(tableName, table => {\n          table.string('test').notNull();\n          table.string('test2').notNull();\n          table.primary('test', constraintName);\n        })).then(() => {\n          if (/sqlite/i.test(knex.client.dialect)) {\n            //For SQLite inspect metadata to make sure the constraint exists\n            return tr.select('type', 'name', 'tbl_name', 'sql').from('sqlite_master').where({\n              type: 'table',\n              name: tableName\n            }).then(value => {\n              expect(value).to.deep.have.same.members(expectedRes, 'Constraint \"' + constraintName + '\" not correctly created.');\n              return Promise.resolve();\n            });\n          } else {\n            return tr.schema.table(tableName, table => {\n              // CockroachDB requires primary column to exist\n              if (!isCockroachDB(knex)) {\n                // For everything else just drop the constraint by name to check existence\n                table.dropPrimary(constraintName);\n              }\n            });\n          }\n        }).then(() => tr.schema.dropTableIfExists(tableName)).then(() => tr.schema.createTable(tableName, table => {\n          table.string('test').notNull();\n          table.string('test2').notNull();\n          table.primary(['test', 'test2'], constraintName);\n        })).then(() => {\n          if (isSQLite(knex)) {\n            //For SQLite inspect metadata to make sure the constraint exists\n            const expectedRes = [{\n              type: 'table',\n              name: tableName,\n              tbl_name: tableName,\n              sql: 'CREATE TABLE `' + tableName + '` (`test` varchar(255) not null, `test2` varchar(255) not null, constraint `' + constraintName + '` primary key (`test`, `test2`))'\n            }];\n            return tr.select('type', 'name', 'tbl_name', 'sql').from('sqlite_master').where({\n              type: 'table',\n              name: tableName\n            }).then(value => {\n              expect(value).to.deep.have.same.members(expectedRes, 'Constraint \"' + constraintName + '\" not correctly created.');\n              return Promise.resolve();\n            });\n          } else {\n            return tr.schema.table(tableName, table => {\n              // CockroachDB requires primary column to exist\n              if (!isCockroachDB(knex)) {\n                // For everything else just drop the constraint by name to check existence\n                table.dropPrimary(constraintName);\n              }\n            });\n          }\n        }).then(() => tr.schema.dropTableIfExists(tableName)));\n      });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"supports named unique keys","suites":["Schema (misc)","sqlite ddl"],"updatePoint":{"line":1527,"column":36,"index":92257},"line":1527,"code":"      it('supports named unique keys', () => {\n        const singleUniqueName = 'uk-single';\n        const multiUniqueName = 'uk-multi';\n        const tableName = 'nameduk';\n        return knex.transaction(tr => tr.schema.dropTableIfExists(tableName).then(() => tr.schema.createTable(tableName, table => {\n          table.string('test').unique(singleUniqueName);\n        })).then(() => {\n          if (/sqlite/i.test(knex.client.dialect)) {\n            //For SQLite inspect metadata to make sure the constraint exists\n            const expectedRes = [{\n              type: 'index',\n              name: singleUniqueName,\n              tbl_name: tableName,\n              sql: 'CREATE UNIQUE INDEX `' + singleUniqueName + '` on `' + tableName + '` (`test`)'\n            }];\n            return tr.select('type', 'name', 'tbl_name', 'sql').from('sqlite_master').where({\n              type: 'index',\n              tbl_name: tableName,\n              name: singleUniqueName\n            }).then(value => {\n              expect(value).to.deep.have.same.members(expectedRes, 'Constraint \"' + singleUniqueName + '\" not correctly created.');\n              return Promise.resolve();\n            });\n          } else {\n            return tr.schema.table(tableName, table => {\n              // For everything else just drop the constraint by name to check existence\n              table.dropUnique('test', singleUniqueName);\n            });\n          }\n        }).then(() => tr.schema.dropTableIfExists(tableName)).then(() => tr.schema.createTable(tableName, table => {\n          table.string('test');\n          table.string('test2');\n        })).then(() => tr.schema.table(tableName, table => {\n          table.unique('test', singleUniqueName);\n          table.unique(['test', 'test2'], multiUniqueName);\n        })).then(() => {\n          if (/sqlite/i.test(knex.client.dialect)) {\n            //For SQLite inspect metadata to make sure the constraint exists\n            const expectedRes = [{\n              type: 'index',\n              name: singleUniqueName,\n              tbl_name: tableName,\n              sql: 'CREATE UNIQUE INDEX `' + singleUniqueName + '` on `' + tableName + '` (`test`)'\n            }, {\n              type: 'index',\n              name: multiUniqueName,\n              tbl_name: tableName,\n              sql: 'CREATE UNIQUE INDEX `' + multiUniqueName + '` on `' + tableName + '` (`test`, `test2`)'\n            }];\n            return tr.select('type', 'name', 'tbl_name', 'sql').from('sqlite_master').where({\n              type: 'index',\n              tbl_name: tableName\n            }).then(value => {\n              expect(value).to.deep.have.same.members(expectedRes, 'Either \"' + singleUniqueName + '\" or \"' + multiUniqueName + '\" is missing.');\n              return Promise.resolve();\n            });\n          } else {\n            return tr.schema.table(tableName, table => {\n              // For everything else just drop the constraint by name to check existence\n              table.dropUnique('test', singleUniqueName);\n              table.dropUnique(['test', 'test2'], multiUniqueName);\n            });\n          }\n        }).then(() => tr.schema.dropTableIfExists(tableName)));\n      });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"supports named foreign keys","suites":["Schema (misc)","sqlite ddl"],"updatePoint":{"line":1592,"column":37,"index":95464},"line":1592,"code":"      it('supports named foreign keys', async () => {\n        const userTableName = 'nfk_user';\n        const groupTableName = 'nfk_group';\n        const joinTableName = 'nfk_user_group';\n        const userConstraint = ['fk', joinTableName, userTableName].join('-');\n        const groupConstraint = ['fk', joinTableName, groupTableName].join('-');\n        await knex.transaction(tr => tr.schema.dropTableIfExists(joinTableName).then(() => tr.schema.dropTableIfExists(userTableName)).then(() => tr.schema.dropTableIfExists(groupTableName)).then(() => tr.schema.createTable(userTableName, table => {\n          table.uuid('id').primary().notNull();\n          table.string('name').unique();\n        })).then(() => tr.schema.createTable(groupTableName, table => {\n          table.uuid('id').primary().notNull();\n          table.string('name').unique();\n        })).then(() => tr.schema.createTable(joinTableName, table => {\n          table.uuid('user').notNull().references('id').inTable(userTableName).withKeyName(['fk', joinTableName, userTableName].join('-'));\n          table.uuid('group').notNull();\n          table.primary(['user', 'group']);\n          table.foreign('group', ['fk', joinTableName, groupTableName].join('-')).references('id').inTable(groupTableName);\n        })).then(() => {\n          if (/sqlite/i.test(knex.client.dialect)) {\n            const expectedRes = [{\n              type: 'table',\n              name: joinTableName,\n              tbl_name: joinTableName,\n              sql: 'CREATE TABLE `' + joinTableName + '` (`user` char(36) not null, `group` char(36) not null, constraint `' + userConstraint + '` foreign key(`user`) references `' + userTableName + '`(`id`), constraint `' + groupConstraint + '` foreign key(`group`) references `' + groupTableName + '`(`id`), primary key (`user`, `group`))'\n            }];\n            return tr.select('type', 'name', 'tbl_name', 'sql').from('sqlite_master').where({\n              type: 'table',\n              name: joinTableName\n            }).then(value => {\n              expect(value).to.deep.have.same.members(expectedRes, 'Named foreign key not correctly created.');\n              return Promise.resolve();\n            });\n          } else {\n            return tr.schema.table(joinTableName, table => {\n              table.dropForeign('user', userConstraint);\n              table.dropForeign('group', groupConstraint);\n            });\n          }\n        }).then(() => tr.schema.dropTableIfExists(userTableName).then(() => tr.schema.dropTableIfExists(groupTableName)).then(() => tr.schema.dropTableIfExists(joinTableName))));\n      });","file":"integration2/schema/misc.spec.js","skipped":false,"dir":"test"},{"name":"creates a new primary key","suites":["Schema","Primary keys","createPrimaryKey"],"updatePoint":{"line":40,"column":39,"index":956},"line":40,"code":"          it('creates a new primary key', async () => {\n            await knex.schema.alterTable('primary_table', table => {\n              table.integer('id_four').notNull().primary();\n            });\n            await knex('primary_table').insert({\n              id_four: 1\n            });\n\n            try {\n              await knex('primary_table').insert({\n                id_four: 1\n              });\n              throw new Error(`Shouldn't reach this`);\n            } catch (err) {\n              if (isBetterSQLite3(knex)) {\n                expect(err.message).to.equal('insert into `primary_table` (`id_four`) values (1) - UNIQUE constraint failed: primary_table.id_four');\n              } else if (isSQLite(knex)) {\n                expect(err.message).to.equal('insert into `primary_table` (`id_four`) values (1) - SQLITE_CONSTRAINT_PRIMARYKEY: UNIQUE constraint failed: primary_table.id_four');\n              }\n\n              if (isPgBased(knex)) {\n                expect(err.message).to.equal('insert into \"primary_table\" (\"id_four\") values ($1) - duplicate key value violates unique constraint \"primary_table_pkey\"');\n              }\n            }\n          });","file":"integration2/schema/primary-keys.spec.js","skipped":false,"dir":"test"},{"name":"create multiple primary keys with increments on same column","suites":["Schema","Primary keys","createPrimaryKey"],"updatePoint":{"line":65,"column":73,"index":2164},"line":65,"code":"          it('create multiple primary keys with increments on same column', async function () {\n            await knex.schema.dropTableIfExists('table_multiple_keys');\n            await knex.schema.createTable('table_multiple_keys', function (t) {\n              t.primary(['id', 'second_id', 'other_col']);\n              t.string('second_id', 16).notNullable();\n              t.integer('other_col').notNullable();\n              t.increments('id');\n            });\n            await knex('table_multiple_keys').insert([{\n              second_id: 'abc',\n              other_col: 2\n            }, {\n              second_id: 'abc',\n              other_col: 3\n            }]);\n            expect(() => {\n              knex('table_multiple_keys').insert([{\n                id: 1,\n                second_id: 'abc',\n                other_col: 2\n              }]);\n            }).to.throw; // It's always ok, the primary key is on three columns.\n\n            await knex('table_multiple_keys').insert([{\n              second_id: 'abc',\n              other_col: 2\n            }, {\n              second_id: 'abc',\n              other_col: 3\n            }]);\n            expect(() => {\n              knex('table_multiple_keys').insert([{\n                id: 4,\n                second_id: 'abc',\n                other_col: 3\n              }]);\n            }).to.throw;\n          });","file":"integration2/schema/primary-keys.spec.js","skipped":false,"dir":"test"},{"name":"create multiple primary keys with increments on other columns","suites":["Schema","Primary keys","createPrimaryKey"],"updatePoint":{"line":103,"column":75,"index":3535},"line":103,"code":"          it('create multiple primary keys with increments on other columns', async function () {\n            await knex.schema.dropTableIfExists('table_multiple_keys');\n            await knex.schema.createTable('table_multiple_keys', function (t) {\n              t.primary(['second_id', 'other_col']);\n              t.string('second_id', 16).notNullable();\n              t.integer('other_col').notNullable();\n              t.increments('id');\n            });\n            await knex('table_multiple_keys').insert([{\n              second_id: 'abc',\n              other_col: 2\n            }, {\n              second_id: 'abc',\n              other_col: 3\n            }]);\n            expect(() => {\n              knex('table_multiple_keys').insert([{\n                second_id: 'abc',\n                other_col: 2\n              }]);\n            }).to.throw; // It's always ok, the primary key is on three columns.\n\n            await knex('table_multiple_keys').insert([{\n              second_id: 'bcd',\n              other_col: 2\n            }, {\n              second_id: 'abc',\n              other_col: 4\n            }]);\n            expect(() => {\n              knex('table_multiple_keys').insert([{\n                id: 4,\n                second_id: 'abc',\n                other_col: 3\n              }]);\n            }).to.throw;\n          });","file":"integration2/schema/primary-keys.spec.js","skipped":false,"dir":"test"},{"name":"creates a primary key with a custom constraint name","suites":["Schema","Primary keys","createPrimaryKey"],"updatePoint":{"line":140,"column":65,"index":4867},"line":140,"code":"          it('creates a primary key with a custom constraint name', async function () {\n            // CockroachDB 21.1 throws \"(72): unimplemented: primary key dropped without subsequent addition of new primary key in same transaction\"\n            if (isCockroachDB(knex)) {\n              return this.skip();\n            }\n\n            await knex.schema.alterTable('primary_table', table => {\n              table.integer('id_four').notNull().primary('my_custom_constraint_name');\n            });\n            await knex('primary_table').insert({\n              id_four: 1\n            });\n\n            try {\n              await knex('primary_table').insert({\n                id_four: 1\n              });\n              throw new Error(`Shouldn't reach this`);\n            } catch (err) {\n              if (isBetterSQLite3(knex)) {\n                expect(err.message).to.equal('insert into `primary_table` (`id_four`) values (1) - UNIQUE constraint failed: primary_table.id_four');\n              } else if (isSQLite(knex)) {\n                expect(err.message).to.equal('insert into `primary_table` (`id_four`) values (1) - SQLITE_CONSTRAINT_PRIMARYKEY: UNIQUE constraint failed: primary_table.id_four');\n              }\n\n              if (isPgBased(knex)) {\n                expect(err.message).to.equal('insert into \"primary_table\" (\"id_four\") values ($1) - duplicate key value violates unique constraint \"my_custom_constraint_name\"');\n              }\n            }\n\n            await knex.schema.alterTable('primary_table', table => {\n              table.dropPrimary('my_custom_constraint_name');\n            });\n            await knex('primary_table').insert({\n              id_four: 1\n            });\n          });","file":"integration2/schema/primary-keys.spec.js","skipped":false,"dir":"test"},{"name":"creates a compound primary key","suites":["Schema","Primary keys","createPrimaryKey"],"updatePoint":{"line":177,"column":44,"index":6561},"line":177,"code":"          it('creates a compound primary key', async () => {\n            await knex.schema.alterTable('primary_table', table => {\n              // CockroachDB and mssql do not support nullable primary keys\n              if (isCockroachDB(knex) || isMssql(knex)) {\n                table.dropNullable('id_two');\n                table.dropNullable('id_three');\n              }\n\n              table.primary(['id_two', 'id_three']);\n            });\n            await knex('primary_table').insert({\n              id_two: 1,\n              id_three: 1\n            });\n            await knex('primary_table').insert({\n              id_two: 2,\n              id_three: 1\n            });\n            await knex('primary_table').insert({\n              id_two: 1,\n              id_three: 2\n            });\n\n            try {\n              await knex('primary_table').insert({\n                id_two: 1,\n                id_three: 1\n              });\n            } catch (err) {\n              if (isBetterSQLite3(knex)) {\n                expect(err.message).to.equal('insert into `primary_table` (`id_three`, `id_two`) values (1, 1) - UNIQUE constraint failed: primary_table.id_two, primary_table.id_three');\n              } else if (isSQLite(knex)) {\n                expect(err.message).to.equal('insert into `primary_table` (`id_three`, `id_two`) values (1, 1) - SQLITE_CONSTRAINT_PRIMARYKEY: UNIQUE constraint failed: primary_table.id_two, primary_table.id_three');\n              }\n\n              if (isPgBased(knex)) {\n                expect(err.message).to.equal('insert into \"primary_table\" (\"id_three\", \"id_two\") values ($1, $2) - duplicate key value violates unique constraint \"primary_table_pkey\"');\n              }\n            }\n          });","file":"integration2/schema/primary-keys.spec.js","skipped":false,"dir":"test"},{"name":"creates a compound primary key with a custom constraint name ","suites":["Schema","Primary keys","createPrimaryKey"],"updatePoint":{"line":221,"column":86,"index":8571},"line":221,"code":"            it(`creates a compound primary key with a custom constraint name ${flavor}`, async function () {\n              // As of 2021-10-02, CockroachDB does not support dropping a primary key without creating a new one in the same transaction.\n              if (isCockroachDB(knex)) {\n                return this.skip();\n              }\n\n              await knex.schema.alterTable('primary_table', table => {\n                // CockroachDB and mssql do not support nullable primary keys\n                if (isCockroachDB(knex) || isMssql(knex)) {\n                  table.dropNullable('id_two');\n                  table.dropNullable('id_three');\n                }\n\n                table.primary(['id_two', 'id_three'], customConstraintName);\n              });\n              await knex('primary_table').insert({\n                id_two: 1,\n                id_three: 1\n              });\n              await knex('primary_table').insert({\n                id_two: 2,\n                id_three: 1\n              });\n              await knex('primary_table').insert({\n                id_two: 1,\n                id_three: 2\n              });\n\n              try {\n                await knex('primary_table').insert({\n                  id_two: 1,\n                  id_three: 1\n                });\n              } catch (err) {\n                if (isBetterSQLite3(knex)) {\n                  expect(err.message).to.equal('insert into `primary_table` (`id_three`, `id_two`) values (1, 1) - UNIQUE constraint failed: primary_table.id_two, primary_table.id_three');\n                } else if (isSQLite(knex)) {\n                  expect(err.message).to.equal('insert into `primary_table` (`id_three`, `id_two`) values (1, 1) - SQLITE_CONSTRAINT_PRIMARYKEY: UNIQUE constraint failed: primary_table.id_two, primary_table.id_three');\n                }\n\n                if (isPgBased(knex)) {\n                  expect(err.message).to.equal('insert into \"primary_table\" (\"id_three\", \"id_two\") values ($1, $2) - duplicate key value violates unique constraint \"my_custom_constraint_name\"');\n                }\n              }\n\n              await knex.schema.alterTable('primary_table', table => {\n                table.dropPrimary('my_custom_constraint_name');\n              });\n              await knex('primary_table').insert({\n                id_two: 1,\n                id_three: 1\n              });\n            });","file":"integration2/schema/primary-keys.spec.js","skipped":false,"dir":"test"},{"name":"should generate correct SQL for set nullable operation","suites":["Schema","alter nullable","setNullable"],"updatePoint":{"line":45,"column":68,"index":1156},"line":45,"code":"          it('should generate correct SQL for set nullable operation', async () => {\n            const builder = knex.schema.table('primary_table', table => {\n              table.setNullable('id_not_nullable');\n            });\n            const queries = await builder.generateDdlCommands();\n\n            if (isSQLite(knex)) {\n              expect(queries.sql).to.eql(['CREATE TABLE `_knex_temp_alter111` (`id_nullable` integer NULL, `id_not_nullable` integer)', 'INSERT INTO \"_knex_temp_alter111\" SELECT * FROM \"primary_table\";', 'DROP TABLE \"primary_table\"', 'ALTER TABLE \"_knex_temp_alter111\" RENAME TO \"primary_table\"']);\n            }\n\n            if (isPostgreSQL(knex)) {\n              expect(queries.sql).to.eql([{\n                bindings: [],\n                sql: 'alter table \"primary_table\" alter column \"id_not_nullable\" drop not null'\n              }]);\n            }\n          });","file":"integration2/schema/set-nullable.spec.js","skipped":false,"dir":"test"},{"name":"sets column to be nullable","suites":["Schema","alter nullable","setNullable"],"updatePoint":{"line":62,"column":40,"index":2024},"line":62,"code":"          it('sets column to be nullable', async () => {\n            await knex.schema.table('primary_table', table => {\n              table.setNullable('id_not_nullable');\n            });\n            await knex('primary_table').insert({\n              id_nullable: null,\n              id_not_nullable: null\n            });\n          });","file":"integration2/schema/set-nullable.spec.js","skipped":false,"dir":"test"},{"name":"should throw error if alter a not nullable column with primary key #4401","suites":["Schema","alter nullable","setNullable"],"updatePoint":{"line":71,"column":86,"index":2407},"line":71,"code":"          it('should throw error if alter a not nullable column with primary key #4401', async function () {\n            if (!(isPostgreSQL(knex) || isCockroachDB(knex))) {\n              this.skip();\n            }\n\n            await knex.schema.dropTableIfExists('primary_table_null');\n            await knex.schema.createTable('primary_table_null', table => {\n              table.integer('id_not_nullable_primary').notNullable().primary();\n            });\n            let error;\n\n            try {\n              await knex.schema.table('primary_table_null', table => {\n                table.integer('id_not_nullable_primary').alter();\n              });\n            } catch (e) {\n              error = e;\n            }\n\n            if (isCockroachDB(knex)) {\n              // TODO: related comment in issue https://github.com/cockroachdb/cockroach/issues/49329#issuecomment-1022120446\n              expect(error.message).to.eq('alter table \"primary_table_null\" alter column \"id_not_nullable_primary\" drop not null - column \"id_not_nullable_primary\" is in a primary index');\n            } else {\n              expect(error.message).to.eq('alter table \"primary_table_null\" alter column \"id_not_nullable_primary\" drop not null - column \"id_not_nullable_primary\" is in a primary key');\n            }\n          });","file":"integration2/schema/set-nullable.spec.js","skipped":false,"dir":"test"},{"name":"should not throw error if alter a not nullable column with primary key with alterNullable is false #4401","suites":["Schema","alter nullable","setNullable"],"updatePoint":{"line":97,"column":118,"index":3749},"line":97,"code":"          it('should not throw error if alter a not nullable column with primary key with alterNullable is false #4401', async function () {\n            // TODO: related issue for cockroach https://github.com/cockroachdb/cockroach/issues/47636\n            if (!(isPostgreSQL(knex) || isCockroachDB(knex))) {\n              this.skip();\n            } // With CoackroachDb we don't alter type (not supported).\n\n\n            const alterType = isPostgreSQL(knex);\n            await knex.schema.dropTableIfExists('primary_table_null');\n            await knex.schema.createTable('primary_table_null', table => {\n              table.integer('id_not_nullable_primary').notNullable().primary();\n            }); // This alter doesn't throw any error now.\n\n            await knex.schema.table('primary_table_null', table => {\n              table.integer('id_not_nullable_primary').alter({\n                alterNullable: false,\n                alterType: alterType\n              });\n            });\n          });","file":"integration2/schema/set-nullable.spec.js","skipped":false,"dir":"test"},{"name":"sets column to be not nullable","suites":["Schema","alter nullable","dropNullable"],"updatePoint":{"line":119,"column":44,"index":4728},"line":119,"code":"          it('sets column to be not nullable', async () => {\n            await knex.schema.table('primary_table', table => {\n              table.dropNullable('id_nullable');\n            });\n            let errorMessage;\n\n            if (isPostgreSQL(knex)) {\n              errorMessage = 'violates not-null constraint';\n            } else if (isMysql(knex)) {\n              errorMessage = 'cannot be null';\n            } else if (isOracle(knex)) {\n              errorMessage = 'ORA-01400: cannot insert NULL into';\n            } else if (isBetterSQLite3(knex)) {\n              errorMessage = 'insert into `primary_table` (`id_not_nullable`, `id_nullable`) values (1, NULL) - NOT NULL constraint failed: primary_table.id_nullable';\n            } else if (isSQLite(knex)) {\n              errorMessage = 'insert into `primary_table` (`id_not_nullable`, `id_nullable`) values (1, NULL) - SQLITE_CONSTRAINT_NOTNULL: NOT NULL constraint failed: primary_table.id_nullable';\n            }\n\n            await expect(knex('primary_table').insert({\n              id_nullable: null,\n              id_not_nullable: 1\n            })).to.eventually.be.rejectedWith(errorMessage);\n          });","file":"integration2/schema/set-nullable.spec.js","skipped":false,"dir":"test"},{"name":"Allows to specify custom type params","suites":["Schema","customType"],"updatePoint":{"line":29,"column":48,"index":792},"line":29,"code":"        it('Allows to specify custom type params', async () => {\n          let res;\n\n          switch (db) {\n            case Db.SQLite:\n              res = await knex.schema.raw(`PRAGMA table_info(${tblName})`);\n              expect(res.find(c => c.name === colName).type).to.equal('varchar(42)');\n              break;\n\n            case Db.PgNative:\n            case Db.PostgresSQL:\n              res = await knex.select(['data_type', 'character_maximum_length']).from('information_schema.columns').where({\n                table_name: tblName,\n                column_name: colName\n              });\n              expect(res[0].data_type).to.equal('character varying');\n              expect(res[0].character_maximum_length).to.equal(42);\n              break;\n\n            case Db.CockroachDB:\n              res = await knex.select(['data_type', 'character_maximum_length']).from('information_schema.columns').where({\n                table_name: tblName,\n                column_name: colName\n              });\n              expect(res[0].data_type).to.equal('character varying');\n              expect(res[0].character_maximum_length).to.equal('42');\n              break;\n\n            case Db.MSSQL:\n            case Db.MySQL:\n            case Db.MySQL2:\n              res = await knex.select(['DATA_TYPE', 'CHARACTER_MAXIMUM_LENGTH']).from('INFORMATION_SCHEMA.COLUMNS').where({\n                table_name: tblName,\n                column_name: colName\n              });\n              expect(res[0].DATA_TYPE).to.equal('varchar');\n              expect(res[0].CHARACTER_MAXIMUM_LENGTH).to.equal(42);\n              break;\n          }\n        });","file":"integration2/schema/specific-type.spec.js","skipped":false,"dir":"test"},{"name":"create view","suites":["Views","view"],"updatePoint":{"line":70,"column":23,"index":1616},"line":70,"code":"        it('create view', async () => {\n          await knex.schema.createView('view_test', function (view) {\n            view.columns(['a', 'b']);\n            view.as(knex('table_view').select('a', 'b').where('b', '>', '10'));\n          }).testSql(tester => {\n            tester(['pg', 'pg-redshift', 'cockroachdb', 'oracledb'], ['create view \"view_test\" (\"a\", \"b\") as select \"a\", \"b\" from \"table_view\" where \"b\" > \\'10\\'']);\n            tester(['sqlite3', 'mysql'], [\"create view `view_test` (`a`, `b`) as select `a`, `b` from `table_view` where `b` > '10'\"]);\n            tester('mssql', [\"CREATE VIEW [view_test] ([a], [b]) AS select [a], [b] from [table_view] where [b] > '10'\"]);\n          }); // We test if the select on the view works and if results are good\n\n          await knex.select(['a', 'b']).from('view_test').then(function (results) {\n            assertNumber(knex, results[0].b, 12);\n            assertNumber(knex, results[1].b, 45);\n            expect(results[0].a).to.be.equal('test2');\n            expect(results[1].a).to.be.equal('test3');\n          });\n        });","file":"integration2/schema/views.spec.js","skipped":false,"dir":"test"},{"name":"create view without columns","suites":["Views","view"],"updatePoint":{"line":87,"column":39,"index":2720},"line":87,"code":"        it('create view without columns', async () => {\n          await knex.schema.createView('view_test', function (view) {\n            view.as(knex('table_view').select('a', 'b').where('b', '>', '10'));\n          }).testSql(tester => {\n            tester(['pg', 'pg-redshift', 'cockroachdb', 'oracledb'], ['create view \"view_test\" as select \"a\", \"b\" from \"table_view\" where \"b\" > \\'10\\'']);\n            tester(['sqlite3', 'mysql'], [\"create view `view_test` as select `a`, `b` from `table_view` where `b` > '10'\"]);\n            tester('mssql', [\"CREATE VIEW [view_test] AS select [a], [b] from [table_view] where [b] > '10'\"]);\n          }); // We test if the select on the view works and if results are good\n\n          await knex.select(['a', 'b']).from('view_test').then(function (results) {\n            assertNumber(knex, results[0].b, 12);\n            assertNumber(knex, results[1].b, 45);\n            expect(results[0].a).to.be.equal('test2');\n            expect(results[1].a).to.be.equal('test3');\n          });\n        });","file":"integration2/schema/views.spec.js","skipped":false,"dir":"test"},{"name":"create or replace view","suites":["Views","view"],"updatePoint":{"line":103,"column":34,"index":3748},"line":103,"code":"        it('create or replace view', async () => {\n          // We create the view and test if all is ok\n          await knex.schema.createView('view_test', view => {\n            view.as(knex('table_view').select('a', 'b'));\n          });\n          await knex.select(['a', 'b']).from('view_test').then(function (results) {\n            expect(results.length).to.equal(3);\n            expect(results[0].a).to.be.equal('test');\n            expect(results[1].a).to.be.equal('test2');\n            expect(results[2].a).to.be.equal('test3');\n            assertNumber(knex, results[0].b, 5);\n            assertNumber(knex, results[1].b, 12);\n            assertNumber(knex, results[2].b, 45);\n          }); // Now we test that the new view is replaced\n\n          await knex.schema.createViewOrReplace('view_test', function (view) {\n            view.columns(['a', 'b']);\n            view.as(knex('table_view').select('a', 'b').where('b', '>', '10'));\n          }).testSql(tester => {\n            tester(['pg', 'pg-redshift', 'cockroachdb', 'oracledb'], ['create or replace view \"view_test\" (\"a\", \"b\") as select \"a\", \"b\" from \"table_view\" where \"b\" > \\'10\\'']);\n            tester(['mysql'], [\"create or replace view `view_test` (`a`, `b`) as select `a`, `b` from `table_view` where `b` > '10'\"]);\n            tester(['sqlite3'], ['drop view if exists `view_test`', \"create view `view_test` (`a`, `b`) as select `a`, `b` from `table_view` where `b` > '10'\"]);\n            tester('mssql', [\"CREATE OR ALTER VIEW [view_test] ([a], [b]) AS select [a], [b] from [table_view] where [b] > '10'\"]);\n          }); // We test if the select on the view works and if results are good\n\n          await knex.select(['a', 'b']).from('view_test').then(function (results) {\n            expect(results.length).to.equal(2);\n            assertNumber(knex, results[0].b, 12);\n            assertNumber(knex, results[1].b, 45);\n            expect(results[0].a).to.be.equal('test2');\n            expect(results[1].a).to.be.equal('test3');\n          });\n        });","file":"integration2/schema/views.spec.js","skipped":false,"dir":"test"},{"name":"create or replace view without columns","suites":["Views","view"],"updatePoint":{"line":136,"column":50,"index":5795},"line":136,"code":"        it('create or replace view without columns', async () => {\n          // We create the view and test if all is ok\n          await knex.schema.createView('view_test', view => {\n            view.as(knex('table_view').select('a', 'b'));\n          });\n          await knex.select(['a', 'b']).from('view_test').then(function (results) {\n            expect(results.length).to.equal(3);\n            expect(results[0].a).to.be.equal('test');\n            expect(results[1].a).to.be.equal('test2');\n            expect(results[2].a).to.be.equal('test3');\n            assertNumber(knex, results[0].b, 5);\n            assertNumber(knex, results[1].b, 12);\n            assertNumber(knex, results[2].b, 45);\n          }); // Now we test that the new view is replaced\n\n          await knex.schema.createViewOrReplace('view_test', function (view) {\n            view.as(knex('table_view').select('a', 'b').where('b', '>', '10'));\n          }).testSql(tester => {\n            tester(['pg', 'pg-redshift', 'cockroachdb', 'oracledb'], ['create or replace view \"view_test\" as select \"a\", \"b\" from \"table_view\" where \"b\" > \\'10\\'']);\n            tester(['mysql'], [\"create or replace view `view_test` as select `a`, `b` from `table_view` where `b` > '10'\"]);\n            tester(['sqlite3'], ['drop view if exists `view_test`', \"create view `view_test` as select `a`, `b` from `table_view` where `b` > '10'\"]);\n            tester('mssql', [\"CREATE OR ALTER VIEW [view_test] AS select [a], [b] from [table_view] where [b] > '10'\"]);\n          }); // We test if the select on the view works and if results are good\n\n          await knex.select(['a', 'b']).from('view_test').then(function (results) {\n            assertNumber(knex, results[0].b, 12);\n            assertNumber(knex, results[1].b, 45);\n            expect(results[0].a).to.be.equal('test2');\n            expect(results[1].a).to.be.equal('test3');\n          });\n        });","file":"integration2/schema/views.spec.js","skipped":false,"dir":"test"},{"name":"create materialized view","suites":["Views","view"],"updatePoint":{"line":167,"column":36,"index":7698},"line":167,"code":"        it('create materialized view', async function () {\n          if (isMssql(knex) || isSQLite(knex) || isMysql(knex)) {\n            return this.skip();\n          }\n\n          await knex.schema.createMaterializedView('mat_view', function (view) {\n            view.columns(['a', 'b']);\n            view.as(knex('table_view').select('a', 'b').where('b', '>', '10'));\n          }).testSql(tester => {\n            tester(['pg', 'cockroachdb', 'pg-redshift', 'oracledb'], ['create materialized view \"mat_view\" (\"a\", \"b\") as select \"a\", \"b\" from \"table_view\" where \"b\" > \\'10\\'']);\n          });\n          await knex.select(['a', 'b']).from('mat_view').then(function (results) {\n            expect(results[0].a).to.be.equal('test2');\n            expect(results[1].a).to.be.equal('test3');\n            assertNumber(knex, results[0].b, 12);\n            assertNumber(knex, results[1].b, 45);\n          });\n          await knex('table_view').insert([{\n            a: 'test',\n            b: 32\n          }]); // We test we have same values, because the view is not refreshed\n\n          await knex.select(['a', 'b']).from('mat_view').then(function (results) {\n            expect(results[0].a).to.be.equal('test2');\n            expect(results[1].a).to.be.equal('test3');\n            assertNumber(knex, results[0].b, 12);\n            assertNumber(knex, results[1].b, 45);\n          });\n          await knex.schema.refreshMaterializedView('mat_view'); // Materialized view is refreshed\n\n          await knex.select(['a', 'b']).from('mat_view').then(function (results) {\n            expect(results[0].a).to.be.equal('test2');\n            expect(results[1].a).to.be.equal('test3');\n            expect(results[2].a).to.be.equal('test');\n            assertNumber(knex, results[0].b, 12);\n            assertNumber(knex, results[1].b, 45);\n            assertNumber(knex, results[2].b, 32);\n          });\n          await knex.schema.dropMaterializedView('mat_view');\n        });","file":"integration2/schema/views.spec.js","skipped":false,"dir":"test"},{"name":"alter column view","suites":["Views","view"],"updatePoint":{"line":207,"column":29,"index":9652},"line":207,"code":"        it('alter column view', async function () {\n          if (isOracle(knex) || isSQLite(knex) || isMysql(knex) || isCockroachDB(knex)) {\n            return this.skip();\n          }\n\n          await knex.schema.createView('view_test', function (view) {\n            view.columns(['a', 'b']);\n            view.as(knex('table_view').select('a', 'b').where('b', '>', '10'));\n          });\n          await knex.schema.alterView('view_test', function (view) {\n            view.column('a').rename('new_a');\n          });\n          await knex.select(['new_a', 'b']).from('view_test').then(function (results) {\n            expect(results[0].new_a).to.be.equal('test2');\n            expect(results[1].new_a).to.be.equal('test3');\n            assertNumber(knex, results[0].b, 12);\n            assertNumber(knex, results[1].b, 45);\n          });\n        });","file":"integration2/schema/views.spec.js","skipped":false,"dir":"test"},{"name":"alter view rename","suites":["Views","view"],"updatePoint":{"line":226,"column":29,"index":10502},"line":226,"code":"        it('alter view rename', async function () {\n          if (isOracle(knex) || isSQLite(knex)) {\n            return this.skip();\n          }\n\n          await knex.schema.createView('view_test', function (view) {\n            view.columns(['a', 'b']);\n            view.as(knex('table_view').select('a', 'b').where('b', '>', '10'));\n          });\n          await knex.schema.renameView('view_test', 'new_view');\n          await knex.select(['a', 'b']).from('new_view').then(function (results) {\n            expect(results[0].a).to.be.equal('test2');\n            expect(results[1].a).to.be.equal('test3');\n            assertNumber(knex, results[0].b, 12);\n            assertNumber(knex, results[1].b, 45);\n          });\n          await knex.schema.dropView('new_view');\n        });","file":"integration2/schema/views.spec.js","skipped":false,"dir":"test"},{"name":"create view with check options","suites":["Views","view"],"updatePoint":{"line":244,"column":42,"index":11298},"line":244,"code":"        it('create view with check options', async function () {\n          if (isMssql(knex) || isCockroachDB(knex) || isSQLite(knex)) {\n            return this.skip();\n          }\n\n          await knex.schema.createView('view_test', function (view) {\n            view.columns(['a', 'b']);\n            view.as(knex('table_view').select('a', 'b').where('b', '>', '10'));\n            view.checkOption();\n          }).testSql(tester => {\n            tester(['oracledb'], ['create view \"view_test\" (\"a\", \"b\") as select \"a\", \"b\" from \"table_view\" where \"b\" > \\'10\\' with check option']);\n          });\n\n          if (isOracle(knex)) {\n            return this.skip();\n          }\n\n          await knex.schema.dropView('view_test');\n          await knex.schema.createView('view_test', function (view) {\n            view.columns(['a', 'b']);\n            view.as(knex('table_view').select('a', 'b').where('b', '>', '10'));\n            view.localCheckOption();\n          }).testSql(tester => {\n            tester(['pg', 'cockroachdb', 'pg-redshift'], ['create view \"view_test\" (\"a\", \"b\") as select \"a\", \"b\" from \"table_view\" where \"b\" > \\'10\\' with local check option']);\n            tester(['mysql'], [\"create view `view_test` (`a`, `b`) as select `a`, `b` from `table_view` where `b` > '10' with local check option\"]);\n          });\n          await knex.schema.dropView('view_test');\n          await knex.schema.createView('view_test', function (view) {\n            view.columns(['a', 'b']);\n            view.as(knex('table_view').select('a', 'b').where('b', '>', '10'));\n            view.cascadedCheckOption();\n          }).testSql(tester => {\n            tester(['pg', 'cockroachdb', 'pg-redshift'], ['create view \"view_test\" (\"a\", \"b\") as select \"a\", \"b\" from \"table_view\" where \"b\" > \\'10\\' with cascaded check option']);\n            tester(['mysql'], [\"create view `view_test` (`a`, `b`) as select `a`, `b` from `table_view` where `b` > '10' with cascaded check option\"]);\n          });\n        });","file":"integration2/schema/views.spec.js","skipped":false,"dir":"test"},{"name":"deferrable initially immediate unique constraint all row are checked at end of update","suites":["Transaction","setDeferrableConstraint"],"updatePoint":{"line":48,"column":97,"index":1515},"line":48,"code":"        it('deferrable initially immediate unique constraint all row are checked at end of update', async () => {\n          await knex.schema.table(tableName, table => {\n            table.integer('value').unique({\n              deferrable: 'immediate'\n            });\n          });\n          await knex.schema.table(tableName1, table => {\n            table.integer('value').unique({\n              deferrable: 'immediate'\n            });\n          });\n          const trx = await knex.transaction({\n            isolationLevel: 'read committed'\n          });\n          await trx(tableName).select();\n          await trx(tableName).insert({\n            id: 1,\n            value: 1\n          });\n          await trx(tableName).insert({\n            id: 2,\n            value: 2\n          }); //This usually fail but deferrable initially immediate allow check to be performed at the end of update isntead\n\n          await trx(tableName).update({\n            value: knex.raw('?? + 1', ['value'])\n          });\n          await trx.commit();\n        });","file":"integration2/transaction/set-deferrable-constraint.spec.js","skipped":false,"dir":"test"},{"name":"deferred unique constraint are only checked when transaction is committed","suites":["Transaction","setDeferrableConstraint"],"updatePoint":{"line":77,"column":85,"index":2547},"line":77,"code":"        it('deferred unique constraint are only checked when transaction is committed', async () => {\n          await knex.schema.table(tableName, table => {\n            table.integer('value').unique({\n              deferrable: 'deferred'\n            });\n          });\n          const trx = await knex.transaction({\n            isolationLevel: 'read committed'\n          });\n          await trx(tableName).insert({\n            id: 1,\n            value: 1\n          });\n          await trx(tableName).insert({\n            id: 2,\n            value: 2\n          }); //This usually fail but deferrable initially deferred allow constraint to be checked at the commit instead\n\n          await trx(tableName).insert({\n            id: 3,\n            value: 1\n          });\n          await trx(tableName).insert({\n            id: 4,\n            value: 2\n          });\n          await trx(tableName).delete().where({\n            id: 3\n          });\n          await trx(tableName).delete().where({\n            id: 4\n          });\n          await trx.commit();\n        });","file":"integration2/transaction/set-deferrable-constraint.spec.js","skipped":false,"dir":"test"},{"name":"deferred foreign constraint are only checked when transaction is committed","suites":["Transaction","setDeferrableConstraint"],"updatePoint":{"line":111,"column":86,"index":3609},"line":111,"code":"        it('deferred foreign constraint are only checked when transaction is committed', async () => {\n          await knex.schema.table(tableName, table => {\n            table.integer('value');\n            table.foreign('value').deferrable('deferred').references(`${tableName1}.id`).withKeyName('fk1');\n          });\n          await knex.schema.table(tableName1, table => {\n            table.integer('value');\n            table.foreign('value').deferrable('deferred').references(`${tableName}.id`).withKeyName('fk');\n          });\n          const trx = await knex.transaction({\n            isolationLevel: 'read committed'\n          });\n          await trx(tableName).select();\n          await trx(tableName).insert({\n            id: 1,\n            value: 1\n          });\n          await trx(tableName).insert({\n            id: 2,\n            value: 2\n          });\n          await trx(tableName1).insert({\n            id: 1,\n            value: 1\n          });\n          await trx(tableName1).insert({\n            id: 2,\n            value: 2\n          });\n          await trx.commit();\n          await knex.schema.table(tableName, table => {\n            table.dropForeign('value', 'fk1');\n          });\n          await knex.schema.table(tableName1, table => {\n            table.dropForeign('value', 'fk');\n          });\n        });","file":"integration2/transaction/set-deferrable-constraint.spec.js","skipped":false,"dir":"test"},{"name":"Expect read skew when read committed","suites":["Transaction","setIsolationLevel"],"updatePoint":{"line":44,"column":48,"index":1192},"line":44,"code":"        it('Expect read skew when read committed', async () => {\n          // SQLite is always Serializable\n          if (isSQLite(knex)) {\n            return;\n          }\n\n          const trx = await knex.transaction({\n            isolationLevel: 'read committed'\n          });\n          const result1 = await trx(tableName).select();\n          await knex(tableName).insert({\n            id: 1,\n            value: 1\n          });\n          const result2 = await trx(tableName).select();\n          await trx.commit();\n          expect(result1).to.not.equal(result2);\n        });","file":"integration2/transaction/set-isolation-level.spec.js","skipped":false,"dir":"test"},{"name":"Expect to avoid read skew when repeatable read (snapshot isolation)","suites":["Transaction","setIsolationLevel"],"updatePoint":{"line":62,"column":79,"index":1802},"line":62,"code":"        it('Expect to avoid read skew when repeatable read (snapshot isolation)', async () => {\n          if (isSQLite(knex) || isOracle(knex)) {\n            return;\n          } // NOTE: mssql requires an alter database call to enable the snapshot isolation level.\n\n\n          const isolationLevel = isMssql(knex) ? 'snapshot' : 'repeatable read';\n          const trx = await knex.transaction({\n            isolationLevel\n          });\n          const result1 = await trx(tableName).select();\n          await knex(tableName).insert({\n            id: 1,\n            value: 1\n          });\n          const result2 = await trx(tableName).select();\n          await trx.commit();\n          expect(result1).to.deep.equal(result2);\n        });","file":"integration2/transaction/set-isolation-level.spec.js","skipped":false,"dir":"test"}]}