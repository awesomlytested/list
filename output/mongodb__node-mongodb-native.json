{"repo":"mongodb/node-mongodb-native","url":"https://github.com/mongodb/node-mongodb-native","branch":"main","configs":[{"package":"mongodb","lang":"js","dir":"test","framework":"mocha","pattern":"**/*[._-]{test,spec,unittest,unit}.{ts,js}"}],"tests":[{"name":"only contains the expected dependencies","suites":["package.json","dependencies"],"updatePoint":{"line":6,"column":47,"index":292},"line":6,"code":"    it('only contains the expected dependencies', function () {\n      expect(Object.getOwnPropertyNames(dependencies)).to.deep.equal(EXPECTED_DEPENDENCIES);\n    });","file":"action/dependency.test.ts","skipped":false,"dir":"test"},{"name":"should auth  when explicitly specifying ","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":97,"column":85,"index":3506},"line":97,"code":"          it(`should auth ${user.description} when explicitly specifying ${mechanism}`, {\n            metadata: {\n              requires: {\n                mongodb: '>=3.7.3'\n              }\n            },\n            test: function () {\n              const options = {\n                auth: {\n                  username: user.username,\n                  password: user.password\n                },\n                authMechanism: mechanism,\n                authSource: this.configuration.db\n              };\n              return withClient(this.configuration.newClient({}, options), client => {\n                return client.db(this.configuration.db).stats();\n              });\n            }\n          });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should auth  when explicitly specifying  in url","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":117,"column":92,"index":4218},"line":117,"code":"          it(`should auth ${user.description} when explicitly specifying ${mechanism} in url`, {\n            metadata: {\n              requires: {\n                mongodb: '>=3.7.3'\n              }\n            },\n            test: function () {\n              const username = encodeURIComponent(user.username);\n              const password = encodeURIComponent(user.password);\n              const url = `${makeConnectionString(this.configuration, username, password)}authMechanism=${mechanism}`;\n              const client = this.configuration.newClient(url);\n              return withClient(client, client => {\n                return client.db(this.configuration.db).stats();\n              });\n            }\n          });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should auth  using mechanism negotiaton","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":134,"column":70,"index":4931},"line":134,"code":"        it(`should auth ${user.description} using mechanism negotiaton`, {\n          metadata: {\n            requires: {\n              mongodb: '>=3.7.3'\n            }\n          },\n          test: function () {\n            const options = {\n              auth: {\n                username: user.username,\n                password: user.password\n              },\n              authSource: this.configuration.db\n            };\n            return withClient(this.configuration.newClient({}, options), client => {\n              return client.db(this.configuration.db).stats();\n            });\n          }\n        });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should auth  using mechanism negotiaton and url","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":153,"column":78,"index":5551},"line":153,"code":"        it(`should auth ${user.description} using mechanism negotiaton and url`, {\n          metadata: {\n            requires: {\n              mongodb: '>=3.7.3'\n            }\n          },\n          test: function () {\n            const username = encodeURIComponent(user.username);\n            const password = encodeURIComponent(user.password);\n            const url = makeConnectionString(this.configuration, username, password);\n            const client = this.configuration.newClient(url);\n            return withClient(client, client => {\n              return client.db(this.configuration.db).stats();\n            });\n          }\n        });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should select SCRAM-SHA-256 for a user that supports both auth mechanisms","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":176,"column":83,"index":6406},"line":176,"code":"      it('should select SCRAM-SHA-256 for a user that supports both auth mechanisms', {\n        metadata: {\n          requires: {\n            mongodb: '>=3.7.3'\n          }\n        },\n        test: function () {\n          const options = {\n            auth: {\n              username: userMap.both.username,\n              password: userMap.both.password\n            },\n            authSource: this.configuration.db\n          };\n          test.sandbox.spy(ScramSHA256.prototype, 'auth');\n          return withClient(this.configuration.newClient({}, options), () => {\n            expect(ScramSHA256.prototype.auth.called).to.equal(true);\n          });\n        }\n      });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should shorten SCRAM conversations if the server supports it","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":198,"column":70,"index":7087},"line":198,"code":"      it('should shorten SCRAM conversations if the server supports it', {\n        metadata: {\n          requires: {\n            mongodb: '>=4.4',\n            topology: ['single']\n          }\n        },\n        test: function () {\n          const options = {\n            auth: {\n              username: userMap.both.username,\n              password: userMap.both.password\n            },\n            authSource: this.configuration.db\n          };\n          let runCommandSpy;\n          test.sandbox.stub(ScramSHA256.prototype, 'auth').callsFake(function (authContext, callback) {\n            const connection = authContext.connection;\n            const auth = ScramSHA256.prototype.auth.wrappedMethod;\n            runCommandSpy = test.sandbox.spy(connection, 'command');\n            function _callback(err, res) {\n              runCommandSpy.restore();\n              callback(err, res);\n            }\n            auth.apply(this, [authContext, _callback]);\n          });\n          return withClient(this.configuration.newClient({}, options), () => {\n            expect(runCommandSpy.callCount).to.equal(1);\n          });\n        }\n      });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail to connect if incorrect auth mechanism is explicitly specified","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":234,"column":84,"index":8395},"line":234,"code":"      it('should fail to connect if incorrect auth mechanism is explicitly specified', {\n        metadata: {\n          requires: {\n            mongodb: '>=3.7.3'\n          }\n        },\n        test: function () {\n          const options = {\n            auth: {\n              username: userMap.sha256.username,\n              password: userMap.sha256.password\n            },\n            authSource: this.configuration.db,\n            authMechanism: 'SCRAM-SHA-1'\n          };\n          return withClient(this.configuration.newClient({}, options), () => Promise.reject(new Error('This request should have failed to authenticate')), err => expect(err).to.match(/Authentication failed/));\n        }\n      });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail for a nonexistent username with same error type as bad password","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":262,"column":85,"index":9694},"line":262,"code":"      it('should fail for a nonexistent username with same error type as bad password', {\n        metadata: {\n          requires: {\n            mongodb: '>=3.7.3'\n          }\n        },\n        test: function () {\n          const noUsernameOptions = {\n            auth: {\n              username: 'roth',\n              password: 'pencil'\n            },\n            authSource: 'admin'\n          };\n          const badPasswordOptions = {\n            auth: {\n              username: 'both',\n              password: 'pencil'\n            },\n            authSource: 'admin'\n          };\n          const getErrorMsg = options => withClient(this.configuration.newClient({}, options), () => Promise.reject(new Error('This request should have failed to authenticate')), err => expect(err).to.match(/Authentication failed/));\n          return Promise.all([getErrorMsg(noUsernameOptions), getErrorMsg(badPasswordOptions)]);\n        }\n      });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should send speculativeAuthenticate on initial handshake on MongoDB 4.4+","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":287,"column":82,"index":10623},"line":287,"code":"      it('should send speculativeAuthenticate on initial handshake on MongoDB 4.4+', {\n        metadata: {\n          requires: {\n            mongodb: '>=4.4',\n            topology: ['single']\n          }\n        },\n        test: function () {\n          const options = {\n            auth: {\n              username: userMap.both.username,\n              password: userMap.both.password\n            },\n            authSource: this.configuration.db\n          };\n          const commandSpy = test.sandbox.spy(Connection.prototype, 'command');\n          return withClient(this.configuration.newClient({}, options), () => {\n            const calls = commandSpy.getCalls().filter(c => c.thisValue.id !== '<monitor>') // ignore all monitor connections\n            .filter(c => c.args[1][LEGACY_HELLO_COMMAND]); // only consider handshakes\n\n            expect(calls).to.have.length(1);\n            const handshakeDoc = calls[0].args[1];\n            expect(handshakeDoc).to.have.property('speculativeAuthenticate');\n          });\n        }\n      });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should be able to login with username \"\" and password \"\"","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Step 4"],"updatePoint":{"line":384,"column":90,"index":14318},"line":384,"code":"        it(`should be able to login with username \"${username}\" and password \"${password}\"`, {\n          metadata: {\n            requires: {\n              mongodb: '>=3.7.3'\n            }\n          },\n          test: function () {\n            const options = {\n              auth: {\n                username,\n                password\n              },\n              authSource: 'admin',\n              authMechanism: 'SCRAM-SHA-256'\n            };\n            return withClient(this.configuration.newClient(options), client => {\n              return client.db('admin').stats();\n            });\n          }\n        });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should not authorize when not authenticated","suites":["MONGODB-AWS"],"updatePoint":{"line":19,"column":49,"index":715},"line":19,"code":"  it('should not authorize when not authenticated', async function () {\n    const url = removeAuthFromConnectionString(this.configuration.url());\n    client = this.configuration.newClient(url); // strip provided URI of credentials\n\n    const error = await client.db('aws').collection('aws_test').estimatedDocumentCount().catch(error => error);\n    expect(error).to.be.instanceOf(MongoServerError);\n    expect(error).to.have.property('code', 13);\n  });","file":"integration/auth/mongodb_aws.test.ts","skipped":false,"dir":"test"},{"name":"should authorize when successfully authenticated","suites":["MONGODB-AWS"],"updatePoint":{"line":27,"column":54,"index":1172},"line":27,"code":"  it('should authorize when successfully authenticated', async function () {\n    client = this.configuration.newClient(process.env.MONGODB_URI); // use the URI built by the test environment\n\n    const result = await client.db('aws').collection('aws_test').estimatedDocumentCount().catch(error => error);\n    expect(result).to.not.be.instanceOf(MongoServerError);\n    expect(result).to.be.a('number');\n  });","file":"integration/auth/mongodb_aws.test.ts","skipped":false,"dir":"test"},{"name":"should allow empty string in authMechanismProperties.AWS_SESSION_TOKEN to override AWS_SESSION_TOKEN environment variable","suites":["MONGODB-AWS"],"updatePoint":{"line":34,"column":127,"index":1652},"line":34,"code":"  it('should allow empty string in authMechanismProperties.AWS_SESSION_TOKEN to override AWS_SESSION_TOKEN environment variable', function () {\n    client = this.configuration.newClient(this.configuration.url(), {\n      authMechanismProperties: {\n        AWS_SESSION_TOKEN: ''\n      }\n    });\n    expect(client).to.have.nested.property('options.credentials.mechanismProperties.AWS_SESSION_TOKEN').that.equals('');\n  });","file":"integration/auth/mongodb_aws.test.ts","skipped":false,"dir":"test"},{"name":"should respect the default timeout of 10000ms","suites":["MONGODB-AWS","EC2 with missing credentials"],"updatePoint":{"line":64,"column":53,"index":2757},"line":64,"code":"    it('should respect the default timeout of 10000ms', async function () {\n      const config = this.configuration;\n      client = config.newClient(process.env.MONGODB_URI, {\n        authMechanism: 'MONGODB-AWS'\n      }); // use the URI built by the test environment\n      const startTime = performance.now();\n      const caughtError = await client.db().command({\n        ping: 1\n      }).catch(error => error);\n      const endTime = performance.now();\n      const timeTaken = endTime - startTime;\n      expect(caughtError).to.be.instanceOf(MongoAWSError);\n      expect(caughtError).property('message').match(/(timed out after)|(Could not load credentials)/);\n      // Credentials provider from the SDK does not allow to configure the timeout\n      // and defaults to 2 seconds - so we ensure this timeout happens below 12s\n      // instead of the 10s-12s range previously.\n      expect(timeTaken).to.be.below(12000);\n    });","file":"integration/auth/mongodb_aws.test.ts","skipped":false,"dir":"test"},{"name":"successfuly authenticates","suites":["SCRAM-SHA-1"],"updatePoint":{"line":15,"column":31,"index":653},"line":15,"code":"  it('successfuly authenticates', async () => {\n    const result = await client.db().admin().command({\n      ping: 1\n    });\n    expect(result).to.have.property('ok', 1);\n  });","file":"integration/auth/scram_sha_1.test.ts","skipped":false,"dir":"test"},{"name":"should shorten SCRAM conversations if the server supports it","suites":["SCRAM_SHA_256"],"updatePoint":{"line":67,"column":66,"index":2168},"line":67,"code":"  it('should shorten SCRAM conversations if the server supports it', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.4',\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const options = {\n        auth: {\n          username: userMap.both.username,\n          password: userMap.both.password\n        },\n        authSource: this.configuration.db\n      };\n      let runCommandSpy;\n      test.sandbox.stub(ScramSHA256.prototype, 'auth').callsFake(function (authContext, callback) {\n        const connection = authContext.connection;\n        const auth = ScramSHA256.prototype.auth.wrappedMethod;\n        runCommandSpy = test.sandbox.spy(connection, 'command');\n        function _callback(err, res) {\n          runCommandSpy.restore();\n          callback(err, res);\n        }\n        auth.apply(this, [authContext, _callback]);\n      });\n      return withClient(this.configuration.newClient({}, options), () => {\n        expect(runCommandSpy.callCount).to.equal(1);\n      });\n    }\n  });","file":"integration/auth/scram_sha_256.test.js","skipped":false,"dir":"test"},{"name":"should send speculativeAuthenticate on initial handshake on MongoDB 4.4+","suites":["SCRAM_SHA_256"],"updatePoint":{"line":98,"column":78,"index":3196},"line":98,"code":"  it('should send speculativeAuthenticate on initial handshake on MongoDB 4.4+', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.4',\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const options = {\n        auth: {\n          username: userMap.both.username,\n          password: userMap.both.password\n        },\n        authSource: this.configuration.db\n      };\n      const commandSpy = test.sandbox.spy(Connection.prototype, 'command');\n      return withClient(this.configuration.newClient({}, options), () => {\n        const calls = commandSpy.getCalls().filter(c => c.thisValue.id !== '<monitor>') // ignore all monitor connections\n        .filter(c => c.args[1][LEGACY_HELLO_COMMAND]); // only consider handshakes\n\n        expect(calls).to.have.length(1);\n        const handshakeDoc = calls[0].args[1];\n        expect(handshakeDoc).to.have.property('speculativeAuthenticate');\n      });\n    }\n  });","file":"integration/auth/scram_sha_256.test.js","skipped":false,"dir":"test"},{"name":"Should correctly authenticate using x509","suites":["SSL (x509)"],"updatePoint":{"line":21,"column":46,"index":388},"line":21,"code":"  it('Should correctly authenticate using x509', {\n    metadata: {\n      requires: {\n        topology: 'ssl'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var ServerManager = require('mongodb-topology-manager').Server;\n\n      // Read the cert and key\n      var cert = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n      var key = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n\n      // User name\n      var userName = 'CN=client,OU=kerneluser,O=10Gen,L=New York City,ST=New York,C=US';\n\n      // Create server manager\n      var serverManager = new ServerManager('mongod', {\n        bind_ip: 'server',\n        port: 27019,\n        dbpath: f('%s/../db/27019', __dirname),\n        sslPEMKeyFile: __dirname + '/ssl/x509/server.pem',\n        sslCAFile: __dirname + '/ssl/x509/ca.pem',\n        sslCRLFile: __dirname + '/ssl/x509/crl.pem',\n        sslMode: 'requireSSL',\n        sslWeakCertificateValidation: null\n      }, {\n        ssl: true,\n        host: 'server',\n        key: cert,\n        cert: cert,\n        rejectUnauthorized: false\n      });\n\n      // Purge the set\n      serverManager.purge().then(function () {\n        // Start the server\n        serverManager.start().then(function () {\n          // Connect and validate the server certificate\n          MongoClient.connect('mongodb://server:27019/test?ssl=true&maxPoolSize=1', {\n            server: {\n              sslKey: key,\n              sslCert: cert,\n              sslValidate: false\n            }\n          }, function (err, client) {\n            expect(err).to.not.exist;\n            var db = client.db(configuration.db);\n\n            // Execute build info\n            db.command({\n              buildInfo: 1\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              var version = parseInt(result.versionArray.slice(0, 3).join(''), 10);\n              if (version < 253) {\n                client.close();\n                return done();\n              }\n\n              // Add the X509 auth user to the $external db\n              var ext = client.db('$external');\n              ext.addUser(userName, {\n                roles: [{\n                  role: 'readWriteAnyDatabase',\n                  db: 'admin'\n                }, {\n                  role: 'userAdminAnyDatabase',\n                  db: 'admin'\n                }]\n              }, function (err, result) {\n                expect(err).to.not.exist;\n                test.equal(userName, result[0].user);\n                test.equal('', result[0].pwd);\n                client.close();\n\n                // Connect using X509 authentication\n                MongoClient.connect(f('mongodb://%s@server:27019/test?authMechanism=%s&ssl=true&maxPoolSize=1', encodeURIComponent(userName), 'MONGODB-X509'), {\n                  server: {\n                    sslKey: key,\n                    sslCert: cert,\n                    sslValidate: false\n                  }\n                }, function (err, client) {\n                  expect(err).to.not.exist;\n                  client.close();\n                  serverManager.stop().then(function () {\n                    done();\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/auth/ssl_x509_connect.test.js","skipped":false,"dir":"test"},{"name":"Should correctly handle bad x509 certificate","suites":["SSL (x509)"],"updatePoint":{"line":119,"column":50,"index":3693},"line":119,"code":"  it('Should correctly handle bad x509 certificate', {\n    metadata: {\n      requires: {\n        topology: 'ssl'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var ServerManager = require('mongodb-topology-manager').Server;\n\n      // Read the cert and key\n      var cert = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n      var key = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n      var serverPem = fs.readFileSync(__dirname + '/ssl/x509/server.pem');\n\n      // User name\n      var userName = 'CN=client,OU=kerneluser,O=10Gen,L=New York City,ST=New York,C=US';\n\n      // Create server manager\n      var serverManager = new ServerManager('mongod', {\n        bind_ip: 'server',\n        port: 27019,\n        dbpath: f('%s/../db/27019', __dirname),\n        sslPEMKeyFile: __dirname + '/ssl/x509/server.pem',\n        sslCAFile: __dirname + '/ssl/x509/ca.pem',\n        sslCRLFile: __dirname + '/ssl/x509/crl.pem',\n        sslMode: 'requireSSL',\n        sslWeakCertificateValidation: null\n      }, {\n        ssl: true,\n        host: 'server',\n        key: cert,\n        cert: cert,\n        rejectUnauthorized: false\n      });\n\n      // Purge the set\n      serverManager.purge().then(function () {\n        // Start the server\n        serverManager.start().then(function () {\n          // Connect and validate the server certificate\n          MongoClient.connect('mongodb://server:27019/test?ssl=true&maxPoolSize=1', {\n            server: {\n              sslKey: key,\n              sslCert: cert,\n              sslValidate: false\n            }\n          }, function (err, client) {\n            expect(err).to.not.exist;\n            var db = client.db(configuration.db);\n\n            // Execute build info\n            db.command({\n              buildInfo: 1\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              var version = parseInt(result.versionArray.slice(0, 3).join(''), 10);\n              if (version < 253) {\n                client.close();\n                return done();\n              }\n\n              // Add the X509 auth user to the $external db\n              var ext = client.db('$external');\n              ext.addUser(userName, {\n                roles: [{\n                  role: 'readWriteAnyDatabase',\n                  db: 'admin'\n                }, {\n                  role: 'userAdminAnyDatabase',\n                  db: 'admin'\n                }]\n              }, function (err, result) {\n                expect(err).to.not.exist;\n                test.equal(userName, result[0].user);\n                test.equal('', result[0].pwd);\n                client.close();\n\n                // Connect using X509 authentication\n                MongoClient.connect(f('mongodb://%s@server:27019/test?authMechanism=%s&ssl=true&maxPoolSize=1', encodeURIComponent(userName), 'MONGODB-X509'), {\n                  server: {\n                    sslKey: serverPem,\n                    sslCert: serverPem,\n                    sslValidate: false\n                  }\n                }, function (err) {\n                  test.equal(0, err.ok);\n                  test.equal('auth failed', err.errmsg);\n                  serverManager.stop().then(function () {\n                    done();\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/auth/ssl_x509_connect.test.js","skipped":false,"dir":"test"},{"name":"Should give reasonable error on x509 authentication failure","suites":["SSL (x509)"],"updatePoint":{"line":218,"column":65,"index":7111},"line":218,"code":"  it('Should give reasonable error on x509 authentication failure', {\n    metadata: {\n      requires: {\n        topology: 'ssl'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var ServerManager = require('mongodb-topology-manager').Server;\n\n      // Read the cert and key\n      var cert = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n      var key = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n\n      // User name\n      var userName = 'CN=client,OU=kerneluser,O=10Gen,L=New York City,ST=New York,C=US';\n\n      // Create server manager\n      var serverManager = new ServerManager('mongod', {\n        bind_ip: 'server',\n        port: 27019,\n        dbpath: f('%s/../db/27019', __dirname),\n        sslPEMKeyFile: __dirname + '/ssl/x509/server.pem',\n        sslCAFile: __dirname + '/ssl/x509/ca.pem',\n        sslCRLFile: __dirname + '/ssl/x509/crl.pem',\n        sslMode: 'requireSSL',\n        sslWeakCertificateValidation: null\n      }, {\n        ssl: true,\n        host: 'server',\n        key: cert,\n        cert: cert,\n        rejectUnauthorized: false\n      });\n\n      // Purge the set\n      serverManager.purge().then(function () {\n        // Start the server\n        serverManager.start().then(function () {\n          // Connect and validate the server certificate\n          MongoClient.connect('mongodb://server:27019/test?ssl=true&maxPoolSize=1', {\n            server: {\n              sslKey: key,\n              sslCert: cert,\n              sslValidate: false\n            }\n          }, function (err, client) {\n            expect(err).to.not.exist;\n            var db = client.db(configuration.db);\n\n            // Execute build info\n            db.command({\n              buildInfo: 1\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              var version = parseInt(result.versionArray.slice(0, 3).join(''), 10);\n              if (version < 253) {\n                client.close();\n                return done();\n              }\n\n              // Add the X509 auth user to the $external db\n              var ext = client.db('$external');\n              ext.addUser(userName, {\n                roles: [{\n                  role: 'readWriteAnyDatabase',\n                  db: 'admin'\n                }, {\n                  role: 'userAdminAnyDatabase',\n                  db: 'admin'\n                }]\n              }, function (err, result) {\n                expect(err).to.not.exist;\n                test.equal(userName, result[0].user);\n                test.equal('', result[0].pwd);\n                client.close();\n\n                // Connect using X509 authentication\n                MongoClient.connect(f('mongodb://%s@server:27019/test?authMechanism=%s&ssl=true&maxPoolSize=1', encodeURIComponent('WRONG_USERNAME'), 'MONGODB-X509'), {\n                  server: {\n                    sslKey: key,\n                    sslCert: cert,\n                    sslValidate: false\n                  }\n                }, function (err) {\n                  test.equal(0, err.ok);\n                  test.equal('auth failed', err.errmsg);\n                  serverManager.stop().then(function () {\n                    done();\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/auth/ssl_x509_connect.test.js","skipped":false,"dir":"test"},{"name":"Should give helpful error when attempting to use x509 without SSL","suites":["SSL (x509)"],"updatePoint":{"line":316,"column":71,"index":10457},"line":316,"code":"  it('Should give helpful error when attempting to use x509 without SSL', {\n    metadata: {\n      requires: {\n        topology: 'ssl'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var ServerManager = require('mongodb-topology-manager').Server;\n\n      // Read the cert and key\n      var cert = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n      var key = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n      var serverPem = fs.readFileSync(__dirname + '/ssl/x509/server.pem');\n\n      // User name\n      var userName = 'CN=client,OU=kerneluser,O=10Gen,L=New York City,ST=New York,C=US';\n\n      // Create server manager\n      var serverManager = new ServerManager('mongod', {\n        bind_ip: 'server',\n        port: 27019,\n        dbpath: f('%s/../db/27019', __dirname)\n      }, {});\n\n      // Purge the set\n      serverManager.purge().then(function () {\n        // Start the server\n        serverManager.start().then(function () {\n          // Connect and validate the server certificate\n          MongoClient.connect('mongodb://server:27019/test?ssl=false&maxPoolSize=1', {\n            server: {\n              sslKey: key,\n              sslCert: cert,\n              sslValidate: false\n            }\n          }, function (err, client) {\n            expect(err).to.not.exist;\n            var db = client.db(configuration.db);\n\n            // Execute build info\n            db.command({\n              buildInfo: 1\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              var version = parseInt(result.versionArray.slice(0, 3).join(''), 10);\n              if (version < 253) {\n                client.close();\n                return done();\n              }\n\n              // Add the X509 auth user to the $external db\n              var ext = client.db('$external');\n              ext.addUser(userName, {\n                roles: [{\n                  role: 'readWriteAnyDatabase',\n                  db: 'admin'\n                }, {\n                  role: 'userAdminAnyDatabase',\n                  db: 'admin'\n                }]\n              }, function (err, result) {\n                expect(err).to.not.exist;\n                test.equal(userName, result[0].user);\n                test.equal('', result[0].pwd);\n                client.close();\n\n                // Connect using X509 authentication\n                MongoClient.connect(f('mongodb://%s@server:27019/test?authMechanism=%s&ssl=false&maxPoolSize=1', encodeURIComponent(userName), 'MONGODB-X509'), {\n                  server: {\n                    sslKey: serverPem,\n                    sslCert: serverPem,\n                    sslValidate: false\n                  }\n                }, function (err) {\n                  test.ok(!!err);\n                  test.equal(0, err.ok);\n                  test.equal('SSL support is required for the MONGODB-X509 mechanism.', err.errmsg);\n                  serverManager.stop().then(function () {\n                    done();\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/auth/ssl_x509_connect.test.js","skipped":false,"dir":"test"},{"name":"Should correctly reauthenticate against x509","suites":["SSL (x509)"],"updatePoint":{"line":405,"column":50,"index":13579},"line":405,"code":"  it('Should correctly reauthenticate against x509', {\n    metadata: {\n      requires: {\n        topology: 'ssl'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var ServerManager = require('mongodb-topology-manager').Server;\n\n      // Read the cert and key\n      var cert = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n      var key = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n\n      // User name\n      var userName = 'CN=client,OU=kerneluser,O=10Gen,L=New York City,ST=New York,C=US';\n\n      // Create server manager\n      var serverManager = new ServerManager('mongod', {\n        bind_ip: 'server',\n        port: 27019,\n        dbpath: f('%s/../db/27019', __dirname),\n        sslPEMKeyFile: __dirname + '/ssl/x509/server.pem',\n        sslCAFile: __dirname + '/ssl/x509/ca.pem',\n        sslCRLFile: __dirname + '/ssl/x509/crl.pem',\n        sslMode: 'requireSSL',\n        sslWeakCertificateValidation: null\n      }, {\n        ssl: true,\n        host: 'server',\n        key: cert,\n        cert: cert,\n        rejectUnauthorized: false\n      });\n\n      // Purge the set\n      serverManager.purge().then(function () {\n        // Start the server\n        serverManager.start().then(function () {\n          // Connect and validate the server certificate\n          MongoClient.connect('mongodb://server:27019/test?ssl=true&maxPoolSize=1', {\n            server: {\n              sslKey: key,\n              sslCert: cert,\n              sslValidate: false\n            }\n          }, function (err, client) {\n            expect(err).to.not.exist;\n            var db = client.db(configuration.db);\n\n            // Execute build info\n            db.command({\n              buildInfo: 1\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              var version = parseInt(result.versionArray.slice(0, 3).join(''), 10);\n              if (version < 253) {\n                client.close();\n                return done();\n              }\n\n              // Add the X509 auth user to the $external db\n              var ext = client.db('$external');\n              ext.addUser(userName, {\n                roles: [{\n                  role: 'readWriteAnyDatabase',\n                  db: 'admin'\n                }, {\n                  role: 'userAdminAnyDatabase',\n                  db: 'admin'\n                }]\n              }, function (err, result) {\n                expect(err).to.not.exist;\n                test.equal(userName, result[0].user);\n                test.equal('', result[0].pwd);\n                client.close();\n\n                // Connect using X509 authentication\n                MongoClient.connect(f('mongodb://%s@server:27019/test?authMechanism=%s&ssl=true&maxPoolSize=1', encodeURIComponent(userName), 'MONGODB-X509'), {\n                  server: {\n                    sslKey: key,\n                    sslCert: cert,\n                    sslValidate: false\n                  }\n                }, function (err, client) {\n                  expect(err).to.not.exist;\n                  var db = client.db(configuration.db);\n                  db.collection('x509collection').insert({\n                    a: 1\n                  }, function (err) {\n                    expect(err).to.not.exist;\n                    db.collection('x509collection').findOne(function (err, doc) {\n                      expect(err).to.not.exist;\n                      test.equal(1, doc.a);\n                      client.topology.once('reconnect', function () {\n                        // Await reconnect and re-authentication\n                        db.collection('x509collection').findOne(function (err, doc) {\n                          expect(err).to.not.exist;\n                          test.equal(1, doc.a);\n\n                          // Attempt disconnect again\n                          client.topology.connections()[0].destroy();\n\n                          // Await reconnect and re-authentication\n                          db.collection('x509collection').findOne(function (err, doc) {\n                            expect(err).to.not.exist;\n                            test.equal(1, doc.a);\n                            client.close();\n                            serverManager.stop().then(function () {\n                              done();\n                            });\n                          });\n                        });\n                      });\n\n                      // Force close\n                      client.topology.connections()[0].destroy();\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/auth/ssl_x509_connect.test.js","skipped":false,"dir":"test"},{"name":"should correctly insert decimal128 value","suites":["Decimal128"],"updatePoint":{"line":19,"column":46,"index":361},"line":19,"code":"  it('should correctly insert decimal128 value', function (done) {\n    var configuration = this.configuration;\n    var client = configuration.newClient(configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    var db = client.db(configuration.db);\n    var object = {\n      id: 1,\n      value: Decimal128.fromString('1.28')\n    };\n    db.collection('decimal128').insertOne(object, function (err) {\n      expect(err).to.not.exist;\n      db.collection('decimal128').findOne({\n        id: 1\n      }, function (err, doc) {\n        expect(err).to.not.exist;\n        test.ok(doc.value instanceof Decimal128);\n        test.equal('1.28', doc.value.toString());\n        client.close(done);\n      });\n    });\n  });","file":"integration/bson-decimal128/decimal128.test.js","skipped":false,"dir":"test"},{"name":"2. The first read in a causally consistent session must not send afterClusterTime to the server","suites":["Causal Consistency - prose tests"],"updatePoint":{"line":52,"column":101,"index":1808},"line":52,"code":"  it('2. The first read in a causally consistent session must not send afterClusterTime to the server',\n  /**\n   * session = client.startSession(causalConsistency = true)\n   * document = collection.anyReadOperation(session, ...)\n   * capture the command sent to the server (using APM or other mechanism)\n   * assert that the command does not have an afterClusterTime\n   */\n  {\n    metadata: {\n      requires: {\n        topology: ['replicaset', 'sharded']\n      }\n    },\n    test: function () {\n      const session = test.client.startSession({\n        causalConsistency: true\n      });\n      const db = test.client.db(this.configuration.db);\n      return db.collection('causal_test').findOne({}, {\n        session: session\n      }).then(() => {\n        expect(test.commands.started).to.have.length(1);\n        expect(test.commands.succeeded).to.have.length(1);\n        const findCommand = test.commands.started[0].command;\n        expect(findCommand).to.have.property('find', 'causal_test');\n        expect(findCommand).to.not.have.key('readConcern');\n      });\n    }\n  });","file":"integration/causal-consistency/causal_consistency.prose.test.js","skipped":false,"dir":"test"},{"name":"case: successful read with causal consistency","suites":["Causal Consistency - prose tests","3. The first read or write on a ClientSession should update the operationTime of the ClientSession, even if there is an error"],"updatePoint":{"line":92,"column":53,"index":3525},"line":92,"code":"    it('case: successful read with causal consistency', {\n      metadata: {\n        requires: {\n          topology: ['replicaset', 'sharded']\n        }\n      },\n      test: function () {\n        const session = test.client.startSession({\n          causalConsistency: true\n        });\n        const db = test.client.db(this.configuration.db);\n        expect(session.operationTime).to.not.exist;\n        return db.collection('causal_test').findOne({}, {\n          session: session\n        }).then(() => {\n          expect(test.commands.started).to.have.length(1);\n          expect(test.commands.succeeded).to.have.length(1);\n          const lastReply = test.commands.succeeded[0].reply;\n          const maybeLong = val => typeof val.equals === 'function' ? val.toNumber() : val;\n          expect(maybeLong(session.operationTime)).to.equal(maybeLong(lastReply.operationTime));\n        });\n      }\n    });","file":"integration/causal-consistency/causal_consistency.prose.test.js","skipped":false,"dir":"test"},{"name":"case: second operation is findOne","suites":["Causal Consistency - prose tests","4. A findOne followed by any other read operation should include the operationTime returned by the server for the first operation in the afterClusterTime parameter of the second operation"],"updatePoint":{"line":126,"column":41,"index":5071},"line":126,"code":"    it('case: second operation is findOne', {\n      metadata: {\n        requires: {\n          topology: ['replicaset', 'sharded']\n        }\n      },\n      test: function () {\n        const session = test.client.startSession({\n          causalConsistency: true\n        });\n        const db = test.client.db(this.configuration.db);\n        expect(session.operationTime).to.not.exist;\n        let firstOperationTime;\n        return db.collection('causal_test').findOne({}, {\n          session: session\n        }).then(() => {\n          const firstFindCommand = test.commands.started[0].command;\n          expect(firstFindCommand).to.not.have.key('readConcern');\n          firstOperationTime = test.commands.succeeded[0].reply.operationTime;\n          return db.collection('causal_test').findOne({}, {\n            session: session\n          });\n        }).then(() => {\n          const secondFindCommand = test.commands.started[1].command;\n          expect(secondFindCommand).to.have.any.key('readConcern');\n          expect(secondFindCommand.readConcern).to.have.any.key('afterClusterTime');\n          expect(secondFindCommand.readConcern.afterClusterTime).to.eql(firstOperationTime);\n        });\n      }\n    });","file":"integration/causal-consistency/causal_consistency.prose.test.js","skipped":false,"dir":"test"},{"name":"case: successful insert","suites":["Causal Consistency - prose tests","5. Any write operation followed by a findOne operation should include the operationTime of the first operation in the afterClusterTime parameter of the second operation"],"updatePoint":{"line":168,"column":31,"index":6996},"line":168,"code":"    it('case: successful insert', {\n      metadata: {\n        requires: {\n          topology: ['replicaset', 'sharded']\n        }\n      },\n      test: function () {\n        const session = test.client.startSession({\n          causalConsistency: true\n        });\n        const db = test.client.db(this.configuration.db);\n        expect(session.operationTime).to.not.exist;\n        let firstOperationTime;\n        return db.collection('causal_test').insert({}, {\n          session: session\n        }).then(() => {\n          firstOperationTime = test.commands.succeeded[0].reply.operationTime;\n          return db.collection('causal_test').findOne({}, {\n            session: session\n          });\n        }).then(() => {\n          const secondFindCommand = test.commands.started[1].command;\n          expect(secondFindCommand).to.have.any.key('readConcern');\n          expect(secondFindCommand.readConcern).to.have.any.key('afterClusterTime');\n          expect(secondFindCommand.readConcern.afterClusterTime).to.eql(firstOperationTime);\n        });\n      }\n    });","file":"integration/causal-consistency/causal_consistency.prose.test.js","skipped":false,"dir":"test"},{"name":"6. A read operation in a ClientSession that is not causally consistent should not include the afterClusterTime parameter in the command sent to the server","suites":["Causal Consistency - prose tests","5. Any write operation followed by a findOne operation should include the operationTime of the first operation in the afterClusterTime parameter of the second operation"],"updatePoint":{"line":197,"column":160,"index":8193},"line":197,"code":"  it('6. A read operation in a ClientSession that is not causally consistent should not include the afterClusterTime parameter in the command sent to the server',\n  /**\n   * session = client.startSession(causalConsistency = false)\n   * collection.anyReadOperation(session, {})\n   * operationTime = session.operationTime\n   * capture the command sent to the server (using APM or other mechanism)\n   * assert that the command does not have an afterClusterTime field\n   */\n  {\n    metadata: {\n      requires: {\n        topology: ['replicaset', 'sharded']\n      }\n    },\n    test: function () {\n      const session = test.client.startSession({\n        causalConsistency: false\n      });\n      const db = test.client.db(this.configuration.db);\n      const coll = db.collection('causal_test', {\n        readConcern: {\n          level: 'majority'\n        }\n      });\n      return coll.findOne({}, {\n        session: session\n      }).then(() => coll.findOne({}, {\n        session: session\n      })).then(() => {\n        const commands = test.commands.started.map(command => command.command);\n        expect(commands).to.have.length(2);\n        for (const command of commands) {\n          expect(command).to.have.any.key('readConcern');\n          expect(command.readConcern).to.not.have.any.key('afterClusterTime');\n        }\n      });\n    }\n  });","file":"integration/causal-consistency/causal_consistency.prose.test.js","skipped":false,"dir":"test"},{"name":"7. A read operation in a causally consistent session against a deployment that does not support cluster times does not include the afterClusterTime parameter in the command sent to the server","suites":["Causal Consistency - prose tests","5. Any write operation followed by a findOne operation should include the operationTime of the first operation in the afterClusterTime parameter of the second operation"],"updatePoint":{"line":235,"column":197,"index":9569},"line":235,"code":"  it('7. A read operation in a causally consistent session against a deployment that does not support cluster times does not include the afterClusterTime parameter in the command sent to the server',\n  /**\n   * session = client.startSession(causalConsistency = true)\n   * collection.anyReadOperation(session, {})\n   * capture the command sent to the server (using APM or other mechanism)\n   * assert that the command does not have an afterClusterTime field\n   */\n  {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const db = test.client.db(this.configuration.db);\n      const coll = db.collection('causal_test', {\n        readConcern: {\n          level: 'local'\n        }\n      });\n      return coll.findOne({}).then(() => coll.findOne({})).then(() => {\n        const command = test.commands.started[1].command;\n        expect(command).to.have.any.key('readConcern');\n        expect(command.readConcern).to.not.have.any.key('afterClusterTime');\n      });\n    }\n  });","file":"integration/causal-consistency/causal_consistency.prose.test.js","skipped":false,"dir":"test"},{"name":"should pass corpus  client schema","suites":["Client Side Encryption Prose Corpus Test"],"updatePoint":{"line":202,"column":84,"index":8613},"line":202,"code":"    it(`should pass corpus ${useClientSideSchema ? 'with' : 'without'} client schema`, metadata, function () {\n      const corpusCopied = {};\n      return Promise.resolve().then(() => {\n        // 5. Load `corpus/corpus.json <../corpus/corpus.json>`_ to a variable named ``corpus``. The corpus contains subdocuments with the following fields:\n        //\n        //    - ``kms`` is either ``aws`` or ``local``\n        //    - ``type`` is a BSON type string `names coming from here <https://docs.mongodb.com/manual/reference/operator/query/type/>`_)\n        //    - ``algo`` is either ``rand`` or ``det`` for random or deterministic encryption\n        //    - ``method`` is either ``auto``, for automatic encryption or ``explicit`` for  explicit encryption\n        //    - ``identifier`` is either ``id`` or ``altname`` for the key identifier\n        //    - ``allowed`` is a boolean indicating whether the encryption for the given parameters is permitted.\n        //    - ``value`` is the value to be tested.\n        //\n        //    Create a new BSON document, named ``corpus_copied``.\n        //\n        //    Iterate over each field of ``corpus``.\n        //    - If the field name is ``_id``, ``altname_aws`` and ``altname_local``, copy the field to ``corpus_copied``.\n        //    - If ``method`` is ``auto``, copy the field to ``corpus_copied``.\n        //    - If ``method`` is ``explicit``, use ``client_encryption`` to explicitly encrypt the value.\n        //      - Encrypt with the algorithm described by ``algo``.\n        //      - If ``identifier`` is ``id``\n        //        - If ``kms`` is ``local`` set the key_id to the UUID with base64 value ``LOCALAAAAAAAAAAAAAAAAA==``.\n        //        - If ``kms`` is ``aws`` set the key_id to the UUID with base64 value ``AWSAAAAAAAAAAAAAAAAAAA==``.\n        //      - If ``identifier`` is ``altname``\n        //        - If ``kms`` is ``local`` set the key_alt_name to \"local\".\n        //        - If ``kms`` is ``aws`` set the key_alt_name to \"aws\".\n        //      If ``allowed`` is true, copy the field and encrypted value to ``corpus_copied``.\n        //      If ``allowed`` is false. verify that an exception is thrown. Copy the unencrypted value to to ``corpus_copied``.\n        return forEachP(Object.keys(corpus), key => {\n          const field = corpus[key];\n          if (copyOverValues.has(key)) {\n            corpusCopied[key] = field;\n            return;\n          }\n          if (field.method === 'auto') {\n            corpusCopied[key] = Object.assign({}, field);\n            return;\n          }\n          if (field.method === 'explicit') {\n            const encryptOptions = {\n              algorithm: algorithmMap.get(field.algo)\n            };\n            if (field.identifier === 'id') {\n              encryptOptions.keyId = identifierMap.get(field.kms);\n            } else if (field.identifier === 'altname') {\n              encryptOptions.keyAltName = keyAltNameMap.get(field.kms);\n            } else {\n              throw new Error('Unexpected identifier: ' + field.identifier);\n            }\n            return Promise.resolve().then(() => clientEncryption.encrypt(field.value, encryptOptions)).then(encryptedValue => {\n              if (field.allowed === true) {\n                corpusCopied[key] = Object.assign({}, field, {\n                  value: encryptedValue\n                });\n              } else {\n                throw new Error(`Expected encryption to fail for case ${key} on value ${field.value}`);\n              }\n            }, e => {\n              if (field.allowed === false) {\n                corpusCopied[key] = Object.assign({}, field);\n              } else {\n                throw e;\n              }\n            });\n          }\n          throw new Error('Unexpected method: ' + field.method);\n        });\n      }).then(() => {\n        // 6. Using ``client_encrypted``, insert ``corpus_copied`` into ``db.coll``.\n        return clientEncrypted.db(dataDbName).collection(dataCollName).insertOne(corpusCopied);\n      }).then(() => {\n        // 7. Using ``client_encrypted``, find the inserted document from ``db.coll`` to a variable named ``corpus_decrypted``.\n        // Since it should have been automatically decrypted, assert the document exactly matches ``corpus``.\n        return clientEncrypted.db(dataDbName).collection(dataCollName).findOne({\n          _id: corpusCopied._id\n        }, {\n          promoteLongs: false,\n          promoteValues: false\n        });\n      }).then(corpusDecrypted => {\n        expect(toComparableExtendedJSON(corpusDecrypted)).to.deep.equal(toComparableExtendedJSON(corpus));\n      }).then(() => {\n        // 8. Load `corpus/corpus_encrypted.json <../corpus/corpus-encrypted.json>`_ to a variable named ``corpus_encrypted_expected``.\n        //    Using ``client`` find the inserted document from ``db.coll`` to a variable named ``corpus_encrypted_actual``.\n\n        //    Iterate over each field of ``corpus_encrypted_expected`` and check the following:\n\n        //    - If the ``algo`` is ``det``, that the value equals the value of the corresponding field in ``corpus_encrypted_actual``.\n        //    - If the ``algo`` is ``rand`` and ``allowed`` is true, that the value does not equal the value of the corresponding field in ``corpus_encrypted_actual``.\n        //    - If ``allowed`` is true, decrypt the value with ``client_encryption``. Decrypt the value of the corresponding field of ``corpus_encrypted`` and validate that they are both equal.\n        //    - If ``allowed`` is false, validate the value exactly equals the value of the corresponding field of ``corpus`` (neither was encrypted).\n        return client.db(dataDbName).collection(dataCollName).findOne({\n          _id: corpusCopied._id\n        }, {\n          promoteLongs: false,\n          promoteValues: false\n        });\n      }).then(corpusEncryptedActual => {\n        return forEachP(Object.keys(corpusEncryptedExpected), key => {\n          return assertion(clientEncryption, key, corpusEncryptedExpected[key], corpusEncryptedActual[key]);\n        });\n      });\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.corpus.test.js","skipped":false,"dir":"test"},{"name":"should work for local KMS provider","suites":["Client Side Encryption Prose Tests","Data key and double encryption"],"updatePoint":{"line":166,"column":42,"index":5866},"line":166,"code":"    it('should work for local KMS provider', metadata, function () {\n      let localDatakeyId;\n      let localEncrypted;\n      return Promise.resolve().then(() => {\n        // #. Call ``client_encryption.createDataKey()`` with the ``local`` KMS provider and keyAltNames set to ``[\"local_altname\"]``.\n        // - Expect a BSON binary with subtype 4 to be returned, referred to as ``local_datakey_id``.\n        // - Use ``client`` to run a ``find`` on ``keyvault.datakeys`` by querying with the ``_id`` set to the ``local_datakey_id``.\n        // - Expect that exactly one document is returned with the \"masterKey.provider\" equal to \"local\".\n        // - Check that ``client`` captured a command_started event for the ``insert`` command containing a majority writeConcern.\n        this.commandStartedEvents.clear();\n        return this.clientEncryption.createDataKey('local', {\n          keyAltNames: ['local_altname']\n        }).then(result => {\n          localDatakeyId = result;\n          expect(localDatakeyId).to.have.property('sub_type', 4);\n        }).then(() => {\n          return this.client.db(keyVaultDbName).collection(keyVaultCollName).find({\n            _id: localDatakeyId\n          }).toArray();\n        }).then(results => {\n          expect(results).to.have.a.lengthOf(1).and.to.have.nested.property('0.masterKey.provider', 'local');\n          expect(this.commandStartedEvents.events).to.containSubset([{\n            commandName: 'insert',\n            command: {\n              writeConcern: {\n                w: 'majority'\n              }\n            }\n          }]);\n        });\n      }).then(() => {\n        // #. Call ``client_encryption.encrypt()`` with the value \"hello local\", the algorithm ``AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic``, and the ``key_id`` of ``local_datakey_id``.\n        // - Expect the return value to be a BSON binary subtype 6, referred to as ``local_encrypted``.\n        // - Use ``client_encrypted`` to insert ``{ _id: \"local\", \"value\": <local_encrypted> }`` into ``db.coll``.\n        // - Use ``client_encrypted`` to run a find querying with ``_id`` of \"local\" and expect ``value`` to be \"hello local\".\n        const coll = this.clientEncrypted.db(dataDbName).collection(dataCollName);\n        return this.clientEncryption.encrypt('hello local', {\n          algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic',\n          keyId: localDatakeyId\n        }).then(value => {\n          localEncrypted = value;\n          expect(localEncrypted).to.have.property('sub_type', 6);\n        }).then(() => coll.insertOne({\n          _id: 'local',\n          value: localEncrypted\n        })).then(() => coll.findOne({\n          _id: 'local'\n        })).then(result => {\n          expect(result).to.have.property('value', 'hello local');\n        });\n      }).then(() => {\n        // #. Call ``client_encryption.encrypt()`` with the value \"hello local\", the algorithm ``AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic``, and the ``key_alt_name`` of ``local_altname``.\n        // - Expect the return value to be a BSON binary subtype 6. Expect the value to exactly match the value of ``local_encrypted``.\n        return this.clientEncryption.encrypt('hello local', {\n          algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic',\n          keyId: localDatakeyId\n        }).then(encrypted => {\n          expect(encrypted).to.deep.equal(localEncrypted);\n        });\n      });\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should work for aws KMS provider","suites":["Client Side Encryption Prose Tests","Data key and double encryption"],"updatePoint":{"line":227,"column":40,"index":9283},"line":227,"code":"    it('should work for aws KMS provider', metadata, function () {\n      // Then, repeat the above tests with the ``aws`` KMS provider:\n      let awsDatakeyId;\n      let awsEncrypted;\n      return Promise.resolve().then(() => {\n        // #. Call ``client_encryption.createDataKey()`` with the ``aws`` KMS provider, keyAltNames set to ``[\"aws_altname\"]``, and ``masterKey`` as follows:\n        //    .. code:: javascript\n        //       {\n        //         region: \"us-east-1\",\n        //         key: \"arn:aws:kms:us-east-1:579766882180:key/89fcc2c4-08b0-4bd9-9f25-e30687b580d0\"\n        //       }\n        //    - Expect a BSON binary with subtype 4 to be returned, referred to as ``aws_datakey_id``.\n        //    - Use ``client`` to run a ``find`` on ``keyvault.datakeys`` by querying with the ``_id`` set to the ``aws_datakey_id``.\n        //    - Expect that exactly one document is returned with the \"masterKey.provider\" equal to \"aws\".\n        //    - Check that ``client`` captured a command_started event for the ``insert`` command containing a majority writeConcern.\n        this.commandStartedEvents.clear();\n        const masterKey = {\n          region: 'us-east-1',\n          key: 'arn:aws:kms:us-east-1:579766882180:key/89fcc2c4-08b0-4bd9-9f25-e30687b580d0'\n        };\n        return this.clientEncryption.createDataKey('aws', {\n          masterKey,\n          keyAltNames: ['aws_altname']\n        }).then(result => {\n          awsDatakeyId = result;\n          expect(awsDatakeyId).to.have.property('sub_type', 4);\n        }).then(() => {\n          return this.client.db(keyVaultDbName).collection(keyVaultCollName).find({\n            _id: awsDatakeyId\n          }).toArray();\n        }).then(results => {\n          expect(results).to.have.a.lengthOf(1).and.to.have.nested.property('0.masterKey.provider', 'aws');\n          expect(this.commandStartedEvents.events).to.containSubset([{\n            commandName: 'insert',\n            command: {\n              writeConcern: {\n                w: 'majority'\n              }\n            }\n          }]);\n        });\n      }).then(() => {\n        // #. Call ``client_encryption.encrypt()`` with the value \"hello aws\", the algorithm ``AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic``, and the ``key_id`` of ``aws_datakey_id``.\n        //    - Expect the return value to be a BSON binary subtype 6, referred to as ``aws_encrypted``.\n        //    - Use ``client_encrypted`` to insert ``{ _id: \"aws\", \"value\": <aws_encrypted> }`` into ``db.coll``.\n        //    - Use ``client_encrypted`` to run a find querying with ``_id`` of \"aws\" and expect ``value`` to be \"hello aws\".\n        const coll = this.clientEncrypted.db(dataDbName).collection(dataCollName);\n        return this.clientEncryption.encrypt('hello aws', {\n          algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic',\n          keyId: awsDatakeyId\n        }).then(value => {\n          awsEncrypted = value;\n          expect(awsEncrypted).to.have.property('sub_type', 6);\n        }).then(() => coll.insertOne({\n          _id: 'aws',\n          value: awsEncrypted\n        })).then(() => coll.findOne({\n          _id: 'aws'\n        })).then(result => {\n          expect(result).to.have.property('value', 'hello aws');\n        });\n      }).then(() => {\n        // #. Call ``client_encryption.encrypt()`` with the value \"hello aws\", the algorithm ``AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic``, and the ``key_alt_name`` of ``aws_altname``.\n        //    - Expect the return value to be a BSON binary subtype 6. Expect the value to exactly match the value of ``aws_encrypted``.\n        return this.clientEncryption.encrypt('hello aws', {\n          algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic',\n          keyId: awsDatakeyId\n        }).then(encrypted => {\n          expect(encrypted).to.deep.equal(awsEncrypted);\n        });\n      });\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should error on an attempt to double-encrypt a value","suites":["Client Side Encryption Prose Tests","Data key and double encryption"],"updatePoint":{"line":299,"column":60,"index":13171},"line":299,"code":"    it('should error on an attempt to double-encrypt a value', metadata, function () {\n      // Then, run the following final tests:\n      // #. Test explicit encrypting an auto encrypted field.\n      //    - Use ``client_encrypted`` to attempt to insert ``{ \"encrypted_placeholder\": (local_encrypted) }``\n      //    - Expect an exception to be thrown, since this is an attempt to auto encrypt an already encrypted value.\n      return Promise.resolve().then(() => this.clientEncryption.createDataKey('local')).then(keyId => this.clientEncryption.encrypt('hello double', {\n        keyId,\n        algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic'\n      })).then(encrypted => this.clientEncrypted.db(dataDbName).collection(dataCollName).insertOne({\n        encrypted_placeholder: encrypted\n      }).then(() => {\n        throw new Error('Expected double-encryption to fail, but it has succeeded');\n      }, err => {\n        expect(err).to.be.an.instanceOf(Error);\n      }));\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should work  external key vault","suites":["Client Side Encryption Prose Tests","External Key Vault Test"],"updatePoint":{"line":350,"column":85,"index":16016},"line":350,"code":"      it(`should work ${withExternalKeyVault ? 'with' : 'without'} external key vault`, metadata, function () {\n        const ClientEncryption = this.configuration.mongodbClientEncryption.ClientEncryption;\n        return Promise.resolve().then(() => {\n          //    If ``withExternalKeyVault == true``, configure both objects with an external key vault client. The external client MUST connect to the same\n          //    MongoDB cluster that is being tested against, except it MUST use the username ``fake-user`` and password ``fake-pwd``.\n          this.externalClient = this.configuration.newClient(\n          // this.configuration.url('fake-user', 'fake-pwd'),\n          // TODO: Do this properly\n          {}, {\n            monitorCommands: true\n          });\n          this.commandStartedEvents = new APMEventCollector(this.externalClient, 'commandStarted', {\n            include: ['find']\n          });\n          return this.externalClient.connect();\n        })\n        // 3. Create the following:\n        //    - A MongoClient configured with auto encryption (referred to as ``client_encrypted``)\n        //    - A ``ClientEncryption`` object (referred to as ``client_encryption``)\n        //    Configure both objects with the ``local`` KMS providers as follows:\n        //    .. code:: javascript\n        //       { \"local\": { \"key\": <base64 decoding of LOCAL_MASTERKEY> } }\n        //    Configure both objects with ``keyVaultNamespace`` set to ``keyvault.datakeys``.\n        //    Configure ``client_encrypted`` to use the schema `external/external-schema.json <../external/external-schema.json>`_  for ``db.coll`` by setting a schema map like: ``{ \"db.coll\": <contents of external-schema.json>}``\n        .then(() => {\n          const options = {\n            bson: BSON,\n            keyVaultNamespace,\n            kmsProviders: getKmsProviders(LOCAL_KEY),\n            extraOptions: getEncryptExtraOptions()\n          };\n          if (withExternalKeyVault) {\n            options.keyVaultClient = this.externalClient;\n          }\n          this.clientEncryption = new ClientEncryption(this.client, Object.assign({}, options));\n          this.clientEncrypted = this.configuration.newClient({}, {\n            autoEncryption: Object.assign({}, options, {\n              schemaMap: {\n                'db.coll': externalSchema\n              }\n            })\n          });\n          return this.clientEncrypted.connect();\n        }).then(() => {\n          // 4. Use ``client_encrypted`` to insert the document ``{\"encrypted\": \"test\"}`` into ``db.coll``.\n          //    If ``withExternalKeyVault == true``, expect an authentication exception to be thrown. Otherwise, expect the insert to succeed.\n          this.commandStartedEvents.clear();\n          return this.clientEncrypted.db(dataDbName).collection(dataCollName).insertOne({\n            encrypted: 'test'\n          }).then(() => {\n            if (withExternalKeyVault) {\n              expect(this.commandStartedEvents.events).to.containSubset([{\n                commandName: 'find',\n                databaseName: keyVaultDbName,\n                command: {\n                  find: keyVaultCollName\n                }\n              }]);\n            } else {\n              expect(this.commandStartedEvents.events).to.not.containSubset([{\n                commandName: 'find',\n                databaseName: keyVaultDbName,\n                command: {\n                  find: keyVaultCollName\n                }\n              }]);\n            }\n          });\n          // TODO: Do this in the spec-compliant way using bad auth credentials\n          // .then(\n          //   () => {\n          //     if (withExternalKeyVault) {\n          //       throw new Error(\n          //         'expected insert to fail with authentication error, but it passed'\n          //       );\n          //     }\n          //   },\n          //   err => {\n          //     if (!withExternalKeyVault) {\n          //       throw err;\n          //     }\n          //     expect(err).to.be.an.instanceOf(Error);\n          //   }\n          // );\n        }).then(() => {\n          // 5. Use ``client_encryption`` to explicitly encrypt the string ``\"test\"`` with key ID ``LOCALAAAAAAAAAAAAAAAAA==`` and deterministic algorithm.\n          //    If ``withExternalKeyVault == true``, expect an authentication exception to be thrown. Otherwise, expect the insert to succeed.\n          this.commandStartedEvents.clear();\n          return this.clientEncryption.encrypt('test', {\n            keyId: externalKey._id,\n            algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic'\n          }).then(() => {\n            if (withExternalKeyVault) {\n              expect(this.commandStartedEvents.events).to.containSubset([{\n                commandName: 'find',\n                databaseName: keyVaultDbName,\n                command: {\n                  find: keyVaultCollName\n                }\n              }]);\n            } else {\n              expect(this.commandStartedEvents.events).to.not.containSubset([{\n                commandName: 'find',\n                databaseName: keyVaultDbName,\n                command: {\n                  find: keyVaultCollName\n                }\n              }]);\n            }\n          });\n          // TODO: Do this in the spec-compliant way using bad auth credentials\n          // .then(\n          //   () => {\n          //     if (withExternalKeyVault) {\n          //       throw new Error(\n          //         'expected insert to fail with authentication error, but it passed'\n          //       );\n          //     }\n          //   },\n          //   err => {\n          //     if (!withExternalKeyVault) {\n          //       throw err;\n          //     }\n          //     expect(err).to.be.an.instanceOf(Error);\n          //   }\n          // );\n        });\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should error when inserting into a view with autoEncryption","suites":["Client Side Encryption Prose Tests","Views are prohibited"],"updatePoint":{"line":721,"column":67,"index":32607},"line":721,"code":"    it('should error when inserting into a view with autoEncryption', metadata, function () {\n      return this.clientEncrypted.db(dataDbName).collection('view').insertOne({\n        a: 1\n      }).then(() => {\n        throw new Error('Expected insert to fail, but it succeeded');\n      }, err => {\n        expect(err).to.have.property('message').that.matches(/cannot auto encrypt a view/);\n      });\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"runs in a separate suite","suites":["Client Side Encryption Prose Tests","Corpus Test"],"updatePoint":{"line":732,"column":32,"index":33025},"line":732,"code":"    it('runs in a separate suite', () => {\n      expect(() => fs.statSync(path.resolve(__dirname, './client_side_encryption.prose.corpus.test.js'))).not.to.throw();\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"Via mongocryptdBypassSpawn","suites":["Client Side Encryption Prose Tests","Bypass spawning mongocryptd"],"line":958,"code":"    it.skip('Via mongocryptdBypassSpawn', () => {}).skipReason = 'TODO(NODE-2422): Implement \"Bypass spawning mongocryptd\" tests';","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":true,"dir":"test"},{"name":"Via bypassAutoEncryption","suites":["Client Side Encryption Prose Tests","Bypass spawning mongocryptd"],"line":959,"code":"    it.skip('Via bypassAutoEncryption', () => {}).skipReason = 'TODO(NODE-2422): Implement \"Bypass spawning mongocryptd\" tests';","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":true,"dir":"test"},{"name":"TBD","suites":["Client Side Encryption Prose Tests","KMS TLS Tests"],"line":967,"code":"    it.skip('TBD', () => {}).skipReason = 'TODO(NODE-3151): Implement \"KMS TLS Tests\"';","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":true,"dir":"test"},{"name":"should fail with no TLS","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 1: AWS"],"updatePoint":{"line":1111,"column":33,"index":47095},"line":1111,"code":"      it('should fail with no TLS', metadata, async function () {\n        try {\n          await clientEncryptionNoTls.createDataKey('aws', {\n            masterKey\n          });\n          expect.fail('it must fail with no tls');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed.\n          expect(e.originalError.message).to.include('certificate required');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should succeed with valid TLS options","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 1: AWS"],"updatePoint":{"line":1122,"column":47,"index":47519},"line":1122,"code":"      it('should succeed with valid TLS options', metadata, async function () {\n        try {\n          await clientEncryptionWithTls.createDataKey('aws', {\n            masterKey\n          });\n          expect.fail('it must fail to parse response');\n        } catch (e) {\n          // Expect an error from libmongocrypt with a message containing the string: \"parse error\".\n          // This implies TLS handshake succeeded.\n          expect(e.message).to.include('parse error');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an expired certificate","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 1: AWS"],"updatePoint":{"line":1134,"column":49,"index":48020},"line":1134,"code":"      it('should fail with an expired certificate', async function () {\n        try {\n          await clientEncryptionWithTlsExpired.createDataKey('aws', {\n            masterKey: masterKeyExpired\n          });\n          expect.fail('it must fail with invalid certificate');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an expired certificate.\n          expect(e.originalError.message).to.include('certificate has expired');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an invalid hostname","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 1: AWS"],"updatePoint":{"line":1145,"column":46,"index":48506},"line":1145,"code":"      it('should fail with an invalid hostname', metadata, async function () {\n        try {\n          await clientEncryptionWithInvalidHostname.createDataKey('aws', {\n            masterKey: masterKeyInvalidHostname\n          });\n          expect.fail('it must fail with invalid hostnames');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an invalid hostname.\n          expect(e.originalError.message).to.include('does not match certificate');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with no TLS","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 2: Azure"],"updatePoint":{"line":1164,"column":33,"index":49183},"line":1164,"code":"      it('should fail with no TLS', metadata, async function () {\n        try {\n          await clientEncryptionNoTls.createDataKey('azure', {\n            masterKey\n          });\n          expect.fail('it must fail with no tls');\n        } catch (e) {\n          //Expect an error indicating TLS handshake failed.\n          expect(e.originalError.message).to.include('certificate required');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should succeed with valid TLS options","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 2: Azure"],"updatePoint":{"line":1175,"column":47,"index":49608},"line":1175,"code":"      it('should succeed with valid TLS options', metadata, async function () {\n        try {\n          await clientEncryptionWithTls.createDataKey('azure', {\n            masterKey\n          });\n          expect.fail('it must fail with HTTP 404');\n        } catch (e) {\n          // Expect an error from libmongocrypt with a message containing the string: \"HTTP status=404\".\n          // This implies TLS handshake succeeded.\n          expect(e.message).to.include('HTTP status=404');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an expired certificate","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 2: Azure"],"updatePoint":{"line":1187,"column":49,"index":50115},"line":1187,"code":"      it('should fail with an expired certificate', async function () {\n        try {\n          await clientEncryptionWithTlsExpired.createDataKey('azure', {\n            masterKey\n          });\n          expect.fail('it must fail with expired certificates');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an expired certificate.\n          expect(e.originalError.message).to.include('certificate has expired');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an invalid hostname","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 2: Azure"],"updatePoint":{"line":1198,"column":46,"index":50586},"line":1198,"code":"      it('should fail with an invalid hostname', metadata, async function () {\n        try {\n          await clientEncryptionWithInvalidHostname.createDataKey('azure', {\n            masterKey\n          });\n          expect.fail('it must fail with invalid hostnames');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an invalid hostname.\n          expect(e.originalError.message).to.include('does not match certificate');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with no TLS","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 3: GCP"],"updatePoint":{"line":1219,"column":33,"index":51264},"line":1219,"code":"      it('should fail with no TLS', metadata, async function () {\n        try {\n          await clientEncryptionNoTls.createDataKey('gcp', {\n            masterKey\n          });\n          expect.fail('it must fail with no tls');\n        } catch (e) {\n          //Expect an error indicating TLS handshake failed.\n          expect(e.originalError.message).to.include('certificate required');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should succeed with valid TLS options","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 3: GCP"],"updatePoint":{"line":1230,"column":47,"index":51687},"line":1230,"code":"      it('should succeed with valid TLS options', metadata, async function () {\n        try {\n          await clientEncryptionWithTls.createDataKey('gcp', {\n            masterKey\n          });\n          expect.fail('it must fail with HTTP 404');\n        } catch (e) {\n          // Expect an error from libmongocrypt with a message containing the string: \"HTTP status=404\".\n          // This implies TLS handshake succeeded.\n          expect(e.message).to.include('HTTP status=404');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an expired certificate","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 3: GCP"],"updatePoint":{"line":1242,"column":49,"index":52192},"line":1242,"code":"      it('should fail with an expired certificate', async function () {\n        try {\n          await clientEncryptionWithTlsExpired.createDataKey('gcp', {\n            masterKey\n          });\n          expect.fail('it must fail with expired certificates');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an expired certificate.\n          expect(e.originalError.message).to.include('certificate has expired');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an invalid hostname","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 3: GCP"],"updatePoint":{"line":1253,"column":46,"index":52661},"line":1253,"code":"      it('should fail with an invalid hostname', metadata, async function () {\n        try {\n          await clientEncryptionWithInvalidHostname.createDataKey('gcp', {\n            masterKey\n          });\n          expect.fail('it must fail with invalid hostnames');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an invalid hostname.\n          expect(e.originalError.message).to.include('does not match certificate');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with no TLS","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 4: KMIP"],"updatePoint":{"line":1269,"column":33,"index":53233},"line":1269,"code":"      it('should fail with no TLS', metadata, async function () {\n        try {\n          await clientEncryptionNoTls.createDataKey('kmip', {\n            masterKey\n          });\n          expect.fail('it must fail with no tls');\n        } catch (e) {\n          //Expect an error indicating TLS handshake failed.\n          expect(e.originalError.message).to.include('before secure TLS connection');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should succeed with valid TLS options","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 4: KMIP"],"updatePoint":{"line":1280,"column":47,"index":53665},"line":1280,"code":"      it('should succeed with valid TLS options', metadata, async function () {\n        const keyId = await clientEncryptionWithTls.createDataKey('kmip', {\n          masterKey\n        });\n        // expect success\n        expect(keyId).to.be.an('object');\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an expired certificate","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 4: KMIP"],"updatePoint":{"line":1287,"column":49,"index":53933},"line":1287,"code":"      it('should fail with an expired certificate', async function () {\n        try {\n          await clientEncryptionWithTlsExpired.createDataKey('kmip', {\n            masterKey\n          });\n          expect.fail('it must fail with expired certificates');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an expired certificate.\n          expect(e.originalError.message).to.include('certificate has expired');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an invalid hostname","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 4: KMIP"],"updatePoint":{"line":1298,"column":46,"index":54403},"line":1298,"code":"      it('should fail with an invalid hostname', metadata, async function () {\n        try {\n          await clientEncryptionWithInvalidHostname.createDataKey('kmip', {\n            masterKey\n          });\n          expect.fail('it must fail with invalid hostnames');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an invalid hostname.\n          expect(e.originalError.message).to.include('does not match certificate');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"returns the decrypted value","suites":["Client Side Encryption Prose Tests","12. Explicit Encryption","Case 1: can insert encrypted indexed and find"],"updatePoint":{"line":1419,"column":37,"index":59465},"line":1419,"code":"      it('returns the decrypted value', async function () {\n        // Use encryptedClient to run a \"find\" operation on the db.explicit_encryption\n        // collection with the filter { \"encryptedIndexed\": <findPayload> }.\n        // Assert one document is returned containing the field\n        // { \"encryptedIndexed\": \"encrypted indexed value\" }.\n        const collection = encryptedClient.db('db').collection('explicit_encryption');\n        const result = await collection.findOne({\n          encryptedIndexed: findPayload\n        });\n        expect(result).to.have.property('encryptedIndexed', 'encrypted indexed value');\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"returns less than the total documents with no contention","suites":["Client Side Encryption Prose Tests","12. Explicit Encryption","Case 2: can insert encrypted indexed and find with non-zero contention"],"updatePoint":{"line":1484,"column":66,"index":62379},"line":1484,"code":"      it('returns less than the total documents with no contention', async function () {\n        // Use encryptedClient to run a \"find\" operation on the db.explicit_encryption\n        // collection with the filter { \"encryptedIndexed\": <findPayload> }.\n        // Assert less than 10 documents are returned. 0 documents may be returned.\n        // Assert each returned document contains the field\n        // { \"encryptedIndexed\": \"encrypted indexed value\" }.\n        const collection = encryptedClient.db('db').collection('explicit_encryption');\n        const result = await collection.find({\n          encryptedIndexed: findPayload\n        }).toArray();\n        expect(result.length).to.be.below(10);\n        for (const doc of result) {\n          expect(doc).to.have.property('encryptedIndexed', 'encrypted indexed value');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"returns all documents with contention","suites":["Client Side Encryption Prose Tests","12. Explicit Encryption","Case 2: can insert encrypted indexed and find with non-zero contention"],"updatePoint":{"line":1499,"column":47,"index":63205},"line":1499,"code":"      it('returns all documents with contention', async function () {\n        // Use encryptedClient to run a \"find\" operation on the db.explicit_encryption\n        // collection with the filter { \"encryptedIndexed\": <findPayload2> }.\n        // Assert 10 documents are returned. Assert each returned document contains the\n        // field { \"encryptedIndexed\": \"encrypted indexed value\" }.\n        const collection = encryptedClient.db('db').collection('explicit_encryption');\n        const result = await collection.find({\n          encryptedIndexed: findPayload2\n        }).toArray();\n        expect(result.length).to.equal(10);\n        for (const doc of result) {\n          expect(doc).to.have.property('encryptedIndexed', 'encrypted indexed value');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"returns unindexed documents","suites":["Client Side Encryption Prose Tests","12. Explicit Encryption","Case 3: can insert encrypted unindexed"],"updatePoint":{"line":1534,"column":37,"index":64854},"line":1534,"code":"      it('returns unindexed documents', async function () {\n        // Use encryptedClient to run a \"find\" operation on the db.explicit_encryption\n        // collection with the filter { \"_id\": 1 }.\n        // Assert one document is returned containing the field\n        // { \"encryptedUnindexed\": \"encrypted unindexed value\" }.\n        const collection = encryptedClient.db('db').collection('explicit_encryption');\n        const result = await collection.findOne({\n          _id: 1\n        });\n        expect(result).to.have.property('encryptedUnindexed', 'encrypted unindexed value');\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"decrypts the value","suites":["Client Side Encryption Prose Tests","12. Explicit Encryption","Case 4: can roundtrip encrypted indexed"],"updatePoint":{"line":1561,"column":28,"index":66028},"line":1561,"code":"      it('decrypts the value', async function () {\n        // Use clientEncryption to decrypt payload. Assert the returned value\n        // equals \"encrypted indexed value\".\n        const result = await clientEncryption.decrypt(payload);\n        expect(result).equals('encrypted indexed value');\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"decrypts the value","suites":["Client Side Encryption Prose Tests","12. Explicit Encryption","Case 5: can roundtrip encrypted unindexed"],"updatePoint":{"line":1582,"column":28,"index":66899},"line":1582,"code":"      it('decrypts the value', async function () {\n        // Use clientEncryption to decrypt payload. Assert the returned value\n        // equals \"encrypted unindexed value\".\n        const result = await clientEncryption.decrypt(payload);\n        expect(result).equals('encrypted unindexed value');\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"createDataKey() handles duplicate key errors on the keyvault collection","suites":["Client Side Encryption Prose Tests","13. Unique Index on keyAltNames","Case 1"],"updatePoint":{"line":1631,"column":81,"index":68749},"line":1631,"code":"      it('createDataKey() handles duplicate key errors on the keyvault collection', async function () {\n        // 1. Use client_encryption to create a new local data key with a keyAltName \"abc\" and assert the operation does not fail.\n        await clientEncryption.createDataKey('local', {\n          keyAltNames: ['abc']\n        });\n\n        // 2. Repeat Step 1 and assert the operation fails due to a duplicate key server error (error code 11000).\n        const resultStep2 = await clientEncryption.createDataKey('local', {\n          keyAltNames: ['abc']\n        }).catch(e => e);\n        expect(resultStep2, 'Error in step 2) expected clientEncryption.createDataKey to throw duplicate key error but it did not').to.be.instanceof(MongoServerError);\n        expect(resultStep2).have.property('code', 11000);\n\n        // 3. Use client_encryption to create a new local data key with a keyAltName \"def\" and assert the operation fails due to a duplicate key server error (error code 11000).\n        const resultStep3 = await clientEncryption.createDataKey('local', {\n          keyAltNames: ['def']\n        }).catch(e => e);\n        expect(resultStep3, 'Error in step 3) expected clientEncryption.createDataKey to throw duplicate key error but it did not').to.be.instanceof(MongoServerError);\n        expect(resultStep3).have.property('code', 11000);\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"addKeyAltName() handles duplicate key errors on the keyvault collection","suites":["Client Side Encryption Prose Tests","13. Unique Index on keyAltNames","Case 2"],"updatePoint":{"line":1653,"column":81,"index":70160},"line":1653,"code":"      it('addKeyAltName() handles duplicate key errors on the keyvault collection', async function () {\n        // 1. Use client_encryption to create a new local data key and assert the operation does not fail.\n        const _id = await clientEncryption.createDataKey('local');\n\n        // 2. Use client_encryption to add a keyAltName \"abc\" to the key created in Step 1 and assert the operation does not fail.\n        await clientEncryption.addKeyAltName(_id, 'abc');\n\n        // 3. Repeat Step 2, assert the operation does not fail, and assert the returned key document contains the keyAltName \"abc\" added in Step 2.\n        const resultStep3 = await clientEncryption.addKeyAltName(_id, 'abc');\n        expect(resultStep3).to.have.property('keyAltNames').to.include('abc');\n\n        // 4. Use client_encryption to add a keyAltName \"def\" to the key created in Step 1 and assert the operation fails due to a duplicate key server error (error code 11000).\n        const resultStep4 = await clientEncryption.addKeyAltName(_id, 'def').catch(e => e);\n        expect(resultStep4, 'Error in step 4) expected clientEncryption.addKeyAltName to throw duplicate key error but it did not').to.be.instanceof(MongoServerError);\n        expect(resultStep4).to.have.property('code', 11000);\n\n        // 5. Use client_encryption to add a keyAltName \"def\" to the existing key, assert the operation does not fail, and assert the returned key document contains the keyAltName \"def\" added during Setup.\n        const resultStep5 = await clientEncryption.addKeyAltName(setupKeyId, 'def');\n        expect(resultStep5).to.have.property('keyAltNames').to.include('def');\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"expects an error and a command failed event","suites":["Client Side Encryption Prose Tests","14. Decryption Events","Case 1: Command Error"],"updatePoint":{"line":1782,"column":53,"index":76156},"line":1782,"code":"      it('expects an error and a command failed event', async function () {\n        // Use ``encryptedClient`` to run an aggregate on ``db.decryption_events``.\n        // Expect an exception to be thrown from the command error. Expect a CommandFailedEvent.\n        const collection = encryptedClient.db('db').collection('decryption_events');\n        try {\n          await collection.aggregate([]).toArray();\n          expect.fail('aggregate must fail with error');\n        } catch (error) {\n          expect(error.code).to.equal(123);\n        }\n        expect(aggregateFailed.failure.code).to.equal(123);\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"expects an error and a command failed event","suites":["Client Side Encryption Prose Tests","14. Decryption Events","Case 2: Network Error"],"updatePoint":{"line":1823,"column":53,"index":77665},"line":1823,"code":"      it('expects an error and a command failed event', async function () {\n        // Use ``encryptedClient`` to run an aggregate on ``db.decryption_events``.\n        // Expect an exception to be thrown from the network error. Expect a CommandFailedEvent.\n        const collection = encryptedClient.db('db').collection('decryption_events');\n        try {\n          await collection.aggregate([]).toArray();\n          expect.fail('aggregate must fail with error');\n        } catch (error) {\n          expect(error).to.be.instanceOf(MongoNetworkError);\n        }\n        expect(aggregateFailed.failure.message).to.include('closed');\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"errors on decryption but command succeeds","suites":["Client Side Encryption Prose Tests","14. Decryption Events","Case 3: Decrypt Error"],"updatePoint":{"line":1837,"column":51,"index":78374},"line":1837,"code":"      it('errors on decryption but command succeeds', async function () {\n        // Use ``encryptedClient`` to insert the document ``{ \"encrypted\": <malformedCiphertext> }``\n        // into ``db.decryption_events``.\n        // Use ``encryptedClient`` to run an aggregate on ``db.decryption_events``.\n        // Expect an exception to be thrown from the decryption error.\n        // Expect a CommandSucceededEvent. Expect the CommandSucceededEvent.reply\n        // to contain BSON binary for the field\n        // ``cursor.firstBatch.encrypted``.\n        const collection = encryptedClient.db('db').collection('decryption_events');\n        await collection.insertOne({\n          encrypted: malformedCiphertext\n        });\n        try {\n          await collection.aggregate([]).toArray();\n          expect.fail('aggregate must fail with error');\n        } catch (error) {\n          expect(error.message).to.include('HMAC validation failure');\n        }\n        const doc = aggregateSucceeded.reply.cursor.firstBatch[0];\n        expect(doc.encrypted).to.be.instanceOf(Binary);\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"succeeds on decryption and command succeeds","suites":["Client Side Encryption Prose Tests","14. Decryption Events","Case 4: Decrypt Success"],"updatePoint":{"line":1860,"column":53,"index":79531},"line":1860,"code":"      it('succeeds on decryption and command succeeds', async function () {\n        // Use ``encryptedClient`` to insert the document ``{ \"encrypted\": <ciphertext> }``\n        // into ``db.decryption_events``.\n        // Use ``encryptedClient`` to run an aggregate on ``db.decryption_events``.\n        // Expect no exception.\n        // Expect a CommandSucceededEvent. Expect the CommandSucceededEvent.reply\n        // to contain BSON binary for the field ``cursor.firstBatch.encrypted``.\n        const collection = encryptedClient.db('db').collection('decryption_events');\n        await collection.insertOne({\n          encrypted: cipherText\n        });\n        let result;\n        try {\n          result = await collection.aggregate([]).toArray();\n        } catch (error) {\n          expect.fail(`aggregate must not fail, got ${error.message}`);\n        }\n        expect(result[0].encrypted).to.equal('hello');\n        const doc = aggregateSucceeded.reply.cursor.firstBatch[0];\n        expect(doc.encrypted).to.be.instanceOf(Binary);\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should rewrap data key from  to ","suites":["Client Side Encryption Prose Tests","16. Rewrap"],"updatePoint":{"line":1931,"column":70,"index":81979},"line":1931,"code":"      it(`should rewrap data key from ${srcProvider} to ${dstProvider}`, metadata, async function () {\n        // Step 1. Drop the collection ``keyvault.datakeys``\n        await client1.db('keyvault').dropCollection('datakeys').catch(() => null);\n\n        // Step 2. Create a ``ClientEncryption`` object named ``clientEncryption1``\n        const clientEncryption1 = new this.configuration.mongodbClientEncryption.ClientEncryption(client1, {\n          keyVaultNamespace: 'keyvault.datakeys',\n          kmsProviders: getKmsProviders(),\n          tlsOptions: {\n            kmip: {\n              tlsCAFile: process.env.KMIP_TLS_CA_FILE,\n              tlsCertificateKeyFile: process.env.KMIP_TLS_CERT_FILE\n            }\n          },\n          extraOptions: getEncryptExtraOptions(),\n          bson: BSON\n        });\n\n        // Step 3. Call ``clientEncryption1.createDataKey`` with ``srcProvider``\n        const keyId = await clientEncryption1.createDataKey(srcProvider, {\n          masterKey: masterKeys[srcProvider]\n        });\n\n        // Step 4. Call ``clientEncryption1.encrypt`` with the value \"test\"\n        const cipherText = await clientEncryption1.encrypt('test', {\n          keyId,\n          algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic'\n        });\n\n        // Step 5. Create a ``ClientEncryption`` object named ``clientEncryption2``\n        const clientEncryption2 = new this.configuration.mongodbClientEncryption.ClientEncryption(client2, {\n          keyVaultNamespace: 'keyvault.datakeys',\n          kmsProviders: getKmsProviders(),\n          tlsOptions: {\n            kmip: {\n              tlsCAFile: process.env.KMIP_TLS_CA_FILE,\n              tlsCertificateKeyFile: process.env.KMIP_TLS_CERT_FILE\n            }\n          },\n          extraOptions: getEncryptExtraOptions(),\n          bson: BSON\n        });\n\n        // Step 6. Call ``clientEncryption2.rewrapManyDataKey`` with an empty ``filter``\n        const rewrapManyDataKeyResult = await clientEncryption2.rewrapManyDataKey({}, {\n          provider: dstProvider,\n          masterKey: masterKeys[dstProvider]\n        });\n        expect(rewrapManyDataKeyResult).to.have.property('bulkWriteResult');\n        expect(rewrapManyDataKeyResult.bulkWriteResult).to.have.property('nModified', 1);\n\n        // 7. Call ``clientEncryption1.decrypt`` with the ``ciphertext``. Assert the return value is \"test\".\n        const decryptResult1 = await clientEncryption1.decrypt(cipherText);\n        expect(decryptResult1).to.equal('test');\n\n        // 8. Call ``clientEncryption2.decrypt`` with the ``ciphertext``. Assert the return value is \"test\".\n        const decryptResult2 = await clientEncryption2.decrypt(cipherText);\n        expect(decryptResult2).to.equal('test');\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"cursor count method should return the correct number when used with collation set","suites":["Collation"],"updatePoint":{"line":13,"column":87,"index":302},"line":13,"code":"  it('cursor count method should return the correct number when used with collation set', async function () {\n    const configuration = this.configuration;\n    const client = configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    const db = client.db(configuration.db);\n    const docs = [{\n      _id: 0,\n      name: 'foo'\n    }, {\n      _id: 1,\n      name: 'Foo'\n    }];\n    const collation = {\n      locale: 'en_US',\n      strength: 2\n    };\n    await Promise.resolve();\n    await db.createCollection('cursor_collation_count');\n    const collection = db.collection('cursor_collation_count');\n    await collection.insertMany(docs);\n    const cursor = collection.find({\n      name: 'foo'\n    }).collation(collation);\n    const val = await cursor.count();\n    expect(val).to.equal(2);\n    await client.close();\n  });","file":"integration/collation/collations.test.js","skipped":false,"dir":"test"},{"name":"should correctly create index with collation","suites":["Collation"],"updatePoint":{"line":43,"column":50,"index":1104},"line":43,"code":"  it('should correctly create index with collation', async function () {\n    const configuration = this.configuration;\n    const client = configuration.newClient();\n    const db = client.db(configuration.db);\n    const col = db.collection('collation_test');\n    await col.createIndexes([{\n      key: {\n        a: 1\n      },\n      collation: {\n        locale: 'nn'\n      },\n      name: 'collation_test'\n    }]);\n    const r = await col.listIndexes().toArray();\n    const indexes = r.filter(i => i.name === 'collation_test');\n    expect(indexes).to.have.length(1);\n    expect(indexes[0]).to.have.property('collation');\n    expect(indexes[0].collation).to.exist;\n    await client.close();\n  });","file":"integration/collation/collations.test.js","skipped":false,"dir":"test"},{"name":"Should correctly create collection with collation","suites":["Collation"],"updatePoint":{"line":64,"column":55,"index":1801},"line":64,"code":"  it('Should correctly create collection with collation', async function () {\n    const configuration = this.configuration;\n    const client = configuration.newClient();\n    const db = client.db(configuration.db);\n    await db.createCollection('collation_test2', {\n      collation: {\n        locale: 'nn'\n      }\n    });\n    const collections = await db.listCollections({\n      name: 'collation_test2'\n    }).toArray();\n    expect(collections).to.have.length(1);\n    expect(collections[0].name).to.equal('collation_test2');\n    expect(collections[0].options.collation).to.exist;\n    await client.close();\n  });","file":"integration/collation/collations.test.js","skipped":false,"dir":"test"},{"name":"Should correctly createCollection using Promise","suites":["Collection Management and Db Management (promise tests)"],"updatePoint":{"line":9,"column":53,"index":418},"line":9,"code":"  it('Should correctly createCollection using Promise', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({}, {\n      maxPoolSize: 5\n    });\n    client.db(configuration.db).createCollection('promiseCollection').then(function (col) {\n      test.ok(col != null);\n      client.close(done);\n    }).catch(function (err) {\n      test.ok(err != null);\n    });\n  });","file":"integration/collection-management/promise_collection_db_management.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly rename and drop collection using Promise","suites":["Collection Management and Db Management (promise tests)"],"updatePoint":{"line":21,"column":63,"index":844},"line":21,"code":"  it('Should correctly rename and drop collection using Promise', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({}, {\n      maxPoolSize: 5\n    });\n    const db = client.db(configuration.db);\n    db.createCollection('promiseCollection1').then(function (col) {\n      test.ok(col != null);\n      const db = client.db(configuration.db);\n      db.renameCollection('promiseCollection1', 'promiseCollection2').then(function (col) {\n        test.ok(col != null);\n        db.dropCollection('promiseCollection2').then(function (r) {\n          test.ok(r);\n          client.close(done);\n        });\n      });\n    });\n  });","file":"integration/collection-management/promise_collection_db_management.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly drop database using Promise","suites":["Collection Management and Db Management (promise tests)"],"updatePoint":{"line":39,"column":50,"index":1503},"line":39,"code":"  it('Should correctly drop database using Promise', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({}, {\n      maxPoolSize: 5\n    });\n    client.db(configuration.db).dropDatabase().then(function (r) {\n      test.ok(r);\n      client.close(done);\n    }).catch(function (e) {\n      test.ok(e != null);\n    });\n  });","file":"integration/collection-management/promise_collection_db_management.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly createCollections and call collections with Promise","suites":["Collection Management and Db Management (promise tests)"],"updatePoint":{"line":51,"column":74,"index":1901},"line":51,"code":"  it('Should correctly createCollections and call collections with Promise', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({}, {\n      maxPoolSize: 5\n    });\n    const db = client.db(configuration.db);\n    db.createCollection('promiseCollectionCollections1').then(function (col) {\n      test.ok(col != null);\n      db.createCollection('promiseCollectionCollections2').then(function (col) {\n        test.ok(col != null);\n        db.collections().then(function (r) {\n          test.ok(Array.isArray(r));\n          client.close(done);\n        });\n      });\n    });\n  });","file":"integration/collection-management/promise_collection_db_management.test.ts","skipped":false,"dir":"test"},{"name":"should correctly receive the APM events for an insert","suites":["Command Monitoring"],"updatePoint":{"line":8,"column":59,"index":354},"line":8,"code":"  it('should correctly receive the APM events for an insert', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      client.on('commandStarted', filterForCommands('insert', started));\n      client.on('commandSucceeded', filterForCommands('insert', succeeded));\n      return client.db(this.configuration.db).collection('apm_test').insertOne({\n        a: 1\n      }).then(r => {\n        expect(r).property('insertedId').to.exist;\n        expect(started.length).to.equal(1);\n        expect(started[0].commandName).to.equal('insert');\n        expect(started[0].command.insert).to.equal('apm_test');\n        expect(succeeded.length).to.equal(1);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly handle cursor.close when no cursor existed","suites":["Command Monitoring"],"updatePoint":{"line":39,"column":65,"index":1363},"line":39,"code":"  it('should correctly handle cursor.close when no cursor existed', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      client.on('commandStarted', filterForCommands('insert', started));\n      client.on('commandSucceeded', filterForCommands('insert', succeeded));\n      const db = client.db(this.configuration.db);\n      const collection = db.collection('apm_test_cursor');\n      return collection.insertMany([{\n        a: 1\n      }, {\n        a: 2\n      }, {\n        a: 3\n      }]).then(r => {\n        expect(r).property('insertedCount').to.equal(3);\n        const cursor = collection.find({});\n        return cursor.count().then(() => {\n          cursor.close(); // <-- Will cause error in APM module.\n          return client.close();\n        });\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly receive the APM events for a listCollections command","suites":["Command Monitoring"],"updatePoint":{"line":76,"column":75,"index":2446},"line":76,"code":"  it('should correctly receive the APM events for a listCollections command', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.0.0'\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      client.on('commandStarted', filterForCommands('listCollections', started));\n      client.on('commandSucceeded', filterForCommands('listCollections', succeeded));\n      const db = client.db(this.configuration.db);\n      return db.collection('apm_test_list_collections').insertOne({\n        a: 1\n      }, this.configuration.writeConcernMax()).then(r => {\n        expect(r).property('insertedId').to.exist;\n        return db.listCollections({}, {\n          readPreference: ReadPreference.primary\n        }).toArray();\n      }).then(() => db.listCollections({}, {\n        readPreference: ReadPreference.secondary\n      }).toArray()).then(() => {\n        expect(started).to.have.lengthOf(2);\n        expect(started[0]).property('address').to.not.equal(started[1].address);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly receive the APM events for a listIndexes command","suites":["Command Monitoring"],"line":115,"code":"  it.skip('should correctly receive the APM events for a listIndexes command', {","file":"integration/command-monitoring/command_monitoring.test.ts","skipped":true,"dir":"test"},{"name":"should correctly receive the APM events for a find with getmore and killcursor","suites":["Command Monitoring"],"updatePoint":{"line":153,"column":84,"index":5123},"line":153,"code":"  it('should correctly receive the APM events for a find with getmore and killcursor', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const failed = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['find', 'getMore', 'killCursors'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      client.on('commandFailed', filterForCommands(desiredEvents, failed));\n      const db = client.db(this.configuration.db);\n\n      // Drop the collection\n      return db.collection('apm_test_2').drop().catch(ignoreNsNotFound).then(() => {\n        // Insert test documents\n        return db.collection('apm_test_2').insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        });\n      }).then(r => {\n        expect(r).property('insertedCount').to.equal(6);\n        return db.collection('apm_test_2').find({\n          a: 1\n        }).project({\n          _id: 1,\n          a: 1\n        }).hint({\n          _id: 1\n        }).skip(1).limit(100).batchSize(2).comment('some comment').maxTimeMS(5000).withReadPreference(ReadPreference.PRIMARY).addCursorFlag('noCursorTimeout', true).toArray();\n      }).then(docs => {\n        // Assert basic documents\n        expect(docs).to.have.length(5);\n        expect(started).to.have.length(3);\n        expect(succeeded).to.have.length(3);\n        expect(failed).to.have.length(0);\n\n        // Success messages\n        expect(succeeded[0].reply).to.not.be.null;\n        expect(succeeded[0].operationId).to.equal(succeeded[1].operationId);\n        expect(succeeded[0].operationId).to.equal(succeeded[2].operationId);\n        expect(succeeded[1].reply).to.not.be.null;\n        expect(succeeded[2].reply).to.not.be.null;\n\n        // Started\n        expect(started[0].operationId).to.equal(started[1].operationId);\n        expect(started[0].operationId).to.equal(started[2].operationId);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly receive the APM failure event for find","suites":["Command Monitoring"],"updatePoint":{"line":228,"column":61,"index":7543},"line":228,"code":"  it('should correctly receive the APM failure event for find', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset'],\n        mongodb: '>=2.6.0'\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const failed = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['find', 'getMore', 'killCursors'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      client.on('commandFailed', filterForCommands(desiredEvents, failed));\n      const db = client.db(this.configuration.db);\n\n      // Drop the collection\n      return db.collection('apm_test_2').drop().catch(ignoreNsNotFound).then(() => {\n        // Insert test documents\n        return db.collection('apm_test_2').insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }]);\n      }).then(r => {\n        expect(r).property('insertedCount').to.equal(6);\n        return db.collection('apm_test_2').find({\n          $illegalfield: 1\n        }).project({\n          _id: 1,\n          a: 1\n        }).hint({\n          _id: 1\n        }).skip(1).limit(100).batchSize(2).comment('some comment').maxTimeMS(5000).withReadPreference(ReadPreference.PRIMARY).addCursorFlag('noCursorTimeout', true).toArray();\n      }).then(() => {\n        throw new Error('this should not happen');\n      }).catch(() => {\n        expect(failed).to.have.length(1);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly receive the APM events for a bulk operation","suites":["Command Monitoring"],"updatePoint":{"line":287,"column":66,"index":9348},"line":287,"code":"  it('should correctly receive the APM events for a bulk operation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['insert', 'update', 'delete'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      const db = client.db(this.configuration.db);\n      return db.collection('apm_test_3').bulkWrite([{\n        insertOne: {\n          document: {\n            a: 1\n          }\n        }\n      }, {\n        updateOne: {\n          filter: {\n            a: 2\n          },\n          update: {\n            $set: {\n              a: 2\n            }\n          },\n          upsert: true\n        }\n      }, {\n        deleteOne: {\n          filter: {\n            c: 1\n          }\n        }\n      }], {\n        ordered: true\n      }).then(() => {\n        expect(started).to.have.length(3);\n        expect(succeeded).to.have.length(3);\n        expect(started[0].operationId).to.equal(started[1].operationId);\n        expect(started[0].operationId).to.equal(started[2].operationId);\n        expect(succeeded[0].operationId).to.equal(succeeded[1].operationId);\n        expect(succeeded[0].operationId).to.equal(succeeded[2].operationId);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly receive the APM explain command","suites":["Command Monitoring"],"updatePoint":{"line":345,"column":54,"index":10949},"line":345,"code":"  it('should correctly receive the APM explain command', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const failed = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['find', 'getMore', 'killCursors', 'explain'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      client.on('commandFailed', filterForCommands(desiredEvents, failed));\n      const db = client.db(this.configuration.db);\n      return db.collection('apm_test_2').drop().catch(ignoreNsNotFound).then(() => db.collection('apm_test_2').insertMany([{\n        a: 1\n      }, {\n        a: 1\n      }, {\n        a: 1\n      }, {\n        a: 1\n      }, {\n        a: 1\n      }, {\n        a: 1\n      }], {\n        writeConcern: {\n          w: 1\n        }\n      })).then(r => {\n        expect(r).property('insertedCount').to.equal(6);\n        return db.collection('apm_test_2').find({\n          a: 1\n        }).explain();\n      }).then(explain => {\n        expect(explain).to.not.be.null;\n        expect(started).to.have.length(1);\n        expect(started[0].commandName).to.equal('explain');\n        expect(started[0].command.explain.find).to.equal('apm_test_2');\n        expect(succeeded).to.have.length(1);\n        expect(succeeded[0].commandName).to.equal('explain');\n        expect(started[0].operationId).to.equal(succeeded[0].operationId);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly filter out sensitive commands","suites":["Command Monitoring"],"updatePoint":{"line":401,"column":52,"index":12701},"line":401,"code":"  it('should correctly filter out sensitive commands', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const failed = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['getnonce'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      client.on('commandFailed', filterForCommands(desiredEvents, failed));\n      return client.db(this.configuration.db).command({\n        getnonce: true\n      }).then(r => {\n        expect(r).to.exist;\n        expect(started).to.have.length(1);\n        expect(succeeded).to.have.length(1);\n        expect(failed).to.have.length(0);\n        expect(started[0].command).to.eql({});\n        expect(succeeded[0].reply).to.eql({});\n        return client.close();\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly receive the APM events for an updateOne","suites":["Command Monitoring"],"updatePoint":{"line":436,"column":62,"index":13822},"line":436,"code":"  it('should correctly receive the APM events for an updateOne', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['update'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      return client.db(this.configuration.db).collection('apm_test_u_1').updateOne({\n        a: 1\n      }, {\n        $set: {\n          b: 1\n        }\n      }, {\n        upsert: true\n      }).then(r => {\n        expect(r).to.exist;\n        expect(started).to.have.length(1);\n        expect(started[0].commandName).to.equal('update');\n        expect(started[0].command.update).to.equal('apm_test_u_1');\n        expect(succeeded).to.have.length(1);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly receive the APM events for an updateMany","suites":["Command Monitoring"],"updatePoint":{"line":474,"column":63,"index":14935},"line":474,"code":"  it('should correctly receive the APM events for an updateMany', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['update'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      return client.db(this.configuration.db).collection('apm_test_u_2').updateMany({\n        a: 1\n      }, {\n        $set: {\n          b: 1\n        }\n      }, {\n        upsert: true\n      }).then(r => {\n        expect(r).to.exist;\n        expect(started).to.have.length(1);\n        expect(started[0].commandName).to.equal('update');\n        expect(started[0].command.update).to.equal('apm_test_u_2');\n        expect(succeeded).to.have.length(1);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly receive the APM events for deleteOne","suites":["Command Monitoring"],"updatePoint":{"line":512,"column":59,"index":16045},"line":512,"code":"  it('should correctly receive the APM events for deleteOne', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['delete'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      return client.db(this.configuration.db).collection('apm_test_u_3').deleteOne({\n        a: 1\n      }).then(r => {\n        expect(r).to.exist;\n        expect(started).to.have.length(1);\n        expect(started[0].commandName).to.equal('delete');\n        expect(started[0].command.delete).to.equal('apm_test_u_3');\n        expect(succeeded).to.have.length(1);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should ensure killcursor commands are sent on 3.0 or earlier when APM is enabled","suites":["Command Monitoring"],"updatePoint":{"line":544,"column":86,"index":17097},"line":544,"code":"  it('should ensure killcursor commands are sent on 3.0 or earlier when APM is enabled', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset'],\n        mongodb: '<=3.0.x'\n      }\n    },\n    test: function () {\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const db = client.db(this.configuration.db);\n      const admindb = db.admin();\n      let cursorCountBefore;\n      let cursorCountAfter;\n      const collection = db.collection('apm_killcursor_tests');\n\n      // make sure collection has records (more than 2)\n      return collection.insertMany([{\n        a: 1\n      }, {\n        a: 2\n      }, {\n        a: 3\n      }]).then(r => {\n        expect(r).to.exist;\n        return admindb.serverStatus();\n      }).then(result => {\n        cursorCountBefore = result.cursors.clientCursors_size;\n        const cursor = collection.find({}).limit(2);\n        return cursor.toArray().then(r => {\n          expect(r).to.exist;\n          return cursor.close();\n        });\n      }).then(() => admindb.serverStatus()).then(result => {\n        cursorCountAfter = result.cursors.clientCursors_size;\n        expect(cursorCountBefore).to.equal(cursorCountAfter);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly decorate the apm result for aggregation with cursorId","suites":["Command Monitoring"],"updatePoint":{"line":590,"column":76,"index":18448},"line":590,"code":"  it('should correctly decorate the apm result for aggregation with cursorId', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset'],\n        mongodb: '>=3.0.0'\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n\n      // Generate docs\n      const docs = [];\n      for (let i = 0; i < 2500; i++) docs.push({\n        a: i\n      });\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['aggregate', 'getMore'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      const db = client.db(this.configuration.db);\n      return db.collection('apm_test_u_4').drop().catch(ignoreNsNotFound).then(() => db.collection('apm_test_u_4').insertMany(docs)).then(r => {\n        expect(r).to.exist;\n        return db.collection('apm_test_u_4').aggregate([{\n          $match: {}\n        }]).toArray();\n      }).then(r => {\n        expect(r).to.exist;\n        expect(started).to.have.length(4);\n        expect(succeeded).to.have.length(4);\n        const cursors = succeeded.map(x => x.reply.cursor);\n\n        // Check we have a cursor\n        expect(cursors[0].id).to.exist;\n        expect(cursors[0].id.toString()).to.equal(cursors[1].id.toString());\n        expect(cursors[3].id.toString()).to.equal('0');\n        return client.close();\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly decorate the apm result for listCollections with cursorId","suites":["Command Monitoring"],"updatePoint":{"line":637,"column":80,"index":20024},"line":637,"code":"  it('should correctly decorate the apm result for listCollections with cursorId', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset'],\n        mongodb: '>=3.0.0'\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['listCollections'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      const db = client.db(this.configuration.db);\n      const promises = [];\n      for (let i = 0; i < 20; i++) {\n        promises.push(db.collection('_mass_collection_' + i).insertOne({\n          a: 1\n        }));\n      }\n      return Promise.all(promises).then(r => {\n        expect(r).to.exist;\n        return db.listCollections().batchSize(10).toArray();\n      }).then(r => {\n        expect(r).to.exist;\n        expect(started).to.have.length(1);\n        expect(succeeded).to.have.length(1);\n        const cursors = succeeded.map(x => x.reply.cursor);\n        expect(cursors[0].id).to.exist;\n        return client.close();\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should not allow mutation of internal state from commands returned by event monitoring","suites":["Command Monitoring","Internal state references"],"updatePoint":{"line":695,"column":94,"index":21717},"line":695,"code":"    it('should not allow mutation of internal state from commands returned by event monitoring', function () {\n      const started = [];\n      const succeeded = [];\n      client.on('commandStarted', filterForCommands('insert', started));\n      client.on('commandSucceeded', filterForCommands('insert', succeeded));\n      const documentToInsert = {\n        a: {\n          b: 1\n        }\n      };\n      const db = client.db(this.configuration.db);\n      return db.collection('apm_test').insertOne(documentToInsert).then(r => {\n        expect(r).to.have.property('insertedId').that.is.an('object');\n        expect(started).to.have.lengthOf(1);\n        // Check if contents of returned document are equal to document inserted (by value)\n        expect(documentToInsert).to.deep.equal(started[0].command.documents[0]);\n        // Check if the returned document is a clone of the original. This confirms that the\n        // reference is not the same.\n        expect(documentToInsert !== started[0].command.documents[0]).to.equal(true);\n        expect(documentToInsert.a !== started[0].command.documents[0].a).to.equal(true);\n        started[0].command.documents[0].a.b = 2;\n        expect(documentToInsert.a.b).to.equal(1);\n        expect(started[0].commandName).to.equal('insert');\n        expect(started[0].command.insert).to.equal('apm_test');\n        expect(succeeded).to.have.lengthOf(1);\n      });\n    });","file":"integration/command-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should execute a command against a server","suites":["Connection","Connection - functional/cmap"],"updatePoint":{"line":18,"column":49,"index":973},"line":18,"code":"    it('should execute a command against a server', {\n      metadata: {\n        requires: {\n          apiVersion: false,\n          topology: '!load-balanced'\n        }\n      },\n      test: function (done) {\n        const connectOptions = Object.assign({\n          connectionType: Connection\n        }, this.configuration.options);\n        connect(connectOptions, (err, conn) => {\n          expect(err).to.not.exist;\n          this.defer(_done => conn.destroy(_done));\n          conn.command(ns('admin.$cmd'), {\n            [LEGACY_HELLO_COMMAND]: 1\n          }, undefined, (err, hello) => {\n            expect(err).to.not.exist;\n            expect(hello).to.exist;\n            expect(hello.ok).to.equal(1);\n            done();\n          });\n        });\n      }\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.ts","skipped":false,"dir":"test"},{"name":"should emit command monitoring events","suites":["Connection","Connection - functional/cmap"],"updatePoint":{"line":43,"column":45,"index":1738},"line":43,"code":"    it('should emit command monitoring events', {\n      metadata: {\n        requires: {\n          apiVersion: false,\n          topology: '!load-balanced'\n        }\n      },\n      test: function (done) {\n        const connectOptions = Object.assign({\n          connectionType: Connection,\n          monitorCommands: true\n        }, this.configuration.options);\n        connect(connectOptions, (err, conn) => {\n          expect(err).to.not.exist;\n          this.defer(_done => conn.destroy(_done));\n          const events = [];\n          conn.on('commandStarted', event => events.push(event));\n          conn.on('commandSucceeded', event => events.push(event));\n          conn.on('commandFailed', event => events.push(event));\n          conn.command(ns('admin.$cmd'), {\n            [LEGACY_HELLO_COMMAND]: 1\n          }, undefined, (err, hello) => {\n            expect(err).to.not.exist;\n            expect(hello).to.exist;\n            expect(hello.ok).to.equal(1);\n            expect(events).to.have.length(2);\n            done();\n          });\n        });\n      }\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.ts","skipped":false,"dir":"test"},{"name":"should support socket timeouts","suites":["Connection","Connection - functional/cmap"],"line":74,"code":"    it.skip('should support socket timeouts', {","file":"integration/connection-monitoring-and-pooling/connection.test.ts","skipped":true,"dir":"test"},{"name":"should support calling back multiple times on exhaust commands","suites":["Connection","Connection - functional/cmap"],"updatePoint":{"line":95,"column":70,"index":3389},"line":95,"code":"    it('should support calling back multiple times on exhaust commands', {\n      metadata: {\n        requires: {\n          apiVersion: false,\n          mongodb: '>=4.2.0',\n          topology: ['single']\n        }\n      },\n      test: function (done) {\n        const namespace = ns(`${this.configuration.db}.$cmd`);\n        const connectOptions = Object.assign({\n          connectionType: Connection\n        }, this.configuration.options);\n        connect(connectOptions, (err, conn) => {\n          expect(err).to.not.exist;\n          this.defer(_done => conn.destroy(_done));\n          const documents = Array.from(Array(10000), (_, idx) => ({\n            test: Math.floor(Math.random() * idx)\n          }));\n          conn.command(namespace, {\n            drop: 'test'\n          }, undefined, () => {\n            conn.command(namespace, {\n              insert: 'test',\n              documents\n            }, undefined, (err, res) => {\n              expect(err).to.not.exist;\n              expect(res).nested.property('n').to.equal(documents.length);\n              let totalDocumentsRead = 0;\n              conn.command(namespace, {\n                find: 'test',\n                batchSize: 100\n              }, undefined, (err, result) => {\n                expect(err).to.not.exist;\n                expect(result).nested.property('cursor').to.exist;\n                const cursor = result.cursor;\n                totalDocumentsRead += cursor.firstBatch.length;\n                conn.command(namespace, {\n                  getMore: cursor.id,\n                  collection: 'test',\n                  batchSize: 100\n                }, {\n                  exhaustAllowed: true\n                }, (err, result) => {\n                  expect(err).to.not.exist;\n                  expect(result).nested.property('cursor').to.exist;\n                  const cursor = result.cursor;\n                  totalDocumentsRead += cursor.nextBatch.length;\n                  if (cursor.id === 0 || cursor.id.isZero()) {\n                    expect(totalDocumentsRead).to.equal(documents.length);\n                    done();\n                  }\n                });\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.ts","skipped":false,"dir":"test"},{"name":"should correctly start monitoring for single server connection","suites":["Connection","Connection - functional"],"updatePoint":{"line":162,"column":70,"index":5824},"line":162,"code":"    it('should correctly start monitoring for single server connection', {\n      metadata: {\n        requires: {\n          topology: 'single',\n          os: '!win32'\n        }\n      },\n      test: async function () {\n        const configuration = this.configuration;\n        client = configuration.newClient(`mongodb://${encodeURIComponent('/tmp/mongodb-27017.sock')}?w=1`, {\n          maxPoolSize: 1,\n          heartbeatFrequencyMS: 250\n        });\n        let isMonitoring = false;\n        client.once('serverHeartbeatStarted', event => {\n          // just to be sure we get what we expect, checking the instanceof\n          isMonitoring = event instanceof ServerHeartbeatStartedEvent;\n        });\n        await client.connect();\n        expect(isMonitoring).to.be.true;\n      }\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.ts","skipped":false,"dir":"test"},{"name":"should correctly connect to server using domain socket","suites":["Connection","Connection - functional"],"updatePoint":{"line":184,"column":62,"index":6605},"line":184,"code":"    it('should correctly connect to server using domain socket', {\n      metadata: {\n        requires: {\n          topology: 'single',\n          os: '!win32'\n        }\n      },\n      test: function (done) {\n        const configuration = this.configuration;\n        client = configuration.newClient(`mongodb://${encodeURIComponent('/tmp/mongodb-27017.sock')}?w=1`, {\n          maxPoolSize: 1\n        });\n        const db = client.db(configuration.db);\n        db.collection('domainSocketCollection0').insert({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('domainSocketCollection0').find({\n            a: 1\n          }).toArray(function (err, items) {\n            expect(err).to.not.exist;\n            test.equal(1, items.length);\n            done();\n          });\n        });\n      }\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.ts","skipped":false,"dir":"test"},{"name":"should only pass one argument (topology and not error) for topology \"open\" events","suites":["Connection","Connection - functional"],"updatePoint":{"line":215,"column":89,"index":7549},"line":215,"code":"    it('should only pass one argument (topology and not error) for topology \"open\" events', function (done) {\n      const configuration = this.configuration;\n      client = configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      });\n      client.on('topologyOpening', () => {\n        client.topology.on('open', (...args) => {\n          expect(args).to.have.lengthOf(1);\n          expect(args[0]).to.be.instanceOf(Topology);\n          done();\n        });\n      });\n      client.connect();\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.ts","skipped":false,"dir":"test"},{"name":"should correctly connect to server using just events","suites":["Connection","Connection - functional"],"updatePoint":{"line":231,"column":60,"index":8039},"line":231,"code":"    it('should correctly connect to server using just events', function (done) {\n      const configuration = this.configuration;\n      client = configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      });\n      client.on('open', clientFromEvent => {\n        expect(clientFromEvent).to.be.instanceOf(MongoClient);\n        expect(clientFromEvent).to.equal(client);\n        done();\n      });\n      client.connect();\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.ts","skipped":false,"dir":"test"},{"name":"should correctly connect to server using big connection pool","suites":["Connection","Connection - functional"],"updatePoint":{"line":245,"column":68,"index":8490},"line":245,"code":"    it('should correctly connect to server using big connection pool', function (done) {\n      const configuration = this.configuration;\n      client = configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 2000\n      });\n      client.on('open', function () {\n        done();\n      });\n      client.connect();\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.ts","skipped":false,"dir":"test"},{"name":"test connect no options","suites":["Connection","Connection - functional"],"updatePoint":{"line":280,"column":31,"index":9508},"line":280,"code":"    it('test connect no options', {\n      metadata: {\n        requires: {\n          topology: 'single'\n        }\n      },\n      test: function (done) {\n        const configuration = this.configuration;\n        client = configuration.newClient();\n        client.connect(connectionTester(configuration, 'testConnectNoOptions', function () {\n          done();\n        }));\n      }\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.ts","skipped":false,"dir":"test"},{"name":"test connect good auth","suites":["Connection","Connection - functional"],"updatePoint":{"line":294,"column":30,"index":9893},"line":294,"code":"    it('test connect good auth', {\n      metadata: {\n        requires: {\n          topology: 'single'\n        }\n      },\n      test: function (done) {\n        const configuration = this.configuration;\n        const username = 'testConnectGoodAuth';\n        const password = 'password';\n        client = configuration.newClient();\n\n        // First add a user.\n        const db = client.db(configuration.db);\n        db.addUser(username, password, function (err) {\n          expect(err).to.not.exist;\n          restOfTest();\n        });\n        function restOfTest() {\n          testClient = configuration.newClient(configuration.url({\n            username,\n            password\n          }));\n          testClient.connect(connectionTester(configuration, 'testConnectGoodAuth', function () {\n            done();\n          }));\n        }\n      }\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.ts","skipped":false,"dir":"test"},{"name":"test connect good auth as option","suites":["Connection","Connection - functional"],"updatePoint":{"line":323,"column":40,"index":10755},"line":323,"code":"    it('test connect good auth as option', {\n      metadata: {\n        requires: {\n          topology: 'single'\n        }\n      },\n      test: function (done) {\n        const configuration = this.configuration;\n        const username = 'testConnectGoodAuthAsOption';\n        const password = 'password';\n\n        // First add a user.\n        client = configuration.newClient();\n        const db = client.db(configuration.db);\n        db.addUser(username, password, {\n          roles: ['readWrite', 'dbAdmin']\n        }, function (err) {\n          expect(err).to.not.exist;\n          restOfTest();\n        });\n        function restOfTest() {\n          const opts = {\n            auth: {\n              username,\n              password\n            },\n            authSource: configuration.db\n          };\n          testClient = configuration.newClient(opts);\n          testClient.connect(connectionTester(configuration, 'testConnectGoodAuthAsOption', function () {\n            done();\n          }));\n        }\n      }\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.ts","skipped":false,"dir":"test"},{"name":"test connect bad auth","suites":["Connection","Connection - functional"],"updatePoint":{"line":358,"column":29,"index":11767},"line":358,"code":"    it('test connect bad auth', async function () {\n      client = this.configuration.newClient({\n        auth: {\n          username: 'slithy',\n          password: 'toves'\n        }\n      });\n      const error = await client.connect().catch(error => error);\n      expect(error).to.be.instanceOf(MongoServerError);\n      await client.close();\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.ts","skipped":false,"dir":"test"},{"name":"test connect bad url","suites":["Connection","Connection - functional"],"updatePoint":{"line":369,"column":28,"index":12116},"line":369,"code":"    it('test connect bad url', {\n      metadata: {\n        requires: {\n          topology: 'single'\n        }\n      },\n      test: function () {\n        const configuration = this.configuration;\n        expect(() => configuration.newClient('mangodb://localhost:27017/test?safe=false')).to.throw();\n      }\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.ts","skipped":false,"dir":"test"},{"name":"getMore iteration","suites":[],"updatePoint":{"line":62,"column":23,"index":2334},"line":62,"code":"  it('getMore iteration', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.2.0',\n        topology: 'replicaset'\n      }\n    },\n    test: function () {\n      return collection.insertMany([{\n        a: 1\n      }, {\n        a: 2\n      }, {\n        a: 3\n      }, {\n        a: 4\n      }, {\n        a: 5\n      }], {\n        writeConcern: {\n          w: 'majority'\n        }\n      }).then(result => expect(result.insertedCount).to.equal(5)).then(() => {\n        const cursor = collection.find({}, {\n          batchSize: 2\n        });\n        deferred.push(() => cursor.close());\n        return cursor.next().then(item => expect(item.a).to.equal(1)).then(() => cursor.next()).then(item => expect(item.a).to.equal(2)).then(() => {\n          return connectionCount(checkClient).then(initialConnectionCount => {\n            return client.db('admin').command({\n              replSetFreeze: 0\n            }, {\n              readPreference: 'secondary'\n            }).then(result => expect(result).property('info').to.equal('unfreezing')).then(() => client.db('admin').command({\n              replSetStepDown: 30,\n              force: true\n            }, {\n              readPreference: 'primary'\n            })).then(() => cursor.next()).then(item => expect(item.a).to.equal(3)).then(() => connectionCount(checkClient).then(expectPoolWasNotCleared(initialConnectionCount)));\n          });\n        });\n      });\n    }\n  });","file":"integration/connections-survive-step-down/connections_survive_step_down.prose.test.ts","skipped":false,"dir":"test"},{"name":"Not Primary - Keep Connection Pool","suites":[],"updatePoint":{"line":130,"column":40,"index":4604},"line":130,"code":"  it('Not Primary - Keep Connection Pool', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.2.0',\n        topology: 'replicaset'\n      }\n    },\n    test: function () {\n      return runStepownScenario(10107, expectPoolWasNotCleared);\n    }\n  });","file":"integration/connections-survive-step-down/connections_survive_step_down.prose.test.ts","skipped":false,"dir":"test"},{"name":"Not Primary - Reset Connection Pool","suites":[],"updatePoint":{"line":141,"column":41,"index":4859},"line":141,"code":"  it('Not Primary - Reset Connection Pool', {\n    metadata: {\n      requires: {\n        mongodb: '4.0.x',\n        topology: 'replicaset'\n      }\n    },\n    test: function () {\n      return runStepownScenario(10107, expectPoolWasCleared);\n    }\n  });","file":"integration/connections-survive-step-down/connections_survive_step_down.prose.test.ts","skipped":false,"dir":"test"},{"name":"Shutdown in progress - Reset Connection Pool","suites":[],"updatePoint":{"line":152,"column":50,"index":5118},"line":152,"code":"  it('Shutdown in progress - Reset Connection Pool', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.0.0',\n        topology: 'replicaset'\n      }\n    },\n    test: function () {\n      return runStepownScenario(91, expectPoolWasCleared);\n    }\n  });","file":"integration/connections-survive-step-down/connections_survive_step_down.prose.test.ts","skipped":false,"dir":"test"},{"name":"Interrupted at shutdown - Reset Connection Pool","suites":[],"updatePoint":{"line":163,"column":53,"index":5379},"line":163,"code":"  it('Interrupted at shutdown - Reset Connection Pool', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.0.0',\n        topology: 'replicaset'\n      }\n    },\n    test: function () {\n      return runStepownScenario(11600, expectPoolWasCleared);\n    }\n  });","file":"integration/connections-survive-step-down/connections_survive_step_down.prose.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute simple aggregation pipeline using array","suites":["Aggregation"],"updatePoint":{"line":12,"column":70,"index":413},"line":12,"code":"  it('should correctly execute simple aggregation pipeline using array', function (done) {\n    const client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n      databaseName = this.configuration.db;\n    const db = client.db(databaseName);\n    // Some docs for insertion\n    const docs = [{\n      title: 'this is my title',\n      author: 'bob',\n      posted: new Date(),\n      pageViews: 5,\n      tags: ['fun', 'good', 'fun'],\n      other: {\n        foo: 5\n      },\n      comments: [{\n        author: 'joe',\n        text: 'this is cool'\n      }, {\n        author: 'sam',\n        text: 'this is bad'\n      }]\n    }];\n\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyExecuteSimpleAggregationPipelineUsingArray');\n    // Insert the docs\n    collection.insertMany(docs, {\n      writeConcern: {\n        w: 1\n      }\n    }, function (err, result) {\n      expect(result).to.exist;\n      expect(err).to.not.exist;\n\n      // Execute aggregate, notice the pipeline is expressed as an Array\n      const cursor = collection.aggregate([{\n        $project: {\n          author: 1,\n          tags: 1\n        }\n      }, {\n        $unwind: '$tags'\n      }, {\n        $group: {\n          _id: {\n            tags: '$tags'\n          },\n          authors: {\n            $addToSet: '$author'\n          }\n        }\n      }, {\n        $sort: {\n          _id: -1\n        }\n      }]);\n      cursor.toArray(function (err, result) {\n        expect(err).to.not.exist;\n        expect(result[0]._id.tags).to.equal('good');\n        expect(result[0].authors).to.eql(['bob']);\n        expect(result[1]._id.tags).to.equal('fun');\n        expect(result[1].authors).to.eql(['bob']);\n        client.close(done);\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute db.aggregate() with $currentOp","suites":["Aggregation"],"updatePoint":{"line":82,"column":61,"index":2175},"line":82,"code":"  it('should correctly execute db.aggregate() with $currentOp', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.0.0'\n      }\n    },\n    test: function (done) {\n      const client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      });\n      const db = client.db('admin');\n      const cursor = db.aggregate([{\n        $currentOp: {\n          localOps: true\n        }\n      }]);\n      cursor.toArray((err, result) => {\n        expect(err).to.not.exist;\n        const aggregateOperation = result.filter(op => op.command && op.command.aggregate)[0];\n        expect(aggregateOperation.command.aggregate).to.equal(1);\n        expect(aggregateOperation.command.pipeline).to.eql([{\n          $currentOp: {\n            localOps: true\n          }\n        }]);\n        expect(aggregateOperation.command.cursor).to.deep.equal({});\n        expect(aggregateOperation.command['$db']).to.equal('admin');\n        client.close(done);\n      });\n    }\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should fail when executing simple aggregation pipeline using arguments not an array","suites":["Aggregation"],"updatePoint":{"line":115,"column":89,"index":3185},"line":115,"code":"  it('should fail when executing simple aggregation pipeline using arguments not an array', function (done) {\n    const client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n      databaseName = this.configuration.db;\n    const db = client.db(databaseName);\n    // Some docs for insertion\n    const docs = [{\n      title: 'this is my title',\n      author: 'bob',\n      posted: new Date(),\n      pageViews: 5,\n      tags: ['fun', 'good', 'fun'],\n      other: {\n        foo: 5\n      },\n      comments: [{\n        author: 'joe',\n        text: 'this is cool'\n      }, {\n        author: 'sam',\n        text: 'this is bad'\n      }]\n    }];\n\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyExecuteSimpleAggregationPipelineUsingArguments');\n    // Insert the docs\n    collection.insertMany(docs, {\n      writeConcern: {\n        w: 1\n      }\n    }, function (err, result) {\n      expect(result).to.exist;\n      expect(err).to.not.exist;\n\n      // Execute aggregate, notice the pipeline is expressed as function call parameters\n      // instead of an Array.\n      const cursor = collection.aggregate([{\n        $project: {\n          author: 1,\n          tags: 1\n        }\n      }, {\n        $unwind: '$tags'\n      }, {\n        $group: {\n          _id: {\n            tags: '$tags'\n          },\n          authors: {\n            $addToSet: '$author'\n          }\n        }\n      }, {\n        $sort: {\n          _id: -1\n        }\n      }]);\n      cursor.toArray(function (err, result) {\n        expect(err).to.not.exist;\n        expect(result[0]._id.tags).to.equal('good');\n        expect(result[0].authors).to.eql(['bob']);\n        expect(result[1]._id.tags).to.equal('fun');\n        expect(result[1].authors).to.eql(['bob']);\n        client.close(done);\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should fail when executing simple aggregation pipeline using arguments using single object","suites":["Aggregation"],"updatePoint":{"line":186,"column":96,"index":5032},"line":186,"code":"  it('should fail when executing simple aggregation pipeline using arguments using single object', function (done) {\n    const client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n      databaseName = this.configuration.db;\n    const db = client.db(databaseName);\n    // Some docs for insertion\n    const docs = [{\n      title: 'this is my title',\n      author: 'bob',\n      posted: new Date(),\n      pageViews: 5,\n      tags: ['fun', 'good', 'fun'],\n      other: {\n        foo: 5\n      },\n      comments: [{\n        author: 'joe',\n        text: 'this is cool'\n      }, {\n        author: 'sam',\n        text: 'this is bad'\n      }]\n    }];\n\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyExecuteSimpleAggregationPipelineUsingArguments');\n    // Insert the docs\n    collection.insertMany(docs, {\n      writeConcern: {\n        w: 1\n      }\n    }, function (err, result) {\n      expect(result).to.exist;\n      expect(err).to.not.exist;\n\n      // Execute aggregate, notice the pipeline is expressed as function call parameters\n      // instead of an Array.\n      const cursor = collection.aggregate([{\n        $project: {\n          author: 1,\n          tags: 1\n        }\n      }, {\n        $unwind: '$tags'\n      }, {\n        $group: {\n          _id: {\n            tags: '$tags'\n          },\n          authors: {\n            $addToSet: '$author'\n          }\n        }\n      }, {\n        $sort: {\n          _id: -1\n        }\n      }]);\n      cursor.toArray(function (err, result) {\n        expect(err).to.not.exist;\n        expect(result[0]._id.tags).to.equal('good');\n        expect(result[0].authors).to.eql(['bob']);\n        expect(result[1]._id.tags).to.equal('fun');\n        expect(result[1].authors).to.eql(['bob']);\n        client.close(done);\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should correctly return and iterate over all the cursor results","suites":["Aggregation"],"updatePoint":{"line":257,"column":69,"index":6852},"line":257,"code":"  it('should correctly return and iterate over all the cursor results', function (done) {\n    const client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n      databaseName = this.configuration.db;\n    const db = client.db(databaseName);\n    // Some docs for insertion\n    const docs = [{\n      title: 'this is my title',\n      author: 'bob',\n      posted: new Date(),\n      pageViews: 5,\n      tags: ['fun', 'good', 'fun'],\n      other: {\n        foo: 5\n      },\n      comments: [{\n        author: 'joe',\n        text: 'this is cool'\n      }, {\n        author: 'sam',\n        text: 'this is bad'\n      }]\n    }];\n\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyDoAggWithCursorGet');\n    // Insert the docs\n    collection.insertMany(docs, {\n      writeConcern: {\n        w: 1\n      }\n    }, function (err, result) {\n      expect(err).to.not.exist;\n      expect(result).to.exist;\n\n      // Execute aggregate, notice the pipeline is expressed as an Array\n      const cursor = collection.aggregate([{\n        $project: {\n          author: 1,\n          tags: 1\n        }\n      }, {\n        $unwind: '$tags'\n      }, {\n        $group: {\n          _id: {\n            tags: '$tags'\n          },\n          authors: {\n            $addToSet: '$author'\n          }\n        }\n      }]);\n\n      // Iterate over all the items in the cursor\n      cursor.toArray(function (err, result) {\n        expect(err).to.not.exist;\n        expect(result).to.exist;\n        client.close(done);\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should correctly return a cursor and call explain","suites":["Aggregation"],"updatePoint":{"line":322,"column":55,"index":8405},"line":322,"code":"  it('should correctly return a cursor and call explain', function (done) {\n    const client = this.configuration.newClient({\n        maxPoolSize: 1\n      }),\n      databaseName = this.configuration.db;\n    const db = client.db(databaseName);\n    // Some docs for insertion\n    const docs = [{\n      title: 'this is my title',\n      author: 'bob',\n      posted: new Date(),\n      pageViews: 5,\n      tags: ['fun', 'good', 'fun'],\n      other: {\n        foo: 5\n      },\n      comments: [{\n        author: 'joe',\n        text: 'this is cool'\n      }, {\n        author: 'sam',\n        text: 'this is bad'\n      }]\n    }];\n\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyDoAggWithCursorGet');\n    // Insert the docs\n    collection.insertMany(docs, {\n      writeConcern: {\n        w: 1\n      }\n    }, function (err, result) {\n      expect(result).to.exist;\n      expect(err).to.not.exist;\n\n      // Execute aggregate, notice the pipeline is expressed as an Array\n      const cursor = collection.aggregate([{\n        $project: {\n          author: 1,\n          tags: 1\n        }\n      }, {\n        $unwind: '$tags'\n      }, {\n        $group: {\n          _id: {\n            tags: '$tags'\n          },\n          authors: {\n            $addToSet: '$author'\n          }\n        }\n      }], {\n        cursor: {\n          batchSize: 100\n        }\n      });\n\n      // Iterate over all the items in the cursor\n      cursor.explain(function (err, result) {\n        expect(err).to.not.exist;\n        expect(result.stages).to.have.lengthOf.at.least(1);\n        expect(result.stages[0]).to.have.property('$cursor');\n        client.close(done);\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should correctly return a cursor with batchSize 1 and call next","suites":["Aggregation"],"updatePoint":{"line":390,"column":69,"index":10101},"line":390,"code":"  it('should correctly return a cursor with batchSize 1 and call next', function (done) {\n    const client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n      databaseName = this.configuration.db;\n    this.defer(() => client.close());\n    const db = client.db(databaseName);\n    // Some docs for insertion\n    const docs = [{\n      title: 'this is my title',\n      author: 'bob',\n      posted: new Date(),\n      pageViews: 5,\n      tags: ['fun', 'good', 'fun'],\n      other: {\n        foo: 5\n      },\n      comments: [{\n        author: 'joe',\n        text: 'this is cool'\n      }, {\n        author: 'sam',\n        text: 'this is bad'\n      }]\n    }];\n\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyDoAggWithCursorGet');\n    // Insert the docs\n    collection.insertMany(docs, {\n      writeConcern: {\n        w: 1\n      }\n    }, (err, result) => {\n      expect(result).to.exist;\n      expect(err).to.not.exist;\n\n      // Execute aggregate, notice the pipeline is expressed as an Array\n      const cursor = collection.aggregate([{\n        $project: {\n          author: 1,\n          tags: 1\n        }\n      }, {\n        $unwind: '$tags'\n      }, {\n        $group: {\n          _id: {\n            tags: '$tags'\n          },\n          authors: {\n            $addToSet: '$author'\n          }\n        }\n      }, {\n        $sort: {\n          _id: -1\n        }\n      }], {\n        cursor: {\n          batchSize: 1\n        }\n      });\n      this.defer(() => cursor.close());\n\n      // Iterate over all the items in the cursor\n      cursor.next((err, result) => {\n        expect(err).to.not.exist;\n        expect(result._id.tags).to.equal('good');\n        expect(result.authors).to.eql(['bob']);\n        done();\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should correctly write the results out to a new collection","suites":["Aggregation"],"updatePoint":{"line":466,"column":64,"index":11897},"line":466,"code":"  it('should correctly write the results out to a new collection', function (done) {\n    const client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n      databaseName = this.configuration.db;\n    const db = client.db(databaseName);\n    // Some docs for insertion\n    const docs = [{\n      title: 'this is my title',\n      author: 'bob',\n      posted: new Date(),\n      pageViews: 5,\n      tags: ['fun', 'good', 'fun'],\n      other: {\n        foo: 5\n      },\n      comments: [{\n        author: 'joe',\n        text: 'this is cool'\n      }, {\n        author: 'sam',\n        text: 'this is bad'\n      }]\n    }];\n\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyDoAggWithCursorGet');\n    // Insert the docs\n    collection.insertMany(docs, {\n      writeConcern: {\n        w: 1\n      }\n    }, function (err, result) {\n      expect(result).to.exist;\n      expect(err).to.not.exist;\n\n      // Execute aggregate, notice the pipeline is expressed as an Array\n      const cursor = collection.aggregate([{\n        $project: {\n          author: 1,\n          tags: 1\n        }\n      }, {\n        $unwind: '$tags'\n      }, {\n        $group: {\n          _id: {\n            tags: '$tags'\n          },\n          authors: {\n            $addToSet: '$author'\n          }\n        }\n      }], {\n        out: 'testingOutCollectionForAggregation'\n      });\n      cursor.toArray(function (err, results) {\n        expect(err).to.not.exist;\n        expect(results).to.be.empty;\n        client.close(done);\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should correctly use allowDiskUse when performing an aggregation","suites":["Aggregation"],"updatePoint":{"line":531,"column":70,"index":13480},"line":531,"code":"  it('should correctly use allowDiskUse when performing an aggregation', function (done) {\n    const client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n      databaseName = this.configuration.db;\n    const db = client.db(databaseName);\n    // Some docs for insertion\n    const docs = [{\n      title: 'this is my title',\n      author: 'bob',\n      posted: new Date(),\n      pageViews: 5,\n      tags: ['fun', 'good', 'fun'],\n      other: {\n        foo: 5\n      },\n      comments: [{\n        author: 'joe',\n        text: 'this is cool'\n      }, {\n        author: 'sam',\n        text: 'this is bad'\n      }]\n    }];\n\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyDoAggWithCursorGet');\n    // Insert the docs\n    collection.insertMany(docs, {\n      writeConcern: {\n        w: 1\n      }\n    }, function (err, result) {\n      expect(result).to.exist;\n      expect(err).to.not.exist;\n\n      // Execute aggregate, notice the pipeline is expressed as an Array\n      const cursor = collection.aggregate([{\n        $project: {\n          author: 1,\n          tags: 1\n        }\n      }, {\n        $unwind: '$tags'\n      }, {\n        $group: {\n          _id: {\n            tags: '$tags'\n          },\n          authors: {\n            $addToSet: '$author'\n          }\n        }\n      }, {\n        $sort: {\n          _id: -1\n        }\n      }], {\n        allowDiskUse: true\n      });\n      cursor.toArray(function (err, results) {\n        expect(err).to.not.exist;\n        expect(results[0]._id.tags).to.equal('good');\n        expect(results[0].authors).to.eql(['bob']);\n        expect(results[1]._id.tags).to.equal('fun');\n        expect(results[1].authors).to.eql(['bob']);\n        client.close(done);\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should perform a simple group aggregation","suites":["Aggregation"],"updatePoint":{"line":603,"column":47,"index":15247},"line":603,"code":"  it('should perform a simple group aggregation', function (done) {\n    const databaseName = this.configuration.db;\n    const client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    const db = client.db(databaseName);\n    // Create a collection\n    const col = db.collection('shouldPerformSimpleGroupAggregation');\n    col.deleteMany({}, function (err) {\n      expect(err).to.not.exist;\n\n      // Insert a single document\n      col.insertMany([{\n        a: 1\n      }, {\n        a: 1\n      }, {\n        a: 1\n      }], function (err, r) {\n        expect(err).to.not.exist;\n        expect(r).property('insertedCount').to.equal(3);\n\n        // Get first two documents that match the query\n        col.aggregate([{\n          $match: {}\n        }, {\n          $group: {\n            _id: '$a',\n            total: {\n              $sum: '$a'\n            }\n          }\n        }]).toArray(function (err, docs) {\n          expect(err).to.not.exist;\n          expect(docs[0].total).to.equal(3);\n          client.close(done);\n        });\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should correctly perform an aggregation using a collection name with dot in it","suites":["Aggregation"],"updatePoint":{"line":643,"column":84,"index":16388},"line":643,"code":"  it('should correctly perform an aggregation using a collection name with dot in it', function (done) {\n    const databaseName = this.configuration.db;\n    const client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    const db = client.db(databaseName);\n    const col = db.collection('te.st');\n    let count = 0;\n    col.insertMany([{\n      a: 1\n    }, {\n      a: 1\n    }, {\n      a: 1\n    }], function (err, r) {\n      expect(err).to.not.exist;\n      expect(r).property('insertedCount').to.equal(3);\n      const cursor = col.aggregate([{\n        $project: {\n          a: 1\n        }\n      }]);\n      cursor.toArray(function (err, docs) {\n        expect(err).to.not.exist;\n        expect(docs.length).to.be.greaterThan(0);\n\n        //Using cursor - KO\n        col.aggregate([{\n          $project: {\n            a: 1\n          }\n        }], {\n          cursor: {\n            batchSize: 10000\n          }\n        }).forEach(function () {\n          count = count + 1;\n        }, function (err) {\n          expect(err).to.not.exist;\n          expect(count).to.be.greaterThan(0);\n          client.close(done);\n        });\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should fail aggregation due to illegal cursor option and streams","suites":["Aggregation"],"updatePoint":{"line":688,"column":70,"index":17571},"line":688,"code":"  it('should fail aggregation due to illegal cursor option and streams', async function () {\n    const db = client.db();\n    // Some docs for insertion\n    const docs = [{\n      title: 'this is my title',\n      author: 'bob',\n      posted: new Date(),\n      pageViews: 5,\n      tags: ['fun', 'good', 'fun'],\n      other: {\n        foo: 5\n      },\n      comments: [{\n        author: 'joe',\n        text: 'this is cool'\n      }, {\n        author: 'sam',\n        text: 'this is bad'\n      }]\n    }];\n\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyDoAggWithCursorGetStream');\n    // Insert the docs\n    const result = await collection.insertMany(docs, {\n      writeConcern: {\n        w: 1\n      }\n    });\n    expect(result).to.exist;\n\n    // Execute aggregate, notice the pipeline is expressed as an Array\n    const cursor = collection.aggregate([{\n      $project: {\n        author: 1,\n        tags: 1\n      }\n    }, {\n      $unwind: '$tags'\n    }, {\n      $group: {\n        _id: {\n          tags: '$tags'\n        },\n        authors: {\n          $addToSet: '$author'\n        }\n      }\n    }], {\n      cursor: 1\n    });\n    const error = await cursor.next().catch(error => error);\n    expect(error).to.be.instanceOf(MongoInvalidArgumentError);\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should fail if you try to use explain flag with { readConcern: { level: 'local' }, writeConcern: { j: true } }","suites":["Aggregation"],"updatePoint":{"line":742,"column":116,"index":18896},"line":742,"code":"  it(`should fail if you try to use explain flag with { readConcern: { level: 'local' }, writeConcern: { j: true } }`, async function () {\n    const db = client.db();\n    const collection = db.collection('foo');\n    Object.assign(collection.s, {\n      writeConcern: {\n        j: true\n      }\n    });\n    const error = await collection.aggregate([{\n      $project: {\n        _id: 0\n      }\n    }, {\n      $out: 'bar'\n    }], {\n      explain: true\n    }).toArray().catch(error => error);\n    expect(error).to.be.instanceOf(MongoInvalidArgumentError);\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should fail if you try to use explain flag with { writeConcern: { j: true } }","suites":["Aggregation"],"updatePoint":{"line":761,"column":83,"index":19418},"line":761,"code":"  it('should fail if you try to use explain flag with { writeConcern: { j: true } }', async function () {\n    const db = client.db();\n    const collection = db.collection('foo');\n    Object.assign(collection.s, {\n      writeConcern: {\n        j: true\n      }\n    });\n    const error = await collection.aggregate([{\n      $project: {\n        _id: 0\n      }\n    }, {\n      $out: 'bar'\n    }], {\n      explain: true\n    }).toArray().catch(error => error);\n    expect(error).to.be.instanceOf(MongoInvalidArgumentError);\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should ensure MaxTimeMS is correctly passed down into command execution when using a cursor","suites":["Aggregation"],"updatePoint":{"line":780,"column":97,"index":19954},"line":780,"code":"  it('should ensure MaxTimeMS is correctly passed down into command execution when using a cursor', function (done) {\n    const client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n      databaseName = this.configuration.db;\n    this.defer(() => client.close());\n    const db = client.db(databaseName);\n    const docs = [{\n      title: 'this is my title',\n      author: 'bob',\n      posted: new Date(),\n      pageViews: 5,\n      tags: ['fun', 'good', 'fun'],\n      other: {\n        foo: 5\n      },\n      comments: [{\n        author: 'joe',\n        text: 'this is cool'\n      }, {\n        author: 'sam',\n        text: 'this is bad'\n      }]\n    }];\n\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyDoAggWithCursorMaxTimeMSSet');\n    // Insert the docs\n    collection.insertMany(docs, {\n      writeConcern: {\n        w: 1\n      }\n    }, (err, result) => {\n      expect(result).to.exist;\n      expect(err).to.not.exist;\n\n      // Execute aggregate, notice the pipeline is expressed as an Array\n      const cursor = collection.aggregate([{\n        $project: {\n          author: 1,\n          tags: 1\n        }\n      }, {\n        $unwind: '$tags'\n      }, {\n        $group: {\n          _id: {\n            tags: '$tags'\n          },\n          authors: {\n            $addToSet: '$author'\n          }\n        }\n      }, {\n        $sort: {\n          _id: -1\n        }\n      }], {\n        cursor: {\n          batchSize: 1\n        },\n        maxTimeMS: 1000\n      });\n      this.defer(() => cursor.close());\n\n      // Override the db.command to validate the correct command\n      // is executed\n      const command = db.command.bind(db);\n      // Validate the command\n      db.command = function (...args) {\n        const c = args[0];\n        expect(err).to.not.exist;\n        expect(c.maxTimeMS).to.equal(1000);\n\n        // Apply to existing command\n        command(...args);\n      };\n\n      // Iterate over all the items in the cursor\n      cursor.next((err, result) => {\n        expect(err).to.not.exist;\n        expect(result._id.tags).to.equal('good');\n        expect(result.authors).to.eql(['bob']);\n\n        // Validate the command\n        db.command = function (...args) {\n          const c = args[0];\n          expect(err).to.not.exist;\n          expect(c.maxTimeMS).to.equal(1000);\n\n          // Apply to existing command\n          command(...args);\n        };\n\n        // Execute aggregate, notice the pipeline is expressed as an Array\n        const secondCursor = collection.aggregate([{\n          $project: {\n            author: 1,\n            tags: 1\n          }\n        }, {\n          $unwind: '$tags'\n        }, {\n          $group: {\n            _id: {\n              tags: '$tags'\n            },\n            authors: {\n              $addToSet: '$author'\n            }\n          }\n        }], {\n          maxTimeMS: 1000\n        });\n        this.defer(() => secondCursor.close());\n        expect(secondCursor).to.exist;\n\n        // Return the command\n        db.command = command;\n        done();\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should pass a comment down via the aggregation command","suites":["Aggregation"],"updatePoint":{"line":905,"column":60,"index":23017},"line":905,"code":"  it('should pass a comment down via the aggregation command', async function () {\n    const client = this.configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    const databaseName = this.configuration.db;\n    const comment = 'Darmok and Jalad at Tanagra';\n    const db = client.db(databaseName);\n    const collection = db.collection('testingPassingDownTheAggregationCommand');\n    const command = db.command.bind(db);\n    db.command = function (...args) {\n      const c = args[0];\n      expect(c).to.be.an('object');\n      expect(c.comment).to.be.a('string').and.to.equal('comment');\n      command(...args);\n    };\n    const cursor = collection.aggregate([{\n      $project: {\n        _id: 1\n      }\n    }], {\n      comment\n    });\n    expect(cursor).to.not.be.null;\n    await client.close();\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should correctly handle ISODate date matches in aggregation framework","suites":["Aggregation"],"updatePoint":{"line":932,"column":75,"index":23855},"line":932,"code":"  it('should correctly handle ISODate date matches in aggregation framework', function (done) {\n    const databaseName = this.configuration.db;\n    const client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    const db = client.db(databaseName);\n    const date1 = new Date();\n    date1.setHours(date1.getHours() - 1);\n\n    // Some docs for insertion\n    const docs = [{\n      a: date1,\n      b: 1\n    }, {\n      a: new Date(),\n      b: 2\n    }];\n\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyQueryUsingISODate');\n    // Insert the docs\n    collection.insertMany(docs, {\n      writeConcern: {\n        w: 1\n      }\n    }, function (err, result) {\n      expect(result).to.exist;\n      expect(err).to.not.exist;\n\n      // Execute aggregate, notice the pipeline is expressed as an Array\n      const cursor = collection.aggregate([{\n        $match: {\n          a: new Date(date1.toISOString())\n        }\n      }]);\n\n      // Iterate over all the items in the cursor\n      cursor.next(function (err, result) {\n        expect(err).to.not.exist;\n        expect(result.b).to.equal(1);\n        client.close(done);\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should correctly exercise hasNext function on aggregation cursor","suites":["Aggregation"],"updatePoint":{"line":976,"column":70,"index":25067},"line":976,"code":"  it('should correctly exercise hasNext function on aggregation cursor', function (done) {\n    const databaseName = this.configuration.db;\n    const client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    const db = client.db(databaseName);\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyQueryUsingISODate3');\n    // Insert the docs\n    collection.insertMany([{\n      a: 1\n    }, {\n      b: 1\n    }], {\n      writeConcern: {\n        w: 1\n      }\n    }, function (err, result) {\n      expect(result).to.exist;\n      expect(err).to.not.exist;\n\n      // Execute aggregate, notice the pipeline is expressed as an Array\n      const cursor = collection.aggregate([{\n        $match: {}\n      }]);\n\n      // Iterate over all the items in the cursor\n      cursor.hasNext(function (err, result) {\n        expect(err).to.not.exist;\n        expect(result).to.equal(true);\n        client.close(done);\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should not send a batchSize for aggregations with an out stage","suites":["Aggregation"],"updatePoint":{"line":1010,"column":68,"index":26065},"line":1010,"code":"  it('should not send a batchSize for aggregations with an out stage', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    async test() {\n      const databaseName = this.configuration.db;\n      const client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const events = [];\n      client.on('commandStarted', filterForCommands(['aggregate'], events));\n      const coll1 = client.db(databaseName).collection('coll1');\n      const coll2 = client.db(databaseName).collection('coll2');\n      await Promise.all([coll1.deleteMany({}), coll2.deleteMany({})]).then(() => {\n        const docs = Array.from({\n          length: 10\n        }).map(() => ({\n          a: 1\n        }));\n        return Promise.all([coll1.insertMany(docs), client.db(databaseName).createCollection('coll2').catch(() => null)]);\n      }).then(() => {\n        return Promise.all([coll1.aggregate([{\n          $out: 'coll2'\n        }]), coll1.aggregate([{\n          $out: 'coll2'\n        }], {\n          batchSize: 0\n        }), coll1.aggregate([{\n          $out: 'coll2'\n        }], {\n          batchSize: 1\n        }), coll1.aggregate([{\n          $out: 'coll2'\n        }], {\n          batchSize: 30\n        }), coll1.aggregate([{\n          $match: {\n            a: 1\n          }\n        }, {\n          $out: 'coll2'\n        }]), coll1.aggregate([{\n          $match: {\n            a: 1\n          }\n        }, {\n          $out: 'coll2'\n        }], {\n          batchSize: 0\n        }), coll1.aggregate([{\n          $match: {\n            a: 1\n          }\n        }, {\n          $out: 'coll2'\n        }], {\n          batchSize: 1\n        }), coll1.aggregate([{\n          $match: {\n            a: 1\n          }\n        }, {\n          $out: 'coll2'\n        }], {\n          batchSize: 30\n        })].map(cursor => cursor.toArray()));\n      }).then(() => {\n        expect(events).to.be.an('array').with.a.lengthOf(8);\n        events.forEach(event => {\n          expect(event).to.have.property('commandName', 'aggregate');\n          expect(event).to.have.property('command').that.has.property('cursor').that.does.not.have.property('batchSize');\n        });\n      }).finally(() => client.close());\n    }\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should use the same session for every operation","suites":["Bulk executeOperation"],"updatePoint":{"line":12,"column":53,"index":313},"line":12,"code":"  it('should use the same session for every operation', async () => {\n    const collection = client.db().collection('bulk_execute_operation');\n\n    // TODO(NODE-4263): Legacy bulk operations require connecting invocation\n    await client.db().command({\n      ping: 1\n    });\n    const batch = collection.initializeOrderedBulkOp();\n    const events = [];\n    client.on('commandStarted', ev => events.push(ev));\n    batch.insert({\n      a: 1\n    });\n    batch.find({\n      a: 1\n    }).update({\n      $set: {\n        b: 1\n      }\n    });\n    batch.find({\n      b: 1\n    }).deleteOne();\n    await batch.execute();\n    expect(events).to.have.lengthOf(3);\n    const sessions = events.map(ev => ev.command.lsid.id.toString('hex'));\n    expect(new Set(sessions)).to.have.property('size', 1);\n  });","file":"integration/crud/bulk_execute_operation.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute findOne method using crud api","suites":["CRUD API"],"updatePoint":{"line":28,"column":60,"index":1173},"line":28,"code":"  it('should correctly execute findOne method using crud api', async function () {\n    const db = client.db();\n    const collection = db.collection('t');\n    await collection.insertOne({\n      findOneTest: 1\n    });\n    const findOneResult = await collection.findOne({\n      findOneTest: 1\n    });\n    expect(findOneResult).to.have.property('findOneTest', 1);\n    expect(findOneResult).to.have.property('_id').that.is.instanceOf(ObjectId);\n    const findNoneResult = await collection.findOne({\n      findOneTest: 2\n    });\n    expect(findNoneResult).to.be.null;\n    await collection.drop();\n    await client.close();\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute find method using crud api","suites":["CRUD API"],"updatePoint":{"line":46,"column":57,"index":1793},"line":46,"code":"  it('should correctly execute find method using crud api', function (done) {\n    const db = client.db();\n    db.collection('t').insertMany([{\n      a: 1\n    }, {\n      a: 1\n    }, {\n      a: 1\n    }, {\n      a: 1\n    }], function (err) {\n      expect(err).to.not.exist;\n\n      //\n      // Cursor\n      // --------------------------------------------------\n      const makeCursor = () => {\n        // Possible methods on the the cursor instance\n        return db.collection('t').find({}).filter({\n          a: 1\n        }).addCursorFlag('noCursorTimeout', true).addQueryModifier('$comment', 'some comment').batchSize(2).comment('some comment 2').limit(2).maxTimeMS(50).project({\n          a: 1\n        }).skip(0).sort({\n          a: 1\n        });\n      };\n\n      //\n      // Exercise count method\n      // -------------------------------------------------\n      const countMethod = function () {\n        // Execute the different methods supported by the cursor\n        const cursor = makeCursor();\n        cursor.count(function (err, count) {\n          expect(err).to.not.exist;\n          test.equal(2, count);\n          eachMethod();\n        });\n      };\n\n      //\n      // Exercise legacy method each\n      // -------------------------------------------------\n      const eachMethod = function () {\n        let count = 0;\n        const cursor = makeCursor();\n        cursor.forEach(() => {\n          count = count + 1;\n        }, err => {\n          expect(err).to.not.exist;\n          test.equal(2, count);\n          toArrayMethod();\n        });\n      };\n\n      //\n      // Exercise toArray\n      // -------------------------------------------------\n      const toArrayMethod = function () {\n        const cursor = makeCursor();\n        cursor.toArray(function (err, docs) {\n          expect(err).to.not.exist;\n          test.equal(2, docs.length);\n          nextMethod();\n        });\n      };\n\n      //\n      // Exercise next method\n      // -------------------------------------------------\n      const nextMethod = function () {\n        const cursor = makeCursor();\n        cursor.next(function (err, doc) {\n          expect(err).to.not.exist;\n          test.ok(doc != null);\n          cursor.next(function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc != null);\n            cursor.next(function (err, doc) {\n              expect(err).to.not.exist;\n              expect(doc).to.not.exist;\n              streamMethod();\n            });\n          });\n        });\n      };\n\n      //\n      // Exercise stream\n      // -------------------------------------------------\n      const streamMethod = function () {\n        let count = 0;\n        const cursor = makeCursor();\n        const stream = cursor.stream();\n        stream.on('data', function () {\n          count = count + 1;\n        });\n        cursor.once('close', function () {\n          test.equal(2, count);\n          explainMethod();\n        });\n      };\n\n      //\n      // Explain method\n      // -------------------------------------------------\n      const explainMethod = function () {\n        const cursor = makeCursor();\n        cursor.explain(function (err, result) {\n          expect(err).to.not.exist;\n          test.ok(result != null);\n          client.close(done);\n        });\n      };\n\n      // Execute all the methods\n      countMethod();\n    });\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute aggregation method using crud api","suites":["CRUD API"],"updatePoint":{"line":165,"column":64,"index":5154},"line":165,"code":"  it('should correctly execute aggregation method using crud api', function (done) {\n    const db = client.db();\n    db.collection('t1').insertMany([{\n      a: 1\n    }, {\n      a: 1\n    }, {\n      a: 2\n    }, {\n      a: 1\n    }], function (err) {\n      expect(err).to.not.exist;\n      const testAllMethods = function () {\n        // Get the cursor\n        const cursor = db.collection('t1').aggregate([{\n          $match: {}\n        }], {\n          allowDiskUse: true,\n          batchSize: 2,\n          maxTimeMS: 50\n        });\n\n        // Exercise all the options\n        cursor.geoNear({\n          geo: 1\n        }).group({\n          group: 1\n        }).limit(10).match({\n          match: 1\n        }).maxTimeMS(10).out('collection').project({\n          project: 1\n        }).redact({\n          redact: 1\n        }).skip(1).sort({\n          sort: 1\n        }).batchSize(10).unwind('name');\n\n        // Execute the command with all steps defined\n        // will fail\n        cursor.toArray(function (err) {\n          test.ok(err != null);\n          testToArray();\n        });\n      };\n\n      //\n      // Exercise toArray\n      // -------------------------------------------------\n      const testToArray = function () {\n        const cursor = db.collection('t1').aggregate();\n        cursor.match({\n          a: 1\n        });\n        cursor.toArray(function (err, docs) {\n          expect(err).to.not.exist;\n          test.equal(3, docs.length);\n          testNext();\n        });\n      };\n\n      //\n      // Exercise next\n      // -------------------------------------------------\n      const testNext = function () {\n        const cursor = db.collection('t1').aggregate();\n        cursor.match({\n          a: 1\n        });\n        cursor.next(function (err) {\n          expect(err).to.not.exist;\n          testEach();\n        });\n      };\n\n      //\n      // Exercise each\n      // -------------------------------------------------\n      const testEach = function () {\n        let count = 0;\n        const cursor = db.collection('t1').aggregate();\n        cursor.match({\n          a: 1\n        });\n        cursor.forEach(() => {\n          count = count + 1;\n        }, err => {\n          expect(err).to.not.exist;\n          test.equal(3, count);\n          testStream();\n        });\n      };\n\n      //\n      // Exercise stream\n      // -------------------------------------------------\n      const testStream = function () {\n        const cursor = db.collection('t1').aggregate();\n        let count = 0;\n        cursor.match({\n          a: 1\n        });\n        const stream = cursor.stream();\n        stream.on('data', function () {\n          count = count + 1;\n        });\n        stream.once('end', function () {\n          test.equal(3, count);\n          testExplain();\n        });\n      };\n\n      //\n      // Explain method\n      // -------------------------------------------------\n      const testExplain = function () {\n        const cursor = db.collection('t1').aggregate();\n        cursor.explain(function (err, result) {\n          expect(err).to.not.exist;\n          test.ok(result != null);\n          client.close(done);\n        });\n      };\n      testAllMethods();\n    });\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute insert methods using crud api","suites":["CRUD API"],"updatePoint":{"line":290,"column":60,"index":8342},"line":290,"code":"  it('should correctly execute insert methods using crud api', function (done) {\n    client.connect(function (err, client) {\n      const db = client.db();\n\n      //\n      // Legacy insert method\n      // -------------------------------------------------\n      const legacyInsert = function () {\n        db.collection('t2_1').insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }], function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedCount').to.equal(2);\n          bulkAPIInsert();\n        });\n      };\n\n      //\n      // Bulk api insert method\n      // -------------------------------------------------\n      const bulkAPIInsert = function () {\n        const bulk = db.collection('t2_2').initializeOrderedBulkOp();\n        bulk.insert({\n          a: 1\n        });\n        bulk.insert({\n          a: 1\n        });\n        bulk.execute(function (err) {\n          expect(err).to.not.exist;\n          insertOne();\n        });\n      };\n\n      //\n      // Insert one method\n      // -------------------------------------------------\n      const insertOne = function () {\n        db.collection('t2_3').insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedId').to.exist;\n          insertMany();\n        });\n      };\n\n      //\n      // Insert many method\n      // -------------------------------------------------\n      const insertMany = function () {\n        const docs = [{\n          a: 1\n        }, {\n          a: 1\n        }];\n        db.collection('t2_4').insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedCount').to.equal(2);\n\n          // Ordered bulk unordered\n          bulkWriteUnOrdered();\n        });\n      };\n\n      //\n      // Bulk write method unordered\n      // -------------------------------------------------\n      const bulkWriteUnOrdered = function () {\n        db.collection('t2_5').insertMany([{\n          c: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedCount').to.equal(1);\n          db.collection('t2_5').bulkWrite([{\n            insertOne: {\n              document: {\n                a: 1\n              }\n            }\n          }, {\n            insertOne: {\n              document: {\n                g: 1\n              }\n            }\n          }, {\n            insertOne: {\n              document: {\n                g: 2\n              }\n            }\n          }, {\n            updateOne: {\n              filter: {\n                a: 2\n              },\n              update: {\n                $set: {\n                  a: 2\n                }\n              },\n              upsert: true\n            }\n          }, {\n            updateMany: {\n              filter: {\n                a: 2\n              },\n              update: {\n                $set: {\n                  a: 2\n                }\n              },\n              upsert: true\n            }\n          }, {\n            deleteOne: {\n              filter: {\n                c: 1\n              }\n            }\n          }, {\n            deleteMany: {\n              filter: {\n                c: 1\n              }\n            }\n          }], {\n            ordered: false,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            test.equal(3, r.nInserted);\n            test.equal(1, r.nUpserted);\n            test.equal(1, r.nRemoved);\n\n            // Crud fields\n            test.equal(3, r.insertedCount);\n            test.equal(3, Object.keys(r.insertedIds).length);\n            test.equal(1, r.matchedCount);\n            test.equal(1, r.deletedCount);\n            test.equal(1, r.upsertedCount);\n            test.equal(1, Object.keys(r.upsertedIds).length);\n\n            // Ordered bulk operation\n            bulkWriteUnOrderedSpec();\n          });\n        });\n      };\n\n      //\n      // Bulk write method unordered\n      // -------------------------------------------------\n      const bulkWriteUnOrderedSpec = function () {\n        db.collection('t2_6').insertMany([{\n          c: 1\n        }, {\n          c: 2\n        }, {\n          c: 3\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedCount').to.equal(3);\n          db.collection('t2_6').bulkWrite([{\n            insertOne: {\n              document: {\n                a: 1\n              }\n            }\n          }, {\n            updateOne: {\n              filter: {\n                a: 2\n              },\n              update: {\n                $set: {\n                  a: 2\n                }\n              },\n              upsert: true\n            }\n          }, {\n            updateMany: {\n              filter: {\n                a: 3\n              },\n              update: {\n                $set: {\n                  a: 3\n                }\n              },\n              upsert: true\n            }\n          }, {\n            deleteOne: {\n              filter: {\n                c: 1\n              }\n            }\n          }, {\n            deleteMany: {\n              filter: {\n                c: 2\n              }\n            }\n          }, {\n            replaceOne: {\n              filter: {\n                c: 3\n              },\n              replacement: {\n                c: 4\n              },\n              upsert: true\n            }\n          }], {\n            ordered: false,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            test.equal(1, r.nInserted);\n            test.equal(2, r.nUpserted);\n            test.equal(2, r.nRemoved);\n\n            // Crud fields\n            test.equal(1, r.insertedCount);\n            test.equal(1, Object.keys(r.insertedIds).length);\n            test.equal(1, r.matchedCount);\n            test.equal(2, r.deletedCount);\n            test.equal(2, r.upsertedCount);\n            test.equal(2, Object.keys(r.upsertedIds).length);\n\n            // Ordered bulk operation\n            bulkWriteOrdered();\n          });\n        });\n      };\n\n      //\n      // Bulk write method ordered\n      // -------------------------------------------------\n      const bulkWriteOrdered = function () {\n        db.collection('t2_7').insertMany([{\n          c: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedCount').to.equal(1);\n          db.collection('t2_7').bulkWrite([{\n            insertOne: {\n              document: {\n                a: 1\n              }\n            }\n          }, {\n            insertOne: {\n              document: {\n                g: 1\n              }\n            }\n          }, {\n            insertOne: {\n              document: {\n                g: 2\n              }\n            }\n          }, {\n            updateOne: {\n              filter: {\n                a: 2\n              },\n              update: {\n                $set: {\n                  a: 2\n                }\n              },\n              upsert: true\n            }\n          }, {\n            updateMany: {\n              filter: {\n                a: 2\n              },\n              update: {\n                $set: {\n                  a: 2\n                }\n              },\n              upsert: true\n            }\n          }, {\n            deleteOne: {\n              filter: {\n                c: 1\n              }\n            }\n          }, {\n            deleteMany: {\n              filter: {\n                c: 1\n              }\n            }\n          }], {\n            ordered: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            test.equal(3, r.nInserted);\n            test.equal(1, r.nUpserted);\n            test.equal(1, r.nRemoved);\n\n            // Crud fields\n            test.equal(3, r.insertedCount);\n            test.equal(3, Object.keys(r.insertedIds).length);\n            test.equal(1, r.matchedCount);\n            test.equal(1, r.deletedCount);\n            test.equal(1, r.upsertedCount);\n            test.equal(1, Object.keys(r.upsertedIds).length);\n            bulkWriteOrderedCrudSpec();\n          });\n        });\n      };\n\n      //\n      // Bulk write method ordered\n      // -------------------------------------------------\n      const bulkWriteOrderedCrudSpec = function () {\n        db.collection('t2_8').insertMany([{\n          c: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedCount').to.equal(1);\n          db.collection('t2_8').bulkWrite([{\n            insertOne: {\n              document: {\n                a: 1\n              }\n            }\n          }, {\n            updateOne: {\n              filter: {\n                a: 2\n              },\n              update: {\n                $set: {\n                  a: 2\n                }\n              },\n              upsert: true\n            }\n          }, {\n            updateMany: {\n              filter: {\n                a: 2\n              },\n              update: {\n                $set: {\n                  a: 2\n                }\n              },\n              upsert: true\n            }\n          }, {\n            deleteOne: {\n              filter: {\n                c: 1\n              }\n            }\n          }, {\n            deleteMany: {\n              filter: {\n                c: 1\n              }\n            }\n          }, {\n            replaceOne: {\n              filter: {\n                c: 3\n              },\n              replacement: {\n                c: 4\n              },\n              upsert: true\n            }\n          }], {\n            ordered: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            // expect(err).to.not.exist;\n            test.equal(1, r.nInserted);\n            test.equal(2, r.nUpserted);\n            test.equal(1, r.nRemoved);\n\n            // Crud fields\n            test.equal(1, r.insertedCount);\n            test.equal(1, Object.keys(r.insertedIds).length);\n            test.equal(1, r.matchedCount);\n            test.equal(1, r.deletedCount);\n            test.equal(2, r.upsertedCount);\n            test.equal(2, Object.keys(r.upsertedIds).length);\n            client.close(done);\n          });\n        });\n      };\n      legacyInsert();\n    });\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute update methods using crud api","suites":["CRUD API"],"updatePoint":{"line":731,"column":60,"index":19254},"line":731,"code":"  it('should correctly execute update methods using crud api', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      client.connect(function (err, client) {\n        const db = client.db();\n\n        //\n        // Legacy update method\n        // -------------------------------------------------\n        const legacyUpdate = function () {\n          db.collection('t3_1').update({\n            a: 1\n          }, {\n            $set: {\n              a: 2\n            }\n          }, {\n            upsert: true\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('upsertedCount').to.equal(1);\n            updateOne();\n          });\n        };\n\n        //\n        // Update one method\n        // -------------------------------------------------\n        const updateOne = function () {\n          db.collection('t3_2').insertMany([{\n            c: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(1);\n            db.collection('t3_2').updateOne({\n              a: 1\n            }, {\n              $set: {\n                a: 1\n              }\n            }, {\n              upsert: true\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              expect(r).property('upsertedCount').to.equal(1);\n              test.equal(0, r.matchedCount);\n              test.ok(r.upsertedId != null);\n              db.collection('t3_2').updateOne({\n                c: 1\n              }, {\n                $set: {\n                  a: 1\n                }\n              }, function (err, r) {\n                expect(err).to.not.exist;\n                expect(r).property('modifiedCount').to.equal(1);\n                test.equal(1, r.matchedCount);\n                test.ok(r.upsertedId == null);\n                replaceOne();\n              });\n            });\n          });\n        };\n\n        //\n        // Replace one method\n        // -------------------------------------------------\n        const replaceOne = function () {\n          db.collection('t3_3').replaceOne({\n            a: 1\n          }, {\n            a: 2\n          }, {\n            upsert: true\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('upsertedCount').to.equal(1);\n            test.equal(0, r.matchedCount);\n            test.ok(r.upsertedId != null);\n            db.collection('t3_3').replaceOne({\n              a: 2\n            }, {\n              a: 3\n            }, {\n              upsert: true\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              expect(r).property('modifiedCount').to.equal(1);\n              expect(r).property('upsertedCount').to.equal(0);\n              expect(r).property('matchedCount').to.equal(1);\n              updateMany();\n            });\n          });\n        };\n\n        //\n        // Update many method\n        // -------------------------------------------------\n        const updateMany = function () {\n          db.collection('t3_4').insertMany([{\n            a: 1\n          }, {\n            a: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(2);\n            db.collection('t3_4').updateMany({\n              a: 1\n            }, {\n              $set: {\n                a: 2\n              }\n            }, {\n              upsert: true,\n              writeConcern: {\n                w: 1\n              }\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              expect(r).property('modifiedCount').to.equal(2);\n              test.equal(2, r.matchedCount);\n              test.ok(r.upsertedId == null);\n              db.collection('t3_4').updateMany({\n                c: 1\n              }, {\n                $set: {\n                  d: 2\n                }\n              }, {\n                upsert: true,\n                writeConcern: {\n                  w: 1\n                }\n              }, function (err, r) {\n                expect(err).to.not.exist;\n                test.equal(0, r.matchedCount);\n                test.ok(r.upsertedId != null);\n                client.close(done);\n              });\n            });\n          });\n        };\n        legacyUpdate();\n      });\n    }\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute remove methods using crud api","suites":["CRUD API"],"updatePoint":{"line":891,"column":60,"index":23985},"line":891,"code":"  it('should correctly execute remove methods using crud api', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      client.connect(function (err, client) {\n        const db = client.db();\n\n        //\n        // Legacy update method\n        // -------------------------------------------------\n        const legacyRemove = function () {\n          db.collection('t4_1').insertMany([{\n            a: 1\n          }, {\n            a: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            test.equal(2, r.insertedCount);\n            db.collection('t4_1').remove({\n              a: 1\n            }, {\n              single: true\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              test.equal(1, r.deletedCount);\n              deleteOne();\n            });\n          });\n        };\n\n        //\n        // Update one method\n        // -------------------------------------------------\n        const deleteOne = function () {\n          db.collection('t4_2').insertMany([{\n            a: 1\n          }, {\n            a: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, (err, r) => {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(2);\n            db.collection('t4_2').deleteOne({\n              a: 1\n            }, (err, r) => {\n              expect(err).to.not.exist;\n              expect(r).property('deletedCount').to.equal(1);\n              deleteMany();\n            });\n          });\n        };\n\n        //\n        // Update many method\n        // -------------------------------------------------\n        const deleteMany = function () {\n          db.collection('t4_3').insertMany([{\n            a: 1\n          }, {\n            a: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, (err, r) => {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(2);\n            db.collection('t4_3').deleteMany({\n              a: 1\n            }, (err, r) => {\n              expect(err).to.not.exist;\n              expect(r).property('deletedCount').to.equal(2);\n              client.close(done);\n            });\n          });\n        };\n        legacyRemove();\n      });\n    }\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute findAndModify methods using crud api","suites":["CRUD API"],"updatePoint":{"line":983,"column":67,"index":26620},"line":983,"code":"  it('should correctly execute findAndModify methods using crud api', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      client.connect(function (err, client) {\n        const db = client.db();\n\n        //\n        // findOneAndRemove method\n        // -------------------------------------------------\n        const findOneAndRemove = function () {\n          db.collection('t5_1').insertMany([{\n            a: 1,\n            b: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(1);\n            db.collection('t5_1').findOneAndDelete({\n              a: 1\n            }, {\n              projection: {\n                b: 1\n              },\n              sort: {\n                a: 1\n              }\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              test.equal(1, r.lastErrorObject.n);\n              test.equal(1, r.value.b);\n              findOneAndReplace();\n            });\n          });\n        };\n\n        //\n        // findOneAndRemove method\n        // -------------------------------------------------\n        const findOneAndReplace = function () {\n          db.collection('t5_2').insertMany([{\n            a: 1,\n            b: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(1);\n            db.collection('t5_2').findOneAndReplace({\n              a: 1\n            }, {\n              c: 1,\n              b: 1\n            }, {\n              projection: {\n                b: 1,\n                c: 1\n              },\n              sort: {\n                a: 1\n              },\n              returnDocument: ReturnDocument.AFTER,\n              upsert: true\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              test.equal(1, r.lastErrorObject.n);\n              test.equal(1, r.value.b);\n              test.equal(1, r.value.c);\n              findOneAndUpdate();\n            });\n          });\n        };\n\n        //\n        // findOneAndRemove method\n        // -------------------------------------------------\n        const findOneAndUpdate = function () {\n          db.collection('t5_3').insertMany([{\n            a: 1,\n            b: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(1);\n            db.collection('t5_3').findOneAndUpdate({\n              a: 1\n            }, {\n              $set: {\n                d: 1\n              }\n            }, {\n              projection: {\n                b: 1,\n                d: 1\n              },\n              sort: {\n                a: 1\n              },\n              returnDocument: ReturnDocument.AFTER,\n              upsert: true\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              test.equal(1, r.lastErrorObject.n);\n              test.equal(1, r.value.b);\n              test.equal(1, r.value.d);\n              client.close(done);\n            });\n          });\n        };\n        findOneAndRemove();\n      });\n    }\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute removeMany with no selector","suites":["CRUD API"],"updatePoint":{"line":1109,"column":58,"index":30218},"line":1109,"code":"  it('should correctly execute removeMany with no selector', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      client.connect(function (err, client) {\n        const db = client.db();\n        expect(err).to.not.exist;\n\n        // Delete all items with no selector\n        db.collection('t6_1').deleteMany({}, function (err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute crud operations with w:0","suites":["CRUD API"],"updatePoint":{"line":1130,"column":55,"index":30889},"line":1130,"code":"  it('should correctly execute crud operations with w:0', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      client.connect(function (err, client) {\n        const db = client.db();\n        expect(err).to.not.exist;\n        const col = db.collection('shouldCorrectlyExecuteInsertOneWithW0');\n        col.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 0\n          }\n        }, function (err, result) {\n          expect(err).to.not.exist;\n          expect(result).property('acknowledged').to.be.false;\n          expect(result).property('insertedId').to.exist;\n          col.insertMany([{\n            a: 1\n          }], {\n            writeConcern: {\n              w: 0\n            }\n          }, function (err, result) {\n            expect(err).to.not.exist;\n            expect(result).to.exist;\n            col.updateOne({\n              a: 1\n            }, {\n              $set: {\n                b: 1\n              }\n            }, {\n              writeConcern: {\n                w: 0\n              }\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              expect(result).to.exist;\n              col.updateMany({\n                a: 1\n              }, {\n                $set: {\n                  b: 1\n                }\n              }, {\n                writeConcern: {\n                  w: 0\n                }\n              }, function (err, result) {\n                expect(err).to.not.exist;\n                expect(result).to.exist;\n                col.deleteOne({\n                  a: 1\n                }, {\n                  writeConcern: {\n                    w: 0\n                  }\n                }, function (err, result) {\n                  expect(err).to.not.exist;\n                  expect(result).to.exist;\n                  col.deleteMany({\n                    a: 1\n                  }, {\n                    writeConcern: {\n                      w: 0\n                    }\n                  }, function (err, result) {\n                    expect(err).to.not.exist;\n                    expect(result).to.exist;\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute updateOne operations with w:0 and upsert","suites":["CRUD API"],"updatePoint":{"line":1216,"column":71,"index":33413},"line":1216,"code":"  it('should correctly execute updateOne operations with w:0 and upsert', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      client.connect(function (err, client) {\n        const db = client.db();\n        expect(err).to.not.exist;\n        db.collection('try').updateOne({\n          _id: 1\n        }, {\n          $set: {\n            x: 1\n          }\n        }, {\n          upsert: true,\n          writeConcern: {\n            w: 0\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          test.ok(r != null);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute crud operations using w:0","suites":["CRUD API"],"updatePoint":{"line":1247,"column":56,"index":34248},"line":1247,"code":"  it('should correctly execute crud operations using w:0', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      client.connect(function (err, client) {\n        const db = client.db();\n        expect(err).to.not.exist;\n        const collection = db.collection('w0crudoperations');\n        collection.insertOne({}, function (err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n\n        // collection.insertOne({a:1});\n        // collection.insertMany([{b:1}]);\n        // collection.updateOne({c:1}, {$set:{a:1}}, {upsert:true});\n\n        // db.collection('try').updateOne({_id:1}, {$set:{x:1}}, {upsert:true, w:0}, function(err, r) {\n        //   expect(err).to.not.exist;\n        //   test.ok(r != null);\n\n        //   client.close();\n        //   done();\n        // });\n      });\n    }\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"should correctly throw error on illegal callback when unordered bulkWrite encounters error","suites":["CRUD API"],"updatePoint":{"line":1280,"column":96,"index":35361},"line":1280,"code":"  it('should correctly throw error on illegal callback when unordered bulkWrite encounters error', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: async function () {\n      const ops = [];\n      // Create a set of operations that go over the 1000 limit causing two messages\n      let i = 0;\n      for (; i < 1005; i++) {\n        ops.push({\n          insertOne: {\n            _id: i,\n            a: i\n          }\n        });\n      }\n      ops.push({\n        insertOne: {\n          _id: 0,\n          a: i\n        }\n      });\n      const db = client.db();\n      const error = await db.collection('t20_1').bulkWrite(ops, {\n        ordered: false,\n        writeConcern: {\n          w: 1\n        }\n      }).catch(error => error);\n      expect(error).to.be.instanceOf(MongoError);\n    }\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"should correctly throw error on illegal callback when ordered bulkWrite encounters error","suites":["CRUD API"],"updatePoint":{"line":1316,"column":94,"index":36372},"line":1316,"code":"  it('should correctly throw error on illegal callback when ordered bulkWrite encounters error', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      const ops = [];\n      // Create a set of operations that go over the 1000 limit causing two messages\n      let i = 0;\n      for (; i < 1005; i++) {\n        ops.push({\n          insertOne: {\n            _id: i,\n            a: i\n          }\n        });\n      }\n      ops.push({\n        insertOne: {\n          _id: 0,\n          a: i\n        }\n      });\n      client.connect(function (err, client) {\n        const db = client.db();\n        expect(err).to.not.exist;\n        db.collection('t20_1').bulkWrite(ops, {\n          ordered: true,\n          writeConcern: {\n            w: 1\n          }\n        }, function (err) {\n          test.ok(err !== null);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"1. WriteConcernError.details exposes writeConcernError.errInfo","suites":["CRUD Prose Spec Tests"],"line":27,"code":"  it.skip('1. WriteConcernError.details exposes writeConcernError.errInfo', {","file":"integration/crud/crud.prose.test.js","skipped":true,"dir":"test"},{"name":"test case: insert MongoServerError","suites":["CRUD Prose Spec Tests","2. WriteError.details exposes writeErrors[].errInfo"],"updatePoint":{"line":97,"column":42,"index":3035},"line":97,"code":"    it('test case: insert MongoServerError', {\n      metadata: {\n        requires: {\n          mongodb: '>=5.0.0'\n        }\n      },\n      async test() {\n        const evCapture = once(client, 'commandSucceeded');\n        let errInfoFromError;\n        try {\n          await collection.insertOne({\n            x: /not a string/\n          });\n          expect.fail('The insert should fail the validation that x must be a string');\n        } catch (error) {\n          expect(error).to.be.instanceOf(MongoServerError);\n          expect(error).to.have.property('code', 121);\n          expect(error).to.have.property('errInfo').that.is.an('object');\n          errInfoFromError = error.errInfo;\n        }\n        const commandSucceededEvents = await evCapture;\n        expect(commandSucceededEvents).to.have.lengthOf(1);\n        const ev = commandSucceededEvents[0];\n        expect(ev).to.have.nested.property('reply.writeErrors[0].errInfo').that.is.an('object');\n        const errInfoFromEvent = ev.reply.writeErrors[0].errInfo;\n        expect(errInfoFromError).to.deep.equal(errInfoFromEvent);\n      }\n    });","file":"integration/crud/crud.prose.test.js","skipped":false,"dir":"test"},{"name":"test case: insertMany MongoBulkWriteError","suites":["CRUD Prose Spec Tests","2. WriteError.details exposes writeErrors[].errInfo"],"updatePoint":{"line":125,"column":49,"index":4147},"line":125,"code":"    it('test case: insertMany MongoBulkWriteError', {\n      metadata: {\n        requires: {\n          mongodb: '>=5.0.0'\n        }\n      },\n      async test() {\n        const evCapture = once(client, 'commandSucceeded');\n        let errInfoFromError;\n        try {\n          await collection.insertMany([{\n            x: /not a string/\n          }]);\n          expect.fail('The insert should fail the validation that x must be a string');\n        } catch (error) {\n          expect(error).to.be.instanceOf(MongoBulkWriteError);\n          expect(error).to.have.property('code', 121);\n          expect(error).to.have.property('writeErrors').that.is.an('array');\n          expect(error.writeErrors[0]).to.have.property('errInfo').that.is.an('object');\n          errInfoFromError = error.writeErrors[0].errInfo;\n        }\n        const commandSucceededEvents = await evCapture;\n        expect(commandSucceededEvents).to.have.lengthOf(1);\n        const ev = commandSucceededEvents[0];\n        expect(ev).to.have.nested.property('reply.writeErrors[0].errInfo').that.is.an('object');\n        const errInfoFromEvent = ev.reply.writeErrors[0].errInfo;\n        expect(errInfoFromError).to.deep.equal(errInfoFromEvent);\n      }\n    });","file":"integration/crud/crud.prose.test.js","skipped":false,"dir":"test"},{"name":"should allow bypassing document validation in 3.2 or higher on inserts","suites":["Document Validation"],"updatePoint":{"line":14,"column":76,"index":317},"line":14,"code":"  it('should allow bypassing document validation in 3.2 or higher on inserts', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>=3.1.7',\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n\n        // Get collection\n        var col = db.collection('createValidationCollection');\n\n        // Drop the collection\n        col.drop(function () {\n          // Create a collection with a validator\n          db.createCollection('createValidationCollection', {\n            validator: {\n              a: {\n                $exists: true\n              }\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n\n            // Ensure validation was correctly applied\n            col.insert({\n              b: 1\n            }, function (err) {\n              test.ok(err != null);\n\n              // Ensure validation was correctly applied\n              col.insert({\n                b: 1\n              }, {\n                bypassDocumentValidation: true\n              }, function (err) {\n                expect(err).to.not.exist;\n\n                // Bypass valiation on insert\n                col.insertOne({\n                  b: 1\n                }, {\n                  bypassDocumentValidation: true\n                }, function (err) {\n                  expect(err).to.not.exist;\n\n                  // Bypass valiation on insert\n                  col.insertMany([{\n                    b: 1\n                  }], {\n                    bypassDocumentValidation: true\n                  }, function (err) {\n                    expect(err).to.not.exist;\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/document_validation.test.js","skipped":false,"dir":"test"},{"name":"should allow bypassing document validation in 3.2 or higher on updates","suites":["Document Validation"],"updatePoint":{"line":86,"column":76,"index":2509},"line":86,"code":"  it('should allow bypassing document validation in 3.2 or higher on updates', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>=3.1.7',\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n\n        // Get collection\n        var col = db.collection('createValidationCollection');\n\n        // Drop the collection\n        col.drop(function () {\n          // Create a collection with a validator\n          db.createCollection('createValidationCollection', {\n            validator: {\n              a: {\n                $exists: true\n              }\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n\n            // Should fail\n            col.update({\n              b: 1\n            }, {\n              $set: {\n                b: 1\n              }\n            }, {\n              upsert: true\n            }, function (err) {\n              expect(err).to.exist;\n\n              // Ensure validation was correctly applied\n              col.update({\n                b: 1\n              }, {\n                $set: {\n                  b: 1\n                }\n              }, {\n                upsert: true,\n                bypassDocumentValidation: true\n              }, function (err) {\n                expect(err).to.not.exist;\n\n                // updateOne\n                col.updateOne({\n                  c: 1\n                }, {\n                  $set: {\n                    c: 1\n                  }\n                }, {\n                  upsert: true,\n                  bypassDocumentValidation: true\n                }, function (err) {\n                  expect(err).to.not.exist;\n\n                  // updateMany\n                  col.updateMany({\n                    d: 1\n                  }, {\n                    $set: {\n                      d: 1\n                    }\n                  }, {\n                    upsert: true,\n                    bypassDocumentValidation: true\n                  }, function (err) {\n                    expect(err).to.not.exist;\n\n                    // updateMany\n                    col.replaceOne({\n                      e: 1\n                    }, {\n                      e: 1\n                    }, {\n                      upsert: true,\n                      bypassDocumentValidation: true\n                    }, function (err) {\n                      expect(err).to.not.exist;\n                      client.close(done);\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/document_validation.test.js","skipped":false,"dir":"test"},{"name":"should allow bypassing document validation in 3.2 or higher on bulkWrite","suites":["Document Validation"],"updatePoint":{"line":191,"column":78,"index":5511},"line":191,"code":"  it('should allow bypassing document validation in 3.2 or higher on bulkWrite', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>=3.1.7',\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n\n        // Get collection\n        var col = db.collection('createValidationCollection');\n\n        // Drop the collection\n        col.drop(function () {\n          // Create a collection with a validator\n          db.createCollection('createValidationCollection', {\n            validator: {\n              a: {\n                $exists: true\n              }\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n\n            // Should fail\n            col.bulkWrite([{\n              insertOne: {\n                b: 1\n              }\n            }], function (err) {\n              test.ok(err != null);\n              col.bulkWrite([{\n                insertOne: {\n                  b: 1\n                }\n              }], {\n                bypassDocumentValidation: true\n              }, function (err) {\n                expect(err).to.not.exist;\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/document_validation.test.js","skipped":false,"dir":"test"},{"name":"should allow bypassing document validation in 3.2 or higher on findAndModify","suites":["Document Validation"],"updatePoint":{"line":247,"column":82,"index":7160},"line":247,"code":"  it('should allow bypassing document validation in 3.2 or higher on findAndModify', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>=3.1.7',\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n\n        // Get collection\n        var col = db.collection('createValidationCollection');\n\n        // Drop the collection\n        col.drop(function () {\n          // Create a collection with a validator\n          db.createCollection('createValidationCollection', {\n            validator: {\n              a: {\n                $exists: true\n              }\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n\n            // Should fail\n            col.findOneAndUpdate({\n              b: 1\n            }, {\n              $set: {\n                b: 1\n              }\n            }, {\n              upsert: true\n            }, function (err) {\n              test.ok(err != null);\n\n              // Should pass\n              col.findOneAndUpdate({\n                b: 1\n              }, {\n                $set: {\n                  b: 1\n                }\n              }, {\n                upsert: true,\n                bypassDocumentValidation: true\n              }, function (err) {\n                expect(err).to.not.exist;\n\n                // Should pass\n                col.findOneAndReplace({\n                  c: 1\n                }, {\n                  c: 1\n                }, {\n                  upsert: true,\n                  bypassDocumentValidation: true\n                }, function (err) {\n                  expect(err).to.not.exist;\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/document_validation.test.js","skipped":false,"dir":"test"},{"name":"should correctly bypass validation for aggregation using out","suites":["Document Validation"],"updatePoint":{"line":324,"column":66,"index":9316},"line":324,"code":"  it('should correctly bypass validation for aggregation using out', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>=3.1.7',\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        // Some docs for insertion\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }];\n\n        // Get collection\n        var col = db.collection('createValidationCollectionOut');\n\n        // Drop the collection\n        col.drop(function () {\n          // Create a collection with a validator\n          db.createCollection('createValidationCollectionOut', {\n            validator: {\n              a: {\n                $exists: true\n              }\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n\n            // Insert the docs\n            col.insertMany(docs, {\n              writeConcern: {\n                w: 1\n              },\n              bypassDocumentValidation: true\n            }, function (err) {\n              expect(err).to.not.exist;\n\n              // Execute aggregate, notice the pipeline is expressed as an Array\n              const cursor = col.aggregate([{\n                $project: {\n                  author: 1,\n                  tags: 1\n                }\n              }, {\n                $unwind: '$tags'\n              }, {\n                $group: {\n                  _id: {\n                    tags: '$tags'\n                  },\n                  authors: {\n                    $addToSet: '$author'\n                  }\n                }\n              }, {\n                $out: 'createValidationCollectionOut'\n              }], {\n                bypassDocumentValidation: true\n              });\n              cursor.toArray(function (err) {\n                expect(err).to.not.exist;\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/document_validation.test.js","skipped":false,"dir":"test"},{"name":"should correctly bypass validation for mapReduce using out","suites":["Document Validation"],"updatePoint":{"line":415,"column":64,"index":11943},"line":415,"code":"  it('should correctly bypass validation for mapReduce using out', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>=3.1.7',\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n\n        // Get collection\n        var col = db.collection('createValidationCollectionOut');\n\n        // Drop the collection\n        col.drop(function () {\n          // Create a collection with a validator\n          db.createCollection('createValidationCollectionOut', {\n            validator: {\n              a: {\n                $exists: true\n              }\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n\n            // Get write concern\n            var writeConcern = configuration.writeConcernMax();\n            writeConcern.bypassDocumentValidation = true;\n\n            // Insert documents\n            col.insertMany([{\n              user_id: 1\n            }, {\n              user_id: 2\n            }], {\n              bypassDocumentValidation: true\n            }, function (err) {\n              expect(err).to.not.exist;\n\n              // String functions\n              var map = 'function() { emit(this.user_id, 1); }';\n              var reduce = 'function(k,vals) { return 1; }';\n              col.mapReduce(map, reduce, {\n                out: {\n                  replace: 'createValidationCollectionOut'\n                },\n                bypassDocumentValidation: true\n              }, function (err) {\n                expect(err).to.not.exist;\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/document_validation.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with delete one","suites":["Explain"],"updatePoint":{"line":22,"column":50,"index":501},"line":22,"code":"  it('should honor boolean explain with delete one', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorBooleanExplainWithDeleteOne');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.deleteOne({\n          a: 1\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with delete many","suites":["Explain"],"updatePoint":{"line":49,"column":51,"index":1215},"line":49,"code":"  it('should honor boolean explain with delete many', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorBooleanExplainWithDeleteMany');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.deleteMany({\n          a: 1\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with update one","suites":["Explain"],"updatePoint":{"line":76,"column":50,"index":1930},"line":76,"code":"  it('should honor boolean explain with update one', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorBooleanExplainWithUpdateOne');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.updateOne({\n          a: 1\n        }, {\n          $inc: {\n            a: 2\n          }\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with update many","suites":["Explain"],"updatePoint":{"line":107,"column":51,"index":2704},"line":107,"code":"  it('should honor boolean explain with update many', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorBooleanExplainWithUpdateMany');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.updateMany({\n          a: 1\n        }, {\n          $inc: {\n            a: 2\n          }\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).nested.property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with remove one","suites":["Explain"],"updatePoint":{"line":138,"column":50,"index":3486},"line":138,"code":"  it('should honor boolean explain with remove one', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorBooleanExplainWithRemoveOne');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.deleteOne({\n          a: 1\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with remove many","suites":["Explain"],"updatePoint":{"line":165,"column":51,"index":4200},"line":165,"code":"  it('should honor boolean explain with remove many', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorBooleanExplainWithRemoveMany');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.deleteMany({\n          a: 1\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with distinct","suites":["Explain"],"updatePoint":{"line":192,"column":48,"index":4913},"line":192,"code":"  it('should honor boolean explain with distinct', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.2'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorBooleanExplainWithDistinct');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.distinct('a', {}, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with findOneAndModify","suites":["Explain"],"updatePoint":{"line":217,"column":56,"index":5611},"line":217,"code":"  it('should honor boolean explain with findOneAndModify', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.2'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorBooleanExplainWithFindOneAndModify');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.findOneAndDelete({\n          a: 1\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with mapReduce","suites":["Explain"],"updatePoint":{"line":244,"column":49,"index":6337},"line":244,"code":"  it('should honor boolean explain with mapReduce', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.4'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorBooleanExplainWithMapReduce');\n      var collection = db.collection('test');\n      collection.insertMany([{\n        user_id: 1\n      }, {\n        user_id: 2\n      }], (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        var map = 'function() { emit(this.user_id, 1); }';\n        var reduce = 'function(k,vals) { return 1; }';\n        collection.mapReduce(map, reduce, {\n          out: {\n            replace: 'tempCollection'\n          },\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('stages').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should use allPlansExecution as true explain verbosity","suites":["Explain"],"updatePoint":{"line":276,"column":60,"index":7260},"line":276,"code":"  it('should use allPlansExecution as true explain verbosity', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldUseAllPlansExecutionAsTrueExplainVerbosity');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n\n        // Verify explanation result contains properties of allPlansExecution output\n        collection.deleteOne({\n          a: 1\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).nested.property('executionStats.allPlansExecution').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should use queryPlanner as false explain verbosity","suites":["Explain"],"updatePoint":{"line":306,"column":56,"index":8167},"line":306,"code":"  it('should use queryPlanner as false explain verbosity', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldUseQueryPlannerAsFalseExplainVerbosity');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n\n        // Verify explanation result contains properties of queryPlanner output\n        collection.deleteOne({\n          a: 1\n        }, {\n          explain: false\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).to.not.have.property('executionStats');\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor queryPlanner string explain","suites":["Explain"],"updatePoint":{"line":336,"column":46,"index":9034},"line":336,"code":"  it('should honor queryPlanner string explain', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorQueryPlannerStringExplain');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n\n        // Verify explanation result contains properties of queryPlanner output\n        collection.deleteOne({\n          a: 1\n        }, {\n          explain: 'queryPlanner'\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).to.not.have.property('executionStats');\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor executionStats string explain","suites":["Explain"],"updatePoint":{"line":366,"column":48,"index":9904},"line":366,"code":"  it('should honor executionStats string explain', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorExecutionStatsStringExplain');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n\n        // Verify explanation result contains properties of executionStats output\n        collection.deleteMany({\n          a: 1\n        }, {\n          explain: 'executionStats'\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).property('executionStats').to.exist;\n          expect(explanation.executionStats).to.not.have.property('allPlansExecution');\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor allPlansExecution string explain","suites":["Explain"],"updatePoint":{"line":397,"column":51,"index":10869},"line":397,"code":"  it('should honor allPlansExecution string explain', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorAllPlansStringExplain');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n\n        // Verify explanation result contains properties of allPlansExecution output\n        collection.deleteOne({\n          a: 1\n        }, {\n          explain: 'allPlansExecution'\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).nested.property('executionStats.allPlansExecution').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor string explain with distinct","suites":["Explain"],"updatePoint":{"line":427,"column":47,"index":11766},"line":427,"code":"  it('should honor string explain with distinct', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.2'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorStringExplainWithDistinct');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.distinct('a', {}, {\n          explain: 'executionStats'\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).property('executionStats').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor string explain with findOneAndModify","suites":["Explain"],"updatePoint":{"line":453,"column":55,"index":12541},"line":453,"code":"  it('should honor string explain with findOneAndModify', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.2'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorStringExplainWithFindOneAndModify');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.findOneAndReplace({\n          a: 1\n        }, {\n          a: 2\n        }, {\n          explain: 'queryPlanner'\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor string explain with mapReduce","suites":["Explain"],"updatePoint":{"line":482,"column":48,"index":13304},"line":482,"code":"  it('should honor string explain with mapReduce', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.4'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorStringExplainWithMapReduce');\n      var collection = db.collection('test');\n      collection.insertMany([{\n        user_id: 1\n      }, {\n        user_id: 2\n      }], (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        var map = 'function() { emit(this.user_id, 1); }';\n        var reduce = 'function(k,vals) { return 1; }';\n        collection.mapReduce(map, reduce, {\n          out: {\n            replace: 'tempCollection'\n          },\n          explain: 'executionStats'\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('stages').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with find","suites":["Explain"],"updatePoint":{"line":514,"column":44,"index":14222},"line":514,"code":"  it('should honor boolean explain with find', async () => {\n    const db = client.db('shouldHonorBooleanExplainWithFind');\n    const collection = db.collection('test');\n    await collection.insertOne({\n      a: 1\n    });\n    const [explanation] = await collection.find({\n      a: 1\n    }, {\n      explain: true\n    }).toArray();\n    expect(explanation).to.exist;\n    expect(explanation).property('queryPlanner').to.exist;\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor string explain with find","suites":["Explain"],"updatePoint":{"line":528,"column":43,"index":14650},"line":528,"code":"  it('should honor string explain with find', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      const db = client.db('shouldHonorStringExplainWithFind');\n      const collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.find({\n          a: 1\n        }, {\n          explain: 'executionStats'\n        }).toArray((err, docs) => {\n          expect(err).to.not.exist;\n          const explanation = docs[0];\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).property('executionStats').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with findOne","suites":["Explain"],"updatePoint":{"line":557,"column":47,"index":15472},"line":557,"code":"  it('should honor boolean explain with findOne', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      const db = client.db('shouldHonorBooleanExplainWithFindOne');\n      const collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.findOne({\n          a: 1\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor string explain with findOne","suites":["Explain"],"updatePoint":{"line":584,"column":46,"index":16181},"line":584,"code":"  it('should honor string explain with findOne', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      const db = client.db('shouldHonorStringExplainWithFindOne');\n      const collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.findOne({\n          a: 1\n        }, {\n          explain: 'executionStats'\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).property('executionStats').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain specified on cursor with find","suites":["Explain"],"updatePoint":{"line":612,"column":64,"index":16986},"line":612,"code":"  it('should honor boolean explain specified on cursor with find', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      const db = client.db('shouldHonorBooleanExplainSpecifiedOnCursor');\n      const collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.find({\n          a: 1\n        }).explain(false, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor string explain specified on cursor with find","suites":["Explain"],"updatePoint":{"line":637,"column":63,"index":17693},"line":637,"code":"  it('should honor string explain specified on cursor with find', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      const db = client.db('shouldHonorStringExplainSpecifiedOnCursor');\n      const collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.find({\n          a: 1\n        }).explain('allPlansExecution', (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).property('executionStats').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor legacy explain with find","suites":["Explain"],"updatePoint":{"line":663,"column":43,"index":18460},"line":663,"code":"  it('should honor legacy explain with find', {\n    metadata: {\n      requires: {\n        mongodb: '<3.0'\n      }\n    },\n    test: function (done) {\n      const db = client.db('shouldHonorLegacyExplainWithFind');\n      const collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.find({\n          a: 1\n        }).explain((err, result) => {\n          expect(err).to.not.exist;\n          expect(result).to.have.property('allPlans');\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with aggregate","suites":["Explain"],"updatePoint":{"line":687,"column":49,"index":19080},"line":687,"code":"  it('should honor boolean explain with aggregate', function (done) {\n    const db = client.db('shouldHonorBooleanExplainWithAggregate');\n    const collection = db.collection('test');\n    collection.insertOne({\n      a: 1\n    }, (err, res) => {\n      expect(err).to.not.exist;\n      expect(res).to.exist;\n      collection.aggregate([{\n        $project: {\n          a: 1\n        }\n      }, {\n        $group: {\n          _id: '$a'\n        }\n      }], {\n        explain: true\n      }).toArray((err, docs) => {\n        expect(err).to.not.exist;\n        const result = JSON.stringify(docs[0]);\n        expect(result).to.include('\"queryPlanner\"');\n        expect(result).to.include('\"executionStats\"');\n        done();\n      });\n    });\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor string explain with aggregate","suites":["Explain"],"updatePoint":{"line":714,"column":48,"index":19816},"line":714,"code":"  it('should honor string explain with aggregate', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.6.0'\n      }\n    },\n    test: function (done) {\n      const db = client.db('shouldHonorStringExplainWithAggregate');\n      const collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.aggregate([{\n          $project: {\n            a: 1\n          }\n        }, {\n          $group: {\n            _id: '$a'\n          }\n        }], {\n          explain: 'executionStats'\n        }).toArray((err, docs) => {\n          expect(err).to.not.exist;\n          const result = JSON.stringify(docs[0]);\n          expect(result).to.include('\"queryPlanner\"');\n          expect(result).to.include('\"executionStats\"');\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain specified on cursor with aggregate","suites":["Explain"],"updatePoint":{"line":748,"column":69,"index":20728},"line":748,"code":"  it('should honor boolean explain specified on cursor with aggregate', function (done) {\n    const db = client.db('shouldHonorBooleanExplainSpecifiedOnCursor');\n    const collection = db.collection('test');\n    collection.insertOne({\n      a: 1\n    }, (err, res) => {\n      expect(err).to.not.exist;\n      expect(res).to.exist;\n      collection.aggregate([{\n        $project: {\n          a: 1\n        }\n      }, {\n        $group: {\n          _id: '$a'\n        }\n      }]).explain(false, (err, res) => {\n        expect(err).to.not.exist;\n        const result = JSON.stringify(res);\n        expect(result).to.include('\"queryPlanner\"');\n        expect(result).not.to.include('\"executionStats\"');\n        done();\n      });\n    });\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor string explain specified on cursor with aggregate","suites":["Explain"],"updatePoint":{"line":773,"column":68,"index":21461},"line":773,"code":"  it('should honor string explain specified on cursor with aggregate', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.6'\n      }\n    },\n    test: function (done) {\n      const db = client.db('shouldHonorStringExplainSpecifiedOnCursor');\n      const collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.aggregate([{\n          $project: {\n            a: 1\n          }\n        }, {\n          $group: {\n            _id: '$a'\n          }\n        }]).explain('allPlansExecution', (err, res) => {\n          expect(err).to.not.exist;\n          expect(res).to.exist;\n          const result = JSON.stringify(res);\n          expect(result).to.include('\"queryPlanner\"');\n          expect(result).to.include('\"executionStats\"');\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor legacy explain with aggregate","suites":["Explain"],"updatePoint":{"line":806,"column":48,"index":22353},"line":806,"code":"  it('should honor legacy explain with aggregate', function (done) {\n    const db = client.db('shouldHonorLegacyExplainWithAggregate');\n    const collection = db.collection('test');\n    collection.insertOne({\n      a: 1\n    }, (err, res) => {\n      expect(err).to.not.exist;\n      expect(res).to.exist;\n      collection.aggregate([{\n        $project: {\n          a: 1\n        }\n      }, {\n        $group: {\n          _id: '$a'\n        }\n      }]).explain((err, res) => {\n        expect(err).to.not.exist;\n        const result = JSON.stringify(res);\n        expect(result).to.include('\"queryPlanner\"');\n        expect(result).to.include('\"executionStats\"');\n        done();\n      });\n    });\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should throw a catchable error with invalid explain string (promise)","suites":["Explain"],"updatePoint":{"line":831,"column":74,"index":23076},"line":831,"code":"  it('should throw a catchable error with invalid explain string (promise)', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.4'\n      }\n    },\n    test: function (done) {\n      const db = client.db('shouldThrowCatchableError');\n      const collection = db.collection('test');\n      collection.find({\n        a: 1\n      }).explain('invalidExplain').then(() => done(new Error('expected explain to fail but it succeeded'))).catch(err => {\n        expect(err).to.exist;\n        expect(err).to.be.instanceOf(MongoServerError);\n        done();\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should throw a catchable error with invalid explain string (callback)","suites":["Explain"],"updatePoint":{"line":849,"column":75,"index":23647},"line":849,"code":"  it('should throw a catchable error with invalid explain string (callback)', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.4'\n      }\n    },\n    test: function (done) {\n      const db = client.db('shouldThrowCatchableError');\n      const collection = db.collection('test');\n      collection.find({\n        a: 1\n      }).explain('invalidExplain', (err, result) => {\n        expect(err).to.exist;\n        expect(result).to.not.exist;\n        expect(err).to.be.instanceOf(MongoServerError);\n        done();\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndDelete operation With Promises and no options passed in","suites":["Find and Modify","promise tests"],"updatePoint":{"line":18,"column":98,"index":417},"line":18,"code":"    it('Should correctly execute findOneAndDelete operation With Promises and no options passed in', function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        const col = db.collection('find_one_and_delete_with_promise_no_option');\n        col.insertMany([{\n          a: 1,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (r) {\n          expect(r).property('insertedCount').to.equal(1);\n          col.findOneAndDelete({\n            a: 1\n          }).then(function (r) {\n            test.equal(1, r.lastErrorObject.n);\n            test.equal(1, r.value.b);\n            client.close(done);\n          }).catch(function (err) {\n            test.ok(err != null);\n          });\n        });\n      });\n    });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndUpate operation With Promises and no options passed in","suites":["Find and Modify","promise tests"],"updatePoint":{"line":47,"column":97,"index":1400},"line":47,"code":"    it('Should correctly execute findOneAndUpate operation With Promises and no options passed in', function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        const col = db.collection('find_one_and_update_with_promise_no_option');\n        col.insertMany([{\n          a: 1,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (r) {\n          expect(r).property('insertedCount').to.equal(1);\n          col.findOneAndUpdate({\n            a: 1\n          }, {\n            $set: {\n              a: 1\n            }\n          }).then(function (r) {\n            test.equal(1, r.lastErrorObject.n);\n            test.equal(1, r.value.b);\n            client.close(done);\n          }).catch(function (err) {\n            test.ok(err != null);\n          });\n        });\n      });\n    });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndReplace operation With Promises and no options passed in","suites":["Find and Modify","promise tests"],"updatePoint":{"line":80,"column":99,"index":2453},"line":80,"code":"    it('Should correctly execute findOneAndReplace operation With Promises and no options passed in', function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        const col = db.collection('find_one_and_replace_with_promise_no_option');\n        col.insertMany([{\n          a: 1,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (r) {\n          expect(r).property('insertedCount').to.equal(1);\n          col.findOneAndReplace({\n            a: 1\n          }, {\n            a: 1\n          }).then(function (r) {\n            test.equal(1, r.lastErrorObject.n);\n            test.equal(1, r.value.b);\n            client.close(done);\n          }).catch(function (err) {\n            test.ok(err != null);\n          });\n        });\n      });\n    });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"should pass through writeConcern to all findAndModify commands at command level","suites":["Find and Modify","promise tests"],"updatePoint":{"line":112,"column":85,"index":3464},"line":112,"code":"  it('should pass through writeConcern to all findAndModify commands at command level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var started = [];\n      var succeeded = [];\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      client.on('commandStarted', function (event) {\n        if (event.commandName === 'findAndModify') started.push(event);\n      });\n      client.on('commandSucceeded', function (event) {\n        if (event.commandName === 'findAndModify') succeeded.push(event);\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        var collection = db.collection('findAndModifyTEST');\n        // Execute findOneAndUpdate\n        collection.findOneAndUpdate({}, {\n          $set: {\n            a: 1\n          }\n        }, {\n          writeConcern: {\n            fsync: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          test.deepEqual({\n            fsync: 1\n          }, started[0].command.writeConcern);\n\n          // Cleanup\n          started = [];\n          succeeded = [];\n\n          // Execute findOneAndReplace\n          collection.findOneAndReplace({}, {\n            b: 1\n          }, {\n            writeConcern: {\n              fsync: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n            test.deepEqual({\n              fsync: 1\n            }, started[0].command.writeConcern);\n\n            // Cleanup\n            started = [];\n            succeeded = [];\n\n            // Execute findOneAndReplace\n            collection.findOneAndDelete({}, {\n              writeConcern: {\n                fsync: 1\n              }\n            }, function (err) {\n              expect(err).to.not.exist;\n              test.deepEqual({\n                fsync: 1\n              }, started[0].command.writeConcern);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"should pass through writeConcern to all findAndModify at collection level","suites":["Find and Modify","promise tests"],"updatePoint":{"line":191,"column":79,"index":5831},"line":191,"code":"  it('should pass through writeConcern to all findAndModify at collection level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var started = [];\n      var succeeded = [];\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      client.on('commandStarted', function (event) {\n        if (event.commandName === 'findAndModify') started.push(event);\n      });\n      client.on('commandSucceeded', function (event) {\n        if (event.commandName === 'findAndModify') succeeded.push(event);\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        var collection = db.collection('findAndModifyTEST', {\n          writeConcern: {\n            fsync: 1\n          }\n        });\n        // Execute findOneAndUpdate\n        collection.findOneAndUpdate({}, {\n          $set: {\n            a: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          test.deepEqual({\n            fsync: 1\n          }, started[0].command.writeConcern);\n\n          // Cleanup\n          started = [];\n          succeeded = [];\n\n          // Execute findOneAndReplace\n          collection.findOneAndReplace({}, {\n            b: 1\n          }, function (err) {\n            expect(err).to.not.exist;\n            test.deepEqual({\n              fsync: 1\n            }, started[0].command.writeConcern);\n\n            // Cleanup\n            started = [];\n            succeeded = [];\n\n            // Execute findOneAndReplace\n            collection.findOneAndDelete({}, function (err) {\n              expect(err).to.not.exist;\n              test.deepEqual({\n                fsync: 1\n              }, started[0].command.writeConcern);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"should pass through writeConcern to all findAndModify at db level","suites":["Find and Modify","promise tests"],"updatePoint":{"line":262,"column":71,"index":8022},"line":262,"code":"  it('should pass through writeConcern to all findAndModify at db level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var started = [];\n      var succeeded = [];\n      var url = configuration.url();\n      url = url.indexOf('?') !== -1 ? f('%s&%s', url, 'fsync=true') : f('%s?%s', url, 'fsync=true');\n\n      // Establish connection to db\n      const client = configuration.newClient(url, {\n        sslValidate: false,\n        monitorCommands: true\n      });\n      client.on('commandStarted', function (event) {\n        if (event.commandName === 'findAndModify') started.push(event);\n      });\n      client.on('commandSucceeded', function (event) {\n        if (event.commandName === 'findAndModify') succeeded.push(event);\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(configuration.db);\n        var collection = db.collection('findAndModifyTEST');\n        // Execute findOneAndUpdate\n        collection.findOneAndUpdate({}, {\n          $set: {\n            a: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          test.deepEqual({\n            fsync: true\n          }, started[0].command.writeConcern);\n\n          // Cleanup\n          started = [];\n          succeeded = [];\n\n          // Execute findOneAndReplace\n          collection.findOneAndReplace({}, {\n            b: 1\n          }, function (err) {\n            expect(err).to.not.exist;\n            test.deepEqual({\n              fsync: true\n            }, started[0].command.writeConcern);\n\n            // Cleanup\n            started = [];\n            succeeded = [];\n\n            // Execute findOneAndReplace\n            collection.findOneAndDelete({}, function (err) {\n              expect(err).to.not.exist;\n              test.deepEqual({\n                fsync: true\n              }, started[0].command.writeConcern);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"should allow all findAndModify commands with non-primary readPreference","suites":["Find and Modify","promise tests"],"updatePoint":{"line":333,"column":77,"index":10309},"line":333,"code":"  it('should allow all findAndModify commands with non-primary readPreference', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'replicaset'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient({\n        readPreference: 'secondary'\n      }, {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        const db = client.db(configuration.db);\n        const collection = db.collection('findAndModifyTEST');\n        // Execute findOneAndUpdate\n        collection.findOneAndUpdate({}, {\n          $set: {\n            a: 1\n          }\n        }, err => {\n          expect(err).to.not.exist;\n          client.close(true, done);\n        });\n      });\n    }\n  });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"should not allow atomic operators for findOneAndReplace","suites":["Find and Modify","promise tests"],"updatePoint":{"line":364,"column":61,"index":11225},"line":364,"code":"  it('should not allow atomic operators for findOneAndReplace', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: async function () {\n      const client = this.configuration.newClient();\n      const db = client.db('fakeDb');\n      const collection = db.collection('test');\n      expect(() => {\n        collection.findOneAndReplace({\n          a: 1\n        }, {\n          $set: {\n            a: 14\n          }\n        });\n      }).to.throw(/must not contain atomic operators/);\n      await client.close();\n    }\n  });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"should support a batch size","suites":["Find Cursor","#next"],"updatePoint":{"line":42,"column":35,"index":928},"line":42,"code":"    it('should support a batch size', function (done) {\n      const commands = [];\n      client.on('commandStarted', filterForCommands(['getMore'], commands));\n      const coll = client.db().collection('abstract_cursor');\n      const cursor = coll.find({}, {\n        batchSize: 2\n      });\n      this.defer(() => cursor.close());\n      cursor.toArray((err, docs) => {\n        expect(err).to.not.exist;\n        expect(docs).to.have.length(6);\n        expect(commands).to.have.length(3);\n        done();\n      });\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should remove buffered documents from subsequent cursor iterations","suites":["Find Cursor","#readBufferedDocuments"],"updatePoint":{"line":68,"column":74,"index":1772},"line":68,"code":"    it('should remove buffered documents from subsequent cursor iterations', async () => {\n      const [doc] = cursor.readBufferedDocuments(1);\n      expect(doc).to.have.property('a', 1);\n      const nextDoc = await cursor.next();\n      expect(nextDoc).to.have.property('a', 2);\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should return the amount of documents requested","suites":["Find Cursor","#readBufferedDocuments"],"updatePoint":{"line":74,"column":55,"index":2040},"line":74,"code":"    it('should return the amount of documents requested', async () => {\n      const buf1 = cursor.readBufferedDocuments(1);\n      expect(buf1).to.be.lengthOf(1);\n      const buf2 = cursor.readBufferedDocuments(3);\n      expect(buf2).to.be.lengthOf(3);\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should bound the request by the maximum amount of documents currently buffered","suites":["Find Cursor","#readBufferedDocuments"],"updatePoint":{"line":80,"column":86,"index":2331},"line":80,"code":"    it('should bound the request by the maximum amount of documents currently buffered', async () => {\n      const buf1 = cursor.readBufferedDocuments(1000);\n      expect(buf1).to.be.lengthOf(5);\n      const buf2 = cursor.readBufferedDocuments(23);\n      expect(buf2).to.be.lengthOf(0);\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should return all buffered documents when no argument is passed","suites":["Find Cursor","#readBufferedDocuments"],"updatePoint":{"line":86,"column":71,"index":2611},"line":86,"code":"    it('should return all buffered documents when no argument is passed', async () => {\n      const buf1 = cursor.readBufferedDocuments();\n      expect(buf1).to.be.lengthOf(5);\n      const buf2 = cursor.readBufferedDocuments();\n      expect(buf2).to.be.lengthOf(0);\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should return empty array for size zero or less","suites":["Find Cursor","#readBufferedDocuments"],"updatePoint":{"line":92,"column":55,"index":2869},"line":92,"code":"    it('should return empty array for size zero or less', async () => {\n      const buf1 = cursor.readBufferedDocuments(0);\n      expect(buf1).to.be.lengthOf(0);\n      const buf2 = cursor.readBufferedDocuments(-23);\n      expect(buf2).to.be.lengthOf(0);\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should return the same amount of documents reported by bufferedCount","suites":["Find Cursor","#readBufferedDocuments"],"updatePoint":{"line":98,"column":76,"index":3152},"line":98,"code":"    it('should return the same amount of documents reported by bufferedCount', async function () {\n      const doc = await cursor.next();\n      expect(doc).property('a', 1);\n      const bufferedCount = cursor.bufferedCount();\n      expect(bufferedCount).to.equal(4);\n\n      // Read the buffered Count\n      const bufferedDocs = cursor.readBufferedDocuments(bufferedCount);\n      expect(bufferedDocs.map(({\n        a\n      }) => a)).to.deep.equal([2, 3, 4, 5]);\n      const doc2 = await cursor.next();\n      expect(doc2).to.have.property('a', 6);\n      const doc3 = await cursor.next();\n      expect(doc3).to.be.null;\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should send a killCursors command when closed before completely iterated","suites":["Find Cursor","#close"],"updatePoint":{"line":116,"column":80,"index":3821},"line":116,"code":"    it('should send a killCursors command when closed before completely iterated', function (done) {\n      const commands = [];\n      client.on('commandStarted', filterForCommands(['killCursors'], commands));\n      const coll = client.db().collection('abstract_cursor');\n      const cursor = coll.find({}, {\n        batchSize: 2\n      });\n      cursor.next(err => {\n        expect(err).to.not.exist;\n        cursor.close(err => {\n          expect(err).to.not.exist;\n          expect(commands).to.have.length(1);\n          done();\n        });\n      });\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should not send a killCursors command when closed after completely iterated","suites":["Find Cursor","#close"],"updatePoint":{"line":132,"column":83,"index":4384},"line":132,"code":"    it('should not send a killCursors command when closed after completely iterated', function (done) {\n      const commands = [];\n      client.on('commandStarted', filterForCommands(['killCursors'], commands));\n      const coll = client.db().collection('abstract_cursor');\n      const cursor = coll.find({}, {\n        batchSize: 2\n      });\n      cursor.toArray(err => {\n        expect(err).to.not.exist;\n        cursor.close(err => {\n          expect(err).to.not.exist;\n          expect(commands).to.have.length(0);\n          done();\n        });\n      });\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should not send a killCursors command when closed before initialization","suites":["Find Cursor","#close"],"updatePoint":{"line":148,"column":79,"index":4946},"line":148,"code":"    it('should not send a killCursors command when closed before initialization', function (done) {\n      const commands = [];\n      client.on('commandStarted', filterForCommands(['killCursors'], commands));\n      const coll = client.db().collection('abstract_cursor');\n      const cursor = coll.find({}, {\n        batchSize: 2\n      });\n      cursor.close(err => {\n        expect(err).to.not.exist;\n        expect(commands).to.have.length(0);\n        done();\n      });\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should iterate each document in a cursor","suites":["Find Cursor","#forEach"],"updatePoint":{"line":163,"column":48,"index":5435},"line":163,"code":"    it('should iterate each document in a cursor', function (done) {\n      const coll = client.db().collection('abstract_cursor');\n      const cursor = coll.find({}, {\n        batchSize: 2\n      });\n      const bag = [];\n      cursor.forEach(doc => bag.push(doc), err => {\n        expect(err).to.not.exist;\n        expect(bag).to.have.lengthOf(6);\n        done();\n      });\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should return control to the user if an empty batch is returned","suites":["Find Cursor","#tryNext"],"updatePoint":{"line":177,"column":71,"index":5882},"line":177,"code":"    it('should return control to the user if an empty batch is returned', function (done) {\n      const db = client.db();\n      db.createCollection('try_next', {\n        capped: true,\n        size: 10000000\n      }, () => {\n        const coll = db.collection('try_next');\n        coll.insertMany([{}, {}], err => {\n          expect(err).to.not.exist;\n          const cursor = coll.find({}, {\n            tailable: true,\n            awaitData: true\n          });\n          this.defer(() => cursor.close());\n          cursor.tryNext((err, doc) => {\n            expect(err).to.not.exist;\n            expect(doc).to.exist;\n            cursor.tryNext((err, doc) => {\n              expect(err).to.not.exist;\n              expect(doc).to.exist;\n              cursor.tryNext((err, doc) => {\n                expect(err).to.not.exist;\n                expect(doc).to.be.null;\n                done();\n              });\n            });\n          });\n        });\n      });\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should clone a find cursor","suites":["Find Cursor","#clone"],"updatePoint":{"line":209,"column":34,"index":6852},"line":209,"code":"    it('should clone a find cursor', function (done) {\n      const coll = client.db().collection('abstract_cursor');\n      const cursor = coll.find({});\n      this.defer(() => cursor.close());\n      cursor.toArray((err, docs) => {\n        expect(err).to.not.exist;\n        expect(docs).to.have.length(6);\n        expect(cursor).property('closed').to.be.true;\n        const clonedCursor = cursor.clone();\n        this.defer(() => clonedCursor.close());\n        clonedCursor.toArray((err, docs) => {\n          expect(err).to.not.exist;\n          expect(docs).to.have.length(6);\n          expect(clonedCursor).property('closed').to.be.true;\n          done();\n        });\n      });\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should clone an aggregate cursor","suites":["Find Cursor","#clone"],"updatePoint":{"line":227,"column":40,"index":7544},"line":227,"code":"    it('should clone an aggregate cursor', function (done) {\n      const coll = client.db().collection('abstract_cursor');\n      const cursor = coll.aggregate([{\n        $match: {}\n      }]);\n      this.defer(() => cursor.close());\n      cursor.toArray((err, docs) => {\n        expect(err).to.not.exist;\n        expect(docs).to.have.length(6);\n        expect(cursor).property('closed').to.be.true;\n        const clonedCursor = cursor.clone();\n        this.defer(() => clonedCursor.close());\n        clonedCursor.toArray((err, docs) => {\n          expect(err).to.not.exist;\n          expect(docs).to.have.length(6);\n          expect(clonedCursor).property('closed').to.be.true;\n          done();\n        });\n      });\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should rewind a cursor","suites":["Find Cursor","#rewind"],"updatePoint":{"line":249,"column":30,"index":8300},"line":249,"code":"    it('should rewind a cursor', function (done) {\n      const coll = client.db().collection('abstract_cursor');\n      const cursor = coll.find({});\n      this.defer(() => cursor.close());\n      cursor.toArray((err, docs) => {\n        expect(err).to.not.exist;\n        expect(docs).to.have.length(6);\n        cursor.rewind();\n        cursor.toArray((err, docs) => {\n          expect(err).to.not.exist;\n          expect(docs).to.have.length(6);\n          done();\n        });\n      });\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should end an implicit session on rewind","suites":["Find Cursor","#rewind"],"updatePoint":{"line":264,"column":48,"index":8810},"line":264,"code":"    it('should end an implicit session on rewind', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.6'\n        }\n      },\n      test: function (done) {\n        const coll = client.db().collection('abstract_cursor');\n        const cursor = coll.find({}, {\n          batchSize: 1\n        });\n        this.defer(() => cursor.close());\n        cursor.next((err, doc) => {\n          expect(err).to.not.exist;\n          expect(doc).to.exist;\n          const session = cursor.session;\n          expect(session).property('hasEnded').to.be.false;\n          cursor.rewind();\n          expect(session).property('hasEnded').to.be.true;\n          done();\n        });\n      }\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should not end an explicit session on rewind","suites":["Find Cursor","#rewind"],"updatePoint":{"line":287,"column":52,"index":9499},"line":287,"code":"    it('should not end an explicit session on rewind', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.6'\n        }\n      },\n      test: function (done) {\n        const coll = client.db().collection('abstract_cursor');\n        const session = client.startSession();\n        const cursor = coll.find({}, {\n          batchSize: 1,\n          session\n        });\n        this.defer(() => cursor.close());\n        cursor.next((err, doc) => {\n          expect(err).to.not.exist;\n          expect(doc).to.exist;\n          const session = cursor.session;\n          expect(session).property('hasEnded').to.be.false;\n          cursor.rewind();\n          expect(session).property('hasEnded').to.be.false;\n          session.endSession(done);\n        });\n      }\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should set allowDiskUse to true by default","suites":["Find Cursor","#allowDiskUse"],"updatePoint":{"line":314,"column":50,"index":10318},"line":314,"code":"    it('should set allowDiskUse to true by default', {\n      metadata: {\n        requires: {\n          mongodb: '>=4.4'\n        }\n      },\n      test: function (done) {\n        const commands = [];\n        client.on('commandStarted', filterForCommands(['find'], commands));\n        const coll = client.db().collection('abstract_cursor');\n        const cursor = coll.find({}, {\n          sort: 'foo'\n        });\n        cursor.allowDiskUse();\n        this.defer(() => cursor.close());\n        cursor.toArray(err => {\n          expect(err).to.not.exist;\n          expect(commands).to.have.length(1);\n          expect(commands[0].command.allowDiskUse).to.equal(true);\n          done();\n        });\n      }\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should set allowDiskUse to false if specified","suites":["Find Cursor","#allowDiskUse"],"updatePoint":{"line":337,"column":53,"index":11032},"line":337,"code":"    it('should set allowDiskUse to false if specified', {\n      metadata: {\n        requires: {\n          mongodb: '>=4.4'\n        }\n      },\n      test: function (done) {\n        const commands = [];\n        client.on('commandStarted', filterForCommands(['find'], commands));\n        const coll = client.db().collection('abstract_cursor');\n        const cursor = coll.find({}, {\n          sort: 'foo'\n        });\n        cursor.allowDiskUse(false);\n        this.defer(() => cursor.close());\n        cursor.toArray(err => {\n          expect(err).to.not.exist;\n          expect(commands).to.have.length(1);\n          expect(commands[0].command.allowDiskUse).to.equal(false);\n          done();\n        });\n      }\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"throws if the query does not have sort specified","suites":["Find Cursor","#allowDiskUse"],"updatePoint":{"line":360,"column":56,"index":11755},"line":360,"code":"    it('throws if the query does not have sort specified', {\n      metadata: {\n        requires: {\n          mongodb: '>=4.4'\n        }\n      },\n      test: function (done) {\n        const coll = client.db().collection('abstract_cursor');\n        const cursor = coll.find({});\n        expect(() => cursor.allowDiskUse(false)).to.throw('Option \"allowDiskUse\" requires a sort specification');\n        done();\n      }\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformSimpleFind","suites":["Find"],"updatePoint":{"line":29,"column":38,"index":469},"line":29,"code":"  it('shouldCorrectlyPerformSimpleFind', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(configuration.db);\n        const collection = db.collection('test_find_simple');\n        const docs = [{\n          a: 2\n        }, {\n          b: 3\n        }];\n\n        // Insert some test documents\n        collection.insert(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n\n          // Ensure correct insertion testing via the cursor and the count function\n          collection.find().toArray(function (err, documents) {\n            expect(err).to.not.exist;\n            test.equal(2, documents.length);\n            collection.count(function (err, count) {\n              expect(err).to.not.exist;\n              test.equal(2, count);\n\n              // Fetch values by selection\n              collection.find({\n                a: docs[0].a\n              }).toArray(function (err, documents) {\n                expect(err).to.not.exist;\n                test.equal(1, documents.length);\n                test.equal(docs[0].a, documents[0].a);\n                // Let's close the db\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformSimpleChainedFind","suites":["Find"],"updatePoint":{"line":82,"column":45,"index":2118},"line":82,"code":"  it('shouldCorrectlyPerformSimpleChainedFind', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_simple_chained', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_find_simple_chained');\n          const docs = [{\n            a: 2\n          }, {\n            b: 3\n          }];\n\n          // Insert some test documents\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n\n            // Ensure correct insertion testing via the cursor and the count function\n            collection.find().toArray(function (err, documents) {\n              test.equal(2, documents.length);\n              collection.count(function (err, count) {\n                test.equal(2, count);\n\n                // Fetch values by selection\n                collection.find({\n                  a: docs[0].a\n                }).toArray(function (err, documents) {\n                  test.equal(1, documents.length);\n                  test.equal(docs[0].a, documents[0].a);\n                  // Let's close the db\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformAdvancedFinds","suites":["Find"],"updatePoint":{"line":134,"column":41,"index":3782},"line":134,"code":"  it('shouldCorrectlyPerformAdvancedFinds', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('test_find_advanced');\n        const docs = [{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          b: 3\n        }];\n\n        // Insert some test documents\n        collection.insert(docs, configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n\n          // Locate by less than\n          collection.find({\n            a: {\n              $lt: 10\n            }\n          }).toArray(function (err, documents) {\n            test.equal(2, documents.length);\n            // Check that the correct documents are returned\n            var results = [];\n            // Check that we have all the results we want\n            documents.forEach(function (doc) {\n              if (doc.a === 1 || doc.a === 2) results.push(1);\n            });\n            test.equal(2, results.length);\n\n            // Locate by greater than\n            collection.find({\n              a: {\n                $gt: 1\n              }\n            }).toArray(function (err, documents) {\n              test.equal(1, documents.length);\n              test.equal(2, documents[0].a);\n\n              // Locate by less than or equal to\n              collection.find({\n                a: {\n                  $lte: 1\n                }\n              }).toArray(function (err, documents) {\n                test.equal(1, documents.length);\n                test.equal(1, documents[0].a);\n\n                // Locate by greater than or equal to\n                collection.find({\n                  a: {\n                    $gte: 1\n                  }\n                }).toArray(function (err, documents) {\n                  test.equal(2, documents.length);\n                  // Check that the correct documents are returned\n                  var results = [];\n                  // Check that we have all the results we want\n                  documents.forEach(function (doc) {\n                    if (doc.a === 1 || doc.a === 2) results.push(1);\n                  });\n                  test.equal(2, results.length);\n\n                  // Locate by between\n                  collection.find({\n                    a: {\n                      $gt: 1,\n                      $lt: 3\n                    }\n                  }).toArray(function (err, documents) {\n                    test.equal(1, documents.length);\n                    test.equal(2, documents[0].a);\n\n                    // Locate in clause\n                    collection.find({\n                      a: {\n                        $in: [1, 2]\n                      }\n                    }).toArray(function (err, documents) {\n                      test.equal(2, documents.length);\n                      // Check that the correct documents are returned\n                      var results = [];\n                      // Check that we have all the results we want\n                      documents.forEach(function (doc) {\n                        if (doc.a === 1 || doc.a === 2) results.push(1);\n                      });\n                      test.equal(2, results.length);\n\n                      // Locate in _id clause\n                      collection.find({\n                        _id: {\n                          $in: [docs[0]['_id'], docs[1]['_id']]\n                        }\n                      }).toArray(function (err, documents) {\n                        test.equal(2, documents.length);\n                        // Check that the correct documents are returned\n                        var results = [];\n                        // Check that we have all the results we want\n                        documents.forEach(function (doc) {\n                          if (doc.a === 1 || doc.a === 2) results.push(1);\n                        });\n                        test.equal(2, results.length);\n                        // Let's close the db\n                        client.close(done);\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformFindWithSort","suites":["Find"],"updatePoint":{"line":264,"column":40,"index":8326},"line":264,"code":"  it('shouldCorrectlyPerformFindWithSort', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_sorting', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_find_sorting');\n          // Insert some test documents\n          collection.insert([{\n            a: 1,\n            b: 2\n          }, {\n            a: 2,\n            b: 1\n          }, {\n            a: 3,\n            b: 2\n          }, {\n            a: 4,\n            b: 1\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Test sorting (ascending)\n            collection.find({\n              a: {\n                $lt: 10\n              }\n            }, {\n              sort: [['a', 1]]\n            }).toArray(function (err, documents) {\n              test.equal(4, documents.length);\n              test.equal(1, documents[0].a);\n              test.equal(2, documents[1].a);\n              test.equal(3, documents[2].a);\n              test.equal(4, documents[3].a);\n\n              // Test sorting (descending)\n              collection.find({\n                a: {\n                  $lt: 10\n                }\n              }, {\n                sort: [['a', -1]]\n              }).toArray(function (err, documents) {\n                test.equal(4, documents.length);\n                test.equal(4, documents[0].a);\n                test.equal(3, documents[1].a);\n                test.equal(2, documents[2].a);\n                test.equal(1, documents[3].a);\n\n                // Test sorting (descending), sort is hash\n                collection.find({\n                  a: {\n                    $lt: 10\n                  }\n                }, {\n                  sort: {\n                    a: -1\n                  }\n                }).toArray(function (err, documents) {\n                  test.equal(4, documents.length);\n                  test.equal(4, documents[0].a);\n                  test.equal(3, documents[1].a);\n                  test.equal(2, documents[2].a);\n                  test.equal(1, documents[3].a);\n\n                  // Sorting using array of names, assumes ascending order\n                  collection.find({\n                    a: {\n                      $lt: 10\n                    }\n                  }, {\n                    sort: ['a']\n                  }).toArray(function (err, documents) {\n                    test.equal(4, documents.length);\n                    test.equal(1, documents[0].a);\n                    test.equal(2, documents[1].a);\n                    test.equal(3, documents[2].a);\n                    test.equal(4, documents[3].a);\n\n                    // Sorting using single name, assumes ascending order\n                    collection.find({\n                      a: {\n                        $lt: 10\n                      }\n                    }, {\n                      sort: 'a'\n                    }).toArray(function (err, documents) {\n                      test.equal(4, documents.length);\n                      test.equal(1, documents[0].a);\n                      test.equal(2, documents[1].a);\n                      test.equal(3, documents[2].a);\n                      test.equal(4, documents[3].a);\n\n                      // Sorting using single name, assumes ascending order, sort is hash\n                      collection.find({\n                        a: {\n                          $lt: 10\n                        }\n                      }, {\n                        sort: {\n                          a: 1\n                        }\n                      }).toArray(function (err, documents) {\n                        test.equal(4, documents.length);\n                        test.equal(1, documents[0].a);\n                        test.equal(2, documents[1].a);\n                        test.equal(3, documents[2].a);\n                        test.equal(4, documents[3].a);\n                        collection.find({\n                          a: {\n                            $lt: 10\n                          }\n                        }, {\n                          sort: ['b', 'a']\n                        }).toArray(function (err, documents) {\n                          test.equal(4, documents.length);\n                          test.equal(2, documents[0].a);\n                          test.equal(4, documents[1].a);\n                          test.equal(1, documents[2].a);\n                          test.equal(3, documents[3].a);\n\n                          // Sorting using empty array, no order guarantee should not blow up\n                          collection.find({\n                            a: {\n                              $lt: 10\n                            }\n                          }, {\n                            sort: []\n                          }).toArray(function (err, documents) {\n                            test.equal(4, documents.length);\n\n                            /* NONACTUAL */\n                            // Sorting using ordered hash\n                            collection.find({\n                              a: {\n                                $lt: 10\n                              }\n                            }, {\n                              sort: {\n                                a: -1\n                              }\n                            }).toArray(function (err, documents) {\n                              // Fail test if not an error\n                              test.equal(4, documents.length);\n                              // Let's close the db\n                              client.close(done);\n                            });\n                          });\n                        });\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformFindWithLimit","suites":["Find"],"updatePoint":{"line":439,"column":41,"index":14614},"line":439,"code":"  it('shouldCorrectlyPerformFindWithLimit', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_limits', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_find_limits');\n          // Insert some test documents\n          collection.insert([{\n            a: 1\n          }, {\n            b: 2\n          }, {\n            c: 3\n          }, {\n            d: 4\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Test limits\n            collection.find({}, {\n              limit: 1\n            }).toArray(function (err, documents) {\n              test.equal(1, documents.length);\n              collection.find({}, {\n                limit: 2\n              }).toArray(function (err, documents) {\n                test.equal(2, documents.length);\n                collection.find({}, {\n                  limit: 3\n                }).toArray(function (err, documents) {\n                  test.equal(3, documents.length);\n                  collection.find({}, {\n                    limit: 4\n                  }).toArray(function (err, documents) {\n                    test.equal(4, documents.length);\n                    collection.find({}, {}).toArray(function (err, documents) {\n                      test.equal(4, documents.length);\n                      collection.find({}, {\n                        limit: 99\n                      }).toArray(function (err, documents) {\n                        test.equal(4, documents.length);\n                        // Let's close the db\n                        client.close(done);\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyFindWithNonQuotedValues","suites":["Find"],"updatePoint":{"line":507,"column":44,"index":16876},"line":507,"code":"  it('shouldCorrectlyFindWithNonQuotedValues', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_non_quoted_values', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_find_non_quoted_values');\n          // insert test document\n          collection.insert([{\n            a: 19,\n            b: 'teststring',\n            c: 59920303\n          }, {\n            a: '19',\n            b: 'teststring',\n            c: 3984929\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.find({\n              a: 19\n            }).toArray(function (err, documents) {\n              test.equal(1, documents.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyFindEmbeddedDocument","suites":["Find"],"updatePoint":{"line":549,"column":41,"index":18177},"line":549,"code":"  it('shouldCorrectlyFindEmbeddedDocument', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_embedded_document', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_find_embedded_document');\n          // insert test document\n          collection.insert([{\n            a: {\n              id: 10,\n              value: 'foo'\n            },\n            b: 'bar',\n            c: {\n              id: 20,\n              value: 'foobar'\n            }\n          }, {\n            a: {\n              id: 11,\n              value: 'foo'\n            },\n            b: 'bar2',\n            c: {\n              id: 20,\n              value: 'foobar'\n            }\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // test using integer value\n            collection.find({\n              'a.id': 10\n            }).toArray(function (err, documents) {\n              test.equal(1, documents.length);\n              test.equal('bar', documents[0].b);\n\n              // test using string value\n              collection.find({\n                'a.value': 'foo'\n              }).toArray(function (err, documents) {\n                // should yield 2 documents\n                test.equal(2, documents.length);\n                test.equal('bar', documents[0].b);\n                test.equal('bar2', documents[1].b);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyFindNoRecords","suites":["Find"],"updatePoint":{"line":616,"column":34,"index":20118},"line":616,"code":"  it('shouldCorrectlyFindNoRecords', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_one_no_records', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_find_one_no_records');\n          expect(err).to.not.exist;\n          collection.find({\n            a: 1\n          }, {}).toArray(function (err, documents) {\n            test.equal(0, documents.length);\n            // Let's close the db\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformFindByWhere","suites":["Find"],"updatePoint":{"line":644,"column":39,"index":21045},"line":644,"code":"  it('shouldCorrectlyPerformFindByWhere', {\n    metadata: {\n      requires: {\n        mongodb: '<=4.2.x',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_where', function (err, collection) {\n          collection.insert([{\n            a: 1\n          }, {\n            a: 2\n          }, {\n            a: 3\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.count(function (err, count) {\n              expect(err).to.not.exist;\n              test.equal(3, count);\n\n              // Let's test usage of the $where statement\n              collection.find({\n                $where: new Code('this.a > 2')\n              }).count(function (err, count) {\n                expect(err).to.not.exist;\n                test.equal(1, count);\n                collection.find({\n                  $where: new Code('this.a > i', {\n                    i: 1\n                  })\n                }).count(function (err, count) {\n                  expect(err).to.not.exist;\n                  test.equal(2, count);\n\n                  // Let's close the db\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformFindsWithHintTurnedOn","suites":["Find"],"updatePoint":{"line":695,"column":49,"index":22660},"line":695,"code":"  it('shouldCorrectlyPerformFindsWithHintTurnedOn', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_hint', function (err, collection) {\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            db.createIndex(collection.collectionName, 'a', configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist;\n              collection.find({\n                a: 1\n              }, {\n                hint: 'a'\n              }).toArray(function (err) {\n                test.ok(err != null);\n                collection.find({\n                  a: 1\n                }, {\n                  hint: ['a']\n                }).toArray(function (err, items) {\n                  expect(err).to.not.exist;\n                  test.equal(1, items.length);\n                  collection.find({\n                    a: 1\n                  }, {\n                    hint: {\n                      a: 1\n                    }\n                  }).toArray(function (err, items) {\n                    test.equal(1, items.length);\n\n                    // Modify hints\n                    collection.hint = 'a_1';\n                    test.equal('a_1', collection.hint);\n                    collection.find({\n                      a: 1\n                    }).toArray(function (err, items) {\n                      test.equal(1, items.length);\n                      collection.hint = ['a'];\n                      test.equal(1, collection.hint['a']);\n                      collection.find({\n                        a: 1\n                      }).toArray(function (err, items) {\n                        test.equal(1, items.length);\n                        collection.hint = {\n                          a: 1\n                        };\n                        test.equal(1, collection.hint['a']);\n                        collection.find({\n                          a: 1\n                        }).toArray(function (err, items) {\n                          test.equal(1, items.length);\n                          collection.hint = null;\n                          test.ok(collection.hint == null);\n                          collection.find({\n                            a: 1\n                          }).toArray(function (err, items) {\n                            test.equal(1, items.length);\n                            // Let's close the db\n                            client.close(done);\n                          });\n                        });\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformFindByObjectId","suites":["Find"],"updatePoint":{"line":779,"column":42,"index":25753},"line":779,"code":"  it('shouldCorrectlyPerformFindByObjectId', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_by_oid', (err, collection) => {\n          collection.insertOne({\n            hello: 'mike'\n          }, configuration.writeConcernMax(), (err, r) => {\n            expect(err).to.not.exist;\n            expect(r).property('insertedId').to.exist;\n            collection.findOne({\n              _id: r.insertedId\n            }, (err, doc) => {\n              test.equal('mike', doc.hello);\n              var id = doc._id.toString();\n              collection.findOne({\n                _id: new ObjectId(id)\n              }, (err, doc) => {\n                test.equal('mike', doc.hello);\n                // Let's close the db\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyReturnDocumentWithOriginalStructure","suites":["Find"],"updatePoint":{"line":817,"column":56,"index":27027},"line":817,"code":"  it('shouldCorrectlyReturnDocumentWithOriginalStructure', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_by_oid_with_subdocs', function (err, collection) {\n          var c1 = {\n            _id: new ObjectId(),\n            comments: [],\n            title: 'number 1'\n          };\n          var c2 = {\n            _id: new ObjectId(),\n            comments: [],\n            title: 'number 2'\n          };\n          var doc = {\n            numbers: [],\n            owners: [],\n            comments: [c1, c2],\n            _id: new ObjectId()\n          };\n          collection.insert(doc, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.findOne({\n              _id: doc._id\n            }, {\n              writeConcern: {\n                w: 1\n              },\n              projection: undefined\n            }, function (err, doc) {\n              expect(err).to.not.exist;\n              test.equal(2, doc.comments.length);\n              test.equal('number 1', doc.comments[0].title);\n              test.equal('number 2', doc.comments[1].title);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveSingleRecord","suites":["Find"],"updatePoint":{"line":868,"column":41,"index":28615},"line":868,"code":"  it('shouldCorrectlyRetrieveSingleRecord', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var p_client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      p_client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_should_correctly_retrieve_one_record', function (err, collection) {\n          collection.insert({\n            a: 0\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            const usercollection = db.collection('test_should_correctly_retrieve_one_record');\n            usercollection.findOne({\n              a: 0\n            }, function (err) {\n              expect(err).to.not.exist;\n              p_client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleError","suites":["Find"],"updatePoint":{"line":898,"column":32,"index":29638},"line":898,"code":"  it('shouldCorrectlyHandleError', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_one_error_handling', function (err, collection) {\n          // Try to fetch an object using a totally invalid and wrong hex string... what we're interested in here\n          // is the error handling of the findOne Method\n          try {\n            collection.findOne({\n              _id: ObjectId.createFromHexString('5e9bd59248305adf18ebc15703a1')\n            }, function () {});\n          } catch (err) {\n            client.close(done);\n          }\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformFindWithOptions","suites":["Find"],"updatePoint":{"line":929,"column":43,"index":30669},"line":929,"code":"  it('shouldCorrectlyPerformFindWithOptions', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_field_select_with_options', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_field_select_with_options');\n          var docCount = 25,\n            docs = [];\n\n          // Insert some test documents\n          while (docCount--) docs.push({\n            a: docCount,\n            b: docCount\n          });\n          collection.insert(docs, configuration.writeConcernMax(), function (err, retDocs) {\n            docs = retDocs;\n            collection.find({}, {\n              limit: 3,\n              sort: [['a', -1]],\n              projection: {\n                a: 1\n              }\n            }).toArray(function (err, documents) {\n              test.equal(3, documents.length);\n              documents.forEach(function (doc, idx) {\n                expect(doc.b).to.not.exist; // making sure field select works\n                test.equal(24 - idx, doc.a); // checking limit sort object with field select\n              });\n\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyfindOneAndUpdateDocument","suites":["Find"],"updatePoint":{"line":979,"column":45,"index":32286},"line":979,"code":"  it('shouldCorrectlyfindOneAndUpdateDocument', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_and_modify_a_document_1', function (err, collection) {\n          // Test return new document on change\n          collection.insert({\n            a: 1,\n            b: 2\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Let's modify the document in place\n            collection.findOneAndUpdate({\n              a: 1\n            }, {\n              $set: {\n                b: 3\n              }\n            }, {\n              returnDocument: ReturnDocument.AFTER\n            }, function (err, updated_doc) {\n              test.equal(1, updated_doc.value.a);\n              test.equal(3, updated_doc.value.b);\n\n              // Test return old document on change\n              collection.insert({\n                a: 2,\n                b: 2\n              }, configuration.writeConcernMax(), function (err) {\n                expect(err).to.not.exist;\n\n                // Let's modify the document in place\n                collection.findOneAndUpdate({\n                  a: 2\n                }, {\n                  $set: {\n                    b: 3\n                  }\n                }, configuration.writeConcernMax(), function (err, result) {\n                  test.equal(2, result.value.a);\n                  test.equal(2, result.value.b);\n\n                  // Test remove object on change\n                  collection.insert({\n                    a: 3,\n                    b: 2\n                  }, configuration.writeConcernMax(), function (err) {\n                    expect(err).to.not.exist;\n                    // Let's modify the document in place\n                    collection.findOneAndUpdate({\n                      a: 3\n                    }, {\n                      $set: {\n                        b: 3\n                      }\n                    }, {\n                      remove: true\n                    }, function (err, updated_doc) {\n                      test.equal(3, updated_doc.value.a);\n                      test.equal(2, updated_doc.value.b);\n\n                      // Let's upsert!\n                      collection.findOneAndUpdate({\n                        a: 4\n                      }, {\n                        $set: {\n                          b: 3\n                        }\n                      }, {\n                        returnDocument: ReturnDocument.AFTER,\n                        upsert: true\n                      }, function (err, updated_doc) {\n                        test.equal(4, updated_doc.value.a);\n                        test.equal(3, updated_doc.value.b);\n\n                        // Test selecting a subset of fields\n                        collection.insert({\n                          a: 100,\n                          b: 101\n                        }, configuration.writeConcernMax(), function (err, r) {\n                          expect(err).to.not.exist;\n                          collection.findOneAndUpdate({\n                            a: 100\n                          }, {\n                            $set: {\n                              b: 5\n                            }\n                          }, {\n                            returnDocument: ReturnDocument.AFTER,\n                            projection: {\n                              b: 1\n                            }\n                          }, function (err, updated_doc) {\n                            test.equal(2, Object.keys(updated_doc.value).length);\n                            test.equal(r.insertedIds[0].toHexString(), updated_doc.value._id.toHexString());\n                            test.equal(5, updated_doc.value.b);\n                            test.equal('undefined', typeof updated_doc.value.a);\n                            client.close(done);\n                          });\n                        });\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyfindOneAndUpdateDocumentAndReturnSelectedFieldsOnly","suites":["Find"],"updatePoint":{"line":1104,"column":72,"index":36848},"line":1104,"code":"  it('shouldCorrectlyfindOneAndUpdateDocumentAndReturnSelectedFieldsOnly', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_and_modify_a_document_2', function (err, collection) {\n          // Test return new document on change\n          collection.insert({\n            a: 1,\n            b: 2\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Let's modify the document in place\n            collection.findOneAndUpdate({\n              a: 1\n            }, {\n              $set: {\n                b: 3\n              }\n            }, {\n              returnDocument: ReturnDocument.AFTER,\n              projection: {\n                a: 1\n              }\n            }, function (err, updated_doc) {\n              test.equal(2, Object.keys(updated_doc.value).length);\n              test.equal(1, updated_doc.value.a);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"ShouldCorrectlyLocatePostAndIncValues","suites":["Find"],"updatePoint":{"line":1147,"column":43,"index":38196},"line":1147,"code":"  it('ShouldCorrectlyLocatePostAndIncValues', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('shouldCorrectlyExecuteFindOneWithAnInSearchTag', function (err, collection) {\n          // Test return new document on change\n          collection.insert({\n            title: 'Tobi',\n            author: 'Brian',\n            newTitle: 'Woot',\n            meta: {\n              visitors: 0\n            }\n          }, configuration.writeConcernMax(), function (err, r) {\n            // Fetch the id\n            var id = r.insertedIds[0];\n            collection.update({\n              _id: id\n            }, {\n              $inc: {\n                'meta.visitors': 1\n              }\n            }, configuration.writeConcernMax(), function (err, r) {\n              expect(r).property('matchedCount').to.equal(1);\n              expect(err).to.not.exist;\n              collection.findOne({\n                _id: id\n              }, function (err, item) {\n                test.equal(1, item.meta.visitors);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly Handle findOneAndUpdate Duplicate Key Error","suites":["Find"],"updatePoint":{"line":1197,"column":66,"index":39773},"line":1197,"code":"  it('Should Correctly Handle findOneAndUpdate Duplicate Key Error', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(configuration.db);\n        db.createCollection('findOneAndUpdateDuplicateKeyError', function (err, collection) {\n          expect(err).to.not.exist;\n          collection.createIndex(['name', 1], {\n            unique: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n            // Test return new document on change\n            collection.insert([{\n              name: 'test1'\n            }, {\n              name: 'test2'\n            }], configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist;\n              // Let's modify the document in place\n              collection.findOneAndUpdate({\n                name: 'test1'\n              }, {\n                $set: {\n                  name: 'test2'\n                }\n              }, {}, function (err, updated_doc) {\n                expect(err).to.exist;\n                expect(updated_doc).to.not.exist;\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly return null when attempting to modify a non-existing document","suites":["Find"],"updatePoint":{"line":1245,"column":84,"index":41376},"line":1245,"code":"  it('Should correctly return null when attempting to modify a non-existing document', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('AttemptTofindOneAndUpdateNonExistingDocument', function (err, collection) {\n          // Let's modify the document in place\n          collection.findOneAndUpdate({\n            name: 'test1'\n          }, {\n            $set: {\n              name: 'test2'\n            }\n          }, {}, function (err, updated_doc) {\n            expect(updated_doc.value).to.not.exist;\n            test.ok(err == null || err.errmsg.match('No matching object found'));\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly handle chained skip and limit on find with toArray","suites":["Find"],"updatePoint":{"line":1275,"column":73,"index":42420},"line":1275,"code":"  it('Should correctly handle chained skip and limit on find with toArray', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('skipAndLimitOnFindWithToArray', function (err, collection) {\n          collection.insert([{\n            a: 1\n          }, {\n            b: 2\n          }, {\n            c: 3\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.find().skip(1).limit(-1).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(1, items.length);\n              test.equal(2, items[0].b);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly handle chained skip and negative limit on find with toArray","suites":["Find"],"updatePoint":{"line":1308,"column":82,"index":43522},"line":1308,"code":"  it('Should correctly handle chained skip and negative limit on find with toArray', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('skipAndNegativeLimitOnFindWithToArray', function (err, collection) {\n          collection.insert([{\n            a: 1\n          }, {\n            b: 2\n          }, {\n            c: 3\n          }, {\n            d: 4\n          }, {\n            e: 5\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.find().skip(1).limit(-3).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(3, items.length);\n              test.equal(2, items[0].b);\n              test.equal(3, items[1].c);\n              test.equal(4, items[2].d);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"should support a timeout option for find operations","suites":["Find"],"updatePoint":{"line":1347,"column":57,"index":44753},"line":1347,"code":"  it('should support a timeout option for find operations', async function () {\n    const client = this.configuration.newClient({\n      monitorCommands: true\n    });\n    const events = [];\n    client.on('commandStarted', event => {\n      if (event.commandName === 'find') {\n        events.push(event);\n      }\n    });\n    const db = client.db(this.configuration.db);\n    const collection = await db.createCollection('cursor_timeout_false_0');\n    await collection.find({}, {\n      timeout: false\n    }).toArray();\n    expect(events[0]).nested.property('command.noCursorTimeout').to.equal(true);\n    await client.close();\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"should correctly findOneAndUpdate document with DB strict","suites":["Find"],"updatePoint":{"line":1365,"column":63,"index":45386},"line":1365,"code":"  it('should correctly findOneAndUpdate document with DB strict', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var p_client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      p_client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('shouldCorrectlyfindOneAndUpdateDocumentWithDBStrict', function (err, collection) {\n          // Test return old document on change\n          collection.insert({\n            a: 2,\n            b: 2\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Let's modify the document in place\n            collection.findOneAndUpdate({\n              a: 2\n            }, {\n              $set: {\n                b: 3\n              }\n            }, {\n              returnDocument: ReturnDocument.AFTER\n            }, function (err, result) {\n              test.equal(2, result.value.a);\n              test.equal(3, result.value.b);\n              p_client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyfindOneAndUpdateDocumentThatFailsInFirstStep","suites":["Find"],"updatePoint":{"line":1409,"column":65,"index":46769},"line":1409,"code":"  it('shouldCorrectlyfindOneAndUpdateDocumentThatFailsInFirstStep', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(configuration.db);\n        db.createCollection('shouldCorrectlyfindOneAndUpdateDocumentThatFailsInFirstStep', function (err, collection) {\n          expect(err).to.not.exist;\n          // Set up an index to force duplicate index erro\n          collection.createIndex([['failIndex', 1]], {\n            unique: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n\n            // Setup a new document\n            collection.insert({\n              a: 2,\n              b: 2,\n              failIndex: 2\n            }, configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist;\n\n              // Let's attempt to upsert with a duplicate key error\n              collection.findOneAndUpdate({\n                c: 2\n              }, {\n                $set: {\n                  a: 10,\n                  b: 10,\n                  failIndex: 2\n                }\n              }, {\n                writeConcern: {\n                  w: 1\n                },\n                upsert: true\n              }, function (err, result) {\n                expect(result).to.not.exist;\n                expect(err).property('errmsg').to.match(/duplicate key/);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly return new modified document","suites":["Find"],"updatePoint":{"line":1467,"column":51,"index":48611},"line":1467,"code":"  it('Should correctly return new modified document', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('Should_correctly_return_new_modified_document', function (err, collection) {\n          var id = new ObjectId();\n          var doc = {\n            _id: id,\n            a: 1,\n            b: 1,\n            c: {\n              a: 1,\n              b: 1\n            }\n          };\n          collection.insert(doc, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Find and modify returning the new object\n            collection.findOneAndUpdate({\n              _id: id\n            }, {\n              $set: {\n                'c.c': 100\n              }\n            }, {\n              returnDocument: ReturnDocument.AFTER\n            }, function (err, item) {\n              test.equal(doc._id.toString(), item.value._id.toString());\n              test.equal(doc.a, item.value.a);\n              test.equal(doc.b, item.value.b);\n              test.equal(doc.c.a, item.value.c.a);\n              test.equal(doc.c.b, item.value.c.b);\n              test.equal(100, item.value.c.c);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecutefindOneAndUpdate","suites":["Find"],"updatePoint":{"line":1521,"column":44,"index":50301},"line":1521,"code":"  it('shouldCorrectlyExecutefindOneAndUpdate', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('execute_find_and_modify', function (err, collection) {\n          var self = {\n            _id: new ObjectId()\n          };\n          var _uuid = 'sddffdss';\n          collection.findOneAndUpdate({\n            _id: self._id,\n            'plays.uuid': _uuid\n          }, {\n            $set: {\n              'plays.$.active': true\n            }\n          }, {\n            returnDocument: ReturnDocument.AFTER,\n            projection: {\n              plays: 0,\n              results: 0\n            },\n            safe: true\n          }, function (err) {\n            expect(err).to.not.exist;\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly return record with 64-bit id","suites":["Find"],"updatePoint":{"line":1561,"column":51,"index":51463},"line":1561,"code":"  it('Should correctly return record with 64-bit id', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('should_correctly_return_record_with_64bit_id', function (err, collection) {\n          var _lowerId = new ObjectId();\n          var _higherId = new ObjectId();\n          var lowerId = Long.fromString('133118461172916224', 10);\n          var higherId = Long.fromString('133118461172916225', 10);\n          var lowerDoc = {\n            _id: _lowerId,\n            id: lowerId\n          };\n          var higherDoc = {\n            _id: _higherId,\n            id: higherId\n          };\n          collection.insert([lowerDoc, higherDoc], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Select record with id of 133118461172916225 using $gt directive\n            collection.find({\n              id: {\n                $gt: lowerId\n              }\n            }, {}).toArray(function (err, arr) {\n              test.ok(err == null);\n              test.equal(arr.length, 1, 'Selecting record via $gt directive on 64-bit integer should return a record with higher Id');\n              test.equal(arr[0].id.toString(), '133118461172916225', 'Returned Id should be equal to 133118461172916225');\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly find a Document using findOne excluding _id field","suites":["Find"],"updatePoint":{"line":1606,"column":72,"index":53212},"line":1606,"code":"  it('Should Correctly find a Document using findOne excluding _id field', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var p_client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      p_client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('Should_Correctly_find_a_Document_using_findOne_excluding__id_field', function (err, collection) {\n          var doc = {\n            _id: new ObjectId(),\n            a: 1,\n            c: 2\n          };\n          // insert doc\n          collection.insert(doc, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Get one document, excluding the _id field\n            collection.findOne({\n              a: 1\n            }, {\n              projection: {\n                _id: 0\n              }\n            }, function (err, item) {\n              expect(item._id).to.not.exist;\n              test.equal(1, item.a);\n              test.equal(2, item.c);\n              collection.find({\n                a: 1\n              }, {\n                projection: {\n                  _id: 0\n                }\n              }).toArray(function (err, items) {\n                var item = items[0];\n                expect(item._id).to.not.exist;\n                test.equal(1, item.a);\n                test.equal(2, item.c);\n                p_client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute find queries with selector set to null","suites":["Find"],"updatePoint":{"line":1659,"column":69,"index":54901},"line":1659,"code":"  it('Should correctly execute find queries with selector set to null', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('Should_correctly_execute_find_and_findOne_queries_in_the_same_way', function (err, collection) {\n          var doc = {\n            _id: new ObjectId(),\n            a: 1,\n            c: 2,\n            comments: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n          };\n          // insert doc\n          collection.insert(doc, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.find({\n              _id: doc._id\n            }).project({\n              comments: {\n                $slice: -5\n              }\n            }).toArray(function (err, docs) {\n              test.equal(5, docs[0].comments.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandlerErrorForfindOneAndUpdateWhenNoRecordExists","suites":["Find"],"updatePoint":{"line":1697,"column":70,"index":56162},"line":1697,"code":"  it('shouldCorrectlyHandlerErrorForfindOneAndUpdateWhenNoRecordExists', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('shouldCorrectlyHandlerErrorForfindOneAndUpdateWhenNoRecordExists', function (err, collection) {\n          collection.findOneAndUpdate({\n            a: 1\n          }, {\n            $set: {\n              b: 3\n            }\n          }, {\n            returnDocument: ReturnDocument.AFTER\n          }, function (err, updated_doc) {\n            expect(err).to.not.exist;\n            expect(updated_doc.value).to.not.exist;\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecutefindOneAndUpdateShouldGenerateCorrectBSON","suites":["Find"],"updatePoint":{"line":1728,"column":69,"index":57172},"line":1728,"code":"  it('shouldCorrectlyExecutefindOneAndUpdateShouldGenerateCorrectBSON', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var transaction = {};\n        transaction.document = {};\n        transaction.document.type = 'documentType';\n        transaction.document.id = new ObjectId();\n        transaction.transactionId = new ObjectId();\n        transaction.amount = 12.3333;\n        var transactions = [];\n        transactions.push(transaction);\n        // Wrapping object\n        var wrapingObject = {\n          funds: {\n            remaining: 100.5\n          },\n          transactions: transactions\n        };\n        db.createCollection('find_and_modify_generate_correct_bson', function (err, collection) {\n          expect(err).to.not.exist;\n          collection.insert(wrapingObject, configuration.writeConcernMax(), function (err, r) {\n            expect(err).to.not.exist;\n            collection.findOne({\n              _id: r.insertedIds[0],\n              'funds.remaining': {\n                $gte: 3.0\n              },\n              'transactions.id': {\n                $ne: transaction.transactionId\n              }\n            }, function (err, item) {\n              test.ok(item != null);\n              collection.findOneAndUpdate({\n                _id: r.insertedIds[0],\n                'funds.remaining': {\n                  $gte: 3.0\n                },\n                'transactions.id': {\n                  $ne: transaction.transactionId\n                }\n              }, {\n                $push: {\n                  transactions: transaction\n                }\n              }, {\n                returnDocument: ReturnDocument.AFTER,\n                safe: true\n              }, function (err) {\n                expect(err).to.not.exist;\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteMultipleFindsInParallel","suites":["Find"],"updatePoint":{"line":1795,"column":51,"index":59391},"line":1795,"code":"  it('shouldCorrectlyExecuteMultipleFindsInParallel', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var p_client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      p_client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('tasks', function (err, collection) {\n          var numberOfOperations = 0;\n\n          // Test return old document on change\n          collection.insert({\n            a: 2,\n            b: 2\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.find({\n              user_id: '4e9fc8d55883d90100000003',\n              lc_status: {\n                $ne: 'deleted'\n              },\n              owner_rating: {\n                $exists: false\n              }\n            }, {\n              skip: 0,\n              limit: 10,\n              sort: {\n                updated: -1\n              }\n            }).count(function (err) {\n              expect(err).to.not.exist;\n              numberOfOperations = numberOfOperations + 1;\n              if (numberOfOperations === 2) {\n                p_client.close(done);\n              }\n            });\n            collection.find({\n              user_id: '4e9fc8d55883d90100000003',\n              lc_status: {\n                $ne: 'deleted'\n              },\n              owner_rating: {\n                $exists: false\n              }\n            }, {\n              skip: 0,\n              limit: 10,\n              sort: {\n                updated: -1\n              }\n            }).count(function (err) {\n              expect(err).to.not.exist;\n              numberOfOperations = numberOfOperations + 1;\n              if (numberOfOperations === 2) {\n                p_client.close(done);\n              }\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyReturnErrorFromMongodbOnfindOneAndUpdateForcedError","suites":["Find"],"updatePoint":{"line":1864,"column":72,"index":61482},"line":1864,"code":"  it('shouldCorrectlyReturnErrorFromMongodbOnfindOneAndUpdateForcedError', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('shouldCorrectlyReturnErrorFromMongodbOnfindOneAndUpdateForcedError', function (err, collection) {\n          var q = {\n            x: 1\n          };\n          var set = {\n            y: 2,\n            _id: new ObjectId()\n          };\n          var opts = {\n            returnDocument: ReturnDocument.AFTER,\n            upsert: true\n          };\n          // Original doc\n          var doc = {\n            _id: new ObjectId(),\n            x: 1\n          };\n\n          // Insert original doc\n          collection.insert(doc, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.findOneAndUpdate(q, {\n              $set: set\n            }, opts, function /* err */\n            () {\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecutefindOneAndUpdateUnderConcurrentLoad","suites":["Find"],"updatePoint":{"line":1909,"column":63,"index":62822},"line":1909,"code":"  it('shouldCorrectlyExecutefindOneAndUpdateUnderConcurrentLoad', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var p_client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var running = true;\n      p_client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        // Create a collection\n        db.createCollection('collection1', function (err, collection) {\n          // Wait a bit and then execute something that will throw a duplicate error\n          setTimeout(function () {\n            var id = new ObjectId();\n            collection.insert({\n              _id: id,\n              a: 1\n            }, configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist;\n              collection.insert({\n                _id: id,\n                a: 1\n              }, configuration.writeConcernMax(), function (err) {\n                test.ok(err !== null);\n                running = false;\n                p_client.close(done);\n              });\n            });\n          }, 200);\n        });\n        db.createCollection('collection2', function (err, collection) {\n          // Keep hammering in inserts\n          var insert;\n          insert = function () {\n            process.nextTick(function () {\n              collection.insert({\n                a: 1\n              });\n              if (running) process.nextTick(insert);\n            });\n          };\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyIterateOverCollection","suites":["Find"],"line":1961,"code":"  it.skip('shouldCorrectlyIterateOverCollection', {","file":"integration/crud/find.test.js","skipped":true,"dir":"test"},{"name":"shouldCorrectlyErrorOutfindOneAndUpdateOnDuplicateRecord","suites":["Find"],"updatePoint":{"line":2011,"column":62,"index":66058},"line":2011,"code":"  it('shouldCorrectlyErrorOutfindOneAndUpdateOnDuplicateRecord', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var p_client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      p_client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        db.createCollection('shouldCorrectlyErrorOutfindOneAndUpdateOnDuplicateRecord', function (err, collection) {\n          expect(err).to.not.exist;\n\n          // Test return old document on change\n          collection.insert([{\n            login: 'user1'\n          }, {\n            login: 'user2'\n          }], configuration.writeConcernMax(), function (err, r) {\n            expect(err).to.not.exist;\n            var id = r.insertedIds[1];\n            // Set an index\n            collection.createIndex('login', {\n              unique: true,\n              writeConcern: {\n                w: 1\n              }\n            }, function (err) {\n              expect(err).to.not.exist;\n\n              // Attemp to modify document\n              collection.findOneAndUpdate({\n                _id: id\n              }, {\n                $set: {\n                  login: 'user1'\n                }\n              }, {}, function (err) {\n                test.ok(err !== null);\n                p_client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformSimpleFindInArray","suites":["Find"],"updatePoint":{"line":2066,"column":36,"index":67710},"line":2066,"code":"  it('shouldPerformSimpleFindInArray', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n\n        // Create a collection we want to drop later\n        db.createCollection('simple_find_in_array', function (err, collection) {\n          expect(err).to.not.exist;\n          var docs = [];\n          for (var i = 0; i < 100; i++) docs.push({\n            a: i\n          });\n\n          // Insert some test documentations\n          collection.insert(docs, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Find all the variables in a specific array\n            for (var i = 0; i < 100; i++) docs.push(i);\n\n            // Fin all in\n            collection.find({\n              a: {\n                $in: docs\n              }\n            }).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(100, items.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldReturnInstanceofErrorWithBadFieldSelection","suites":["Find"],"updatePoint":{"line":2110,"column":54,"index":69088},"line":2110,"code":"  it('shouldReturnInstanceofErrorWithBadFieldSelection', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        var col = db.collection('bad_field_selection');\n        col.insert([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          col.find({}, {\n            skip: 1,\n            limit: 1,\n            projection: {\n              a: 1,\n              b: 0\n            }\n          }).toArray(function (err) {\n            test.ok(err instanceof Error);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleLimitSkipFindWithFields","suites":["Find"],"updatePoint":{"line":2155,"column":49,"index":70243},"line":2155,"code":"  it('shouldPerformASimpleLimitSkipFindWithFields', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n\n        // Create a collection we want to drop later\n        db.createCollection('simple_find_with_fields', function (err, collection) {\n          expect(err).to.not.exist;\n\n          // Insert a bunch of documents for the testing\n          collection.insert([{\n            a: 1,\n            b: 1\n          }, {\n            a: 2,\n            b: 2\n          }, {\n            a: 3,\n            b: 3\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Perform a simple find and return all the documents\n            collection.find({\n              a: 2\n            }).project({\n              b: 1\n            }).toArray(function (err, docs) {\n              expect(err).to.not.exist;\n              test.equal(1, docs.length);\n              expect(docs[0].a).to.not.exist;\n              test.equal(2, docs[0].b);\n\n              // Perform a simple find and return all the documents\n              collection.find({\n                a: 2\n              }).project({\n                b: 1\n              }).toArray(function (err, docs) {\n                expect(err).to.not.exist;\n                test.equal(1, docs.length);\n                expect(docs[0].a).to.not.exist;\n                test.equal(2, docs[0].b);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleLimitSkipFindWithFields2","suites":["Find"],"updatePoint":{"line":2219,"column":50,"index":72148},"line":2219,"code":"  it('shouldPerformASimpleLimitSkipFindWithFields2', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n\n        // Create a collection we want to drop later\n        db.createCollection('simple_find_with_fields_2', function (err, collection) {\n          expect(err).to.not.exist;\n\n          // Insert a bunch of documents for the testing\n          collection.insert([{\n            a: 1,\n            b: 1\n          }, {\n            a: 2,\n            b: 2\n          }, {\n            a: 3,\n            b: 3\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Perform a simple find and return all the documents\n            collection.find({\n              a: 2\n            }).project({\n              b: 1\n            }).toArray(function (err, docs) {\n              expect(err).to.not.exist;\n              test.equal(1, docs.length);\n              expect(docs[0].a).to.not.exist;\n              test.equal(2, docs[0].b);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformQueryWithBatchSizeDifferentToStandard","suites":["Find"],"updatePoint":{"line":2271,"column":56,"index":73652},"line":2271,"code":"  it('shouldPerformQueryWithBatchSizeDifferentToStandard', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n\n        // Create a collection we want to drop later\n        db.createCollection('shouldPerformQueryWithBatchSizeDifferentToStandard', function (err, collection) {\n          expect(err).to.not.exist;\n          var docs = [];\n          for (var i = 0; i < 1000; i++) {\n            docs.push({\n              a: i\n            });\n          }\n\n          // Insert a bunch of documents for the testing\n          collection.insert(docs, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Perform a simple find and return all the documents\n            collection.find({}, {\n              batchSize: 1000\n            }).toArray(function (err, docs) {\n              expect(err).to.not.exist;\n              test.equal(1000, docs.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformNegativeLimit","suites":["Find"],"updatePoint":{"line":2316,"column":41,"index":75040},"line":2316,"code":"  it('shouldCorrectlyPerformNegativeLimit', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n\n        // Create a collection we want to drop later\n        const collection = db.collection('shouldCorrectlyPerformNegativeLimit');\n        var docs = [];\n        for (var i = 0; i < 1000; i++) {\n          docs.push({\n            a: 1,\n            b: 'helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld'\n          });\n        }\n\n        // Insert a bunch of documents\n        collection.insert(docs, configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n\n          // Perform a simple find and return all the documents\n          collection.find({}).limit(-10).toArray(function (err, docs) {\n            expect(err).to.not.exist;\n            test.equal(10, docs.length);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteExhaustQuery","suites":["Find"],"updatePoint":{"line":2358,"column":40,"index":76393},"line":2358,"code":"  it('shouldCorrectlyExecuteExhaustQuery', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n\n        // Create a collection we want to drop later\n        db.createCollection('shouldCorrectlyExecuteExhaustQuery', function (err, collection) {\n          expect(err).to.not.exist;\n          var docs1 = [];\n          for (var i = 0; i < 1000; i++) {\n            docs1.push({\n              a: 1,\n              b: 'helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld',\n              c: new Binary(Buffer.alloc(1024))\n            });\n          }\n\n          // Insert a bunch of documents\n          collection.insert(docs1, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            for (var i = 0; i < 1000; i++) {\n              var docs2 = [];\n              docs2.push({\n                a: 1,\n                b: 'helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld',\n                c: new Binary(Buffer.alloc(1024))\n              });\n            }\n            collection.insert(docs2, configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist;\n\n              // Perform a simple find and return all the documents\n              collection.find({}, {\n                exhaust: true\n              }).toArray(function (err, docs3) {\n                expect(err).to.not.exist;\n                test.equal(docs1.length + docs2.length, docs3.length);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Readpreferences should work fine when using a single server instance","suites":["Find"],"updatePoint":{"line":2412,"column":74,"index":78391},"line":2412,"code":"  it('Readpreferences should work fine when using a single server instance', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        var docs = [];\n        for (var i = 0; i < 1; i++) {\n          docs.push({\n            a: 1,\n            b: 'helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld'\n          });\n        }\n\n        // Create a collection we want to drop later\n        db.createCollection('Readpreferencesshouldworkfine', function (err, collection) {\n          // Insert a bunch of documents\n          collection.insert(docs, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            // Perform a simple find and return all the documents\n            collection.find({}, {\n              exhaust: true\n            }).toArray(function (err, docs2) {\n              expect(err).to.not.exist;\n              test.equal(docs.length, docs2.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Each should not hang on iterating over no results","suites":["Find"],"updatePoint":{"line":2452,"column":55,"index":79819},"line":2452,"code":"  it('Each should not hang on iterating over no results', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        // Create a collection we want to drop later\n        const collection = db.collection('noresultAvailableForEachToIterate');\n        // Perform a simple find and return all the documents\n        collection.find({}).forEach(doc => {\n          expect(doc).to.not.exist;\n        }, err => {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyFindDocumentsByRegExp","suites":["Find"],"updatePoint":{"line":2478,"column":42,"index":80704},"line":2478,"code":"  it('shouldCorrectlyFindDocumentsByRegExp', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        // Serialized regexes contain extra trailing chars. Sometimes these trailing chars contain / which makes\n        // the original regex invalid, and leads to segmentation fault.\n        db.createCollection('test_regex_serialization', function (err, collection) {\n          collection.insert({\n            keywords: ['test', 'segmentation', 'fault', 'regex', 'serialization', 'native']\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            let count = 0;\n            for (let i = 0; i <= 20; ++i) {\n              // search by regex\n              collection.findOne({\n                keywords: {\n                  $all: [/ser/, /test/, /seg/, /fault/, /nat/]\n                }\n              }, function (err, item) {\n                expect(err).to.not.exist;\n                expect(item).property('keywords').to.have.length(6);\n                if (count++ === 20) {\n                  client.close(done);\n                }\n              });\n            }\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDoFindMinMax","suites":["Find"],"updatePoint":{"line":2518,"column":33,"index":82177},"line":2518,"code":"  it('shouldCorrectlyDoFindMinMax', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        // Serialized regexes contain extra trailing chars. Sometimes these trailing chars contain / which makes\n        // the original regex invalid, and leads to segmentation fault.\n        db.createCollection('shouldCorrectlyDoFindMinMax', function (err, collection) {\n          collection.insert({\n            _id: 123,\n            name: 'some name',\n            min: 1,\n            max: 10\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.find({\n              _id: {\n                $in: ['some', 'value', 123]\n              }\n            }).project({\n              _id: 1,\n              max: 1\n            }).toArray(function (err, docs) {\n              expect(err).to.not.exist;\n              test.equal(10, docs[0].max);\n              collection.find({\n                _id: {\n                  $in: ['some', 'value', 123]\n                }\n              }, {\n                projection: {\n                  _id: 1,\n                  max: 1\n                }\n              }).toArray(function (err, docs) {\n                expect(err).to.not.exist;\n                test.equal(10, docs[0].max);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly sort using text search on 2.6 or higher in find","suites":["Find"],"updatePoint":{"line":2571,"column":70,"index":83956},"line":2571,"code":"  it('Should correctly sort using text search on 2.6 or higher in find', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.5.5',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n\n        // Get the collection\n        var collection = db.collection('textSearchWithSort');\n        collection.createIndex({\n          s: 'text'\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.insert([{\n            s: 'spam'\n          }, {\n            s: 'spam eggs and spam'\n          }, {\n            s: 'sausage and eggs'\n          }], function (err) {\n            expect(err).to.not.exist;\n            collection.find({\n              $text: {\n                $search: 'spam'\n              }\n            }, {\n              projection: {\n                _id: false,\n                s: true,\n                score: {\n                  $meta: 'textScore'\n                }\n              }\n            }).sort({\n              score: {\n                $meta: 'textScore'\n              }\n            }).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal('spam eggs and spam', items[0].s);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldNotMutateUserOptions","suites":["Find"],"updatePoint":{"line":2628,"column":32,"index":85628},"line":2628,"code":"  it('shouldNotMutateUserOptions', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('shouldNotMutateUserOptions');\n        var options = {\n          raw: 'TEST'\n        };\n        collection.find({}, options);\n        expect(options.skip).to.not.exist;\n        expect(options.limit).to.not.exist;\n        test.equal('TEST', options.raw);\n        client.close(done);\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute a findOneAndUpdateWithAWriteConcern","suites":["Find"],"updatePoint":{"line":2657,"column":66,"index":86534},"line":2657,"code":"  it('should correctly execute a findOneAndUpdateWithAWriteConcern', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_and_modify_a_document_3', function (err, collection) {\n          // Test return new document on change\n          collection.insert({\n            a: 1,\n            b: 2\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Let's modify the document in place\n            collection.findOneAndUpdate({\n              a: 1\n            }, {\n              $set: {\n                b: 3\n              }\n            }, {\n              returnDocument: ReturnDocument.AFTER\n            }, function (err, updated_doc) {\n              test.equal(1, updated_doc.value.a);\n              test.equal(3, updated_doc.value.b);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"should execute query using batchSize of 0","suites":["Find"],"updatePoint":{"line":2701,"column":47,"index":87839},"line":2701,"code":"  it('should execute query using batchSize of 0', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        const collection = db.collection('test_find_simple_batchsize_0');\n        // Insert some test documents\n        collection.insert([{\n          a: 2\n        }, {\n          b: 3\n        }, {\n          b: 4\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          // Ensure correct insertion testing via the cursor and the count function\n          collection.find().batchSize(-5).toArray(function (err, documents) {\n            expect(err).to.not.exist;\n            test.equal(3, documents.length);\n            // Let's close the db\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"should execute query using limit of 0","suites":["Find"],"updatePoint":{"line":2739,"column":43,"index":89002},"line":2739,"code":"  it('should execute query using limit of 0', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        const collection = db.collection('test_find_simple_limit_0');\n\n        // Insert some test documents\n        collection.insert([{\n          a: 2\n        }, {\n          b: 3\n        }, {\n          b: 4\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          // Ensure correct insertion testing via the cursor and the count function\n          collection.find().limit(-5).toArray(function (err, documents) {\n            expect(err).to.not.exist;\n            test.equal(3, documents.length);\n\n            // Let's close the db\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"should execute query using $elemMatch","suites":["Find"],"updatePoint":{"line":2779,"column":43,"index":90159},"line":2779,"code":"  it('should execute query using $elemMatch', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        const collection = db.collection('elem_match_test');\n        // Insert some test documents\n        collection.insert([{\n          _id: 1,\n          results: [82, 85, 88]\n        }, {\n          _id: 2,\n          results: [75, 88, 89]\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n\n          // Ensure correct insertion testing via the cursor and the count function\n          collection.find({\n            results: {\n              $elemMatch: {\n                $gte: 80,\n                $lt: 85\n              }\n            }\n          }).toArray(function (err, documents) {\n            expect(err).to.not.exist;\n            test.deepEqual([{\n              _id: 1,\n              results: [82, 85, 88]\n            }], documents);\n\n            // Let's close the db\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"should execute query using limit of 101","suites":["Find"],"updatePoint":{"line":2829,"column":45,"index":91556},"line":2829,"code":"  it('should execute query using limit of 101', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        const collection = db.collection('test_find_simple_limit_101');\n        function clone(obj) {\n          var o = {};\n          for (var name in obj) o[name] = obj[name];\n          return o;\n        }\n        var template = {\n          linkid: '12633170',\n          advertisercid: '4612127',\n          websitename: 'Car Rental 8',\n          destinationurl: 'https://www.carrental8.com/en/',\n          who: '8027061-12633170-1467924618000',\n          href: 'http://www.tkqlhce.com',\n          src: 'http://www.awltovhc.com',\n          r1: 3,\n          r2: 44,\n          r3: 24,\n          r4: 58\n        };\n        var docs = [];\n        for (var i = 0; i < 1000; i++) {\n          docs.push(clone(template));\n        }\n\n        // Insert some test documents\n        collection.insertMany(docs, configuration.writeConcernMax(), function (err, r) {\n          expect(err).to.not.exist;\n          test.ok(r);\n\n          // Ensure correct insertion testing via the cursor and the count function\n          collection.find().limit(200).toArray(function (err, documents) {\n            expect(err).to.not.exist;\n            test.equal(200, documents.length);\n            // Let's close the db\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply db level options to find cursor","suites":["Find"],"updatePoint":{"line":2886,"column":60,"index":93335},"line":2886,"code":"  it('Should correctly apply db level options to find cursor', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient({}, {\n        ignoreUndefined: true\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('test_find_simple_cursor_inheritance');\n\n        // Insert some test documents\n        collection.insert([{\n          a: 2\n        }, {\n          b: 3,\n          c: undefined\n        }], function (err) {\n          expect(err).to.not.exist;\n          // Ensure correct insertion testing via the cursor and the count function\n          var cursor = collection.find({\n            c: undefined\n          });\n          cursor.toArray(function (err, documents) {\n            test.equal(2, documents.length);\n            // Let's close the db\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"should respect client-level read preference","suites":["Find"],"updatePoint":{"line":2922,"column":49,"index":94379},"line":2922,"code":"  it('should respect client-level read preference', {\n    metadata: {\n      requires: {\n        topology: ['replicaset']\n      }\n    },\n    test: function (done) {\n      const config = this.configuration;\n      const client = config.newClient({}, {\n        monitorCommands: true,\n        readPreference: 'secondary'\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        let selectedServer;\n        const topology = client.topology;\n        const selectServerStub = sinon.stub(topology, 'selectServer').callsFake(function () {\n          const args = Array.prototype.slice.call(arguments);\n          const originalCallback = args.pop();\n          args.push((err, server) => {\n            selectedServer = server;\n            originalCallback(err, server);\n          });\n          return topology.selectServer.wrappedMethod.apply(this, args);\n        });\n        const collection = client.db().collection('test_read_preference');\n        collection.find().toArray(err => {\n          expect(err).to.not.exist;\n          expect(selectedServer.description.type).to.eql('RSSecondary');\n          client.close(err => {\n            selectServerStub.restore();\n            done(err);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute Collection.prototype.insertOne","suites":["crud - insert","insert promise tests"],"updatePoint":{"line":70,"column":63,"index":1855},"line":70,"code":"    it('Should correctly execute Collection.prototype.insertOne', function (done) {\n      const configuration = this.configuration;\n      let url = configuration.url();\n      url = url.indexOf('?') !== -1 ? f('%s&%s', url, 'maxPoolSize=100') : f('%s?%s', url, 'maxPoolSize=100');\n      const client = configuration.newClient(url);\n      client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        db.collection('insertOne').insertOne({\n          a: 1\n        }).then(function (r) {\n          expect(r).property('insertedId').to.exist;\n          client.close(done);\n        });\n      });\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should correctly return failing Promise when no document array passed into insertMany","suites":["crud - insert","insert promise tests"],"updatePoint":{"line":85,"column":93,"index":2518},"line":85,"code":"    it('Should correctly return failing Promise when no document array passed into insertMany', function (done) {\n      const configuration = this.configuration;\n      let url = configuration.url();\n      url = url.indexOf('?') !== -1 ? f('%s&%s', url, 'maxPoolSize=100') : f('%s?%s', url, 'maxPoolSize=100');\n      const client = configuration.newClient(url);\n      client.connect().then(() => {\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        expect(() => {\n          db.collection('insertMany_Promise_error').insertMany({\n            a: 1\n          });\n        }).to.throw(/Argument \"docs\" must be an array of documents/);\n        done();\n      });\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformSingleInsert","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":106,"column":42,"index":3312},"line":106,"code":"    it('shouldCorrectlyPerformSingleInsert', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyPerformSingleInsert');\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.findOne(function (err, item) {\n              test.equal(1, item.a);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleMultipleDocumentInsert","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":134,"column":51,"index":4347},"line":134,"code":"    it('shouldCorrectlyHandleMultipleDocumentInsert', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_multiple_insert');\n          var docs = [{\n            a: 1\n          }, {\n            a: 2\n          }];\n          collection.insert(docs, configuration.writeConcernMax(), function (err, r) {\n            expect(r).property('insertedCount').to.equal(2);\n            test.ok(r.insertedIds[0]._bsontype === 'ObjectID');\n            test.ok(r.insertedIds[1]._bsontype === 'ObjectID');\n\n            // Let's ensure we have both documents\n            collection.find().toArray(function (err, docs) {\n              test.equal(2, docs.length);\n              var results = [];\n              // Check that we have all the results we want\n              docs.forEach(function (doc) {\n                if (doc.a === 1 || doc.a === 2) results.push(1);\n              });\n              test.equal(2, results.length);\n              // Let's close the db\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertAndRetrieveLargeIntegratedArrayDocument","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":176,"column":68,"index":5964},"line":176,"code":"    it('shouldCorrectlyInsertAndRetrieveLargeIntegratedArrayDocument', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_should_deserialize_large_integrated_array');\n          var doc = {\n            a: 0,\n            b: ['tmp1', 'tmp2', 'tmp3', 'tmp4', 'tmp5', 'tmp6', 'tmp7', 'tmp8', 'tmp9', 'tmp10', 'tmp11', 'tmp12', 'tmp13', 'tmp14', 'tmp15', 'tmp16']\n          };\n          // Insert the collection\n          collection.insert(doc, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            // Fetch and check the collection\n            collection.findOne({\n              a: 0\n            }, function (err, result) {\n              test.deepEqual(doc.a, result.a);\n              test.deepEqual(doc.b, result.b);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertAndRetrieveDocumentWithAllTypes","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":211,"column":60,"index":7373},"line":211,"code":"    it('shouldCorrectlyInsertAndRetrieveDocumentWithAllTypes', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_all_serialization_types');\n          var date = new Date();\n          var oid = new ObjectId();\n          var string = 'binstring';\n          var bin = new Binary();\n          for (var index = 0; index < string.length; index++) {\n            bin.put(string.charAt(index));\n          }\n          var motherOfAllDocuments = {\n            string: 'hello',\n            array: [1, 2, 3],\n            hash: {\n              a: 1,\n              b: 2\n            },\n            date: date,\n            oid: oid,\n            binary: bin,\n            int: 42,\n            float: 33.3333,\n            regexp: /regexp/,\n            boolean: true,\n            long: date.getTime(),\n            where: new Code('this.a > i', {\n              i: 1\n            }),\n            dbref: new DBRef('namespace', oid, 'integration_tests_')\n          };\n          collection.insert(motherOfAllDocuments, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.findOne(function (err, doc) {\n              // Assert correct deserialization of the values\n              test.equal(motherOfAllDocuments.string, doc.string);\n              test.deepEqual(motherOfAllDocuments.array, doc.array);\n              test.equal(motherOfAllDocuments.hash.a, doc.hash.a);\n              test.equal(motherOfAllDocuments.hash.b, doc.hash.b);\n              test.equal(date.getTime(), doc.long);\n              test.equal(date.toString(), doc.date.toString());\n              test.equal(date.getTime(), doc.date.getTime());\n              test.equal(motherOfAllDocuments.oid.toHexString(), doc.oid.toHexString());\n              test.equal(motherOfAllDocuments.binary.value(), doc.binary.value());\n              test.equal(motherOfAllDocuments.int, doc.int);\n              test.equal(motherOfAllDocuments.long, doc.long);\n              test.equal(motherOfAllDocuments.float, doc.float);\n              test.equal(motherOfAllDocuments.regexp.toString(), doc.regexp.toString());\n              test.equal(motherOfAllDocuments.boolean, doc.boolean);\n              test.equal(motherOfAllDocuments.where.code, doc.where.code);\n              test.equal(motherOfAllDocuments.where.scope['i'], doc.where.scope.i);\n              test.equal(motherOfAllDocuments.dbref.namespace, doc.dbref.namespace);\n              test.equal(motherOfAllDocuments.dbref.oid.toHexString(), doc.dbref.oid.toHexString());\n              test.equal(motherOfAllDocuments.dbref.db, doc.dbref.db);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertAndUpdateDocumentWithNewScriptContext","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":283,"column":66,"index":10616},"line":283,"code":"    it('shouldCorrectlyInsertAndUpdateDocumentWithNewScriptContext', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n\n          //convience curried handler for functions of type 'a -> (err, result)\n          function getResult(callback) {\n            return function (error, result) {\n              test.ok(error == null);\n              return callback(result);\n            };\n          }\n          db.createCollection('users', getResult(function (user_collection) {\n            user_collection.remove({}, configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist;\n\n              //first, create a user object\n              var newUser = {\n                name: 'Test Account',\n                settings: {}\n              };\n              user_collection.insert([newUser], configuration.writeConcernMax(), getResult(function () {\n                var scriptCode = \"settings.block = []; settings.block.push('test');\";\n                var context = {\n                  settings: {\n                    thisOneWorks: 'somestring'\n                  }\n                };\n                Script.runInNewContext(scriptCode, context, 'testScript');\n\n                //now create update command and issue it\n                var updateCommand = {\n                  $set: context\n                };\n                user_collection.update({\n                  _id: newUser._id\n                }, updateCommand, configuration.writeConcernMax(), getResult(function () {\n                  // Fetch the object and check that the changes are persisted\n                  user_collection.findOne({\n                    _id: newUser._id\n                  }, function (err, doc) {\n                    test.ok(err == null);\n                    test.equal('Test Account', doc.name);\n                    test.equal('somestring', doc.settings.thisOneWorks);\n                    test.equal('test', doc.settings.block[0]);\n                    client.close(done);\n                  });\n                }));\n              }));\n            });\n          }));\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlySerializeDocumentWithAllTypesInNewContext","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":348,"column":64,"index":13219},"line":348,"code":"    it('shouldCorrectlySerializeDocumentWithAllTypesInNewContext', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_all_serialization_types_new_context');\n          var date = new Date();\n          var scriptCode = \"var string = 'binstring'\\n\" + 'var bin = new mongo.Binary()\\n' + 'for(var index = 0; index < string.length; index++) {\\n' + '  bin.put(string.charAt(index))\\n' + '}\\n' + \"motherOfAllDocuments['string'] = 'hello';\" + \"motherOfAllDocuments['array'] = [1,2,3];\" + \"motherOfAllDocuments['hash'] = {'a':1, 'b':2};\" + \"motherOfAllDocuments['date'] = date;\" + \"motherOfAllDocuments['oid'] = new mongo.ObjectId();\" + \"motherOfAllDocuments['binary'] = bin;\" + \"motherOfAllDocuments['int'] = 42;\" + \"motherOfAllDocuments['float'] = 33.3333;\" + \"motherOfAllDocuments['regexp'] = /regexp/;\" + \"motherOfAllDocuments['boolean'] = true;\" + \"motherOfAllDocuments['long'] = motherOfAllDocuments['date'].getTime();\" + \"motherOfAllDocuments['where'] = new mongo.Code('this.a > i', {i:1});\" + \"motherOfAllDocuments['dbref'] = new mongo.DBRef('namespace', motherOfAllDocuments['oid'], 'integration_tests_');\";\n          var context = {\n            motherOfAllDocuments: {},\n            mongo: {\n              ObjectId: ObjectId,\n              Binary: Binary,\n              Code: Code,\n              DBRef: DBRef\n            },\n            date: date\n          };\n\n          // Execute function in context\n          Script.runInNewContext(scriptCode, context, 'testScript');\n          // sys.puts(sys.inspect(context.motherOfAllDocuments))\n          var motherOfAllDocuments = context.motherOfAllDocuments;\n          collection.insert(context.motherOfAllDocuments, configuration.writeConcernMax(), function (err, docs) {\n            test.ok(docs);\n            collection.findOne(function (err, doc) {\n              // Assert correct deserialization of the values\n              test.equal(motherOfAllDocuments.string, doc.string);\n              test.deepEqual(motherOfAllDocuments.array, doc.array);\n              test.equal(motherOfAllDocuments.hash.a, doc.hash.a);\n              test.equal(motherOfAllDocuments.hash.b, doc.hash.b);\n              test.equal(date.getTime(), doc.long);\n              test.equal(date.toString(), doc.date.toString());\n              test.equal(date.getTime(), doc.date.getTime());\n              test.equal(motherOfAllDocuments.oid.toHexString(), doc.oid.toHexString());\n              test.equal(motherOfAllDocuments.binary.value(), doc.binary.value());\n              test.equal(motherOfAllDocuments.int, doc.int);\n              test.equal(motherOfAllDocuments.long, doc.long);\n              test.equal(motherOfAllDocuments.float, doc.float);\n              test.equal(motherOfAllDocuments.regexp.toString(), doc.regexp.toString());\n              test.equal(motherOfAllDocuments.boolean, doc.boolean);\n              test.equal(motherOfAllDocuments.where.code, doc.where.code);\n              test.equal(motherOfAllDocuments.where.scope['i'], doc.where.scope.i);\n              test.equal(motherOfAllDocuments.dbref.namespace, doc.dbref.namespace);\n              test.equal(motherOfAllDocuments.dbref.oid.toHexString(), doc.dbref.oid.toHexString());\n              test.equal(motherOfAllDocuments.dbref.db, doc.dbref.db);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDoToJsonForLongValue","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":410,"column":43,"index":17098},"line":410,"code":"    it('shouldCorrectlyDoToJsonForLongValue', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_to_json_for_long');\n          collection.insert([{\n            value: Long.fromNumber(32222432)\n          }], configuration.writeConcernMax(), function (err, ids) {\n            test.ok(ids);\n            collection.findOne({}, function (err, item) {\n              test.equal(32222432, item.value);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldInsertAndQueryTimestamp","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":438,"column":37,"index":18144},"line":438,"code":"    it('shouldInsertAndQueryTimestamp', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_insert_and_query_timestamp');\n\n          // Insert the update\n          collection.insert({\n            i: Timestamp.fromNumber(100),\n            j: Long.fromNumber(200)\n          }, configuration.writeConcernMax(), function (err, r) {\n            test.ok(r);\n            // Locate document\n            collection.findOne({}, function (err, item) {\n              test.ok(item.i._bsontype === 'Timestamp');\n              test.equal(100, item.i.toInt());\n              test.equal(200, item.j);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertAndQueryUndefined","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":472,"column":46,"index":19394},"line":472,"code":"    it('shouldCorrectlyInsertAndQueryUndefined', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_insert_and_query_undefined');\n\n          // Insert the update\n          collection.insert({\n            i: undefined\n          }, configuration.writeConcernMax(), function (err, r) {\n            expect(err).to.not.exist;\n            test.ok(r);\n\n            // Locate document\n            collection.findOne({}, function (err, item) {\n              expect(item.i).to.not.exist;\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlySerializeDBRefToJSON","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":505,"column":43,"index":20527},"line":505,"code":"    it('shouldCorrectlySerializeDBRefToJSON', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var dbref = new DBRef('foo', ObjectId.createFromHexString('fc24a04d4560531f00000000'), null);\n        JSON.stringify(dbref);\n        done();\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldThrowErrorIfSerializingFunctionOrdered","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":519,"column":52,"index":21056},"line":519,"code":"    it('shouldThrowErrorIfSerializingFunctionOrdered', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_should_throw_error_if_serializing_function');\n          var func = function () {\n            return 1;\n          };\n          // Insert the update\n          collection.insert({\n            i: 1,\n            z: func\n          }, {\n            writeConcern: {\n              w: 1\n            },\n            serializeFunctions: true\n          }, function (err, result) {\n            expect(err).to.not.exist;\n            collection.findOne({\n              _id: result.insertedIds[0]\n            }, function (err, object) {\n              expect(err).to.not.exist;\n              test.equal(normalizedFunctionString(func), object.z.code);\n              test.equal(1, object.i);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldThrowErrorIfSerializingFunctionUnOrdered","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":561,"column":54,"index":22493},"line":561,"code":"    it('shouldThrowErrorIfSerializingFunctionUnOrdered', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_should_throw_error_if_serializing_function_1');\n          var func = function () {\n            return 1;\n          };\n          // Insert the update\n          collection.insert({\n            i: 1,\n            z: func\n          }, {\n            writeConcern: {\n              w: 1\n            },\n            serializeFunctions: true,\n            ordered: false\n          }, function (err, result) {\n            expect(err).to.not.exist;\n            collection.findOne({\n              _id: result.insertedIds[0]\n            }, function (err, object) {\n              expect(err).to.not.exist;\n              test.equal(normalizedFunctionString(func), object.z.code);\n              test.equal(1, object.i);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertDocumentWithUUID","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":604,"column":45,"index":23940},"line":604,"code":"    it('shouldCorrectlyInsertDocumentWithUUID', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('insert_doc_with_uuid');\n          collection.insert({\n            _id: '12345678123456781234567812345678',\n            field: '1'\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.find({\n              _id: '12345678123456781234567812345678'\n            }).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(items[0]._id, '12345678123456781234567812345678');\n              test.equal(items[0].field, '1');\n\n              // Generate a binary id\n              var binaryUUID = new Binary(Buffer.from('00000078123456781234567812345678', 'hex'), Binary.SUBTYPE_UUID);\n\n              // UUID must be 16 bytes\n              expect(binaryUUID.buffer).to.have.property('byteLength', 16);\n              collection.insert({\n                _id: binaryUUID,\n                field: '2'\n              }, configuration.writeConcernMax(), function (err, result) {\n                expect(err).to.not.exist;\n                test.ok(result);\n                collection.find({\n                  _id: binaryUUID\n                }).toArray(function (err, items) {\n                  expect(err).to.not.exist;\n                  test.equal(items[0].field, '2');\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCallCallbackWithDbDriverInStrictMode","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":657,"column":59,"index":26043},"line":657,"code":"    it('shouldCorrectlyCallCallbackWithDbDriverInStrictMode', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_insert_and_update_no_callback_strict');\n          collection.insert({\n            _id: '12345678123456781234567812345678',\n            field: '1'\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.updateOne({\n              _id: '12345678123456781234567812345678'\n            }, {\n              $set: {\n                field: 0\n              }\n            }, configuration.writeConcernMax(), function (err, r) {\n              expect(err).to.not.exist;\n              expect(r).property('matchedCount').to.equal(1);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertDBRefWithDbNotDefined","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":694,"column":50,"index":27428},"line":694,"code":"    it('shouldCorrectlyInsertDBRefWithDbNotDefined', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyInsertDBRefWithDbNotDefined');\n          var doc = {\n            _id: new ObjectId()\n          };\n          var doc2 = {\n            _id: new ObjectId()\n          };\n          var doc3 = {\n            _id: new ObjectId()\n          };\n          collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n\n            // Create object with dbref\n            doc2.ref = new DBRef('shouldCorrectlyInsertDBRefWithDbNotDefined', doc._id);\n            doc3.ref = new DBRef('shouldCorrectlyInsertDBRefWithDbNotDefined', doc._id, configuration.db_name);\n            collection.insert([doc2, doc3], configuration.writeConcernMax(), function (err, result) {\n              expect(err).to.not.exist;\n              test.ok(result);\n\n              // Get all items\n              collection.find().toArray(function (err, items) {\n                test.equal('shouldCorrectlyInsertDBRefWithDbNotDefined', items[1].ref.namespace);\n                test.equal(doc._id.toString(), items[1].ref.oid.toString());\n                expect(items[1].ref.db).to.not.exist;\n                test.equal('shouldCorrectlyInsertDBRefWithDbNotDefined', items[2].ref.namespace);\n                test.equal(doc._id.toString(), items[2].ref.oid.toString());\n                expect(items[2].ref.db).to.not.exist;\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertUpdateRemoveWithNoOptions","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":745,"column":54,"index":29585},"line":745,"code":"    it('shouldCorrectlyInsertUpdateRemoveWithNoOptions', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyInsertUpdateRemoveWithNoOptions');\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.update({\n              a: 1\n            }, {\n              $set: {\n                a: 2\n              }\n            }, configuration.writeConcernMax(), function (err, result) {\n              expect(err).to.not.exist;\n              test.ok(result);\n              collection.remove({\n                a: 2\n              }, configuration.writeConcernMax(), function (err, result) {\n                expect(err).to.not.exist;\n                test.ok(result);\n                collection.count(function (err, count) {\n                  test.equal(0, count);\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteMultipleFetches","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":790,"column":45,"index":31187},"line":790,"code":"    it('shouldCorrectlyExecuteMultipleFetches', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        // Search parameter\n        var to = 'ralph';\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyExecuteMultipleFetches');\n          // Execute query\n          collection.insert({\n            addresses: {\n              localPart: 'ralph'\n            }\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n\n            // Let's find our user\n            collection.findOne({\n              'addresses.localPart': to\n            }, function (err, doc) {\n              expect(err).to.not.exist;\n              test.equal(to, doc.addresses.localPart);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyFailWhenNoObjectToUpdate","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":829,"column":47,"index":32544},"line":829,"code":"    it('shouldCorrectlyFailWhenNoObjectToUpdate', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyFailWhenNoObjectToUpdate');\n          collection.update({\n            _id: new ObjectId()\n          }, {\n            $set: {\n              email: 'update'\n            }\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            expect(result).property('matchedCount').to.equal(0);\n            client.close(done);\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should correctly insert object and retrieve it when containing array and IsoDate","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":859,"column":88,"index":33679},"line":859,"code":"    it('Should correctly insert object and retrieve it when containing array and IsoDate', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var doc = {\n          _id: new ObjectId('4e886e687ff7ef5e00000162'),\n          str: 'foreign',\n          type: 2,\n          timestamp: ISODate('2011-10-02T14:00:08.383Z'),\n          links: ['http://www.reddit.com/r/worldnews/comments/kybm0/uk_home_secretary_calls_for_the_scrapping_of_the/']\n        };\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('Should_correctly_insert_object_and_retrieve_it_when_containing_array_and_IsoDate');\n          collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n            test.ok(err == null);\n            test.ok(result);\n            collection.findOne(function (err, item) {\n              test.ok(err == null);\n              test.deepEqual(doc, item);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should correctly insert object with timestamps","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":894,"column":54,"index":35120},"line":894,"code":"    it('Should correctly insert object with timestamps', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var doc = {\n          _id: new ObjectId('4e886e687ff7ef5e00000162'),\n          str: 'foreign',\n          type: 2,\n          timestamp: new Timestamp(10000),\n          links: ['http://www.reddit.com/r/worldnews/comments/kybm0/uk_home_secretary_calls_for_the_scrapping_of_the/'],\n          timestamp2: new Timestamp(33333)\n        };\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('Should_correctly_insert_object_with_timestamps');\n          collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n            test.ok(err == null);\n            test.ok(result);\n            collection.findOne(function (err, item) {\n              test.ok(err == null);\n              test.deepEqual(doc, item);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly allow for control of serialization of functions on command level","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":930,"column":89,"index":36591},"line":930,"code":"    it('Should Correctly allow for control of serialization of functions on command level', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var doc = {\n          str: 'String',\n          func: function () {}\n        };\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('Should_Correctly_allow_for_control_of_serialization_of_functions_on_command_level');\n          collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.update({\n              str: 'String'\n            }, {\n              $set: {\n                c: 1,\n                d: function () {}\n              }\n            }, {\n              writeConcern: {\n                w: 1\n              },\n              serializeFunctions: false\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              expect(result).property('matchedCount').to.equal(1);\n              collection.findOne({\n                str: 'String'\n              }, function (err, item) {\n                expect(item.d).to.not.exist;\n\n                // Execute a safe insert with replication to two servers\n                collection.findOneAndUpdate({\n                  str: 'String'\n                }, {\n                  $set: {\n                    f: function () {}\n                  }\n                }, {\n                  returnDocument: ReturnDocument.AFTER,\n                  safe: true,\n                  serializeFunctions: true\n                }, function (err, result) {\n                  test.ok(result.value.f._bsontype === 'Code');\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly allow for control of serialization of functions on collection level","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":994,"column":92,"index":38870},"line":994,"code":"    it('Should Correctly allow for control of serialization of functions on collection level', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var doc = {\n          str: 'String',\n          func: function () {}\n        };\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('Should_Correctly_allow_for_control_of_serialization_of_functions_on_collection_level', {\n            serializeFunctions: true\n          });\n          collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({\n              str: 'String'\n            }, function (err, item) {\n              test.ok(item.func._bsontype === 'Code');\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly allow for using a Date object as _id","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1029,"column":61,"index":40177},"line":1029,"code":"    it('Should Correctly allow for using a Date object as _id', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var doc = {\n          _id: new Date(),\n          str: 'hello'\n        };\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('Should_Correctly_allow_for_using_a_Date_object_as__id');\n          collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({\n              str: 'hello'\n            }, function (err, item) {\n              test.ok(item._id instanceof Date);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly fail to update returning 0 results","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1062,"column":59,"index":41386},"line":1062,"code":"    it('Should Correctly fail to update returning 0 results', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('Should_Correctly_fail_to_update_returning_0_results');\n          collection.updateMany({\n            a: 1\n          }, {\n            $set: {\n              a: 1\n            }\n          }, configuration.writeConcernMax(), function (err, r) {\n            expect(r).property('matchedCount').to.equal(0);\n            client.close(done);\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly update two fields including a sub field","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1091,"column":64,"index":42439},"line":1091,"code":"    it('Should Correctly update two fields including a sub field', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var doc = {\n          _id: new ObjectId(),\n          Prop1: 'p1',\n          Prop2: 'p2',\n          More: {\n            Sub1: 's1',\n            Sub2: 's2',\n            Sub3: 's3'\n          }\n        };\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('Should_Correctly_update_two_fields_including_a_sub_field');\n          collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n\n            // Update two fields\n            collection.update({\n              _id: doc._id\n            }, {\n              $set: {\n                Prop1: 'p1_2',\n                'More.Sub2': 's2_2'\n              }\n            }, configuration.writeConcernMax(), function (err, r) {\n              expect(err).to.not.exist;\n              expect(r).property('matchedCount').to.equal(1);\n              collection.findOne({\n                _id: doc._id\n              }, function (err, item) {\n                expect(err).to.not.exist;\n                test.equal('p1_2', item.Prop1);\n                test.equal('s2_2', item.More.Sub2);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should correctly fail due to duplicate key for _id","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1145,"column":58,"index":44282},"line":1145,"code":"    it('Should correctly fail due to duplicate key for _id', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('Should_Correctly_update_two_fields_including_a_sub_field_2');\n          collection.insertOne({\n            _id: 1\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n\n            // Update two fields\n            collection.insertOne({\n              _id: 1\n            }, configuration.writeConcernMax(), function (err, r) {\n              expect(err).to.exist;\n              expect(r).to.not.exist;\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertDocWithCustomId","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1179,"column":44,"index":45517},"line":1179,"code":"    it('shouldCorrectlyInsertDocWithCustomId', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyInsertDocWithCustomId');\n          // Insert the update\n          collection.insert({\n            _id: 0,\n            test: 'hello'\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({\n              _id: 0\n            }, function (err, item) {\n              test.equal(0, item._id);\n              test.equal('hello', item.test);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformUpsertAgainstNewDocumentAndExistingOne","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1213,"column":68,"index":46754},"line":1213,"code":"    it('shouldCorrectlyPerformUpsertAgainstNewDocumentAndExistingOne', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyPerformUpsertAgainstNewDocumentAndExistingOne');\n\n          // Upsert a new doc\n          collection.update({\n            a: 1\n          }, {\n            $set: {\n              a: 1\n            }\n          }, {\n            upsert: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, result) {\n            expect(err).to.not.exist;\n            expect(result).property('upsertedCount').to.equal(1);\n\n            // Upsert an existing doc\n            collection.update({\n              a: 1\n            }, {\n              $set: {\n                a: 1\n              }\n            }, {\n              upsert: true,\n              writeConcern: {\n                w: 1\n              }\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              expect(result).property('matchedCount').to.equal(1);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformLargeTextInsert","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1267,"column":45,"index":48385},"line":1267,"code":"    it('shouldCorrectlyPerformLargeTextInsert', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyPerformLargeTextInsert');\n\n          // Create large string, insert and then retrive\n          var string = '';\n          // Create large text field\n          for (var i = 0; i < 50000; i++) {\n            string = string + 'a';\n          }\n          collection.insert({\n            a: 1,\n            string: string\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({\n              a: 1\n            }, function (err, doc) {\n              expect(err).to.not.exist;\n              test.equal(50000, doc.string.length);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformInsertOfObjectsUsingToBSON","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1307,"column":56,"index":49797},"line":1307,"code":"    it('shouldCorrectlyPerformInsertOfObjectsUsingToBSON', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyPerformInsertOfObjectsUsingToBSON');\n\n          // Create document with toBSON method\n          var doc = {\n            a: 1,\n            b: 1\n          };\n          doc.toBSON = function () {\n            return {\n              c: this.a\n            };\n          };\n          collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({\n              c: 1\n            }, function (err, doc) {\n              expect(err).to.not.exist;\n              test.deepEqual(1, doc.c);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldAttempToForceBsonSize","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1348,"column":35,"index":51147},"line":1348,"code":"    it('shouldAttempToForceBsonSize', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: 'single'\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          db.createCollection('shouldAttempToForceBsonSize', function (err, collection) {\n            // var doc = {a:1, b:new Binary(Buffer.alloc(16777216)/5)}\n            var doc = [{\n              a: 1,\n              b: new Binary(Buffer.alloc(16777216 / 3))\n            }, {\n              a: 1,\n              b: new Binary(Buffer.alloc(16777216 / 3))\n            }, {\n              a: 1,\n              b: new Binary(Buffer.alloc(16777216 / 3))\n            }];\n            collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n              expect(err).to.not.exist;\n              test.ok(result);\n              collection.findOne({\n                a: 1\n              }, function (err, doc) {\n                expect(err).to.not.exist;\n                test.deepEqual(1, doc.a);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUseCustomObjectToUpdateDocument","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1390,"column":54,"index":52637},"line":1390,"code":"    it('shouldCorrectlyUseCustomObjectToUpdateDocument', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyUseCustomObjectToUpdateDocument');\n          collection.insert({\n            a: {\n              b: {\n                c: 1\n              }\n            }\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n\n            // Dynamically build query\n            var query = {};\n            query['a'] = {};\n            query.a['b'] = {};\n            query.a.b['c'] = 1;\n\n            // Update document\n            collection.update(query, {\n              $set: {\n                'a.b.d': 1\n              }\n            }, configuration.writeConcernMax(), function (err, r) {\n              expect(err).to.not.exist;\n              expect(r).property('matchedCount').to.equal(1);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldExecuteInsertWithNoCallbackAndWriteConcern","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1436,"column":56,"index":54171},"line":1436,"code":"    it('shouldExecuteInsertWithNoCallbackAndWriteConcern', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldExecuteInsertWithNoCallbackAndWriteConcern');\n          collection.insert({\n            a: {\n              b: {\n                c: 1\n              }\n            }\n          }).then(() => {\n            client.close(done);\n          }, err => {\n            client.close(err2 => done(err || err2));\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"executesCallbackOnceWithOveriddenDefaultDbWriteConcern","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1466,"column":62,"index":55192},"line":1466,"code":"    it('executesCallbackOnceWithOveriddenDefaultDbWriteConcern', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        function cb(err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        }\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('gh-completely2');\n          collection.insert({\n            a: 1\n          }, {\n            writeConcern: {\n              w: 0\n            }\n          }, cb);\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"executesCallbackOnceWithOveriddenDefaultDbWriteConcernWithUpdate","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1496,"column":72,"index":56158},"line":1496,"code":"    it('executesCallbackOnceWithOveriddenDefaultDbWriteConcernWithUpdate', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        function cb(err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        }\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('gh-completely3');\n          collection.update({\n            a: 1\n          }, {\n            $set: {\n              a: 2\n            }\n          }, {\n            upsert: true,\n            writeConcern: {\n              w: 0\n            }\n          }, cb);\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"executesCallbackOnceWithOveriddenDefaultDbWriteConcernWithRemove","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1531,"column":72,"index":57218},"line":1531,"code":"    it('executesCallbackOnceWithOveriddenDefaultDbWriteConcernWithRemove', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        function cb(err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        }\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('gh-completely1');\n          collection.remove({\n            a: 1\n          }, {\n            writeConcern: {\n              w: 0\n            }\n          }, cb);\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"handleBSONTypeInsertsCorrectly","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1561,"column":38,"index":58150},"line":1561,"code":"    it('handleBSONTypeInsertsCorrectly', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger'],\n          mongodb: '<2.8.0'\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('bson_types_insert');\n          var document = {\n            symbol: new BSONSymbol('abcdefghijkl'),\n            objid: new ObjectId('abcdefghijkl'),\n            double: new Double(1),\n            binary: new Binary(Buffer.from('hello world')),\n            minkey: new MinKey(),\n            maxkey: new MaxKey(),\n            code: new Code('function () {}', {\n              a: 55\n            })\n          };\n          collection.insert(document, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({\n              symbol: new BSONSymbol('abcdefghijkl')\n            }, function (err, doc) {\n              expect(err).to.not.exist;\n              test.equal('abcdefghijkl', doc.symbol.toString());\n              collection.findOne({\n                objid: new ObjectId('abcdefghijkl')\n              }, function (err, doc) {\n                expect(err).to.not.exist;\n                test.equal('6162636465666768696a6b6c', doc.objid.toString());\n                collection.findOne({\n                  double: new Double(1)\n                }, function (err, doc) {\n                  expect(err).to.not.exist;\n                  test.equal(1, doc.double);\n                  collection.findOne({\n                    binary: new Binary(Buffer.from('hello world'))\n                  }, function (err, doc) {\n                    expect(err).to.not.exist;\n                    test.equal('hello world', doc.binary.toString());\n                    collection.findOne({\n                      minkey: new MinKey()\n                    }, function (err, doc) {\n                      expect(err).to.not.exist;\n                      test.ok(doc.minkey._bsontype === 'MinKey');\n                      collection.findOne({\n                        maxkey: new MaxKey()\n                      }, function (err, doc) {\n                        expect(err).to.not.exist;\n                        test.ok(doc.maxkey._bsontype === 'MaxKey');\n                        collection.findOne({\n                          code: new Code('function () {}', {\n                            a: 55\n                          })\n                        }, function (err, doc) {\n                          expect(err).to.not.exist;\n                          test.ok(doc != null);\n                          client.close(done);\n                        });\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"handleBSONTypeInsertsCorrectlyFor28OrHigher","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1641,"column":51,"index":61406},"line":1641,"code":"    it('handleBSONTypeInsertsCorrectlyFor28OrHigher', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger'],\n          mongodb: '>=2.8.0'\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('bson_types_insert_1');\n          var document = {\n            string: 'abcdefghijkl',\n            objid: new ObjectId('abcdefghijkl'),\n            double: new Double(1),\n            binary: new Binary(Buffer.from('hello world')),\n            minkey: new MinKey(),\n            maxkey: new MaxKey(),\n            code: new Code('function () {}', {\n              a: 55\n            })\n          };\n          collection.insert(document, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({\n              string: 'abcdefghijkl'\n            }, function (err, doc) {\n              expect(err).to.not.exist;\n              test.equal('abcdefghijkl', doc.string.toString());\n              collection.findOne({\n                objid: new ObjectId('abcdefghijkl')\n              }, function (err, doc) {\n                expect(err).to.not.exist;\n                test.equal('6162636465666768696a6b6c', doc.objid.toString());\n                collection.findOne({\n                  double: new Double(1)\n                }, function (err, doc) {\n                  expect(err).to.not.exist;\n                  test.equal(1, doc.double);\n                  collection.findOne({\n                    binary: new Binary(Buffer.from('hello world'))\n                  }, function (err, doc) {\n                    expect(err).to.not.exist;\n                    test.equal('hello world', doc.binary.toString());\n                    collection.findOne({\n                      minkey: new MinKey()\n                    }, function (err, doc) {\n                      expect(err).to.not.exist;\n                      test.ok(doc.minkey._bsontype === 'MinKey');\n                      collection.findOne({\n                        maxkey: new MaxKey()\n                      }, function (err, doc) {\n                        expect(err).to.not.exist;\n                        test.ok(doc.maxkey._bsontype === 'MaxKey');\n                        collection.findOne({\n                          code: new Code('function () {}', {\n                            a: 55\n                          })\n                        }, function (err, doc) {\n                          expect(err).to.not.exist;\n                          test.ok(doc != null);\n                          client.close(done);\n                        });\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"mixedTimestampAndDateQuery","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1721,"column":34,"index":64616},"line":1721,"code":"    it('mixedTimestampAndDateQuery', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('timestamp_date');\n          var d = new Date();\n          var documents = [{\n            x: new Timestamp(1, 2)\n          }, {\n            x: d\n          }];\n          collection.insert(documents, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({\n              x: new Timestamp(1, 2)\n            }, function (err, doc) {\n              expect(err).to.not.exist;\n              test.ok(doc != null);\n              collection.findOne({\n                x: d\n              }, function (err, doc) {\n                expect(err).to.not.exist;\n                test.ok(doc != null);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"positiveAndNegativeInfinity","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1763,"column":35,"index":66058},"line":1763,"code":"    it('positiveAndNegativeInfinity', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('negative_pos');\n          var document = {\n            pos: Number.POSITIVE_INFINITY,\n            neg: Number.NEGATIVE_INFINITY\n          };\n          collection.insert(document, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({}, function (err, doc) {\n              expect(err).to.not.exist;\n              test.equal(Number.POSITIVE_INFINITY, doc.pos);\n              test.equal(Number.NEGATIVE_INFINITY, doc.neg);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertSimpleRegExpDocument","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1796,"column":49,"index":67337},"line":1796,"code":"    it('shouldCorrectlyInsertSimpleRegExpDocument', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var regexp = /foobar/i;\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          db.createCollection('test_regex', function (err, collection) {\n            collection.insert({\n              b: regexp\n            }, configuration.writeConcernMax(), function (err, ids) {\n              expect(err).to.not.exist;\n              test.ok(ids);\n              collection.find({}).project({\n                b: 1\n              }).toArray(function (err, items) {\n                test.equal('' + regexp, '' + items[0].b);\n                // Let's close the db\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertSimpleUTF8Regexp","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1830,"column":45,"index":68576},"line":1830,"code":"    it('shouldCorrectlyInsertSimpleUTF8Regexp', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var regexp = /foobar/;\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyInsertSimpleUTF8Regexp');\n          collection.insert({\n            b: regexp\n          }, configuration.writeConcernMax(), function (err, ids) {\n            expect(err).to.not.exist;\n            test.ok(ids);\n            collection.find({}).project({\n              b: 1\n            }).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal('' + regexp, '' + items[0].b);\n              // Let's close the db\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyThrowDueToIllegalCollectionName","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1864,"column":54,"index":69834},"line":1864,"code":"    it('shouldCorrectlyThrowDueToIllegalCollectionName', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var k = Buffer.alloc(15);\n          for (var i = 0; i < 15; i++) k[i] = 0;\n          k.write('hello');\n          k[6] = 0x06;\n          k.write('world', 10);\n          try {\n            db.collection(k.toString());\n            test.fail(false);\n          } catch (err) {} // eslint-disable-line\n\n          client.close(done);\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHonorPromoteLongFalseNativeBSON","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1893,"column":54,"index":70825},"line":1893,"code":"    it('shouldCorrectlyHonorPromoteLongFalseNativeBSON', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var o = configuration.writeConcernMax();\n        o.promoteLongs = false;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1,\n          promoteLongs: false\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          db.collection('shouldCorrectlyHonorPromoteLong').insert({\n            doc: Long.fromNumber(10),\n            array: [[Long.fromNumber(10)]]\n          }, function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc);\n            db.collection('shouldCorrectlyHonorPromoteLong').findOne(function (err, doc) {\n              expect(err).to.not.exist;\n              test.ok(doc.doc._bsontype === 'Long');\n              test.ok(doc.array[0][0]._bsontype === 'Long');\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHonorPromoteLongFalseNativeBSONWithGetMore","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1927,"column":65,"index":72160},"line":1927,"code":"    it('shouldCorrectlyHonorPromoteLongFalseNativeBSONWithGetMore', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var o = configuration.writeConcernMax();\n        o.promoteLongs = false;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1,\n          promoteLongs: false\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          db.collection('shouldCorrectlyHonorPromoteLongFalseNativeBSONWithGetMore').insertMany([{\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }], function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc);\n            db.collection('shouldCorrectlyHonorPromoteLongFalseNativeBSONWithGetMore').find({}).batchSize(2).toArray(function (err, docs) {\n              expect(err).to.not.exist;\n              var doc = docs.pop();\n              test.ok(doc.a._bsontype === 'Long');\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInheritPromoteLongFalseNativeBSONWithGetMore","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2006,"column":67,"index":74655},"line":2006,"code":"    it('shouldCorrectlyInheritPromoteLongFalseNativeBSONWithGetMore', {\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: async function () {\n        const db = client.db('shouldCorrectlyInheritPromoteLongFalseNativeBSONWithGetMore', {\n          promoteLongs: true\n        });\n        const collection = db.collection('test', {\n          promoteLongs: false\n        });\n        const doc = await collection.insertMany([{\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }]);\n        test.ok(doc);\n        const docs = await collection.find({}).batchSize(2).toArray();\n        docs.forEach((d, i) => {\n          expect(d.a, `Failed on the document at index ${i}`).to.not.be.a('number');\n          expect(d.a, `Failed on the document at index ${i}`).to.have.property('_bsontype');\n          expect(d.a._bsontype, `Failed on the document at index ${i}`).to.be.equal('Long');\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHonorPromoteLongTrueNativeBSON","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2077,"column":53,"index":76695},"line":2077,"code":"    it('shouldCorrectlyHonorPromoteLongTrueNativeBSON', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          db.collection('shouldCorrectlyHonorPromoteLongTrueNativeBSON').insert({\n            doc: Long.fromNumber(10),\n            array: [[Long.fromNumber(10)]]\n          }, function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc);\n            db.collection('shouldCorrectlyHonorPromoteLongTrueNativeBSON').findOne(function (err, doc) {\n              expect(err).to.not.exist;\n              expect(err).to.not.exist;\n              test.ok('number', typeof doc.doc);\n              test.ok('number', typeof doc.array[0][0]);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHonorPromoteLongFalseJSBSON","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2109,"column":50,"index":77963},"line":2109,"code":"    it('shouldCorrectlyHonorPromoteLongFalseJSBSON', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1,\n          promoteLongs: false\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          db.collection('shouldCorrectlyHonorPromoteLongFalseJSBSON').insert({\n            doc: Long.fromNumber(10),\n            array: [[Long.fromNumber(10)]]\n          }, function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc);\n            db.collection('shouldCorrectlyHonorPromoteLongFalseJSBSON').findOne(function (err, doc) {\n              expect(err).to.not.exist;\n              expect(err).to.not.exist;\n              test.ok(doc.doc._bsontype === 'Long');\n              test.ok(doc.array[0][0]._bsontype === 'Long');\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHonorPromoteLongTrueJSBSON","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2142,"column":49,"index":79263},"line":2142,"code":"    it('shouldCorrectlyHonorPromoteLongTrueJSBSON', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          db.collection('shouldCorrectlyHonorPromoteLongTrueJSBSON').insert({\n            doc: Long.fromNumber(10),\n            array: [[Long.fromNumber(10)]]\n          }, function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc);\n            db.collection('shouldCorrectlyHonorPromoteLongTrueJSBSON').findOne(function (err, doc) {\n              expect(err).to.not.exist;\n              expect(err).to.not.exist;\n              test.ok('number', typeof doc.doc);\n              test.ok('number', typeof doc.array[0][0]);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyWorkWithCheckKeys","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2174,"column":40,"index":80513},"line":2174,"code":"    it('shouldCorrectlyWorkWithCheckKeys', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          db.collection('shouldCorrectlyOverrideCheckKeysJSOnUpdate').update({\n            'ps.op.t': 1\n          }, {\n            $set: {\n              b: 1\n            }\n          }, {\n            checkKeys: false\n          }, function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc);\n            client.close(done);\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyApplyBitOperator","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2205,"column":39,"index":81514},"line":2205,"code":"    it('shouldCorrectlyApplyBitOperator', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var col = db.collection('shouldCorrectlyApplyBitOperator');\n          col.insert({\n            a: 1,\n            b: 1\n          }, function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            col.update({\n              a: 1\n            }, {\n              $bit: {\n                b: {\n                  and: 0\n                }\n              }\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              test.ok(result);\n              col.findOne({\n                a: 1\n              }, function (err, doc) {\n                expect(err).to.not.exist;\n                test.equal(1, doc.a);\n                test.equal(0, doc.b);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformInsertAndUpdateWithFunctionSerialization","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2254,"column":70,"index":83068},"line":2254,"code":"    it('shouldCorrectlyPerformInsertAndUpdateWithFunctionSerialization', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var col = db.collection('shouldCorrectlyPerformInsertAndUpdateWithFunctionSerialization', {\n            serializeFunctions: true\n          });\n          col.insert({\n            a: 1,\n            f: function (x) {\n              return x;\n            }\n          }, function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc);\n            col.update({\n              a: 1\n            }, {\n              $set: {\n                f: function (y) {\n                  return y;\n                }\n              }\n            }, function (err, doc) {\n              expect(err).to.not.exist;\n              test.ok(doc);\n              col.findOne({\n                a: 1\n              }, function (err, doc) {\n                expect(err).to.not.exist;\n                test.equal(trim('function (y){return y;}'), trim(doc.f.code));\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"should correctly insert > 1000 docs using insert and insertMany","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2303,"column":71,"index":84678},"line":2303,"code":"    it('should correctly insert > 1000 docs using insert and insertMany', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var col = db.collection('shouldCorrectlyAllowforMoreThanAThousandDocsInsert', {\n            serializeFunctions: true\n          });\n          var docs = [];\n          for (var i = 0; i < 2000; i++) {\n            docs.push({\n              a: i\n            });\n          }\n          col.insertMany(docs, function (err, result) {\n            expect(err).to.not.exist;\n            expect(result).property('insertedCount').to.equal(2000);\n            docs = [];\n            for (var i = 0; i < 2000; i++) {\n              docs.push({\n                a: i\n              });\n            }\n            col.insertMany(docs, function (err, res) {\n              expect(err).to.not.exist;\n              expect(res).property('insertedCount').to.equal(2000);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"should return error on unordered insertMany with multiple unique key constraints","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2345,"column":88,"index":86184},"line":2345,"code":"    it('should return error on unordered insertMany with multiple unique key constraints', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          // Get collection\n          var col = db.collection('insertManyMultipleWriteErrors');\n          col.drop(function (err, r) {\n            expect(r).to.not.exist;\n\n            // Create unique index\n            col.createIndex({\n              a: 1\n            }, {\n              unique: true\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              test.ok(r);\n              col.insertMany([{\n                a: 1\n              }, {\n                a: 2\n              }, {\n                a: 1\n              }, {\n                a: 3\n              }, {\n                a: 1\n              }], {\n                ordered: false\n              }, function (err, r) {\n                expect(r).to.not.exist;\n                expect(err).to.exist;\n                expect(err.result).to.exist;\n                expect(err.result.getWriteErrors()).to.have.length(2);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"should return error on unordered insert with multiple unique key constraints","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2397,"column":84,"index":87838},"line":2397,"code":"    it('should return error on unordered insert with multiple unique key constraints', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          // Get collection\n          var col = db.collection('insertManyMultipleWriteErrors1');\n          col.drop(function (err, r) {\n            expect(r).to.not.exist;\n\n            // Create unique index\n            col.createIndex({\n              a: 1\n            }, {\n              unique: true\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              test.ok(r);\n              col.insert([{\n                a: 1\n              }, {\n                a: 2\n              }, {\n                a: 1\n              }, {\n                a: 3\n              }, {\n                a: 1\n              }], {\n                ordered: false\n              }, function (err, r) {\n                expect(r).to.not.exist;\n                expect(err).to.exist;\n                expect(err.result).to.exist;\n                expect(err.result.getWriteErrors()).to.have.length(2);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"should return error on ordered insertMany with multiple unique key constraints","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2449,"column":86,"index":89491},"line":2449,"code":"    it('should return error on ordered insertMany with multiple unique key constraints', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          // Get collection\n          var col = db.collection('insertManyMultipleWriteErrors2');\n          col.drop(function /*err, r*/\n          () {\n            // TODO: reenable once SERVER-36317 is resolved\n            // expect(r).to.not.exist;\n\n            // Create unique index\n            col.createIndex({\n              a: 1\n            }, {\n              unique: true\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              test.ok(r);\n              col.insertMany([{\n                a: 1\n              }, {\n                a: 2\n              }, {\n                a: 1\n              }, {\n                a: 3\n              }, {\n                a: 1\n              }], {\n                ordered: true\n              }, function (err, r) {\n                expect(r).to.not.exist;\n                test.ok(err != null);\n                test.ok(err.result);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"should return error on ordered insert with multiple unique key constraints","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2502,"column":82,"index":91153},"line":2502,"code":"    it('should return error on ordered insert with multiple unique key constraints', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          // Get collection\n          var col = db.collection('insertManyMultipleWriteErrors3');\n          col.drop(function /*err, r*/\n          () {\n            // TODO: reenable once SERVER-36317 is resolved\n            // expect(r).to.not.exist;\n\n            // Create unique index\n            col.createIndex({\n              a: 1\n            }, {\n              unique: true\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              test.ok(r);\n              col.insert([{\n                a: 1\n              }, {\n                a: 2\n              }, {\n                a: 1\n              }, {\n                a: 3\n              }, {\n                a: 1\n              }], {\n                ordered: true\n              }, function (err, r) {\n                expect(r).to.not.exist;\n                test.ok(err != null);\n                test.ok(err.result);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Correctly allow forceServerObjectId for insertOne","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2555,"column":57,"index":92786},"line":2555,"code":"    it('Correctly allow forceServerObjectId for insertOne', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n      test: function (done) {\n        var started = [];\n        var succeeded = [];\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1,\n          monitorCommands: true\n        });\n        client.on('commandStarted', function (event) {\n          if (event.commandName === 'insert') started.push(event);\n        });\n        client.on('commandSucceeded', function (event) {\n          if (event.commandName === 'insert') succeeded.push(event);\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          expect(err).to.not.exist;\n          db.collection('apm_test').insertOne({\n            a: 1\n          }, {\n            forceServerObjectId: true\n          }).then(function () {\n            expect(started[0].command.documents[0]._id).to.not.exist;\n            client.close(done);\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Correctly allow forceServerObjectId for insertMany","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2589,"column":58,"index":93917},"line":2589,"code":"    it('Correctly allow forceServerObjectId for insertMany', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n      test: function (done) {\n        var started = [];\n        var succeeded = [];\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1,\n          monitorCommands: true\n        });\n        client.on('commandStarted', function (event) {\n          if (event.commandName === 'insert') started.push(event);\n        });\n        client.on('commandSucceeded', function (event) {\n          if (event.commandName === 'insert') succeeded.push(event);\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          expect(err).to.not.exist;\n          db.collection('apm_test').insertMany([{\n            a: 1\n          }], {\n            forceServerObjectId: true\n          }).then(function () {\n            expect(started[0].command.documents[0]._id).to.not.exist;\n            client.close(done);\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"should return correct number of ids for insertMany { ordered: true }","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2623,"column":76,"index":95069},"line":2623,"code":"    it('should return correct number of ids for insertMany { ordered: true }', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          expect(err).to.not.exist;\n          db.collection('inserted_ids_test').insertMany([{}, {}, {}], {\n            ordered: true\n          }).then(function (r) {\n            expect(r).property('insertedCount').to.equal(3);\n            client.close(done);\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"should return correct number of ids for insertMany { ordered: false }","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2646,"column":77,"index":95832},"line":2646,"code":"    it('should return correct number of ids for insertMany { ordered: false }', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          expect(err).to.not.exist;\n          db.collection('inserted_ids_test').insertMany([{}, {}, {}], {\n            ordered: false\n          }).then(function (r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(3);\n            client.close(done);\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Insert document including sub documents","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2670,"column":47,"index":96604},"line":2670,"code":"    it('Insert document including sub documents', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          expect(err).to.not.exist;\n          var shipment = {\n            shipment1: 'a'\n          };\n          var supplier = {\n            shipments: [shipment]\n          };\n          var product = {\n            suppliers: [supplier]\n          };\n          var doc = {\n            a: 1,\n            products: [product]\n          };\n          db.collection('sub_documents').insertOne(doc, function (err, r) {\n            expect(err).to.not.exist;\n            test.ok(r);\n            db.collection('sub_documents').find({}).next(function (err, v) {\n              expect(err).to.not.exist;\n              test.equal('a', v.products[0].suppliers[0].shipments[0].shipment1);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"MongoBulkWriteError and BulkWriteResult should respect BulkWrite","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2709,"column":72,"index":97824},"line":2709,"code":"    it('MongoBulkWriteError and BulkWriteResult should respect BulkWrite', function () {\n      return client.connect().then(() => {\n        return client.db().collection('test_insertMany_bulkResult').drop();\n      }).catch(ignoreNsNotFound).then(() => {\n        const collection = client.db().collection('test_insertMany_bulkResult');\n        return collection.insertMany([{\n          _id: 2,\n          x: 22\n        }, {\n          _id: 2,\n          x: 22\n        }, {\n          _id: 3,\n          x: 33\n        }], {\n          ordered: false\n        });\n      }).then(() => {\n        expect.fail('InsertMany should fail with multi key error');\n      }).catch(error => {\n        expect(error).to.be.instanceOf(MongoBulkWriteError);\n        expect(error.insertedCount, 'MongoBulkWriteError.insertedCount did not respect BulkResult.nInserted').to.equal(error.result.result.nInserted);\n        expect(error.result.insertedCount, 'BulkWriteResult.insertedCount did not respect BulkResult.nInserted').to.equal(error.result.result.nInserted);\n        expect(error.result.result.nInserted, 'BulkWrite did not correctly represent the operation').to.equal(2);\n      }).finally(() => client.db().collection('test_insertMany_bulkResult').drop()).finally(() => client.close());\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"should not throw an error when toArray and forEach are called after cursor is closed","suites":["Cursor"],"updatePoint":{"line":52,"column":90,"index":1165},"line":52,"code":"  it('should not throw an error when toArray and forEach are called after cursor is closed', async function () {\n    const db = client.db();\n    const collection = await db.collection('test_to_a');\n    await collection.insertMany([{\n      a: 1\n    }]);\n    const cursor = collection.find({});\n    const firstToArray = await cursor.toArray().catch(error => error);\n    expect(firstToArray).to.be.an('array');\n    expect(cursor.closed).to.be.true;\n    const secondToArray = await cursor.toArray().catch(error => error);\n    expect(secondToArray).to.be.an('array');\n    expect(secondToArray).to.have.lengthOf(0);\n    const forEachResult = await cursor.forEach(() => {\n      expect.fail('should not run forEach on an empty/closed cursor');\n    }).catch(error => error);\n    expect(forEachResult).to.be.undefined;\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"cursor should close after first next operation","suites":["Cursor"],"updatePoint":{"line":70,"column":52,"index":1942},"line":70,"code":"  it('cursor should close after first next operation', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('close_on_next', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert([{\n            a: 1\n          }, {\n            a: 1\n          }, {\n            a: 1\n          }], configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            var cursor = collection.find({});\n            this.defer(() => cursor.close());\n            cursor.batchSize(2);\n            cursor.next(err => {\n              expect(err).to.not.exist;\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"cursor should trigger getMore","suites":["Cursor"],"updatePoint":{"line":106,"column":35,"index":3050},"line":106,"code":"  it('cursor should trigger getMore', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('trigger_get_more', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert([{\n            a: 1\n          }, {\n            a: 1\n          }, {\n            a: 1\n          }], configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find({}).batchSize(2);\n            this.defer(() => cursor.close());\n            cursor.toArray(err => {\n              expect(err).to.not.exist;\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteCursorExplain","suites":["Cursor"],"updatePoint":{"line":141,"column":41,"index":4152},"line":141,"code":"  it('shouldCorrectlyExecuteCursorExplain', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_explain', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            collection.find({\n              a: 1\n            }).explain((err, explanation) => {\n              expect(err).to.not.exist;\n              expect(explanation).to.exist;\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteCursorCount","suites":["Cursor"],"updatePoint":{"line":173,"column":39,"index":5179},"line":173,"code":"  it('shouldCorrectlyExecuteCursorCount', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_count', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.find().count(err => {\n            expect(err).to.not.exist;\n            function insert(callback) {\n              var total = 10;\n              for (var i = 0; i < 10; i++) {\n                collection.insert({\n                  x: i\n                }, configuration.writeConcernMax(), e => {\n                  expect(e).to.not.exist;\n                  total = total - 1;\n                  if (total === 0) callback();\n                });\n              }\n            }\n            function finished() {\n              collection.find().count((err, count) => {\n                expect(err).to.not.exist;\n                test.equal(10, count);\n                test.ok(count.constructor === Number);\n                collection.find({}, {\n                  limit: 5\n                }).count((err, count) => {\n                  expect(err).to.not.exist;\n                  test.equal(5, count);\n                  collection.find({}, {\n                    skip: 5\n                  }).count((err, count) => {\n                    expect(err).to.not.exist;\n                    test.equal(5, count);\n                    db.collection('acollectionthatdoesn').count((err, count) => {\n                      expect(err).to.not.exist;\n                      test.equal(0, count);\n                      var cursor = collection.find();\n                      cursor.count((err, count) => {\n                        expect(err).to.not.exist;\n                        test.equal(10, count);\n                        cursor.forEach(() => {}, err => {\n                          expect(err).to.not.exist;\n                          cursor.count((err, count2) => {\n                            expect(err).to.not.exist;\n                            expect(count2).to.equal(10);\n                            expect(count2).to.equal(count);\n                            done();\n                          });\n                        });\n                      });\n                    });\n                  });\n                });\n              });\n            }\n            insert(function () {\n              finished();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute cursor count with secondary readPreference","suites":["Cursor"],"updatePoint":{"line":248,"column":73,"index":7999},"line":248,"code":"  it('should correctly execute cursor count with secondary readPreference', {\n    metadata: {\n      requires: {\n        topology: 'replicaset'\n      }\n    },\n    async test() {\n      const bag = [];\n      client.on('commandStarted', filterForCommands(['count'], bag));\n      const cursor = client.db().collection('countTEST').find({\n        qty: {\n          $gt: 4\n        }\n      });\n      await cursor.count({\n        readPreference: ReadPreference.SECONDARY\n      });\n      const selectedServerAddress = bag[0].address.replace('127.0.0.1', 'localhost').replace('[::1]', 'localhost');\n      const selectedServer = client.topology.description.servers.get(selectedServerAddress);\n      expect(selectedServer).property('type').to.equal(ServerType.RSSecondary);\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteCursorCountWithDottedCollectionName","suites":["Cursor"],"updatePoint":{"line":270,"column":63,"index":8761},"line":270,"code":"  it('shouldCorrectlyExecuteCursorCountWithDottedCollectionName', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_count.ext', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.find().count(err => {\n            expect(err).to.not.exist;\n            function insert(callback) {\n              var total = 10;\n              for (var i = 0; i < 10; i++) {\n                collection.insert({\n                  x: i\n                }, configuration.writeConcernMax(), e => {\n                  expect(e).to.not.exist;\n                  total = total - 1;\n                  if (total === 0) callback();\n                });\n              }\n            }\n            function finished() {\n              collection.find().count((err, count) => {\n                expect(err).to.not.exist;\n                test.equal(10, count);\n                test.ok(count.constructor === Number);\n                collection.find({}, {\n                  limit: 5\n                }).count((err, count) => {\n                  expect(err).to.not.exist;\n                  test.equal(5, count);\n                  collection.find({}, {\n                    skip: 5\n                  }).count((err, count) => {\n                    expect(err).to.not.exist;\n                    test.equal(5, count);\n                    db.collection('acollectionthatdoesn').count((err, count) => {\n                      expect(err).to.not.exist;\n                      test.equal(0, count);\n                      var cursor = collection.find();\n                      cursor.count((err, count) => {\n                        expect(err).to.not.exist;\n                        test.equal(10, count);\n                        cursor.forEach(() => {}, err => {\n                          expect(err).to.not.exist;\n                          cursor.count((err, count2) => {\n                            expect(err).to.not.exist;\n                            expect(count2).to.equal(10);\n                            expect(count2).to.equal(count);\n                            done();\n                          });\n                        });\n                      });\n                    });\n                  });\n                });\n              });\n            }\n            insert(function () {\n              finished();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldThrowErrorOnEachWhenMissingCallback","suites":["Cursor"],"updatePoint":{"line":345,"column":47,"index":11559},"line":345,"code":"  it('shouldThrowErrorOnEachWhenMissingCallback', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_each', (err, collection) => {\n          expect(err).to.not.exist;\n          function insert(callback) {\n            var total = 10;\n            for (var i = 0; i < 10; i++) {\n              collection.insert({\n                x: i\n              }, configuration.writeConcernMax(), e => {\n                expect(e).to.not.exist;\n                total = total - 1;\n                if (total === 0) callback();\n              });\n            }\n          }\n          function finished() {\n            const cursor = collection.find();\n            test.throws(function () {\n              cursor.forEach();\n            });\n            done();\n          }\n          insert(function () {\n            finished();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleLimitOnCursor","suites":["Cursor"],"updatePoint":{"line":387,"column":40,"index":12862},"line":387,"code":"  it('shouldCorrectlyHandleLimitOnCursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_cursor_limit', (err, collection) => {\n          function insert(callback) {\n            var total = 10;\n            for (var i = 0; i < 10; i++) {\n              collection.insert({\n                x: i\n              }, configuration.writeConcernMax(), e => {\n                expect(e).to.not.exist;\n                total = total - 1;\n                if (total === 0) callback();\n              });\n            }\n          }\n          function finished() {\n            collection.find().limit(5).toArray((err, items) => {\n              test.equal(5, items.length);\n\n              // Let's close the db\n              expect(err).to.not.exist;\n              done();\n            });\n          }\n          insert(function () {\n            finished();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleNegativeOneLimitOnCursor","suites":["Cursor"],"updatePoint":{"line":430,"column":51,"index":14219},"line":430,"code":"  it('shouldCorrectlyHandleNegativeOneLimitOnCursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_cursor_negative_one_limit', (err, collection) => {\n          expect(err).to.not.exist;\n          function insert(callback) {\n            var total = 10;\n            for (var i = 0; i < 10; i++) {\n              collection.insert({\n                x: i\n              }, configuration.writeConcernMax(), e => {\n                expect(e).to.not.exist;\n                total = total - 1;\n                if (total === 0) callback();\n              });\n            }\n          }\n          function finished() {\n            collection.find().limit(-1).toArray((err, items) => {\n              expect(err).to.not.exist;\n              test.equal(1, items.length);\n\n              // Let's close the db\n              done();\n            });\n          }\n          insert(function () {\n            finished();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleAnyNegativeLimitOnCursor","suites":["Cursor"],"updatePoint":{"line":474,"column":51,"index":15626},"line":474,"code":"  it('shouldCorrectlyHandleAnyNegativeLimitOnCursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_cursor_any_negative_limit', (err, collection) => {\n          expect(err).to.not.exist;\n          function insert(callback) {\n            var total = 10;\n            for (var i = 0; i < 10; i++) {\n              collection.insert({\n                x: i\n              }, configuration.writeConcernMax(), e => {\n                expect(e).to.not.exist;\n                total = total - 1;\n                if (total === 0) callback();\n              });\n            }\n          }\n          function finished() {\n            collection.find().limit(-5).toArray((err, items) => {\n              expect(err).to.not.exist;\n              test.equal(5, items.length);\n\n              // Let's close the db\n              done();\n            });\n          }\n          insert(function () {\n            finished();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyReturnErrorsOnIllegalLimitValuesNotAnInt","suites":["Cursor"],"updatePoint":{"line":518,"column":61,"index":17043},"line":518,"code":"  it('shouldCorrectlyReturnErrorsOnIllegalLimitValuesNotAnInt', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_limit_exceptions_2', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find();\n            this.defer(() => cursor.close());\n            try {\n              cursor.limit('not-an-integer');\n            } catch (err) {\n              test.equal('Operation \"limit\" requires an integer', err.message);\n            }\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyReturnErrorsOnIllegalLimitValuesIsClosedWithinNext","suites":["Cursor"],"updatePoint":{"line":551,"column":71,"index":18193},"line":551,"code":"  it('shouldCorrectlyReturnErrorsOnIllegalLimitValuesIsClosedWithinNext', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_limit_exceptions', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find();\n            this.defer(() => cursor.close());\n            cursor.next(err => {\n              expect(err).to.not.exist;\n              expect(() => {\n                cursor.limit(1);\n              }).to.throw(/Cursor is already initialized/);\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyReturnErrorsOnIllegalLimitValuesIsClosedWithinClose","suites":["Cursor"],"line":587,"code":"  it.skip('shouldCorrectlyReturnErrorsOnIllegalLimitValuesIsClosedWithinClose', {","file":"integration/crud/misc_cursors.test.js","skipped":true,"dir":"test"},{"name":"shouldCorrectlySkipRecordsOnCursor","suites":["Cursor"],"updatePoint":{"line":620,"column":40,"index":20522},"line":620,"code":"  it('shouldCorrectlySkipRecordsOnCursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_skip', (err, collection) => {\n          expect(err).to.not.exist;\n          const insert = callback => {\n            var total = 10;\n            for (var i = 0; i < 10; i++) {\n              collection.insert({\n                x: i\n              }, configuration.writeConcernMax(), e => {\n                expect(e).to.not.exist;\n                total = total - 1;\n                if (total === 0) callback();\n              });\n            }\n          };\n          insert(() => {\n            const cursor = collection.find();\n            this.defer(() => cursor.close());\n            cursor.count((err, count) => {\n              expect(err).to.not.exist;\n              test.equal(10, count);\n            });\n            const cursor2 = collection.find();\n            this.defer(() => cursor2.close());\n            cursor2.toArray((err, items) => {\n              expect(err).to.not.exist;\n              test.equal(10, items.length);\n              collection.find().skip(2).toArray((err, items2) => {\n                expect(err).to.not.exist;\n                test.equal(8, items2.length);\n\n                // Check that we have the same elements\n                var numberEqual = 0;\n                var sliced = items.slice(2, 10);\n                for (var i = 0; i < sliced.length; i++) {\n                  if (sliced[i].x === items2[i].x) numberEqual = numberEqual + 1;\n                }\n                test.equal(8, numberEqual);\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyReturnErrorsOnIllegalSkipValues","suites":["Cursor"],"updatePoint":{"line":679,"column":52,"index":22623},"line":679,"code":"  it('shouldCorrectlyReturnErrorsOnIllegalSkipValues', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_skip_exceptions', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            try {\n              collection.find().skip('not-an-integer');\n            } catch (err) {\n              test.equal('Operation \"skip\" requires an integer', err.message);\n            }\n            const cursor = collection.find();\n            cursor.next(err => {\n              expect(err).to.not.exist;\n\n              // NOTE: who cares what you set when closed, if not initialized\n              // expect(() => {\n              //   cursor.skip(1);\n              // }).to.throw(/not extensible/);\n\n              const cursor2 = collection.find();\n              cursor2.close(err => {\n                expect(err).to.not.exist;\n\n                // NOTE: who cares what you set when closed, if not initialized\n                // expect(() => {\n                //   cursor2.skip(1);\n                // }).to.throw(/not extensible/);\n\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldReturnErrorsOnIllegalBatchSizes","suites":["Cursor"],"updatePoint":{"line":730,"column":43,"index":24343},"line":730,"code":"  it('shouldReturnErrorsOnIllegalBatchSizes', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_batchSize_exceptions', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            let cursor = collection.find();\n            try {\n              cursor.batchSize('not-an-integer');\n              test.ok(false);\n            } catch (err) {\n              test.equal('Operation \"batchSize\" requires an integer', err.message);\n            }\n            cursor = collection.find();\n            cursor.next(err => {\n              expect(err).to.not.exist;\n              cursor.next(err => {\n                expect(err).to.not.exist;\n\n                // NOTE: who cares what you set when closed, if not initialized\n                // expect(() => {\n                //   cursor.batchSize(1);\n                // }).to.throw(/not extensible/);\n\n                const cursor2 = collection.find();\n                cursor2.close(err => {\n                  expect(err).to.not.exist;\n\n                  // NOTE: who cares what you set when closed, if not initialized\n                  // expect(() => {\n                  //   cursor2.batchSize(1);\n                  // }).to.throw(/not extensible/);\n\n                  done();\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleBatchSize","suites":["Cursor"],"updatePoint":{"line":786,"column":36,"index":26259},"line":786,"code":"  it('shouldCorrectlyHandleBatchSize', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_multiple_batch_size', (err, collection) => {\n          expect(err).to.not.exist;\n\n          //test with the last batch that is a multiple of batchSize\n          var records = 4;\n          var batchSize = 2;\n          var docs = [];\n          for (var i = 0; i < records; i++) {\n            docs.push({\n              a: i\n            });\n          }\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find({}, {\n              batchSize: batchSize\n            });\n\n            //1st\n            cursor.next((err, items) => {\n              expect(err).to.not.exist;\n              test.equal(1, cursor.bufferedCount());\n              test.ok(items != null);\n\n              //2nd\n              cursor.next((err, items) => {\n                expect(err).to.not.exist;\n                test.equal(0, cursor.bufferedCount());\n                test.ok(items != null);\n\n                //3rd\n                cursor.next((err, items) => {\n                  expect(err).to.not.exist;\n                  test.equal(1, cursor.bufferedCount());\n                  test.ok(items != null);\n\n                  //4th\n                  cursor.next((err, items) => {\n                    expect(err).to.not.exist;\n                    test.equal(0, cursor.bufferedCount());\n                    test.ok(items != null);\n\n                    //No more\n                    cursor.next((err, items) => {\n                      expect(err).to.not.exist;\n                      test.ok(items == null);\n                      test.ok(cursor.closed);\n                      done();\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldHandleWhenLimitBiggerThanBatchSize","suites":["Cursor"],"updatePoint":{"line":858,"column":46,"index":28608},"line":858,"code":"  it('shouldHandleWhenLimitBiggerThanBatchSize', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_limit_greater_than_batch_size', (err, collection) => {\n          expect(err).to.not.exist;\n          var limit = 4;\n          var records = 10;\n          var batchSize = 3;\n          var docs = [];\n          for (var i = 0; i < records; i++) {\n            docs.push({\n              a: i\n            });\n          }\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            var cursor = collection.find({}, {\n              batchSize: batchSize,\n              limit: limit\n            });\n            //1st\n            cursor.next(err => {\n              expect(err).to.not.exist;\n              test.equal(2, cursor.bufferedCount());\n\n              //2nd\n              cursor.next(err => {\n                expect(err).to.not.exist;\n                test.equal(1, cursor.bufferedCount());\n\n                //3rd\n                cursor.next(err => {\n                  expect(err).to.not.exist;\n                  test.equal(0, cursor.bufferedCount());\n\n                  //4th\n                  cursor.next(err => {\n                    expect(err).to.not.exist;\n\n                    //No more\n                    cursor.next((err, items) => {\n                      expect(err).to.not.exist;\n                      test.ok(items == null);\n                      test.ok(cursor.closed);\n                      done();\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldHandleLimitLessThanBatchSize","suites":["Cursor"],"updatePoint":{"line":924,"column":40,"index":30683},"line":924,"code":"  it('shouldHandleLimitLessThanBatchSize', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_limit_less_than_batch_size', (err, collection) => {\n          expect(err).to.not.exist;\n          var limit = 2;\n          var records = 10;\n          var batchSize = 4;\n          var docs = [];\n          for (var i = 0; i < records; i++) {\n            docs.push({\n              a: i\n            });\n          }\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            var cursor = collection.find({}, {\n              batchSize: batchSize,\n              limit: limit\n            });\n            //1st\n            cursor.next(err => {\n              expect(err).to.not.exist;\n              test.equal(1, cursor.bufferedCount());\n\n              //2nd\n              cursor.next(err => {\n                expect(err).to.not.exist;\n                test.equal(0, cursor.bufferedCount());\n\n                //No more\n                cursor.next((err, items) => {\n                  expect(err).to.not.exist;\n                  test.ok(items == null);\n                  test.ok(cursor.closed);\n                  done();\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldHandleSkipLimitChaining","suites":["Cursor"],"updatePoint":{"line":979,"column":35,"index":32409},"line":979,"code":"  it('shouldHandleSkipLimitChaining', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var collection = db.collection('shouldHandleSkipLimitChaining');\n        function insert(callback) {\n          var total = 10;\n          for (var i = 0; i < 10; i++) {\n            collection.insert({\n              x: i\n            }, configuration.writeConcernMax(), e => {\n              expect(e).to.not.exist;\n              total = total - 1;\n              if (total === 0) callback();\n            });\n          }\n        }\n        function finished() {\n          collection.find().toArray((err, items) => {\n            expect(err).to.not.exist;\n            test.equal(10, items.length);\n            collection.find().limit(5).skip(3).toArray(function (err, items2) {\n              expect(err).to.not.exist;\n              test.equal(5, items2.length);\n\n              // Check that we have the same elements\n              var numberEqual = 0;\n              var sliced = items.slice(3, 8);\n              for (var i = 0; i < sliced.length; i++) {\n                if (sliced[i].x === items2[i].x) numberEqual = numberEqual + 1;\n              }\n              test.equal(5, numberEqual);\n              done();\n            });\n          });\n        }\n        insert(function () {\n          finished();\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleLimitSkipChainingInline","suites":["Cursor"],"updatePoint":{"line":1031,"column":50,"index":34177},"line":1031,"code":"  it('shouldCorrectlyHandleLimitSkipChainingInline', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_limit_skip_chaining_inline', (err, collection) => {\n          expect(err).to.not.exist;\n          function insert(callback) {\n            var total = 10;\n            for (var i = 0; i < 10; i++) {\n              collection.insert({\n                x: i\n              }, configuration.writeConcernMax(), e => {\n                expect(e).to.not.exist;\n                total = total - 1;\n                if (total === 0) callback();\n              });\n            }\n          }\n          function finished() {\n            collection.find().toArray((err, items) => {\n              expect(err).to.not.exist;\n              test.equal(10, items.length);\n              collection.find().limit(5).skip(3).toArray(function (err, items2) {\n                expect(err).to.not.exist;\n                test.equal(5, items2.length);\n\n                // Check that we have the same elements\n                var numberEqual = 0;\n                var sliced = items.slice(3, 8);\n                for (var i = 0; i < sliced.length; i++) {\n                  if (sliced[i].x === items2[i].x) numberEqual = numberEqual + 1;\n                }\n                test.equal(5, numberEqual);\n                done();\n              });\n            });\n          }\n          insert(function () {\n            finished();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCloseCursorNoQuerySent","suites":["Cursor"],"updatePoint":{"line":1085,"column":34,"index":36056},"line":1085,"code":"  it('shouldCloseCursorNoQuerySent', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_close_no_query_sent', (err, collection) => {\n          expect(err).to.not.exist;\n          const cursor = collection.find();\n          cursor.close(err => {\n            expect(err).to.not.exist;\n            test.equal(true, cursor.closed);\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRefillViaGetMoreCommand","suites":["Cursor"],"updatePoint":{"line":1111,"column":44,"index":36921},"line":1111,"code":"  it('shouldCorrectlyRefillViaGetMoreCommand', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var COUNT = 1000;\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_refill_via_get_more', (err, collection) => {\n          expect(err).to.not.exist;\n          function insert(callback) {\n            var docs = [];\n            for (var i = 0; i < COUNT; i++) {\n              docs.push({\n                a: i\n              });\n            }\n            collection.insertMany(docs, configuration.writeConcernMax(), callback);\n          }\n          function finished() {\n            collection.count((err, count) => {\n              expect(err).to.not.exist;\n              test.equal(COUNT, count);\n            });\n            var total = 0;\n            collection.find({}, {}).forEach(item => {\n              total = total + item.a;\n            }, err => {\n              expect(err).to.not.exist;\n              test.equal(499500, total);\n              collection.count((err, count) => {\n                expect(err).to.not.exist;\n                test.equal(COUNT, count);\n              });\n              collection.count((err, count) => {\n                expect(err).to.not.exist;\n                test.equal(COUNT, count);\n                var total2 = 0;\n                collection.find().forEach(item => {\n                  total2 = total2 + item.a;\n                }, err => {\n                  expect(err).to.not.exist;\n                  test.equal(499500, total2);\n                  collection.count((err, count) => {\n                    expect(err).to.not.exist;\n                    test.equal(COUNT, count);\n                    test.equal(total, total2);\n                    done();\n                  });\n                });\n              });\n            });\n          }\n          insert(function () {\n            finished();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRefillViaGetMoreAlternativeCollection","suites":["Cursor"],"updatePoint":{"line":1178,"column":58,"index":39223},"line":1178,"code":"  it('shouldCorrectlyRefillViaGetMoreAlternativeCollection', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_refill_via_get_more_alt_coll', (err, collection) => {\n          expect(err).to.not.exist;\n          var COUNT = 1000;\n          function insert(callback) {\n            var docs = [];\n            for (var i = 0; i < COUNT; i++) {\n              docs.push({\n                a: i\n              });\n            }\n            collection.insertMany(docs, configuration.writeConcernMax(), callback);\n          }\n          function finished() {\n            collection.count((err, count) => {\n              expect(err).to.not.exist;\n              test.equal(1000, count);\n            });\n            var total = 0;\n            collection.find().forEach(doc => {\n              total = total + doc.a;\n            }, err => {\n              expect(err).to.not.exist;\n              test.equal(499500, total);\n              collection.count((err, count) => {\n                expect(err).to.not.exist;\n                test.equal(1000, count);\n              });\n              collection.count((err, count) => {\n                expect(err).to.not.exist;\n                test.equal(1000, count);\n                var total2 = 0;\n                collection.find().forEach(doc => {\n                  total2 = total2 + doc.a;\n                }, err => {\n                  expect(err).to.not.exist;\n                  expect(total2).to.equal(499500);\n                  collection.count((err, count) => {\n                    expect(err).to.not.exist;\n                    expect(count).to.equal(1000);\n                    expect(total2).to.equal(total);\n                    done();\n                  });\n                });\n              });\n            });\n          }\n          insert(function () {\n            finished();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCloseCursorAfterQueryHasBeenSent","suites":["Cursor"],"updatePoint":{"line":1245,"column":44,"index":41525},"line":1245,"code":"  it('shouldCloseCursorAfterQueryHasBeenSent', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_close_after_query_sent', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find({\n              a: 1\n            });\n            cursor.next(err => {\n              expect(err).to.not.exist;\n              cursor.close(err => {\n                expect(err).to.not.exist;\n                test.equal(true, cursor.closed);\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteCursorCountWithFields","suites":["Cursor"],"updatePoint":{"line":1281,"column":49,"index":42697},"line":1281,"code":"  it('shouldCorrectlyExecuteCursorCountWithFields', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_count_with_fields', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insertOne({\n            x: 1,\n            a: 2\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            collection.find({}).project({\n              a: 1\n            }).toArray((err, items) => {\n              expect(err).to.not.exist;\n              test.equal(1, items.length);\n              test.equal(2, items[0].a);\n              expect(items[0].x).to.not.exist;\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCountWithFieldsUsingExclude","suites":["Cursor"],"updatePoint":{"line":1316,"column":48,"index":43857},"line":1316,"code":"  it('shouldCorrectlyCountWithFieldsUsingExclude', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_count_with_fields_using_exclude', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insertOne({\n            x: 1,\n            a: 2\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            collection.find({}, {\n              projection: {\n                x: 0\n              }\n            }).toArray((err, items) => {\n              expect(err).to.not.exist;\n              test.equal(1, items.length);\n              test.equal(2, items[0].a);\n              expect(items[0].x).to.not.exist;\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute count on cursor","suites":["Cursor"],"updatePoint":{"line":1353,"column":46,"index":45067},"line":1353,"code":"  it('Should correctly execute count on cursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      for (var i = 0; i < 1000; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('Should_correctly_execute_count_on_cursor_1', (err, collection) => {\n          expect(err).to.not.exist;\n\n          // insert all docs\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            let total = 0;\n            // Create a cursor for the content\n            const cursor = collection.find({});\n            this.defer(() => cursor.close());\n            cursor.count(err => {\n              expect(err).to.not.exist;\n              // Ensure each returns all documents\n              cursor.forEach(() => {\n                total++;\n              }, err => {\n                expect(err).to.not.exist;\n                cursor.count((err, c) => {\n                  expect(err).to.not.exist;\n                  expect(c).to.equal(1000);\n                  expect(total).to.equal(1000);\n                  done();\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"does not auto destroy streams","suites":["Cursor"],"updatePoint":{"line":1405,"column":35,"index":46785},"line":1405,"code":"  it('does not auto destroy streams', function (done) {\n    const docs = [];\n    for (var i = 0; i < 10; i++) {\n      docs.push({\n        a: i + 1\n      });\n    }\n    const configuration = this.configuration;\n    client.connect((err, client) => {\n      expect(err).to.not.exist;\n      const db = client.db(configuration.db);\n      db.createCollection('does_not_autodestroy_streams', (err, collection) => {\n        expect(err).to.not.exist;\n        collection.insertMany(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n          const cursor = collection.find();\n          const stream = cursor.stream();\n          stream.on('close', () => {\n            expect.fail('extra close event must not be called');\n          });\n          stream.on('end', () => {\n            client.close();\n            done();\n          });\n          stream.on('data', doc => {\n            expect(doc).to.exist;\n          });\n          stream.resume();\n        });\n      });\n    });\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should be able to stream documents","suites":["Cursor"],"updatePoint":{"line":1437,"column":40,"index":47791},"line":1437,"code":"  it('should be able to stream documents', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      for (var i = 0; i < 1000; i++) {\n        docs[i] = {\n          a: i + 1\n        };\n      }\n      var count = 0;\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('Should_be_able_to_stream_documents', (err, collection) => {\n          expect(err).to.not.exist;\n\n          // insert all docs\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            var paused = 0,\n              closed = 0,\n              resumed = 0,\n              i = 0;\n            const cursor = collection.find();\n            const stream = cursor.stream();\n            stream.on('data', function (doc) {\n              test.equal(true, !!doc);\n              test.equal(true, !!doc.a);\n              count = count + 1;\n              if (paused > 0 && 0 === resumed) {\n                err = new Error('data emitted during pause');\n                return testDone();\n              }\n              if (++i === 3) {\n                stream.pause();\n                paused++;\n                setTimeout(function () {\n                  stream.resume();\n                  resumed++;\n                }, 20);\n              }\n            });\n            stream.once('error', function (er) {\n              err = er;\n              testDone();\n            });\n            stream.once('end', function () {\n              closed++;\n              testDone();\n            });\n            function testDone() {\n              expect(err).to.not.exist;\n              test.equal(i, docs.length);\n              test.equal(1, closed);\n              test.equal(1, paused);\n              test.equal(1, resumed);\n              test.strictEqual(cursor.closed, true);\n              done();\n            }\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"immediately destroying a stream prevents the query from executing","suites":["Cursor"],"updatePoint":{"line":1509,"column":71,"index":50104},"line":1509,"code":"  it('immediately destroying a stream prevents the query from executing', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var i = 0,\n        docs = [{\n          b: 2\n        }, {\n          b: 3\n        }],\n        doneCalled = 0;\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('immediately_destroying_a_stream_prevents_the_query_from_executing', (err, collection) => {\n          expect(err).to.not.exist;\n\n          // insert all docs\n          collection.insertMany(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find();\n            const stream = cursor.stream();\n            stream.on('data', function () {\n              i++;\n            });\n            cursor.once('close', testDone('close'));\n            stream.once('error', testDone('error'));\n            stream.destroy();\n            function testDone() {\n              return err => {\n                ++doneCalled;\n                if (doneCalled === 1) {\n                  expect(err).to.not.exist;\n                  test.strictEqual(0, i);\n                  test.strictEqual(true, cursor.closed);\n                  done();\n                }\n              };\n            }\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"removes session wheen cloning a find cursor","suites":["Cursor"],"updatePoint":{"line":1560,"column":49,"index":51755},"line":1560,"code":"  it('removes session wheen cloning a find cursor', function (done) {\n    const configuration = this.configuration;\n    client.connect((err, client) => {\n      expect(err).to.not.exist;\n      const db = client.db(configuration.db);\n      db.createCollection('clone_find_cursor_session', (err, collection) => {\n        expect(err).to.not.exist;\n        collection.insertOne({\n          a: 1\n        }, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n          const cursor = collection.find();\n          const clonedCursor = cursor.clone();\n          cursor.toArray(err => {\n            expect(err).to.not.exist;\n            clonedCursor.toArray(err => {\n              expect(err).to.not.exist;\n              client.close();\n              done();\n            });\n          });\n        });\n      });\n    });\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"removes session wheen cloning an aggregation cursor","suites":["Cursor"],"updatePoint":{"line":1585,"column":57,"index":52605},"line":1585,"code":"  it('removes session wheen cloning an aggregation cursor', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        const db = client.db(configuration.db);\n        db.createCollection('clone_aggregation_cursor_session', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insertOne({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.aggregate([{\n              $match: {\n                a: 1\n              }\n            }]);\n            const clonedCursor = cursor.clone();\n            cursor.toArray(err => {\n              expect(err).to.not.exist;\n              clonedCursor.toArray(err => {\n                expect(err).to.not.exist;\n                client.close();\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"destroying a stream stops it","suites":["Cursor"],"updatePoint":{"line":1621,"column":34,"index":53689},"line":1621,"code":"  it('destroying a stream stops it', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('destroying_a_stream_stops_it', (err, collection) => {\n          expect(err).to.not.exist;\n          var docs = [];\n          for (var ii = 0; ii < 10; ++ii) docs.push({\n            b: ii + 1\n          });\n\n          // insert all docs\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            var finished = 0,\n              i = 0;\n            const cursor = collection.find();\n            const stream = cursor.stream();\n            test.strictEqual(false, cursor.closed);\n            stream.on('data', function () {\n              if (++i === 5) {\n                stream.destroy();\n              }\n            });\n            cursor.once('close', testDone);\n            stream.once('error', testDone);\n            stream.once('end', testDone);\n            function testDone(err) {\n              ++finished;\n              if (finished === 2) {\n                test.strictEqual(undefined, err);\n                test.strictEqual(5, i);\n                test.strictEqual(2, finished);\n                test.strictEqual(true, cursor.closed);\n                done();\n              }\n            }\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"cursor stream errors","suites":["Cursor"],"line":1675,"code":"  it.skip('cursor stream errors', {","file":"integration/crud/misc_cursors.test.js","skipped":true,"dir":"test"},{"name":"cursor stream pipe","suites":["Cursor"],"updatePoint":{"line":1733,"column":24,"index":57362},"line":1733,"code":"  it('cursor stream pipe', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('cursor_stream_pipe', (err, collection) => {\n          expect(err).to.not.exist;\n          var docs = [];\n          'Aaden Aaron Adrian Aditya Bob Joe'.split(' ').forEach(function (name) {\n            docs.push({\n              name: name\n            });\n          });\n\n          // insert all docs\n          collection.insertMany(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const filename = path.join(os.tmpdir(), '_nodemongodbnative_stream_out.txt');\n            const out = fs.createWriteStream(filename);\n            const stream = collection.find().stream({\n              transform: doc => JSON.stringify(doc)\n            });\n            stream.pipe(out);\n            // Wait for output stream to close\n            out.on('close', testDone);\n            function testDone(err) {\n              // Object.prototype.toString = toString;\n              test.strictEqual(undefined, err);\n              var contents = fs.readFileSync(filename, 'utf8');\n              test.ok(/Aaden/.test(contents));\n              test.ok(/Aaron/.test(contents));\n              test.ok(/Adrian/.test(contents));\n              test.ok(/Aditya/.test(contents));\n              test.ok(/Bob/.test(contents));\n              test.ok(/Joe/.test(contents));\n              fs.unlinkSync(filename);\n              done();\n            }\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should close dead tailable cursors","suites":["Cursor"],"updatePoint":{"line":1785,"column":40,"index":59316},"line":1785,"code":"  it('should close dead tailable cursors', {\n    metadata: {\n      os: '!win32' // NODE-2943: timeout on windows\n    },\n\n    test: function (done) {\n      // http://www.mongodb.org/display/DOCS/Tailable+Cursors\n\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        const options = {\n          capped: true,\n          size: 10000000\n        };\n        db.createCollection('test_if_dead_tailable_cursors_close', options, function (err, collection) {\n          expect(err).to.not.exist;\n          let closeCount = 0;\n          const docs = Array.from({\n            length: 100\n          }).map(() => ({\n            a: 1\n          }));\n          collection.insertMany(docs, {\n            w: 'majority',\n            wtimeoutMS: 5000\n          }, err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find({}, {\n              tailable: true,\n              awaitData: true\n            });\n            const stream = cursor.stream();\n            stream.resume();\n            var validator = () => {\n              closeCount++;\n              if (closeCount === 2) {\n                done();\n              }\n            };\n\n            // we validate that the stream \"ends\" either cleanly or with an error\n            stream.on('end', validator);\n            stream.on('error', validator);\n            cursor.on('close', validator);\n            const docs = Array.from({\n              length: 100\n            }).map(() => ({\n              a: 1\n            }));\n            collection.insertMany(docs, err => {\n              expect(err).to.not.exist;\n              setTimeout(() => client.close());\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldAwaitData","suites":["Cursor"],"updatePoint":{"line":1846,"column":21,"index":61146},"line":1846,"code":"  it('shouldAwaitData', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      // http://www.mongodb.org/display/DOCS/Tailable+Cursors\n\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        const options = {\n          capped: true,\n          size: 8\n        };\n        db.createCollection('should_await_data_retry_tailable_cursor', options, (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n\n            // Create cursor with awaitData, and timeout after the period specified\n            const cursor = collection.find({}, {\n              tailable: true,\n              awaitData: true\n            });\n            this.defer(() => cursor.close());\n\n            // Execute each\n            cursor.forEach(() => cursor.close(), () => {\n              // Even though cursor is exhausted, should not close session\n              // unless cursor is manually closed, due to awaitData / tailable\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldAwaitDataWithDocumentsAvailable","suites":["Cursor"],"updatePoint":{"line":1891,"column":43,"index":62671},"line":1891,"code":"  it('shouldAwaitDataWithDocumentsAvailable', function (done) {\n    // http://www.mongodb.org/display/DOCS/Tailable+Cursors\n\n    const configuration = this.configuration;\n    const client = configuration.newClient({\n      maxPoolSize: 1\n    });\n    client.connect((err, client) => {\n      expect(err).to.not.exist;\n      this.defer(() => client.close());\n      const db = client.db(configuration.db);\n      const options = {\n        capped: true,\n        size: 8\n      };\n      db.createCollection('should_await_data_no_docs', options, (err, collection) => {\n        expect(err).to.not.exist;\n\n        // Create cursor with awaitData, and timeout after the period specified\n        const cursor = collection.find({}, {\n          tailable: true,\n          awaitData: true\n        });\n        this.defer(() => cursor.close());\n        cursor.forEach(() => {}, err => {\n          expect(err).to.not.exist;\n          done();\n        });\n      });\n    });\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should block waiting for new data to arrive when the cursor reaches the end of the capped collection","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":1932,"column":108,"index":63996},"line":1932,"code":"    it('should block waiting for new data to arrive when the cursor reaches the end of the capped collection', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.2'\n        }\n      },\n      async test() {\n        const db = client.db('cursor_tailable');\n        try {\n          await db.collection('cursor_tailable').drop();\n          // eslint-disable-next-line no-empty\n        } catch (_) {}\n        const collection = await db.createCollection('cursor_tailable', {\n          capped: true,\n          size: 10000\n        });\n        const res = await collection.insertOne({\n          a: 1\n        });\n        expect(res).property('insertedId').to.exist;\n        cursor = collection.find({}, {\n          batchSize: 2,\n          tailable: true,\n          awaitData: true\n        });\n        const doc0 = await cursor.next();\n        expect(doc0).to.have.property('a', 1);\n\n        // After 300ms make an insert\n        const later = runLater(async () => {\n          const res = await collection.insertOne({\n            b: 2\n          });\n          expect(res).property('insertedId').to.exist;\n        }, 300);\n        const start = new Date();\n        const doc1 = await cursor.next();\n        expect(doc1).to.have.property('b', 2);\n        const end = new Date();\n        await later; // make sure this finished, without a failure\n\n        // We should see here that cursor.next blocked for at least 300ms\n        expect(end.getTime() - start.getTime()).to.be.at.least(300);\n      }\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly retry tailable cursor connection","suites":["Cursor","awaiting data core tailable cursor test"],"line":1980,"code":"  it.skip('Should correctly retry tailable cursor connection', {","file":"integration/crud/misc_cursors.test.js","skipped":true,"dir":"test"},{"name":"shouldCorrectExecuteExplainHonoringLimit","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2021,"column":46,"index":66881},"line":2021,"code":"  it('shouldCorrectExecuteExplainHonoringLimit', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      docs[0] = {\n        _keywords: ['compact', 'ii2gd', 'led', '24-48v', 'presse-etoupe', 'bexbgl1d24483', 'flash', '48v', 'eexd', 'feu', 'presse', 'compris', 'rouge', 'etoupe', 'iic', 'ii2gdeexdiict5', 'red', 'aet']\n      };\n      docs[1] = {\n        _keywords: ['reducteur', '06212', 'd20/16', 'manch', 'd20', 'manchon', 'ard', 'sable', 'irl', 'red']\n      };\n      docs[2] = {\n        _keywords: ['reducteur', '06214', 'manch', 'd25/20', 'd25', 'manchon', 'ard', 'sable', 'irl', 'red']\n      };\n      docs[3] = {\n        _keywords: ['bar', 'rac', 'boite', '6790178', '50-240/4-35', '240', 'branch', 'coulee', 'ddc', 'red', 'ip2x']\n      };\n      docs[4] = {\n        _keywords: ['bar', 'ip2x', 'boite', '6790158', 'ddi', '240', 'branch', 'injectee', '50-240/4-35?', 'red']\n      };\n      docs[5] = {\n        _keywords: ['bar', 'ip2x', 'boite', '6790179', 'coulee', '240', 'branch', 'sdc', '50-240/4-35?', 'red', 'rac']\n      };\n      docs[6] = {\n        _keywords: ['bar', 'ip2x', 'boite', '6790159', '240', 'branch', 'injectee', '50-240/4-35?', 'sdi', 'red']\n      };\n      docs[7] = {\n        _keywords: ['6000', 'r-6000', 'resin', 'high', '739680', 'red', 'performance', 'brd', 'with', 'ribbon', 'flanges']\n      };\n      docs[8] = {\n        _keywords: ['804320', 'for', 'paint', 'roads', 'brd', 'red']\n      };\n      docs[9] = {\n        _keywords: ['38mm', 'padlock', 'safety', '813594', 'brd', 'red']\n      };\n      docs[10] = {\n        _keywords: ['114551', 'r6900', 'for', 'red', 'bmp71', 'brd', 'ribbon']\n      };\n      docs[11] = {\n        _keywords: ['catena', 'diameter', '621482', 'rings', 'brd', 'legend', 'red', '2mm']\n      };\n      docs[12] = {\n        _keywords: ['catena', 'diameter', '621491', 'rings', '5mm', 'brd', 'legend', 'red']\n      };\n      docs[13] = {\n        _keywords: ['catena', 'diameter', '621499', 'rings', '3mm', 'brd', 'legend', 'red']\n      };\n      docs[14] = {\n        _keywords: ['catena', 'diameter', '621508', 'rings', '5mm', 'brd', 'legend', 'red']\n      };\n      docs[15] = {\n        _keywords: ['insert', 'for', 'cable', '3mm', 'carrier', '621540', 'blank', 'brd', 'ademark', 'red']\n      };\n      docs[16] = {\n        _keywords: ['insert', 'for', 'cable', '621544', '3mm', 'carrier', 'brd', 'ademark', 'legend', 'red']\n      };\n      docs[17] = {\n        _keywords: ['catena', 'diameter', '6mm', '621518', 'rings', 'brd', 'legend', 'red']\n      };\n      docs[18] = {\n        _keywords: ['catena', 'diameter', '621455', '8mm', 'rings', 'brd', 'legend', 'red']\n      };\n      docs[19] = {\n        _keywords: ['catena', 'diameter', '621464', 'rings', '5mm', 'brd', 'legend', 'red']\n      };\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        // Insert all the docs\n        var collection = db.collection('shouldCorrectExecuteExplainHonoringLimit');\n        collection.insert(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n          collection.createIndex({\n            _keywords: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            collection.find({\n              _keywords: 'red'\n            }).limit(10).toArray(function (err, result) {\n              expect(err).to.not.exist;\n              test.ok(result != null);\n              collection.find({\n                _keywords: 'red'\n              }, {}).limit(10).explain(function (err, result) {\n                expect(err).to.not.exist;\n                test.ok(result != null);\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldNotExplainWhenFalse","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2122,"column":31,"index":70945},"line":2122,"code":"  it('shouldNotExplainWhenFalse', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var doc = {\n        name: 'camera',\n        _keywords: ['compact', 'ii2gd', 'led', 'red', 'aet']\n      };\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var collection = db.collection('shouldNotExplainWhenFalse');\n        collection.insert(doc, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n          collection.find({\n            _keywords: 'red'\n          }).limit(10).toArray(function (err, result) {\n            expect(err).to.not.exist;\n            test.equal('camera', result[0].name);\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldFailToSetReadPreferenceOnCursor","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2154,"column":43,"index":72026},"line":2154,"code":"  it('shouldFailToSetReadPreferenceOnCursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        try {\n          db.collection('shouldFailToSetReadPreferenceOnCursor').find().withReadPreference('notsecondary');\n          test.ok(false);\n        } catch (err) {} // eslint-disable-line\n\n        db.collection('shouldFailToSetReadPreferenceOnCursor').find().withReadPreference('secondary');\n        done();\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should allow setting the cursors readConcern through a builder","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2178,"column":68,"index":72911},"line":2178,"code":"  it('should allow setting the cursors readConcern through a builder', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.2'\n      }\n    },\n    test: function (done) {\n      const client = this.configuration.newClient({\n        monitorCommands: true\n      });\n      const events = [];\n      client.on('commandStarted', event => {\n        if (event.commandName === 'find') {\n          events.push(event);\n        }\n      });\n      const db = client.db(this.configuration.db);\n      const cursor = db.collection('foo').find().withReadConcern('local');\n      expect(cursor).property('readConcern').to.have.property('level').equal('local');\n      cursor.toArray(err => {\n        expect(err).to.not.exist;\n        expect(events).to.have.length(1);\n        const findCommand = events[0];\n        expect(findCommand).nested.property('command.readConcern').to.eql({\n          level: 'local'\n        });\n        client.close(done);\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldNotFailDueToStackOverflowEach","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2208,"column":41,"index":73836},"line":2208,"code":"  it('shouldNotFailDueToStackOverflowEach', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('shouldNotFailDueToStackOverflowEach', (err, collection) => {\n          expect(err).to.not.exist;\n          var docs = [];\n          var total = 0;\n          for (var i = 0; i < 30000; i++) docs.push({\n            a: i\n          });\n          var allDocs = [];\n          var left = 0;\n          while (docs.length > 0) {\n            allDocs.push(docs.splice(0, 1000));\n          }\n          // Get all batches we must insert\n          left = allDocs.length;\n          var totalI = 0;\n\n          // Execute inserts\n          for (i = 0; i < left; i++) {\n            collection.insert(allDocs.shift(), configuration.writeConcernMax(), function (err, d) {\n              expect(err).to.not.exist;\n              left = left - 1;\n              totalI = totalI + d.length;\n              if (left === 0) {\n                collection.find({}).forEach(() => {\n                  total++;\n                }, err => {\n                  expect(err).to.not.exist;\n                  expect(total).to.equal(30000);\n                  done();\n                });\n              }\n            });\n          }\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should not fail due to stack overflow toArray","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2259,"column":51,"index":75516},"line":2259,"code":"  it('should not fail due to stack overflow toArray', async function () {\n    const configuration = this.configuration;\n    const db = client.db(configuration.db);\n    const collection = await db.createCollection('shouldNotFailDueToStackOverflowToArray');\n    var docs = Array.from({\n      length: 30000\n    }, (_, i) => ({\n      a: i\n    }));\n    var allDocs = [];\n    var left = 0;\n    while (docs.length > 0) {\n      allDocs.push(docs.splice(0, 1000));\n    }\n    // Get all batches we must insert\n    left = allDocs.length;\n    var totalI = 0;\n    var timeout = 0;\n\n    // Execute inserts\n    for (let i = 0; i < left; i++) {\n      await sleep(timeout);\n      const d = await collection.insert(allDocs.shift());\n      left = left - 1;\n      totalI = totalI + d.length;\n      if (left === 0) {\n        const items = await collection.find({}).toArray();\n        expect(items).to.have.a.lengthOf(3000);\n      }\n      timeout = timeout + 100;\n    }\n    await client.close();\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should correctly skip and limit","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2292,"column":37,"index":76482},"line":2292,"code":"  it('should correctly skip and limit', function (done) {\n    const configuration = this.configuration;\n    client.connect((err, client) => {\n      expect(err).to.not.exist;\n      const db = client.db(configuration.db);\n      var collection = db.collection('shouldCorrectlySkipAndLimit');\n      var docs = [];\n      for (var i = 0; i < 100; i++) docs.push({\n        a: i,\n        OrderNumber: i\n      });\n      collection.insert(docs, configuration.writeConcernMax(), err => {\n        expect(err).to.not.exist;\n        collection.find({}, {\n          OrderNumber: 1\n        }).skip(10).limit(10).toArray((err, items) => {\n          expect(err).to.not.exist;\n          test.equal(10, items[0].OrderNumber);\n          collection.find({}, {\n            OrderNumber: 1\n          }).skip(10).limit(10).count().then(count => {\n            test.equal(10, count);\n            client.close(done);\n          });\n        });\n      });\n    });\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldFailToTailANormalCollection","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2320,"column":39,"index":77422},"line":2320,"code":"  it('shouldFailToTailANormalCollection', function (done) {\n    const configuration = this.configuration;\n    client.connect((err, client) => {\n      expect(err).to.not.exist;\n      this.defer(() => client.close());\n      const db = client.db(configuration.db);\n      var collection = db.collection('shouldFailToTailANormalCollection');\n      var docs = [];\n      for (var i = 0; i < 100; i++) docs.push({\n        a: i,\n        OrderNumber: i\n      });\n      collection.insert(docs, configuration.writeConcernMax(), err => {\n        expect(err).to.not.exist;\n        const cursor = collection.find({}, {\n          tailable: true\n        });\n        cursor.forEach(() => {}, err => {\n          test.ok(err instanceof Error);\n          test.ok(typeof err.code === 'number');\n\n          // Close cursor b/c we did not exhaust cursor\n          cursor.close();\n          done();\n        });\n      });\n    });\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUseFindAndCursorCount","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2348,"column":42,"index":78335},"line":2348,"code":"  it('shouldCorrectlyUseFindAndCursorCount', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n\n      // DOC_LINE var client = new MongoClient(new Server('localhost', 27017));\n      // DOC_START\n      // Establish connection to db\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n\n        // Create a lot of documents to insert\n        var docs = [];\n        for (var i = 0; i < 100; i++) {\n          docs.push({\n            a: i\n          });\n        }\n\n        // Create a collection\n        db.createCollection('test_close_function_on_cursor_2', (err, collection) => {\n          expect(err).to.not.exist;\n\n          // Insert documents into collection\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find({});\n            cursor.count((err, count) => {\n              expect(err).to.not.exist;\n              test.equal(100, count);\n              done();\n            });\n          });\n        });\n      });\n      // DOC_END\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should correctly apply hint to count command for cursor","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2395,"column":61,"index":79773},"line":2395,"code":"  it('should correctly apply hint to count command for cursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded'],\n        mongodb: '>2.5.5'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n\n      // DOC_LINE var client = new MongoClient(new Server('localhost', 27017));\n      // DOC_START\n      // Establish connection to db\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var col = db.collection('count_hint');\n        col.insert([{\n          i: 1\n        }, {\n          i: 2\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, err => {\n          expect(err).to.not.exist;\n          col.createIndex({\n            i: 1\n          }, err => {\n            expect(err).to.not.exist;\n            col.find({\n              i: 1\n            }, {\n              hint: '_id_'\n            }).count((err, count) => {\n              expect(err).to.not.exist;\n              test.equal(1, count);\n              col.find({}, {\n                hint: '_id_'\n              }).count((err, count) => {\n                expect(err).to.not.exist;\n                test.equal(2, count);\n                col.find({\n                  i: 1\n                }, {\n                  hint: 'BAD HINT'\n                }).count(err => {\n                  test.ok(err != null);\n                  col.createIndex({\n                    x: 1\n                  }, {\n                    sparse: true\n                  }, err => {\n                    expect(err).to.not.exist;\n                    col.find({\n                      i: 1\n                    }, {\n                      hint: 'x_1'\n                    }).count((err, count) => {\n                      expect(err).to.not.exist;\n                      test.equal(0, count);\n                      col.find({}, {\n                        hint: 'i_1'\n                      }).count((err, count) => {\n                        expect(err).to.not.exist;\n                        test.equal(2, count);\n                        done();\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n      // DOC_END\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Terminate each after first document by returning false","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2479,"column":60,"index":82268},"line":2479,"code":"  it('Terminate each after first document by returning false', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n\n        // Create a lot of documents to insert\n        var docs = [];\n        for (var i = 0; i < 100; i++) {\n          docs.push({\n            a: i\n          });\n        }\n\n        // Create a collection\n        db.createCollection('terminate_each_returning_false', (err, collection) => {\n          expect(err).to.not.exist;\n\n          // Insert documents into collection\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            var finished = false;\n            collection.find({}).forEach(doc => {\n              expect(doc).to.exist;\n              test.equal(finished, false);\n              finished = true;\n              done();\n              return false;\n            }, err => {\n              expect(err).to.not.exist;\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly handle maxTimeMS as part of findOne options","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2524,"column":66,"index":83672},"line":2524,"code":"  it('Should correctly handle maxTimeMS as part of findOne options', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var donkey = {\n          color: 'brown'\n        };\n        db.collection('donkies').insertOne(donkey, function (err, result) {\n          expect(err).to.not.exist;\n          var query = {\n            _id: result.insertedId\n          };\n          var options = {\n            maxTimeMS: 1000\n          };\n          db.collection('donkies').findOne(query, options, function (err, doc) {\n            expect(err).to.not.exist;\n            test.equal('brown', doc.color);\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly handle batchSize of 2","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2558,"column":44,"index":84736},"line":2558,"code":"  it('Should correctly handle batchSize of 2', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        const collectionName = 'should_correctly_handle_batchSize_2';\n        db.collection(collectionName).insert([{\n          x: 1\n        }, {\n          x: 2\n        }, {\n          x: 3\n        }], err => {\n          expect(err).to.not.exist;\n          const cursor = db.collection(collectionName).find({}, {\n            batchSize: 2\n          });\n          this.defer(() => cursor.close());\n          cursor.next(err => {\n            expect(err).to.not.exist;\n            cursor.next(err => {\n              expect(err).to.not.exist;\n              cursor.next(err => {\n                expect(err).to.not.exist;\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should report database name and collection name","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2599,"column":53,"index":85988},"line":2599,"code":"  it('Should report database name and collection name', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        const cursor = db.collection('myCollection').find({});\n        test.equal('myCollection', cursor.namespace.collection);\n        test.equal('integration_tests', cursor.namespace.db);\n        done();\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute count on cursor with maxTimeMS","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2618,"column":61,"index":86600},"line":2618,"code":"  it('Should correctly execute count on cursor with maxTimeMS', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      for (var i = 0; i < 1000; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('Should_correctly_execute_count_on_cursor_2', function (err, collection) {\n          expect(err).to.not.exist;\n\n          // insert all docs\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n\n            // Create a cursor for the content\n            var cursor = collection.find({});\n            cursor.limit(100);\n            cursor.skip(10);\n            cursor.count({\n              maxTimeMS: 1000\n            }, err => {\n              expect(err).to.not.exist;\n\n              // Create a cursor for the content\n              var cursor = collection.find({});\n              cursor.limit(100);\n              cursor.skip(10);\n              cursor.maxTimeMS(100);\n              cursor.count(err => {\n                expect(err).to.not.exist;\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute count on cursor with maxTimeMS set using legacy method","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2671,"column":85,"index":88302},"line":2671,"code":"  it('Should correctly execute count on cursor with maxTimeMS set using legacy method', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      for (var i = 0; i < 1000; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('Should_correctly_execute_count_on_cursor_3', function (err, collection) {\n          expect(err).to.not.exist;\n\n          // insert all docs\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n\n            // Create a cursor for the content\n            var cursor = collection.find({}, {\n              maxTimeMS: 100\n            });\n            cursor.toArray(err => {\n              expect(err).to.not.exist;\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply map to toArray","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2713,"column":43,"index":89606},"line":2713,"code":"  it('Should correctly apply map to toArray', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      for (var i = 0; i < 1000; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var collection = db.collection('map_toArray');\n\n        // insert all docs\n        collection.insert(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n\n          // Create a cursor for the content\n          var cursor = collection.find({}).map(function () {\n            return {\n              a: 1\n            };\n          }).batchSize(5).limit(10);\n          cursor.toArray(function (err, docs) {\n            expect(err).to.not.exist;\n            test.equal(10, docs.length);\n\n            // Ensure all docs where mapped\n            docs.forEach(doc => {\n              expect(doc).property('a').to.equal(1);\n            });\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply map to next","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2761,"column":40,"index":91057},"line":2761,"code":"  it('Should correctly apply map to next', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const docs = [];\n      for (var i = 0; i < 1000; i++) {\n        const d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        const collection = db.collection('map_next');\n\n        // insert all docs\n        collection.insert(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n\n          // Create a cursor for the content\n          const cursor = collection.find({}).map(function () {\n            return {\n              a: 1\n            };\n          }).batchSize(5).limit(10);\n          this.defer(() => cursor.close());\n          cursor.next((err, doc) => {\n            expect(err).to.not.exist;\n            test.equal(1, doc.a);\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply map to each","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2805,"column":40,"index":92392},"line":2805,"code":"  it('Should correctly apply map to each', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      for (var i = 0; i < 1000; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        const collection = db.collection('map_each');\n\n        // insert all docs\n        collection.insert(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n\n          // Create a cursor for the content\n          var cursor = collection.find({}).map(function () {\n            return {\n              a: 1\n            };\n          }).batchSize(5).limit(10);\n          cursor.forEach(doc => {\n            test.equal(1, doc.a);\n          }, err => {\n            expect(err).to.not.exist;\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply map to forEach","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2849,"column":43,"index":93698},"line":2849,"code":"  it('Should correctly apply map to forEach', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      for (var i = 0; i < 1000; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var collection = db.collection('map_forEach');\n\n        // insert all docs\n        collection.insert(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n\n          // Create a cursor for the content\n          var cursor = collection.find({}).map(function () {\n            return {\n              a: 2\n            };\n          }).map(function (x) {\n            return {\n              a: x.a * x.a\n            };\n          }).batchSize(5).limit(10);\n          cursor.forEach(doc => {\n            test.equal(4, doc.a);\n          }, err => {\n            expect(err).to.not.exist;\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply multiple uses of map and apply forEach","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2897,"column":67,"index":95124},"line":2897,"code":"  it('Should correctly apply multiple uses of map and apply forEach', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      for (var i = 0; i < 1000; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var collection = db.collection('map_mapmapforEach');\n\n        // insert all docs\n        collection.insert(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n\n          // Create a cursor for the content\n          var cursor = collection.find({}).map(function () {\n            return {\n              a: 1\n            };\n          }).batchSize(5).limit(10);\n          cursor.forEach(doc => {\n            expect(doc).property('a').to.equal(1);\n          }, err => {\n            expect(err).to.not.exist;\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply skip and limit to large set of documents","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2941,"column":69,"index":96480},"line":2941,"code":"  it('Should correctly apply skip and limit to large set of documents', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var collection = db.collection('cursor_limit_skip_correctly');\n\n        // Insert x number of docs\n        var ordered = collection.initializeUnorderedBulkOp();\n        for (var i = 0; i < 6000; i++) {\n          ordered.insert({\n            a: i\n          });\n        }\n        ordered.execute({\n          writeConcern: {\n            w: 1\n          }\n        }, err => {\n          expect(err).to.not.exist;\n\n          // Let's attempt to skip and limit\n          collection.find({}).limit(2016).skip(2016).toArray(function (err, docs) {\n            expect(err).to.not.exist;\n            test.equal(2016, docs.length);\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should tail cursor using maxAwaitTimeMS for 3.2 or higher","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2981,"column":63,"index":97705},"line":2981,"code":"  it('should tail cursor using maxAwaitTimeMS for 3.2 or higher', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>3.1.9'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var options = {\n          capped: true,\n          size: 8\n        };\n        db.createCollection('should_await_data_max_awaittime_ms', options, function (err, collection) {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n\n            // Create cursor with awaitData, and timeout after the period specified\n            var cursor = collection.find({}).addCursorFlag('tailable', true).addCursorFlag('awaitData', true).maxAwaitTimeMS(500);\n            const s = new Date();\n            cursor.forEach(() => {\n              setTimeout(() => cursor.close(), 300);\n            }, () => {\n              test.ok(new Date().getTime() - s.getTime() >= 500);\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should not emit any events after close event emitted due to cursor killed","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3022,"column":79,"index":99183},"line":3022,"code":"  it('Should not emit any events after close event emitted due to cursor killed', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var collection = db.collection('cursor_limit_skip_correctly');\n\n        // Insert x number of docs\n        var ordered = collection.initializeUnorderedBulkOp();\n        for (var i = 0; i < 100; i++) {\n          ordered.insert({\n            a: i\n          });\n        }\n        ordered.execute({\n          writeConcern: {\n            w: 1\n          }\n        }, err => {\n          expect(err).to.not.exist;\n\n          // Let's attempt to skip and limit\n          var cursor = collection.find({}).batchSize(10);\n          const stream = cursor.stream();\n          stream.on('data', function () {\n            stream.destroy();\n          });\n          cursor.on('close', function () {\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteEnsureIndexWithNoCallback","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3065,"column":53,"index":100461},"line":3065,"code":"  it('shouldCorrectlyExecuteEnsureIndexWithNoCallback', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      for (var i = 0; i < 1; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          createdAt: new Date(d)\n        };\n      }\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('shouldCorrectlyExecuteEnsureIndexWithNoCallback', function (err, collection) {\n          expect(err).to.not.exist;\n\n          // ensure index of createdAt index\n          collection.createIndex({\n            createdAt: 1\n          }, err => {\n            expect(err).to.not.exist;\n\n            // insert all docs\n            collection.insert(docs, configuration.writeConcernMax(), err => {\n              expect(err).to.not.exist;\n\n              // Find with sort\n              collection.find().sort(['createdAt', 'asc']).toArray((err, items) => {\n                expect(err).to.not.exist;\n                test.equal(1, items.length);\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute count on cursor with limit and skip","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3111,"column":66,"index":101955},"line":3111,"code":"  it('Should correctly execute count on cursor with limit and skip', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      for (var i = 0; i < 50; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('negative_batch_size_and_limit_set', (err, collection) => {\n          expect(err).to.not.exist;\n\n          // insert all docs\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n\n            // Create a cursor for the content\n            var cursor = collection.find({});\n            cursor.limit(100).skip(0).count(function (err, c) {\n              expect(err).to.not.exist;\n              test.equal(50, c);\n              var cursor = collection.find({});\n              cursor.limit(100).skip(0).toArray(err => {\n                expect(err).to.not.exist;\n                test.equal(50, c);\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly handle negative batchSize and set the limit","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3157,"column":66,"index":103482},"line":3157,"code":"  it('Should correctly handle negative batchSize and set the limit', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      const configuration = this.configuration;\n      for (var i = 0; i < 50; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('Should_correctly_execute_count_on_cursor_1_', function (err, collection) {\n          expect(err).to.not.exist;\n\n          // insert all docs\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n\n            // Create a cursor for the content\n            var cursor = collection.find({});\n            cursor.batchSize(-10).next(err => {\n              expect(err).to.not.exist;\n              test.ok(cursor.id.equals(BSON.Long.ZERO));\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Correctly decorate the cursor count command with skip, limit, hint, readConcern","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3198,"column":85,"index":104850},"line":3198,"code":"  it('Correctly decorate the cursor count command with skip, limit, hint, readConcern', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var started = [];\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      client.on('commandStarted', function (event) {\n        if (event.commandName === 'count') started.push(event);\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.collection('cursor_count_test', {\n          readConcern: {\n            level: 'local'\n          }\n        }).find({\n          project: '123'\n        }).limit(5).skip(5).hint({\n          project: 1\n        }).count(err => {\n          expect(err).to.not.exist;\n          test.equal(1, started.length);\n          if (started[0].command.readConcern) test.deepEqual({\n            level: 'local'\n          }, started[0].command.readConcern);\n          test.deepEqual({\n            project: 1\n          }, started[0].command.hint);\n          test.equal(5, started[0].command.skip);\n          test.equal(5, started[0].command.limit);\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Correctly decorate the collection count command with skip, limit, hint, readConcern","suites":["Cursor","awaiting data core tailable cursor test"],"line":3244,"code":"  it.skip('Correctly decorate the collection count command with skip, limit, hint, readConcern', {","file":"integration/crud/misc_cursors.test.js","skipped":true,"dir":"test"},{"name":"Should properly kill a cursor","suites":["Cursor","awaiting data core tailable cursor test"],"line":3295,"code":"  it.skip('Should properly kill a cursor', {","file":"integration/crud/misc_cursors.test.js","skipped":true,"dir":"test"},{"name":"should return implicit session to pool when client-side cursor exhausts results on initial query","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3354,"column":102,"index":110214},"line":3354,"code":"  it('should return implicit session to pool when client-side cursor exhausts results on initial query', async function () {\n    const configuration = this.configuration;\n    const client = configuration.newClient();\n    await client.connect();\n    const db = client.db(configuration.db);\n    const collection = db.collection('cursor_session_tests');\n    await collection.insertMany([{\n      a: 1,\n      b: 2\n    }]);\n    const cursor = collection.find({});\n    await cursor.next(); // implicit close, cursor is exhausted\n    expect(client.s.activeSessions.size).to.equal(0);\n    await cursor.close();\n    await client.close();\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should return implicit session to pool when client-side cursor exhausts results after a getMore","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3370,"column":101,"index":110847},"line":3370,"code":"  it('should return implicit session to pool when client-side cursor exhausts results after a getMore', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    const db = client.db(configuration.db);\n    const collection = db.collection('cursor_session_tests2');\n    const docs = [{\n      a: 1,\n      b: 2\n    }, {\n      a: 3,\n      b: 4\n    }, {\n      a: 5,\n      b: 6\n    }, {\n      a: 7,\n      b: 8\n    }, {\n      a: 9,\n      b: 10\n    }];\n    collection.insertMany(docs, err => {\n      expect(err).to.not.exist;\n      const cursor = collection.find({}, {\n        batchSize: 3\n      });\n      cursor.next(function () {\n        expect(client.s.activeSessions.size).to.equal(1);\n        cursor.next(function () {\n          expect(client.s.activeSessions.size).to.equal(1);\n          cursor.next(function () {\n            expect(client.s.activeSessions.size).to.equal(1);\n            cursor.next(function () {\n              expect(client.s.activeSessions.size).to.equal(0);\n              cursor.close(() => {\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    });\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"removes the existing session from the cloned cursor","suites":["Cursor","#clone","when executing on a find cursor"],"updatePoint":{"line":3434,"column":61,"index":112510},"line":3434,"code":"      it('removes the existing session from the cloned cursor', function () {\n        const docs = [{\n          name: 'test1'\n        }, {\n          name: 'test2'\n        }];\n        return collection.insertMany(docs).then(() => {\n          const cursor = collection.find({}, {\n            batchSize: 1\n          });\n          return cursor.next().then(doc => {\n            expect(doc).to.exist;\n            const clonedCursor = cursor.clone();\n            expect(clonedCursor.cursorOptions.session).to.not.exist;\n            const kServerSession = getSymbolFrom(clonedCursor.session, 'serverSession');\n            expect(clonedCursor.session).to.have.property(kServerSession, null); // session is brand new and has not been used\n          }).finally(() => {\n            return cursor.close();\n          });\n        });\n      });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"removes the existing session from the cloned cursor","suites":["Cursor","#clone","when executing on an aggregation cursor"],"updatePoint":{"line":3457,"column":61,"index":113417},"line":3457,"code":"      it('removes the existing session from the cloned cursor', function () {\n        const docs = [{\n          name: 'test1'\n        }, {\n          name: 'test2'\n        }];\n        return collection.insertMany(docs).then(() => {\n          const cursor = collection.aggregate([{\n            $match: {}\n          }], {\n            batchSize: 1\n          });\n          return cursor.next().then(doc => {\n            expect(doc).to.exist;\n            const clonedCursor = cursor.clone();\n            expect(clonedCursor.cursorOptions.session).to.not.exist;\n            const kServerSession = getSymbolFrom(clonedCursor.session, 'serverSession');\n            expect(clonedCursor.session).to.have.property(kServerSession, null); // session is brand new and has not been used\n          }).finally(() => {\n            return cursor.close();\n          });\n        });\n      });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should propagate error when exceptions are thrown from an awaited forEach call","suites":["Cursor","Cursor forEach Error propagation"],"updatePoint":{"line":3505,"column":86,"index":114951},"line":3505,"code":"    it('should propagate error when exceptions are thrown from an awaited forEach call', async function () {\n      const docs = [{\n        unique_key_2035: 1\n      }, {\n        unique_key_2035: 2\n      }, {\n        unique_key_2035: 3\n      }];\n      await collection.insertMany(docs).catch(() => {\n        expect.fail('Failed to insert documents');\n      });\n      cursor = collection.find({\n        unique_key_2035: {\n          $exists: true\n        }\n      });\n      await cursor.forEach(() => {\n        throw new Error('FAILURE IN FOREACH CALL');\n      }).then(() => {\n        expect.fail('Error in forEach call not caught');\n      }).catch(err => {\n        expect(err.message).to.deep.equal('FAILURE IN FOREACH CALL');\n      });\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should return a promise when no callback supplied to forEach method","suites":["Cursor","Cursor forEach Error propagation"],"updatePoint":{"line":3530,"column":73,"index":115685},"line":3530,"code":"  it('should return a promise when no callback supplied to forEach method', function () {\n    const configuration = this.configuration;\n    const client = configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    return client.connect().then(() => {\n      this.defer(() => client.close());\n      const db = client.db(configuration.db);\n      const collection = db.collection('cursor_session_tests2');\n      const cursor = collection.find();\n      this.defer(() => cursor.close());\n      const promise = cursor.forEach(() => {});\n      expect(promise).to.exist.and.to.be.an.instanceof(Promise);\n      return promise;\n    });\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should return false when exhausted and hasNext called more than once","suites":["Cursor","Cursor forEach Error propagation"],"updatePoint":{"line":3548,"column":74,"index":116337},"line":3548,"code":"  it('should return false when exhausted and hasNext called more than once', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    client.connect((err, client) => {\n      expect(err).to.not.exist;\n      this.defer(() => client.close());\n      const db = client.db(configuration.db);\n      db.createCollection('cursor_hasNext_test').then(() => {\n        const cursor = db.collection('cursor_hasNext_test').find();\n        this.defer(() => cursor.close());\n        cursor.hasNext().then(val1 => {\n          expect(val1).to.equal(false);\n          return cursor.hasNext();\n        }).then(val2 => {\n          expect(val2).to.equal(false);\n          done();\n        });\n      });\n    });\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"stream should apply the supplied transformation function to each document in the stream","suites":["Cursor","Cursor forEach Error propagation"],"updatePoint":{"line":3624,"column":93,"index":118692},"line":3624,"code":"  it('stream should apply the supplied transformation function to each document in the stream', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    const expectedDocs = [{\n      _id: 0,\n      b: 1,\n      c: 0\n    }, {\n      _id: 1,\n      b: 1,\n      c: 0\n    }, {\n      _id: 2,\n      b: 1,\n      c: 0\n    }];\n    const config = {\n      client: client,\n      configuration: configuration,\n      collectionName: 'stream-test-transform',\n      transformFunc: doc => ({\n        _id: doc._id,\n        b: doc.a.b,\n        c: doc.a.c\n      }),\n      expectedSet: new Set(expectedDocs)\n    };\n    testTransformStream(config, done);\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"stream should return a stream of unmodified docs if no transform function applied","suites":["Cursor","Cursor forEach Error propagation"],"updatePoint":{"line":3657,"column":87,"index":119426},"line":3657,"code":"  it('stream should return a stream of unmodified docs if no transform function applied', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    const expectedDocs = [{\n      _id: 0,\n      a: {\n        b: 1,\n        c: 0\n      }\n    }, {\n      _id: 1,\n      a: {\n        b: 1,\n        c: 0\n      }\n    }, {\n      _id: 2,\n      a: {\n        b: 1,\n        c: 0\n      }\n    }];\n    const config = {\n      client: client,\n      configuration: configuration,\n      collectionName: 'transformStream-test-notransform',\n      transformFunc: null,\n      expectedSet: new Set(expectedDocs)\n    };\n    testTransformStream(config, done);\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should apply parent read preference to count command","suites":["Cursor","Cursor forEach Error propagation"],"line":3692,"code":"  it.skip('should apply parent read preference to count command', function (done) {","file":"integration/crud/misc_cursors.test.js","skipped":true,"dir":"test"},{"name":"should not consume first document on hasNext when streaming","suites":["Cursor","Cursor forEach Error propagation"],"updatePoint":{"line":3713,"column":65,"index":121408},"line":3713,"code":"  it('should not consume first document on hasNext when streaming', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    client.connect(err => {\n      expect(err).to.not.exist;\n      this.defer(() => client.close());\n      const collection = client.db().collection('documents');\n      collection.drop(() => {\n        const docs = [{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }];\n        collection.insertMany(docs, err => {\n          expect(err).to.not.exist;\n          const cursor = collection.find({}, {\n            sort: {\n              a: 1\n            }\n          });\n          cursor.hasNext((err, hasNext) => {\n            expect(err).to.not.exist;\n            expect(hasNext).to.be.true;\n            const collected = [];\n            const stream = new Writable({\n              objectMode: true,\n              write: (chunk, encoding, next) => {\n                collected.push(chunk);\n                next(undefined, chunk);\n              }\n            });\n            const cursorStream = cursor.stream();\n            cursorStream.on('end', () => {\n              expect(collected).to.have.length(3);\n              expect(collected).to.eql(docs);\n              done();\n            });\n            cursorStream.pipe(stream);\n          });\n        });\n      });\n    });\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should correctly apply map transform to cursor as readable stream","suites":["Cursor","transforms"],"updatePoint":{"line":3763,"column":73,"index":122884},"line":3763,"code":"    it('should correctly apply map transform to cursor as readable stream', function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect(err => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const docs = 'Aaden Aaron Adrian Aditya Bob Joe'.split(' ').map(x => ({\n          name: x\n        }));\n        const coll = client.db(configuration.db).collection('cursor_stream_mapping');\n        coll.insertMany(docs, err => {\n          expect(err).to.not.exist;\n          const bag = [];\n          const stream = coll.find().project({\n            _id: 0,\n            name: 1\n          }).map(doc => ({\n            mapped: doc\n          })).stream().on('data', doc => bag.push(doc));\n          stream.on('error', done).on('end', () => {\n            expect(bag.map(x => x.mapped)).to.eql(docs.map(x => ({\n              name: x.name\n            })));\n            done();\n          });\n        });\n      });\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should correctly apply map transform when converting cursor to array","suites":["Cursor","transforms"],"updatePoint":{"line":3791,"column":76,"index":123905},"line":3791,"code":"    it('should correctly apply map transform when converting cursor to array', function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect(err => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const docs = 'Aaden Aaron Adrian Aditya Bob Joe'.split(' ').map(x => ({\n          name: x\n        }));\n        const coll = client.db(configuration.db).collection('cursor_toArray_mapping');\n        coll.insertMany(docs, err => {\n          expect(err).to.not.exist;\n          coll.find().project({\n            _id: 0,\n            name: 1\n          }).map(doc => ({\n            mapped: doc\n          })).toArray((err, mappedDocs) => {\n            expect(err).to.not.exist;\n            expect(mappedDocs.map(x => x.mapped)).to.eql(docs.map(x => ({\n              name: x.name\n            })));\n            done();\n          });\n        });\n      });\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use find options object","suites":["Cursor","sort"],"updatePoint":{"line":3862,"column":38,"index":126317},"line":3862,"code":"    it('should use find options object', findSort({\n      alpha: 1\n    }, new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use find options string","suites":["Cursor","sort"],"updatePoint":{"line":3865,"column":38,"index":126418},"line":3865,"code":"    it('should use find options string', findSort('alpha', new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use find options shallow array","suites":["Cursor","sort"],"updatePoint":{"line":3866,"column":45,"index":126511},"line":3866,"code":"    it('should use find options shallow array', findSort(['alpha', 1], new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use find options deep array","suites":["Cursor","sort"],"updatePoint":{"line":3867,"column":42,"index":126606},"line":3867,"code":"    it('should use find options deep array', findSort([['alpha', 1]], new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use cursor.sort object","suites":["Cursor","sort"],"updatePoint":{"line":3868,"column":37,"index":126698},"line":3868,"code":"    it('should use cursor.sort object', cursorSort({\n      alpha: 1\n    }, new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use cursor.sort string","suites":["Cursor","sort"],"updatePoint":{"line":3871,"column":37,"index":126800},"line":3871,"code":"    it('should use cursor.sort string', cursorSort('alpha', new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use cursor.sort shallow array","suites":["Cursor","sort"],"updatePoint":{"line":3872,"column":44,"index":126894},"line":3872,"code":"    it('should use cursor.sort shallow array', cursorSort(['alpha', 1], new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use cursor.sort deep array","suites":["Cursor","sort"],"updatePoint":{"line":3873,"column":41,"index":126990},"line":3873,"code":"    it('should use cursor.sort deep array', cursorSort([['alpha', 1]], new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"formatSort - one key","suites":["Cursor","sort"],"updatePoint":{"line":3874,"column":28,"index":127075},"line":3874,"code":"    it('formatSort - one key', () => {\n      // TODO (NODE-3236): These are unit tests for a standalone function and should be moved out of the cursor context file\n      expect(formatSort('alpha')).to.deep.equal(new Map([['alpha', 1]]));\n      expect(formatSort(['alpha'])).to.deep.equal(new Map([['alpha', 1]]));\n      expect(formatSort('alpha', 1)).to.deep.equal(new Map([['alpha', 1]]));\n      expect(formatSort('alpha', 'asc')).to.deep.equal(new Map([['alpha', 1]]));\n      expect(formatSort([['alpha', 'asc']])).to.deep.equal(new Map([['alpha', 1]]));\n      expect(formatSort('alpha', 'ascending')).to.deep.equal(new Map([['alpha', 1]]));\n      expect(formatSort({\n        alpha: 1\n      })).to.deep.equal(new Map([['alpha', 1]]));\n      expect(formatSort('beta')).to.deep.equal(new Map([['beta', 1]]));\n      expect(formatSort(['beta'])).to.deep.equal(new Map([['beta', 1]]));\n      expect(formatSort('beta', -1)).to.deep.equal(new Map([['beta', -1]]));\n      expect(formatSort('beta', 'desc')).to.deep.equal(new Map([['beta', -1]]));\n      expect(formatSort('beta', 'descending')).to.deep.equal(new Map([['beta', -1]]));\n      expect(formatSort({\n        beta: -1\n      })).to.deep.equal(new Map([['beta', -1]]));\n      expect(formatSort({\n        alpha: {\n          $meta: 'hi'\n        }\n      })).to.deep.equal(new Map([['alpha', {\n        $meta: 'hi'\n      }]]));\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"formatSort - multi key","suites":["Cursor","sort"],"updatePoint":{"line":3901,"column":30,"index":128459},"line":3901,"code":"    it('formatSort - multi key', () => {\n      expect(formatSort(['alpha', 'beta'])).to.deep.equal(new Map([['alpha', 1], ['beta', 1]]));\n      expect(formatSort({\n        alpha: 1,\n        beta: 1\n      })).to.deep.equal(new Map([['alpha', 1], ['beta', 1]]));\n      expect(formatSort([['alpha', 'asc'], ['beta', 'ascending']])).to.deep.equal(new Map([['alpha', 1], ['beta', 1]]));\n      expect(formatSort(new Map([['alpha', 'asc'], ['beta', 'ascending']]))).to.deep.equal(new Map([['alpha', 1], ['beta', 1]]));\n      expect(formatSort([['3', 'asc'], ['1', 'ascending']])).to.deep.equal(new Map([['3', 1], ['1', 1]]));\n      expect(formatSort({\n        alpha: {\n          $meta: 'hi'\n        },\n        beta: 'ascending'\n      })).to.deep.equal(new Map([['alpha', {\n        $meta: 'hi'\n      }], ['beta', 1]]));\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use allowDiskUse option on sort","suites":["Cursor","sort"],"updatePoint":{"line":3919,"column":46,"index":129295},"line":3919,"code":"    it('should use allowDiskUse option on sort', {\n      metadata: {\n        requires: {\n          mongodb: '>=4.4'\n        }\n      },\n      test: async function () {\n        const events = [];\n        client.on('commandStarted', event => {\n          if (event.commandName === 'find') {\n            events.push(event);\n          }\n        });\n        const db = client.db('test');\n        const collection = db.collection('test_sort_allow_disk_use');\n        const cursor = collection.find({}).sort(['alpha', 1]).allowDiskUse();\n        await cursor.next();\n        const {\n          command\n        } = events.shift();\n        expect(command.sort).to.deep.equal(new Map([['alpha', 1]]));\n        expect(command.allowDiskUse).to.be.true;\n      }\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should error if allowDiskUse option used without sort","suites":["Cursor","sort"],"updatePoint":{"line":3943,"column":61,"index":130064},"line":3943,"code":"    it('should error if allowDiskUse option used without sort', {\n      metadata: {\n        requires: {\n          mongodb: '>=4.4'\n        }\n      },\n      test: async function () {\n        const client = this.configuration.newClient();\n        const db = client.db('test');\n        const collection = db.collection('test_sort_allow_disk_use');\n        expect(() => collection.find({}).allowDiskUse()).to.throw(/Option \"allowDiskUse\" requires a sort specification/);\n        await client.close();\n      }\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should create records with custom PK factory","suites":["PkFactory"],"updatePoint":{"line":16,"column":50,"index":328},"line":16,"code":"  it('should create records with custom PK factory', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n\n      // Custom factory (need to provide a 12 byte array);\n      var CustomPKFactory = {\n        createPk() {\n          return new ObjectId('aaaaaaaaaaaa');\n        }\n      };\n      var client = configuration.newClient({\n        writeConcern: {\n          w: 1\n        },\n        maxPoolSize: 1\n      }, {\n        pkFactory: CustomPKFactory\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('test_custom_key');\n        collection.insert({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.find({\n            _id: new ObjectId('aaaaaaaaaaaa')\n          }).toArray(function (err, items) {\n            expect(items.length).to.equal(1);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/pk_factory.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute stats using Promise","suites":["stats"],"updatePoint":{"line":14,"column":50,"index":358},"line":14,"code":"  it('Should correctly execute stats using Promise', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var url = configuration.url();\n      url = url.indexOf('?') !== -1 ? f('%s&%s', url, 'maxPoolSize=5') : f('%s?%s', url, 'maxPoolSize=5');\n      const client = configuration.newClient(url);\n      client.connect().then(function (client) {\n        client.db(configuration.db).stats().then(function (stats) {\n          test.ok(stats != null);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/promise_stats.test.js","skipped":false,"dir":"test"},{"name":"should correctly clear out collection","suites":["Remove"],"updatePoint":{"line":13,"column":43,"index":255},"line":13,"code":"  it('should correctly clear out collection', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      const self = this;\n      const client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(self.configuration.db);\n        expect(err).to.not.exist;\n        db.createCollection('test_clear', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_clear');\n          collection.insert({\n            i: 1\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n            collection.insert({\n              i: 2\n            }, {\n              writeConcern: {\n                w: 1\n              }\n            }, function (err) {\n              expect(err).to.not.exist;\n              collection.count(function (err, count) {\n                expect(err).to.not.exist;\n                expect(count).to.equal(2);\n\n                // Clear the collection\n                collection.remove({}, {\n                  writeConcern: {\n                    w: 1\n                  }\n                }, function (err, r) {\n                  expect(err).to.not.exist;\n                  expect(r).property('deletedCount').to.equal(2);\n                  collection.count(function (err, count) {\n                    expect(err).to.not.exist;\n                    expect(count).to.equal(0);\n\n                    // Let's close the db\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/remove.test.js","skipped":false,"dir":"test"},{"name":"should correctly remove document using RegExp","suites":["Remove"],"updatePoint":{"line":73,"column":51,"index":2111},"line":73,"code":"  it('should correctly remove document using RegExp', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      const self = this;\n      const client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(self.configuration.db);\n        expect(err).to.not.exist;\n        db.createCollection('test_remove_regexp', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_remove_regexp');\n          collection.insert({\n            address: '485 7th ave new york'\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n\n            // Clear the collection\n            collection.remove({\n              address: /485 7th ave/\n            }, {\n              writeConcern: {\n                w: 1\n              }\n            }, function (err, r) {\n              expect(r).property('deletedCount').to.equal(1);\n              collection.count(function (err, count) {\n                expect(err).to.not.exist;\n                expect(count).to.equal(0);\n\n                // Let's close the db\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/remove.test.js","skipped":false,"dir":"test"},{"name":"should correctly remove only first document","suites":["Remove"],"updatePoint":{"line":121,"column":49,"index":3577},"line":121,"code":"  it('should correctly remove only first document', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      const self = this;\n      const client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(self.configuration.db);\n        expect(err).to.not.exist;\n        db.createCollection('shouldCorrectlyRemoveOnlyFirstDocument', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('shouldCorrectlyRemoveOnlyFirstDocument');\n          collection.insert([{\n            a: 1\n          }, {\n            a: 1\n          }, {\n            a: 1\n          }, {\n            a: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n\n            // Remove the first\n            collection.remove({\n              a: 1\n            }, {\n              writeConcern: {\n                w: 1\n              },\n              single: true\n            }, function (err, r) {\n              expect(r).property('deletedCount').to.equal(1);\n              collection.find({\n                a: 1\n              }).count(function (err, result) {\n                expect(result).to.equal(3);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/remove.test.js","skipped":false,"dir":"test"},{"name":"should not error on empty remove","suites":["Remove"],"updatePoint":{"line":175,"column":38,"index":5115},"line":175,"code":"  it('should not error on empty remove', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      const self = this;\n      const client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(self.configuration.db);\n        expect(err).to.not.exist;\n        const collection = db.collection('remove_test');\n        collection.deleteMany({}).then(() => {\n          client.close(done);\n        }, err => {\n          client.close(err2 => done(err || err2));\n        });\n      });\n    }\n  });","file":"integration/crud/remove.test.js","skipped":false,"dir":"test"},{"name":"should fail insert due to unique index","suites":["Errors"],"updatePoint":{"line":24,"column":44,"index":584},"line":24,"code":"  it('should fail insert due to unique index', function (done) {\n    const db = client.db(this.configuration.db);\n    db.createCollection('test_failing_insert_due_to_unique_index', (err, collection) => {\n      expect(err).to.not.exist;\n      collection.createIndexes([{\n        name: 'test_failing_insert_due_to_unique_index',\n        key: {\n          a: 1\n        },\n        unique: true\n      }], {\n        writeConcern: {\n          w: 1\n        }\n      }, err => {\n        expect(err).to.not.exist;\n        collection.insertOne({\n          a: 2\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, err => {\n          expect(err).to.not.exist;\n          collection.insertOne({\n            a: 2\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, err => {\n            expect(err.code).to.equal(11000);\n            done();\n          });\n        });\n      });\n    });\n  });","file":"integration/crud/server_errors.test.js","skipped":false,"dir":"test"},{"name":"should fail insert due to unique index strict","suites":["Errors"],"updatePoint":{"line":62,"column":51,"index":1527},"line":62,"code":"  it('should fail insert due to unique index strict', function (done) {\n    const db = client.db(this.configuration.db);\n    db.dropCollection('test_failing_insert_due_to_unique_index_strict', () => {\n      db.createCollection('test_failing_insert_due_to_unique_index_strict', err => {\n        expect(err).to.not.exist;\n        const collection = db.collection('test_failing_insert_due_to_unique_index_strict');\n        collection.createIndexes([{\n          name: 'test_failing_insert_due_to_unique_index_strict',\n          key: {\n            a: 1\n          },\n          unique: true\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, err => {\n          expect(err).to.not.exist;\n          collection.insertOne({\n            a: 2\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, err => {\n            expect(err).to.not.exist;\n            collection.insertOne({\n              a: 2\n            }, {\n              writeConcern: {\n                w: 1\n              }\n            }, err => {\n              expect(err.code).to.equal(11000);\n              done();\n            });\n          });\n        });\n      });\n    });\n  });","file":"integration/crud/server_errors.test.js","skipped":false,"dir":"test"},{"name":"should return an error object with message when mixing included and excluded fields","suites":["Errors"],"updatePoint":{"line":104,"column":89,"index":2915},"line":104,"code":"  it('should return an error object with message when mixing included and excluded fields', {\n    metadata: {\n      requires: {\n        mongodb: '>3.0'\n      }\n    },\n    test: function (done) {\n      const db = client.db(this.configuration.db);\n      const c = db.collection('test_error_object_should_include_message');\n      c.insertOne({\n        a: 2,\n        b: 5\n      }, {\n        writeConcern: {\n          w: 1\n        }\n      }, err => {\n        expect(err).to.not.exist;\n        c.findOne({\n          a: 2\n        }, {\n          projection: {\n            a: 1,\n            b: 0\n          }\n        }, err => {\n          expect(PROJECTION_ERRORS).to.include(err.errmsg);\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/server_errors.test.js","skipped":false,"dir":"test"},{"name":"should handle error throw in user callback","suites":["Errors"],"updatePoint":{"line":136,"column":48,"index":3605},"line":136,"code":"  it('should handle error throw in user callback', {\n    metadata: {\n      requires: {\n        mongodb: '>3.0'\n      }\n    },\n    test: function (done) {\n      const db = client.db(this.configuration.db);\n      const c = db.collection('test_error_object_should_include_message');\n      c.findOne({}, {\n        projection: {\n          a: 1,\n          b: 0\n        }\n      }, err => {\n        expect(PROJECTION_ERRORS).to.include(err.errmsg);\n        done();\n      });\n    }\n  });","file":"integration/crud/server_errors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertUnicodeContainingDocument","suites":["Unicode"],"updatePoint":{"line":14,"column":52,"index":281},"line":14,"code":"  it('shouldCorrectlyInsertUnicodeContainingDocument', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var doc = {\n          statuses_count: 1687,\n          created_at: 'Mon Oct 22 14:55:08 +0000 2007',\n          description: 'NodeJS hacker, Cofounder of Debuggable, CakePHP core alumnus',\n          favourites_count: 6,\n          profile_sidebar_fill_color: 'EADEAA',\n          screen_name: 'felixge',\n          status: {\n            created_at: 'Fri Mar 12 08:59:44 +0000 2010',\n            in_reply_to_screen_name: null,\n            truncated: false,\n            in_reply_to_user_id: null,\n            source: '<a href=\"http://www.atebits.com/\" rel=\"nofollow\">Tweetie</a>',\n            favorited: false,\n            in_reply_to_status_id: null,\n            id: 10364119169,\n            text: '#berlin #snow = #fail : ('\n          },\n          contributors_enabled: false,\n          following: null,\n          geo_enabled: false,\n          time_zone: 'Eastern Time (US & Canada)',\n          profile_sidebar_border_color: 'D9B17E',\n          url: 'http://debuggable.com',\n          verified: false,\n          location: 'Berlin',\n          profile_text_color: '333333',\n          notifications: null,\n          profile_background_image_url: 'http://s.twimg.com/a/1268354287/images/themes/theme8/bg.gif',\n          protected: false,\n          profile_link_color: '9D582E',\n          followers_count: 840,\n          name: 'Felix Geisend\\u00f6rfer',\n          profile_background_tile: false,\n          id: 9599342,\n          lang: 'en',\n          utc_offset: -18000,\n          friends_count: 450,\n          profile_background_color: '8B542B',\n          profile_image_url: 'http://a3.twimg.com/profile_images/107142257/passbild-square_normal.jpg'\n        };\n        db.createCollection('test_should_correctly_insert_unicode_containing_document', function (err, collection) {\n          doc['_id'] = 'felixge';\n          collection.insertOne(doc, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n            collection.findOne(function (err, doc) {\n              test.equal('felixge', doc._id);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/unicode.test.js","skipped":false,"dir":"test"},{"name":"should Correctly Insert Unicode Characters","suites":["Unicode"],"updatePoint":{"line":85,"column":48,"index":2917},"line":85,"code":"  it('should Correctly Insert Unicode Characters', function (done) {\n    const client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    client.connect((err, client) => {\n      expect(err).to.not.exist;\n      const db = client.db(this.configuration.db);\n      db.createCollection('unicode_test_collection', (err, collection) => {\n        expect(err).to.not.exist;\n        const test_strings = ['ouooueauiOUOOUEAUI', '', ''];\n        collection.insert({\n          id: 0,\n          text: test_strings[0]\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, err => {\n          expect(err).to.not.exist;\n          collection.insert({\n            id: 1,\n            text: test_strings[1]\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, err => {\n            expect(err).to.not.exist;\n            collection.find().forEach(doc => {\n              expect(doc).property('text').to.equal(test_strings[doc.id]);\n            }, err => {\n              expect(err).to.not.exist;\n              client.close(done);\n            });\n          });\n        });\n      });\n    });\n  });","file":"integration/crud/unicode.test.js","skipped":false,"dir":"test"},{"name":"shouldCreateObjectWithChineseObjectName","suites":["Unicode"],"updatePoint":{"line":124,"column":45,"index":4127},"line":124,"code":"  it('shouldCreateObjectWithChineseObjectName', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var object = {\n        : 'Hello'\n      };\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('create_object_with_chinese_object_name', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('create_object_with_chinese_object_name');\n          collection.insert(object, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n            collection.findOne(function (err, item) {\n              test.equal(object[''], item['']);\n              collection.find().toArray(function (err, items) {\n                test.equal(object[''], items[0]['']);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/unicode.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleUT8KeyNames","suites":["Unicode"],"updatePoint":{"line":161,"column":38,"index":5356},"line":161,"code":"  it('shouldCorrectlyHandleUT8KeyNames', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_utf8_key_name', function (err, collection) {\n          collection.insert({\n            : 1\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n            collection.find({}).project({\n              : 1\n            }).toArray(function (err, items) {\n              test.equal(1, items[0]['']);\n              // Let's close the db\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/unicode.test.js","skipped":false,"dir":"test"},{"name":"Verify that the method returns an Iterable of Document types","suites":["listDatabases() spec prose"],"updatePoint":{"line":37,"column":66,"index":1379},"line":37,"code":"  it('Verify that the method returns an Iterable of Document types', async () => {\n    const dbInfo = await client.db().admin().listDatabases();\n    expect(dbInfo).to.have.property('databases');\n    expect(dbInfo.databases).to.be.an('array');\n    expect(dbInfo.databases).to.have.lengthOf(ENTIRE_DB_LIST.length);\n    for (const db of dbInfo.databases) {\n      expect(db).to.be.a('object');\n    }\n  });","file":"integration/enumerate_databases.prose.test.ts","skipped":false,"dir":"test"},{"name":"Verify that all databases on the server are present in the result set","suites":["listDatabases() spec prose"],"updatePoint":{"line":46,"column":75,"index":1790},"line":46,"code":"  it('Verify that all databases on the server are present in the result set', async () => {\n    const dbInfo = await client.db().admin().listDatabases();\n    const namesFromHelper = dbInfo.databases.map(({\n      name\n    }) => name);\n    namesFromHelper.sort();\n    expect(namesFromHelper).to.have.lengthOf(ENTIRE_DB_LIST.length);\n    expect(namesFromHelper).to.deep.equal(ENTIRE_DB_LIST);\n    expect(namesFromHelper).to.include(DB_NAME);\n  });","file":"integration/enumerate_databases.prose.test.ts","skipped":false,"dir":"test"},{"name":"Verify that the result set does not contain duplicates","suites":["listDatabases() spec prose"],"updatePoint":{"line":56,"column":60,"index":2220},"line":56,"code":"  it('Verify that the result set does not contain duplicates', async () => {\n    const dbInfo = await client.db().admin().listDatabases();\n    const databaseNames = dbInfo.databases.map(({\n      name\n    }) => name);\n    const databaseNamesSet = new Set(databaseNames);\n    expect(databaseNames).to.have.lengthOf(databaseNamesSet.size);\n  });","file":"integration/enumerate_databases.prose.test.ts","skipped":false,"dir":"test"},{"name":"should list all databases when admin client sets authorizedDatabases to true","suites":["listDatabases()","authorizedDatabases option"],"updatePoint":{"line":44,"column":84,"index":1610},"line":44,"code":"    it('should list all databases when admin client sets authorizedDatabases to true', metadata, async function () {\n      const adminListDbs = await adminClient.db().admin().listDatabases({\n        authorizedDatabases: true\n      });\n      const adminDbs = adminListDbs.databases.map(({\n        name\n      }) => name);\n\n      // no change in the dbs listed since we're using the admin user\n      expect(adminDbs).to.have.length.greaterThan(1);\n      expect(adminDbs.filter(db => db === mockAuthorizedDb)).to.have.lengthOf(1);\n      expect(adminDbs.filter(db => db !== mockAuthorizedDb)).to.have.length.greaterThan(1);\n    });","file":"integration/enumerate_databases.test.ts","skipped":false,"dir":"test"},{"name":"should list all databases when admin client sets authorizedDatabases to false","suites":["listDatabases()","authorizedDatabases option"],"updatePoint":{"line":57,"column":85,"index":2238},"line":57,"code":"    it('should list all databases when admin client sets authorizedDatabases to false', metadata, async function () {\n      const adminListDbs = await adminClient.db().admin().listDatabases({\n        authorizedDatabases: false\n      });\n      const adminDbs = adminListDbs.databases.map(({\n        name\n      }) => name);\n\n      // no change in the dbs listed since we're using the admin user\n      expect(adminDbs).to.have.length.greaterThan(1);\n      expect(adminDbs.filter(db => db === mockAuthorizedDb)).to.have.lengthOf(1);\n      expect(adminDbs.filter(db => db !== mockAuthorizedDb)).to.have.length.greaterThan(1);\n    });","file":"integration/enumerate_databases.test.ts","skipped":false,"dir":"test"},{"name":"should list authorized databases with authorizedDatabases set to true","suites":["listDatabases()","authorizedDatabases option"],"updatePoint":{"line":70,"column":77,"index":2859},"line":70,"code":"    it('should list authorized databases with authorizedDatabases set to true', metadata, async function () {\n      const adminListDbs = await adminClient.db().admin().listDatabases();\n      const authorizedListDbs = await authorizedClient.db().admin().listDatabases({\n        authorizedDatabases: true\n      });\n      const adminDbs = adminListDbs.databases;\n      const authorizedDbs = authorizedListDbs.databases;\n      expect(adminDbs).to.have.length.greaterThan(1);\n      expect(authorizedDbs).to.have.lengthOf(1);\n      expect(adminDbs.filter(db => db.name === mockAuthorizedDb)).to.have.lengthOf(1);\n      expect(adminDbs.filter(db => db.name !== mockAuthorizedDb)).to.have.length.greaterThan(1);\n      expect(authorizedDbs.filter(db => db.name === mockAuthorizedDb)).to.have.lengthOf(1);\n    });","file":"integration/enumerate_databases.test.ts","skipped":false,"dir":"test"},{"name":"should list authorized databases by default with authorizedDatabases unspecified","suites":["listDatabases()","authorizedDatabases option"],"updatePoint":{"line":83,"column":88,"index":3674},"line":83,"code":"    it('should list authorized databases by default with authorizedDatabases unspecified', metadata, async function () {\n      const adminListDbs = await adminClient.db().admin().listDatabases();\n      const authorizedListDbs = await authorizedClient.db().admin().listDatabases();\n      const adminDbs = adminListDbs.databases;\n      const authorizedDbs = authorizedListDbs.databases;\n      expect(adminDbs).to.have.length.greaterThan(1);\n      expect(authorizedDbs).to.have.lengthOf(1);\n      expect(adminDbs.filter(db => db.name === mockAuthorizedDb)).to.have.lengthOf(1);\n      expect(adminDbs.filter(db => db.name !== mockAuthorizedDb)).to.have.length.greaterThan(1);\n      expect(authorizedDbs.filter(db => db.name === mockAuthorizedDb)).to.have.lengthOf(1);\n    });","file":"integration/enumerate_databases.test.ts","skipped":false,"dir":"test"},{"name":"should not show authorized databases with authorizedDatabases set to false","suites":["listDatabases()","authorizedDatabases option"],"updatePoint":{"line":94,"column":82,"index":4440},"line":94,"code":"    it('should not show authorized databases with authorizedDatabases set to false', metadata, async function () {\n      let thrownError;\n      try {\n        await authorizedClient.db().admin().listDatabases({\n          authorizedDatabases: false\n        });\n      } catch (error) {\n        thrownError = error;\n      }\n\n      // check correctly produces an 'Insufficient permissions to list all databases' error\n      expect(thrownError).to.be.instanceOf(MongoServerError);\n      expect(thrownError).to.have.property('message').that.includes('list');\n    });","file":"integration/enumerate_databases.test.ts","skipped":false,"dir":"test"},{"name":"should upload from file stream","suites":["GridFS Stream"],"updatePoint":{"line":34,"column":36,"index":699},"line":34,"code":"  it('should upload from file stream', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        db.dropDatabase(function (error) {\n          expect(error).to.not.exist;\n          const bucket = new GridFSBucket(db);\n          const readStream = fs.createReadStream('./LICENSE.md');\n          const uploadStream = bucket.openUploadStream('test.dat');\n          const license = fs.readFileSync('./LICENSE.md');\n          const id = uploadStream.id;\n\n          // Wait for stream to finish\n          uploadStream.once('finish', function () {\n            const chunksColl = db.collection('fs.chunks');\n            const chunksQuery = chunksColl.find({\n              files_id: id\n            });\n\n            // Get all the chunks\n            chunksQuery.toArray(function (error, docs) {\n              expect(error).to.not.exist;\n              expect(docs.length).to.equal(1);\n              expect(docs[0].data.toString('hex')).to.equal(license.toString('hex'));\n              const filesColl = db.collection('fs.files');\n              const filesQuery = filesColl.find({\n                _id: id\n              });\n              filesQuery.toArray(function (error, docs) {\n                expect(error).to.not.exist;\n                expect(docs.length).to.equal(1);\n                expect(docs[0]).to.not.have.property('md5');\n\n                // make sure we created indexes\n                filesColl.listIndexes().toArray(function (error, indexes) {\n                  expect(error).to.not.exist;\n                  expect(indexes.length).to.equal(2);\n                  expect(indexes[1].name).to.equal('filename_1_uploadDate_1');\n                  chunksColl.listIndexes().toArray(function (error, indexes) {\n                    expect(error).to.not.exist;\n                    expect(indexes.length).to.equal(2);\n                    expect(indexes[1].name).to.equal('files_id_1_n_1');\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n          readStream.pipe(uploadStream);\n        });\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"destroy publishes provided error","suites":["GridFS Stream"],"updatePoint":{"line":96,"column":38,"index":3089},"line":96,"code":"  it('destroy publishes provided error', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        db.dropDatabase(function (error) {\n          expect(error).to.not.exist;\n          const bucket = new GridFSBucket(db);\n          const readStream = fs.createReadStream('./LICENSE.md');\n          const uploadStream = bucket.openUploadStream('test.dat');\n          const errorMessage = 'error';\n          uploadStream.once('error', function (e) {\n            expect(e).to.equal(errorMessage);\n            client.close(done);\n          });\n          uploadStream.once('finish', function () {\n            uploadStream.destroy(errorMessage);\n          });\n          readStream.pipe(uploadStream);\n        });\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should upload from file stream with custom id","suites":["GridFS Stream"],"updatePoint":{"line":134,"column":51,"index":4299},"line":134,"code":"  it('should upload from file stream with custom id', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        db.dropDatabase(function (error) {\n          expect(error).to.not.exist;\n          const bucket = new GridFSBucket(db);\n          const readStream = fs.createReadStream('./LICENSE.md');\n          const uploadStream = bucket.openUploadStreamWithId(1, 'test.dat');\n          const license = fs.readFileSync('./LICENSE.md');\n          const id = uploadStream.id;\n          expect(id).to.equal(1);\n\n          // Wait for stream to finish\n          uploadStream.once('finish', function () {\n            const chunksColl = db.collection('fs.chunks');\n            const chunksQuery = chunksColl.find({\n              files_id: id\n            });\n\n            // Get all the chunks\n            chunksQuery.toArray(function (error, docs) {\n              expect(error).to.not.exist;\n              expect(docs.length).to.equal(1);\n              expect(docs[0].data.toString('hex')).to.equal(license.toString('hex'));\n              const filesColl = db.collection('fs.files');\n              const filesQuery = filesColl.find({\n                _id: id\n              });\n              filesQuery.toArray(function (error, docs) {\n                expect(error).to.not.exist;\n                expect(docs.length).to.equal(1);\n                expect(docs[0]).to.not.have.property('md5');\n\n                // make sure we created indexes\n                filesColl.listIndexes().toArray(function (error, indexes) {\n                  expect(error).to.not.exist;\n                  expect(indexes.length).to.equal(2);\n                  expect(indexes[1].name).to.equal('filename_1_uploadDate_1');\n                  chunksColl.listIndexes().toArray(function (error, indexes) {\n                    expect(error).to.not.exist;\n                    expect(indexes.length).to.equal(2);\n                    expect(indexes[1].name).to.equal('files_id_1_n_1');\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n          readStream.pipe(uploadStream);\n        });\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should download to upload stream","suites":["GridFS Stream"],"updatePoint":{"line":204,"column":38,"index":6895},"line":204,"code":"  it('should download to upload stream', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload'\n        });\n        const CHUNKS_COLL = 'gridfsdownload.chunks';\n        const FILES_COLL = 'gridfsdownload.files';\n        const readStream = fs.createReadStream('./LICENSE.md');\n        let uploadStream = bucket.openUploadStream('test.dat');\n        const license = fs.readFileSync('./LICENSE.md');\n        let id = uploadStream.id;\n        uploadStream.once('finish', function () {\n          const downloadStream = bucket.openDownloadStream(id);\n          uploadStream = bucket.openUploadStream('test2.dat');\n          id = uploadStream.id;\n          downloadStream.pipe(uploadStream).once('finish', function () {\n            const chunksQuery = db.collection(CHUNKS_COLL).find({\n              files_id: id\n            });\n            chunksQuery.toArray(function (error, docs) {\n              expect(error).to.not.exist;\n              expect(docs.length).to.equal(1);\n              expect(docs[0].data.toString('hex')).to.equal(license.toString('hex'));\n              const filesQuery = db.collection(FILES_COLL).find({\n                _id: id\n              });\n              filesQuery.toArray(function (error, docs) {\n                expect(error).to.not.exist;\n                expect(docs.length).to.equal(1);\n                expect(docs[0]).to.not.have.property('md5');\n                client.close(done);\n              });\n            });\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should fail to locate gridfs stream","suites":["GridFS Stream"],"updatePoint":{"line":258,"column":41,"index":8867},"line":258,"code":"  it('should fail to locate gridfs stream', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload'\n        });\n\n        // Get an unknown file\n        const downloadStream = bucket.openDownloadStream(new ObjectId());\n        downloadStream.on('data', function () {});\n        downloadStream.on('error', function (err) {\n          expect(err.code).to.equal('ENOENT');\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"openDownloadStreamByName","suites":["GridFS Stream"],"updatePoint":{"line":292,"column":30,"index":9812},"line":292,"code":"  it('openDownloadStreamByName', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload'\n        });\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('test.dat');\n        uploadStream.once('finish', function () {\n          const downloadStream = bucket.openDownloadStreamByName('test.dat');\n          let gotData = false;\n          downloadStream.on('data', function (data) {\n            expect(gotData).to.equal(false);\n            gotData = true;\n            expect(data.toString('utf8').indexOf('TERMS AND CONDITIONS') !== -1).to.equal(true);\n          });\n          downloadStream.on('end', function () {\n            expect(gotData).to.equal(true);\n            client.close(done);\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"start/end options for openDownloadStream","suites":["GridFS Stream"],"updatePoint":{"line":334,"column":46,"index":11264},"line":334,"code":"  it('start/end options for openDownloadStream', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload',\n          chunkSizeBytes: 2\n        });\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('teststart.dat');\n        uploadStream.once('finish', function () {\n          const downloadStream = bucket.openDownloadStreamByName('teststart.dat', {\n            start: 1\n          }).end(6);\n          downloadStream.on('error', function (error) {\n            expect(error).to.not.exist;\n          });\n          let gotData = 0;\n          let str = '';\n          downloadStream.on('data', function (data) {\n            ++gotData;\n            str += data.toString('utf8');\n          });\n          downloadStream.on('end', function () {\n            // Depending on different versions of node, we may get\n            // different amounts of 'data' events. node 0.10 gives 2,\n            // node >= 0.12 gives 3. Either is correct, but we just\n            // care that we got between 1 and 3, and got the right result\n            expect(gotData >= 1 && gotData <= 3).to.equal(true);\n            expect(str).to.equal('pache');\n            client.close(done);\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should emit close after all chunks are received","suites":["GridFS Stream"],"updatePoint":{"line":380,"column":53,"index":12958},"line":380,"code":"  it('should emit close after all chunks are received', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const db = client.db();\n      const bucket = new GridFSBucket(db, {\n        bucketName: 'gridfsdownload',\n        chunkSizeBytes: 6000\n      });\n      const readStream = fs.createReadStream('./LICENSE.md');\n      const uploadStream = bucket.openUploadStream('teststart.dat');\n      uploadStream.once('finish', function () {\n        const downloadStream = bucket.openDownloadStreamByName('teststart.dat');\n        const events = [];\n        downloadStream.on('data', () => events.push('data'));\n        downloadStream.on('close', () => events.push('close'));\n        downloadStream.on('end', () => {\n          expect(events).to.deep.equal(['data', 'data', 'close']);\n          expect(downloadStream).to.exist;\n          client.close(done);\n        });\n      });\n      readStream.pipe(uploadStream);\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"Deleting a file","suites":["GridFS Stream"],"updatePoint":{"line":415,"column":21,"index":14007},"line":415,"code":"  it('Deleting a file', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload'\n        });\n        const CHUNKS_COLL = 'gridfsdownload.chunks';\n        const FILES_COLL = 'gridfsdownload.files';\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const id = uploadStream.id;\n        uploadStream.once('finish', function () {\n          bucket.delete(id, function (err) {\n            expect(err).to.not.exist;\n            const chunksQuery = db.collection(CHUNKS_COLL).find({\n              files_id: id\n            });\n            chunksQuery.toArray(function (error, docs) {\n              expect(error).to.not.exist;\n              expect(docs.length).to.equal(0);\n              const filesQuery = db.collection(FILES_COLL).find({\n                _id: id\n              });\n              filesQuery.toArray(function (error, docs) {\n                expect(error).to.not.exist;\n                expect(docs.length).to.equal(0);\n                client.close(done);\n              });\n            });\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"Aborting an upload","suites":["GridFS Stream"],"updatePoint":{"line":467,"column":24,"index":15670},"line":467,"code":"  it('Aborting an upload', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsabort',\n          chunkSizeBytes: 1\n        });\n        const CHUNKS_COLL = 'gridfsabort.chunks';\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const id = uploadStream.id;\n        const query = {\n          files_id: id\n        };\n        uploadStream.write('a', 'utf8', function (error) {\n          expect(error).to.not.exist;\n          db.collection(CHUNKS_COLL).count(query, function (error, c) {\n            expect(error).to.not.exist;\n            expect(c).to.equal(1);\n            uploadStream.abort(function (error) {\n              expect(error).to.not.exist;\n              db.collection(CHUNKS_COLL).count(query, function (error, c) {\n                expect(error).to.not.exist;\n                expect(c).to.equal(0);\n                uploadStream.write('b', 'utf8', function (error) {\n                  expect(error.toString()).to.equal('MongoAPIError: Stream has been aborted');\n                  uploadStream.end('c', 'utf8', function (error) {\n                    expect(error.toString()).to.equal('MongoAPIError: Stream has been aborted');\n                    // Fail if user tries to abort an aborted stream\n                    uploadStream.abort().then(null, function (error) {\n                      expect(error.toString()).to.equal(\n                      // TODO(NODE-3485): Replace with MongoGridFSStreamClosedError\n                      'MongoAPIError: Cannot call abort() on a stream twice');\n                      client.close(done);\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"Destroy an upload","suites":["GridFS Stream"],"updatePoint":{"line":524,"column":23,"index":17789},"line":524,"code":"  it('Destroy an upload', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsabort',\n          chunkSizeBytes: 1\n        });\n        const CHUNKS_COLL = 'gridfsabort.chunks';\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const id = uploadStream.id;\n        const query = {\n          files_id: id\n        };\n        uploadStream.write('a', 'utf8', function (error) {\n          expect(error).to.not.exist;\n          db.collection(CHUNKS_COLL).count(query, function (error, c) {\n            expect(error).to.not.exist;\n            expect(c).to.equal(1);\n            uploadStream.abort(function (error) {\n              expect(error).to.not.exist;\n              db.collection(CHUNKS_COLL).count(query, function (error, c) {\n                expect(error).to.not.exist;\n                expect(c).to.equal(0);\n                uploadStream.write('b', 'utf8', function (error) {\n                  expect(error.toString()).to.equal('MongoAPIError: Stream has been aborted');\n                  uploadStream.end('c', 'utf8', function (error) {\n                    expect(error.toString()).to.equal('MongoAPIError: Stream has been aborted');\n                    // Fail if user tries to abort an aborted stream\n                    uploadStream.abort().then(null, function (error) {\n                      expect(error.toString()).to.equal(\n                      // TODO(NODE-3485): Replace with MongoGridFSStreamClosedError\n                      'MongoAPIError: Cannot call abort() on a stream twice');\n                      client.close(done);\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"Destroying a download stream","suites":["GridFS Stream"],"updatePoint":{"line":584,"column":34,"index":20019},"line":584,"code":"  it('Destroying a download stream', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        apiVersion: false\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdestroy',\n          chunkSizeBytes: 10\n        });\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('test.dat');\n\n        // Wait for stream to finish\n        uploadStream.once('finish', function () {\n          const id = uploadStream.id;\n          const downloadStream = bucket.openDownloadStream(id);\n          const finished = {};\n          downloadStream.on('data', function () {\n            expect.fail('Should be unreachable');\n          });\n          downloadStream.on('error', function () {\n            expect.fail('Should be unreachable');\n          });\n          downloadStream.on('end', function () {\n            expect(downloadStream.s.cursor).to.not.exist;\n            if (finished.close) {\n              client.close(done);\n              return;\n            }\n            finished.end = true;\n          });\n          downloadStream.on('close', function () {\n            if (finished.end) {\n              client.close(done);\n              return;\n            }\n            finished.close = true;\n          });\n          downloadStream.abort(function (error) {\n            expect(error).to.not.exist;\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"Deleting a file using promises","suites":["GridFS Stream"],"updatePoint":{"line":646,"column":36,"index":21907},"line":646,"code":"  it('Deleting a file using promises', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient(configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    client.connect(function (err, client) {\n      const db = client.db(configuration.db);\n      const bucket = new GridFSBucket(db, {\n        bucketName: 'gridfsdownload'\n      });\n      const CHUNKS_COLL = 'gridfsdownload.chunks';\n      const FILES_COLL = 'gridfsdownload.files';\n      const readStream = fs.createReadStream('./LICENSE.md');\n      const uploadStream = bucket.openUploadStream('test.dat');\n      const id = uploadStream.id;\n      uploadStream.once('finish', function () {\n        bucket.delete(id).then(function () {\n          const chunksQuery = db.collection(CHUNKS_COLL).find({\n            files_id: id\n          });\n          chunksQuery.toArray(function (error, docs) {\n            expect(error).to.not.exist;\n            expect(docs.length).to.equal(0);\n            const filesQuery = db.collection(FILES_COLL).find({\n              _id: id\n            });\n            filesQuery.toArray(function (error, docs) {\n              expect(error).to.not.exist;\n              expect(docs.length).to.equal(0);\n              client.close(done);\n            });\n          });\n        });\n      });\n      readStream.pipe(uploadStream);\n    });\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"find()","suites":["GridFS Stream"],"updatePoint":{"line":683,"column":12,"index":23254},"line":683,"code":"  it('find()', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient(configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    client.connect(function (err, client) {\n      const db = client.db(configuration.db);\n      const bucket = new GridFSBucket(db, {\n        bucketName: 'fs'\n      });\n\n      // We're only making sure this doesn't throw\n      bucket.find({\n        batchSize: 1,\n        limit: 2,\n        maxTimeMS: 3,\n        noCursorTimeout: true,\n        skip: 4,\n        sort: {\n          _id: 1\n        }\n      });\n      client.close(done);\n    });\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"drop example","suites":["GridFS Stream"],"updatePoint":{"line":708,"column":18,"index":23890},"line":708,"code":"  it('drop example', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient(configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    client.connect(function (err, client) {\n      const db = client.db(configuration.db);\n      const bucket = new GridFSBucket(db, {\n        bucketName: 'gridfsdownload'\n      });\n      const CHUNKS_COLL = 'gridfsdownload.chunks';\n      const FILES_COLL = 'gridfsdownload.files';\n      const readStream = fs.createReadStream('./LICENSE.md');\n      const uploadStream = bucket.openUploadStream('test.dat');\n      const id = uploadStream.id;\n      uploadStream.once('finish', function () {\n        bucket.drop(function (err) {\n          expect(err).to.not.exist;\n          const chunksQuery = db.collection(CHUNKS_COLL).find({\n            files_id: id\n          });\n          chunksQuery.toArray(function (error, docs) {\n            expect(error).to.not.exist;\n            expect(docs.length).to.equal(0);\n            const filesQuery = db.collection(FILES_COLL).find({\n              _id: id\n            });\n            filesQuery.toArray(function (error, docs) {\n              expect(error).to.not.exist;\n              expect(docs.length).to.equal(0);\n              client.close(done);\n            });\n          });\n        });\n      });\n      readStream.pipe(uploadStream);\n    });\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"drop using promises","suites":["GridFS Stream"],"updatePoint":{"line":753,"column":25,"index":25415},"line":753,"code":"  it('drop using promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload'\n        });\n        const CHUNKS_COLL = 'gridfsdownload.chunks';\n        const FILES_COLL = 'gridfsdownload.files';\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const id = uploadStream.id;\n        uploadStream.once('finish', function () {\n          bucket.drop().then(function () {\n            const chunksQuery = db.collection(CHUNKS_COLL).find({\n              files_id: id\n            });\n            chunksQuery.toArray(function (error, docs) {\n              expect(error).to.not.exist;\n              expect(docs.length).to.equal(0);\n              const filesQuery = db.collection(FILES_COLL).find({\n                _id: id\n              });\n              filesQuery.toArray(function (error, docs) {\n                expect(error).to.not.exist;\n                expect(docs.length).to.equal(0);\n                client.close(done);\n              });\n            });\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"find example","suites":["GridFS Stream"],"updatePoint":{"line":804,"column":18,"index":27040},"line":804,"code":"  it('find example', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload_2'\n        });\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('test.dat');\n        uploadStream.once('finish', function () {\n          bucket.find({}, {\n            batchSize: 1\n          }).toArray(function (err, files) {\n            expect(err).to.not.exist;\n            expect(1).to.equal(files.length);\n            client.close(done);\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"rename example","suites":["GridFS Stream"],"updatePoint":{"line":842,"column":20,"index":28093},"line":842,"code":"  it('rename example', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload_3'\n        });\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const id = uploadStream.id;\n        uploadStream.once('finish', function () {\n          // Rename the file\n          bucket.rename(id, 'renamed_it.dat', function (err) {\n            expect(err).to.not.exist;\n            client.close(done);\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"download empty doc","suites":["GridFS Stream"],"updatePoint":{"line":872,"column":24,"index":29036},"line":872,"code":"  it('download empty doc', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'fs'\n        });\n        db.collection('fs.files').insertMany([{\n          length: 0\n        }], function (error, result) {\n          expect(error).to.not.exist;\n          expect(Object.keys(result.insertedIds).length).to.equal(1);\n          const id = result.insertedIds[0];\n          const stream = bucket.openDownloadStream(id);\n          stream.on('error', function (error) {\n            expect(error).to.not.exist;\n          });\n          stream.on('data', function () {\n            expect.fail('Should be unreachable');\n          });\n          stream.on('end', function () {\n            // As per spec, make sure we didn't actually fire a query\n            // because the document length is 0\n            expect(stream.s.cursor).to.not.exist;\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should use chunkSize for download","suites":["GridFS Stream"],"updatePoint":{"line":911,"column":39,"index":30327},"line":911,"code":"  it('should use chunkSize for download', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      if (typeof stream.pipeline !== 'function') {\n        this.skip();\n      }\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfs'\n        });\n        const uploadStream = bucket.openUploadStream('test');\n        uploadStream.end(Buffer.alloc(40 * 1024 * 1024), err => {\n          expect(err).to.not.exist;\n          const range = {\n            start: 35191617,\n            end: 35192831\n          };\n          const downloadStream = bucket.openDownloadStreamByName('test', range);\n          const outputStream = fs.createWriteStream('output');\n          stream.pipeline(downloadStream, outputStream, err => {\n            expect(err).to.not.exist;\n            client.close(() => {\n              fs.stat('output', (err, stats) => {\n                expect(err).to.not.exist;\n                expect(range.end - range.start).to.equal(stats.size);\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should correctly handle calling end function with only a callback","suites":["GridFS Stream"],"updatePoint":{"line":957,"column":71,"index":31826},"line":957,"code":"  it('should correctly handle calling end function with only a callback', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsabort',\n          chunkSizeBytes: 1\n        });\n        const CHUNKS_COLL = 'gridfsabort.chunks';\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const id = uploadStream.id;\n        const query = {\n          files_id: id\n        };\n        uploadStream.write('a', 'utf8', function (error) {\n          expect(error).to.not.exist;\n          db.collection(CHUNKS_COLL).count(query, function (error, c) {\n            expect(error).to.not.exist;\n            expect(c).to.equal(1);\n            uploadStream.abort(function (error) {\n              expect(error).to.not.exist;\n              db.collection(CHUNKS_COLL).count(query, function (error, c) {\n                expect(error).to.not.exist;\n                expect(c).to.equal(0);\n                uploadStream.write('b', 'utf8', function (error) {\n                  expect(error.toString()).to.equal('MongoAPIError: Stream has been aborted');\n                  uploadStream.end(function (error) {\n                    expect(error.toString()).to.equal('MongoAPIError: Stream has been aborted');\n\n                    // Fail if user tries to abort an aborted stream\n                    uploadStream.abort().then(null, function (error) {\n                      expect(error.toString()).to.equal(\n                      // TODO(NODE-3485): Replace with MongoGridFSStreamClosedError\n                      'MongoAPIError: Cannot call abort() on a stream twice');\n                      client.close(done);\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should not call the callback on repeat calls to end","suites":["GridFS Stream","upload stream end()"],"updatePoint":{"line":1017,"column":59,"index":34081},"line":1017,"code":"    it('should not call the callback on repeat calls to end', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n      async test() {\n        const configuration = this.configuration;\n        client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        await client.connect();\n        db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsabort',\n          chunkSizeBytes: 1\n        });\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const endPromise = new Promise(resolve => {\n          uploadStream.end('1', resolve);\n        });\n        const endPromise2 = new Promise((resolve, reject) => {\n          uploadStream.end('2', () => {\n            reject(new Error('Expected callback to not be called on duplicate end'));\n          });\n        });\n        await endPromise;\n        // in the fail case, the callback would be called when the actual write is finished,\n        // so we need to give it a moment\n        await Promise.race([endPromise2, sleep(100)]);\n      }\n    });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should not write a chunk on repeat calls to end","suites":["GridFS Stream","upload stream end()"],"updatePoint":{"line":1049,"column":55,"index":35229},"line":1049,"code":"    it('should not write a chunk on repeat calls to end', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n      async test() {\n        const configuration = this.configuration;\n        client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        await client.connect();\n        db = client.db(this.configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsabort',\n          chunkSizeBytes: 1\n        });\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const spy = sinon.spy(uploadStream, 'write');\n        const endPromise = new Promise(resolve => {\n          uploadStream.end('1', resolve);\n        });\n        await endPromise;\n        expect(spy).to.have.been.calledWith('1');\n        uploadStream.end('2');\n\n        // wait for potential async calls to happen before we close the client\n        // so that we don't get a client not connected failure in the afterEach\n        // in the failure case since it would be confusing and unnecessary\n        // given the assertions we already have for this case\n        await sleep(100);\n        expect(spy).not.to.have.been.calledWith('2');\n        expect(spy.calledOnce).to.be.true;\n      }\n    });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should return only end - start bytes when the end is within a chunk","suites":["GridFS Stream","upload stream end()"],"updatePoint":{"line":1085,"column":73,"index":36556},"line":1085,"code":"  it('should return only end - start bytes when the end is within a chunk', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      // Provide start and end parameters for file download to skip\n      // ahead x bytes and limit the total amount of bytes read to n\n      const db = client.db();\n      const start = 1;\n      const end = 6;\n      const bucket = new GridFSBucket(db, {\n        bucketName: 'gridfsdownload',\n        chunkSizeBytes: 20\n      });\n      const readStream = fs.createReadStream('./LICENSE.md');\n      const uploadStream = bucket.openUploadStream('teststart.dat');\n      uploadStream.once('finish', function () {\n        const downloadStream = bucket.openDownloadStreamByName('teststart.dat', {\n          start\n        }).end(end);\n        downloadStream.on('error', done);\n        let str = '';\n        downloadStream.on('data', function (data) {\n          str += data.toString('utf8');\n        });\n        downloadStream.on('end', function () {\n          expect(str).to.equal('pache');\n          expect(str).to.have.lengthOf(end - start);\n          client.close(done);\n        });\n      });\n      readStream.pipe(uploadStream);\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should correctly handle indexes create with BSON.Double","suites":["GridFS Stream","upload stream end()"],"updatePoint":{"line":1121,"column":61,"index":37755},"line":1121,"code":"  it('should correctly handle indexes create with BSON.Double', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient();\n    client.connect((err, client) => {\n      expect(err).to.not.exist;\n      const db = client.db(configuration.db);\n      const col = db.collection('fs.files');\n      col.createIndex({\n        filename: new Double(1.0),\n        uploadDate: new Double(1.0)\n      }, err => {\n        expect(err).to.not.exist;\n        col.listIndexes().toArray((err, indexes) => {\n          expect(err).to.not.exist;\n          const names = indexes.map(i => i.name);\n          expect(names).to.eql(['_id_', 'filename_1_uploadDate_1']);\n          client.close(done);\n        });\n      });\n    });\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"NODE-2623 downloadStream should emit error on end > size","suites":["GridFS Stream","upload stream end()"],"updatePoint":{"line":1142,"column":62,"index":38513},"line":1142,"code":"  it('NODE-2623 downloadStream should emit error on end > size', function (done) {\n    const configuration = this.configuration;\n    const client = this.configuration.newClient({\n      monitorCommands: true\n    });\n    const db = client.db(configuration.db);\n    const bucket = new GridFSBucket(db, {\n      bucketName: 'gridfsdownload'\n    });\n    const readStream = fs.createReadStream('./LICENSE.md');\n    const uploadStream = bucket.openUploadStream('test.dat');\n    const actualSize = fs.fstatSync(fs.openSync('./LICENSE.md', 'r')).size;\n    const wrongExpectedSize = Math.floor(actualSize * 1.1);\n    const id = uploadStream.id;\n    uploadStream.once('finish', function () {\n      const downloadStream = bucket.openDownloadStream(id, {\n        end: wrongExpectedSize\n      });\n      downloadStream.on('data', function () {});\n      downloadStream.on('error', function (err) {\n        expect(err.message).to.equal(`Stream end (${wrongExpectedSize}) must not be more than the length of the file (${actualSize})`);\n        client.close(done);\n      });\n    });\n    readStream.pipe(uploadStream);\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute createIndex using Promise","suites":["Indexes","promise tests"],"updatePoint":{"line":16,"column":58,"index":366},"line":16,"code":"    it('Should correctly execute createIndex using Promise', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        const client = configuration.newClient({\n          maxPoolSize: 5\n        });\n        // Create an index\n        client.db(configuration.db).createIndex('promiseCollectionCollections1', {\n          a: 1\n        }).then(function (r) {\n          test.ok(r != null);\n          client.close(done);\n        });\n      }\n    });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute ensureIndex using Promise","suites":["Indexes","promise tests"],"updatePoint":{"line":36,"column":58,"index":925},"line":36,"code":"    it('Should correctly execute ensureIndex using Promise', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        const client = configuration.newClient({\n          maxPoolSize: 5\n        });\n\n        // Create an index\n        client.db(configuration.db).createIndex('promiseCollectionCollections2', {\n          a: 1\n        }).then(function (r) {\n          test.ok(r != null);\n          client.close(done);\n        });\n      }\n    });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExtractIndexInformation","suites":["Indexes","promise tests"],"updatePoint":{"line":58,"column":44,"index":1477},"line":58,"code":"  it('shouldCorrectlyExtractIndexInformation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.createCollection('test_index_information', function (err, collection) {\n        collection.insertMany([{\n          a: 1\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n\n          // Create an index on the collection\n          db.createIndex(collection.collectionName, 'a', configuration.writeConcernMax(), function (err, indexName) {\n            expect(err).to.not.exist;\n            test.equal('a_1', indexName);\n\n            // Let's fetch the index information\n            db.indexInformation(collection.collectionName, function (err, collectionInfo) {\n              expect(err).to.not.exist;\n              test.ok(collectionInfo['_id_'] != null);\n              test.equal('_id', collectionInfo['_id_'][0][0]);\n              test.ok(collectionInfo['a_1'] != null);\n              test.deepEqual([['a', 1]], collectionInfo['a_1']);\n              db.indexInformation(collection.collectionName, function (err, collectionInfo2) {\n                var count1 = Object.keys(collectionInfo).length,\n                  count2 = Object.keys(collectionInfo2).length;\n\n                // Tests\n                test.ok(count2 >= count1);\n                test.ok(collectionInfo2['_id_'] != null);\n                test.equal('_id', collectionInfo2['_id_'][0][0]);\n                test.ok(collectionInfo2['a_1'] != null);\n                test.deepEqual([['a', 1]], collectionInfo2['a_1']);\n                test.ok(collectionInfo[indexName] != null);\n                test.deepEqual([['a', 1]], collectionInfo[indexName]);\n\n                // Let's close the db\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleMultipleColumnIndexes","suites":["Indexes","promise tests"],"updatePoint":{"line":110,"column":48,"index":3613},"line":110,"code":"  it('shouldCorrectlyHandleMultipleColumnIndexes', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.createCollection('test_multiple_index_cols', function (err, collection) {\n        collection.insert({\n          a: 1\n        }, function (err) {\n          expect(err).to.not.exist;\n          // Create an index on the collection\n          db.createIndex(collection.collectionName, [['a', -1], ['b', 1], ['c', -1]], configuration.writeConcernMax(), function (err, indexName) {\n            expect(err).to.not.exist;\n            test.equal('a_-1_b_1_c_-1', indexName);\n            // Let's fetch the index information\n            db.indexInformation(collection.collectionName, function (err, collectionInfo) {\n              var count1 = Object.keys(collectionInfo).length;\n\n              // Test\n              test.equal(2, count1);\n              test.ok(collectionInfo[indexName] != null);\n              test.deepEqual([['a', -1], ['b', 1], ['c', -1]], collectionInfo[indexName]);\n\n              // Let's close the db\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleUniqueIndex","suites":["Indexes","promise tests"],"updatePoint":{"line":148,"column":38,"index":5039},"line":148,"code":"  it('shouldCorrectlyHandleUniqueIndex', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      // Create a non-unique index and test inserts\n      db.createCollection('test_unique_index', function (err, collection) {\n        db.createIndex(collection.collectionName, 'hello', configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          // Insert some docs\n          collection.insert([{\n            hello: 'world'\n          }, {\n            hello: 'mike'\n          }, {\n            hello: 'world'\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Create a unique index and test that insert fails\n            db.createCollection('test_unique_index2', function (err, collection) {\n              db.createIndex(collection.collectionName, 'hello', {\n                unique: true,\n                writeConcern: {\n                  w: 1\n                }\n              }, function (err) {\n                expect(err).to.not.exist;\n                // Insert some docs\n                collection.insert([{\n                  hello: 'world'\n                }, {\n                  hello: 'mike'\n                }, {\n                  hello: 'world'\n                }], configuration.writeConcernMax(), function (err) {\n                  test.ok(err != null);\n                  test.equal(11000, err.code);\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateSubfieldIndex","suites":["Indexes","promise tests"],"updatePoint":{"line":204,"column":40,"index":6970},"line":204,"code":"  it('shouldCorrectlyCreateSubfieldIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      // Create a non-unique index and test inserts\n      db.createCollection('test_index_on_subfield', function (err, collection) {\n        collection.insert([{\n          hello: {\n            a: 4,\n            b: 5\n          }\n        }, {\n          hello: {\n            a: 7,\n            b: 2\n          }\n        }, {\n          hello: {\n            a: 4,\n            b: 10\n          }\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n\n          // Create a unique subfield index and test that insert fails\n          db.createCollection('test_index_on_subfield2', function (err, collection) {\n            db.createIndex(collection.collectionName, 'hello_a', {\n              writeConcern: {\n                w: 1\n              },\n              unique: true\n            }, function (err) {\n              expect(err).to.not.exist;\n              collection.insert([{\n                hello: {\n                  a: 4,\n                  b: 5\n                }\n              }, {\n                hello: {\n                  a: 7,\n                  b: 2\n                }\n              }, {\n                hello: {\n                  a: 4,\n                  b: 10\n                }\n              }], configuration.writeConcernMax(), function (err) {\n                // Assert that we have erros\n                test.ok(err != null);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDropIndexes","suites":["Indexes","promise tests"],"updatePoint":{"line":271,"column":32,"index":8858},"line":271,"code":"  it('shouldCorrectlyDropIndexes', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.createCollection('test_drop_indexes', function (err, collection) {\n        collection.insert({\n          a: 1\n        }, configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          // Create an index on the collection\n          db.createIndex(collection.collectionName, 'a', configuration.writeConcernMax(), function (err, indexName) {\n            test.equal('a_1', indexName);\n            // Drop all the indexes\n            collection.dropIndexes(function (err, result) {\n              test.equal(true, result);\n              collection.indexInformation(function (err, result) {\n                test.ok(result['a_1'] == null);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleDistinctIndexes","suites":["Indexes","promise tests"],"updatePoint":{"line":304,"column":42,"index":10058},"line":304,"code":"  it('shouldCorrectlyHandleDistinctIndexes', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.createCollection('test_distinct_queries', function (err, collection) {\n        collection.insert([{\n          a: 0,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'b'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'c'\n          }\n        }, {\n          a: 2,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 3\n        }, {\n          a: 3\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          collection.distinct('a', function (err, docs) {\n            test.deepEqual([0, 1, 2, 3], docs.sort());\n            collection.distinct('b.c', function (err, docs) {\n              test.deepEqual(['a', 'b', 'c'], docs.sort());\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteEnsureIndex","suites":["Indexes","promise tests"],"updatePoint":{"line":354,"column":39,"index":11346},"line":354,"code":"  it('shouldCorrectlyExecuteEnsureIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.createCollection('test_ensure_index', function (err, collection) {\n        expect(err).to.not.exist;\n        // Create an index on the collection\n        db.createIndex(collection.collectionName, 'a', configuration.writeConcernMax(), function (err, indexName) {\n          expect(err).to.not.exist;\n          test.equal('a_1', indexName);\n          // Let's fetch the index information\n          db.indexInformation(collection.collectionName, function (err, collectionInfo) {\n            test.ok(collectionInfo['_id_'] != null);\n            test.equal('_id', collectionInfo['_id_'][0][0]);\n            test.ok(collectionInfo['a_1'] != null);\n            test.deepEqual([['a', 1]], collectionInfo['a_1']);\n            db.createIndex(collection.collectionName, 'a', configuration.writeConcernMax(), function (err, indexName) {\n              test.equal('a_1', indexName);\n              // Let's fetch the index information\n              db.indexInformation(collection.collectionName, function (err, collectionInfo) {\n                test.ok(collectionInfo['_id_'] != null);\n                test.equal('_id', collectionInfo['_id_'][0][0]);\n                test.ok(collectionInfo['a_1'] != null);\n                test.deepEqual([['a', 1]], collectionInfo['a_1']);\n                // Let's close the db\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateAndUseSparseIndex","suites":["Indexes","promise tests"],"updatePoint":{"line":395,"column":44,"index":13179},"line":395,"code":"  it('shouldCorrectlyCreateAndUseSparseIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.createCollection('create_and_use_sparse_index_test', function (err) {\n        expect(err).to.not.exist;\n        const collection = db.collection('create_and_use_sparse_index_test');\n        collection.createIndex({\n          title: 1\n        }, {\n          sparse: true,\n          writeConcern: {\n            w: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.insert([{\n            name: 'Jim'\n          }, {\n            name: 'Sarah',\n            title: 'Princess'\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.find({\n              title: {\n                $ne: null\n              }\n            }).sort({\n              title: 1\n            }).toArray(function (err, items) {\n              test.equal(1, items.length);\n              test.equal('Sarah', items[0].name);\n\n              // Fetch the info for the indexes\n              collection.indexInformation({\n                full: true\n              }, function (err, indexInfo) {\n                expect(err).to.not.exist;\n                test.equal(2, indexInfo.length);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleGeospatialIndexes","suites":["Indexes","promise tests"],"updatePoint":{"line":450,"column":44,"index":14871},"line":450,"code":"  it('shouldCorrectlyHandleGeospatialIndexes', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.6.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.createCollection('geospatial_index_test', function (err) {\n        expect(err).to.not.exist;\n        const collection = db.collection('geospatial_index_test');\n        collection.createIndex({\n          loc: '2d'\n        }, configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          collection.insert({\n            loc: [-100, 100]\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.insert({\n              loc: [200, 200]\n            }, configuration.writeConcernMax(), function (err) {\n              test.ok(err.errmsg.indexOf('point not in interval of') !== -1);\n              test.ok(err.errmsg.indexOf('-180') !== -1);\n              test.ok(err.errmsg.indexOf('180') !== -1);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleGeospatialIndexesAlteredRange","suites":["Indexes","promise tests"],"updatePoint":{"line":489,"column":56,"index":16348},"line":489,"code":"  it('shouldCorrectlyHandleGeospatialIndexesAlteredRange', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.6.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.createCollection('geospatial_index_altered_test', function (err) {\n        expect(err).to.not.exist;\n        const collection = db.collection('geospatial_index_altered_test');\n        collection.createIndex({\n          loc: '2d'\n        }, {\n          min: 0,\n          max: 1024,\n          writeConcern: {\n            w: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.insert({\n            loc: [100, 100]\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.insert({\n              loc: [200, 200]\n            }, configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist;\n              collection.insert({\n                loc: [-200, -200]\n              }, configuration.writeConcernMax(), function (err) {\n                test.ok(err.errmsg.indexOf('point not in interval of') !== -1);\n                test.ok(err.errmsg.indexOf('0') !== -1);\n                test.ok(err.errmsg.indexOf('1024') !== -1);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldThrowDuplicateKeyErrorWhenCreatingIndex","suites":["Indexes","promise tests"],"updatePoint":{"line":539,"column":51,"index":18108},"line":539,"code":"  it('shouldThrowDuplicateKeyErrorWhenCreatingIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.createCollection('shouldThrowDuplicateKeyErrorWhenCreatingIndex', function (err, collection) {\n        collection.insert([{\n          a: 1\n        }, {\n          a: 1\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          collection.createIndex({\n            a: 1\n          }, {\n            unique: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            test.ok(err != null);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldThrowDuplicateKeyErrorWhenDriverInStrictMode","suites":["Indexes","promise tests"],"updatePoint":{"line":573,"column":56,"index":19102},"line":573,"code":"  it('shouldThrowDuplicateKeyErrorWhenDriverInStrictMode', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.createCollection('shouldThrowDuplicateKeyErrorWhenDriverInStrictMode', function (err, collection) {\n        collection.insert([{\n          a: 1\n        }, {\n          a: 1\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          collection.createIndex({\n            a: 1\n          }, {\n            unique: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            test.ok(err != null);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUseMinMaxForSettingRangeInEnsureIndex","suites":["Indexes","promise tests"],"updatePoint":{"line":607,"column":58,"index":20103},"line":607,"code":"  it('shouldCorrectlyUseMinMaxForSettingRangeInEnsureIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      // Establish connection to db\n      db.createCollection('shouldCorrectlyUseMinMaxForSettingRangeInEnsureIndex', function (err, collection) {\n        expect(err).to.not.exist;\n        collection.createIndex({\n          loc: '2d'\n        }, {\n          min: 200,\n          max: 1400,\n          writeConcern: {\n            w: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.insert({\n            loc: [600, 600]\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"Should correctly create an index with overriden name","suites":["Indexes","promise tests"],"updatePoint":{"line":642,"column":58,"index":21173},"line":642,"code":"  it('Should correctly create an index with overriden name', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      // Establish connection to db\n      db.createCollection('shouldCorrectlyCreateAnIndexWithOverridenName', function (err, collection) {\n        expect(err).to.not.exist;\n        collection.createIndex('name', {\n          name: 'myfunky_name'\n        }, function (err) {\n          expect(err).to.not.exist;\n\n          // Fetch full index information\n          collection.indexInformation({\n            full: false\n          }, function (err, indexInformation) {\n            test.ok(indexInformation['myfunky_name'] != null);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should handle index declarations using objects from other contexts","suites":["Indexes","promise tests"],"updatePoint":{"line":673,"column":72,"index":22219},"line":673,"code":"  it('should handle index declarations using objects from other contexts', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.collection('indexcontext').createIndex(shared.object, {\n        background: true\n      }, function (err) {\n        expect(err).to.not.exist;\n        db.collection('indexcontext').createIndex(shared.array, {\n          background: true\n        }, function (err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly return error message when applying unique index to duplicate documents","suites":["Indexes","promise tests"],"updatePoint":{"line":698,"column":93,"index":23049},"line":698,"code":"  it('should correctly return error message when applying unique index to duplicate documents', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      var collection = db.collection('should_throw_error_due_to_duplicates');\n      collection.insert([{\n        a: 1\n      }, {\n        a: 1\n      }, {\n        a: 1\n      }], configuration.writeConcernMax(), function (err) {\n        expect(err).to.not.exist;\n        collection.createIndex({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          },\n          unique: true\n        }, function (err) {\n          test.ok(err != null);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly drop index with no callback","suites":["Indexes","promise tests"],"updatePoint":{"line":733,"column":50,"index":23989},"line":733,"code":"  it('should correctly drop index with no callback', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      var collection = db.collection('should_correctly_drop_index');\n      collection.insert([{\n        a: 1\n      }], configuration.writeConcernMax(), function (err) {\n        expect(err).to.not.exist;\n        collection.createIndex({\n          a: 1\n        }, configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          collection.dropIndex('a_1').then(() => {\n            client.close(done);\n          }).catch(err => {\n            client.close();\n            done(err);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly apply hint to find","suites":["Indexes","promise tests"],"updatePoint":{"line":764,"column":41,"index":24954},"line":764,"code":"  it('should correctly apply hint to find', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      var collection = db.collection('should_correctly_apply_hint');\n      collection.insert([{\n        a: 1\n      }], configuration.writeConcernMax(), function (err) {\n        expect(err).to.not.exist;\n        collection.createIndex({\n          a: 1\n        }, configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          collection.indexInformation({\n            full: false\n          }, function (err) {\n            expect(err).to.not.exist;\n            collection.find({}, {\n              hint: 'a_1'\n            }).toArray(function (err, docs) {\n              expect(err).to.not.exist;\n              test.equal(1, docs[0].a);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly set language_override option","suites":["Indexes","promise tests"],"updatePoint":{"line":801,"column":51,"index":26135},"line":801,"code":"  it('should correctly set language_override option', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      var collection = db.collection('should_correctly_set_language_override');\n      collection.insert([{\n        text: 'Lorem ipsum dolor sit amet.',\n        langua: 'italian'\n      }], function (err) {\n        expect(err).to.not.exist;\n        collection.createIndex({\n          text: 'text'\n        }, {\n          language_override: 'langua',\n          name: 'language_override_index'\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.indexInformation({\n            full: true\n          }, function (err, indexInformation) {\n            expect(err).to.not.exist;\n            for (var i = 0; i < indexInformation.length; i++) {\n              if (indexInformation[i].name === 'language_override_index') test.equal(indexInformation[i].language_override, 'langua');\n            }\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly use listIndexes to retrieve index list","suites":["Indexes","promise tests"],"updatePoint":{"line":840,"column":61,"index":27485},"line":840,"code":"  it('should correctly use listIndexes to retrieve index list', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.4.0',\n        topology: ['single', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.collection('testListIndexes').createIndex({\n        a: 1\n      }, function (err) {\n        expect(err).to.not.exist;\n\n        // Get the list of indexes\n        db.collection('testListIndexes').listIndexes().toArray(function (err, indexes) {\n          expect(err).to.not.exist;\n          test.equal(2, indexes.length);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly use listIndexes to retrieve index list using hasNext","suites":["Indexes","promise tests"],"updatePoint":{"line":867,"column":75,"index":28321},"line":867,"code":"  it('should correctly use listIndexes to retrieve index list using hasNext', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.4.0',\n        topology: ['single', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.collection('testListIndexes_2').createIndex({\n        a: 1\n      }, function (err) {\n        expect(err).to.not.exist;\n\n        // Get the list of indexes\n        db.collection('testListIndexes_2').listIndexes().hasNext(function (err, result) {\n          expect(err).to.not.exist;\n          test.equal(true, result);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly ensureIndex for nested style index name c.d","suites":["Indexes","promise tests"],"updatePoint":{"line":894,"column":66,"index":29146},"line":894,"code":"  it('should correctly ensureIndex for nested style index name c.d', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.4.0',\n        topology: ['single', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.collection('ensureIndexWithNestedStyleIndex').createIndex({\n        'c.d': 1\n      }, function (err) {\n        expect(err).to.not.exist;\n\n        // Get the list of indexes\n        db.collection('ensureIndexWithNestedStyleIndex').listIndexes().toArray(function (err, indexes) {\n          expect(err).to.not.exist;\n          test.equal(2, indexes.length);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute createIndexes with multiple indexes","suites":["Indexes","promise tests"],"updatePoint":{"line":921,"column":66,"index":30009},"line":921,"code":"  it('should correctly execute createIndexes with multiple indexes', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.collection('createIndexes').createIndexes([{\n        key: {\n          a: 1\n        }\n      }, {\n        key: {\n          b: 1\n        },\n        name: 'hello1'\n      }], function (err, r) {\n        expect(err).to.not.exist;\n        expect(r).to.deep.equal(['a_1', 'hello1']);\n        db.collection('createIndexes').listIndexes().toArray(function (err, docs) {\n          expect(err).to.not.exist;\n          var keys = {};\n          for (var i = 0; i < docs.length; i++) {\n            keys[docs[i].name] = true;\n          }\n          test.ok(keys['a_1']);\n          test.ok(keys['hello1']);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute createIndexes with one index","suites":["Indexes","promise tests"],"updatePoint":{"line":959,"column":59,"index":31070},"line":959,"code":"  it('should correctly execute createIndexes with one index', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.collection('createIndexes').createIndexes([{\n        key: {\n          a: 1\n        }\n      }], function (err, r) {\n        expect(err).to.not.exist;\n        expect(r).to.deep.equal(['a_1']);\n        db.collection('createIndexes').listIndexes().toArray(function (err, docs) {\n          expect(err).to.not.exist;\n          var keys = {};\n          for (var i = 0; i < docs.length; i++) {\n            keys[docs[i].name] = true;\n          }\n          test.ok(keys['a_1']);\n          test.ok(keys['hello1']);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateTextIndex","suites":["Indexes","promise tests"],"updatePoint":{"line":992,"column":36,"index":32023},"line":992,"code":"  it('shouldCorrectlyCreateTextIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.collection('text_index').createIndex({\n        '$**': 'text'\n      }, {\n        name: 'TextIndex'\n      }, function (err, r) {\n        expect(err).to.not.exist;\n        test.equal('TextIndex', r);\n        // Let's close the db\n        client.close(done);\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly pass partialIndexes through to createIndexCommand","suites":["Indexes","promise tests"],"updatePoint":{"line":1016,"column":72,"index":32747},"line":1016,"code":"  it('should correctly pass partialIndexes through to createIndexCommand', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger'],\n        mongodb: '>=3.1.8'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var started = [];\n      var succeeded = [];\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      client.on('commandStarted', function (event) {\n        if (event.commandName === 'createIndexes') started.push(event);\n      });\n      client.on('commandSucceeded', function (event) {\n        if (event.commandName === 'createIndexes') succeeded.push(event);\n      });\n      var db = client.db(configuration.db);\n      db.collection('partialIndexes').createIndex({\n        a: 1\n      }, {\n        partialFilterExpression: {\n          a: 1\n        }\n      }, function (err) {\n        expect(err).to.not.exist;\n        test.deepEqual({\n          a: 1\n        }, started[0].command.indexes[0].partialFilterExpression);\n        client.close(done);\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should not retry partial index expression error","suites":["Indexes","promise tests"],"updatePoint":{"line":1053,"column":53,"index":33902},"line":1053,"code":"  it('should not retry partial index expression error', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded'],\n        mongodb: '>=3.1.8'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      // Can't use $exists: false in partial filter expression, see\n      // https://jira.mongodb.org/browse/SERVER-17853\n      var opts = {\n        partialFilterExpression: {\n          a: {\n            $exists: false\n          }\n        }\n      };\n      db.collection('partialIndexes').createIndex({\n        a: 1\n      }, opts, function (err) {\n        test.ok(err);\n        test.equal(err.code, 67);\n        var msg = \"key $exists must not start with '$'\";\n        test.ok(err.toString().indexOf(msg) === -1);\n        client.close(done);\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly create index on embedded key","suites":["Indexes","promise tests"],"updatePoint":{"line":1086,"column":51,"index":34880},"line":1086,"code":"  it('should correctly create index on embedded key', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      var collection = db.collection('embedded_key_indes');\n      collection.insertMany([{\n        a: {\n          a: 1\n        }\n      }, {\n        a: {\n          a: 2\n        }\n      }], function (err) {\n        expect(err).to.not.exist;\n        collection.createIndex({\n          'a.a': 1\n        }, function (err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly create index using . keys","suites":["Indexes","promise tests"],"updatePoint":{"line":1118,"column":48,"index":35713},"line":1118,"code":"  it('should correctly create index using . keys', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      var collection = db.collection('embedded_key_indes_1');\n      collection.createIndex({\n        'key.external_id': 1,\n        'key.type': 1\n      }, {\n        unique: true,\n        sparse: true,\n        name: 'indexname'\n      }, function (err) {\n        expect(err).to.not.exist;\n        client.close(done);\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"error on duplicate key index","suites":["Indexes","promise tests"],"updatePoint":{"line":1144,"column":34,"index":36449},"line":1144,"code":"  it('error on duplicate key index', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      var collection = db.collection('embedded_key_indes_2');\n      collection.insertMany([{\n        key: {\n          external_id: 1,\n          type: 1\n        }\n      }, {\n        key: {\n          external_id: 1,\n          type: 1\n        }\n      }], function (err) {\n        expect(err).to.not.exist;\n        collection.createIndex({\n          'key.external_id': 1,\n          'key.type': 1\n        }, {\n          unique: true,\n          sparse: true,\n          name: 'indexname'\n        }, function (err) {\n          test.equal(11000, err.code);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly create Index with sub element","suites":["Indexes","promise tests"],"updatePoint":{"line":1183,"column":52,"index":37479},"line":1183,"code":"  it('should correctly create Index with sub element', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      // insert a doc\n      db.collection('messed_up_index').createIndex({\n        temporary: 1,\n        'store.addressLines': 1,\n        lifecycleStatus: 1\n      }, configuration.writeConcernMax(), function (err) {\n        expect(err).to.not.exist;\n        client.close(done);\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly fail detect error code 85 when performing createIndex","suites":["Indexes","promise tests"],"updatePoint":{"line":1206,"column":76,"index":38221},"line":1206,"code":"  it('should correctly fail detect error code 85 when performing createIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger'],\n        mongodb: '>=3.0.0 <=4.8.0'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      var collection = db.collection('messed_up_options');\n      collection.createIndex({\n        'a.one': 1,\n        'a.two': 1\n      }, {\n        name: 'n1',\n        sparse: false\n      }, function (err) {\n        expect(err).to.not.exist;\n        collection.createIndex({\n          'a.one': 1,\n          'a.two': 1\n        }, {\n          name: 'n2',\n          sparse: true\n        }, function (err) {\n          test.ok(err);\n          test.equal(85, err.code);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly fail by detecting error code 86 when performing createIndex","suites":["Indexes","promise tests"],"updatePoint":{"line":1242,"column":82,"index":39233},"line":1242,"code":"  it('should correctly fail by detecting error code 86 when performing createIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger'],\n        mongodb: '>=3.0.0'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      var collection = db.collection('messed_up_options');\n      collection.createIndex({\n        'b.one': 1,\n        'b.two': 1\n      }, {\n        name: 'test'\n      }, function (err) {\n        expect(err).to.not.exist;\n        collection.createIndex({\n          'b.one': -1,\n          'b.two': -1\n        }, {\n          name: 'test'\n        }, function (err) {\n          test.ok(err);\n          test.equal(86, err.code);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly create Index with sub element running in background","suites":["Indexes","promise tests"],"updatePoint":{"line":1276,"column":74,"index":40188},"line":1276,"code":"  it('should correctly create Index with sub element running in background', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      // insert a doc\n      db.collection('messed_up_index_2').createIndex({\n        'accessControl.get': 1\n      }, {\n        background: true\n      }, function (err) {\n        expect(err).to.not.exist;\n        client.close(done);\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if commitQuorum specified on db.createIndex","suites":["Indexes","commitQuorum"],"updatePoint":{"line":1328,"column":73,"index":41728},"line":1328,"code":"    it('should throw an error if commitQuorum specified on db.createIndex', throwErrorTest((db, collection, cb) => db.createIndex(collection.collectionName, 'a', {\n      commitQuorum: 'all'\n    }, cb)));","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if commitQuorum specified on collection.createIndex","suites":["Indexes","commitQuorum"],"updatePoint":{"line":1331,"column":81,"index":41940},"line":1331,"code":"    it('should throw an error if commitQuorum specified on collection.createIndex', throwErrorTest((db, collection, cb) => collection.createIndex('a', {\n      commitQuorum: 'all'\n    }, cb)));","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if commitQuorum specified on collection.createIndexes","suites":["Indexes","commitQuorum"],"updatePoint":{"line":1334,"column":83,"index":42135},"line":1334,"code":"    it('should throw an error if commitQuorum specified on collection.createIndexes', throwErrorTest((db, collection, cb) => collection.createIndexes([{\n      key: {\n        a: 1\n      }\n    }, {\n      key: {\n        b: 1\n      }\n    }], {\n      commitQuorum: 'all'\n    }, cb)));","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should run command with commitQuorum if specified on db.createIndex","suites":["Indexes","commitQuorum"],"updatePoint":{"line":1377,"column":75,"index":43444},"line":1377,"code":"    it('should run command with commitQuorum if specified on db.createIndex', commitQuorumTest((db, collection, cb) => db.createIndex(collection.collectionName, 'a', {\n      writeConcern: {\n        w: 'majority'\n      },\n      commitQuorum: 0\n    }, cb)));","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should run command with commitQuorum if specified on collection.createIndex","suites":["Indexes","commitQuorum"],"updatePoint":{"line":1383,"column":83,"index":43709},"line":1383,"code":"    it('should run command with commitQuorum if specified on collection.createIndex', commitQuorumTest((db, collection, cb) => collection.createIndex('a', {\n      writeConcern: {\n        w: 'majority'\n      },\n      commitQuorum: 0\n    }, cb)));","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should run command with commitQuorum if specified on collection.createIndexes","suites":["Indexes","commitQuorum"],"updatePoint":{"line":1389,"column":85,"index":43957},"line":1389,"code":"    it('should run command with commitQuorum if specified on collection.createIndexes', commitQuorumTest((db, collection, cb) => collection.createIndexes([{\n      key: {\n        a: 1\n      }\n    }], {\n      writeConcern: {\n        w: 'majority'\n      },\n      commitQuorum: 0\n    }, cb)));","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should create index hidden","suites":["Indexes","commitQuorum"],"updatePoint":{"line":1400,"column":32,"index":44200},"line":1400,"code":"  it('should create index hidden', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.4',\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      const db = client.db(configuration.db);\n      db.createCollection('hidden_index_collection', (err, collection) => {\n        expect(err).to.not.exist;\n        collection.createIndex('a', {\n          hidden: true\n        }, (err, index) => {\n          expect(err).to.not.exist;\n          expect(index).to.equal('a_1');\n          collection.listIndexes().toArray((err, indexes) => {\n            expect(err).to.not.exist;\n            expect(indexes).to.deep.equal([{\n              v: 2,\n              key: {\n                _id: 1\n              },\n              name: '_id_'\n            }, {\n              v: 2,\n              key: {\n                a: 1\n              },\n              name: 'a_1',\n              hidden: true\n            }]);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly set maxStalenessSeconds on Mongos query on connect","suites":["Max Staleness"],"updatePoint":{"line":54,"column":73,"index":1386},"line":54,"code":"  it('should correctly set maxStalenessSeconds on Mongos query on connect', {\n    metadata: {\n      requires: {\n        generators: true,\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      const configuration = this.configuration;\n      const client = configuration.newClient(`mongodb://${test.server.uri()}/test?readPreference=secondary&maxStalenessSeconds=250`);\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(self.configuration.db);\n        db.collection('test').find({}).toArray(function (err) {\n          expect(err).to.not.exist;\n          expect(test.checkCommand).to.containSubset({\n            $query: {\n              find: 'test',\n              filter: {}\n            },\n            $readPreference: {\n              mode: 'secondary',\n              maxStalenessSeconds: 250\n            }\n          });\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/max-staleness/max_staleness.test.js","skipped":false,"dir":"test"},{"name":"should correctly set maxStalenessSeconds on Mongos query using db level readPreference","suites":["Max Staleness"],"updatePoint":{"line":85,"column":92,"index":2389},"line":85,"code":"  it('should correctly set maxStalenessSeconds on Mongos query using db level readPreference', {\n    metadata: {\n      requires: {\n        generators: true,\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(`mongodb://${test.server.uri()}/test`);\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n\n        // Get a db with a new readPreference\n        var db1 = client.db('test', {\n          readPreference: new ReadPreference('secondary', null, {\n            maxStalenessSeconds: 250\n          })\n        });\n        db1.collection('test').find({}).toArray(function (err) {\n          expect(err).to.not.exist;\n          expect(test.checkCommand).to.containSubset({\n            $query: {\n              find: 'test',\n              filter: {}\n            },\n            $readPreference: {\n              mode: 'secondary',\n              maxStalenessSeconds: 250\n            }\n          });\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/max-staleness/max_staleness.test.js","skipped":false,"dir":"test"},{"name":"should correctly set maxStalenessSeconds on Mongos query using collection level readPreference","suites":["Max Staleness"],"updatePoint":{"line":121,"column":100,"index":3491},"line":121,"code":"  it('should correctly set maxStalenessSeconds on Mongos query using collection level readPreference', {\n    metadata: {\n      requires: {\n        generators: true,\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      const configuration = this.configuration;\n      const client = configuration.newClient(`mongodb://${test.server.uri()}/test`);\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(self.configuration.db);\n\n        // Get a db with a new readPreference\n        db.collection('test', {\n          readPreference: new ReadPreference('secondary', null, {\n            maxStalenessSeconds: 250\n          })\n        }).find({}).toArray(function (err) {\n          expect(err).to.not.exist;\n          expect(test.checkCommand).to.containSubset({\n            $query: {\n              find: 'test',\n              filter: {}\n            },\n            $readPreference: {\n              mode: 'secondary',\n              maxStalenessSeconds: 250\n            }\n          });\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/max-staleness/max_staleness.test.js","skipped":false,"dir":"test"},{"name":"should correctly set maxStalenessSeconds on Mongos query using cursor level readPreference","suites":["Max Staleness"],"updatePoint":{"line":158,"column":96,"index":4625},"line":158,"code":"  it('should correctly set maxStalenessSeconds on Mongos query using cursor level readPreference', {\n    metadata: {\n      requires: {\n        generators: true,\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      const configuration = this.configuration;\n      const client = configuration.newClient(`mongodb://${test.server.uri()}/test`);\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(self.configuration.db);\n        var readPreference = new ReadPreference('secondary', null, {\n          maxStalenessSeconds: 250\n        });\n\n        // Get a db with a new readPreference\n        db.collection('test').find({}).withReadPreference(readPreference).toArray(function (err) {\n          expect(err).to.not.exist;\n          expect(test.checkCommand).to.containSubset({\n            $query: {\n              find: 'test',\n              filter: {}\n            },\n            $readPreference: {\n              mode: 'secondary',\n              maxStalenessSeconds: 250\n            }\n          });\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/max-staleness/max_staleness.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute legacy hello command using Promise","suites":["Handshake"],"updatePoint":{"line":17,"column":65,"index":447},"line":17,"code":"  it('Should correctly execute legacy hello command using Promise', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var url = configuration.url();\n      url = url.indexOf('?') !== -1 ? f('%s&%s', url, 'maxPoolSize=5') : f('%s?%s', url, 'maxPoolSize=5');\n      const client = configuration.newClient(url);\n      client.connect().then(function (client) {\n        // Execute legacy hello command\n        client.db(configuration.db).command({\n          [LEGACY_HELLO_COMMAND]: true\n        }).then(function (result) {\n          test.ok(result !== null);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/mongodb-handshake/promise_handshake.test.js","skipped":false,"dir":"test"},{"name":"supports mapping to falsey value ''","suites":["class AbstractCursor","toArray() with custom transforms"],"updatePoint":{"line":23,"column":62,"index":803},"line":23,"code":"      it(`supports mapping to falsey value '${inspect(value)}'`, async function () {\n        const cursor = collection.find();\n        cursor.map(() => value);\n        const result = await cursor.toArray();\n        const expected = Array.from({\n          length: 5\n        }, () => value);\n        expect(result).to.deep.equal(expected);\n      });","file":"integration/node-specific/abstract_cursor.test.ts","skipped":false,"dir":"test"},{"name":"throws when mapping to `null` and cleans up cursor","suites":["class AbstractCursor","toArray() with custom transforms"],"updatePoint":{"line":33,"column":58,"index":1153},"line":33,"code":"    it('throws when mapping to `null` and cleans up cursor', async function () {\n      const cursor = collection.find();\n      cursor.map(() => null);\n      const error = await cursor.toArray().catch(e => e);\n      expect(error).be.instanceOf(MongoAPIError);\n      expect(cursor.closed).to.be.true;\n    });","file":"integration/node-specific/abstract_cursor.test.ts","skipped":false,"dir":"test"},{"name":"supports mapping to falsey value ''","suites":["class AbstractCursor","Symbol.asyncIterator() with custom transforms"],"updatePoint":{"line":43,"column":62,"index":1583},"line":43,"code":"      it(`supports mapping to falsey value '${inspect(value)}'`, async function () {\n        const cursor = collection.find();\n        cursor.map(() => value);\n        let count = 0;\n        for await (const document of cursor) {\n          expect(document).to.deep.equal(value);\n          count++;\n        }\n        expect(count).to.equal(5);\n      });","file":"integration/node-specific/abstract_cursor.test.ts","skipped":false,"dir":"test"},{"name":"throws when mapping to `null` and cleans up cursor","suites":["class AbstractCursor","Symbol.asyncIterator() with custom transforms"],"updatePoint":{"line":54,"column":58,"index":1938},"line":54,"code":"    it('throws when mapping to `null` and cleans up cursor', async function () {\n      const cursor = collection.find();\n      cursor.map(() => null);\n      try {\n        // eslint-disable-next-line @typescript-eslint/no-unused-vars\n        for await (const document of cursor) {\n          expect.fail('Expected error to be thrown');\n        }\n      } catch (error) {\n        expect(error).to.be.instanceOf(MongoAPIError);\n        expect(cursor.closed).to.be.true;\n      }\n    });","file":"integration/node-specific/abstract_cursor.test.ts","skipped":false,"dir":"test"},{"name":"supports mapping to falsey value ''","suites":["class AbstractCursor","forEach() with custom transforms"],"updatePoint":{"line":70,"column":62,"index":2529},"line":70,"code":"      it(`supports mapping to falsey value '${inspect(value)}'`, async function () {\n        const cursor = collection.find();\n        cursor.map(() => value);\n        let count = 0;\n        function transform(value) {\n          expect(value).to.deep.equal(value);\n          count++;\n        }\n        await cursor.forEach(transform);\n        expect(count).to.equal(5);\n      });","file":"integration/node-specific/abstract_cursor.test.ts","skipped":false,"dir":"test"},{"name":"throws when mapping to `null` and cleans up cursor","suites":["class AbstractCursor","forEach() with custom transforms"],"updatePoint":{"line":82,"column":58,"index":2911},"line":82,"code":"    it('throws when mapping to `null` and cleans up cursor', async function () {\n      const cursor = collection.find();\n      cursor.map(() => null);\n      function iterator() {\n        expect.fail('Expected no documents from cursor, received at least one.');\n      }\n      const error = await cursor.forEach(iterator).catch(e => e);\n      expect(error).to.be.instanceOf(MongoAPIError);\n      expect(cursor.closed).to.be.true;\n    });","file":"integration/node-specific/abstract_cursor.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Admin","#addUser()"],"updatePoint":{"line":21,"column":35,"index":900},"line":21,"code":"      it('should connect the client', async () => {\n        const admin = client.db().admin();\n        await admin.addUser('neal', 'iLoveJavaScript', {\n          roles: ['root']\n        }).catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Admin","#buildInfo()"],"updatePoint":{"line":30,"column":35,"index":1245},"line":30,"code":"      it('should connect the client', async () => {\n        const admin = client.db().admin();\n        await admin.buildInfo();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Admin","#command()"],"updatePoint":{"line":37,"column":35,"index":1508},"line":37,"code":"      it('should connect the client', async () => {\n        const admin = client.db().admin();\n        await admin.command({\n          ping: 1\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Admin","#listDatabases()"],"updatePoint":{"line":46,"column":35,"index":1804},"line":46,"code":"      it('should connect the client', async () => {\n        const admin = client.db().admin();\n        await admin.listDatabases();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Admin","#ping()"],"updatePoint":{"line":53,"column":35,"index":2068},"line":53,"code":"      it('should connect the client', async () => {\n        const admin = client.db().admin();\n        await admin.ping();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Admin","#removeUser()"],"updatePoint":{"line":60,"column":35,"index":2329},"line":60,"code":"      it('should connect the client', async () => {\n        const admin = client.db().admin();\n        await admin.removeUser('neal').catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Admin","#replSetGetStatus()"],"updatePoint":{"line":67,"column":35,"index":2626},"line":67,"code":"      it('should connect the client', {\n        requires: {\n          topology: 'replicaset'\n        }\n      }, async () => {\n        const admin = client.db().admin();\n        await admin.replSetGetStatus();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Admin","#serverInfo()"],"updatePoint":{"line":78,"column":35,"index":2973},"line":78,"code":"      it('should connect the client', async () => {\n        const admin = client.db().admin();\n        await admin.serverInfo();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Admin","#serverStatus()"],"updatePoint":{"line":85,"column":35,"index":3242},"line":85,"code":"      it('should connect the client', async () => {\n        const admin = client.db().admin();\n        await admin.serverStatus();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Admin","#validateCollection()"],"updatePoint":{"line":92,"column":35,"index":3519},"line":92,"code":"      it('should connect the client', async () => {\n        const admin = client.db().admin();\n        await admin.validateCollection('test').catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class AggregationCursor","#explain()"],"updatePoint":{"line":108,"column":35,"index":3983},"line":108,"code":"      it('should connect the client', async () => {\n        const agg = client.db().collection('test').aggregate(pipeline);\n        await agg.explain().catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class AggregationCursor","#close()"],"updatePoint":{"line":115,"column":35,"index":4287},"line":115,"code":"      it('should connect the client', async () => {\n        const agg = client.db().collection('test').aggregate(pipeline);\n        await agg.close().catch(error => {\n          expect.fail('cursor.close should work without connecting: ' + error.message);\n        });\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class AggregationCursor","#forEach()"],"updatePoint":{"line":123,"column":35,"index":4607},"line":123,"code":"      it('should connect the client', async () => {\n        const agg = client.db().collection('test').aggregate(pipeline);\n        await agg.forEach(item => {\n          expect(item).to.be.a('object');\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class AggregationCursor","#hasNext()"],"updatePoint":{"line":132,"column":35,"index":4956},"line":132,"code":"      it('should connect the client', async () => {\n        const agg = client.db().collection('test').aggregate(pipeline);\n        await agg.hasNext();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class AggregationCursor","#next()"],"updatePoint":{"line":139,"column":35,"index":5241},"line":139,"code":"      it('should connect the client', async () => {\n        const agg = client.db().collection('test').aggregate(pipeline);\n        await agg.next();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class AggregationCursor","#toArray()"],"updatePoint":{"line":146,"column":35,"index":5526},"line":146,"code":"      it('should connect the client', async () => {\n        const agg = client.db().collection('test').aggregate(pipeline);\n        await agg.toArray();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class AggregationCursor","#tryNext()"],"updatePoint":{"line":153,"column":35,"index":5814},"line":153,"code":"      it('should connect the client', async () => {\n        const agg = client.db().collection('test').aggregate(pipeline);\n        await agg.tryNext();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class AggregationCursor","#stream()"],"updatePoint":{"line":160,"column":35,"index":6101},"line":160,"code":"      it('should connect the client', async () => {\n        const agg = client.db().collection('test').aggregate(pipeline);\n        const stream = agg.stream();\n        await once(stream, 'readable');\n        await stream.read();\n        stream.destroy();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should not connect the client","suites":["When executing an operation for the first time","class OrderedBulkOperation","#execute()"],"updatePoint":{"line":172,"column":39,"index":6551},"line":172,"code":"      it('should not connect the client', async () => {\n        expect(() => client.db().collection('test').initializeOrderedBulkOp()).to.throw(MongoNotConnectedError);\n        expect(client).to.not.have.property('topology');\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should not connect the client","suites":["When executing an operation for the first time","class UnorderedBulkOperation","#execute()"],"updatePoint":{"line":180,"column":39,"index":6887},"line":180,"code":"      it('should not connect the client', async () => {\n        expect(() => client.db().collection('test').initializeUnorderedBulkOp()).to.throw(MongoNotConnectedError);\n        expect(client).to.not.have.property('topology');\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ChangeStream","#close()"],"updatePoint":{"line":210,"column":35,"index":7998},"line":210,"code":"      it('should connect the client', async () => {\n        await cs.close().catch(error => {\n          expect.fail('cs.close should work without connecting: ' + error.message);\n        });\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ChangeStream","#hasNext()"],"updatePoint":{"line":221,"column":35,"index":8304},"line":221,"code":"      it('should connect the client', async () => {\n        const willHaveNext = cs.hasNext();\n        await once(cs.cursor, 'init');\n        await changeCausingCollection.insertOne({\n          a: 1\n        });\n        await willHaveNext;\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ChangeStream","#next()"],"updatePoint":{"line":236,"column":35,"index":8738},"line":236,"code":"      it('should connect the client', async () => {\n        const willBeNext = cs.next();\n        await once(cs.cursor, 'init');\n        await changeCausingCollection.insertOne({\n          a: 1\n        });\n        await willBeNext;\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ChangeStream","#tryNext()"],"updatePoint":{"line":251,"column":35,"index":9168},"line":251,"code":"      it('should connect the client', async () => {\n        await cs.tryNext();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ChangeStream","#stream()"],"updatePoint":{"line":261,"column":35,"index":9445},"line":261,"code":"      it('should connect the client', async () => {\n        const stream = cs.stream();\n        const willBeNext = stream[Symbol.asyncIterator]().next();\n        await once(cs.cursor, 'init');\n        await changeCausingCollection.insertOne({\n          a: 1\n        });\n        await willBeNext;\n        stream.destroy();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ClientSession","#abortTransaction()"],"updatePoint":{"line":276,"column":35,"index":9959},"line":276,"code":"      it('should connect the client', async () => {\n        const session = client.startSession();\n        session.startTransaction();\n        await session.abortTransaction(); // Abort transaction will not connect (as expected)\n        expect(client).to.not.have.property('topology');\n        await session.endSession();\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ClientSession","#commitTransaction()"],"updatePoint":{"line":285,"column":35,"index":10344},"line":285,"code":"      it('should connect the client', async () => {\n        const session = client.startSession();\n        session.startTransaction();\n        await session.commitTransaction(); // Commit transaction will not connect (as expected)\n        expect(client).to.not.have.property('topology');\n        await session.endSession();\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ClientSession","#endSession()"],"updatePoint":{"line":294,"column":35,"index":10724},"line":294,"code":"      it('should connect the client', async () => {\n        const session = client.startSession();\n        await session.endSession();\n        expect(client).to.not.have.property('topology');\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ClientSession","#withTransaction()"],"updatePoint":{"line":301,"column":35,"index":10977},"line":301,"code":"      it('should connect the client', async () => {\n        const session = client.startSession();\n        await session.withTransaction(async () => {\n          // withTransaction will not connect (as expected)\n        });\n        await session.endSession();\n        expect(client).to.not.have.property('topology');\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#bulkWrite()"],"updatePoint":{"line":313,"column":35,"index":11393},"line":313,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.bulkWrite([{\n          insertOne: {\n            document: {\n              a: 1\n            }\n          }\n        }]);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#count()"],"updatePoint":{"line":326,"column":35,"index":11762},"line":326,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.count();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#countDocuments()"],"updatePoint":{"line":333,"column":35,"index":12031},"line":333,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.countDocuments();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#createIndex()"],"updatePoint":{"line":340,"column":35,"index":12306},"line":340,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.createIndex({\n          a: 1\n        }).catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#createIndexes()"],"updatePoint":{"line":349,"column":35,"index":12624},"line":349,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.createIndexes([{\n          key: {\n            a: 1\n          }\n        }]).catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#deleteMany()"],"updatePoint":{"line":360,"column":35,"index":12974},"line":360,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.deleteMany({\n          a: 1\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#deleteOne()"],"updatePoint":{"line":369,"column":35,"index":13269},"line":369,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.deleteOne({\n          a: 1\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#distinct()"],"updatePoint":{"line":378,"column":35,"index":13562},"line":378,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.distinct('a');\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#drop()"],"updatePoint":{"line":385,"column":35,"index":13827},"line":385,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.drop();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#dropIndex()"],"updatePoint":{"line":392,"column":35,"index":14090},"line":392,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.dropIndex('a_1').catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#dropIndexes()"],"updatePoint":{"line":399,"column":35,"index":14383},"line":399,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.dropIndexes().catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#estimatedDocumentCount()"],"updatePoint":{"line":406,"column":35,"index":14684},"line":406,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.estimatedDocumentCount();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#findOne()"],"updatePoint":{"line":413,"column":35,"index":14963},"line":413,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.findOne();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#findOneAndDelete()"],"updatePoint":{"line":420,"column":35,"index":15236},"line":420,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.findOneAndDelete({\n          a: 1\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#findOneAndReplace()"],"updatePoint":{"line":429,"column":35,"index":15545},"line":429,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.findOneAndReplace({\n          a: 1\n        }, {\n          a: 2\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#findOneAndUpdate()"],"updatePoint":{"line":440,"column":35,"index":15882},"line":440,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.findOneAndUpdate({\n          a: 1\n        }, {\n          $set: {\n            a: 2\n          }\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#indexes()"],"updatePoint":{"line":453,"column":35,"index":16241},"line":453,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.indexes().catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#indexExists()"],"updatePoint":{"line":460,"column":35,"index":16527},"line":460,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.indexExists('a_1').catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#indexInformation()"],"updatePoint":{"line":467,"column":35,"index":16827},"line":467,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.indexInformation().catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#insert()"],"updatePoint":{"line":474,"column":35,"index":17117},"line":474,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        // @ts-expect-error: deprecated API\n        await c.insert({\n          a: 1\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#insertMany()"],"updatePoint":{"line":484,"column":35,"index":17453},"line":484,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.insertMany([{\n          a: 1\n        }]);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#insertOne()"],"updatePoint":{"line":493,"column":35,"index":17750},"line":493,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.insertOne({\n          a: 1\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#isCapped()"],"updatePoint":{"line":502,"column":35,"index":18043},"line":502,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.isCapped();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#mapReduce()"],"updatePoint":{"line":509,"column":35,"index":18310},"line":509,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.mapReduce(function () {\n          // @ts-expect-error: mapReduce is deprecated\n          emit(this.a, [0]);\n        }, function (a, b) {\n          // @ts-expect-error: mapReduce is deprecated\n          return Array.sum(b);\n        }, {\n          out: 'inline'\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#options()"],"updatePoint":{"line":524,"column":35,"index":18835},"line":524,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.options();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#remove()"],"updatePoint":{"line":531,"column":35,"index":19098},"line":531,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        // @ts-expect-error: deprecated API\n        await c.remove({\n          a: 1\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#rename()"],"updatePoint":{"line":541,"column":35,"index":19430},"line":541,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test0');\n        await c.rename('test1').catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#replaceOne()"],"updatePoint":{"line":548,"column":35,"index":19722},"line":548,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.replaceOne({\n          a: 1\n        }, {\n          a: 2\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#stats()"],"updatePoint":{"line":559,"column":35,"index":20041},"line":559,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.stats();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#update()"],"updatePoint":{"line":566,"column":35,"index":20302},"line":566,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        // @ts-expect-error: deprecated API\n        await c.update({\n          a: 1\n        }, {\n          $set: {\n            a: 2\n          }\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#updateMany()"],"updatePoint":{"line":580,"column":35,"index":20698},"line":580,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.updateMany({\n          a: 1\n        }, {\n          $set: {\n            a: 2\n          }\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#updateOne()"],"updatePoint":{"line":593,"column":35,"index":21053},"line":593,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.updateOne({\n          a: 1\n        }, {\n          $set: {\n            a: 2\n          }\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#addUser()"],"updatePoint":{"line":608,"column":35,"index":21442},"line":608,"code":"      it('should connect the client', async () => {\n        const db = client.db();\n        await db.addUser('neal', 'iLoveJavaScript', {\n          roles: ['dbAdmin']\n        }).catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#collections()"],"updatePoint":{"line":617,"column":35,"index":21778},"line":617,"code":"      it('should connect the client', async () => {\n        const db = client.db();\n        await db.collections();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#command()"],"updatePoint":{"line":624,"column":35,"index":22029},"line":624,"code":"      it('should connect the client', async () => {\n        const db = client.db();\n        await db.command({\n          ping: 1\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#createCollection()"],"updatePoint":{"line":633,"column":35,"index":22314},"line":633,"code":"      it('should connect the client', async () => {\n        const db = client.db();\n        await db.createCollection('test4');\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#createIndex()"],"updatePoint":{"line":640,"column":35,"index":22581},"line":640,"code":"      it('should connect the client', async () => {\n        const db = client.db();\n        await db.createIndex('test', {\n          a: 1\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#dropCollection()"],"updatePoint":{"line":649,"column":35,"index":22873},"line":649,"code":"      it('should connect the client', async () => {\n        const db = client.db();\n        await db.dropCollection('test');\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#dropDatabase()"],"updatePoint":{"line":656,"column":35,"index":23138},"line":656,"code":"      it('should connect the client', async () => {\n        const db = client.db();\n        await db.dropDatabase();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#indexInformation()"],"updatePoint":{"line":663,"column":35,"index":23399},"line":663,"code":"      it('should connect the client', async () => {\n        const db = client.db();\n        await db.indexInformation('test').catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#profilingLevel()"],"updatePoint":{"line":670,"column":35,"index":23686},"line":670,"code":"      it('should connect the client', async () => {\n        const db = client.db('admin');\n        await db.profilingLevel().catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#removeUser()"],"updatePoint":{"line":677,"column":35,"index":23968},"line":677,"code":"      it('should connect the client', async () => {\n        const db = client.db();\n        await db.removeUser('neal').catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#renameCollection()"],"updatePoint":{"line":684,"column":35,"index":24251},"line":684,"code":"      it('should connect the client', async () => {\n        const db = client.db();\n        await db.renameCollection('test0', 'test1').catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#setProfilingLevel()"],"updatePoint":{"line":691,"column":35,"index":24551},"line":691,"code":"      it('should connect the client', async () => {\n        const db = client.db('admin');\n        await db.setProfilingLevel(ProfilingLevel.off).catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#stats()"],"updatePoint":{"line":698,"column":35,"index":24849},"line":698,"code":"      it('should connect the client', async () => {\n        const db = client.db();\n        await db.stats();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class FindCursor","#count()"],"updatePoint":{"line":707,"column":35,"index":25137},"line":707,"code":"      it('should connect the client', async () => {\n        const find = client.db().collection('test').find();\n        await find.count();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class FindCursor","#explain()"],"updatePoint":{"line":714,"column":35,"index":25412},"line":714,"code":"      it('should connect the client', async () => {\n        const find = client.db().collection('test').find();\n        await find.explain().catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class FindCursor","#close()"],"updatePoint":{"line":721,"column":35,"index":25705},"line":721,"code":"      it('should connect the client', async () => {\n        const find = client.db().collection('test').find();\n        await find.close();\n        expect(client).to.not.have.property('topology');\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class FindCursor","#forEach()"],"updatePoint":{"line":728,"column":35,"index":25955},"line":728,"code":"      it('should connect the client', async () => {\n        const find = client.db().collection('test').find();\n        await find.forEach(item => {\n          expect(item).to.be.a('object');\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class FindCursor","#hasNext()"],"updatePoint":{"line":737,"column":35,"index":26293},"line":737,"code":"      it('should connect the client', async () => {\n        const find = client.db().collection('test').find();\n        await find.hasNext();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class FindCursor","#next()"],"updatePoint":{"line":744,"column":35,"index":26567},"line":744,"code":"      it('should connect the client', async () => {\n        const find = client.db().collection('test').find();\n        await find.next();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class FindCursor","#toArray()"],"updatePoint":{"line":751,"column":35,"index":26841},"line":751,"code":"      it('should connect the client', async () => {\n        const find = client.db().collection('test').find();\n        await find.toArray();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class FindCursor","#tryNext()"],"updatePoint":{"line":758,"column":35,"index":27118},"line":758,"code":"      it('should connect the client', async () => {\n        const find = client.db().collection('test').find();\n        await find.tryNext();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class FindCursor","#stream()"],"updatePoint":{"line":765,"column":35,"index":27394},"line":765,"code":"      it('should connect the client', async () => {\n        const find = client.db().collection('test').find();\n        const stream = find.stream();\n        await once(stream, 'readable');\n        await stream.read();\n        stream.destroy();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ListCollectionsCursor","#forEach()"],"updatePoint":{"line":780,"column":35,"index":27902},"line":780,"code":"      it('should connect the client', async () => {\n        const collections = client.db().listCollections();\n        await collections.forEach(item => {\n          expect(item).is.an('object');\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ListCollectionsCursor","#hasNext()"],"updatePoint":{"line":789,"column":35,"index":28244},"line":789,"code":"      it('should connect the client', async () => {\n        const collections = client.db().listCollections();\n        await collections.hasNext();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ListCollectionsCursor","#next()"],"updatePoint":{"line":796,"column":35,"index":28524},"line":796,"code":"      it('should connect the client', async () => {\n        const collections = client.db().listCollections();\n        await collections.next();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ListCollectionsCursor","#toArray()"],"updatePoint":{"line":803,"column":35,"index":28804},"line":803,"code":"      it('should connect the client', async () => {\n        const collections = client.db().listCollections();\n        await collections.toArray();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ListCollectionsCursor","#tryNext()"],"updatePoint":{"line":810,"column":35,"index":29087},"line":810,"code":"      it('should connect the client', async () => {\n        const collections = client.db().listCollections();\n        await collections.tryNext();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ListIndexesCursor","#forEach()"],"updatePoint":{"line":819,"column":35,"index":29422},"line":819,"code":"      it('should connect the client', async () => {\n        const indexes = client.db().collection('test').listIndexes();\n        await indexes.forEach(item => {\n          expect(item).is.an('object');\n        }).catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ListIndexesCursor","#hasNext()"],"updatePoint":{"line":828,"column":35,"index":29789},"line":828,"code":"      it('should connect the client', async () => {\n        const indexes = client.db().collection('test').listIndexes();\n        await indexes.hasNext().catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ListIndexesCursor","#next()"],"updatePoint":{"line":835,"column":35,"index":30094},"line":835,"code":"      it('should connect the client', async () => {\n        const indexes = client.db().collection('test').listIndexes();\n        await indexes.next().catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ListIndexesCursor","#toArray()"],"updatePoint":{"line":842,"column":35,"index":30399},"line":842,"code":"      it('should connect the client', async () => {\n        const indexes = client.db().collection('test').listIndexes();\n        await indexes.toArray().catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ListIndexesCursor","#tryNext()"],"updatePoint":{"line":849,"column":35,"index":30707},"line":849,"code":"      it('should connect the client', async () => {\n        const indexes = client.db().collection('test').listIndexes();\n        await indexes.tryNext().catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should not connect the client","suites":["When executing an operation for the first time","class MongoClient","#withSession()"],"updatePoint":{"line":858,"column":39,"index":31069},"line":858,"code":"      it('should not connect the client', async () => {\n        await client.withSession(async session => {\n          expect(session).to.be.instanceOf(ClientSession);\n        });\n        expect(client).to.not.have.property('topology'); // withSession won't connect, that's expected\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should respond with BSONRegExp class with option passed to ","suites":["BSONRegExp","bsonRegExp option"],"updatePoint":{"line":17,"column":84,"index":462},"line":17,"code":"      it(`should respond with BSONRegExp class with option passed to ${passOptionTo}`, async function () {\n        try {\n          client = this.configuration.newClient(passOptionTo === 'client' ? option : undefined);\n          await client.connect();\n          const db = client.db('bson_regex_db', passOptionTo === 'db' ? option : undefined);\n          const collection = db.collection('bson_regex_coll', passOptionTo === 'collection' ? option : undefined);\n          await collection.insertOne({\n            regex: new BSONRegExp('abc', 'imx')\n          });\n          const res = await collection.findOne({\n            regex: new BSONRegExp('abc', 'imx')\n          }, passOptionTo === 'operation' ? option : undefined);\n          expect(res).has.property('regex').that.is.instanceOf(BSONRegExp);\n        } finally {\n          await client.close();\n        }\n      });","file":"integration/node-specific/bson-options/bsonRegExp.test.js","skipped":false,"dir":"test"},{"name":"Should correctly insert document ignoring undefined field","suites":["Ignore Undefined"],"updatePoint":{"line":24,"column":63,"index":517},"line":24,"code":"  it('Should correctly insert document ignoring undefined field', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        ignoreUndefined: true\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('shouldCorrectlyIgnoreUndefinedValue');\n\n        // Ignore the undefined field\n        collection.insert({\n          a: 1,\n          b: undefined\n        }, configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n\n          // Locate the doument\n          collection.findOne(function (err, item) {\n            test.equal(1, item.a);\n            test.ok(item.b === undefined);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"Should correctly connect using MongoClient and perform insert document ignoring undefined field","suites":["Ignore Undefined"],"updatePoint":{"line":57,"column":101,"index":1534},"line":57,"code":"  it('Should correctly connect using MongoClient and perform insert document ignoring undefined field', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient({}, {\n        ignoreUndefined: true,\n        sslValidate: false\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('shouldCorrectlyIgnoreUndefinedValue1');\n        collection.insert({\n          a: 1,\n          b: undefined\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.findOne(function (err, item) {\n            test.equal(1, item.a);\n            test.ok(item.b === undefined);\n            collection.insertOne({\n              a: 2,\n              b: undefined\n            }, function (err) {\n              expect(err).to.not.exist;\n              collection.findOne({\n                a: 2\n              }, function (err, item) {\n                test.equal(2, item.a);\n                test.ok(item.b === undefined);\n                collection.insertMany([{\n                  a: 3,\n                  b: undefined\n                }], function (err) {\n                  expect(err).to.not.exist;\n                  collection.findOne({\n                    a: 3\n                  }, function (err, item) {\n                    test.equal(3, item.a);\n                    test.ok(item.b === undefined);\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"Should correctly update document ignoring undefined field","suites":["Ignore Undefined"],"updatePoint":{"line":110,"column":63,"index":3185},"line":110,"code":"  it('Should correctly update document ignoring undefined field', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        ignoreUndefined: true\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('shouldCorrectlyIgnoreUndefinedValue2');\n        var id = new ObjectId();\n        collection.updateOne({\n          _id: id,\n          a: 1,\n          b: undefined\n        }, {\n          $set: {\n            a: 1,\n            b: undefined\n          }\n        }, {\n          upsert: true\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.findOne({\n            _id: id\n          }, function (err, item) {\n            test.equal(1, item.a);\n            test.ok(item.b === undefined);\n            var id = new ObjectId();\n            collection.updateMany({\n              _id: id,\n              a: 1,\n              b: undefined\n            }, {\n              $set: {\n                a: 1,\n                b: undefined\n              }\n            }, {\n              upsert: true\n            }, function (err) {\n              expect(err).to.not.exist;\n              collection.findOne({\n                _id: id\n              }, function (err, item) {\n                test.equal(1, item.a);\n                test.ok(item.b === undefined);\n                var id = new ObjectId();\n                collection.update({\n                  _id: id,\n                  a: 1,\n                  b: undefined\n                }, {\n                  $set: {\n                    a: 1,\n                    b: undefined\n                  }\n                }, {\n                  upsert: true\n                }, function (err) {\n                  expect(err).to.not.exist;\n                  collection.findOne({\n                    _id: id\n                  }, function (err, item) {\n                    test.equal(1, item.a);\n                    test.ok(item.b === undefined);\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"Should correctly inherit ignore undefined field from db during insert","suites":["Ignore Undefined"],"updatePoint":{"line":192,"column":75,"index":5540},"line":192,"code":"  it('Should correctly inherit ignore undefined field from db during insert', async function () {\n    const configuration = this.configuration;\n    const client = configuration.newClient(configuration.writeConcernMax(), {\n      maxPoolSize: 1,\n      ignoreUndefined: false\n    });\n    const db = client.db(configuration.db, {\n      ignoreUndefined: true\n    });\n    const collection = db.collection('shouldCorrectlyIgnoreUndefinedValue3');\n    await collection.insert({\n      a: 1,\n      b: undefined\n    });\n    const item = await collection.findOne();\n    expect(item).to.have.property('a', 1);\n    expect(item).to.not.have.property('b');\n    await client.close();\n  });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"Should correctly inherit ignore undefined field from collection during insert","suites":["Ignore Undefined"],"updatePoint":{"line":211,"column":83,"index":6221},"line":211,"code":"  it('Should correctly inherit ignore undefined field from collection during insert', function (done) {\n    const db = client.db('shouldCorrectlyIgnoreUndefinedValue4', {\n      ignoreUndefined: false\n    });\n    const collection = db.collection('shouldCorrectlyIgnoreUndefinedValue4', {\n      ignoreUndefined: true\n    });\n\n    // Ignore the undefined field\n    collection.insert({\n      a: 1,\n      b: undefined\n    }, err => {\n      expect(err).to.not.exist;\n\n      // Locate the doument\n      collection.findOne((err, item) => {\n        expect(err).to.not.exist;\n        expect(item).to.have.property('a', 1);\n        expect(item).to.not.have.property('b');\n        done();\n      });\n    });\n  });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"Should correctly inherit ignore undefined field from operation during insert","suites":["Ignore Undefined"],"updatePoint":{"line":235,"column":82,"index":6921},"line":235,"code":"  it('Should correctly inherit ignore undefined field from operation during insert', function (done) {\n    const db = client.db('shouldCorrectlyIgnoreUndefinedValue5');\n    const collection = db.collection('shouldCorrectlyIgnoreUndefinedValue5', {\n      ignoreUndefined: false\n    });\n\n    // Ignore the undefined field\n    collection.insert({\n      a: 1,\n      b: undefined\n    }, {\n      ignoreUndefined: true\n    }, err => {\n      expect(err).to.not.exist;\n\n      // Locate the doument\n      collection.findOne({}, (err, item) => {\n        expect(err).to.not.exist;\n        expect(item).to.have.property('a', 1);\n        expect(item).to.not.have.property('b');\n        done();\n      });\n    });\n  });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"Should correctly inherit ignore undefined field from operation during findOneAndReplace","suites":["Ignore Undefined"],"updatePoint":{"line":259,"column":93,"index":7636},"line":259,"code":"  it('Should correctly inherit ignore undefined field from operation during findOneAndReplace', function (done) {\n    const db = client.db('shouldCorrectlyIgnoreUndefinedValue6');\n    const collection = db.collection('shouldCorrectlyIgnoreUndefinedValue6', {\n      ignoreUndefined: false\n    });\n    collection.insert({\n      a: 1,\n      b: 2\n    }, err => {\n      expect(err).to.not.exist;\n\n      // Replace the doument, ignoring undefined fields\n      collection.findOneAndReplace({}, {\n        a: 1,\n        b: undefined\n      }, {\n        ignoreUndefined: true\n      }, err => {\n        expect(err).to.not.exist;\n\n        // Locate the doument\n        collection.findOne((err, item) => {\n          expect(err).to.not.exist;\n          expect(item).to.have.property('a', 1);\n          expect(item).to.not.have.property('b');\n          done();\n        });\n      });\n    });\n  });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"Should correctly ignore undefined field during bulk write","suites":["Ignore Undefined"],"updatePoint":{"line":289,"column":63,"index":8487},"line":289,"code":"  it('Should correctly ignore undefined field during bulk write', function (done) {\n    const db = client.db('shouldCorrectlyIgnoreUndefinedValue7');\n    const collection = db.collection('shouldCorrectlyIgnoreUndefinedValue7');\n\n    // Ignore the undefined field\n    collection.bulkWrite([{\n      insertOne: {\n        a: 1,\n        b: undefined\n      }\n    }], {\n      ignoreUndefined: true\n    }, err => {\n      expect(err).to.not.exist;\n\n      // Locate the doument\n      collection.findOne((err, item) => {\n        expect(err).to.not.exist;\n        expect(item).to.have.property('a', 1);\n        expect(item).to.not.have.property('b');\n        done();\n      });\n    });\n  });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute insert culling undefined","suites":["Ignore Undefined","ignoreUndefined A server"],"updatePoint":{"line":314,"column":57,"index":9213},"line":314,"code":"    it('should correctly execute insert culling undefined', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.2'\n        }\n      },\n      test: function (done) {\n        const coll = client.db().collection('insert1');\n        coll.drop(() => {\n          const objectId = new ObjectId();\n          coll.insertOne({\n            _id: objectId,\n            a: 1,\n            b: undefined\n          }, {\n            ignoreUndefined: true\n          }, (err, res) => {\n            expect(err).to.not.exist;\n            expect(res).property('insertedId').to.exist;\n            const cursor = coll.find({\n              _id: objectId\n            });\n            this.defer(() => cursor.close());\n            cursor.next((err, doc) => {\n              expect(err).to.not.exist;\n              expect(doc).to.not.have.property('b');\n              done();\n            });\n          });\n        });\n      }\n    });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute update culling undefined","suites":["Ignore Undefined","ignoreUndefined A server"],"updatePoint":{"line":346,"column":57,"index":10126},"line":346,"code":"    it('should correctly execute update culling undefined', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.2'\n        }\n      },\n      test: function (done) {\n        const coll = client.db().collection('update1');\n        coll.drop(() => {\n          const objectId = new ObjectId();\n          coll.updateOne({\n            _id: objectId,\n            a: 1,\n            b: undefined\n          }, {\n            $set: {\n              a: 1,\n              b: undefined\n            }\n          }, {\n            ignoreUndefined: true,\n            upsert: true\n          }, (err, res) => {\n            expect(err).to.not.exist;\n            expect(res).property('upsertedCount').to.equal(1);\n            const cursor = coll.find({\n              _id: objectId\n            });\n            this.defer(() => cursor.close());\n            cursor.next((err, doc) => {\n              expect(err).to.not.exist;\n              expect(doc).to.not.have.property('b');\n              done();\n            });\n          });\n        });\n      }\n    });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute remove culling undefined","suites":["Ignore Undefined","ignoreUndefined A server"],"updatePoint":{"line":384,"column":57,"index":11167},"line":384,"code":"    it('should correctly execute remove culling undefined', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.2'\n        }\n      },\n      test: function (done) {\n        const coll = client.db().collection('remove1');\n        coll.drop(() => {\n          const objectId = new ObjectId();\n          coll.insertMany([{\n            id: objectId,\n            a: 1,\n            b: undefined\n          }, {\n            id: objectId,\n            a: 2,\n            b: 1\n          }], (err, res) => {\n            expect(err).to.not.exist;\n            expect(res).property('insertedCount').to.equal(2);\n            coll.deleteMany({\n              b: undefined\n            }, {\n              ignoreUndefined: true\n            }, (err, res) => {\n              expect(err).to.not.exist;\n              expect(res).property('deletedCount').to.equal(2);\n              done();\n            });\n          });\n        });\n      }\n    });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute remove not culling undefined","suites":["Ignore Undefined","ignoreUndefined A server"],"updatePoint":{"line":418,"column":61,"index":12102},"line":418,"code":"    it('should correctly execute remove not culling undefined', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.2'\n        }\n      },\n      test: function (done) {\n        const coll = client.db().collection('remove1');\n        coll.drop(() => {\n          const objectId = new ObjectId();\n          coll.insertMany([{\n            id: objectId,\n            a: 1,\n            b: undefined\n          }, {\n            id: objectId,\n            a: 2,\n            b: 1\n          }], (err, res) => {\n            expect(err).to.not.exist;\n            expect(res).property('insertedCount').to.equal(2);\n            coll.deleteMany({\n              b: null\n            }, (err, res) => {\n              expect(err).to.not.exist;\n              expect(res).property('deletedCount').to.equal(1);\n              done();\n            });\n          });\n        });\n      }\n    });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteBuffers when creating an instance using Db","suites":["Promote Buffers"],"updatePoint":{"line":14,"column":78,"index":318},"line":14,"code":"  it('should correctly honor promoteBuffers when creating an instance using Db', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        promoteBuffers: true\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteBuffer1').insert({\n          doc: Buffer.alloc(256)\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteBuffer1').findOne(function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc.doc instanceof Buffer);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_buffers.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteBuffers when creating an instance using MongoClient","suites":["Promote Buffers"],"updatePoint":{"line":43,"column":87,"index":1404},"line":43,"code":"  it('should correctly honor promoteBuffers when creating an instance using MongoClient', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient({}, {\n        promoteBuffers: true\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteBuffer2').insert({\n          doc: Buffer.alloc(256)\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteBuffer2').findOne(function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc.doc instanceof Buffer);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_buffers.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteBuffers at cursor level","suites":["Promote Buffers"],"updatePoint":{"line":71,"column":59,"index":2411},"line":71,"code":"  it('should correctly honor promoteBuffers at cursor level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient({}, {\n        promoteBuffers: true\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteBuffer3').insert({\n          doc: Buffer.alloc(256)\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteBuffer3').find().next(function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc.doc instanceof Buffer);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_buffers.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteBuffers at cursor find level","suites":["Promote Buffers"],"updatePoint":{"line":99,"column":64,"index":3427},"line":99,"code":"  it('should correctly honor promoteBuffers at cursor find level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteBuffer4').insert({\n          doc: Buffer.alloc(256)\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteBuffer4').find({}, {\n            promoteBuffers: true\n          }).next(function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc.doc instanceof Buffer);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_buffers.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteBuffers at aggregate level","suites":["Promote Buffers"],"updatePoint":{"line":127,"column":62,"index":4449},"line":127,"code":"  it('should correctly honor promoteBuffers at aggregate level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger'],\n        mongodb: '>=2.4.0'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteBuffer5').insert({\n          doc: Buffer.alloc(256)\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteBuffer5').aggregate([{\n            $match: {}\n          }], {\n            promoteBuffers: true\n          }).next(function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc.doc instanceof Buffer);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_buffers.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteValues when creating an instance using Db","suites":["Promote Values"],"updatePoint":{"line":19,"column":77,"index":382},"line":19,"code":"  it('should correctly honor promoteValues when creating an instance using Db', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        promoteValues: false\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteValues').insert({\n          doc: Long.fromNumber(10),\n          int: 10,\n          double: 2.2222,\n          array: [[Long.fromNumber(10)]]\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteValues').findOne(function (err, doc) {\n            expect(err).to.not.exist;\n            test.deepEqual(Long.fromNumber(10), doc.doc);\n            test.deepEqual(new Int32(10), doc.int);\n            test.deepEqual(new Double(2.2222), doc.double);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_values.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteValues when creating an instance using MongoClient","suites":["Promote Values"],"updatePoint":{"line":53,"column":86,"index":1676},"line":53,"code":"  it('should correctly honor promoteValues when creating an instance using MongoClient', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient({}, {\n        promoteValues: false\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteValues').insert({\n          doc: Long.fromNumber(10),\n          int: 10,\n          double: 2.2222,\n          array: [[Long.fromNumber(10)]]\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteValues').findOne(function (err, doc) {\n            expect(err).to.not.exist;\n            test.deepEqual(Long.fromNumber(10), doc.doc);\n            test.deepEqual(new Int32(10), doc.int);\n            test.deepEqual(new Double(2.2222), doc.double);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_values.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteValues at cursor level","suites":["Promote Values"],"updatePoint":{"line":86,"column":58,"index":2891},"line":86,"code":"  it('should correctly honor promoteValues at cursor level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient({}, {\n        promoteValues: false\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteValues').insert({\n          doc: Long.fromNumber(10),\n          int: 10,\n          double: 2.2222,\n          array: [[Long.fromNumber(10)]]\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteValues').find().next(function (err, doc) {\n            expect(err).to.not.exist;\n            test.deepEqual(Long.fromNumber(10), doc.doc);\n            test.deepEqual(new Int32(10), doc.int);\n            test.deepEqual(new Double(2.2222), doc.double);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_values.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteValues at cursor find level","suites":["Promote Values"],"updatePoint":{"line":119,"column":63,"index":4115},"line":119,"code":"  it('should correctly honor promoteValues at cursor find level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteValues').insert({\n          doc: Long.fromNumber(10),\n          int: 10,\n          double: 2.2222,\n          array: [[Long.fromNumber(10)]]\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteValues').find({}, {\n            promoteValues: false\n          }).next(function (err, doc) {\n            expect(err).to.not.exist;\n            test.deepEqual(Long.fromNumber(10), doc.doc);\n            test.deepEqual(new Int32(10), doc.int);\n            test.deepEqual(new Double(2.2222), doc.double);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_values.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteValues at aggregate level","suites":["Promote Values"],"updatePoint":{"line":152,"column":61,"index":5345},"line":152,"code":"  it('should correctly honor promoteValues at aggregate level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteValues2').insert({\n          doc: Long.fromNumber(10),\n          int: 10,\n          double: 2.2222,\n          array: [[Long.fromNumber(10)]]\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteValues2').aggregate([{\n            $match: {}\n          }], {\n            promoteValues: false\n          }).next(function (err, doc) {\n            expect(err).to.not.exist;\n            test.deepEqual(Long.fromNumber(10), doc.doc);\n            test.deepEqual(new Int32(10), doc.int);\n            test.deepEqual(new Double(2.2222), doc.double);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_values.test.js","skipped":false,"dir":"test"},{"name":"Should correctly promoteValues when calling getMore on queries","suites":["Promote Values"],"updatePoint":{"line":187,"column":68,"index":6625},"line":187,"code":"  it('Should correctly promoteValues when calling getMore on queries', {\n    metadata: {\n      requires: {\n        topology: ['single', 'ssl', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect(function (err, client) {\n        var docs = new Array(150).fill(0).map(function (_, i) {\n          return {\n            _id: 'needle_' + i,\n            is_even: i % 2,\n            long: Long.fromString('1234567890'),\n            double: 0.23456,\n            int: 1234\n          };\n        });\n        var db = client.db(configuration.db);\n        db.collection('haystack').insertMany(docs, function (errInsert) {\n          if (errInsert) throw errInsert;\n          // change limit from 102 to 101 and this test passes.\n          // seems to indicate that the promoteValues flag is used for the\n          // initial find, but not for subsequent getMores\n          db.collection('haystack').find({}, {\n            limit: 102,\n            promoteValues: false\n          }).stream().on('data', function (doc) {\n            test.equal(typeof doc.int, 'object');\n            test.equal(doc.int._bsontype, 'Int32');\n            test.equal(typeof doc.long, 'object');\n            test.equal(doc.long._bsontype, 'Long');\n            test.equal(typeof doc.double, 'object');\n            test.equal(doc.double._bsontype, 'Double');\n          }).on('end', function () {\n            db.dropCollection('haystack', function () {\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_values.test.js","skipped":false,"dir":"test"},{"name":"should disable validation with option passed to ","suites":["class BinMsg","enableUtf8Validation option set to false"],"updatePoint":{"line":28,"column":73,"index":833},"line":28,"code":"      it(`should disable validation with option passed to ${passOptionTo}`, async function () {\n        try {\n          client = this.configuration.newClient(passOptionTo === 'client' ? option : undefined);\n          await client.connect();\n          const db = client.db('bson_utf8Validation_db', passOptionTo === 'db' ? option : undefined);\n          const collection = db.collection('bson_utf8Validation_coll', passOptionTo === 'collection' ? option : undefined);\n          await collection.insertOne({\n            name: 'John Doe'\n          }, passOptionTo === 'operation' ? option : {});\n          expect(deserializeSpy.called).to.be.true;\n          const validationArgument = deserializeSpy.lastCall.lastArg.validation;\n          expect(validationArgument).to.deep.equal(EXPECTED_VALIDATION_DISABLED_ARGUMENT);\n        } finally {\n          await client.close();\n        }\n      });","file":"integration/node-specific/bson-options/utf8_validation.test.ts","skipped":false,"dir":"test"},{"name":"should enable validation with option passed to ","suites":["class BinMsg","enableUtf8Validation option set to true"],"updatePoint":{"line":53,"column":72,"index":1999},"line":53,"code":"      it(`should enable validation with option passed to ${passOptionTo}`, async function () {\n        try {\n          client = this.configuration.newClient(passOptionTo === 'client' ? option : undefined);\n          await client.connect();\n          const db = client.db('bson_utf8Validation_db', passOptionTo === 'db' ? option : undefined);\n          const collection = db.collection('bson_utf8Validation_coll', passOptionTo === 'collection' ? option : undefined);\n          await collection.insertOne({\n            name: 'John Doe'\n          }, passOptionTo === 'operation' ? option : {});\n          expect(deserializeSpy.called).to.be.true;\n          const validationArgument = deserializeSpy.lastCall.lastArg.validation;\n          expect(validationArgument).to.deep.equal(EXPECTED_VALIDATION_ENABLED_ARGUMENT);\n        } finally {\n          await client.close();\n        }\n      });","file":"integration/node-specific/bson-options/utf8_validation.test.ts","skipped":false,"dir":"test"},{"name":"should default to enabled with option passed to ","suites":["class BinMsg","enableUtf8Validation option not set"],"updatePoint":{"line":77,"column":73,"index":3112},"line":77,"code":"      it(`should default to enabled with option passed to ${passOptionTo}`, async function () {\n        try {\n          client = this.configuration.newClient(passOptionTo === 'client' ? option : undefined);\n          await client.connect();\n          const db = client.db('bson_utf8Validation_db', passOptionTo === 'db' ? option : undefined);\n          const collection = db.collection('bson_utf8Validation_coll', passOptionTo === 'collection' ? option : undefined);\n          await collection.insertOne({\n            name: 'John Doe'\n          }, passOptionTo === 'operation' ? option : {});\n          expect(deserializeSpy.called).to.be.true;\n          const validationArgument = deserializeSpy.lastCall.lastArg.validation;\n          expect(validationArgument).to.deep.equal(EXPECTED_VALIDATION_ENABLED_ARGUMENT);\n        } finally {\n          await client.close();\n        }\n      });","file":"integration/node-specific/bson-options/utf8_validation.test.ts","skipped":false,"dir":"test"},{"name":"should be able to use a for-await loop on a find command cursor","suites":["Cursor Async Iterator Tests","default promise library"],"updatePoint":{"line":36,"column":71,"index":1104},"line":36,"code":"    it('should be able to use a for-await loop on a find command cursor', async function () {\n      const cursor = collection.find({\n        bar: 1\n      });\n      let counter = 0;\n      for await (const doc of cursor) {\n        expect(doc).to.have.property('bar', 1);\n        counter += 1;\n      }\n      expect(counter).to.equal(1000);\n    });","file":"integration/node-specific/cursor_async_iterator.test.js","skipped":false,"dir":"test"},{"name":"should be able to use a for-await loop on an aggregation cursor","suites":["Cursor Async Iterator Tests","default promise library"],"updatePoint":{"line":47,"column":71,"index":1449},"line":47,"code":"    it('should be able to use a for-await loop on an aggregation cursor', async function () {\n      const cursor = collection.aggregate([{\n        $match: {\n          bar: 1\n        }\n      }]);\n      let counter = 0;\n      for await (const doc of cursor) {\n        expect(doc).to.have.property('bar', 1);\n        counter += 1;\n      }\n      expect(counter).to.equal(1000);\n    });","file":"integration/node-specific/cursor_async_iterator.test.js","skipped":false,"dir":"test"},{"name":"should be able to use a for-await loop on a command cursor","suites":["Cursor Async Iterator Tests","default promise library"],"updatePoint":{"line":60,"column":66,"index":1826},"line":60,"code":"    it('should be able to use a for-await loop on a command cursor', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.0.0'\n        }\n      },\n      test: async function () {\n        const cursor1 = collection.listIndexes();\n        const cursor2 = collection.listIndexes();\n        const indexes = await cursor1.toArray();\n        let counter = 0;\n        for await (const doc of cursor2) {\n          expect(doc).to.exist;\n          counter += 1;\n        }\n        expect(counter).to.equal(indexes.length);\n      }\n    });","file":"integration/node-specific/cursor_async_iterator.test.js","skipped":false,"dir":"test"},{"name":"should properly stop when cursor is closed","suites":["Cursor Async Iterator Tests","default promise library"],"updatePoint":{"line":78,"column":50,"index":2348},"line":78,"code":"    it('should properly stop when cursor is closed', async function () {\n      const cursor = collection.find();\n      let count = 0;\n      for await (const doc of cursor) {\n        expect(doc).to.exist;\n        count++;\n        await cursor.close();\n      }\n      expect(count).to.equal(1);\n    });","file":"integration/node-specific/cursor_async_iterator.test.js","skipped":false,"dir":"test"},{"name":"should properly use custom promise","suites":["Cursor Async Iterator Tests","custom promise library"],"updatePoint":{"line":120,"column":42,"index":3723},"line":120,"code":"    it('should properly use custom promise', async function () {\n      const cursor = collection.find();\n      const countBeforeIteration = promiseSpy.callCount;\n      for await (const doc of cursor) {\n        expect(doc).to.exist;\n      }\n      expect(countBeforeIteration).to.not.equal(promiseSpy.callCount);\n      expect(promiseSpy.called).to.equal(true);\n    });","file":"integration/node-specific/cursor_async_iterator.test.js","skipped":false,"dir":"test"},{"name":"should properly use custom promise manual iteration","suites":["Cursor Async Iterator Tests","custom promise library"],"updatePoint":{"line":129,"column":59,"index":4107},"line":129,"code":"    it('should properly use custom promise manual iteration', async function () {\n      const cursor = collection.find();\n      const iterator = cursor[Symbol.asyncIterator]();\n      let isDone;\n      do {\n        const promiseFromIterator = iterator.next();\n        expect(promiseFromIterator).to.be.instanceOf(BluebirdPromise);\n        const {\n          done,\n          value\n        } = await promiseFromIterator;\n        if (done) expect(value).to.be.a('undefined');\n        isDone = done;\n      } while (!isDone);\n    });","file":"integration/node-specific/cursor_async_iterator.test.js","skipped":false,"dir":"test"},{"name":"should stream documents with pause and resume for fetching","suites":["Cursor Streams"],"updatePoint":{"line":21,"column":64,"index":427},"line":21,"code":"  it('should stream documents with pause and resume for fetching', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var docs = [];\n      var j = 0;\n      for (var i = 0; i < 3000; i++) {\n        docs.push({\n          a: i\n        });\n      }\n      var allDocs = [];\n      while (docs.length > 0) {\n        allDocs.push(docs.splice(0, 1000));\n      }\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        db.createCollection('test_streaming_function_with_limit_for_fetching2', function (err, collection) {\n          var left = allDocs.length;\n          for (var i = 0; i < allDocs.length; i++) {\n            collection.insert(allDocs[i], {\n              writeConcern: {\n                w: 1\n              }\n            }, function (err) {\n              expect(err).to.not.exist;\n              left = left - 1;\n              if (left === 0) {\n                // Perform a find to get a cursor\n                var stream = collection.find({}).stream();\n                var data = [];\n\n                // For each data item\n                stream.on('data', function () {\n                  data.push(1);\n                  j = j + 1;\n                  stream.pause();\n                  collection.findOne({}, function (err) {\n                    expect(err).to.not.exist;\n                    stream.resume();\n                  });\n                });\n\n                // When the stream is done\n                stream.on('end', function () {\n                  setTimeout(() => {\n                    let err;\n                    try {\n                      expect(data).to.have.length(3000);\n                    } catch (e) {\n                      err = e;\n                    }\n                    client.close(() => done(err));\n                  }, 1000);\n                });\n              }\n            });\n          }\n        });\n      });\n    }\n  });","file":"integration/node-specific/cursor_stream.test.js","skipped":false,"dir":"test"},{"name":"should stream 10K documents","suites":["Cursor Streams"],"updatePoint":{"line":90,"column":33,"index":2560},"line":90,"code":"  it('should stream 10K documents', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var docs = [];\n      for (var i = 0; i < 10000; i++) {\n        docs.push({\n          a: i,\n          bin: new Binary(Buffer.alloc(256))\n        });\n      }\n      var j = 0;\n      var allDocs = [];\n      while (docs.length > 0) {\n        allDocs.push(docs.splice(0, 1000));\n      }\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        db.createCollection('test_streaming_function_with_limit_for_fetching_2', function (err, collection) {\n          var left = allDocs.length;\n          for (var i = 0; i < allDocs.length; i++) {\n            collection.insert(allDocs[i], {\n              writeConcern: {\n                w: 1\n              }\n            }, function (err) {\n              expect(err).to.not.exist;\n              left = left - 1;\n              if (left === 0) {\n                // Perform a find to get a cursor\n                var stream = collection.find({}).stream();\n                var data = [];\n\n                // For each data item\n                stream.on('data', function () {\n                  j = j + 1;\n                  stream.pause();\n                  data.push(1);\n                  collection.findOne({}, function (err) {\n                    expect(err).to.not.exist;\n                    stream.resume();\n                  });\n                });\n\n                // When the stream is done\n                stream.on('end', function () {\n                  setTimeout(() => {\n                    let err;\n                    try {\n                      expect(data).to.have.length(10000);\n                    } catch (e) {\n                      err = e;\n                    }\n                    client.close(err2 => done(err || err2));\n                  }, 1000);\n                });\n              }\n            });\n          }\n        });\n      });\n    }\n  });","file":"integration/node-specific/cursor_stream.test.js","skipped":false,"dir":"test"},{"name":"should trigger massive amount of getMores","suites":["Cursor Streams"],"updatePoint":{"line":160,"column":47,"index":4766},"line":160,"code":"  it('should trigger massive amount of getMores', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var docs = [];\n      var counter = 0;\n      var counter2 = 0;\n      for (var i = 0; i < 1000; i++) {\n        docs.push({\n          a: i,\n          bin: new Binary(Buffer.alloc(256))\n        });\n      }\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        db.createCollection('test_streaming_function_with_limit_for_fetching_3', function (err, collection) {\n          collection.insert(docs, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n\n            // Perform a find to get a cursor\n            var stream = collection.find({}).stream();\n\n            // For each data item\n            stream.on('data', function () {\n              counter++;\n              stream.pause();\n              stream.resume();\n              counter2++;\n            });\n\n            // When the stream is done\n            stream.on('end', function () {\n              expect(counter).to.equal(1000);\n              expect(counter2).to.equal(1000);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/cursor_stream.test.js","skipped":false,"dir":"test"},{"name":"should stream documents across getMore command and count correctly","suites":["Cursor Streams"],"updatePoint":{"line":212,"column":72,"index":6310},"line":212,"code":"  it('should stream documents across getMore command and count correctly', async function () {\n    if (process.platform === 'darwin') {\n      this.skipReason = 'TODO(NODE-3819): Unskip flaky MacOS tests.';\n      return this.skip();\n    }\n    const db = client.db();\n    const collection = db.collection('streaming');\n    const updateCollection = db.collection('update_within_streaming');\n    await collection.drop().catch(() => null);\n    await updateCollection.drop().catch(() => null);\n    const docs = Array.from({\n      length: 10\n    }, (_, i) => ({\n      _id: i,\n      b: new Binary(Buffer.alloc(1024))\n    }));\n    await collection.insertMany(docs);\n    // Set the batchSize to be a 5th of the total docCount to make getMores happen\n    const stream = collection.find({}, {\n      batchSize: 2\n    }).stream();\n    let done;\n    const end = new Promise((resolve, reject) => {\n      done = error => error != null ? reject(error) : resolve();\n    });\n    stream.on('end', () => {\n      updateCollection.findOne({\n        id: 1\n      }).then(function (doc) {\n        expect(doc.count).to.equal(9);\n        done();\n      }).catch(done).finally(() => client.close());\n    });\n    let docCount = 0;\n    stream.on('data', data => {\n      stream.pause();\n      try {\n        expect(data).to.have.property('_id', docCount);\n      } catch (assertionError) {\n        return done(assertionError);\n      }\n      if (docCount++ === docs.length - 1) {\n        stream.resume();\n        return;\n      }\n      updateCollection.updateMany({\n        id: 1\n      }, {\n        $inc: {\n          count: 1\n        }\n      }, {\n        writeConcern: {\n          w: 1\n        },\n        upsert: true\n      }).then(() => {\n        stream.resume();\n      }).catch(done);\n    });\n    return end;\n  });","file":"integration/node-specific/cursor_stream.test.js","skipped":false,"dir":"test"},{"name":"should correctly error out stream","suites":["Cursor Streams"],"updatePoint":{"line":274,"column":39,"index":8056},"line":274,"code":"  it('should correctly error out stream', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        const db = client.db(self.configuration.db);\n        const cursor = db.collection('myCollection').find({\n          timestamp: {\n            $ltx: '1111'\n          } // Error in query.\n        });\n\n        let error;\n        const stream = cursor.stream();\n        stream.on('error', err => error = err);\n        cursor.on('close', function () {\n          // NOTE: use `setImmediate` here because the stream implementation uses `nextTick` to emit the error\n          setImmediate(() => {\n            expect(error).to.exist;\n            client.close(done);\n          });\n        });\n        stream.pipe(process.stdout);\n      });\n    }\n  });","file":"integration/node-specific/cursor_stream.test.js","skipped":false,"dir":"test"},{"name":"should correctly stream cursor after stream","suites":["Cursor Streams"],"updatePoint":{"line":307,"column":49,"index":9102},"line":307,"code":"  it('should correctly stream cursor after stream', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var docs = [];\n        var received = [];\n        for (var i = 0; i < 1000; i++) {\n          docs.push({\n            a: i,\n            field: 'hello world'\n          });\n        }\n        db.collection('cursor_sort_stream').insertMany(docs, function (err) {\n          expect(err).to.not.exist;\n          var cursor = db.collection('cursor_sort_stream').find({}).project({\n            a: 1\n          }).sort({\n            a: -1\n          });\n          const stream = cursor.stream();\n          stream.on('end', function () {\n            expect(received).to.have.length(1000);\n            client.close(done);\n          });\n          stream.on('data', function (d) {\n            received.push(d);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/cursor_stream.test.js","skipped":false,"dir":"test"},{"name":"should initially be set to null","suites":["Optional PromiseLibrary"],"updatePoint":{"line":24,"column":37,"index":515},"line":24,"code":"  it('should initially be set to null', () => {\n    expect(PromiseProvider.get()).to.be.null;\n  });","file":"integration/node-specific/custom_promise_library.test.js","skipped":false,"dir":"test"},{"name":"should allow passing null to .set() to clear the set promise","suites":["Optional PromiseLibrary"],"updatePoint":{"line":27,"column":66,"index":644},"line":27,"code":"  it('should allow passing null to .set() to clear the set promise', () => {\n    PromiseProvider.set(Promise);\n    expect(PromiseProvider.get()).to.equal(Promise);\n    expect(() => PromiseProvider.set(null)).to.not.throw();\n    expect(PromiseProvider.get()).to.be.null;\n  });","file":"integration/node-specific/custom_promise_library.test.js","skipped":false,"dir":"test"},{"name":"should emit a deprecation warning when a promiseLibrary is set","suites":["Optional PromiseLibrary"],"updatePoint":{"line":33,"column":68,"index":922},"line":33,"code":"  it('should emit a deprecation warning when a promiseLibrary is set', async () => {\n    const willEmitWarning = once(process, 'warning');\n    new MongoClient('mongodb://iLoveJavascript', {\n      promiseLibrary: () => {}\n    });\n    const [warning] = await willEmitWarning;\n    expect(warning).to.have.property('message', 'promiseLibrary is a deprecated option');\n  });","file":"integration/node-specific/custom_promise_library.test.js","skipped":false,"dir":"test"},{"name":"should correctly implement custom dependency-less promise","suites":["Optional PromiseLibrary"],"updatePoint":{"line":41,"column":63,"index":1287},"line":41,"code":"  it('should correctly implement custom dependency-less promise', function (done) {\n    const getCustomPromise = v => new CustomPromise(resolve => resolve(v));\n    const getNativePromise = v => new Promise(resolve => resolve(v));\n    expect(getNativePromise()).to.not.have.property('isCustomMongo');\n    expect(getCustomPromise()).to.have.property('isCustomMongo');\n    expect(getNativePromise()).to.have.property('then');\n    expect(getCustomPromise()).to.have.property('then');\n    done();\n  });","file":"integration/node-specific/custom_promise_library.test.js","skipped":false,"dir":"test"},{"name":"should have cursor return native promise","suites":["Optional PromiseLibrary"],"updatePoint":{"line":50,"column":46,"index":1768},"line":50,"code":"  it('should have cursor return native promise', function (done) {\n    const configuration = this.configuration;\n    const client = this.configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    client.connect((err, client) => {\n      expect(err).to.not.exist;\n      const db = client.db(configuration.db);\n      const collection = db.collection('test');\n      const cursor = collection.find({});\n      const isPromise = cursor.toArray();\n      expect(isPromise).to.not.have.property('isCustomMongo');\n      expect(isPromise).to.have.property('then');\n      isPromise.then(() => client.close(done));\n    });\n  });","file":"integration/node-specific/custom_promise_library.test.js","skipped":false,"dir":"test"},{"name":"should have cursor return custom promise from new client options","suites":["Optional PromiseLibrary"],"updatePoint":{"line":68,"column":70,"index":2427},"line":68,"code":"  it('should have cursor return custom promise from new client options', function (done) {\n    const configuration = this.configuration;\n    const client = this.configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1,\n      promiseLibrary: CustomPromise\n    });\n    client.connect((err, client) => {\n      const db = client.db(configuration.db);\n      expect(err).to.not.exist;\n      const collection = db.collection('test');\n      const cursor = collection.find({});\n      const isPromise = cursor.toArray();\n      expect(isPromise).to.have.property('isCustomMongo');\n      expect(isPromise).to.have.property('then');\n      isPromise.then(() => client.close(done));\n    });\n  });","file":"integration/node-specific/custom_promise_library.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleIllegalDbNames","suites":["Db"],"updatePoint":{"line":18,"column":41,"index":322},"line":18,"code":"  it('shouldCorrectlyHandleIllegalDbNames', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: done => {\n      const client = {\n        bsonOptions: {}\n      };\n      expect(() => new Db(client, 5)).to.throw('Database name must be a string');\n      expect(() => new Db(client, '')).to.throw('Database name cannot be the empty string');\n      expect(() => new Db(client, 'te$t')).to.throw(\"database names cannot contain the character '$'\");\n      expect(() => new Db(client, '.test', function () {})).to.throw(\"database names cannot contain the character '.'\");\n      expect(() => new Db(client, '\\\\test', function () {})).to.throw(\"database names cannot contain the character '\\\\'\");\n      expect(() => new Db(client, 'test test', function () {})).to.throw(\"database names cannot contain the character ' '\");\n      done();\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleFailedConnection","suites":["Db"],"updatePoint":{"line":37,"column":43,"index":1223},"line":37,"code":"  it('shouldCorrectlyHandleFailedConnection', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var fs_client = configuration.newClient('mongodb://127.0.0.1:25117/test', {\n        serverSelectionTimeoutMS: 10\n      });\n      fs_client.connect(function (err) {\n        test.ok(err != null);\n        done();\n      });\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyGetErrorDroppingNonExistingDb","suites":["Db"],"updatePoint":{"line":54,"column":50,"index":1693},"line":54,"code":"  it('shouldCorrectlyGetErrorDroppingNonExistingDb', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var _db = client.db('nonexistingdb');\n        _db.dropDatabase(function (err, result) {\n          expect(err).to.not.exist;\n          test.equal(true, result);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyThrowWhenTryingToReOpenConnection","suites":["Db"],"line":75,"code":"  it.skip('shouldCorrectlyThrowWhenTryingToReOpenConnection', {","file":"integration/node-specific/db.test.js","skipped":true,"dir":"test"},{"name":"should not cut collection name when it is the same as the database","suites":["Db"],"updatePoint":{"line":97,"column":72,"index":2920},"line":97,"code":"  it('should not cut collection name when it is the same as the database', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db1 = client.db('node972');\n        db1.collection('node972.test').insertOne({\n          a: 1\n        }, function (err) {\n          expect(err).to.not.exist;\n          db1.collections(function (err, collections) {\n            expect(err).to.not.exist;\n            collections = collections.map(function (c) {\n              return c.collectionName;\n            });\n            test.notEqual(-1, collections.indexOf('node972.test'));\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUseCursorWithListCollectionsCommand","suites":["Db"],"updatePoint":{"line":127,"column":56,"index":3873},"line":127,"code":"  it('shouldCorrectlyUseCursorWithListCollectionsCommand', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n\n        // Get a db we that does not have any collections\n        var db1 = client.db('shouldCorrectlyUseCursorWithListCollectionsCommand');\n\n        // Create a collection\n        db1.collection('test').insertOne({\n          a: 1\n        }, function (err) {\n          expect(err).to.not.exist;\n\n          // Create a collection\n          db1.collection('test1').insertOne({\n            a: 1\n          }, function () {\n            expect(err).to.not.exist;\n\n            // Get listCollections filtering out the name\n            var cursor = db1.listCollections({\n              name: 'test1'\n            });\n            cursor.toArray(function (err, names) {\n              expect(err).to.not.exist;\n              test.equal(1, names.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUseCursorWithListCollectionsCommandAndBatchSize","suites":["Db"],"updatePoint":{"line":170,"column":68,"index":5154},"line":170,"code":"  it('shouldCorrectlyUseCursorWithListCollectionsCommandAndBatchSize', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n\n        // Get a db we that does not have any collections\n        var db1 = client.db('shouldCorrectlyUseCursorWithListCollectionsCommandAndBatchSize');\n\n        // Create a collection\n        db1.collection('test').insertOne({\n          a: 1\n        }, function (err) {\n          expect(err).to.not.exist;\n\n          // Create a collection\n          db1.collection('test1').insertOne({\n            a: 1\n          }, function () {\n            expect(err).to.not.exist;\n\n            // Get listCollections filtering out the name\n            var cursor = db1.listCollections({\n              name: 'test'\n            }, {\n              batchSize: 1\n            });\n            cursor.toArray(function (err, names) {\n              expect(err).to.not.exist;\n              test.equal(1, names.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"should correctly list collection names with . in the middle","suites":["Db"],"updatePoint":{"line":215,"column":65,"index":6487},"line":215,"code":"  it('should correctly list collection names with . in the middle', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n\n        // Get a db we that does not have any collections\n        var db1 = client.db('shouldCorrectlyListCollectionsWithDotsOnThem');\n\n        // Create a collection\n        db1.collection('test.collection1').insertOne({\n          a: 1\n        }, function (err) {\n          expect(err).to.not.exist;\n\n          // Create a collection\n          db1.collection('test.collection2').insertOne({\n            a: 1\n          }, function () {\n            expect(err).to.not.exist;\n\n            // Get listCollections filtering out the name\n            var cursor = db1.listCollections({\n              name: /test.collection/\n            });\n            cursor.toArray(function (err, names) {\n              expect(err).to.not.exist;\n              test.equal(2, names.length);\n\n              // Get listCollections filtering out the name\n              var cursor = db1.listCollections({\n                name: 'test.collection1'\n              }, {});\n              cursor.toArray(function (err, names) {\n                expect(err).to.not.exist;\n                test.equal(1, names.length);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"should correctly list collection names with batchSize 1 for 2.8 or higher","suites":["Db"],"updatePoint":{"line":267,"column":79,"index":8139},"line":267,"code":"  it('should correctly list collection names with batchSize 1 for 2.8 or higher', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n\n        // Get a db we that does not have any collections\n        var db1 = client.db('shouldCorrectlyListCollectionsWithDotsOnThemFor28');\n\n        // Create a collection\n        db1.collection('test.collection1').insertOne({\n          a: 1\n        }, function (err) {\n          expect(err).to.not.exist;\n\n          // Create a collection\n          db1.collection('test.collection2').insertOne({\n            a: 1\n          }, function () {\n            expect(err).to.not.exist;\n\n            // Get listCollections filtering out the name\n            var cursor = db1.listCollections({\n              name: /test.collection/\n            }, {\n              batchSize: 1\n            });\n            cursor.toArray(function (err, names) {\n              expect(err).to.not.exist;\n              test.equal(2, names.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"should throw if Db.collection is passed a deprecated callback argument","suites":["Db"],"updatePoint":{"line":313,"column":76,"index":9533},"line":313,"code":"  it('should throw if Db.collection is passed a deprecated callback argument', () => {\n    const client = new MongoClient('mongodb://iLoveJavascript');\n    expect(() => client.db('test').collection('test', () => {})).to.throw('The callback form of this helper has been removed.');\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"supports simple aggregation","suites":["examples.aggregaton:"],"updatePoint":{"line":20,"column":33,"index":603},"line":20,"code":"  it('supports simple aggregation', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.8.0',\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // Start aggregate example 1\n      const cursor = collection.aggregate([{\n        $match: {\n          'items.fruit': 'banana'\n        }\n      }, {\n        $sort: {\n          date: 1\n        }\n      }]);\n      // End aggregate example 1\n    }\n  });","file":"integration/node-specific/examples/aggregate.test.js","skipped":false,"dir":"test"},{"name":"supports $match, $group, $project, $unwind, $sum, $sort, $dayOfWeek","suites":["examples.aggregaton:"],"updatePoint":{"line":42,"column":73,"index":1072},"line":42,"code":"  it('supports $match, $group, $project, $unwind, $sum, $sort, $dayOfWeek', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.8.0',\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // Start aggregate example 2\n      const cursor = collection.aggregate([{\n        $unwind: '$items'\n      }, {\n        $match: {\n          'items.fruit': 'banana'\n        }\n      }, {\n        $group: {\n          _id: {\n            day: {\n              $dayOfWeek: '$date'\n            }\n          },\n          count: {\n            $sum: '$items.quantity'\n          }\n        }\n      }, {\n        $project: {\n          dayOfWeek: '$_id.day',\n          numberSold: '$count',\n          _id: 0\n        }\n      }, {\n        $sort: {\n          numberSold: 1\n        }\n      }]);\n      // End aggregate example 2\n    }\n  });","file":"integration/node-specific/examples/aggregate.test.js","skipped":false,"dir":"test"},{"name":"supports $unwind, $group, $sum, $dayOfWeek, $multiply, $project, $cond","suites":["examples.aggregaton:"],"updatePoint":{"line":83,"column":76,"index":1913},"line":83,"code":"  it('supports $unwind, $group, $sum, $dayOfWeek, $multiply, $project, $cond', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.8.0',\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // Start aggregate example 3\n      const cursor = collection.aggregate([{\n        $unwind: '$items'\n      }, {\n        $group: {\n          _id: {\n            day: {\n              $dayOfWeek: '$date'\n            }\n          },\n          items_sold: {\n            $sum: '$items.quantity'\n          },\n          revenue: {\n            $sum: {\n              $multiply: ['$items.quantity', '$items.price']\n            }\n          }\n        }\n      }, {\n        $project: {\n          day: '$_id.day',\n          revenue: 1,\n          items_sold: 1,\n          discount: {\n            $cond: {\n              if: {\n                $lte: ['$revenue', 250]\n              },\n              then: 25,\n              else: 0\n            }\n          }\n        }\n      }]);\n      // End aggregate example 3\n    }\n  });","file":"integration/node-specific/examples/aggregate.test.js","skipped":false,"dir":"test"},{"name":"supports $lookup, $filter, $match","suites":["examples.aggregaton:"],"updatePoint":{"line":130,"column":39,"index":2900},"line":130,"code":"  it('supports $lookup, $filter, $match', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.6.0',\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // Start aggregate example 4\n      const cursor = collection.aggregate([{\n        $lookup: {\n          from: 'air_airlines',\n          let: {\n            constituents: '$airlines'\n          },\n          pipeline: [{\n            $match: {\n              $expr: {\n                $in: ['$name', '$$constituents']\n              }\n            }\n          }],\n          as: 'airlines'\n        }\n      }, {\n        $project: {\n          _id: 0,\n          name: 1,\n          airlines: {\n            $filter: {\n              input: '$airlines',\n              as: 'airline',\n              cond: {\n                $eq: ['$$airline.country', 'Canada']\n              }\n            }\n          }\n        }\n      }]);\n      // End aggregate example 4\n    }\n  });","file":"integration/node-specific/examples/aggregate.test.js","skipped":false,"dir":"test"},{"name":"supports array filters when updating","suites":["examples(array filters):"],"updatePoint":{"line":19,"column":42,"index":588},"line":19,"code":"  it('supports array filters when updating', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.6.x',\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // 3. Exploiting the power of arrays\n      await collection.updateOne({\n        _id: 1\n      }, {\n        $set: {\n          'a.$[i].b': 2\n        }\n      }, {\n        arrayFilters: [{\n          'i.b': 0\n        }]\n      });\n    }\n  });","file":"integration/node-specific/examples/array_filters.test.js","skipped":false,"dir":"test"},{"name":"returns the databases","suites":["AWS Lambda Examples","#handler","when using aws environment variable authentication"],"updatePoint":{"line":18,"column":31,"index":462},"line":18,"code":"      it('returns the databases', async function () {\n        expect(response.databases).to.exist;\n      });","file":"integration/node-specific/examples/aws_handler.test.js","skipped":false,"dir":"test"},{"name":"returns the status code","suites":["AWS Lambda Examples","#handler","when using aws environment variable authentication"],"updatePoint":{"line":21,"column":33,"index":573},"line":21,"code":"      it('returns the status code', async function () {\n        expect(response.statusCode).to.equal(200);\n      });","file":"integration/node-specific/examples/aws_handler.test.js","skipped":false,"dir":"test"},{"name":"supports causal consistency","suites":["examples(causal-consistency):"],"updatePoint":{"line":25,"column":33,"index":724},"line":25,"code":"  it('supports causal consistency', async function () {\n    const session = client.startSession({\n      causalConsistency: true\n    });\n    collection.insertOne({\n      darmok: 'jalad'\n    }, {\n      session\n    });\n    collection.updateOne({\n      darmok: 'jalad'\n    }, {\n      $set: {\n        darmok: 'tanagra'\n      }\n    }, {\n      session\n    });\n    const results = await collection.find({}, {\n      session\n    }).toArray();\n    expect(results).to.exist;\n    await session.endSession();\n  });","file":"integration/node-specific/examples/causal_consistency.test.js","skipped":false,"dir":"test"},{"name":"Open A Change Stream","suites":[],"updatePoint":{"line":54,"column":26,"index":1412},"line":54,"code":"  it('Open A Change Stream', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.6.0'\n      }\n    },\n    test: async function () {\n      const looper = new Looper(() => db.collection('inventory').insertOne({\n        a: 1\n      }));\n      looper.run();\n\n      // Start Changestream Example 1\n      const collection = db.collection('inventory');\n      const changeStream = collection.watch();\n      changeStream.on('change', next => {\n        // process next document\n      });\n      // End Changestream Example 1\n\n      // Start Changestream Example 1 Alternative\n      const changeStreamIterator = collection.watch();\n      const next = await changeStreamIterator.next();\n      // End Changestream Example 1 Alternative\n\n      await changeStream.close();\n      await changeStreamIterator.close();\n      await looper.stop();\n      expect(next).to.have.property('operationType').that.equals('insert');\n    }\n  });","file":"integration/node-specific/examples/change_streams.test.js","skipped":false,"dir":"test"},{"name":"Lookup Full Document for Update Operations","suites":[],"updatePoint":{"line":86,"column":48,"index":2386},"line":86,"code":"  it('Lookup Full Document for Update Operations', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.6.0'\n      }\n    },\n    test: async function () {\n      await db.collection('inventory').insertOne({\n        a: 1,\n        b: 2\n      });\n      const looper = new Looper(() => db.collection('inventory').updateOne({\n        a: 1\n      }, {\n        $set: {\n          a: 2\n        }\n      }));\n      looper.run();\n\n      // Start Changestream Example 2\n      const collection = db.collection('inventory');\n      const changeStream = collection.watch([], {\n        fullDocument: 'updateLookup'\n      });\n      changeStream.on('change', next => {\n        // process next document\n      });\n      // End Changestream Example 2\n\n      // Start Changestream Example 2 Alternative\n      const changeStreamIterator = collection.watch([], {\n        fullDocument: 'updateLookup'\n      });\n      const next = await changeStreamIterator.next();\n      // End Changestream Example 2 Alternative\n\n      await changeStream.close();\n      await changeStreamIterator.close();\n      await looper.stop();\n      expect(next).to.have.property('operationType').that.equals('update');\n      expect(next).to.have.property('fullDocument').that.has.all.keys(['_id', 'a', 'b']);\n    }\n  });","file":"integration/node-specific/examples/change_streams.test.js","skipped":false,"dir":"test"},{"name":"Resume a Change Stream","suites":[],"updatePoint":{"line":131,"column":28,"index":3670},"line":131,"code":"  it('Resume a Change Stream', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.6.0'\n      }\n    },\n    test: async function () {\n      const looper = new Looper(async () => {\n        await db.collection('inventory').insertOne({\n          a: 1\n        });\n        await db.collection('inventory').insertOne({\n          b: 2\n        });\n      });\n      looper.run();\n      let processChange;\n      const streamExampleFinished = new Promise(resolve => {\n        processChange = resolve;\n      });\n\n      // Start Changestream Example 3\n      const collection = db.collection('inventory');\n      const changeStream = collection.watch();\n      let newChangeStream;\n      changeStream.once('change', next => {\n        const resumeToken = changeStream.resumeToken;\n        changeStream.close();\n        newChangeStream = collection.watch([], {\n          resumeAfter: resumeToken\n        });\n        newChangeStream.on('change', next => {\n          processChange(next);\n        });\n      });\n      // End Changestream Example 3\n\n      // Start Changestream Example 3 Alternative\n      const changeStreamIterator = collection.watch();\n      const change1 = await changeStreamIterator.next();\n      const resumeToken = changeStreamIterator.resumeToken;\n      changeStreamIterator.close();\n      const newChangeStreamIterator = collection.watch([], {\n        resumeAfter: resumeToken\n      });\n      const change2 = await newChangeStreamIterator.next();\n      // End Changestream Example 3 Alternative\n\n      await newChangeStreamIterator.close();\n      await streamExampleFinished;\n      await newChangeStream.close();\n      await looper.stop();\n      expect(change1).to.have.nested.property('fullDocument.a', 1);\n      expect(change2).to.have.nested.property('fullDocument.b', 2);\n    }\n  });","file":"integration/node-specific/examples/change_streams.test.js","skipped":false,"dir":"test"},{"name":"Modify Change Stream Output","suites":[],"updatePoint":{"line":188,"column":33,"index":5503},"line":188,"code":"  it('Modify Change Stream Output', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.6.0'\n      }\n    },\n    test: async function () {\n      const looper = new Looper(async () => {\n        await db.collection('inventory').insertOne({\n          username: 'alice'\n        });\n      });\n      looper.run();\n\n      // Start Changestream Example 4\n      const pipeline = [{\n        $match: {\n          'fullDocument.username': 'alice'\n        }\n      }, {\n        $addFields: {\n          newField: 'this is an added field!'\n        }\n      }];\n      const collection = db.collection('inventory');\n      const changeStream = collection.watch(pipeline);\n      changeStream.on('change', next => {\n        // process next document\n      });\n      // End Changestream Example 4\n\n      // Start Changestream Example 4 Alternative\n      const changeStreamIterator = collection.watch(pipeline);\n      const next = await changeStreamIterator.next();\n      // End Changestream Example 4 Alternative\n\n      await changeStream.close();\n      await changeStreamIterator.close();\n      await looper.stop();\n      expect(next).to.have.nested.property('fullDocument.username', 'alice');\n      expect(next).to.have.property('newField', 'this is an added field!');\n    }\n  });","file":"integration/node-specific/examples/change_streams.test.js","skipped":false,"dir":"test"},{"name":"supports building simple ascending index","suites":["examples.createIndex:"],"updatePoint":{"line":19,"column":46,"index":583},"line":19,"code":"  it('supports building simple ascending index', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // Start createIndex example 1\n      await collection.createIndex({\n        score: 1\n      });\n      // End createIndex example 1\n    }\n  });","file":"integration/node-specific/examples/create_index.test.js","skipped":false,"dir":"test"},{"name":"supports building multikey index with partial filter expression","suites":["examples.createIndex:"],"updatePoint":{"line":34,"column":69,"index":914},"line":34,"code":"  it('supports building multikey index with partial filter expression', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>=3.2.x'\n      }\n    },\n    test: async function () {\n      // Start createIndex example 2\n      await collection.createIndex({\n        cuisine: 1,\n        name: 1\n      }, {\n        partialFilterExpression: {\n          rating: {\n            $gt: 5\n          }\n        }\n      });\n      // End createIndex example 2\n    }\n  });","file":"integration/node-specific/examples/create_index.test.js","skipped":false,"dir":"test"},{"name":"returns the databases","suites":["AWS Lambda Examples","#handler","when using standard authentication"],"updatePoint":{"line":18,"column":31,"index":442},"line":18,"code":"      it('returns the databases', async function () {\n        expect(response.databases).to.exist;\n      });","file":"integration/node-specific/examples/handler.test.js","skipped":false,"dir":"test"},{"name":"returns the status code","suites":["AWS Lambda Examples","#handler","when using standard authentication"],"updatePoint":{"line":21,"column":33,"index":553},"line":21,"code":"      it('returns the status code', async function () {\n        expect(response.statusCode).to.equal(200);\n      });","file":"integration/node-specific/examples/handler.test.js","skipped":false,"dir":"test"},{"name":"Insert a Single Document","suites":["examples(insert):"],"updatePoint":{"line":21,"column":30,"index":598},"line":21,"code":"  it('Insert a Single Document', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 1\n      await db.collection('inventory').insertOne({\n        item: 'canvas',\n        qty: 100,\n        tags: ['cotton'],\n        size: {\n          h: 28,\n          w: 35.5,\n          uom: 'cm'\n        }\n      });\n      // End Example 1\n\n      // Start Example 2\n      const cursor = db.collection('inventory').find({\n        item: 'canvas'\n      });\n      // End Example 2\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/insert.test.js","skipped":false,"dir":"test"},{"name":"Insert Multiple Documents","suites":["examples(insert):"],"updatePoint":{"line":51,"column":31,"index":1228},"line":51,"code":"  it('Insert Multiple Documents', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 3\n      await db.collection('inventory').insertMany([{\n        item: 'journal',\n        qty: 25,\n        tags: ['blank', 'red'],\n        size: {\n          h: 14,\n          w: 21,\n          uom: 'cm'\n        }\n      }, {\n        item: 'mat',\n        qty: 85,\n        tags: ['gray'],\n        size: {\n          h: 27.9,\n          w: 35.5,\n          uom: 'cm'\n        }\n      }, {\n        item: 'mousepad',\n        qty: 25,\n        tags: ['gel', 'blue'],\n        size: {\n          h: 19,\n          w: 22.85,\n          uom: 'cm'\n        }\n      }]);\n      // End Example 3\n\n      expect(await db.collection('inventory').count({})).to.equal(3);\n    }\n  });","file":"integration/node-specific/examples/insert.test.js","skipped":false,"dir":"test"},{"name":"Return All Fields in Matching Documents","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":88,"column":45,"index":1732},"line":88,"code":"  it('Return All Fields in Matching Documents', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 43\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      });\n      // End Example 43\n\n      expect(await cursor.count()).to.equal(3);\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Return the Specified Fields and the ``_id`` Field Only","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":105,"column":60,"index":2130},"line":105,"code":"  it('Return the Specified Fields and the ``_id`` Field Only', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 44\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      }).project({\n        item: 1,\n        status: 1\n      });\n      // End Example 44\n\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.all.keys(['_id', 'item', 'status']);\n        expect(doc).to.not.have.all.keys(['size', 'instock']);\n      });\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Suppress ``_id`` Field","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":129,"column":28,"index":2719},"line":129,"code":"  it('Suppress ``_id`` Field', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 45\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      }).project({\n        item: 1,\n        status: 1,\n        _id: 0\n      });\n      // End Example 45\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.all.keys(['item', 'status']);\n        expect(doc).to.not.have.all.keys(['_id', 'size', 'instock']);\n      });\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Return All But the Excluded Fields","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":153,"column":40,"index":3335},"line":153,"code":"  it('Return All But the Excluded Fields', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 46\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      }).project({\n        status: 0,\n        instock: 0\n      });\n      // End Example 46\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.all.keys(['_id', 'item', 'size']);\n        expect(doc).to.not.have.all.keys(['status', 'instock']);\n      });\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Return Specific Fields in Embedded Documents","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":176,"column":50,"index":3948},"line":176,"code":"  it('Return Specific Fields in Embedded Documents', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 47\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      }).project({\n        item: 1,\n        status: 1,\n        'size.uom': 1\n      });\n      // End Example 47\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.all.keys(['_id', 'item', 'status', 'size']);\n        expect(doc).to.not.have.property('instock');\n        const size = doc.size;\n        expect(size).to.have.property('uom');\n        expect(size).to.not.have.all.keys(['h', 'w']);\n      });\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Suppress Specific Fields in Embedded Documents","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":203,"column":52,"index":4713},"line":203,"code":"  it('Suppress Specific Fields in Embedded Documents', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 48\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      }).project({\n        'size.uom': 0\n      });\n      // End Example 48\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.all.keys(['_id', 'item', 'status', 'size', 'instock']);\n        const size = doc.size;\n        expect(size).to.have.all.keys(['h', 'w']);\n        expect(size).to.not.have.property('uom');\n      });\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Projection on Embedded Documents in an Array","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":227,"column":50,"index":5398},"line":227,"code":"  it('Projection on Embedded Documents in an Array', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 49\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      }).project({\n        item: 1,\n        status: 1,\n        'instock.qty': 1\n      });\n      // End Example 49\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.all.keys(['_id', 'item', 'status', 'instock']);\n        expect(doc).to.not.have.property('size');\n        doc.instock.forEach(function (subdoc) {\n          expect(subdoc).to.have.property('qty');\n          expect(subdoc).to.not.have.property('warehouse');\n        });\n      });\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Project Specific Array Elements in the Returned Array","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":255,"column":59,"index":6211},"line":255,"code":"  it('Project Specific Array Elements in the Returned Array', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 50\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      }).project({\n        item: 1,\n        status: 1,\n        instock: {\n          $slice: -1\n        }\n      });\n      // End Example 50\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.all.keys(['_id', 'item', 'status', 'instock']);\n        expect(doc).to.not.have.property('size');\n        expect(doc).to.have.property('instock').with.a.lengthOf(1);\n      });\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Query for a Document Nested in an Array","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":67,"column":45,"index":1425},"line":67,"code":"  it('Query for a Document Nested in an Array', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 30\n      const cursor = db.collection('inventory').find({\n        instock: {\n          warehouse: 'A',\n          qty: 5\n        }\n      });\n      // End Example 30\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"Query for a Document Nested in an Array - document order","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":87,"column":62,"index":1877},"line":87,"code":"  it('Query for a Document Nested in an Array - document order', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 31\n      const cursor = db.collection('inventory').find({\n        instock: {\n          qty: 5,\n          warehouse: 'A'\n        }\n      });\n      // End Example 31\n\n      expect(await cursor.count()).to.equal(0);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"Use the Array Index to Query for a Field in the Embedded Document","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":107,"column":71,"index":2338},"line":107,"code":"  it('Use the Array Index to Query for a Field in the Embedded Document', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 32\n      const cursor = db.collection('inventory').find({\n        'instock.0.qty': {\n          $lte: 20\n        }\n      });\n      // End Example 32\n\n      expect(await cursor.count()).to.equal(3);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"Specify a Query Condition on a Field Embedded in an Array of Documents","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":126,"column":76,"index":2788},"line":126,"code":"  it('Specify a Query Condition on a Field Embedded in an Array of Documents', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 33\n      const cursor = db.collection('inventory').find({\n        'instock.qty': {\n          $lte: 20\n        }\n      });\n      // End Example 33\n\n      expect(await cursor.count()).to.equal(5);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"A Single Nested Document Meets Multiple Query Conditions on Nested Fields","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":145,"column":79,"index":3239},"line":145,"code":"  it('A Single Nested Document Meets Multiple Query Conditions on Nested Fields', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 34\n      const cursor = db.collection('inventory').find({\n        instock: {\n          $elemMatch: {\n            qty: 5,\n            warehouse: 'A'\n          }\n        }\n      });\n      // End Example 34\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"A Single Nested Document Meets Multiple Query Conditions on Nested Fields: operators","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":167,"column":90,"index":3759},"line":167,"code":"  it('A Single Nested Document Meets Multiple Query Conditions on Nested Fields: operators', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 35\n      const cursor = db.collection('inventory').find({\n        instock: {\n          $elemMatch: {\n            qty: {\n              $gt: 10,\n              $lte: 20\n            }\n          }\n        }\n      });\n      // End Example 35\n\n      expect(await cursor.count()).to.equal(3);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"Combination of Elements Satisfies the Criteria","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":191,"column":52,"index":4273},"line":191,"code":"  it('Combination of Elements Satisfies the Criteria', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 36\n      const cursor = db.collection('inventory').find({\n        'instock.qty': {\n          $gt: 10,\n          $lte: 20\n        }\n      });\n      // End Example 36\n\n      expect(await cursor.count()).to.equal(4);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"Combination of Elements Satisfies the Criteria 2","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":211,"column":54,"index":4718},"line":211,"code":"  it('Combination of Elements Satisfies the Criteria 2', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 37\n      const cursor = db.collection('inventory').find({\n        'instock.qty': 5,\n        'instock.warehouse': 'A'\n      });\n      // End Example 37\n\n      expect(await cursor.count()).to.equal(2);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"Match an Array","suites":["examples(query-arrays):"],"updatePoint":{"line":50,"column":20,"index":1200},"line":50,"code":"  it('Match an Array', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 21\n      const cursor = db.collection('inventory').find({\n        tags: ['red', 'blank']\n      });\n      // End Example 21\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Match an Array: $all","suites":["examples(query-arrays):"],"updatePoint":{"line":67,"column":26,"index":1575},"line":67,"code":"  it('Match an Array: $all', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 22\n      const cursor = db.collection('inventory').find({\n        tags: {\n          $all: ['red', 'blank']\n        }\n      });\n      // End Example 22\n\n      expect(await cursor.count()).to.equal(4);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Query an Array for an Element","suites":["examples(query-arrays):"],"updatePoint":{"line":86,"column":35,"index":1987},"line":86,"code":"  it('Query an Array for an Element', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 23\n      const cursor = db.collection('inventory').find({\n        tags: 'red'\n      });\n      // End Example 23\n\n      expect(await cursor.count()).to.equal(4);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Query an Array for an Element w/ operators","suites":["examples(query-arrays):"],"updatePoint":{"line":103,"column":48,"index":2373},"line":103,"code":"  it('Query an Array for an Element w/ operators', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 24\n      const cursor = db.collection('inventory').find({\n        dim_cm: {\n          $gt: 25\n        }\n      });\n      // End Example 24\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Query an Array with Compound Filter Conditions on the Array Elements","suites":["examples(query-arrays):"],"updatePoint":{"line":122,"column":74,"index":2811},"line":122,"code":"  it('Query an Array with Compound Filter Conditions on the Array Elements', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 25\n      const cursor = db.collection('inventory').find({\n        dim_cm: {\n          $gt: 15,\n          $lt: 20\n        }\n      });\n      // End Example 25\n\n      expect(await cursor.count()).to.equal(4);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Query for an Array Element that Meets Multiple Criteria","suites":["examples(query-arrays):"],"updatePoint":{"line":142,"column":61,"index":3255},"line":142,"code":"  it('Query for an Array Element that Meets Multiple Criteria', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 26\n      const cursor = db.collection('inventory').find({\n        dim_cm: {\n          $elemMatch: {\n            $gt: 22,\n            $lt: 30\n          }\n        }\n      });\n      // End Example 26\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Query for an Element by the Array Index Position","suites":["examples(query-arrays):"],"updatePoint":{"line":164,"column":54,"index":3732},"line":164,"code":"  it('Query for an Element by the Array Index Position', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 27\n      const cursor = db.collection('inventory').find({\n        'dim_cm.1': {\n          $gt: 25\n        }\n      });\n      // End Example 27\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Query an Array by Array Length","suites":["examples(query-arrays):"],"updatePoint":{"line":183,"column":36,"index":4136},"line":183,"code":"  it('Query an Array by Array Length', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 28\n      const cursor = db.collection('inventory').find({\n        tags: {\n          $size: 3\n        }\n      });\n      // End Example 28\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Match an Embedded/Nested Document","suites":["examples(query-embedded-documents):"],"updatePoint":{"line":70,"column":39,"index":1412},"line":70,"code":"  it('Match an Embedded/Nested Document', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 15\n      const cursor = db.collection('inventory').find({\n        size: {\n          h: 14,\n          w: 21,\n          uom: 'cm'\n        }\n      });\n      // End Example 15\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_embedded_documents.test.js","skipped":false,"dir":"test"},{"name":"Match an Embedded/Nested Document - document order","suites":["examples(query-embedded-documents):"],"updatePoint":{"line":91,"column":56,"index":1866},"line":91,"code":"  it('Match an Embedded/Nested Document - document order', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 16\n      const cursor = db.collection('inventory').find({\n        size: {\n          w: 21,\n          h: 14,\n          uom: 'cm'\n        }\n      });\n      // End Example 16\n\n      expect(await cursor.count()).to.equal(0);\n    }\n  });","file":"integration/node-specific/examples/query_embedded_documents.test.js","skipped":false,"dir":"test"},{"name":"Specify Equality Match on a Nested Field","suites":["examples(query-embedded-documents):"],"updatePoint":{"line":112,"column":46,"index":2310},"line":112,"code":"  it('Specify Equality Match on a Nested Field', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 17\n      const cursor = db.collection('inventory').find({\n        'size.uom': 'in'\n      });\n      // End Example 17\n\n      expect(await cursor.count()).to.equal(2);\n    }\n  });","file":"integration/node-specific/examples/query_embedded_documents.test.js","skipped":false,"dir":"test"},{"name":"Specify Match using Query Operator","suites":["examples(query-embedded-documents):"],"updatePoint":{"line":129,"column":40,"index":2693},"line":129,"code":"  it('Specify Match using Query Operator', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 18\n      const cursor = db.collection('inventory').find({\n        'size.h': {\n          $lt: 15\n        }\n      });\n      // End Example 18\n\n      expect(await cursor.count()).to.equal(4);\n    }\n  });","file":"integration/node-specific/examples/query_embedded_documents.test.js","skipped":false,"dir":"test"},{"name":"Specify ``AND`` Condition","suites":["examples(query-embedded-documents):"],"updatePoint":{"line":148,"column":31,"index":3090},"line":148,"code":"  it('Specify ``AND`` Condition', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 19\n      const cursor = db.collection('inventory').find({\n        'size.h': {\n          $lt: 15\n        },\n        'size.uom': 'in',\n        status: 'D'\n      });\n      // End Example 19\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_embedded_documents.test.js","skipped":false,"dir":"test"},{"name":"Equality Filter","suites":["examples(query-for-null-fields):"],"updatePoint":{"line":30,"column":21,"index":764},"line":30,"code":"  it('Equality Filter', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 39\n      const cursor = db.collection('inventory').find({\n        item: null\n      });\n      // End Example 39\n\n      expect(await cursor.count()).to.equal(2);\n    }\n  });","file":"integration/node-specific/examples/query_for_null_fields.test.js","skipped":false,"dir":"test"},{"name":"Type Check","suites":["examples(query-for-null-fields):"],"updatePoint":{"line":47,"column":16,"index":1117},"line":47,"code":"  it('Type Check', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 40\n      const cursor = db.collection('inventory').find({\n        item: {\n          $type: 10\n        }\n      });\n      // End Example 40\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_for_null_fields.test.js","skipped":false,"dir":"test"},{"name":"Existence Check","suites":["examples(query-for-null-fields):"],"updatePoint":{"line":66,"column":21,"index":1502},"line":66,"code":"  it('Existence Check', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 41\n      const cursor = db.collection('inventory').find({\n        item: {\n          $exists: false\n        }\n      });\n      // End Example 41\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_for_null_fields.test.js","skipped":false,"dir":"test"},{"name":"select all documents in a collection","suites":["examples(query):"],"updatePoint":{"line":70,"column":42,"index":1394},"line":70,"code":"  it('select all documents in a collection', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 7\n      const cursor = db.collection('inventory').find({});\n      // End Example 7\n\n      expect(await cursor.count()).to.equal(5);\n    }\n  });","file":"integration/node-specific/examples/query.test.js","skipped":false,"dir":"test"},{"name":"Specify Equality Condition","suites":["examples(query):"],"updatePoint":{"line":85,"column":32,"index":1735},"line":85,"code":"  it('Specify Equality Condition', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 9\n      const cursor = db.collection('inventory').find({\n        status: 'D'\n      });\n      // End Example 9\n\n      expect(await cursor.count()).to.equal(2);\n    }\n  });","file":"integration/node-specific/examples/query.test.js","skipped":false,"dir":"test"},{"name":"Specify Conditions Using Query Operators","suites":["examples(query):"],"updatePoint":{"line":102,"column":46,"index":2117},"line":102,"code":"  it('Specify Conditions Using Query Operators', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 10\n      const cursor = db.collection('inventory').find({\n        status: {\n          $in: ['A', 'D']\n        }\n      });\n      // End Example 10\n      expect(await cursor.count()).to.equal(5);\n    }\n  });","file":"integration/node-specific/examples/query.test.js","skipped":false,"dir":"test"},{"name":"Specify ``AND`` Condition","suites":["examples(query):"],"updatePoint":{"line":120,"column":31,"index":2519},"line":120,"code":"  it('Specify ``AND`` Condition', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 11\n      const cursor = db.collection('inventory').find({\n        status: 'A',\n        qty: {\n          $lt: 30\n        }\n      });\n      // End Example 11\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query.test.js","skipped":false,"dir":"test"},{"name":"Specify ``OR`` Condition","suites":["examples(query):"],"updatePoint":{"line":139,"column":30,"index":2930},"line":139,"code":"  it('Specify ``OR`` Condition', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 12\n      const cursor = db.collection('inventory').find({\n        $or: [{\n          status: 'A'\n        }, {\n          qty: {\n            $lt: 30\n          }\n        }]\n      });\n      // End Example 12\n      expect(await cursor.count()).to.equal(3);\n    }\n  });","file":"integration/node-specific/examples/query.test.js","skipped":false,"dir":"test"},{"name":"Specify ``AND`` as well as ``OR`` Conditions","suites":["examples(query):"],"updatePoint":{"line":161,"column":50,"index":3408},"line":161,"code":"  it('Specify ``AND`` as well as ``OR`` Conditions', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 13\n      const cursor = db.collection('inventory').find({\n        status: 'A',\n        $or: [{\n          qty: {\n            $lt: 30\n          }\n        }, {\n          item: {\n            $regex: '^p'\n          }\n        }]\n      });\n      // End Example 13\n      expect(await cursor.count()).to.equal(2);\n    }\n  });","file":"integration/node-specific/examples/query.test.js","skipped":false,"dir":"test"},{"name":"Delete All Documents","suites":["examples(remove-documents):"],"updatePoint":{"line":70,"column":26,"index":1391},"line":70,"code":"  it('Delete All Documents', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 56\n      await db.collection('inventory').deleteMany({});\n      // End Example 56\n      const cursor = db.collection('inventory').find({});\n      expect(await cursor.count()).to.equal(0);\n    }\n  });","file":"integration/node-specific/examples/remove_documents.test.js","skipped":false,"dir":"test"},{"name":"Delete All Documents that Match a Condition","suites":["examples(remove-documents):"],"updatePoint":{"line":85,"column":49,"index":1805},"line":85,"code":"  it('Delete All Documents that Match a Condition', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 57\n      await db.collection('inventory').deleteMany({\n        status: 'A'\n      });\n      // End Example 57\n      const cursor = db.collection('inventory').find({});\n      expect(await cursor.count()).to.equal(3);\n    }\n  });","file":"integration/node-specific/examples/remove_documents.test.js","skipped":false,"dir":"test"},{"name":"Delete Only One Document that Matches a Condition","suites":["examples(remove-documents):"],"updatePoint":{"line":102,"column":55,"index":2252},"line":102,"code":"  it('Delete Only One Document that Matches a Condition', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 58\n      await db.collection('inventory').deleteOne({\n        status: 'D'\n      });\n      // End Example 58\n      const cursor = db.collection('inventory').find({});\n      expect(await cursor.count()).to.equal(4);\n    }\n  });","file":"integration/node-specific/examples/remove_documents.test.js","skipped":false,"dir":"test"},{"name":"supports runCommand 1","suites":["examples.runCommand:"],"updatePoint":{"line":22,"column":27,"index":607},"line":22,"code":"  it('supports runCommand 1', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // Start runCommand example 1\n      await db.command({\n        buildInfo: 1\n      });\n      // End runCommand example 1\n    }\n  });","file":"integration/node-specific/examples/run_command.test.js","skipped":false,"dir":"test"},{"name":"supports runCommand 2","suites":["examples.runCommand:"],"updatePoint":{"line":37,"column":27,"index":886},"line":37,"code":"  it('supports runCommand 2', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // Start runCommand example 2\n      await db.command({\n        collStats: 'restaurants'\n      });\n      // End runCommand example 2\n    }\n  });","file":"integration/node-specific/examples/run_command.test.js","skipped":false,"dir":"test"},{"name":"Transactions Retry Example 1","suites":["examples(transactions):"],"updatePoint":{"line":25,"column":34,"index":776},"line":25,"code":"  it('Transactions Retry Example 1', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.8.0'\n      }\n    },\n    test: async function () {\n      // Start Transactions Retry Example 1\n      async function runTransactionWithRetry(txnFunc, client, session) {\n        try {\n          await txnFunc(client, session);\n        } catch (error) {\n          console.log('Transaction aborted. Caught exception during transaction.');\n\n          // If transient error, retry the whole transaction\n          if (error.hasErrorLabel('TransientTransactionError')) {\n            console.log('TransientTransactionError, retrying transaction ...');\n            await runTransactionWithRetry(txnFunc, client, session);\n          } else {\n            throw error;\n          }\n        }\n      }\n      // End Transactions Retry Example 1\n\n      async function updateEmployeeInfo(client, session) {\n        session.startTransaction({\n          readConcern: {\n            level: 'snapshot'\n          },\n          writeConcern: {\n            w: 'majority'\n          },\n          readPreference: 'primary'\n        });\n        const employeesCollection = client.db('hr').collection('employees');\n        const eventsCollection = client.db('reporting').collection('events');\n        await employeesCollection.updateOne({\n          employee: 3\n        }, {\n          $set: {\n            status: 'Inactive'\n          }\n        }, {\n          session\n        });\n        await eventsCollection.insertOne({\n          employee: 3,\n          status: {\n            new: 'Inactive',\n            old: 'Active'\n          }\n        }, {\n          session\n        });\n        try {\n          await session.commitTransaction();\n        } catch (error) {\n          await session.abortTransaction();\n          throw error;\n        }\n      }\n      return client.withSession(session => runTransactionWithRetry(updateEmployeeInfo, client, session));\n    }\n  });","file":"integration/node-specific/examples/transactions.test.js","skipped":false,"dir":"test"},{"name":"Transactions Retry Example 2","suites":["examples(transactions):"],"updatePoint":{"line":91,"column":34,"index":2731},"line":91,"code":"  it('Transactions Retry Example 2', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.8.0'\n      }\n    },\n    test: async function () {\n      // Start Transactions Retry Example 2\n      async function commitWithRetry(session) {\n        try {\n          await session.commitTransaction();\n          console.log('Transaction committed.');\n        } catch (error) {\n          if (error.hasErrorLabel('UnknownTransactionCommitResult')) {\n            console.log('UnknownTransactionCommitResult, retrying commit operation ...');\n            await commitWithRetry(session);\n          } else {\n            console.log('Error during commit ...');\n            throw error;\n          }\n        }\n      }\n      // End Transactions Retry Example 2\n\n      async function updateEmployeeInfo(client, session) {\n        session.startTransaction({\n          readConcern: {\n            level: 'snapshot'\n          },\n          writeConcern: {\n            w: 'majority'\n          },\n          readPreference: 'primary'\n        });\n        const employeesCollection = client.db('hr').collection('employees');\n        const eventsCollection = client.db('reporting').collection('events');\n        await employeesCollection.updateOne({\n          employee: 3\n        }, {\n          $set: {\n            status: 'Inactive'\n          }\n        }, {\n          session\n        });\n        await eventsCollection.insertOne({\n          employee: 3,\n          status: {\n            new: 'Inactive',\n            old: 'Active'\n          }\n        }, {\n          session\n        });\n        try {\n          await commitWithRetry(session);\n        } catch (error) {\n          await session.abortTransaction();\n          throw error;\n        }\n      }\n      return client.withSession(session => updateEmployeeInfo(client, session));\n    }\n  });","file":"integration/node-specific/examples/transactions.test.js","skipped":false,"dir":"test"},{"name":"Transaction Retry Example 3","suites":["examples(transactions):"],"updatePoint":{"line":156,"column":33,"index":4580},"line":156,"code":"  it('Transaction Retry Example 3', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.8.0'\n      }\n    },\n    test: async function () {\n      // Start Transactions Retry Example 3\n      async function commitWithRetry(session) {\n        try {\n          await session.commitTransaction();\n          console.log('Transaction committed.');\n        } catch (error) {\n          if (error.hasErrorLabel('UnknownTransactionCommitResult')) {\n            console.log('UnknownTransactionCommitResult, retrying commit operation ...');\n            await commitWithRetry(session);\n          } else {\n            console.log('Error during commit ...');\n            throw error;\n          }\n        }\n      }\n      async function runTransactionWithRetry(txnFunc, client, session) {\n        try {\n          await txnFunc(client, session);\n        } catch (error) {\n          console.log('Transaction aborted. Caught exception during transaction.');\n\n          // If transient error, retry the whole transaction\n          if (error.hasErrorLabel('TransientTransactionError')) {\n            console.log('TransientTransactionError, retrying transaction ...');\n            await runTransactionWithRetry(txnFunc, client, session);\n          } else {\n            throw error;\n          }\n        }\n      }\n      async function updateEmployeeInfo(client, session) {\n        session.startTransaction({\n          readConcern: {\n            level: 'snapshot'\n          },\n          writeConcern: {\n            w: 'majority'\n          },\n          readPreference: 'primary'\n        });\n        const employeesCollection = client.db('hr').collection('employees');\n        const eventsCollection = client.db('reporting').collection('events');\n        await employeesCollection.updateOne({\n          employee: 3\n        }, {\n          $set: {\n            status: 'Inactive'\n          }\n        }, {\n          session\n        });\n        await eventsCollection.insertOne({\n          employee: 3,\n          status: {\n            new: 'Inactive',\n            old: 'Active'\n          }\n        }, {\n          session\n        });\n        try {\n          await commitWithRetry(session);\n        } catch (error) {\n          await session.abortTransaction();\n          throw error;\n        }\n      }\n      return client.withSession(session => runTransactionWithRetry(updateEmployeeInfo, client, session));\n      // End Transactions Retry Example 3\n    }\n  });","file":"integration/node-specific/examples/transactions.test.js","skipped":false,"dir":"test"},{"name":"Transactions withTransaction API Example 1","suites":["examples(transactions):"],"updatePoint":{"line":236,"column":48,"index":7059},"line":236,"code":"  it('Transactions withTransaction API Example 1', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.8.0'\n      }\n    },\n    test: async function () {\n      const uri = this.configuration.url();\n\n      // Start Transactions withTxn API Example 1\n\n      // For a replica set, include the replica set name and a seedlist of the members in the URI string; e.g.\n      // const uri = 'mongodb://mongodb0.example.com:27017,mongodb1.example.com:27017/?replicaSet=myRepl'\n      // For a sharded cluster, connect to the mongos instances; e.g.\n      // const uri = 'mongodb://mongos0.example.com:27017,mongos1.example.com:27017/'\n\n      const client = new MongoClient(uri);\n      await client.connect();\n\n      // Prereq: Create collections.\n\n      await client.db('mydb1').collection('foo').insertOne({\n        abc: 0\n      }, {\n        writeConcern: {\n          w: 'majority'\n        }\n      });\n      await client.db('mydb2').collection('bar').insertOne({\n        xyz: 0\n      }, {\n        writeConcern: {\n          w: 'majority'\n        }\n      });\n\n      // Step 1: Start a Client Session\n      const session = client.startSession();\n\n      // Step 2: Optional. Define options to use for the transaction\n      const transactionOptions = {\n        readPreference: 'primary',\n        readConcern: {\n          level: 'local'\n        },\n        writeConcern: {\n          w: 'majority'\n        }\n      };\n\n      // Step 3: Use withTransaction to start a transaction, execute the callback, and commit (or abort on error)\n      // Note: The callback for withTransaction MUST be async and/or return a Promise.\n      try {\n        await session.withTransaction(async () => {\n          const coll1 = client.db('mydb1').collection('foo');\n          const coll2 = client.db('mydb2').collection('bar');\n\n          // Important:: You must pass the session to the operations\n\n          await coll1.insertOne({\n            abc: 1\n          }, {\n            session\n          });\n          await coll2.insertOne({\n            xyz: 999\n          }, {\n            session\n          });\n        }, transactionOptions);\n      } finally {\n        await session.endSession();\n        await client.close();\n      }\n      // End Transactions withTxn API Example 1\n    }\n  });","file":"integration/node-specific/examples/transactions.test.js","skipped":false,"dir":"test"},{"name":"Update a Single Document","suites":["examples(update-documents):"],"updatePoint":{"line":115,"column":30,"index":2092},"line":115,"code":"  it('Update a Single Document', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 52\n      await db.collection('inventory').updateOne({\n        item: 'paper'\n      }, {\n        $set: {\n          'size.uom': 'cm',\n          status: 'P'\n        },\n        $currentDate: {\n          lastModified: true\n        }\n      });\n      // End Example 52\n      const cursor = db.collection('inventory').find({\n        item: 'paper'\n      });\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.nested.property('size.uom').that.equals('cm');\n        expect(doc).to.have.property('status').that.equals('P');\n        expect(doc).to.have.property('lastModified');\n      });\n    }\n  });","file":"integration/node-specific/examples/update_documents.test.js","skipped":false,"dir":"test"},{"name":"Update Multiple Documents","suites":["examples(update-documents):"],"updatePoint":{"line":147,"column":31,"index":2931},"line":147,"code":"  it('Update Multiple Documents', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 53\n      await db.collection('inventory').updateMany({\n        qty: {\n          $lt: 50\n        }\n      }, {\n        $set: {\n          'size.uom': 'in',\n          status: 'P'\n        },\n        $currentDate: {\n          lastModified: true\n        }\n      });\n      // End Example 53\n\n      const cursor = db.collection('inventory').find({\n        qty: {\n          $lt: 50\n        }\n      });\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.nested.property('size.uom').that.equals('in');\n        expect(doc).to.have.property('status').that.equals('P');\n        expect(doc).to.have.property('lastModified');\n      });\n    }\n  });","file":"integration/node-specific/examples/update_documents.test.js","skipped":false,"dir":"test"},{"name":"Replace a Document","suites":["examples(update-documents):"],"updatePoint":{"line":184,"column":24,"index":3807},"line":184,"code":"  it('Replace a Document', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 54\n      await db.collection('inventory').replaceOne({\n        item: 'paper'\n      }, {\n        item: 'paper',\n        instock: [{\n          warehouse: 'A',\n          qty: 60\n        }, {\n          warehouse: 'B',\n          qty: 40\n        }]\n      });\n      // End Example 54\n\n      const cursor = db.collection('inventory').find({\n        item: 'paper'\n      }).project({\n        _id: 0\n      });\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(Object.keys(doc)).to.have.a.lengthOf(2);\n        expect(doc).to.have.property('item');\n        expect(doc).to.have.property('instock').that.has.a.lengthOf(2);\n      });\n    }\n  });","file":"integration/node-specific/examples/update_documents.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformMapReduceWithStringFunctions","suites":["MapReduce"],"updatePoint":{"line":21,"column":47,"index":380},"line":21,"code":"  it('shouldPerformMapReduceWithStringFunctions', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_map_reduce', function (err, collection) {\n          collection.insert([{\n            user_id: 1\n          }, {\n            user_id: 2\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // String functions\n            var map = 'function() { emit(this.user_id, 1); }';\n            var reduce = 'function(k,vals) { return 1; }';\n            collection.mapReduce(map, reduce, {\n              out: {\n                replace: 'tempCollection'\n              }\n            }, function (err, collection) {\n              collection.findOne({\n                _id: 1\n              }, function (err, result) {\n                test.equal(1, result.value);\n                collection.findOne({\n                  _id: 2\n                }, function (err, result) {\n                  test.equal(1, result.value);\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/mapreduce.test.js","skipped":false,"dir":"test"},{"name":"shouldForceMapReduceError","suites":["MapReduce"],"updatePoint":{"line":71,"column":31,"index":1864},"line":71,"code":"  it('shouldForceMapReduceError', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>1.7.6',\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(configuration.db);\n        db.createCollection('should_force_map_reduce_error', function (err, collection) {\n          collection.insert([{\n            user_id: 1\n          }, {\n            user_id: 2\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            // String functions\n            var map = 'function() { emiddft(this.user_id, 1); }';\n            var reduce = 'function(k,vals) { return 1; }';\n            collection.mapReduce(map, reduce, {\n              out: {\n                inline: 1\n              }\n            }, function (err) {\n              test.ok(err != null);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/mapreduce.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformMapReduceWithParametersBeingFunctions","suites":["MapReduce"],"updatePoint":{"line":111,"column":56,"index":3215},"line":111,"code":"  it('shouldPerformMapReduceWithParametersBeingFunctions', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_map_reduce_with_functions_as_arguments', function (err, collection) {\n          expect(err).to.not.exist;\n          collection.insert([{\n            user_id: 1\n          }, {\n            user_id: 2\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // String functions\n            var map = function () {\n              emit(this.user_id, 1); // eslint-disable-line\n            };\n\n            var reduce = function () {\n              return 1;\n            };\n            collection.mapReduce(map, reduce, {\n              out: {\n                replace: 'tempCollection'\n              }\n            }, function (err, collection) {\n              collection.findOne({\n                _id: 1\n              }, function (err, result) {\n                test.equal(1, result.value);\n                collection.findOne({\n                  _id: 2\n                }, function (err, result) {\n                  test.equal(1, result.value);\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/mapreduce.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformMapReduceWithCodeObjects","suites":["MapReduce"],"updatePoint":{"line":163,"column":43,"index":4809},"line":163,"code":"  it('shouldPerformMapReduceWithCodeObjects', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_map_reduce_with_code_objects', function (err, collection) {\n          collection.insert([{\n            user_id: 1\n          }, {\n            user_id: 2\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            // String functions\n            var map = new Code('function() { emit(this.user_id, 1); }');\n            var reduce = new Code('function(k,vals) { return 1; }');\n            collection.mapReduce(map, reduce, {\n              out: {\n                replace: 'tempCollection'\n              }\n            }, function (err, collection) {\n              collection.findOne({\n                _id: 1\n              }, function (err, result) {\n                test.equal(1, result.value);\n                collection.findOne({\n                  _id: 2\n                }, function (err, result) {\n                  test.equal(1, result.value);\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/mapreduce.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformMapReduceWithOptions","suites":["MapReduce"],"updatePoint":{"line":208,"column":39,"index":6304},"line":208,"code":"  it('shouldPerformMapReduceWithOptions', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_map_reduce_with_options', function (err, collection) {\n          collection.insert([{\n            user_id: 1\n          }, {\n            user_id: 2\n          }, {\n            user_id: 3\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            // String functions\n            var map = new Code('function() { emit(this.user_id, 1); }');\n            var reduce = new Code('function(k,vals) { return 1; }');\n            collection.mapReduce(map, reduce, {\n              out: {\n                replace: 'tempCollection'\n              },\n              query: {\n                user_id: {\n                  $gt: 1\n                }\n              }\n            }, function (err, collection) {\n              collection.count(function (err, count) {\n                test.equal(2, count);\n                collection.findOne({\n                  _id: 2\n                }, function (err, result) {\n                  test.equal(1, result.value);\n                  collection.findOne({\n                    _id: 3\n                  }, function (err, result) {\n                    test.equal(1, result.value);\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/mapreduce.test.js","skipped":false,"dir":"test"},{"name":"shouldHandleMapReduceErrors","suites":["MapReduce"],"updatePoint":{"line":263,"column":33,"index":8069},"line":263,"code":"  it('shouldHandleMapReduceErrors', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_map_reduce_error', function (err, collection) {\n          collection.insert([{\n            user_id: 1\n          }, {\n            user_id: 2\n          }, {\n            user_id: 3\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            // String functions\n            var map = new Code(\"function() { throw 'error'; }\");\n            var reduce = new Code(\"function(k,vals) { throw 'error'; }\");\n            collection.mapReduce(map, reduce, {\n              out: {\n                inline: 1\n              },\n              query: {\n                user_id: {\n                  $gt: 1\n                }\n              }\n            }, function (err) {\n              test.ok(err != null);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/mapreduce.test.js","skipped":false,"dir":"test"},{"name":"shouldSaveDataToDifferentDbFromMapreduce","suites":["MapReduce"],"updatePoint":{"line":306,"column":46,"index":9372},"line":306,"code":"  it('shouldSaveDataToDifferentDbFromMapreduce', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded'],\n        mongodb: '>= 3.4'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        const outDb = client.db('outputCollectionDb');\n\n        // Create a test collection\n        db.createCollection('test_map_reduce_functions', function (err, collection) {\n          // create the output collection\n          outDb.createCollection('tempCollection', err => {\n            expect(err).to.not.exist;\n\n            // Insert some documents to perform map reduce over\n            collection.insert([{\n              user_id: 1\n            }, {\n              user_id: 2\n            }], configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist;\n              // Map function\n              var map = function () {\n                emit(this.user_id, 1); // eslint-disable-line\n              };\n              // Reduce function\n              var reduce = function () {\n                return 1;\n              };\n\n              // Perform the map reduce\n              collection.mapReduce(map, reduce, {\n                out: {\n                  replace: 'test_map_reduce_functions_temp',\n                  db: 'outputCollectionDb'\n                }\n              }, function (err, collection) {\n                expect(err).to.not.exist;\n\n                // Mapreduce returns the temporary collection with the results\n                collection.findOne({\n                  _id: 1\n                }, function (err, result) {\n                  expect(err).to.not.exist;\n                  test.equal(1, result.value);\n                  collection.findOne({\n                    _id: 2\n                  }, function (err, result) {\n                    expect(err).to.not.exist;\n                    test.equal(1, result.value);\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/mapreduce.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformMapReduceWithScopeContainingFunction","suites":["MapReduce"],"line":378,"code":"  it.skip('shouldPerformMapReduceWithScopeContainingFunction', {","file":"integration/node-specific/mapreduce.test.js","skipped":true,"dir":"test"},{"name":"aggregationExample1","suites":["Operation Examples"],"updatePoint":{"line":44,"column":25,"index":1125},"line":44,"code":"  it('aggregationExample1', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Some docs for insertion\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }];\n\n        // Create a collection\n        var collection = db.collection('aggregationExample1');\n        // Insert the docs\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          expect(err).to.not.exist;\n          test.ok(result);\n\n          // Execute aggregate, notice the pipeline is expressed as an Array\n          const cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }, {\n            $sort: {\n              _id: -1\n            }\n          }]);\n          cursor.toArray(function (err, result) {\n            expect(err).to.not.exist;\n            test.equal('good', result[0]._id.tags);\n            test.deepEqual(['bob'], result[0].authors);\n            test.equal('fun', result[1]._id.tags);\n            test.deepEqual(['bob'], result[1].authors);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"aggregationExample2","suites":["Operation Examples"],"updatePoint":{"line":142,"column":25,"index":4050},"line":142,"code":"  it('aggregationExample2', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Some docs for insertion\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }];\n\n        // Create a collection\n        var collection = db.collection('aggregationExample2');\n        // Insert the docs\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          expect(err).to.not.exist;\n          test.ok(result);\n\n          // Execute aggregate, notice the pipeline is expressed as an Array\n          var cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }], {\n            cursor: {\n              batchSize: 1\n            }\n          });\n\n          // Get all the aggregation results\n          cursor.toArray(function (err, docs) {\n            expect(err).to.not.exist;\n            test.equal(2, docs.length);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Aggregation Cursor toArray Test","suites":["Operation Examples"],"updatePoint":{"line":239,"column":37,"index":6877},"line":239,"code":"  it('Aggregation Cursor toArray Test', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Some docs for insertion\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }];\n\n        // Create a collection\n        var collection = db.collection('aggregation_toArray_example');\n        // Insert the docs\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          expect(err).to.not.exist;\n          test.ok(result);\n\n          // Execute aggregate, notice the pipeline is expressed as an Array\n          var cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }], {\n            cursor: {\n              batchSize: 1\n            }\n          });\n\n          // Get all the aggregation results\n          cursor.toArray(function (err, docs) {\n            expect(err).to.not.exist;\n            test.equal(2, docs.length);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Aggregation Cursor toArray Test","suites":["Operation Examples"],"updatePoint":{"line":336,"column":37,"index":9706},"line":336,"code":"  it('Aggregation Cursor toArray Test', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Some docs for insertion\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }];\n\n        // Create a collection\n        var collection = db.collection('aggregation_next_example');\n        // Insert the docs\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, (err, result) => {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Execute aggregate, notice the pipeline is expressed as an Array\n          var cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }], {\n            cursor: {\n              batchSize: 1\n            }\n          });\n          this.defer(() => cursor.close());\n\n          // Get all the aggregation results\n          cursor.next((err, docs) => {\n            test.ok(docs);\n            expect(err).to.not.exist;\n            done();\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Aggregation Cursor each Test","suites":["Operation Examples"],"updatePoint":{"line":436,"column":34,"index":12603},"line":436,"code":"  it('Aggregation Cursor each Test', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Some docs for insertion\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }];\n\n        // Create a collection\n        var collection = db.collection('aggregation_each_example');\n        // Insert the docs\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Execute aggregate, notice the pipeline is expressed as an Array\n          var cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }], {\n            cursor: {\n              batchSize: 1\n            }\n          });\n\n          // Get all the aggregation results\n          cursor.forEach(() => {}, err => {\n            expect(err).to.not.exist;\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Aggregation Cursor forEach Test","suites":["Operation Examples"],"updatePoint":{"line":532,"column":37,"index":15391},"line":532,"code":"  it('Aggregation Cursor forEach Test', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Some docs for insertion\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }];\n\n        // Create a collection\n        var collection = db.collection('aggregation_forEach_example');\n        // Insert the docs\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Execute aggregate, notice the pipeline is expressed as an Array\n          var cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }], {\n            cursor: {\n              batchSize: 1\n            }\n          });\n          var count = 0;\n          // Get all the aggregation results\n          cursor.forEach(function (doc) {\n            test.ok(doc != null);\n            count = count + 1;\n          }, function (err) {\n            expect(err).to.not.exist;\n            test.equal(2, count);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"aggregationExample3","suites":["Operation Examples"],"updatePoint":{"line":632,"column":25,"index":18309},"line":632,"code":"  it('aggregationExample3', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Some docs for insertion\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }];\n\n        // Create a collection\n        var collection = db.collection('aggregationExample3');\n        // Insert the docs\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Execute aggregate, notice the pipeline is expressed as an Array\n          var cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }], {\n            cursor: {\n              batchSize: 1\n            }\n          });\n          const stream = cursor.stream();\n          var count = 0;\n          // Get all the aggregation results\n          stream.on('data', function () {\n            count = count + 1;\n          });\n          stream.once('end', function () {\n            test.equal(2, count);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDoSimpleCountExamples","suites":["Operation Examples"],"updatePoint":{"line":732,"column":42,"index":21241},"line":732,"code":"  it('shouldCorrectlyDoSimpleCountExamples', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Crete the collection for the distinct example\n        var collection = db.collection('countExample1');\n        // Insert documents to perform distinct against\n        collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }, {\n          a: 4,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, ids) {\n          test.ok(ids);\n          expect(err).to.not.exist;\n\n          // Perform a total count command\n          collection.count(function (err, count) {\n            expect(err).to.not.exist;\n            test.equal(4, count);\n\n            // Perform a partial account where b=1\n            collection.count({\n              b: 1\n            }, function (err, count) {\n              expect(err).to.not.exist;\n              test.equal(1, count);\n              client.close(done);\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCreateComplexIndexOnTwoFields","suites":["Operation Examples"],"updatePoint":{"line":801,"column":41,"index":23368},"line":801,"code":"  it('shouldCreateComplexIndexOnTwoFields', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection we want to drop later\n        var collection = db.collection('createIndexExample1');\n        // Insert a bunch of documents for the index\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Create an index on the a field\n          collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, indexName) {\n            test.ok(indexName);\n            expect(err).to.not.exist;\n\n            // Show that duplicate records got dropped\n            collection.find({}).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(4, items.length);\n\n              // Perform a query, with explain to show we hit the query\n              collection.find({\n                a: 2\n              }).explain(function (err, explanation) {\n                expect(err).to.not.exist;\n                test.ok(explanation != null);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCreateASimpleIndexOnASingleField","suites":["Operation Examples"],"updatePoint":{"line":884,"column":44,"index":25928},"line":884,"code":"  it('shouldCreateASimpleIndexOnASingleField', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection we want to drop later\n        var collection = db.collection('createIndexExample2');\n        // Insert a bunch of documents for the index\n        collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }, {\n          a: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Create an index on the a field\n          collection.createIndex('a', {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, indexName) {\n            test.equal('a_1', indexName);\n\n            // Perform a query, with explain to show we hit the query\n            collection.find({\n              a: 2\n            }).explain(function (err, explanation) {\n              expect(err).to.not.exist;\n              test.ok(explanation != null);\n              client.close(done);\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"createIndexExample3","suites":["Operation Examples"],"updatePoint":{"line":955,"column":25,"index":28096},"line":955,"code":"  it('createIndexExample3', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection we want to drop later\n        var collection = db.collection('createIndexExample3');\n        // Insert a bunch of documents for the index\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n          var options = {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          };\n          // Create an index on the a field\n          collection.createIndex({\n            a: 1,\n            b: 1\n          }, options, function (err, indexName) {\n            test.ok(indexName);\n            expect(err).to.not.exist;\n            test.ok(!options.readPreference);\n            // Show that duplicate records got dropped\n            collection.find({}).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(4, items.length);\n\n              // Perform a query, with explain to show we hit the query\n              collection.find({\n                a: 2\n              }).explain(function (err, explanation) {\n                expect(err).to.not.exist;\n                test.ok(explanation != null);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleDistinctIndexesWithSubQueryFilter","suites":["Operation Examples"],"updatePoint":{"line":1042,"column":60,"index":30787},"line":1042,"code":"  it('shouldCorrectlyHandleDistinctIndexesWithSubQueryFilter', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Crete the collection for the distinct example\n        var collection = db.collection('distinctExample1');\n\n        // Insert documents to perform distinct against\n        collection.insertMany([{\n          a: 0,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'b'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'c'\n          }\n        }, {\n          a: 2,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 3\n        }, {\n          a: 3\n        }], configuration.writeConcernMax(), function (err, ids) {\n          test.ok(ids);\n          expect(err).to.not.exist;\n\n          // Perform a distinct query against the a field\n          collection.distinct('a', function (err, docs) {\n            test.deepEqual([0, 1, 2, 3], docs.sort());\n\n            // Perform a distinct query against the sub-field b.c\n            collection.distinct('b.c', function (err, docs) {\n              test.deepEqual(['a', 'b', 'c'], docs.sort());\n              client.close(done);\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleDistinctIndexes","suites":["Operation Examples"],"updatePoint":{"line":1119,"column":42,"index":33058},"line":1119,"code":"  it('shouldCorrectlyHandleDistinctIndexes', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Crete the collection for the distinct example\n        var collection = db.collection('distinctExample2');\n\n        // Insert documents to perform distinct against\n        collection.insertMany([{\n          a: 0,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'b'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'c'\n          }\n        }, {\n          a: 2,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 3\n        }, {\n          a: 3\n        }, {\n          a: 5,\n          c: 1\n        }], configuration.writeConcernMax(), function (err, ids) {\n          test.ok(ids);\n          expect(err).to.not.exist;\n\n          // Perform a distinct query with a filter against the documents\n          collection.distinct('a', {\n            c: 1\n          }, function (err, docs) {\n            test.deepEqual([5], docs.sort());\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDropCollectionWithDropFunction","suites":["Operation Examples"],"updatePoint":{"line":1196,"column":51,"index":35166},"line":1196,"code":"  it('shouldCorrectlyDropCollectionWithDropFunction', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection we want to drop later\n        var collection = db.collection('test_other_drop');\n\n        // Drop the collection\n        collection.drop(function /*err, reply*/\n        () {\n          // TODO: reenable once SERVER-36317 is resolved\n          // expect(err).to.exist;\n          // expect(reply).to.not.exist;\n\n          // Ensure we don't have the collection in the set of names\n          db.listCollections().toArray(function (err, replies) {\n            var found = false;\n            // For each collection in the list of collection names in this db look for the\n            // dropped collection\n            replies.forEach(function (document) {\n              if (document.name === 'test_other_drop') {\n                found = true;\n                return;\n              }\n            });\n\n            // Ensure the collection is not found\n            test.equal(false, found);\n\n            // Let's close the db\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"dropIndexesExample1","suites":["Operation Examples"],"updatePoint":{"line":1259,"column":25,"index":37308},"line":1259,"code":"  it('dropIndexesExample1', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        db.createCollection('dropExample1', function (err, r) {\n          test.ok(r);\n          expect(err).to.not.exist;\n\n          // Drop the collection\n          db.collection('dropExample1').dropIndexes(function (err, reply) {\n            test.ok(reply);\n            expect(err).to.not.exist;\n\n            // Let's close the db\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateAndDropIndex","suites":["Operation Examples"],"updatePoint":{"line":1306,"column":39,"index":38831},"line":1306,"code":"  it('shouldCorrectlyCreateAndDropIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        var collection = db.collection('dropIndexExample1');\n        // Insert a bunch of documents for the index\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Create an index on the a field\n          collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, indexName) {\n            test.ok(indexName);\n            expect(err).to.not.exist;\n\n            // Drop the index\n            collection.dropIndex('a_1_b_1', function (err, result) {\n              test.ok(result);\n              expect(err).to.not.exist;\n\n              // Verify that the index is gone\n              collection.indexInformation(function (err, indexInformation) {\n                test.deepEqual([['_id', 1]], indexInformation._id_);\n                expect(indexInformation.a_1_b_1).to.not.exist;\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCreateComplexEnsureIndex","suites":["Operation Examples"],"updatePoint":{"line":1390,"column":36,"index":41374},"line":1390,"code":"  it('shouldCreateComplexEnsureIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        var collection = db.collection('ensureIndexExample1');\n        // Insert a bunch of documents for the index\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Create an index on the a field\n          db.createIndex('ensureIndexExample1', {\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, indexName) {\n            test.ok(indexName);\n            expect(err).to.not.exist;\n\n            // Show that duplicate records got dropped\n            collection.find({}).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(4, items.length);\n\n              // Perform a query, with explain to show we hit the query\n              collection.find({\n                a: 2\n              }).explain(function (err, explanation) {\n                expect(err).to.not.exist;\n                test.ok(explanation != null);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"ensureIndexExampleWithCompountIndex","suites":["Operation Examples"],"updatePoint":{"line":1472,"column":41,"index":43914},"line":1472,"code":"  it('ensureIndexExampleWithCompountIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        var collection = db.collection('ensureIndexExample2');\n        // Insert a bunch of documents for the index\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Create an index on the a field\n          collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, indexName) {\n            test.ok(indexName);\n            expect(err).to.not.exist;\n\n            // Show that duplicate records got dropped\n            collection.find({}).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(4, items.length);\n\n              // Perform a query, with explain to show we hit the query\n              collection.find({\n                a: 2\n              }).explain(function (err, explanation) {\n                expect(err).to.not.exist;\n                test.ok(explanation != null);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleQuery","suites":["Operation Examples"],"updatePoint":{"line":1558,"column":31,"index":46437},"line":1558,"code":"  it('shouldPerformASimpleQuery', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection we want to drop later\n        var collection = db.collection('simple_query');\n\n        // Insert a bunch of documents for the testing\n        collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Perform a simple find and return all the documents\n          collection.find().toArray(function (err, docs) {\n            expect(err).to.not.exist;\n            test.equal(3, docs.length);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleExplainQuery","suites":["Operation Examples"],"updatePoint":{"line":1613,"column":38,"index":48214},"line":1613,"code":"  it('shouldPerformASimpleExplainQuery', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection we want to drop later\n        var collection = db.collection('simple_explain_query');\n        // Insert a bunch of documents for the testing\n        collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Perform a simple find and return all the documents\n          collection.find({}).explain(function (err, explain) {\n            expect(err).to.not.exist;\n            test.ok(explain != null);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleLimitSkipQuery","suites":["Operation Examples"],"updatePoint":{"line":1667,"column":40,"index":49994},"line":1667,"code":"  it('shouldPerformASimpleLimitSkipQuery', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection we want to drop later\n        var collection = db.collection('simple_limit_skip_query');\n        // Insert a bunch of documents for the testing\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Perform a simple find and return all the documents\n          collection.find({}).skip(1).limit(1).project({\n            b: 1\n          }).toArray(function (err, docs) {\n            expect(err).to.not.exist;\n            test.equal(1, docs.length);\n            expect(docs[0].a).to.not.exist;\n            test.equal(2, docs[0].b);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformSimplefindOneAndUpdateOperations","suites":["Operation Examples"],"updatePoint":{"line":1732,"column":51,"index":52273},"line":1732,"code":"  it('shouldPerformSimplefindOneAndUpdateOperations', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection we want to drop later\n        var collection = db.collection('simple_find_and_modify_operations_');\n\n        // Insert some test documentations\n        collection.insertMany([{\n          a: 1\n        }, {\n          b: 1\n        }, {\n          c: 1\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Simple findOneAndUpdate command returning the new document\n          collection.findOneAndUpdate({\n            a: 1\n          }, {\n            $set: {\n              b1: 1\n            }\n          }, {\n            returnDocument: ReturnDocument.AFTER\n          }, function (err, doc) {\n            expect(err).to.not.exist;\n            test.equal(1, doc.value.a);\n            test.equal(1, doc.value.b1);\n\n            // Simple findOneAndUpdate command returning the new document and\n            // removing it at the same time\n            collection.findOneAndUpdate({\n              b: 1\n            }, {\n              $set: {\n                b: 2\n              }\n            }, {\n              remove: true\n            }, function (err, doc) {\n              test.ok(doc);\n              expect(err).to.not.exist;\n\n              // Verify that the document is gone\n              collection.findOne({\n                b: 1\n              }, function (err, item) {\n                expect(err).to.not.exist;\n                expect(item).to.not.exist;\n\n                // Simple findOneAndUpdate command performing an upsert and returning the new document\n                // executing the command safely\n                collection.findOneAndUpdate({\n                  d: 1\n                }, {\n                  $set: {\n                    d: 1,\n                    f: 1\n                  }\n                }, {\n                  returnDocument: ReturnDocument.AFTER,\n                  upsert: true,\n                  writeConcern: {\n                    w: 1\n                  }\n                }, function (err, doc) {\n                  expect(err).to.not.exist;\n                  test.equal(1, doc.value.d);\n                  test.equal(1, doc.value.f);\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformSimplefindOneAndDelete","suites":["Operation Examples"],"updatePoint":{"line":1840,"column":41,"index":55685},"line":1840,"code":"  it('shouldPerformSimplefindOneAndDelete', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection we want to drop later\n        var collection = db.collection('simple_find_and_modify_operations_2');\n        // Insert some test documentations\n        collection.insertMany([{\n          a: 1\n        }, {\n          b: 1,\n          d: 1\n        }, {\n          c: 1\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Simple findOneAndDelete command returning the old document and\n          // removing it at the same time\n          collection.findOneAndDelete({\n            b: 1\n          }, [['b', 1]], function (err, doc) {\n            expect(err).to.not.exist;\n            test.equal(1, doc.value.b);\n            test.equal(1, doc.value.d);\n\n            // Verify that the document is gone\n            collection.findOne({\n              b: 1\n            }, function (err, item) {\n              expect(err).to.not.exist;\n              expect(item).to.not.exist;\n              client.close(done);\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleLimitSkipFindOneQuery","suites":["Operation Examples"],"updatePoint":{"line":1907,"column":47,"index":57859},"line":1907,"code":"  it('shouldPerformASimpleLimitSkipFindOneQuery', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection we want to drop later\n        var collection = db.collection('simple_limit_skip_find_one_query');\n        // Insert a bunch of documents for the testing\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Perform a simple find and return all the documents\n          collection.findOne({\n            a: 2\n          }, {\n            projection: {\n              b: 1\n            }\n          }, function (err, doc) {\n            expect(err).to.not.exist;\n            expect(doc.a).to.not.exist;\n            test.equal(2, doc.b);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformSimpleMapReduceFunctions","suites":["Operation Examples"],"updatePoint":{"line":1971,"column":43,"index":59826},"line":1971,"code":"  it('shouldPerformSimpleMapReduceFunctions', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n\n      /* eslint-disable */\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a test collection\n        var collection = db.collection('test_map_reduce_functions');\n\n        // Insert some documents to perform map reduce over\n        collection.insertMany([{\n          user_id: 1\n        }, {\n          user_id: 2\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          test.ok(r);\n          expect(err).to.not.exist;\n\n          // Map function\n          var map = function () {\n            emit(this.user_id, 1);\n          };\n          // Reduce function\n          var reduce = function (k, vals) {\n            return 1;\n          };\n\n          // Perform the map reduce\n          collection.mapReduce(map, reduce, {\n            out: {\n              replace: 'tempCollection'\n            }\n          }, function (err, collection) {\n            expect(err).to.not.exist;\n\n            // Mapreduce returns the temporary collection with the results\n            collection.findOne({\n              _id: 1\n            }, function (err, result) {\n              test.equal(1, result.value);\n              collection.findOne({\n                _id: 2\n              }, function (err, result) {\n                test.equal(1, result.value);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n      // END\n      /* eslint-enable */\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformMapReduceFunctionInline","suites":["Operation Examples"],"updatePoint":{"line":2055,"column":42,"index":62377},"line":2055,"code":"  it('shouldPerformMapReduceFunctionInline', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>1.7.6',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a test collection\n        var collection = db.collection('test_map_reduce_functions_inline');\n\n        // Insert some test documents\n        collection.insertMany([{\n          user_id: 1\n        }, {\n          user_id: 2\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          test.ok(r);\n          expect(err).to.not.exist;\n\n          // Map function\n          var map = function () {\n            emit(this.user_id, 1); // eslint-disable-line\n          };\n\n          // Reduce function\n          // eslint-disable-next-line\n          var reduce = function (k, vals) {\n            return 1;\n          };\n\n          // Execute map reduce and return results inline\n          collection.mapReduce(map, reduce, {\n            out: {\n              inline: 1\n            },\n            verbose: true\n          }, function (err, result) {\n            test.equal(2, result.results.length);\n            test.ok(result.stats != null);\n            collection.mapReduce(map, reduce, {\n              out: {\n                replace: 'mapreduce_integration_test'\n              },\n              verbose: true\n            }, function (err, result) {\n              test.ok(result.stats != null);\n              client.close(done);\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformMapReduceWithContext","suites":["Operation Examples"],"updatePoint":{"line":2139,"column":39,"index":65015},"line":2139,"code":"  it('shouldPerformMapReduceWithContext', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a test collection\n        var collection = db.collection('test_map_reduce_functions_scope');\n\n        // Insert some test documents\n        collection.insertMany([{\n          user_id: 1,\n          timestamp: new Date()\n        }, {\n          user_id: 2,\n          timestamp: new Date()\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          test.ok(r);\n          expect(err).to.not.exist;\n\n          // Map function\n          var map = function () {\n            emit(fn(this.timestamp.getYear()), 1); // eslint-disable-line\n          };\n\n          // Reduce function\n          var reduce = function (k, v) {\n            var count = 0;\n            for (var i = 0; i < v.length; i++) {\n              count += v[i];\n            }\n            return count;\n          };\n\n          // Javascript function available in the map reduce scope\n          var t = function (val) {\n            return val + 1;\n          };\n\n          // Execute the map reduce with the custom scope\n          var o = {};\n          o.scope = {\n            fn: new Code(t.toString())\n          };\n          o.out = {\n            replace: 'replacethiscollection'\n          };\n          collection.mapReduce(map, reduce, o, function (err, outCollection) {\n            expect(err).to.not.exist;\n\n            // Find all entries in the map-reduce collection\n            outCollection.find().toArray(function (err, results) {\n              expect(err).to.not.exist;\n              test.equal(2, results[0].value);\n\n              // mapReduce with scope containing plain function\n              var o = {};\n              o.scope = {\n                fn: t\n              };\n              o.out = {\n                replace: 'replacethiscollection'\n              };\n              collection.mapReduce(map, reduce, o, function (err, outCollection) {\n                expect(err).to.not.exist;\n\n                // Find all entries in the map-reduce collection\n                outCollection.find().toArray(function (err, results) {\n                  expect(err).to.not.exist;\n                  test.equal(2, results[0].value);\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformMapReduceInContextObjects","suites":["Operation Examples"],"line":2247,"code":"  it.skip('shouldPerformMapReduceInContextObjects', {","file":"integration/node-specific/operation_example.test.js","skipped":true,"dir":"test"},{"name":"shouldCorrectlyRetrieveACollectionsIndexes","suites":["Operation Examples"],"updatePoint":{"line":2358,"column":48,"index":71922},"line":2358,"code":"  it('shouldCorrectlyRetrieveACollectionsIndexes', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Crete the collection for the distinct example\n        var collection = db.collection('simple_key_based_distinct');\n        // Create a geo 2d index\n        collection.createIndex({\n          loc: '2d'\n        }, configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Create a simple single field index\n          collection.createIndex({\n            a: 1\n          }, configuration.writeConcernMax(), function (err, result) {\n            test.ok(result);\n            expect(err).to.not.exist;\n            setTimeout(function () {\n              // List all of the indexes on the collection\n              collection.indexes(function (err, indexes) {\n                test.equal(3, indexes.length);\n                client.close(done);\n              });\n            }, 1000);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteIndexExists","suites":["Operation Examples"],"updatePoint":{"line":2416,"column":39,"index":73991},"line":2416,"code":"  it('shouldCorrectlyExecuteIndexExists', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a test collection that we are getting the options back from\n        var collection = db.collection('test_collection_index_exists', configuration.writeConcernMax());\n        expect(err).to.not.exist;\n\n        // Create an index on the collection\n        collection.createIndex('a', configuration.writeConcernMax(), function (err, indexName) {\n          test.ok(indexName);\n          expect(err).to.not.exist;\n\n          // Let's test to check if a single index exists\n          collection.indexExists('a_1', function (err, result) {\n            test.equal(true, result);\n\n            // Let's test to check if multiple indexes are available\n            collection.indexExists(['a_1', '_id_'], function (err, result) {\n              test.equal(true, result);\n\n              // Check if a non existing index exists\n              collection.indexExists('c_1', function (err, result) {\n                test.equal(false, result);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyShowTheResultsFromIndexInformation","suites":["Operation Examples"],"updatePoint":{"line":2475,"column":55,"index":76190},"line":2475,"code":"  it('shouldCorrectlyShowTheResultsFromIndexInformation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection we want to drop later\n        var collection = db.collection('more_index_information_test_2');\n        // Insert a bunch of documents for the index\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Create an index on the a field\n          collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, indexName) {\n            test.ok(indexName);\n            expect(err).to.not.exist;\n\n            // Fetch basic indexInformation for collection\n            db.indexInformation('more_index_information_test_2', function (err, indexInformation) {\n              test.deepEqual([['_id', 1]], indexInformation._id_);\n              test.deepEqual([['a', 1], ['b', 1]], indexInformation.a_1_b_1);\n\n              // Fetch full index information\n              collection.indexInformation({\n                full: true\n              }, function (err, indexInformation) {\n                test.deepEqual({\n                  _id: 1\n                }, indexInformation[0].key);\n                test.deepEqual({\n                  a: 1,\n                  b: 1\n                }, indexInformation[1].key);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyShowAllTheResultsFromIndexInformation","suites":["Operation Examples"],"updatePoint":{"line":2563,"column":58,"index":78980},"line":2563,"code":"  it('shouldCorrectlyShowAllTheResultsFromIndexInformation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection we want to drop later\n        var collection = db.collection('more_index_information_test_3');\n        // Insert a bunch of documents for the index\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Create an index on the a field\n          collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, indexName) {\n            test.ok(indexName);\n            expect(err).to.not.exist;\n\n            // Fetch basic indexInformation for collection\n            collection.indexInformation(function (err, indexInformation) {\n              test.deepEqual([['_id', 1]], indexInformation._id_);\n              test.deepEqual([['a', 1], ['b', 1]], indexInformation.a_1_b_1);\n\n              // Fetch full index information\n              collection.indexInformation({\n                full: true\n              }, function (err, indexInformation) {\n                test.deepEqual({\n                  _id: 1\n                }, indexInformation[0].key);\n                test.deepEqual({\n                  a: 1,\n                  b: 1\n                }, indexInformation[1].key);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformASimpleSingleDocumentInsertNoCallbackNoSafe","suites":["Operation Examples"],"updatePoint":{"line":2655,"column":71,"index":81854},"line":2655,"code":"  it('shouldCorrectlyPerformASimpleSingleDocumentInsertNoCallbackNoSafe', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        var collection = db.collection('simple_document_insert_collection_no_safe');\n        // Insert a single document\n        collection.insertOne({\n          hello: 'world_no_safe'\n        }, err => {\n          expect(err).to.not.exist;\n          // Wait for a second before finishing up, to ensure we have written the item to disk\n          setTimeout(function () {\n            // Fetch the document\n            collection.findOne({\n              hello: 'world_no_safe'\n            }, function (err, item) {\n              expect(err).to.not.exist;\n              test.equal('world_no_safe', item.hello);\n              client.close(done);\n            });\n          }, 100);\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformABatchDocumentInsertSafe","suites":["Operation Examples"],"updatePoint":{"line":2709,"column":52,"index":83849},"line":2709,"code":"  it('shouldCorrectlyPerformABatchDocumentInsertSafe', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Fetch a collection to insert document into\n        var collection = db.collection('batch_document_insert_collection_safe');\n        // Insert a single document\n        collection.insertMany([{\n          hello: 'world_safe1'\n        }, {\n          hello: 'world_safe2'\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Fetch the document\n          collection.findOne({\n            hello: 'world_safe2'\n          }, function (err, item) {\n            expect(err).to.not.exist;\n            test.equal('world_safe2', item.hello);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformASimpleDocumentInsertWithFunctionSafe","suites":["Operation Examples"],"updatePoint":{"line":2765,"column":65,"index":85822},"line":2765,"code":"  it('shouldCorrectlyPerformASimpleDocumentInsertWithFunctionSafe', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Fetch a collection to insert document into\n        var collection = db.collection('simple_document_insert_with_function_safe');\n        var o = configuration.writeConcernMax();\n        o.serializeFunctions = true;\n        // Insert a single document\n        collection.insertOne({\n          hello: 'world',\n          func: function () {}\n        }, o, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Fetch the document\n          collection.findOne({\n            hello: 'world'\n          }, function (err, item) {\n            expect(err).to.not.exist;\n            test.ok('function() {}', item.code);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute insert with keepGoing option on mongod >= 1.9.1","suites":["Operation Examples"],"updatePoint":{"line":2822,"column":78,"index":87898},"line":2822,"code":"  it('Should correctly execute insert with keepGoing option on mongod >= 1.9.1', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>1.9.1',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection\n        var collection = db.collection('keepGoingExample');\n\n        // Add an unique index to title to force errors in the batch insert\n        collection.createIndex({\n          title: 1\n        }, {\n          unique: true\n        }, function (err, indexName) {\n          test.ok(indexName);\n          expect(err).to.not.exist;\n\n          // Insert some intial data into the collection\n          collection.insertMany([{\n            name: 'Jim'\n          }, {\n            name: 'Sarah',\n            title: 'Princess'\n          }], configuration.writeConcernMax(), function (err, result) {\n            test.ok(result);\n            expect(err).to.not.exist;\n\n            // Force keep going flag, ignoring unique index issue\n            collection.insert([{\n              name: 'Jim'\n            }, {\n              name: 'Sarah',\n              title: 'Princess'\n            }, {\n              name: 'Gump',\n              title: 'Gump'\n            }], {\n              writeConcern: {\n                w: 1\n              },\n              keepGoing: true\n            }, function (err, result) {\n              expect(result).to.not.exist;\n              test.ok(err);\n              test.ok(err.result);\n\n              // Count the number of documents left (should not include the duplicates)\n              collection.count(function (err, count) {\n                test.equal(3, count);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteIsCapped","suites":["Operation Examples"],"updatePoint":{"line":2908,"column":36,"index":90696},"line":2908,"code":"  it('shouldCorrectlyExecuteIsCapped', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a test collection that we are getting the options back from\n        db.createCollection('test_collection_is_capped', {\n          capped: true,\n          size: 1024\n        }, function (err, collection) {\n          test.equal('test_collection_is_capped', collection.collectionName);\n\n          // Let's fetch the collection options\n          collection.isCapped(function (err, capped) {\n            test.equal(true, capped);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveCollectionOptions","suites":["Operation Examples"],"updatePoint":{"line":2955,"column":46,"index":92326},"line":2955,"code":"  it('shouldCorrectlyRetrieveCollectionOptions', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a test collection that we are getting the options back from\n        db.createCollection('test_collection_options', {\n          capped: true,\n          size: 1024\n        }, function (err, collection) {\n          test.equal('test_collection_options', collection.collectionName);\n\n          // Let's fetch the collection options\n          collection.options(function (err, options) {\n            test.equal(true, options.capped);\n            test.ok(options.size >= 1024);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldRemoveAllDocumentsNoSafe","suites":["Operation Examples"],"updatePoint":{"line":3003,"column":36,"index":94011},"line":3003,"code":"  it('shouldRemoveAllDocumentsNoSafe', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        const db = client.db(configuration.db);\n        const collection = db.collection('remove_all_documents_no_safe');\n\n        // Insert a bunch of documents\n        collection.insertMany([{\n          a: 1\n        }, {\n          b: 2\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, (err, result) => {\n          expect(err).to.not.exist;\n          expect(result).to.exist;\n\n          // Remove all the document\n          collection.deleteMany((err, result) => {\n            expect(err).to.not.exist;\n            expect(result).to.exist;\n\n            // Fetch all results\n            collection.find().toArray((err, docs) => {\n              expect(err).to.not.exist;\n              expect(docs).to.have.lengthOf(0);\n              client.close(done);\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldRemoveSubsetOfDocumentsSafeMode","suites":["Operation Examples"],"updatePoint":{"line":3067,"column":43,"index":95989},"line":3067,"code":"  it('shouldRemoveSubsetOfDocumentsSafeMode', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n\n        // Fetch a collection to insert document into\n        var collection = db.collection('remove_subset_of_documents_safe');\n        // Insert a bunch of documents\n        collection.insertMany([{\n          a: 1\n        }, {\n          b: 2\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Remove all the document\n          collection.deleteOne({\n            a: 1\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('deletedCount').to.equal(1);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRenameCollection","suites":["Operation Examples"],"updatePoint":{"line":3131,"column":37,"index":97915},"line":3131,"code":"  it('shouldCorrectlyRenameCollection', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Open a couple of collections\n        db.createCollection('test_rename_collection', function (err, collection1) {\n          db.createCollection('test_rename_collection2', function (err, collection2) {\n            test.ok(collection2);\n            expect(err).to.not.exist;\n\n            // Attemp to rename a collection to a number\n            try {\n              collection1.rename(5, function (err, collection) {}); // eslint-disable-line\n            } catch (err) {\n              test.ok(err instanceof Error);\n              test.equal('Collection name must be a String', err.message);\n            }\n\n            // Attemp to rename a collection to an empty string\n            try {\n              collection1.rename('', function (err, collection) {}); // eslint-disable-line\n            } catch (err) {\n              test.ok(err instanceof Error);\n              test.equal('Collection names cannot be empty', err.message);\n            }\n\n            // Attemp to rename a collection to an illegal name including the character $\n            try {\n              collection1.rename('te$t', function (err, collection) {}); // eslint-disable-line\n            } catch (err) {\n              test.ok(err instanceof Error);\n              test.equal(\"Collection names must not contain '$'\", err.message);\n            }\n\n            // Attemp to rename a collection to an illegal name starting with the character .\n            try {\n              collection1.rename('.test', function (err, collection) {}); // eslint-disable-line\n            } catch (err) {\n              test.ok(err instanceof Error);\n              test.equal(\"Collection names must not start or end with '.'\", err.message);\n            }\n\n            // Attemp to rename a collection to an illegal name ending with the character .\n            try {\n              collection1.rename('test.', function (err, collection) {}); // eslint-disable-line\n            } catch (err) {\n              test.ok(err instanceof Error);\n              test.equal(\"Collection names must not start or end with '.'\", err.message);\n            }\n\n            // Attemp to rename a collection to an illegal name with an empty middle name\n            try {\n              collection1.rename('tes..t', function (err, collection) {}); // eslint-disable-line\n            } catch (err) {\n              test.equal('Collection names cannot be empty', err.message);\n            }\n\n            // Insert a couple of documents\n            collection1.insertMany([{\n              x: 1\n            }, {\n              x: 2\n            }], configuration.writeConcernMax(), function (err, docs) {\n              test.ok(docs);\n              expect(err).to.not.exist;\n\n              // Attemp to rename the first collection to the second one, this will fail\n              collection1.rename('test_rename_collection2', function (err, collection) {\n                expect(collection).to.not.exist;\n                test.ok(err instanceof Error);\n                test.ok(err.message.length > 0);\n\n                // Attemp to rename the first collection to a name that does not exist\n                // this will be successful\n                collection1.rename('test_rename_collection3', function (err, collection2) {\n                  test.equal('test_rename_collection3', collection2.collectionName);\n\n                  // Ensure that the collection is pointing to the new one\n                  collection2.count(function (err, count) {\n                    test.equal(2, count);\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUpdateASimpleDocument","suites":["Operation Examples"],"updatePoint":{"line":3248,"column":42,"index":102723},"line":3248,"code":"  it('shouldCorrectlyUpdateASimpleDocument', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Get a collection\n        var collection = db.collection('update_a_simple_document');\n\n        // Insert a document, then update it\n        collection.insertOne({\n          a: 1\n        }, configuration.writeConcernMax(), function (err, doc) {\n          test.ok(doc);\n          expect(err).to.not.exist;\n\n          // Update the document with an atomic operator\n          collection.updateOne({\n            a: 1\n          }, {\n            $set: {\n              b: 2\n            }\n          });\n\n          // Wait for a second then fetch the document\n          setTimeout(function () {\n            // Fetch the document that we modified\n            collection.findOne({\n              a: 1\n            }, function (err, item) {\n              expect(err).to.not.exist;\n              test.equal(1, item.a);\n              test.equal(2, item.b);\n              client.close(done);\n            });\n          }, 1000);\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUpsertASimpleDocument","suites":["Operation Examples"],"updatePoint":{"line":3314,"column":42,"index":104834},"line":3314,"code":"  it('shouldCorrectlyUpsertASimpleDocument', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Get a collection\n        var collection = db.collection('update_a_simple_document_upsert');\n        // Update the document using an upsert operation, ensuring creation if it does not exist\n        collection.updateOne({\n          a: 1\n        }, {\n          $set: {\n            b: 2,\n            a: 1\n          }\n        }, {\n          upsert: true,\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          expect(err).to.not.exist;\n          expect(result).property('upsertedCount').to.equal(1);\n\n          // Fetch the document that we modified and check if it got inserted correctly\n          collection.findOne({\n            a: 1\n          }, function (err, item) {\n            expect(err).to.not.exist;\n            test.equal(1, item.a);\n            test.equal(2, item.b);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUpdateMultipleDocuments","suites":["Operation Examples"],"updatePoint":{"line":3377,"column":44,"index":106876},"line":3377,"code":"  it('shouldCorrectlyUpdateMultipleDocuments', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Get a collection\n        var collection = db.collection('update_a_simple_document_multi');\n\n        // Insert a couple of documentations\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 1,\n          b: 2\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n          var o = configuration.writeConcernMax();\n          collection.updateMany({\n            a: 1\n          }, {\n            $set: {\n              b: 0\n            }\n          }, o, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('matchedCount').to.equal(2);\n\n            // Fetch all the documents and verify that we have changed the b value\n            collection.find().toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(1, items[0].a);\n              test.equal(0, items[0].b);\n              test.equal(1, items[1].a);\n              test.equal(0, items[1].b);\n              client.close(done);\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyReturnACollectionsStats","suites":["Operation Examples"],"updatePoint":{"line":3446,"column":44,"index":109112},"line":3446,"code":"  it('shouldCorrectlyReturnACollectionsStats', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Crete the collection for the distinct example\n        var collection = db.collection('collection_stats_test');\n\n        // Insert some documents\n        collection.insertMany([{\n          a: 1\n        }, {\n          hello: 'world'\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Retrieve the statistics for the collection\n          collection.stats(function (err, stats) {\n            test.equal(2, stats.count);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateAndDropAllIndex","suites":["Operation Examples"],"updatePoint":{"line":3498,"column":42,"index":110830},"line":3498,"code":"  it('shouldCorrectlyCreateAndDropAllIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection we want to drop later\n        var collection = db.collection('shouldCorrectlyCreateAndDropAllIndex');\n        // Insert a bunch of documents for the index\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4,\n          c: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Create an index on the a field\n          collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, indexName) {\n            test.ok(indexName);\n            expect(err).to.not.exist;\n\n            // Create an additional index\n            collection.createIndex({\n              c: 1\n            }, {\n              unique: true,\n              background: true,\n              writeConcern: {\n                w: 1\n              }\n            }, function () {\n              // Drop the index\n              collection.dropIndexes(function (err, result) {\n                test.ok(result);\n                expect(err).to.not.exist;\n\n                // Verify that the index is gone\n                collection.indexInformation(function (err, indexInformation) {\n                  test.deepEqual([['_id', 1]], indexInformation._id_);\n                  expect(indexInformation.a_1_b_1).to.not.exist;\n                  expect(indexInformation.c_1).to.not.exist;\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"accessAdminLevelOperations","suites":["Operation Examples"],"updatePoint":{"line":3602,"column":32,"index":113952},"line":3602,"code":"  it('accessAdminLevelOperations', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Use the admin database for the operation\n        var adminDb = db.admin();\n        test.ok(adminDb != null);\n        client.close(done);\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyOpenASimpleDbSingleServerConnection","suites":["Operation Examples"],"updatePoint":{"line":3640,"column":56,"index":115229},"line":3640,"code":"  it('shouldCorrectlyOpenASimpleDbSingleServerConnection', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      // NODE-2484: investigate double close event in Unified Topology environment\n      // client.on('close', function() {\n      //   done();\n      // });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        expect(err).to.not.exist;\n        client.close(done);\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyOpenASimpleDbSingleServerConnectionAndCloseWithCallback","suites":["Operation Examples"],"updatePoint":{"line":3679,"column":76,"index":116570},"line":3679,"code":"  it('shouldCorrectlyOpenASimpleDbSingleServerConnectionAndCloseWithCallback', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        // Close the connection with a callback that is optional\n        client.close(function (err) {\n          expect(err).to.not.exist;\n          done();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrievelistCollections","suites":["Operation Examples"],"updatePoint":{"line":3719,"column":44,"index":117867},"line":3719,"code":"  it('shouldCorrectlyRetrievelistCollections', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n\n        // Get an empty db\n        var db1 = client.db('listCollectionTestDb');\n        // Create a collection\n        var collection = db1.collection('shouldCorrectlyRetrievelistCollections');\n        // Ensure the collection was created\n        collection.insertOne({\n          a: 1\n        }, function (err, r) {\n          test.ok(r);\n          expect(err).to.not.exist;\n\n          // Return the information of a single collection name\n          db1.listCollections({\n            name: 'shouldCorrectlyRetrievelistCollections'\n          }).toArray(function (err, items) {\n            expect(err).to.not.exist;\n            test.equal(1, items.length);\n\n            // Return the information of a all collections, using the callback format\n            db1.listCollections().toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.ok(items.length >= 1);\n              client.close(done);\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrievelistCollectionsWiredTiger","suites":["Operation Examples"],"updatePoint":{"line":3774,"column":54,"index":119812},"line":3774,"code":"  it('shouldCorrectlyRetrievelistCollectionsWiredTiger', {\n    metadata: {\n      requires: {\n        topology: ['wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        // Get an empty db\n        var db1 = client.db('listCollectionTestDb2');\n        // Create a collection\n        var collection = db1.collection('shouldCorrectlyRetrievelistCollections');\n        // Ensure the collection was created\n        collection.insertOne({\n          a: 1\n        }, function (err, r) {\n          test.ok(r);\n          expect(err).to.not.exist;\n\n          // Return the information of a single collection name\n          db1.listCollections({\n            name: 'shouldCorrectlyRetrievelistCollections'\n          }).toArray(function (err, items) {\n            test.equal(1, items.length);\n\n            // Return the information of a all collections, using the callback format\n            db1.listCollections().toArray(function (err, items) {\n              test.equal(1, items.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveAllCollections","suites":["Operation Examples"],"updatePoint":{"line":3831,"column":43,"index":121770},"line":3831,"code":"  it('shouldCorrectlyRetrieveAllCollections', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n\n        // Retry to get the collection, should work as it's now created\n        db.collections(function (err, collections) {\n          expect(err).to.not.exist;\n          test.ok(collections.length > 0);\n          client.close(done);\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyAddUserToDb","suites":["Operation Examples"],"updatePoint":{"line":3873,"column":32,"index":123153},"line":3873,"code":"  it('shouldCorrectlyAddUserToDb', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n\n        // Add a user to the database\n        db.addUser('user', 'name', function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Remove the user from the db\n          db.removeUser('user', function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"should correctly create a collection","suites":["Operation Examples"],"updatePoint":{"line":3921,"column":42,"index":124648},"line":3921,"code":"  it('should correctly create a collection', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n\n        // Create a capped collection with a maximum of 1000 documents\n        db.createCollection('a_simple_collection', {\n          capped: true,\n          size: 10000,\n          max: 1000,\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, collection) {\n          expect(err).to.not.exist;\n\n          // Insert a document in the capped collection\n          collection.insertOne({\n            a: 1\n          }, configuration.writeConcernMax(), function (err, result) {\n            test.ok(result);\n            expect(err).to.not.exist;\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteACommandAgainstTheServer","suites":["Operation Examples"],"updatePoint":{"line":3977,"column":52,"index":126490},"line":3977,"code":"  it('shouldCorrectlyExecuteACommandAgainstTheServer', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n\n        // Execute ping against the server\n        db.command({\n          ping: 1\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Create a capped collection with a maximum of 1000 documents\n          db.createCollection('a_simple_create_drop_collection', {\n            capped: true,\n            size: 10000,\n            max: 1000,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, collection) {\n            expect(err).to.not.exist;\n\n            // Insert a document in the capped collection\n            collection.insertOne({\n              a: 1\n            }, configuration.writeConcernMax(), function (err, result) {\n              test.ok(result);\n              expect(err).to.not.exist;\n\n              // Drop the collection from this world\n              db.dropCollection('a_simple_create_drop_collection', function (err, result) {\n                test.ok(result);\n                expect(err).to.not.exist;\n\n                // Verify that the collection is gone\n                db.listCollections({\n                  name: 'a_simple_create_drop_collection'\n                }).toArray(function (err, names) {\n                  test.equal(0, names.length);\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateDropAndVerifyThatCollectionIsGone","suites":["Operation Examples"],"updatePoint":{"line":4054,"column":60,"index":129048},"line":4054,"code":"  it('shouldCorrectlyCreateDropAndVerifyThatCollectionIsGone', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n\n        // Execute ping against the server\n        db.command({\n          ping: 1\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRenameACollection","suites":["Operation Examples"],"updatePoint":{"line":4098,"column":38,"index":130475},"line":4098,"code":"  it('shouldCorrectlyRenameACollection', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n\n        // Create a collection\n        db.createCollection('simple_rename_collection', configuration.writeConcernMax(), function (err, collection) {\n          expect(err).to.not.exist;\n\n          // Insert a document in the collection\n          collection.insertOne({\n            a: 1\n          }, configuration.writeConcernMax(), function (err, result) {\n            test.ok(result);\n            expect(err).to.not.exist;\n\n            // Retrieve the number of documents from the collection\n            collection.count(function (err, count) {\n              expect(err).to.not.exist;\n              test.equal(1, count);\n\n              // Rename the collection\n              db.renameCollection('simple_rename_collection', 'simple_rename_collection_2', function (err, collection2) {\n                expect(err).to.not.exist;\n\n                // Retrieve the number of documents from the collection\n                collection2.count(function (err, count) {\n                  test.equal(1, count);\n\n                  // Verify that the collection is gone\n                  db.listCollections({\n                    name: 'simple_rename_collection'\n                  }).toArray(function (err, names) {\n                    test.equal(0, names.length);\n\n                    // Verify that the new collection exists\n                    db.listCollections({\n                      name: 'simple_rename_collection_2'\n                    }).toArray(function (err, names) {\n                      test.equal(1, names.length);\n                      client.close(done);\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCreateOnDbComplexIndexOnTwoFields","suites":["Operation Examples"],"updatePoint":{"line":4177,"column":45,"index":133374},"line":4177,"code":"  it('shouldCreateOnDbComplexIndexOnTwoFields', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection we want to drop later\n        var collection = db.collection('more_complex_index_test');\n        // Insert a bunch of documents for the index\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Create an index on the a field\n          db.createIndex('more_complex_index_test', {\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, indexName) {\n            test.ok(indexName);\n            expect(err).to.not.exist;\n\n            // Show that duplicate records got dropped\n            collection.find({}).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(4, items.length);\n\n              // Perform a query, with explain to show we hit the query\n              collection.find({\n                a: 2\n              }).explain(function (err, explanation) {\n                expect(err).to.not.exist;\n                test.ok(explanation != null);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCreateComplexEnsureIndexDb","suites":["Operation Examples"],"updatePoint":{"line":4260,"column":38,"index":135998},"line":4260,"code":"  it('shouldCreateComplexEnsureIndexDb', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection we want to drop later\n        var collection = db.collection('more_complex_ensure_index_db_test');\n        // Insert a bunch of documents for the index\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Create an index on the a field\n          db.createIndex('more_complex_ensure_index_db_test', {\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, indexName) {\n            test.ok(indexName);\n            expect(err).to.not.exist;\n\n            // Show that duplicate records got dropped\n            collection.find({}).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(4, items.length);\n\n              // Perform a query, with explain to show we hit the query\n              collection.find({\n                a: 2\n              }).explain(function (err, explanation) {\n                expect(err).to.not.exist;\n                test.ok(explanation != null);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"should correctly drop the database","suites":["Operation Examples"],"updatePoint":{"line":4343,"column":40,"index":138582},"line":4343,"code":"  it('should correctly drop the database', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection\n        var collection = db.collection('more_index_information_test_1');\n        // Insert a bunch of documents for the index\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Let's drop the database\n          db.dropDatabase(function (err, result) {\n            test.ok(result);\n            expect(err).to.not.exist;\n\n            // Wait two seconds to let it replicate across\n            setTimeout(function () {\n              // Get the admin database\n              db.admin().listDatabases(function (err, dbs) {\n                // Grab the databases\n                dbs = dbs.databases;\n                // Did we find the db\n                var found = false;\n\n                // Check if we have the db in the list\n                for (var i = 0; i < dbs.length; i++) {\n                  if (dbs[i].name === 'integration_tests_to_drop') found = true;\n                }\n\n                // We should not find the databases\n                if (process.env['JENKINS'] == null) test.equal(false, found);\n                client.close(done);\n              });\n            }, 2000);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveDbStats","suites":["Operation Examples"],"updatePoint":{"line":4425,"column":36,"index":141115},"line":4425,"code":"  it('shouldCorrectlyRetrieveDbStats', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        db.stats(function (err, stats) {\n          expect(err).to.not.exist;\n          test.ok(stats != null);\n          client.close(done);\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyShareConnectionPoolsAcrossMultipleDbInstances","suites":["Operation Examples"],"updatePoint":{"line":4465,"column":66,"index":142479},"line":4465,"code":"  it('shouldCorrectlyShareConnectionPoolsAcrossMultipleDbInstances', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n\n        // Reference a different database sharing the same connections\n        // for the data transfer\n        var secondDb = client.db('integration_tests_2');\n\n        // Fetch the collections\n        var multipleColl1 = db.collection('multiple_db_instances');\n        var multipleColl2 = secondDb.collection('multiple_db_instances');\n\n        // Write a record into each and then count the records stored\n        multipleColl1.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n          multipleColl2.insertOne({\n            a: 1\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, result) {\n            test.ok(result);\n            expect(err).to.not.exist;\n\n            // Count over the results ensuring only on record in each collection\n            multipleColl1.count(function (err, count) {\n              test.equal(1, count);\n              multipleColl2.count(function (err, count) {\n                test.equal(1, count);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveBuildInfo","suites":["Operation Examples"],"updatePoint":{"line":4545,"column":38,"index":145046},"line":4545,"code":"  it('shouldCorrectlyRetrieveBuildInfo', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n\n        // Use the admin database for the operation\n        var adminDb = db.admin();\n\n        // Retrieve the build information for the MongoDB instance\n        adminDb.buildInfo(function (err, info) {\n          test.ok(info);\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveBuildInfoUsingCommand","suites":["Operation Examples"],"updatePoint":{"line":4589,"column":50,"index":146425},"line":4589,"code":"  it('shouldCorrectlyRetrieveBuildInfoUsingCommand', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n\n        // Use the admin database for the operation\n        var adminDb = db.admin();\n        // Retrieve the build information using the admin command\n        adminDb.command({\n          buildInfo: 1\n        }, function (err, info) {\n          test.ok(info);\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCallValidateCollection","suites":["Operation Examples"],"updatePoint":{"line":4635,"column":43,"index":147949},"line":4635,"code":"  it('shouldCorrectlyCallValidateCollection', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Grab a collection object\n        var collection = db.collection('test');\n\n        // Force the creation of the collection by inserting a document\n        // Collections are not created until the first document is inserted\n        collection.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, doc) {\n          test.ok(doc);\n          expect(err).to.not.exist;\n\n          // Use the admin database for the operation\n          var adminDb = db.admin();\n\n          // Validate the 'test' collection\n          adminDb.validateCollection('test', function (err, doc) {\n            test.ok(doc);\n            expect(err).to.not.exist;\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPingTheMongoDbInstance","suites":["Operation Examples"],"updatePoint":{"line":4693,"column":43,"index":149767},"line":4693,"code":"  it('shouldCorrectlyPingTheMongoDbInstance', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Use the admin database for the operation\n        var adminDb = db.admin();\n\n        // Ping the server\n        adminDb.ping(function (err, pingResult) {\n          test.ok(pingResult);\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyAddAUserToAdminDb","suites":["Operation Examples"],"updatePoint":{"line":4736,"column":38,"index":151104},"line":4736,"code":"  it('shouldCorrectlyAddAUserToAdminDb', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Use the admin database for the operation\n        var adminDb = db.admin();\n\n        // Add the new user to the admin database\n        adminDb.addUser('admin11', 'admin11', function (err, result) {\n          expect(err).to.not.exist;\n          test.ok(result);\n          adminDb.removeUser('admin11', function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyAddAUserAndRemoveItFromAdminDb","suites":["Operation Examples"],"updatePoint":{"line":4782,"column":51,"index":152637},"line":4782,"code":"  it('shouldCorrectlyAddAUserAndRemoveItFromAdminDb', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Use the admin database for the operation\n        var adminDb = db.admin();\n\n        // Add the new user to the admin database\n        adminDb.addUser('admin12', 'admin12', function (err, result) {\n          test.ok(result);\n\n          // Remove the user\n          adminDb.removeUser('admin12', function (err, result) {\n            expect(err).to.not.exist;\n            test.equal(true, result);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"should correctly list all available databases","suites":["Operation Examples"],"updatePoint":{"line":4830,"column":51,"index":154177},"line":4830,"code":"  it('should correctly list all available databases', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Use the admin database for the operation\n        var adminDb = db.admin();\n\n        // List all the available databases\n        adminDb.listDatabases(function (err, dbs) {\n          expect(err).to.not.exist;\n          test.ok(dbs.databases.length > 0);\n          client.close(done);\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"should correctly list all available databases names and no database sizes","suites":["Operation Examples"],"updatePoint":{"line":4867,"column":79,"index":155513},"line":4867,"code":"  it('should correctly list all available databases names and no database sizes', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger'],\n        mongodb: '>=3.2.13'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Use the admin database for the operation\n        var adminDb = db.admin();\n\n        // List all the available databases\n        adminDb.listDatabases({\n          nameOnly: 1\n        }, function (err, dbs) {\n          expect(err).to.not.exist;\n          expect(dbs.databases).to.containSubset([{\n            name: 'admin'\n          }]);\n          client.close(done);\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveServerInfo","suites":["Operation Examples"],"updatePoint":{"line":4915,"column":39,"index":157036},"line":4915,"code":"  it('shouldCorrectlyRetrieveServerInfo', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Grab a collection object\n        var collection = db.collection('test');\n\n        // Force the creation of the collection by inserting a document\n        // Collections are not created until the first document is inserted\n        collection.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, doc) {\n          test.ok(doc);\n          expect(err).to.not.exist;\n\n          // Use the admin database for the operation\n          var adminDb = db.admin();\n\n          // Retrieve the server Info\n          adminDb.serverStatus(function (err, info) {\n            expect(err).to.not.exist;\n            test.ok(info != null);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveReplSetGetStatus","suites":["Operation Examples"],"updatePoint":{"line":4974,"column":45,"index":158905},"line":4974,"code":"  it('shouldCorrectlyRetrieveReplSetGetStatus', {\n    metadata: {\n      requires: {\n        topology: 'replicaset'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        // Grab a collection object\n        var collection = db.collection('test');\n\n        // Force the creation of the collection by inserting a document\n        // Collections are not created until the first document is inserted\n        collection.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, doc) {\n          test.ok(doc);\n          expect(err).to.not.exist;\n\n          // Use the admin database for the operation\n          var adminDb = db.admin();\n\n          // Retrieve the server Info, returns error if we are not\n          // running a replicaset\n          adminDb.replSetGetStatus(function (err, info) {\n            test.ok(info);\n            expect(err).to.not.exist;\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteToArray","suites":["Operation Examples"],"updatePoint":{"line":5040,"column":35,"index":160980},"line":5040,"code":"  it('shouldCorrectlyExecuteToArray', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection to hold our documents\n        var collection = db.collection('test_array');\n\n        // Insert a test document\n        collection.insertOne({\n          b: [1, 2, 3]\n        }, configuration.writeConcernMax(), function (err, ids) {\n          test.ok(ids);\n          expect(err).to.not.exist;\n\n          // Retrieve all the documents in the collection\n          collection.find().toArray(function (err, documents) {\n            test.equal(1, documents.length);\n            test.deepEqual([1, 2, 3], documents[0].b);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyFailToArrayDueToFinishedEachOperation","suites":["Operation Examples"],"updatePoint":{"line":5093,"column":58,"index":162877},"line":5093,"code":"  it('shouldCorrectlyFailToArrayDueToFinishedEachOperation', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection\n        var collection = db.collection('test_to_a_after_each');\n\n        // Insert a document in the collection\n        collection.insertOne({\n          a: 1\n        }, configuration.writeConcernMax(), function (err, ids) {\n          test.ok(ids);\n          expect(err).to.not.exist;\n\n          // Grab a cursor\n          var cursor = collection.find();\n          // Execute the each command, triggers for each document\n          cursor.forEach(() => {}, err => {\n            expect(err).to.not.exist;\n\n            // Show that the cursor is closed\n            cursor.toArray((err, docs) => {\n              expect(err).to.not.exist;\n              expect(docs).to.exist;\n\n              // Let's close the db\n              client.close(done);\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly iterate over cursor using forEach","suites":["Operation Examples"],"updatePoint":{"line":5155,"column":56,"index":164989},"line":5155,"code":"  it('Should correctly iterate over cursor using forEach', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection\n        var collection = db.collection('test_to_a_after_for_each');\n\n        // Insert a document in the collection\n        collection.insertOne({\n          a: 1\n        }, configuration.writeConcernMax(), function (err, ids) {\n          test.ok(ids);\n          expect(err).to.not.exist;\n\n          // Count of documents returned\n          var count = 0;\n          // Grab a cursor\n          var cursor = collection.find();\n          // Execute the each command, triggers for each document\n          cursor.forEach(function (doc) {\n            test.ok(doc != null);\n            count = count + 1;\n          }, function (err) {\n            expect(err).to.not.exist;\n            test.equal(1, count);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly rewind and restart cursor","suites":["Operation Examples"],"updatePoint":{"line":5215,"column":48,"index":167048},"line":5215,"code":"  it('Should correctly rewind and restart cursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        var docs = [];\n\n        // Insert 100 documents with some data\n        for (var i = 0; i < 100; i++) {\n          var d = new Date().getTime() + i * 1000;\n          docs[i] = {\n            a: i,\n            createdAt: new Date(d)\n          };\n        }\n\n        // Create collection\n        var collection = db.collection('Should_correctly_rewind_and_restart_cursor');\n\n        // insert all docs\n        collection.insertMany(docs, configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n\n          // Grab a cursor using the find\n          var cursor = collection.find({});\n          // Fetch the first object off the cursor\n          cursor.next(function (err, item) {\n            expect(err).to.not.exist;\n            expect(item).to.have.property('a', 0);\n            // Rewind the cursor, resetting it to point to the start of the query\n            cursor.rewind();\n\n            // Grab the first object again\n            cursor.next(function (err, item) {\n              expect(err).to.not.exist;\n              expect(item).to.have.property('a', 0);\n              client.close(done);\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUseCursorCountFunction","suites":["Operation Examples"],"updatePoint":{"line":5287,"column":43,"index":169512},"line":5287,"code":"  it('shouldCorrectlyUseCursorCountFunction', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Creat collection\n        var collection = db.collection('cursor_count_collection');\n\n        // Insert some docs\n        collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }], configuration.writeConcernMax(), function (err, docs) {\n          test.ok(docs);\n          expect(err).to.not.exist;\n\n          // Do a find and get the cursor count\n          collection.find().count(function (err, count) {\n            expect(err).to.not.exist;\n            test.equal(2, count);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformSimpleSorts","suites":["Operation Examples"],"updatePoint":{"line":5342,"column":39,"index":171330},"line":5342,"code":"  it('shouldCorrectlyPerformSimpleSorts', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection\n        var collection = db.collection('simple_sort_collection');\n\n        // Insert some documents we can sort on\n        collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax(), function (err, docs) {\n          test.ok(docs);\n          expect(err).to.not.exist;\n\n          // Do normal ascending sort\n          collection.find().sort({\n            a: 1\n          }).next(function (err, item) {\n            expect(err).to.not.exist;\n            test.equal(1, item.a);\n\n            // Do normal descending sort, with new syntax that enforces ordering of sort keys\n            collection.find().sort([['a', -1]]).next(function (err, item) {\n              expect(err).to.not.exist;\n              test.equal(3, item.a);\n              client.close(done);\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformLimitOnCursor","suites":["Operation Examples"],"updatePoint":{"line":5407,"column":41,"index":173493},"line":5407,"code":"  it('shouldCorrectlyPerformLimitOnCursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection\n        var collection = db.collection('simple_limit_collection');\n\n        // Insert some documents we can sort on\n        collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax(), function (err, docs) {\n          test.ok(docs);\n          expect(err).to.not.exist;\n\n          // Limit to only one document returned\n          collection.find().limit(1).toArray(function (err, items) {\n            expect(err).to.not.exist;\n            test.equal(1, items.length);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformSkipOnCursor","suites":["Operation Examples"],"updatePoint":{"line":5464,"column":40,"index":175381},"line":5464,"code":"  it('shouldCorrectlyPerformSkipOnCursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection\n        var collection = db.collection('simple_skip_collection');\n\n        // Insert some documents we can sort on\n        collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax(), function (err, docs) {\n          test.ok(docs);\n          expect(err).to.not.exist;\n\n          // Skip one document\n          collection.find().skip(1).next(function (err, item) {\n            expect(err).to.not.exist;\n            test.equal(2, item.a);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformBatchSizeOnCursor","suites":["Operation Examples"],"updatePoint":{"line":5522,"column":45,"index":177384},"line":5522,"code":"  it('shouldCorrectlyPerformBatchSizeOnCursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        const db = client.db(configuration.db);\n        // Create a collection\n        const collection = db.collection('simple_batch_size_collection');\n\n        // Insert some documents we can sort on\n        collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax(), (err, docs) => {\n          test.ok(docs);\n          expect(err).to.not.exist;\n\n          // Do normal ascending sort\n          const cursor = collection.find().batchSize(1);\n          this.defer(() => cursor.close());\n          cursor.next((err, item) => {\n            expect(err).to.not.exist;\n            test.equal(1, item.a);\n            done();\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformNextOnCursorWithCallbacks","suites":["Operation Examples"],"updatePoint":{"line":5584,"column":53,"index":179388},"line":5584,"code":"  it('shouldCorrectlyPerformNextOnCursorWithCallbacks', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection\n        var collection = db.collection('simple_next_object_collection_with_next');\n\n        // Insert some documents we can sort on\n        collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax(), function (err, docs) {\n          test.ok(docs);\n          expect(err).to.not.exist;\n\n          // Do normal ascending sort\n          var cursor = collection.find();\n          // Perform hasNext check\n          cursor.hasNext(function (err, r) {\n            expect(err).to.not.exist;\n            test.ok(r);\n            cursor.next(function (err, r) {\n              expect(err).to.not.exist;\n              test.equal(1, r.a);\n              cursor.hasNext(function (err, r) {\n                expect(err).to.not.exist;\n                test.ok(r);\n                cursor.next(function (err, r) {\n                  expect(err).to.not.exist;\n                  test.equal(2, r.a);\n                  cursor.hasNext(function (err, r) {\n                    expect(err).to.not.exist;\n                    test.ok(r);\n                    cursor.next(function (err, r) {\n                      expect(err).to.not.exist;\n                      test.equal(3, r.a);\n                      cursor.hasNext(function (err, r) {\n                        expect(err).to.not.exist;\n                        test.ok(!r);\n                        client.close(done);\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformSimpleExplainCursor","suites":["Operation Examples"],"updatePoint":{"line":5667,"column":47,"index":182259},"line":5667,"code":"  it('shouldCorrectlyPerformSimpleExplainCursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a collection\n        var collection = db.collection('simple_explain_collection');\n\n        // Insert some documents we can sort on\n        collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax(), function (err, docs) {\n          test.ok(docs);\n          expect(err).to.not.exist;\n\n          // Do normal ascending sort\n          collection.find().explain(function (err, explanation) {\n            test.ok(explanation);\n            expect(err).to.not.exist;\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldStreamDocumentsUsingTheStreamFunction","suites":["Operation Examples"],"updatePoint":{"line":5724,"column":49,"index":184148},"line":5724,"code":"  it('shouldStreamDocumentsUsingTheStreamFunction', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a lot of documents to insert\n        var docs = [];\n        for (var i = 0; i < 100; i++) {\n          docs.push({\n            a: i\n          });\n        }\n\n        // Create a collection\n        var collection = db.collection('test_stream_function');\n\n        // Insert documents into collection\n        collection.insertMany(docs, configuration.writeConcernMax(), function (err, ids) {\n          test.ok(ids);\n          expect(err).to.not.exist;\n\n          // Perform a find to get a cursor\n          var stream = collection.find().stream();\n\n          // Execute find on all the documents\n          stream.on('end', function () {\n            client.close(done);\n          });\n          stream.on('data', function (data) {\n            test.ok(data != null);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldStreamDocumentsUsingTheIsCloseFunction","suites":["Operation Examples"],"updatePoint":{"line":5784,"column":50,"index":186163},"line":5784,"code":"  it('shouldStreamDocumentsUsingTheIsCloseFunction', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a lot of documents to insert\n        var docs = [];\n        for (var i = 0; i < 100; i++) {\n          docs.push({\n            a: i\n          });\n        }\n\n        // Create a collection\n        var collection = db.collection('test_is_close_function_on_cursor');\n\n        // Insert documents into collection\n        collection.insertMany(docs, configuration.writeConcernMax(), function (err, ids) {\n          test.ok(ids);\n          expect(err).to.not.exist;\n\n          // Perform a find to get a cursor\n          var cursor = collection.find();\n\n          // Fetch the first object\n          cursor.next(function (err, object) {\n            test.ok(object);\n            expect(err).to.not.exist;\n\n            // Close the cursor, this is the same as reseting the query\n            cursor.close(function (err) {\n              expect(err).to.not.exist;\n              test.equal(true, cursor.closed);\n              client.close(done);\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldStreamDocumentsUsingTheCloseFunction","suites":["Operation Examples"],"updatePoint":{"line":5852,"column":48,"index":188425},"line":5852,"code":"  it('shouldStreamDocumentsUsingTheCloseFunction', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a lot of documents to insert\n        var docs = [];\n        for (var i = 0; i < 100; i++) {\n          docs.push({\n            a: i\n          });\n        }\n\n        // Create a collection\n        var collection = db.collection('test_close_function_on_cursor');\n\n        // Insert documents into collection\n        collection.insertMany(docs, configuration.writeConcernMax(), function (err, ids) {\n          test.ok(ids);\n          expect(err).to.not.exist;\n\n          // Perform a find to get a cursor\n          var cursor = collection.find();\n\n          // Fetch the first object\n          cursor.next(function (err, object) {\n            test.ok(object);\n            expect(err).to.not.exist;\n\n            // Close the cursor, this is the same as reseting the query\n            cursor.close(function (err) {\n              expect(err).to.not.exist;\n              client.close(done);\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldStreamDocumentsUsingTheCursorStreamPauseFunction","suites":["Operation Examples"],"updatePoint":{"line":5919,"column":60,"index":190656},"line":5919,"code":"  it('shouldStreamDocumentsUsingTheCursorStreamPauseFunction', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a lot of documents to insert\n        var docs = [];\n        var fetchedDocs = [];\n        for (var i = 0; i < 2; i++) {\n          docs.push({\n            a: i\n          });\n        }\n\n        // Create a collection\n        var collection = db.collection('test_cursorstream_pause');\n\n        // Insert documents into collection\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, ids) {\n          test.ok(ids);\n          expect(err).to.not.exist;\n\n          // Perform a find to get a cursor\n          var stream = collection.find().stream();\n\n          // For each data item\n          stream.on('data', function (item) {\n            fetchedDocs.push(item);\n            // Pause stream\n            stream.pause();\n\n            // Restart the stream after 1 miliscecond\n            setTimeout(function () {\n              fetchedDocs.push(null);\n              stream.resume();\n            }, 1);\n          });\n\n          // When the stream is done\n          stream.on('end', function () {\n            expect(fetchedDocs[1]).to.not.exist;\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldStreamDocumentsUsingTheCursorStreamDestroyFunction","suites":["Operation Examples"],"updatePoint":{"line":5996,"column":62,"index":192995},"line":5996,"code":"  it('shouldStreamDocumentsUsingTheCursorStreamDestroyFunction', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Create a lot of documents to insert\n        var docs = [];\n        for (var i = 0; i < 1; i++) {\n          docs.push({\n            a: i\n          });\n        }\n\n        // Create a collection\n        var collection = db.collection('test_cursorstream_destroy');\n\n        // Insert documents into collection\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, ids) {\n          test.ok(ids);\n          expect(err).to.not.exist;\n\n          // Perform a find to get a cursor\n          const cursor = collection.find();\n          const stream = cursor.stream();\n\n          // For each data item\n          stream.on('data', function () {\n            // Destroy stream\n            stream.destroy();\n          });\n\n          // When the stream is done\n          cursor.on('close', function () {\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly connect to a replicaset","suites":["Operation Examples"],"updatePoint":{"line":6070,"column":46,"index":195249},"line":6070,"code":"  it('Should correctly connect to a replicaset', {\n    metadata: {\n      requires: {\n        topology: 'replicaset'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n\n      // Create url\n      var url = f('mongodb://%s,%s/%s?replicaSet=%s&readPreference=%s', f('%s:%s', configuration.host, configuration.port), f('%s:%s', configuration.host, configuration.port + 1), 'integration_test_', configuration.replicasetName, 'primary');\n      const client = configuration.newClient(url);\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        test.ok(db != null);\n        db.collection('replicaset_mongo_client_collection').updateOne({\n          a: 1\n        }, {\n          $set: {\n            b: 1\n          }\n        }, {\n          upsert: true\n        }, function (err, result) {\n          expect(err).to.not.exist;\n          expect(result).property('upsertedCount').to.equal(1);\n          client.close(done);\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should connect to mongos proxies using connectiong string","suites":["Operation Examples"],"updatePoint":{"line":6119,"column":63,"index":196979},"line":6119,"code":"  it('Should connect to mongos proxies using connectiong string', {\n    metadata: {\n      requires: {\n        topology: 'sharded'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var url = f('mongodb://%s:%s,%s:%s/sharded_test_db?w=1', configuration.host, configuration.port, configuration.host, configuration.port + 1);\n      const client = configuration.newClient(url);\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        test.ok(db != null);\n        db.collection('replicaset_mongo_client_collection').updateOne({\n          a: 1\n        }, {\n          $set: {\n            b: 1\n          }\n        }, {\n          upsert: true\n        }, function (err, result) {\n          expect(err).to.not.exist;\n          test.equal(1, result.upsertedCount);\n          client.close(done);\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly connect using MongoClient to a single server using connect","suites":["Operation Examples"],"updatePoint":{"line":6166,"column":81,"index":198578},"line":6166,"code":"  it('Should correctly connect using MongoClient to a single server using connect', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient();\n\n      // DOC_START\n      // Connect using the connection string\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        db.collection('mongoclient_test').updateOne({\n          a: 1\n        }, {\n          $set: {\n            b: 1\n          }\n        }, {\n          upsert: true\n        }, function (err, result) {\n          expect(err).to.not.exist;\n          expect(result).property('upsertedCount').to.equal(1);\n          client.close(done);\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyGenerate12ByteStringFromTimestamp","suites":["Operation Examples"],"updatePoint":{"line":6224,"column":54,"index":200408},"line":6224,"code":"  it('shouldCorrectlyGenerate12ByteStringFromTimestamp', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      // LINE var ObjectId = require('mongodb').ObjectId,\n      // LINE   test = require('assert');\n      // REPLACE configuration.writeConcernMax() WITH {w:1}\n      // REMOVE-LINE done();\n      // BEGIN\n      // Get a timestamp in seconds\n      var timestamp = Math.floor(new Date().getTime() / 1000);\n      // Create a date with the timestamp\n      var timestampDate = new Date(timestamp * 1000);\n\n      // Create a new ObjectId with a specific timestamp\n      var objectId = new ObjectId(timestamp);\n\n      // Get the timestamp and validate correctness\n      test.equal(timestampDate.toString(), objectId.getTimestamp().toString());\n      done();\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieve24CharacterHexStringFromToHexString","suites":["Operation Examples"],"updatePoint":{"line":6257,"column":64,"index":201463},"line":6257,"code":"  it('shouldCorrectlyRetrieve24CharacterHexStringFromToHexString', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      // LINE var ObjectId = require('mongodb').ObjectId,\n      // LINE   test = require('assert');\n      // REPLACE configuration.writeConcernMax() WITH {w:1}\n      // REMOVE-LINE done();\n      // BEGIN\n      // Create a new ObjectId\n      var objectId = new ObjectId();\n      // Verify that the hex string is 24 characters long\n      test.equal(24, objectId.toHexString().length);\n      done();\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyGetAndSetObjectIdUsingGenerationTimeProperty","suites":["Operation Examples"],"updatePoint":{"line":6284,"column":65,"index":202251},"line":6284,"code":"  it('shouldCorrectlyGetAndSetObjectIdUsingGenerationTimeProperty', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      // LINE var ObjectId = require('mongodb').ObjectId,\n      // LINE   test = require('assert');\n      // REPLACE configuration.writeConcernMax() WITH {w:1}\n      // REMOVE-LINE done();\n      // BEGIN\n      // Create a new ObjectId\n      var objectId = new ObjectId();\n      // Get the generation time\n      var generationTime = objectId.generationTime;\n      // Add 1000 milliseconds to the generation time\n      objectId.generationTime = generationTime + 1000;\n\n      // Create a timestamp\n      var timestampDate = new Date();\n      timestampDate.setTime((generationTime + 1000) * 1000);\n\n      // Get the timestamp and validate correctness\n      test.equal(timestampDate.toString(), objectId.getTimestamp().toString());\n      done();\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyTransformObjectIdToHexAndObjectId","suites":["Operation Examples"],"updatePoint":{"line":6320,"column":54,"index":203410},"line":6320,"code":"  it('shouldCorrectlyTransformObjectIdToHexAndObjectId', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      // LINE var ObjectId = require('mongodb').ObjectId,\n      // LINE   test = require('assert');\n      // REPLACE configuration.writeConcernMax() WITH {w:1}\n      // REMOVE-LINE done();\n      // BEGIN\n      // Create a new ObjectId\n      var objectId = new ObjectId();\n      // Convert the object id to a hex string\n      var originalHex = objectId.toHexString();\n      // Create a new ObjectId using the createFromHexString function\n      var newObjectId = ObjectId.createFromHexString(originalHex);\n      // Convert the new ObjectId back into a hex string using the toHexString function\n      var newHex = newObjectId.toHexString();\n      // Compare the two hex strings\n      test.equal(originalHex, newHex);\n      done();\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDifferentiateBetweenObjectIdInstances","suites":["Operation Examples"],"updatePoint":{"line":6353,"column":58,"index":204523},"line":6353,"code":"  it('shouldCorrectlyDifferentiateBetweenObjectIdInstances', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      // LINE var ObjectId = require('mongodb').ObjectId,\n      // LINE   test = require('assert');\n      // REPLACE configuration.writeConcernMax() WITH {w:1}\n      // REMOVE-LINE done();\n      // BEGIN\n      // Create a new ObjectId\n      var objectId = new ObjectId();\n      // Create a new ObjectId Based on the first ObjectId\n      var objectId2 = new ObjectId(objectId.id);\n      // Create another ObjectId\n      var objectId3 = new ObjectId();\n      // objectId and objectId2 should be the same\n      test.ok(objectId.equals(objectId2));\n      // objectId and objectId2 should be different\n      test.ok(!objectId.equals(objectId3));\n      done();\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUseCreateFromTime","suites":["Operation Examples"],"updatePoint":{"line":6386,"column":38,"index":205558},"line":6386,"code":"  it('shouldCorrectlyUseCreateFromTime', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      // LINE var ObjectId = require('mongodb').ObjectId,\n      // LINE   test = require('assert');\n      // REPLACE configuration.writeConcernMax() WITH {w:1}\n      // REMOVE-LINE done();\n      // BEGIN\n      var objectId = ObjectId.createFromTime(1);\n      test.equal('000000010000000000000000', objectId.toHexString());\n      done();\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute ordered batch with no errors using write commands","suites":["Operation Examples"],"updatePoint":{"line":6417,"column":80,"index":206522},"line":6417,"code":"  it('Should correctly execute ordered batch with no errors using write commands', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Get the collection\n        var col = db.collection('batch_write_ordered_ops_0');\n        // Initialize the Ordered Batch\n        var batch = col.initializeOrderedBulkOp();\n        // Add some operations to be executed in order\n        batch.insert({\n          a: 1\n        });\n        batch.find({\n          a: 1\n        }).updateOne({\n          $set: {\n            b: 1\n          }\n        });\n        batch.find({\n          a: 2\n        }).upsert().updateOne({\n          $set: {\n            b: 2\n          }\n        });\n        batch.insert({\n          a: 3\n        });\n        batch.find({\n          a: 3\n        }).delete({\n          a: 3\n        });\n\n        // Execute the operations\n        batch.execute(function (err, result) {\n          // Check state of result\n          test.equal(2, result.nInserted);\n          test.equal(1, result.nUpserted);\n          test.equal(1, result.nMatched);\n          test.ok(1 === result.nModified || result.nModified == null);\n          test.equal(1, result.nRemoved);\n          var upserts = result.getUpsertedIds();\n          test.equal(1, upserts.length);\n          test.equal(2, upserts[0].index);\n          test.ok(upserts[0]._id != null);\n          var upsert = result.getUpsertedIdAt(0);\n          test.equal(2, upsert.index);\n          test.ok(upsert._id != null);\n\n          // Finish up test\n          client.close(done);\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute unordered batch with no errors","suites":["Operation Examples"],"updatePoint":{"line":6502,"column":61,"index":209113},"line":6502,"code":"  it('Should correctly execute unordered batch with no errors', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Get the collection\n        var col = db.collection('batch_write_unordered_ops_legacy_0');\n        // Initialize the unordered Batch\n        var batch = col.initializeUnorderedBulkOp();\n\n        // Add some operations to be executed in order\n        batch.insert({\n          a: 1\n        });\n        batch.find({\n          a: 1\n        }).updateOne({\n          $set: {\n            b: 1\n          }\n        });\n        batch.find({\n          a: 2\n        }).upsert().updateOne({\n          $set: {\n            b: 2\n          }\n        });\n        batch.insert({\n          a: 3\n        });\n        batch.find({\n          a: 3\n        }).delete({\n          a: 3\n        });\n\n        // Execute the operations\n        batch.execute(function (err, result) {\n          // Check state of result\n          test.equal(2, result.nInserted);\n          test.equal(1, result.nUpserted);\n          test.equal(1, result.nMatched);\n          test.ok(1 === result.nModified || result.nModified == null);\n          test.equal(1, result.nRemoved);\n          var upserts = result.getUpsertedIds();\n          test.equal(1, upserts.length);\n          test.equal(2, upserts[0].index);\n          test.ok(upserts[0]._id != null);\n          var upsert = result.getUpsertedIdAt(0);\n          test.equal(2, upsert.index);\n          test.ok(upsert._id != null);\n\n          // Finish up test\n          client.close(done);\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute insertOne operation","suites":["Operation Examples"],"updatePoint":{"line":6593,"column":50,"index":211823},"line":6593,"code":"  it('Should correctly execute insertOne operation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Get the collection\n        var col = db.collection('insert_one');\n        col.insertOne({\n          a: 1\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedId').to.exist;\n          // Finish up test\n          client.close(done);\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute insertMany operation","suites":["Operation Examples"],"updatePoint":{"line":6637,"column":51,"index":213257},"line":6637,"code":"  it('Should correctly execute insertMany operation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Get the collection\n        var col = db.collection('insert_many');\n        col.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }], function (err, r) {\n          expect(err).to.not.exist;\n          test.equal(2, r.insertedCount);\n          // Finish up test\n          client.close(done);\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute updateOne operation","suites":["Operation Examples"],"updatePoint":{"line":6683,"column":50,"index":214709},"line":6683,"code":"  it('Should correctly execute updateOne operation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Get the collection\n        var col = db.collection('update_one');\n        col.updateOne({\n          a: 1\n        }, {\n          $set: {\n            a: 2\n          }\n        }, {\n          upsert: true\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          test.equal(0, r.matchedCount);\n          test.equal(1, r.upsertedCount);\n          // Finish up test\n          client.close(done);\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute updateMany operation","suites":["Operation Examples"],"updatePoint":{"line":6734,"column":51,"index":216269},"line":6734,"code":"  it('Should correctly execute updateMany operation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Get the collection\n        var col = db.collection('update_many');\n        col.insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }], function (err, r) {\n          expect(err).to.not.exist;\n          test.equal(2, r.insertedCount);\n\n          // Update all documents\n          col.updateMany({\n            a: 1\n          }, {\n            $set: {\n              b: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            test.equal(2, r.matchedCount);\n            test.equal(2, r.modifiedCount);\n\n            // Finish up test\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute deleteOne operation","suites":["Operation Examples"],"updatePoint":{"line":6794,"column":50,"index":218045},"line":6794,"code":"  it('Should correctly execute deleteOne operation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Get the collection\n        var col = db.collection('remove_one');\n        col.insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }], function (err, r) {\n          expect(err).to.not.exist;\n          test.equal(2, r.insertedCount);\n          col.deleteOne({\n            a: 1\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            test.equal(1, r.deletedCount);\n            // Finish up test\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute removeMany operation","suites":["Operation Examples"],"updatePoint":{"line":6846,"column":51,"index":219674},"line":6846,"code":"  it('Should correctly execute removeMany operation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Get the collection\n        var col = db.collection('remove_many');\n        col.insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }], function (err, r) {\n          expect(err).to.not.exist;\n          test.equal(2, r.insertedCount);\n\n          // Update all documents\n          col.deleteMany({\n            a: 1\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            test.equal(2, r.deletedCount);\n\n            // Finish up test\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute bulkWrite operation","suites":["Operation Examples"],"updatePoint":{"line":6901,"column":50,"index":221338},"line":6901,"code":"  it('Should correctly execute bulkWrite operation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Get the collection\n        var col = db.collection('bulk_write');\n        col.bulkWrite([{\n          insertOne: {\n            document: {\n              a: 1\n            }\n          }\n        }, {\n          updateOne: {\n            filter: {\n              a: 2\n            },\n            update: {\n              $set: {\n                a: 2\n              }\n            },\n            upsert: true\n          }\n        }, {\n          updateMany: {\n            filter: {\n              a: 2\n            },\n            update: {\n              $set: {\n                a: 2\n              }\n            },\n            upsert: true\n          }\n        }, {\n          deleteOne: {\n            filter: {\n              c: 1\n            }\n          }\n        }, {\n          deleteMany: {\n            filter: {\n              c: 1\n            }\n          }\n        }, {\n          replaceOne: {\n            filter: {\n              c: 3\n            },\n            replacement: {\n              c: 4\n            },\n            upsert: true\n          }\n        }], {\n          ordered: true,\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          test.equal(1, r.nInserted);\n          test.equal(2, r.nUpserted);\n          test.equal(0, r.nRemoved);\n\n          // Crud fields\n          test.equal(1, r.insertedCount);\n          test.equal(1, Object.keys(r.insertedIds).length);\n          test.equal(1, r.matchedCount);\n          test.ok(r.modifiedCount === 0 || r.modifiedCount === 1);\n          test.equal(0, r.deletedCount);\n          test.equal(2, r.upsertedCount);\n          test.equal(2, Object.keys(r.upsertedIds).length);\n\n          // Ordered bulk operation\n          client.close(done);\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndDelete operation","suites":["Operation Examples"],"updatePoint":{"line":7012,"column":57,"index":224259},"line":7012,"code":"  it('Should correctly execute findOneAndDelete operation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Get the collection\n        var col = db.collection('find_one_and_delete');\n        col.insertMany([{\n          a: 1,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedCount').to.equal(1);\n          col.findOneAndDelete({\n            a: 1\n          }, {\n            projection: {\n              b: 1\n            },\n            sort: {\n              a: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            test.equal(1, r.lastErrorObject.n);\n            test.equal(1, r.value.b);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndReplace operation","suites":["Operation Examples"],"updatePoint":{"line":7074,"column":58,"index":226139},"line":7074,"code":"  it('Should correctly execute findOneAndReplace operation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Get the collection\n        var col = db.collection('find_one_and_replace');\n        col.insertMany([{\n          a: 1,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedCount').to.equal(1);\n          col.findOneAndReplace({\n            a: 1\n          }, {\n            c: 1,\n            b: 1\n          }, {\n            projection: {\n              b: 1,\n              c: 1\n            },\n            sort: {\n              a: 1\n            },\n            returnDocument: ReturnDocument.AFTER,\n            upsert: true\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            test.equal(1, r.lastErrorObject.n);\n            test.equal(1, r.value.b);\n            test.equal(1, r.value.c);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndUpdate operation","suites":["Operation Examples"],"updatePoint":{"line":7143,"column":57,"index":228202},"line":7143,"code":"  it('Should correctly execute findOneAndUpdate operation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        // Get the collection\n        var col = db.collection('find_one_and_update');\n        col.insertMany([{\n          a: 1,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedCount').to.equal(1);\n          col.findOneAndUpdate({\n            a: 1\n          }, {\n            $set: {\n              d: 1\n            }\n          }, {\n            projection: {\n              b: 1,\n              d: 1\n            },\n            sort: {\n              a: 1\n            },\n            returnDocument: ReturnDocument.AFTER,\n            upsert: true\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            test.equal(1, r.lastErrorObject.n);\n            test.equal(1, r.value.b);\n            test.equal(1, r.value.d);\n            client.close(done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly add capped collection options to cursor","suites":["Operation Examples"],"updatePoint":{"line":7213,"column":62,"index":230293},"line":7213,"code":"  it('Should correctly add capped collection options to cursor', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n\n        // Create a capped collection with a maximum of 1000 documents\n        db.createCollection('a_simple_collection_2', {\n          capped: true,\n          size: 100000,\n          max: 1000,\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, collection) {\n          expect(err).to.not.exist;\n          var docs = [];\n          for (var i = 0; i < 1000; i++) docs.push({\n            a: i\n          });\n\n          // Insert a document in the capped collection\n          collection.insertMany(docs, configuration.writeConcernMax(), function (err, result) {\n            test.ok(result);\n            expect(err).to.not.exist;\n            var total = 0;\n\n            // Get the cursor\n            var cursor = collection.find({}).addCursorFlag('tailable', true).addCursorFlag('awaitData', true);\n            const stream = cursor.stream();\n            stream.on('data', function () {\n              total = total + 1;\n              if (total === 1000) {\n                cursor.close();\n              }\n            });\n            cursor.on('close', function () {\n              client.close(done);\n            });\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"aggregationExample2WithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":49,"column":37,"index":1303},"line":49,"code":"  it('aggregationExample2WithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Some docs for insertion\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }];\n\n        // Create a collection\n        var collection = db.collection('aggregationExample2_with_promise');\n\n        // Insert the docs\n        return collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          test.ok(result);\n\n          // Execute aggregate, notice the pipeline is expressed as an Array\n          var cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }], {\n            cursor: {\n              batchSize: 1\n            }\n          });\n\n          // Get all the aggregation results\n          return cursor.toArray();\n        }).then(function (docs) {\n          test.equal(2, docs.length);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Aggregation Cursor next Test With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":143,"column":48,"index":3927},"line":143,"code":"  it('Aggregation Cursor next Test With Promises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Some docs for insertion\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }];\n\n        // Create a collection\n        var collection = db.collection('aggregation_next_example_with_promise');\n        let cursor;\n        // Insert the docs\n        return collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          test.ok(result);\n\n          // Execute aggregate, notice the pipeline is expressed as an Array\n          cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }], {\n            cursor: {\n              batchSize: 1\n            }\n          });\n\n          // Get all the aggregation results\n          return cursor.next();\n        }).then(function (docs) {\n          test.ok(docs);\n\n          // Need to close cursor to close implicit session,\n          // since cursor is not exhausted\n          return cursor.close();\n        }).then(() => client.close());\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDoSimpleCountExamplesWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":239,"column":54,"index":6670},"line":239,"code":"  it('shouldCorrectlyDoSimpleCountExamplesWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        w: 0\n      }, {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Crete the collection for the distinct example\n        var collection = db.collection('countExample1_with_promise');\n\n        // Insert documents to perform distinct against\n        return collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }, {\n          a: 4,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (ids) {\n          test.ok(ids);\n\n          // Perform a total count command\n          return collection.count();\n        }).then(function (count) {\n          test.equal(4, count);\n\n          // Perform a partial account where b=1\n          return collection.count({\n            b: 1\n          });\n        }).then(function (count) {\n          test.equal(1, count);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCreateComplexIndexOnTwoFieldsWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":306,"column":53,"index":8559},"line":306,"code":"  it('shouldCreateComplexIndexOnTwoFieldsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection we want to drop later\n        var collection = db.collection('createIndexExample1_with_promise');\n\n        // Insert a bunch of documents for the index\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result);\n\n          // Create an index on the a field\n          return collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          test.ok(indexName);\n\n          // Show that duplicate records got dropped\n          return collection.find({}).toArray();\n        }).then(function (items) {\n          test.equal(4, items.length);\n\n          // Perform a query, with explain to show we hit the query\n          return collection.find({\n            a: 2\n          }).explain();\n        }).then(function (explanation) {\n          test.ok(explanation != null);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleDistinctIndexesWithSubQueryFilterWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":384,"column":72,"index":10852},"line":384,"code":"  it('shouldCorrectlyHandleDistinctIndexesWithSubQueryFilterWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Crete the collection for the distinct example\n        var collection = db.collection('distinctExample1_with_promise');\n\n        // Insert documents to perform distinct against\n        return collection.insertMany([{\n          a: 0,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'b'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'c'\n          }\n        }, {\n          a: 2,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 3\n        }, {\n          a: 3\n        }], configuration.writeConcernMax()).then(function (ids) {\n          test.ok(ids);\n\n          // Perform a distinct query against the a field\n          return collection.distinct('a');\n        }).then(function (docs) {\n          test.deepEqual([0, 1, 2, 3], docs.sort());\n\n          // Perform a distinct query against the sub-field b.c\n          return collection.distinct('b.c');\n        }).then(function (docs) {\n          test.deepEqual(['a', 'b', 'c'], docs.sort());\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleDistinctIndexesWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":455,"column":54,"index":12909},"line":455,"code":"  it('shouldCorrectlyHandleDistinctIndexesWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Crete the collection for the distinct example\n        var collection = db.collection('distinctExample2_with_promise');\n\n        // Insert documents to perform distinct against\n        return collection.insertMany([{\n          a: 0,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'b'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'c'\n          }\n        }, {\n          a: 2,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 3\n        }, {\n          a: 3\n        }, {\n          a: 5,\n          c: 1\n        }], configuration.writeConcernMax()).then(function (ids) {\n          test.ok(ids);\n\n          // Perform a distinct query with a filter against the documents\n          return collection.distinct('a', {\n            c: 1\n          });\n        }).then(function (docs) {\n          test.deepEqual([5], docs.sort());\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDropCollectionWithDropFunctionWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":530,"column":63,"index":14877},"line":530,"code":"  it('shouldCorrectlyDropCollectionWithDropFunctionWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection we want to drop later\n        return db.createCollection('test_other_drop_with_promise').then(function (collection) {\n          // Drop the collection\n          return collection.drop();\n        }).then(function (reply) {\n          test.ok(reply);\n\n          // Ensure we don't have the collection in the set of names\n          return db.listCollections().toArray();\n        }).then(function (replies) {\n          var found = false;\n          // For each collection in the list of collection names in this db look for the\n          // dropped collection\n          replies.forEach(function (document) {\n            if (document.name === 'test_other_drop_with_promise') {\n              found = true;\n              return;\n            }\n          });\n\n          // Ensure the collection is not found\n          test.equal(false, found);\n\n          // Let's close the db\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"dropIndexesExample1WithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":589,"column":37,"index":16827},"line":589,"code":"  it('dropIndexesExample1WithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        return db.createCollection('dropExample1_with_promise').then(function (r) {\n          test.ok(r);\n\n          // Drop the collection\n          return db.collection('dropExample1_with_promise').dropIndexes();\n        }).then(function (reply) {\n          test.ok(reply);\n\n          // Let's close the db\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateAndDropIndexWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":632,"column":51,"index":18184},"line":632,"code":"  it('shouldCorrectlyCreateAndDropIndexWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        var collection = db.collection('dropIndexExample1_with_promise');\n\n        // Insert a bunch of documents for the index\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          test.ok(result);\n\n          // Create an index on the a field\n          return collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          test.ok(indexName);\n\n          // Drop the index\n          return collection.dropIndex('a_1_b_1');\n        }).then(function (result) {\n          test.ok(result);\n          // Verify that the index is gone\n          return collection.indexInformation();\n        }).then(function (indexInformation) {\n          test.deepEqual([['_id', 1]], indexInformation._id_);\n          expect(indexInformation.a_1_b_1).to.not.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCreateComplexEnsureIndexWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":711,"column":48,"index":20449},"line":711,"code":"  it('shouldCreateComplexEnsureIndexWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        var collection = db.collection('ensureIndexExample1_with_promise');\n\n        // Insert a bunch of documents for the index\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result);\n\n          // Create an index on the a field\n          return db.createIndex('ensureIndexExample1_with_promise', {\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          test.ok(indexName);\n\n          // Show that duplicate records got dropped\n          return collection.find({}).toArray();\n        }).then(function (items) {\n          test.equal(4, items.length);\n\n          // Perform a query, with explain to show we hit the query\n          return collection.find({\n            a: 2\n          }).explain();\n        }).then(function (explanation) {\n          test.ok(explanation != null);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"ensureIndexExampleWithCompountIndexWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":788,"column":53,"index":22716},"line":788,"code":"  it('ensureIndexExampleWithCompountIndexWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        var collection = db.collection('ensureIndexExample2_with_promise');\n\n        // Insert a bunch of documents for the index\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          test.ok(result);\n\n          // Create an index on the a field\n          return collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          test.ok(indexName);\n\n          // Show that duplicate records got dropped\n          return collection.find({}).toArray();\n        }).then(function (items) {\n          test.equal(4, items.length);\n\n          // Perform a query, with explain to show we hit the query\n          return collection.find({\n            a: 2\n          }).explain();\n        }).then(function (explanation) {\n          test.ok(explanation != null);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleQueryWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":869,"column":43,"index":24920},"line":869,"code":"  it('shouldPerformASimpleQueryWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection we want to drop later\n        var collection = db.collection('simple_query_with_promise');\n\n        // Insert a bunch of documents for the testing\n        return collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result);\n\n          // Perform a simple find and return all the documents\n          return collection.find().toArray();\n        }).then(function (docs) {\n          test.equal(3, docs.length);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleExplainQueryWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":921,"column":50,"index":26522},"line":921,"code":"  it('shouldPerformASimpleExplainQueryWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection we want to drop later\n        var collection = db.collection('simple_explain_query_with_promise');\n\n        // Insert a bunch of documents for the testing\n        return collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result);\n\n          // Perform a simple find and return all the documents\n          return collection.find({}).explain();\n        }).then(function (docs) {\n          test.ok(docs != null);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleLimitSkipQueryWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":973,"column":52,"index":28122},"line":973,"code":"  it('shouldPerformASimpleLimitSkipQueryWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection we want to drop later\n        var collection = db.collection('simple_limit_skip_query_with_promise');\n\n        // Insert a bunch of documents for the testing\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result);\n\n          // Perform a simple find and return all the documents\n          return collection.find({}).skip(1).limit(1).project({\n            b: 1\n          }).toArray();\n        }).then(function (docs) {\n          test.equal(1, docs.length);\n          expect(docs[0].a).to.not.exist;\n          test.equal(2, docs[0].b);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformSimpleFindAndModifyOperationsWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1036,"column":60,"index":30204},"line":1036,"code":"  it('shouldPerformSimpleFindAndModifyOperationsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection we want to drop later\n        var collection = db.collection('simple_find_and_modify_operations_with_promise');\n\n        // Insert some test documentations\n        return collection.insertMany([{\n          a: 1\n        }, {\n          b: 1\n        }, {\n          c: 1\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result);\n\n          // Simple findAndModify command returning the new document\n          return collection.findOneAndUpdate({\n            a: 1\n          }, {\n            $set: {\n              b1: 1\n            }\n          }, {\n            returnDocument: ReturnDocument.AFTER\n          });\n        }).then(function (doc) {\n          test.equal(1, doc.value.a);\n          test.equal(1, doc.value.b1);\n\n          // Simple findAndModify command returning the new document and\n          // removing it at the same time\n          return collection.findOneAndUpdate({\n            b: 1\n          }, {\n            $set: {\n              b: 2\n            }\n          }, {\n            remove: true\n          });\n        }).then(function (doc) {\n          test.ok(doc);\n\n          // Verify that the document is gone\n          return collection.findOne({\n            b: 1\n          });\n        }).then(function (item) {\n          expect(item).to.not.exist;\n\n          // Simple findAndModify command performing an upsert and returning the new document\n          // executing the command safely\n          return collection.findOneAndUpdate({\n            d: 1\n          }, {\n            $set: {\n              d: 1,\n              f: 1\n            }\n          }, {\n            returnDocument: ReturnDocument.AFTER,\n            upsert: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (doc) {\n          test.equal(1, doc.value.d);\n          test.equal(1, doc.value.f);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformSimplefindOneAndDeleteWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1137,"column":53,"index":33137},"line":1137,"code":"  it('shouldPerformSimplefindOneAndDeleteWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection we want to drop later\n        var collection = db.collection('simple_find_and_modify_operations_2_with_promise');\n\n        // Insert some test documentations\n        return collection.insertMany([{\n          a: 1\n        }, {\n          b: 1,\n          d: 1\n        }, {\n          c: 1\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result);\n\n          // Simple findAndModify command returning the old document and\n          // removing it at the same time\n          return collection.findOneAndDelete({\n            b: 1\n          }, [['b', 1]]);\n        }).then(function (doc) {\n          test.equal(1, doc.value.b);\n          test.equal(1, doc.value.d);\n\n          // Verify that the document is gone\n          return collection.findOne({\n            b: 1\n          });\n        }).then(function (item) {\n          expect(item).to.not.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleLimitSkipFindOneQueryWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1201,"column":59,"index":35078},"line":1201,"code":"  it('shouldPerformASimpleLimitSkipFindOneQueryWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection we want to drop later\n        var collection = db.collection('simple_limit_skip_find_one_query_with_promise');\n\n        // Insert a bunch of documents for the testing\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result);\n\n          // Perform a simple find and return all the documents\n          return collection.findOne({\n            a: 2\n          }, {\n            projection: {\n              b: 1\n            }\n          });\n        }).then(function (doc) {\n          expect(doc.a).to.not.exist;\n          test.equal(2, doc.b);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformSimpleMapReduceFunctionsWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1263,"column":55,"index":36867},"line":1263,"code":"  it('shouldPerformSimpleMapReduceFunctionsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        w: 0\n      }, {\n        maxPoolSize: 1\n      });\n\n      /* eslint-disable */\n\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a test collection\n        var collection = db.collection('test_map_reduce_functions_with_promise');\n\n        // Insert some documents to perform map reduce over\n        return collection.insertMany([{\n          user_id: 1\n        }, {\n          user_id: 2\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function () {\n          // Map function\n          var map = function () {\n            emit(this.user_id, 1);\n          };\n\n          // Reduce function\n          var reduce = function (k, vals) {\n            return 1;\n          };\n\n          // Perform the map reduce\n          return collection.mapReduce(map, reduce, {\n            out: {\n              replace: 'tempCollection'\n            }\n          });\n        }).then(function (reducedCollection) {\n          // Mapreduce returns the temporary collection with the results\n          return reducedCollection.findOne({\n            _id: 1\n          }).then(function (result) {\n            test.equal(1, result.value);\n            return reducedCollection;\n          });\n        }).then(function (reducedCollection) {\n          return reducedCollection.findOne({\n            _id: 2\n          });\n        }).then(function (result) {\n          test.equal(1, result.value);\n          return client.close();\n        });\n      });\n      // END\n\n      /* eslint-enable */\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformMapReduceFunctionInlineWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1348,"column":54,"index":39292},"line":1348,"code":"  it('shouldPerformMapReduceFunctionInlineWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>1.7.6',\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        w: 0\n      }, {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a test collection\n        var collection = db.collection('test_map_reduce_functions_inline_with_promise');\n\n        /* eslint-disable */\n        // Map function\n        var map = function () {\n          emit(this.user_id, 1);\n        };\n\n        // Reduce function\n        var reduce = function (k, vals) {\n          return 1;\n        };\n        /* eslint-enable */\n\n        // Insert some test documents\n        return collection.insertMany([{\n          user_id: 1\n        }, {\n          user_id: 2\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function () {\n          // Execute map reduce and return results inline\n          return collection.mapReduce(map, reduce, {\n            out: {\n              inline: 1\n            },\n            verbose: true\n          });\n        }).then(function (result) {\n          test.equal(2, result.results.length);\n          test.ok(result.stats != null);\n          return collection.mapReduce(map, reduce, {\n            out: {\n              replace: 'mapreduce_integration_test'\n            },\n            verbose: true\n          });\n        }).then(function (result) {\n          test.ok(result.stats != null);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformMapReduceWithContextWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1431,"column":51,"index":41715},"line":1431,"code":"  it('shouldPerformMapReduceWithContextWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   Code = require('mongodb').Code,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a test collection\n        var collection = db.collection('test_map_reduce_functions_scope_with_promise');\n\n        /* eslint-disable */\n        // Map function\n        var map = function () {\n          emit(fn(this.timestamp.getYear()), 1);\n        };\n\n        // Reduce function\n        var reduce = function (k, v) {\n          var count = 0;\n          for (var i = 0; i < v.length; i++) {\n            count += v[i];\n          }\n          return count;\n        };\n\n        // Javascript function available in the map reduce scope\n        var t = function (val) {\n          return val + 1;\n        };\n\n        // Execute the map reduce with the custom scope\n        var o = {};\n        o.scope = {\n          fn: new Code(t.toString())\n        };\n        o.out = {\n          replace: 'replacethiscollection'\n        };\n        /* eslint-enable */\n\n        // Insert some test documents\n        return collection.insertMany([{\n          user_id: 1,\n          timestamp: new Date()\n        }, {\n          user_id: 2,\n          timestamp: new Date()\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function () {\n          return collection.mapReduce(map, reduce, o);\n        }).then(function (outCollection) {\n          // Find all entries in the map-reduce collection\n          return outCollection.find().toArray();\n        }).then(function (results) {\n          test.equal(2, results[0].value);\n\n          // mapReduce with scope containing plain function\n          var o = {};\n          o.scope = {\n            fn: t\n          };\n          o.out = {\n            replace: 'replacethiscollection'\n          };\n          return collection.mapReduce(map, reduce, o);\n        }).then(function (outCollection) {\n          // Find all entries in the map-reduce collection\n          return outCollection.find().toArray();\n        }).then(function (results) {\n          test.equal(2, results[0].value);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformMapReduceInContextObjectsWithPromises","suites":["Operation (Promises)"],"line":1533,"code":"  it.skip('shouldPerformMapReduceInContextObjectsWithPromises', {","file":"integration/node-specific/operation_promises_example.test.js","skipped":true,"dir":"test"},{"name":"shouldCorrectlyRetrieveACollectionsIndexesWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1641,"column":60,"index":47882},"line":1641,"code":"  it('shouldCorrectlyRetrieveACollectionsIndexesWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Crete the collection for the distinct example\n        var collection = db.collection('simple_key_based_distinct_with_promise');\n\n        // Create a geo 2d index\n        return collection.createIndex({\n          loc: '2d'\n        }, configuration.writeConcernMax()).then(function (result) {\n          test.ok(result);\n\n          // Create a simple single field index\n          return collection.createIndex({\n            a: 1\n          }, configuration.writeConcernMax());\n        }).then(function (result) {\n          test.ok(result);\n          return delay(1000);\n        }).then(function () {\n          // List all of the indexes on the collection\n          return collection.indexes();\n        }).then(function (indexes) {\n          test.equal(3, indexes.length);\n          return client.close();\n        });\n      });\n    }\n    // END\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteIndexExistsWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1696,"column":51,"index":49757},"line":1696,"code":"  it('shouldCorrectlyExecuteIndexExistsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a test collection that we are getting the options back from\n        var collection = db.collection('test_collection_index_exists_with_promise', configuration.writeConcernMax());\n\n        // Create an index on the collection\n        return collection.createIndex('a', configuration.writeConcernMax()).then(function (indexName) {\n          test.ok(indexName);\n\n          // Let's test to check if a single index exists\n          return collection.indexExists('a_1');\n        }).then(function (result) {\n          test.equal(true, result);\n\n          // Let's test to check if multiple indexes are available\n          return collection.indexExists(['a_1', '_id_']);\n        }).then(function (result) {\n          test.equal(true, result);\n\n          // Check if a non existing index exists\n          return collection.indexExists('c_1');\n        }).then(function (result) {\n          test.equal(false, result);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyShowTheResultsFromIndexInformationWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1751,"column":67,"index":51760},"line":1751,"code":"  it('shouldCorrectlyShowTheResultsFromIndexInformationWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection we want to drop later\n        var collection = db.collection('more_index_information_test_2_with_promise');\n\n        // Insert a bunch of documents for the index\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result);\n\n          // Create an index on the a field\n          return collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          test.ok(indexName);\n\n          // Fetch basic indexInformation for collection\n          return db.indexInformation('more_index_information_test_2_with_promise');\n        }).then(function (indexInformation) {\n          test.deepEqual([['_id', 1]], indexInformation._id_);\n          test.deepEqual([['a', 1], ['b', 1]], indexInformation.a_1_b_1);\n\n          // Fetch full index information\n          return collection.indexInformation({\n            full: true\n          });\n        }).then(function (indexInformation) {\n          test.deepEqual({\n            _id: 1\n          }, indexInformation[0].key);\n          test.deepEqual({\n            a: 1,\n            b: 1\n          }, indexInformation[1].key);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyShowAllTheResultsFromIndexInformationWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1837,"column":70,"index":54338},"line":1837,"code":"  it('shouldCorrectlyShowAllTheResultsFromIndexInformationWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection we want to drop later\n        var collection = db.collection('more_index_information_test_3_with_promise');\n\n        // Insert a bunch of documents for the index\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          test.ok(result);\n\n          // Create an index on the a field\n          return collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          test.ok(indexName);\n\n          // Fetch basic indexInformation for collection\n          return collection.indexInformation();\n        }).then(function (indexInformation) {\n          test.deepEqual([['_id', 1]], indexInformation._id_);\n          test.deepEqual([['a', 1], ['b', 1]], indexInformation.a_1_b_1);\n\n          // Fetch full index information\n          return collection.indexInformation({\n            full: true\n          });\n        }).then(function (indexInformation) {\n          test.deepEqual({\n            _id: 1\n          }, indexInformation[0].key);\n          test.deepEqual({\n            a: 1,\n            b: 1\n          }, indexInformation[1].key);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformASimpleSingleDocumentInsertNoCallbackNoSafeWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1927,"column":83,"index":56934},"line":1927,"code":"  it('shouldCorrectlyPerformASimpleSingleDocumentInsertNoCallbackNoSafeWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        var collection = db.collection('simple_document_insert_collection_no_safe_with_promise');\n\n        // Insert a single document\n        return collection.insertOne({\n          hello: 'world_no_safe'\n        }).then(function () {\n          // Fetch the document\n          return collection.findOne({\n            hello: 'world_no_safe'\n          });\n        }).then(function (item) {\n          test.equal('world_no_safe', item.hello);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformABatchDocumentInsertSafeWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1975,"column":64,"index":58596},"line":1975,"code":"  it('shouldCorrectlyPerformABatchDocumentInsertSafeWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Fetch a collection to insert document into\n        var collection = db.collection('batch_document_insert_collection_safe_with_promise');\n\n        // Insert a single document\n        return collection.insertMany([{\n          hello: 'world_safe1'\n        }, {\n          hello: 'world_safe2'\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result);\n\n          // Fetch the document\n          return collection.findOne({\n            hello: 'world_safe2'\n          });\n        }).then(function (item) {\n          test.equal('world_safe2', item.hello);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformASimpleDocumentInsertWithFunctionSafeWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2028,"column":77,"index":60392},"line":2028,"code":"  it('shouldCorrectlyPerformASimpleDocumentInsertWithFunctionSafeWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Fetch a collection to insert document into\n        var collection = db.collection('simple_document_insert_with_function_safe_with_promise');\n        var o = configuration.writeConcernMax();\n        o.serializeFunctions = true;\n\n        // Insert a single document\n        return collection.insertOne({\n          hello: 'world',\n          func: function () {}\n        }, o).then(function (result) {\n          test.ok(result);\n\n          // Fetch the document\n          return collection.findOne({\n            hello: 'world'\n          });\n        }).then(function (item) {\n          test.ok('function() {}', item.code);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute insert with keepGoing option on mongod >= 1.9.1 With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":2082,"column":92,"index":62292},"line":2082,"code":"  it('Should correctly execute insert with keepGoing option on mongod >= 1.9.1 With Promises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>1.9.1',\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection\n        var collection = db.collection('keepGoingExample_with_promise');\n        return collection.drop().catch(function () {}).then(function () {\n          // Add an unique index to title to force errors in the batch insert\n          return collection.createIndex({\n            title: 1\n          }, {\n            unique: true\n          });\n        }).then(function (indexName) {\n          test.ok(indexName);\n\n          // Insert some intial data into the collection\n          return collection.insertMany([{\n            name: 'Jim'\n          }, {\n            name: 'Sarah',\n            title: 'Princess'\n          }], configuration.writeConcernMax());\n        }).then(function (result) {\n          test.ok(result);\n\n          // Force keep going flag, ignoring unique index issue\n          return collection.insert([{\n            name: 'Jim'\n          }, {\n            name: 'Sarah',\n            title: 'Princess'\n          }, {\n            name: 'Gump',\n            title: 'Gump'\n          }], {\n            writeConcern: {\n              w: 1\n            },\n            keepGoing: true\n          });\n        }).catch(function () {\n          // Count the number of documents left (should not include the duplicates)\n          return collection.count();\n        }).then(function (count) {\n          test.equal(3, count);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteIsCappedWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2162,"column":48,"index":64856},"line":2162,"code":"  it('shouldCorrectlyExecuteIsCappedWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a test collection that we are getting the options back from\n        return db.createCollection('test_collection_is_capped_with_promise', {\n          capped: true,\n          size: 1024\n        }).then(function (collection) {\n          test.equal('test_collection_is_capped_with_promise', collection.collectionName);\n\n          // Let's fetch the collection options\n          return collection.isCapped();\n        }).then(function (capped) {\n          test.equal(true, capped);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveCollectionOptionsWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2208,"column":58,"index":66397},"line":2208,"code":"  it('shouldCorrectlyRetrieveCollectionOptionsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a test collection that we are getting the options back from\n        return db.createCollection('test_collection_options_with_promise', {\n          capped: true,\n          size: 1024\n        }).then(function (collection) {\n          test.equal('test_collection_options_with_promise', collection.collectionName);\n\n          // Let's fetch the collection options\n          return collection.options();\n        }).then(function (options) {\n          test.equal(true, options.capped);\n          test.ok(options.size >= 1024);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldRemoveAllDocumentsNoSafeWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2255,"column":48,"index":67992},"line":2255,"code":"  it('shouldRemoveAllDocumentsNoSafeWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Fetch a collection to insert document into\n        var collection = db.collection('remove_all_documents_no_safe_with_promise');\n\n        // Insert a bunch of documents\n        return collection.insertMany([{\n          a: 1\n        }, {\n          b: 2\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          test.ok(result);\n\n          // Remove all the document\n          return collection.deleteMany();\n        }).then(function () {\n          // Fetch all results\n          return collection.find().toArray();\n        }).then(function (items) {\n          test.equal(0, items.length);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldRemoveSubsetOfDocumentsSafeModeWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2312,"column":55,"index":69696},"line":2312,"code":"  it('shouldRemoveSubsetOfDocumentsSafeModeWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        w: 0\n      }, {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Fetch a collection to insert document into\n        var collection = db.collection('remove_subset_of_documents_safe_with_promise');\n\n        // Insert a bunch of documents\n        return collection.insertMany([{\n          a: 1\n        }, {\n          b: 2\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          test.ok(result);\n\n          // Remove all the document\n          return collection.deleteOne({\n            a: 1\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (r) {\n          expect(r).property('deletedCount').to.equal(1);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRenameCollectionWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2374,"column":49,"index":71402},"line":2374,"code":"  it('shouldCorrectlyRenameCollectionWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n\n      /* eslint-disable */\n\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Open a couple of collections\n\n        var collection1, collection2;\n        return Promise.all([db.createCollection('test_rename_collection_with_promise'), db.createCollection('test_rename_collection2_with_promise')]).then(function (collections) {\n          collection1 = collections[0];\n          collection2 = collections[1];\n          test.ok(collection2);\n\n          // Attemp to rename a collection to a number\n          try {\n            collection1.rename(5, function (err, collection) {});\n          } catch (err) {\n            test.ok(err instanceof Error);\n            test.equal('Collection name must be a String', err.message);\n          }\n\n          // Attemp to rename a collection to an empty string\n          try {\n            collection1.rename('', function (err, collection) {});\n          } catch (err) {\n            test.ok(err instanceof Error);\n            test.equal('Collection names cannot be empty', err.message);\n          }\n\n          // Attemp to rename a collection to an illegal name including the character $\n          try {\n            collection1.rename('te$t', function (err, collection) {});\n          } catch (err) {\n            test.ok(err instanceof Error);\n            test.equal(\"Collection names must not contain '$'\", err.message);\n          }\n\n          // Attemp to rename a collection to an illegal name starting with the character .\n          try {\n            collection1.rename('.test', function (err, collection) {});\n          } catch (err) {\n            test.ok(err instanceof Error);\n            test.equal(\"Collection names must not start or end with '.'\", err.message);\n          }\n\n          // Attemp to rename a collection to an illegal name ending with the character .\n          try {\n            collection1.rename('test.', function (err, collection) {});\n          } catch (err) {\n            test.ok(err instanceof Error);\n            test.equal(\"Collection names must not start or end with '.'\", err.message);\n          }\n\n          // Attemp to rename a collection to an illegal name with an empty middle name\n          try {\n            collection1.rename('tes..t', function (err, collection) {});\n          } catch (err) {\n            test.equal('Collection names cannot be empty', err.message);\n          }\n\n          // Insert a couple of documents\n          return collection1.insertMany([{\n            x: 1\n          }, {\n            x: 2\n          }], configuration.writeConcernMax());\n        }).then(function (docs) {\n          test.ok(docs);\n\n          // Attemp to rename the first collection to the second one, this will fail\n          return collection1.rename('test_rename_collection2_with_promise');\n        }).catch(function (err) {\n          test.ok(err instanceof Error);\n          test.ok(err.message.length > 0);\n\n          // Attemp to rename the first collection to a name that does not exist\n          // this will be successful\n          return collection1.rename('test_rename_collection3_with_promise');\n        }).then(function (collection2) {\n          test.equal('test_rename_collection3_with_promise', collection2.collectionName);\n\n          // Ensure that the collection is pointing to the new one\n          return collection2.count();\n        }).then(function (count) {\n          test.equal(2, count);\n        }).then(() => client.close(), e => {\n          client.close();\n          throw e;\n        });\n      });\n      // END\n      /* eslint-enable */\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUpdateASimpleDocumentWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2494,"column":54,"index":75896},"line":2494,"code":"  it('shouldCorrectlyUpdateASimpleDocumentWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        w: 0\n      }, {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Get a collection\n        var collection = db.collection('update_a_simple_document_with_promise');\n\n        // Insert a document, then update it\n        return collection.insertOne({\n          a: 1\n        }, configuration.writeConcernMax()).then(function (doc) {\n          test.ok(doc);\n          // Update the document with an atomic operator\n          return collection.updateOne({\n            a: 1\n          }, {\n            $set: {\n              b: 2\n            }\n          });\n        }).then(function () {\n          // Fetch the document that we modified\n          return collection.findOne({\n            a: 1\n          });\n        }).then(function (item) {\n          test.equal(1, item.a);\n          test.equal(2, item.b);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUpsertASimpleDocumentWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2555,"column":54,"index":77723},"line":2555,"code":"  it('shouldCorrectlyUpsertASimpleDocumentWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Get a collection\n        var collection = db.collection('update_a_simple_document_upsert_with_promise');\n\n        // Update the document using an upsert operation, ensuring creation if it does not exist\n        return collection.updateOne({\n          a: 1\n        }, {\n          $set: {\n            b: 2,\n            a: 1\n          }\n        }, {\n          upsert: true,\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          expect(result).property('upsertedCount').to.equal(1);\n\n          // Fetch the document that we modified and check if it got inserted correctly\n          return collection.findOne({\n            a: 1\n          });\n        }).then(function (item) {\n          test.equal(1, item.a);\n          test.equal(2, item.b);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUpdateMultipleDocumentsWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2616,"column":56,"index":79586},"line":2616,"code":"  it('shouldCorrectlyUpdateMultipleDocumentsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Get a collection\n        var collection = db.collection('update_a_simple_document_multi_with_promise');\n\n        // Insert a couple of documentations\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 1,\n          b: 2\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result);\n          var o = configuration.writeConcernMax();\n          return collection.updateMany({\n            a: 1\n          }, {\n            $set: {\n              b: 0\n            }\n          }, o);\n        }).then(function (r) {\n          expect(r).property('matchedCount').to.equal(2);\n\n          // Fetch all the documents and verify that we have changed the b value\n          return collection.find().toArray();\n        }).then(function (items) {\n          test.equal(1, items[0].a);\n          test.equal(0, items[0].b);\n          test.equal(1, items[1].a);\n          test.equal(0, items[1].b);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyReturnACollectionsStatsWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2681,"column":56,"index":81588},"line":2681,"code":"  it('shouldCorrectlyReturnACollectionsStatsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Crete the collection for the distinct example\n        var collection = db.collection('collection_stats_test_with_promise');\n\n        // Insert some documents\n        return collection.insertMany([{\n          a: 1\n        }, {\n          hello: 'world'\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result);\n          // Retrieve the statistics for the collection\n          return collection.stats();\n        }).then(function (stats) {\n          test.equal(2, stats.count);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateAndDropAllIndexWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2730,"column":54,"index":83167},"line":2730,"code":"  it('shouldCorrectlyCreateAndDropAllIndexWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection we want to drop later\n        var collection = db.collection('shouldCorrectlyCreateAndDropAllIndex_with_promise');\n        // Insert a bunch of documents for the index\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4,\n          c: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          test.ok(result);\n\n          // Create an index on the a field\n          return collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          test.ok(indexName);\n          // Create an additional index\n          return collection.createIndex({\n            c: 1\n          }, {\n            unique: true,\n            background: true,\n            sparse: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          test.ok(indexName);\n          // Drop the index\n          return collection.dropIndexes();\n        }).then(function (result) {\n          test.ok(result);\n          // Verify that the index is gone\n          return collection.indexInformation();\n        }).then(function (indexInformation) {\n          test.deepEqual([['_id', 1]], indexInformation._id_);\n          expect(indexInformation.a_1_b_1).to.not.exist;\n          expect(indexInformation.c_1).to.not.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyOpenASimpleDbSingleServerConnectionAndCloseWithCallbackWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2830,"column":88,"index":86073},"line":2830,"code":"  it('shouldCorrectlyOpenASimpleDbSingleServerConnectionAndCloseWithCallbackWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Close the connection with a callback that is optional\n        return client.close();\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrievelistCollectionsWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2864,"column":56,"index":87134},"line":2864,"code":"  it('shouldCorrectlyRetrievelistCollectionsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get an empty db\n        var db1 = client.db('listCollectionTestDb2');\n\n        // Create a collection\n        var collection = db1.collection('shouldCorrectlyRetrievelistCollections_with_promise');\n\n        // Ensure the collection was created\n        return collection.insertOne({\n          a: 1\n        }).then(function () {\n          // Return the information of a single collection name\n          return db1.listCollections({\n            name: 'shouldCorrectlyRetrievelistCollections_with_promise'\n          }).toArray();\n        }).then(function (items) {\n          test.equal(1, items.length);\n\n          // Return the information of a all collections, using the callback format\n          return db1.listCollections().toArray();\n        }).then(function (items) {\n          test.ok(items.length >= 1);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrievelistCollectionsWiredTigerWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2912,"column":66,"index":88852},"line":2912,"code":"  it('shouldCorrectlyRetrievelistCollectionsWiredTigerWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['wiredtiger']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        // Get an empty db\n        var db1 = client.db('listCollectionTestDb2');\n\n        // Create a collection\n        var collection = db1.collection('shouldCorrectlyRetrievelistCollections_with_promise');\n\n        // Ensure the collection was created\n        return collection.insertOne({\n          a: 1\n        }).then(function () {\n          // Return the information of a single collection name\n          return db1.listCollections({\n            name: 'shouldCorrectlyRetrievelistCollections_with_promise'\n          }).toArray();\n        }).then(function (items) {\n          test.equal(1, items.length);\n\n          // Return the information of a all collections, using the callback format\n          return db1.listCollections().toArray();\n        }).then(function (items) {\n          test.equal(1, items.length);\n          return client.close();\n        });\n      });\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveAllCollectionsWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2957,"column":55,"index":90285},"line":2957,"code":"  it('shouldCorrectlyRetrieveAllCollectionsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Retry to get the collection, should work as it's now created\n        return db.collections().then(function (collections) {\n          test.ok(collections.length > 0);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyAddUserToDbWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2994,"column":44,"index":91480},"line":2994,"code":"  it('shouldCorrectlyAddUserToDbWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Add a user to the database\n        return db.addUser('user', 'name').then(function (result) {\n          test.ok(result);\n          // Remove the user from the db\n          return db.removeUser('user');\n        }).then(function (result) {\n          test.ok(result);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyAddAndRemoveUserWithPromises","suites":["Operation (Promises)"],"line":3036,"code":"  it.skip('shouldCorrectlyAddAndRemoveUserWithPromises', {","file":"integration/node-specific/operation_promises_example.test.js","skipped":true,"dir":"test"},{"name":"shouldCorrectlyCreateACollectionWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3096,"column":50,"index":94835},"line":3096,"code":"  it('shouldCorrectlyCreateACollectionWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a capped collection with a maximum of 1000 documents\n        return db.createCollection('a_simple_collection_with_promise', {\n          capped: true,\n          size: 10000,\n          max: 1000,\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (collection) {\n          // Insert a document in the capped collection\n          return collection.insertOne({\n            a: 1\n          }, configuration.writeConcernMax());\n        }).then(function (result) {\n          test.ok(result);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteACommandAgainstTheServerWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3145,"column":64,"index":96462},"line":3145,"code":"  it('shouldCorrectlyExecuteACommandAgainstTheServerWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Execute ping against the server\n        return db.command({\n          ping: 1\n        }).then(function (result) {\n          test.ok(result);\n          // Create a capped collection with a maximum of 1000 documents\n          return db.createCollection('a_simple_create_drop_collection_with_promise', {\n            capped: true,\n            size: 10000,\n            max: 1000,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (collection) {\n          // Insert a document in the capped collection\n          return collection.insertOne({\n            a: 1\n          }, configuration.writeConcernMax());\n        }).then(function (result) {\n          test.ok(result);\n          // Drop the collection from this world\n          return db.dropCollection('a_simple_create_drop_collection_with_promise');\n        }).then(function (result) {\n          test.ok(result);\n          // Verify that the collection is gone\n          return db.listCollections({\n            name: 'a_simple_create_drop_collection_with_promise'\n          }).toArray();\n        }).then(function (names) {\n          test.equal(0, names.length);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateDropAndVerifyThatCollectionIsGoneWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3210,"column":72,"index":98689},"line":3210,"code":"  it('shouldCorrectlyCreateDropAndVerifyThatCollectionIsGoneWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Execute ping against the server\n        return db.command({\n          ping: 1\n        }).then(function (result) {\n          test.ok(result);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRenameACollectionWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3249,"column":50,"index":99910},"line":3249,"code":"  it('shouldCorrectlyRenameACollectionWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection\n\n        return db.createCollection('simple_rename_collection_with_promise', configuration.writeConcernMax()).then(function (collection) {\n          // Insert a document in the collection\n          return collection.insertOne({\n            a: 1\n          }, configuration.writeConcernMax()).then(function () {\n            return collection;\n          });\n        }).then(function (collection) {\n          // Retrieve the number of documents from the collection\n          return collection.count();\n        }).then(function (count) {\n          test.equal(1, count);\n\n          // Rename the collection\n          return db.renameCollection('simple_rename_collection_with_promise', 'simple_rename_collection_2_with_promise');\n        }).then(function (collection2) {\n          // Retrieve the number of documents from the collection\n          return collection2.count();\n        }).then(function (count) {\n          test.equal(1, count);\n\n          // Verify that the collection is gone\n          return db.listCollections({\n            name: 'simple_rename_collection_with_promise'\n          }).toArray();\n        }).then(function (names) {\n          test.equal(0, names.length);\n\n          // Verify that the new collection exists\n          return db.listCollections({\n            name: 'simple_rename_collection_2_with_promise'\n          }).toArray();\n        }).then(function (names) {\n          test.equal(1, names.length);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCreateOnDbComplexIndexOnTwoFieldsWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3319,"column":57,"index":102467},"line":3319,"code":"  it('shouldCreateOnDbComplexIndexOnTwoFieldsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection we want to drop later\n        var collection = db.collection('more_complex_index_test_with_promise');\n\n        // Insert a bunch of documents for the index\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result);\n          // Create an index on the a field\n          return db.createIndex('more_complex_index_test_with_promise', {\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          test.ok(indexName);\n          // Show that duplicate records got dropped\n          return collection.find({}).toArray();\n        }).then(function (items) {\n          test.equal(4, items.length);\n\n          // Perform a query, with explain to show we hit the query\n          return collection.find({\n            a: 2\n          }).explain();\n        }).then(function (explanation) {\n          test.ok(explanation != null);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCreateComplexEnsureIndexDbWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3396,"column":50,"index":104817},"line":3396,"code":"  it('shouldCreateComplexEnsureIndexDbWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection we want to drop later\n        var collection = db.collection('more_complex_ensure_index_db_test_with_promise');\n\n        // Insert a bunch of documents for the index\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result);\n          // Create an index on the a field\n          return db.createIndex('more_complex_ensure_index_db_test_with_promise', {\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          test.ok(indexName);\n          // Show that duplicate records got dropped\n          return collection.find({}).toArray();\n        }).then(function (items) {\n          test.equal(4, items.length);\n\n          // Perform a query, with explain to show we hit the query\n          return collection.find({\n            a: 2\n          }).explain();\n        }).then(function (explanation) {\n          test.ok(explanation != null);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDropTheDatabaseWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3473,"column":48,"index":107124},"line":3473,"code":"  it('shouldCorrectlyDropTheDatabaseWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection\n        var collection = db.collection('more_index_information_test_1_with_promise');\n\n        // Insert a bunch of documents for the index\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result);\n\n          // Let's drop the database\n          return db.dropDatabase();\n        }).then(function (result) {\n          test.ok(result);\n\n          // Get the admin database\n          return db.admin().listDatabases();\n        }).then(function (dbs) {\n          // Grab the databases\n          dbs = dbs.databases;\n          // Did we find the db\n          var found = false;\n\n          // Check if we have the db in the list\n          for (var i = 0; i < dbs.length; i++) {\n            if (dbs[i].name === 'integration_tests_to_drop') found = true;\n          }\n\n          // We should not find the databases\n          if (process.env['JENKINS'] == null) test.equal(false, found);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveDbStatsWithPromisesWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3550,"column":60,"index":109362},"line":3550,"code":"  it('shouldCorrectlyRetrieveDbStatsWithPromisesWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        return db.stats().then(function (stats) {\n          test.ok(stats != null);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyShareConnectionPoolsAcrossMultipleDbInstancesWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3586,"column":78,"index":110539},"line":3586,"code":"  it('shouldCorrectlyShareConnectionPoolsAcrossMultipleDbInstancesWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Reference a different database sharing the same connections\n        // for the data transfer\n        var secondDb = client.db('integration_tests_2');\n\n        // Fetch the collections\n        var multipleColl1 = db.collection('multiple_db_instances_with_promise');\n        var multipleColl2 = secondDb.collection('multiple_db_instances_with_promise');\n\n        // Write a record into each and then count the records stored\n        return multipleColl1.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          test.ok(result);\n          return multipleColl2.insertOne({\n            a: 1\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (result) {\n          test.ok(result);\n          // Count over the results ensuring only on record in each collection\n          return multipleColl1.count();\n        }).then(function (count) {\n          test.equal(1, count);\n          return multipleColl2.count();\n        }).then(function (count) {\n          test.equal(1, count);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveBuildInfoWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3659,"column":50,"index":112891},"line":3659,"code":"  it('shouldCorrectlyRetrieveBuildInfoWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Use the admin database for the operation\n        var adminDb = db.admin();\n\n        // Retrieve the build information for the MongoDB instance\n        return adminDb.buildInfo().then(function (info) {\n          test.ok(info);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveBuildInfoUsingCommandWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3701,"column":62,"index":114210},"line":3701,"code":"  it('shouldCorrectlyRetrieveBuildInfoUsingCommandWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Use the admin database for the operation\n        var adminDb = db.admin();\n\n        // Retrieve the build information using the admin command\n        return adminDb.command({\n          buildInfo: 1\n        }).then(function (info) {\n          test.ok(info);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlySetDefaultProfilingLevelWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3745,"column":57,"index":115575},"line":3745,"code":"  it('shouldCorrectlySetDefaultProfilingLevelWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Grab a collection object\n        var collection = db.collection('test_with_promise');\n\n        // Force the creation of the collection by inserting a document\n        // Collections are not created until the first document is inserted\n        return collection.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (doc) {\n          test.ok(doc);\n          // Use the admin database for the operation\n          var adminDb = client.db('admin');\n\n          // Retrieve the profiling level\n          return adminDb.profilingLevel();\n        }).then(function (level) {\n          test.ok(level);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyChangeProfilingLevelWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3802,"column":53,"index":117391},"line":3802,"code":"  it('shouldCorrectlyChangeProfilingLevelWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Grab a collection object\n        var collection = db.collection('test_with_promise');\n        var adminDb = client.db('admin');\n\n        // Force the creation of the collection by inserting a document\n        // Collections are not created until the first document is inserted\n        return collection.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (doc) {\n          test.ok(doc);\n          // Set the profiling level to only profile slow queries\n          return adminDb.setProfilingLevel('slow_only');\n        }).then(function (level) {\n          test.ok(level);\n          // Retrieve the profiling level and verify that it's set to slow_only\n          return adminDb.profilingLevel();\n        }).then(function (level) {\n          test.equal('slow_only', level);\n\n          // Turn profiling off\n          return adminDb.setProfilingLevel('off');\n        }).then(function (level) {\n          test.ok(level);\n          // Retrieve the profiling level and verify that it's set to off\n          return adminDb.profilingLevel();\n        }).then(function (level) {\n          test.equal('off', level);\n\n          // Set the profiling level to log all queries\n          return adminDb.setProfilingLevel('all');\n        }).then(function (level) {\n          test.ok(level);\n          // Retrieve the profiling level and verify that it's set to all\n          return adminDb.profilingLevel();\n        }).then(function (level) {\n          test.equal('all', level);\n\n          // Attempt to set an illegal profiling level\n          return adminDb.setProfilingLevel('medium');\n        }).catch(function (err) {\n          test.ok(err instanceof Error);\n          test.equal(`Profiling level must be one of \"${enumToString(ProfilingLevel)}\"`, err.message);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCallValidateCollectionWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3885,"column":55,"index":120414},"line":3885,"code":"  it('shouldCorrectlyCallValidateCollectionWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Grab a collection object\n        var collection = db.collection('test_with_promise');\n\n        // Force the creation of the collection by inserting a document\n        // Collections are not created until the first document is inserted\n        return collection.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (doc) {\n          test.ok(doc);\n          // Use the admin database for the operation\n          var adminDb = db.admin();\n\n          // Validate the 'test' collection\n          return adminDb.validateCollection('test_with_promise');\n        }).then(function (doc) {\n          test.ok(doc);\n          return client.close();\n        });\n      });\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPingTheMongoDbInstanceWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3940,"column":55,"index":122159},"line":3940,"code":"  it('shouldCorrectlyPingTheMongoDbInstanceWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Use the admin database for the operation\n        var adminDb = db.admin();\n\n        // Ping the server\n        return adminDb.ping().then(function (pingResult) {\n          test.ok(pingResult);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyAddAUserToAdminDbWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3982,"column":50,"index":123437},"line":3982,"code":"  it('shouldCorrectlyAddAUserToAdminDbWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Use the admin database for the operation\n        var adminDb = db.admin();\n\n        // Add the new user to the admin database\n        return adminDb.addUser('admin11', 'admin11').then(function (result) {\n          test.ok(result);\n          return adminDb.removeUser('admin11');\n        }).then(function (result) {\n          test.ok(result);\n          return client.close();\n        });\n      });\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyAddAUserAndRemoveItFromAdminDbWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":4026,"column":63,"index":124872},"line":4026,"code":"  it('shouldCorrectlyAddAUserAndRemoveItFromAdminDbWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Use the admin database for the operation\n        var adminDb = db.admin();\n\n        // Add the new user to the admin database\n        return adminDb.addUser('admin12', 'admin12').then(function (result) {\n          test.ok(result);\n\n          // Remove the user\n          return adminDb.removeUser('admin12');\n        }).then(function (result) {\n          test.equal(true, result);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyListAllAvailableDatabasesWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":4073,"column":58,"index":126345},"line":4073,"code":"  it('shouldCorrectlyListAllAvailableDatabasesWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Use the admin database for the operation\n        var adminDb = db.admin();\n\n        // List all the available databases\n        return adminDb.listDatabases().then(function (dbs) {\n          test.ok(dbs.databases.length > 0);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveServerInfoWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":4115,"column":51,"index":127643},"line":4115,"code":"  it('shouldCorrectlyRetrieveServerInfoWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Grab a collection object\n        var collection = db.collection('test_with_promise');\n\n        // Use the admin database for the operation\n        var adminDb = db.admin();\n\n        // Force the creation of the collection by inserting a document\n        // Collections are not created until the first document is inserted\n        return collection.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (doc) {\n          test.ok(doc);\n          // Add the new user to the admin database\n          return adminDb.addUser('admin13', 'admin13');\n        }).then(function (result) {\n          test.ok(result);\n          // Retrieve the server Info\n          return adminDb.serverStatus();\n        }).then(function (info) {\n          test.ok(info != null);\n          return adminDb.removeUser('admin13');\n        }).then(function (result) {\n          test.ok(result);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteToArrayWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":4184,"column":47,"index":129849},"line":4184,"code":"  it('shouldCorrectlyExecuteToArrayWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection to hold our documents\n        var collection = db.collection('test_array_with_promise');\n\n        // Insert a test document\n        return collection.insertOne({\n          b: [1, 2, 3]\n        }, configuration.writeConcernMax()).then(function (ids) {\n          test.ok(ids);\n          // Retrieve all the documents in the collection\n          return collection.find().toArray();\n        }).then(function (documents) {\n          test.equal(1, documents.length);\n          test.deepEqual([1, 2, 3], documents[0].b);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUseCursorCountFunctionWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":4235,"column":55,"index":131609},"line":4235,"code":"  it('shouldCorrectlyUseCursorCountFunctionWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Creat collection\n        var collection = db.collection('cursor_count_collection_with_promise');\n\n        // Insert some docs\n        return collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }], configuration.writeConcernMax()).then(function (docs) {\n          test.ok(docs);\n          // Do a find and get the cursor count\n          return collection.find().count();\n        }).then(function (count) {\n          test.equal(2, count);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformNextOnCursorWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":4287,"column":52,"index":133275},"line":4287,"code":"  it('shouldCorrectlyPerformNextOnCursorWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection\n        var collection = db.collection('simple_next_object_collection_with_promise');\n\n        // Insert some documents we can sort on\n        return collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax()).then(function (docs) {\n          test.ok(docs);\n          // Do normal ascending sort\n          return collection.find().next();\n        }).then(function (item) {\n          test.equal(1, item.a);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformSimpleExplainCursorWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":4341,"column":59,"index":135020},"line":4341,"code":"  it('shouldCorrectlyPerformSimpleExplainCursorWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection\n        var collection = db.collection('simple_explain_collection_with_promise');\n\n        // Insert some documents we can sort on\n        return collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax()).then(function (docs) {\n          test.ok(docs);\n          // Do normal ascending sort\n          return collection.find().explain();\n        }).then(function (explanation) {\n          test.ok(explanation);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldStreamDocumentsUsingTheCloseFunctionWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":4395,"column":60,"index":136767},"line":4395,"code":"  it('shouldStreamDocumentsUsingTheCloseFunctionWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a lot of documents to insert\n        var docs = [];\n        for (var i = 0; i < 100; i++) {\n          docs.push({\n            a: i\n          });\n        }\n\n        // Create a collection\n        var collection = db.collection('test_close_function_on_cursor_with_promise');\n\n        // Perform a find to get a cursor\n        var cursor = collection.find();\n\n        // Insert documents into collection\n        return collection.insertMany(docs, configuration.writeConcernMax()).then(function (ids) {\n          test.ok(ids);\n          // Fetch the first object\n          return cursor.next();\n        }).then(function (object) {\n          test.ok(object);\n          // Close the cursor, this is the same as reseting the query\n          return cursor.close();\n        }).then(function () {\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly connect to a replicaset With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":4462,"column":60,"index":138992},"line":4462,"code":"  it('Should correctly connect to a replicaset With Promises', {\n    metadata: {\n      requires: {\n        topology: 'replicaset'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var url = f('mongodb://%s,%s/%s?replicaSet=%s&readPreference=%s', f('%s:%s', configuration.host, configuration.port), f('%s:%s', configuration.host, configuration.port + 1), 'integration_test_', configuration.replicasetName, 'primary');\n      const client = configuration.newClient(url);\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n        test.ok(db != null);\n        return db.collection('replicaset_mongo_client_collection_with_promise').updateOne({\n          a: 1\n        }, {\n          $set: {\n            b: 1\n          }\n        }, {\n          upsert: true\n        }).then(function (result) {\n          expect(result).property('upsertedCount').to.equal(1);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should connect to mongos proxies using connectiong string With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":4506,"column":77,"index":140619},"line":4506,"code":"  it('Should connect to mongos proxies using connectiong string With Promises', {\n    metadata: {\n      requires: {\n        topology: 'sharded'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var url = f('mongodb://%s:%s,%s:%s/sharded_test_db?w=1', configuration.host, configuration.port, configuration.host, configuration.port + 1);\n      const client = configuration.newClient(url);\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n        test.ok(db != null);\n        return db.collection('replicaset_mongo_client_collection_with_promise').updateOne({\n          a: 1\n        }, {\n          $set: {\n            b: 1\n          }\n        }, {\n          upsert: true\n        }).then(function (result) {\n          test.equal(1, result.upsertedCount);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly connect using MongoClient to a single server using connect With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":4550,"column":95,"index":142120},"line":4550,"code":"  it('Should correctly connect using MongoClient to a single server using connect With Promises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      const client = configuration.newClient();\n\n      // DOC_START\n      // Connect using the connection string\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n        return db.collection('mongoclient_test_with_promise').updateOne({\n          a: 1\n        }, {\n          $set: {\n            b: 1\n          }\n        }, {\n          upsert: true\n        }).then(function (result) {\n          expect(result).property('upsertedCount').to.equal(1);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute ordered batch with no errors using write commands With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":4604,"column":94,"index":143880},"line":4604,"code":"  it('Should correctly execute ordered batch with no errors using write commands With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        var col = db.collection('batch_write_ordered_ops_0_with_promise');\n        // Initialize the Ordered Batch\n        var batch = col.initializeOrderedBulkOp();\n        // Add some operations to be executed in order\n        batch.insert({\n          a: 1\n        });\n        batch.find({\n          a: 1\n        }).updateOne({\n          $set: {\n            b: 1\n          }\n        });\n        batch.find({\n          a: 2\n        }).upsert().updateOne({\n          $set: {\n            b: 2\n          }\n        });\n        batch.insert({\n          a: 3\n        });\n        batch.find({\n          a: 3\n        }).delete({\n          a: 3\n        });\n\n        // Execute the operations\n        return batch.execute().then(function (result) {\n          // Check state of result\n          test.equal(2, result.nInserted);\n          test.equal(1, result.nUpserted);\n          test.equal(1, result.nMatched);\n          test.ok(1 === result.nModified || result.nModified === 0 || result.nModified == null);\n          test.equal(1, result.nRemoved);\n          var upserts = result.getUpsertedIds();\n          test.equal(1, upserts.length);\n          test.equal(2, upserts[0].index);\n          test.ok(upserts[0]._id != null);\n          var upsert = result.getUpsertedIdAt(0);\n          test.equal(2, upsert.index);\n          test.ok(upsert._id != null);\n\n          // Finish up test\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute unordered batch with no errors With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":4687,"column":75,"index":146396},"line":4687,"code":"  it('Should correctly execute unordered batch with no errors With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        var col = db.collection('batch_write_unordered_ops_legacy_0_with_promise');\n        // Initialize the unordered Batch\n        var batch = col.initializeUnorderedBulkOp();\n\n        // Add some operations to be executed in order\n        batch.insert({\n          a: 1\n        });\n        batch.find({\n          a: 1\n        }).updateOne({\n          $set: {\n            b: 1\n          }\n        });\n        batch.find({\n          a: 2\n        }).upsert().updateOne({\n          $set: {\n            b: 2\n          }\n        });\n        batch.insert({\n          a: 3\n        });\n        batch.find({\n          a: 3\n        }).delete({\n          a: 3\n        });\n\n        // Execute the operations\n        return batch.execute().then(function (result) {\n          // Check state of result\n          test.equal(2, result.nInserted);\n          test.equal(1, result.nUpserted);\n          test.equal(1, result.nMatched);\n          test.ok(1 === result.nModified || result.nModified === 0 || result.nModified == null);\n          test.equal(1, result.nRemoved);\n          var upserts = result.getUpsertedIds();\n          test.equal(1, upserts.length);\n          test.equal(2, upserts[0].index);\n          test.ok(upserts[0]._id != null);\n          var upsert = result.getUpsertedIdAt(0);\n          test.equal(2, upsert.index);\n          test.ok(upsert._id != null);\n\n          // Finish up test\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute insertOne operation With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":4776,"column":64,"index":149042},"line":4776,"code":"  it('Should correctly execute insertOne operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        var col = db.collection('insert_one_with_promise');\n        return col.insertOne({\n          a: 1\n        }).then(function (r) {\n          expect(r).property('insertedId').to.exist;\n          // Finish up test\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute insertMany operation With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":4817,"column":65,"index":150337},"line":4817,"code":"  it('Should correctly execute insertMany operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        var col = db.collection('insert_many_with_promise');\n        return col.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }]).then(function (r) {\n          test.equal(2, r.insertedCount);\n          // Finish up test\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute updateOne operation With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":4860,"column":64,"index":151650},"line":4860,"code":"  it('Should correctly execute updateOne operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        var col = db.collection('update_one_with_promise');\n        return col.updateOne({\n          a: 1\n        }, {\n          $set: {\n            a: 2\n          }\n        }, {\n          upsert: true\n        }).then(function (r) {\n          test.equal(0, r.matchedCount);\n          test.equal(1, r.upsertedCount);\n          // Finish up test\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute updateMany operation With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":4908,"column":65,"index":153071},"line":4908,"code":"  it('Should correctly execute updateMany operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        var col = db.collection('update_many_with_promise');\n        return col.insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }]).then(function (r) {\n          test.equal(2, r.insertedCount);\n\n          // Update all documents\n          return col.updateMany({\n            a: 1\n          }, {\n            $set: {\n              b: 1\n            }\n          });\n        }).then(function (r) {\n          if (r.n) {\n            test.equal(2, r.n);\n          } else {\n            test.equal(2, r.matchedCount);\n            test.equal(2, r.modifiedCount);\n          }\n\n          // Finish up test\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute deleteOne operation With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":4968,"column":64,"index":154755},"line":4968,"code":"  it('Should correctly execute deleteOne operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        var col = db.collection('remove_one_with_promise');\n        return col.insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }]).then(function (r) {\n          test.equal(2, r.insertedCount);\n          return col.deleteOne({\n            a: 1\n          });\n        }).then(function (r) {\n          test.equal(1, r.deletedCount);\n          // Finish up test\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute deleteMany operation With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":5016,"column":65,"index":156206},"line":5016,"code":"  it('Should correctly execute deleteMany operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        var col = db.collection('remove_many_with_promise');\n        return col.insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }]).then(function (r) {\n          test.equal(2, r.insertedCount);\n\n          // Update all documents\n          return col.deleteMany({\n            a: 1\n          });\n        }).then(function (r) {\n          test.equal(2, r.deletedCount);\n\n          // Finish up test\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute bulkWrite operation With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":5067,"column":64,"index":157692},"line":5067,"code":"  it('Should correctly execute bulkWrite operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        var col = db.collection('bulk_write_with_promise');\n        return col.bulkWrite([{\n          insertOne: {\n            document: {\n              a: 1\n            }\n          }\n        }, {\n          updateOne: {\n            filter: {\n              a: 2\n            },\n            update: {\n              $set: {\n                a: 2\n              }\n            },\n            upsert: true\n          }\n        }, {\n          updateMany: {\n            filter: {\n              a: 2\n            },\n            update: {\n              $set: {\n                a: 2\n              }\n            },\n            upsert: true\n          }\n        }, {\n          deleteOne: {\n            filter: {\n              c: 1\n            }\n          }\n        }, {\n          deleteMany: {\n            filter: {\n              c: 1\n            }\n          }\n        }, {\n          replaceOne: {\n            filter: {\n              c: 3\n            },\n            replacement: {\n              c: 4\n            },\n            upsert: true\n          }\n        }], {\n          ordered: true,\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (r) {\n          test.equal(1, r.nInserted);\n          test.equal(2, r.nUpserted);\n          test.equal(0, r.nRemoved);\n          // Crud fields\n          test.equal(1, r.insertedCount);\n          test.equal(1, Object.keys(r.insertedIds).length);\n          test.equal(1, r.matchedCount);\n          test.ok(r.modifiedCount === 0 || r.modifiedCount === 1);\n          test.equal(0, r.deletedCount);\n          test.equal(2, r.upsertedCount);\n          test.equal(2, Object.keys(r.upsertedIds).length);\n\n          // Ordered bulk operation\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly handle duplicate key error with bulkWrite","suites":["Operation (Promises)"],"updatePoint":{"line":5171,"column":64,"index":160348},"line":5171,"code":"  it('Should correctly handle duplicate key error with bulkWrite', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // Get the collection\n        var col = db.collection('bulk_write_with_promise_write_error');\n        return col.bulkWrite([{\n          insertOne: {\n            document: {\n              _id: 1\n            }\n          }\n        }, {\n          insertOne: {\n            document: {\n              _id: 1\n            }\n          }\n        }], {\n          ordered: true,\n          writeConcern: {\n            w: 1\n          }\n        }).catch(function (err) {\n          test.equal(true, err.result.hasWriteErrors());\n          // Ordered bulk operation\n          return client.close();\n        });\n      });\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndDelete operation With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":5218,"column":71,"index":161563},"line":5218,"code":"  it('Should correctly execute findOneAndDelete operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        var col = db.collection('find_one_and_delete_with_promise');\n        return col.insertMany([{\n          a: 1,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (r) {\n          expect(r).property('insertedCount').to.equal(1);\n          return col.findOneAndDelete({\n            a: 1\n          }, {\n            projection: {\n              b: 1\n            },\n            sort: {\n              a: 1\n            }\n          });\n        }).then(function (r) {\n          test.equal(1, r.lastErrorObject.n);\n          test.equal(1, r.value.b);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndReplace operation With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":5276,"column":72,"index":163265},"line":5276,"code":"  it('Should correctly execute findOneAndReplace operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        var col = db.collection('find_one_and_replace_with_promise');\n        return col.insertMany([{\n          a: 1,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (r) {\n          expect(r).property('insertedCount').to.equal(1);\n          return col.findOneAndReplace({\n            a: 1\n          }, {\n            c: 1,\n            b: 1\n          }, {\n            projection: {\n              b: 1,\n              c: 1\n            },\n            sort: {\n              a: 1\n            },\n            returnDocument: ReturnDocument.AFTER,\n            upsert: true\n          }).then(function (r) {\n            test.equal(1, r.lastErrorObject.n);\n            test.equal(1, r.value.b);\n            test.equal(1, r.value.c);\n            return client.close();\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndUpdate operation With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":5341,"column":71,"index":165158},"line":5341,"code":"  it('Should correctly execute findOneAndUpdate operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        var col = db.collection('find_one_and_update_with_promise');\n        return col.insertMany([{\n          a: 1,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (r) {\n          expect(r).property('insertedCount').to.equal(1);\n          return col.findOneAndUpdate({\n            a: 1\n          }, {\n            $set: {\n              d: 1\n            }\n          }, {\n            projection: {\n              b: 1,\n              d: 1\n            },\n            sort: {\n              a: 1\n            },\n            returnDocument: ReturnDocument.AFTER,\n            upsert: true\n          });\n        }).then(function (r) {\n          test.equal(1, r.lastErrorObject.n);\n          test.equal(1, r.value.b);\n          test.equal(1, r.value.d);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly add capped collection options to cursor With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":5407,"column":76,"index":167069},"line":5407,"code":"  it('Should correctly add capped collection options to cursor With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a capped collection with a maximum of 1000 documents\n        var collection;\n        db.createCollection('a_simple_collection_2_with_promise', {\n          capped: true,\n          size: 100000,\n          max: 1000,\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (_collection) {\n          collection = _collection;\n          var docs = [];\n          for (var i = 0; i < 1000; i++) docs.push({\n            a: i\n          });\n\n          // Insert a document in the capped collection\n          return collection.insertMany(docs, configuration.writeConcernMax());\n        }).then(function (result) {\n          test.ok(result);\n          var total = 0;\n\n          // Get the cursor\n          var cursor = collection.find({\n            a: {\n              $gte: 0\n            }\n          }).addCursorFlag('tailable', true).addCursorFlag('awaitData', true);\n          const stream = cursor.stream();\n          stream.on('data', function (d) {\n            test.ok(d);\n            total = total + 1;\n            if (total === 1000) {\n              cursor.close();\n            }\n          });\n          cursor.on('close', function () {\n            // TODO: forced because the cursor is still open/active\n            client.close(true, done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"should be able to run transactions example 1","suites":["Operation (Promises)","Transaction Examples"],"updatePoint":{"line":5482,"column":52,"index":169648},"line":5482,"code":"    it('should be able to run transactions example 1', {\n      metadata: {\n        requires: {\n          topology: ['replicaset'],\n          mongodb: '>=3.8.0'\n        }\n      },\n      test: function () {\n        const configuration = this.configuration;\n        const client = configuration.newClient(configuration.writeConcernMax());\n\n        // BEGIN\n        function updateEmployeeInfo(client) {\n          return client.withSession(session => {\n            function commit() {\n              return session.commitTransaction().catch(e => {\n                if (e.hasErrorLabel('UnknownTransactionCommitResult')) {\n                  // LINE console.log('Transaction aborted. Caught exception during transaction.');\n                  return commit();\n                }\n\n                // LINE console.log('Error during commit ...');\n                throw e;\n              });\n            }\n            const employeesCollection = client.db('hr').collection('employees');\n            const eventsCollection = client.db('reporting').collection('events');\n            session.startTransaction({\n              readConcern: {\n                level: 'snapshot'\n              },\n              writeConcern: {\n                w: 'majority'\n              }\n            });\n            return employeesCollection.updateOne({\n              employee: 3\n            }, {\n              $set: {\n                status: 'Inactive'\n              }\n            }, {\n              session\n            }).then(() => {\n              return eventsCollection.insertOne({\n                employee: 3,\n                status: {\n                  new: 'Inactive',\n                  old: 'Active'\n                }\n              }, {\n                session\n              });\n            }).catch(e => {\n              // LINE console.log('caugh exception during transaction, aborting')\n              return session.abortTransaction().then(() => Promise.reject(e));\n            }).then(() => commit()).then(() => {\n              // LINE console.log('Transaction committed');\n            });\n          });\n          // END\n        }\n\n        return client.connect().then(() => updateEmployeeInfo(client)).then(() => client.close());\n      }\n    });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"should be able to run transactions retry example 1","suites":["Operation (Promises)","Transaction Examples"],"updatePoint":{"line":5551,"column":58,"index":171958},"line":5551,"code":"    it('should be able to run transactions retry example 1', {\n      metadata: {\n        requires: {\n          topology: ['replicaset'],\n          mongodb: '>=3.8.0'\n        }\n      },\n      test: function () {\n        // BEGIN\n        function runTransactionWithRetry(txnFunc, client, session) {\n          return txnFunc(client, session).catch(error => {\n            // LINE console.log('Transaction aborted. Caught exception during transaction.');\n\n            // If transient error, retry the whole transaction\n            if (error.hasErrorLabel('TransientTransactionError')) {\n              // LINE console.log('TransientTransactionError, retrying transaction ...');\n              return runTransactionWithRetry(txnFunc, client, session);\n            }\n            throw error;\n          });\n        }\n        // END\n\n        function updateEmployeeInfo(client, session) {\n          session.startTransaction({\n            readConcern: {\n              level: 'snapshot'\n            },\n            writeConcern: {\n              w: 'majority'\n            }\n          });\n          const employeesCollection = client.db('hr').collection('employees');\n          const eventsCollection = client.db('reporting').collection('events');\n          return employeesCollection.updateOne({\n            employee: 3\n          }, {\n            $set: {\n              status: 'Inactive'\n            }\n          }, {\n            session\n          }).then(() => {\n            return eventsCollection.insertOne({\n              employee: 3,\n              status: {\n                new: 'Inactive',\n                old: 'Active'\n              }\n            }, {\n              session\n            });\n          }).then(() => session.commitTransaction()).catch(e => {\n            return session.abortTransaction().then(() => Promise.reject(e));\n          });\n        }\n        const configuration = this.configuration;\n        const client = configuration.newClient(configuration.writeConcernMax());\n        return client.connect().then(() => client.withSession(session => runTransactionWithRetry(updateEmployeeInfo, client, session))).then(() => client.close());\n      }\n    });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"should be able to run transactions retry example 2","suites":["Operation (Promises)","Transaction Examples"],"updatePoint":{"line":5616,"column":58,"index":174201},"line":5616,"code":"    it('should be able to run transactions retry example 2', {\n      metadata: {\n        requires: {\n          topology: ['replicaset'],\n          mongodb: '>=3.8.0'\n        }\n      },\n      test: function () {\n        // BEGIN\n        function commitWithRetry(session) {\n          return session.commitTransaction()\n          // LINE .then(() => console.log('Transaction committed.'))\n          .catch(error => {\n            if (error.hasErrorLabel('UnknownTransactionCommitResult')) {\n              // LINE console.log('UnknownTransactionCommitResult, retrying commit operation ...');\n              return commitWithRetry(session);\n            }\n            // LINE console.log('Error during commit ...');\n            throw error;\n          });\n        }\n        // END\n\n        function updateEmployeeInfo(client, session) {\n          session.startTransaction({\n            readConcern: {\n              level: 'snapshot'\n            },\n            writeConcern: {\n              w: 'majority'\n            }\n          });\n          const employeesCollection = client.db('hr').collection('employees');\n          const eventsCollection = client.db('reporting').collection('events');\n          return employeesCollection.updateOne({\n            employee: 3\n          }, {\n            $set: {\n              status: 'Inactive'\n            }\n          }, {\n            session\n          }).then(() => {\n            return eventsCollection.insertOne({\n              employee: 3,\n              status: {\n                new: 'Inactive',\n                old: 'Active'\n              }\n            }, {\n              session\n            });\n          }).then(() => commitWithRetry(session)).catch(e => {\n            return session.abortTransaction().then(() => Promise.reject(e));\n          });\n        }\n        const configuration = this.configuration;\n        const client = configuration.newClient(configuration.writeConcernMax());\n        return client.connect().then(() => client.withSession(session => updateEmployeeInfo(client, session))).then(() => client.close());\n      }\n    });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"should be able to run transactions retry example 3","suites":["Operation (Promises)","Transaction Examples"],"updatePoint":{"line":5680,"column":58,"index":176365},"line":5680,"code":"    it('should be able to run transactions retry example 3', {\n      metadata: {\n        requires: {\n          topology: ['replicaset'],\n          mongodb: '>=3.8.0'\n        }\n      },\n      test: function () {\n        const configuration = this.configuration;\n        const client = configuration.newClient(configuration.writeConcernMax());\n\n        // BEGIN\n        function commitWithRetry(session) {\n          return session.commitTransaction()\n          // LINE .then(() => console.log('Transaction committed.'))\n          .catch(error => {\n            if (error.hasErrorLabel('UnknownTransactionCommitResult')) {\n              // LINE console.log('UnknownTransactionCommitResult, retrying commit operation ...');\n              return commitWithRetry(session);\n            }\n            // LINE console.log('Error during commit ...');\n            throw error;\n          });\n        }\n        function runTransactionWithRetry(txnFunc, client, session) {\n          return txnFunc(client, session).catch(error => {\n            // LINE console.log('Transaction aborted. Caught exception during transaction.');\n\n            // If transient error, retry the whole transaction\n            if (error.hasErrorLabel('TransientTransactionError')) {\n              // LINE console.log('TransientTransactionError, retrying transaction ...');\n              return runTransactionWithRetry(txnFunc, client, session);\n            }\n            throw error;\n          });\n        }\n        function updateEmployeeInfo(client, session) {\n          const employeesCollection = client.db('hr').collection('employees');\n          const eventsCollection = client.db('reporting').collection('events');\n          session.startTransaction({\n            readConcern: {\n              level: 'snapshot'\n            },\n            writeConcern: {\n              w: 'majority'\n            }\n          });\n          return employeesCollection.updateOne({\n            employee: 3\n          }, {\n            $set: {\n              status: 'Inactive'\n            }\n          }, {\n            session\n          }).then(() => {\n            return eventsCollection.insertOne({\n              employee: 3,\n              status: {\n                new: 'Inactive',\n                old: 'Active'\n              }\n            }, {\n              session\n            });\n          }).catch(e => {\n            // LINE console.log('caugh exception during transaction, aborting')\n            return session.abortTransaction().then(() => Promise.reject(e));\n          }).then(() => commitWithRetry(session));\n        }\n\n        // LINE const { MongoClient } = require('mongodb'),\n        // LINE const client = new MongoClient('myRepl/mongodb0.example.net:27017,mongodb1.example.net:27017,mongodb2.example.net:27017');\n        return client.connect().then(() => client.withSession(session => runTransactionWithRetry(updateEmployeeInfo, client, session))).then(() => client.close());\n        // END\n      }\n    });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"should correctly track states of a topology","suites":["Topology"],"updatePoint":{"line":7,"column":49,"index":138},"line":7,"code":"  it('should correctly track states of a topology', {\n    metadata: {\n      requires: {\n        apiVersion: false,\n        topology: '!load-balanced'\n      }\n    },\n    // apiVersion not supported by newTopology()\n    test: function (done) {\n      const topology = this.configuration.newTopology();\n      const states = [];\n      topology.on('stateChanged', (_, newState) => states.push(newState));\n      topology.connect(err => {\n        expect(err).to.not.exist;\n        topology.close(err => {\n          expect(err).to.not.exist;\n          expect(topology.isDestroyed()).to.be.true;\n          expect(states).to.eql(['connecting', 'connected', 'closing', 'closed']);\n          done();\n        });\n      });\n    }\n  });","file":"integration/node-specific/topology.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyGenerateObjectId","suites":["ObjectId"],"updatePoint":{"line":22,"column":37,"index":449},"line":22,"code":"  it('shouldCorrectlyGenerateObjectId', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      var number_of_tests_done = 0;\n      var collection = db.collection('test_object_id_generation.data');\n      // Insert test documents (creates collections and test fetch by query)\n      collection.insertMany([{\n        name: 'Fred',\n        age: 42\n      }], {\n        writeConcern: {\n          w: 1\n        }\n      }, function (err, r) {\n        expect(r).property('insertedCount').to.equal(1);\n        const id = r.insertedIds[0];\n        expect(id.toHexString().length).to.equal(24);\n        // Locate the first document inserted\n        collection.findOne({\n          name: 'Fred'\n        }, function (err, document) {\n          expect(err).to.not.exist;\n          expect(id.toHexString()).to.equal(document._id.toHexString());\n          number_of_tests_done++;\n        });\n      });\n\n      // Insert another test document and collect using ObjectId\n      collection.insert({\n        name: 'Pat',\n        age: 21\n      }, {\n        writeConcern: {\n          w: 1\n        }\n      }, function (err, r) {\n        expect(r).property('insertedCount').to.equal(1);\n        const id = r.insertedIds[0];\n        expect(id.toHexString().length).to.equal(24);\n\n        // Locate the first document inserted\n        collection.findOne(id, function (err, document) {\n          expect(err).to.not.exist;\n          expect(id.toHexString()).to.equal(document._id.toHexString());\n          number_of_tests_done++;\n        });\n      });\n\n      // Manually created id\n      var objectId = new ObjectId(null);\n      // Insert a manually created document with generated oid\n      collection.insert({\n        _id: objectId,\n        name: 'Donald',\n        age: 95\n      }, {\n        writeConcern: {\n          w: 1\n        }\n      }, function (err, r) {\n        expect(err).to.not.exist;\n        expect(r).property('insertedCount').to.equal(1);\n        const id = r.insertedIds[0];\n        expect(id.toHexString().length).to.equal(24);\n        expect(id.toHexString()).to.equal(objectId.toHexString());\n\n        // Locate the first document inserted\n        collection.findOne(id, function (err, document) {\n          expect(err).to.not.exist;\n          expect(id.toHexString()).to.equal(document._id.toHexString());\n          expect(objectId.toHexString()).to.equal(document._id.toHexString());\n          number_of_tests_done++;\n        });\n      });\n      var intervalId = setInterval(function () {\n        if (number_of_tests_done === 3) {\n          clearInterval(intervalId);\n          client.close(done);\n        }\n      }, 100);\n    }\n  });","file":"integration/objectid.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieve24CharacterHexStringFromToString","suites":["ObjectId"],"updatePoint":{"line":113,"column":61,"index":3410},"line":113,"code":"  it('shouldCorrectlyRetrieve24CharacterHexStringFromToString', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      // Create a new ObjectId\n      var objectId = new ObjectId();\n      // Verify that the hex string is 24 characters long\n      test.equal(24, objectId.toString().length);\n      done();\n    }\n  });","file":"integration/objectid.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieve24CharacterHexStringFromToJSON","suites":["ObjectId"],"updatePoint":{"line":127,"column":59,"index":3836},"line":127,"code":"  it('shouldCorrectlyRetrieve24CharacterHexStringFromToJSON', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      // Create a new ObjectId\n      var objectId = new ObjectId();\n      // Verify that the hex string is 24 characters long\n      test.equal(24, objectId.toJSON().length);\n      done();\n    }\n  });","file":"integration/objectid.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateOIDNotUsingObjectId","suites":["ObjectId"],"updatePoint":{"line":141,"column":46,"index":4247},"line":141,"code":"  it('shouldCorrectlyCreateOIDNotUsingObjectId', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      var collection = db.collection('test_non_oid_id');\n      var date = new Date();\n      date.setUTCDate(12);\n      date.setUTCFullYear(2009);\n      date.setUTCMonth(11 - 1);\n      date.setUTCHours(12);\n      date.setUTCMinutes(0);\n      date.setUTCSeconds(30);\n      collection.insert({\n        _id: date\n      }, {\n        writeConcern: {\n          w: 1\n        }\n      }, function (err) {\n        expect(err).to.not.exist;\n        collection.find({\n          _id: date\n        }).toArray(function (err, items) {\n          test.equal('' + date, '' + items[0]._id);\n\n          // Let's close the db\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/objectid.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyGenerateObjectIdFromTimestamp","suites":["ObjectId"],"updatePoint":{"line":180,"column":50,"index":5330},"line":180,"code":"  it('shouldCorrectlyGenerateObjectIdFromTimestamp', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var timestamp = Math.floor(new Date().getTime() / 1000);\n      var objectID = new ObjectId(timestamp);\n      var time2 = objectID.generationTime;\n      test.equal(timestamp, time2);\n      done();\n    }\n  });","file":"integration/objectid.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateAnObjectIdAndOverrideTheTimestamp","suites":["ObjectId"],"updatePoint":{"line":194,"column":60,"index":5769},"line":194,"code":"  it('shouldCorrectlyCreateAnObjectIdAndOverrideTheTimestamp', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var timestamp = 1000;\n      var objectID = new ObjectId();\n      var id1 = objectID.id;\n      // Override the timestamp\n      objectID.generationTime = timestamp;\n      var id2 = objectID.id;\n\n      // Check the timestamp\n      if (id1 instanceof Buffer && id2 instanceof Buffer) {\n        test.deepEqual(id1.slice(0, 4), id2.slice(0, 4));\n      } else {\n        test.equal(id1.substr(4), id2.substr(4));\n      }\n      done();\n    }\n  });","file":"integration/objectid.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertWithObjectId","suites":["ObjectId"],"updatePoint":{"line":217,"column":39,"index":6418},"line":217,"code":"  it('shouldCorrectlyInsertWithObjectId', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: async function () {\n      const client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      const db = client.db(this.configuration.db);\n      const collection = db.collection('shouldCorrectlyInsertWithObjectId');\n      await collection.insertMany([{}], {\n        writeConcern: {\n          w: 1\n        }\n      });\n      const firstCompareDate = new Date();\n      await sleep(200);\n      await collection.insertMany([{}], {\n        writeConcern: {\n          w: 1\n        }\n      });\n      const secondCompareDate = new Date();\n      const items = await collection.find().toArray();\n      // Date 1\n      const date1 = new Date();\n      date1.setTime(items[0]._id.generationTime * 1000);\n      // Date 2\n      const date2 = new Date();\n      date2.setTime(items[1]._id.generationTime * 1000);\n\n      // Compare\n      test.equal(firstCompareDate.getFullYear(), date1.getFullYear());\n      test.equal(firstCompareDate.getDate(), date1.getDate());\n      test.equal(firstCompareDate.getMonth(), date1.getMonth());\n      test.equal(firstCompareDate.getHours(), date1.getHours());\n      test.equal(secondCompareDate.getFullYear(), date2.getFullYear());\n      test.equal(secondCompareDate.getDate(), date2.getDate());\n      test.equal(secondCompareDate.getMonth(), date2.getMonth());\n      test.equal(secondCompareDate.getHours(), date2.getHours());\n\n      // Let's close the db\n      await client.close();\n    }\n  });","file":"integration/objectid.test.js","skipped":false,"dir":"test"},{"name":"Should set majority readConcern aggregate command but ignore due to out","suites":["ReadConcern","client-url specific ReadConcern"],"updatePoint":{"line":276,"column":77,"index":8547},"line":276,"code":"  it('Should set majority readConcern aggregate command but ignore due to out', {\n    metadata: {\n      requires: {\n        topology: 'replicaset',\n        mongodb: '>= 3.2 < 4.1'\n      }\n    },\n    test: function (done) {\n      const started = [];\n      const succeeded = [];\n      // Get a new instance\n      const configuration = this.configuration;\n      client = configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1,\n        readConcern: {\n          level: 'majority'\n        },\n        monitorCommands: true\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        const db = client.db(configuration.db);\n        expect(db.readConcern).to.deep.equal({\n          level: 'majority'\n        });\n\n        // Get a collection\n        const collection = db.collection('readConcernCollectionAggregate1');\n        // Validate readConcern\n        expect(collection.readConcern).to.deep.equal({\n          level: 'majority'\n        });\n\n        // Listen to apm events\n        client.on('commandStarted', filterForCommands('aggregate', started));\n        client.on('commandSucceeded', filterForCommands('aggregate', succeeded));\n\n        // Execute find\n        collection.aggregate([{\n          $match: {}\n        }, {\n          $out: 'readConcernCollectionAggregate1Output'\n        }]).toArray(err => {\n          expect(err).to.not.exist;\n          validateTestResults(started, succeeded, 'aggregate');\n\n          // Execute find\n          collection.aggregate([{\n            $match: {}\n          }], {\n            out: 'readConcernCollectionAggregate2Output'\n          }).toArray(err => {\n            expect(err).to.not.exist;\n            validateTestResults(started, succeeded, 'aggregate');\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/read-write-concern/readconcern.test.js","skipped":false,"dir":"test"},{"name":"Should set majority readConcern aggregate command against server >= 4.1","suites":["ReadConcern","client-url specific ReadConcern"],"updatePoint":{"line":338,"column":77,"index":10361},"line":338,"code":"  it('Should set majority readConcern aggregate command against server >= 4.1', {\n    metadata: {\n      requires: {\n        topology: 'replicaset',\n        mongodb: '>= 4.1'\n      }\n    },\n    test: function (done) {\n      const started = [];\n      const succeeded = [];\n      // Get a new instance\n      const configuration = this.configuration;\n      client = configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1,\n        readConcern: {\n          level: 'majority'\n        },\n        monitorCommands: true\n      });\n      client.connect().then(() => {\n        // Get a collection\n        const collection = client.db(configuration.db).collection('readConcernCollectionAggregate1');\n\n        // Listen to apm events\n        client.on('commandStarted', filterForCommands('aggregate', started));\n        client.on('commandSucceeded', filterForCommands('aggregate', succeeded));\n\n        // Execute find\n        return collection.aggregate([{\n          $match: {}\n        }, {\n          $out: 'readConcernCollectionAggregate1Output'\n        }]).toArray().then(() => {\n          validateTestResults(started, succeeded, 'aggregate', 'majority');\n\n          // Execute find\n          return collection.aggregate([{\n            $match: {}\n          }], {\n            out: 'readConcernCollectionAggregate2Output'\n          }).toArray().then(() => {\n            validateTestResults(started, succeeded, 'aggregate', 'majority');\n          });\n        });\n      }).then(() => client.close(done), e => client.close(() => done(e)));\n    }\n  });","file":"integration/read-write-concern/readconcern.test.js","skipped":false,"dir":"test"},{"name":"Should set majority readConcern mapReduce command but be ignored","suites":["ReadConcern","client-url specific ReadConcern"],"updatePoint":{"line":387,"column":70,"index":11907},"line":387,"code":"  it('Should set majority readConcern mapReduce command but be ignored', {\n    metadata: {\n      requires: {\n        topology: 'replicaset',\n        mongodb: '>= 3.2'\n      }\n    },\n    test: function (done) {\n      const started = [];\n      const succeeded = [];\n      // Get a new instance\n      const configuration = this.configuration;\n      client = configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1,\n        readConcern: {\n          level: 'majority'\n        },\n        monitorCommands: true\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        const db = client.db(configuration.db);\n        expect(db.readConcern).to.deep.equal({\n          level: 'majority'\n        });\n\n        // Get the collection\n        const collection = db.collection('test_map_reduce_read_concern');\n        collection.insertMany([{\n          user_id: 1\n        }, {\n          user_id: 2\n        }], configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n          // String functions\n          const map = 'function() { emit(this.user_id, 1); }';\n          const reduce = 'function(k,vals) { return 1; }';\n\n          // Listen to apm events\n          client.on('commandStarted', filterForCommands('mapReduce', started));\n          client.on('commandSucceeded', filterForCommands('mapReduce', succeeded));\n\n          // Execute mapReduce\n          collection.mapReduce(map, reduce, {\n            out: {\n              replace: 'tempCollection'\n            }\n          }, err => {\n            expect(err).to.not.exist;\n            validateTestResults(started, succeeded, 'mapReduce');\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/read-write-concern/readconcern.test.js","skipped":false,"dir":"test"},{"name":"Should set local readConcern on db level when using createCollection method","suites":["ReadConcern","client-url specific ReadConcern"],"updatePoint":{"line":445,"column":81,"index":13637},"line":445,"code":"  it('Should set local readConcern on db level when using createCollection method', {\n    metadata: {\n      requires: {\n        topology: 'replicaset',\n        mongodb: '>= 3.2'\n      }\n    },\n    test: function (done) {\n      // Get a new instance\n      const configuration = this.configuration;\n      client = configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1,\n        readConcern: {\n          level: 'local'\n        }\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        const db = client.db(configuration.db);\n        expect(db.readConcern).to.deep.equal({\n          level: 'local'\n        });\n\n        // Get a collection using createCollection\n        db.createCollection('readConcernCollection_createCollection', (err, collection) => {\n          expect(err).to.not.exist;\n\n          // Validate readConcern\n          expect(collection.readConcern).to.deep.equal({\n            level: 'local'\n          });\n          done();\n        });\n      });\n    }\n  });","file":"integration/read-write-concern/readconcern.test.js","skipped":false,"dir":"test"},{"name":"should respect writeConcern from uri","suites":["Write Concern"],"updatePoint":{"line":14,"column":42,"index":313},"line":14,"code":"  it('should respect writeConcern from uri', function (done) {\n    const client = this.configuration.newClient(`${this.configuration.url()}&w=0&monitorCommands=true`);\n    const events = [];\n    client.on('commandStarted', event => {\n      if (event.commandName === 'insert') {\n        events.push(event);\n      }\n    });\n    expect(client.writeConcern).to.eql({\n      w: 0\n    });\n    client.db('test').collection('test').insertOne({\n      a: 1\n    }, (err, result) => {\n      expect(err).to.not.exist;\n      expect(result).to.exist;\n      expect(events).to.be.an('array').with.lengthOf(1);\n      expect(events[0]).to.containSubset({\n        commandName: 'insert',\n        command: {\n          writeConcern: {\n            w: 0\n          }\n        }\n      });\n      client.close(done);\n    });\n  });","file":"integration/read-write-concern/write_concern.test.js","skipped":false,"dir":"test"},{"name":"should pipe writeConcern from client down to API call","suites":["Write Concern","mock server write concern test"],"line":52,"code":"    it.skip('should pipe writeConcern from client down to API call', function () {","file":"integration/read-write-concern/write_concern.test.js","skipped":true,"dir":"test"},{"name":"ensure monitors sleep for an appropriate amount of time between pings","suites":["Server Discovery and Monitoring Prose Tests","Monitors sleep at least minHeartbeatFrequencyMS between checks"],"updatePoint":{"line":68,"column":77,"index":2426},"line":68,"code":"    it('ensure monitors sleep for an appropriate amount of time between pings', {\n      metadata: {\n        requires: {\n          mongodb: '>=4.9.0',\n          topology: '!load-balanced'\n        }\n      },\n      test: async function () {\n        // 3.\n        const startTime = Date.now();\n        // 4.\n        await client.db().command({\n          ping: 1\n        });\n        // 5.\n        const timeTaken = Date.now() - startTime;\n        const secondsTaken = timeTaken / 1000;\n        expect(secondsTaken).to.be.within(2, 3.5);\n      }\n    });","file":"integration/server-discovery-and-monitoring/server_discovery_and_monitoring.prose.test.ts","skipped":false,"dir":"test"},{"name":"ensure monitors properly create and unpause connection pools when they discover servers","suites":["Server Discovery and Monitoring Prose Tests","Connection Pool Management"],"updatePoint":{"line":138,"column":95,"index":4980},"line":138,"code":"    it('ensure monitors properly create and unpause connection pools when they discover servers', {\n      metadata: {\n        requires: {\n          mongodb: '>=4.2.9',\n          topology: '!load-balanced'\n        }\n      },\n      test: async function () {\n        await client.connect();\n        expect(events.shift()).to.equal(SERVER_HEARTBEAT_SUCCEEDED);\n        expect(events.shift()).to.equal(CONNECTION_POOL_READY);\n        expect(events).to.be.empty;\n        const heartBeatFailedEvent = once(client, SERVER_HEARTBEAT_FAILED);\n        await client.db('admin').command({\n          configureFailPoint: 'failCommand',\n          mode: {\n            times: 2\n          },\n          data: {\n            failCommands: ['hello'],\n            errorCode: 1234,\n            appName: 'SDAMPoolManagementTest'\n          }\n        });\n        await heartBeatFailedEvent;\n        expect(events.shift()).to.equal(SERVER_HEARTBEAT_FAILED);\n        expect(events.shift()).to.equal(CONNECTION_POOL_CLEARED);\n        expect(events).to.be.empty;\n        await once(client, SERVER_HEARTBEAT_SUCCEEDED);\n        expect(events.shift()).to.equal(SERVER_HEARTBEAT_SUCCEEDED);\n        expect(events.shift()).to.equal(CONNECTION_POOL_READY);\n        expect(events).to.be.empty;\n      }\n    });","file":"integration/server-discovery-and-monitoring/server_discovery_and_monitoring.prose.test.ts","skipped":false,"dir":"test"},{"name":"is zero after a successful command","suites":["Server Operation Count Tests","load balanced mode with pinnable operations"],"updatePoint":{"line":59,"column":42,"index":1641},"line":59,"code":"    it('is zero after a successful command', loadBalancedTestMetadata, async function () {\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      const commandSpy = sinon.spy(server, 'command');\n      await collection.findOne({\n        count: 1\n      });\n      expect(commandSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"is zero after a command fails","suites":["Server Operation Count Tests","load balanced mode with pinnable operations"],"updatePoint":{"line":69,"column":37,"index":2068},"line":69,"code":"    it('is zero after a command fails', loadBalancedTestMetadata, async function () {\n      await client.db('admin').command(enableFailPointCommand);\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      const commandSpy = sinon.spy(server, 'command');\n      const error = await collection.findOne({\n        count: 1\n      }).catch(e => e);\n      expect(error).to.exist;\n      expect(commandSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"is zero after failing to check out a connection for a command","suites":["Server Operation Count Tests","load balanced mode with pinnable operations"],"updatePoint":{"line":81,"column":69,"index":2649},"line":81,"code":"    it('is zero after failing to check out a connection for a command', loadBalancedTestMetadata, async function () {\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      sinon.stub(ConnectionPool.prototype, 'checkOut').callsFake(function (cb) {\n        cb(new Error('unable to checkout connection'), undefined);\n      });\n      const commandSpy = sinon.spy(server, 'command');\n      const error = await collection.findOne({\n        count: 1\n      }).catch(e => e);\n      expect(error).to.exist;\n      expect(error).to.match(/unable to checkout connection/i);\n      expect(commandSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"is zero after a successful command","suites":["Server Operation Count Tests","operationCount is adjusted properly on successful operation"],"updatePoint":{"line":98,"column":42,"index":3454},"line":98,"code":"    it('is zero after a successful command', testMetadata, async function () {\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      const commandSpy = sinon.spy(server, 'command');\n      const operationPromises = Array.from({\n        length: 10\n      }, () => collection.insertOne({\n        count: 1\n      }));\n\n      // operation count is incremented after connection checkout, which happens asynchronously (even though there are plenty of connections in the pool).\n      // we sleep to give the event loop a turn so that all the commands check out a connection before asserting the operation count\n      await sleep(1);\n      expect(server.s.operationCount).to.equal(10);\n      await Promise.all(operationPromises);\n      expect(commandSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"is zero after a command fails","suites":["Server Operation Count Tests","operationCount is adjusted properly when operations fail"],"updatePoint":{"line":118,"column":37,"index":4436},"line":118,"code":"    it('is zero after a command fails', testMetadata, async function () {\n      await client.db('admin').command(enableFailPointCommand);\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      const commandSpy = sinon.spy(server, 'command');\n      const error = await collection.insertOne({\n        count: 1\n      }).catch(e => e);\n      expect(error).to.exist;\n      expect(commandSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"is zero after failing to check out a connection for a command","suites":["Server Operation Count Tests","operationCount is decremented when the server fails to checkout a connection"],"updatePoint":{"line":132,"column":69,"index":5117},"line":132,"code":"    it('is zero after failing to check out a connection for a command', testMetadata, async function () {\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      sinon.stub(ConnectionPool.prototype, 'checkOut').callsFake(function (cb) {\n        cb(new Error('unable to checkout connection'), undefined);\n      });\n      const commandSpy = sinon.spy(server, 'command');\n      const error = await collection.insertOne({\n        count: 1\n      }).catch(e => e);\n      expect(error).to.exist;\n      expect(error).to.match(/unable to checkout connection/i);\n      expect(commandSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly apply collection level read Preference to count","suites":["ReadPreference"],"updatePoint":{"line":29,"column":70,"index":673},"line":29,"code":"  it('Should correctly apply collection level read Preference to count', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        // Set read preference\n        var collection = db.collection('read_pref_1', {\n          readPreference: ReadPreference.SECONDARY_PREFERRED\n        });\n        // Save checkout function\n        var command = client.topology.command;\n        // Set up our checker method\n        client.topology.command = function () {\n          var args = Array.prototype.slice.call(arguments, 0);\n          if (args[0] === 'integration_tests.$cmd') {\n            test.equal(ReadPreference.SECONDARY_PREFERRED, args[2].readPreference.mode);\n          }\n          return command.apply(db.s.topology, args);\n        };\n\n        // Execute count\n        collection.count(function (err) {\n          expect(err).to.not.exist;\n          client.topology.command = command;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply collection level read Preference to mapReduce","suites":["ReadPreference"],"updatePoint":{"line":68,"column":74,"index":1997},"line":68,"code":"  it('Should correctly apply collection level read Preference to mapReduce', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        // Set read preference\n        var collection = db.collection('read_pref_1', {\n          readPreference: ReadPreference.SECONDARY_PREFERRED\n        });\n        // Save checkout function\n        var command = client.topology.command;\n        // Set up our checker method\n        client.topology.command = function () {\n          var args = Array.prototype.slice.call(arguments, 0);\n          if (args[0] === 'integration_tests.$cmd') {\n            test.equal(ReadPreference.SECONDARY_PREFERRED, args[2].readPreference.mode);\n          }\n          return command.apply(db.s.topology, args);\n        };\n\n        // Map function\n        var map = function () {\n          emit(this.user_id, 1); // eslint-disable-line\n        };\n        // Reduce function\n        var reduce = function /* k, vals */\n        () {\n          return 1;\n        };\n\n        // Perform the map reduce\n        collection.mapReduce(map, reduce, {\n          out: {\n            inline: 1\n          }\n        }, function /* err */\n        () {\n          // expect(err).to.not.exist;\n\n          client.topology.command = command;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply collection level read Preference to mapReduce backward compatibility","suites":["ReadPreference"],"updatePoint":{"line":123,"column":97,"index":3692},"line":123,"code":"  it('Should correctly apply collection level read Preference to mapReduce backward compatibility', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        // Set read preference\n        var collection = db.collection('read_pref_1', {\n          readPreference: ReadPreference.SECONDARY_PREFERRED\n        });\n        // Save checkout function\n        var command = client.topology.command;\n        // Set up our checker method\n        client.topology.command = function () {\n          var args = Array.prototype.slice.call(arguments, 0);\n          if (args[0] === 'integration_tests.$cmd') {\n            test.equal(ReadPreference.SECONDARY_PREFERRED, args[2].readPreference.mode);\n          }\n          return command.apply(db.s.topology, args);\n        };\n\n        // Map function\n        var map = function () {\n          emit(this.user_id, 1); // eslint-disable-line\n        };\n\n        // Reduce function\n        var reduce = function /* k, vals */\n        () {\n          return 1;\n        };\n\n        // Perform the map reduce\n        collection.mapReduce(map, reduce, {\n          out: 'inline'\n        }, function /* err */\n        () {\n          // expect(err).to.not.exist;\n          client.topology.command = command;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should fail due to not using mapReduce inline with read preference","suites":["ReadPreference"],"updatePoint":{"line":176,"column":72,"index":5335},"line":176,"code":"  it('Should fail due to not using mapReduce inline with read preference', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        // Set read preference\n        var collection = db.collection('read_pref_1', {\n          readPreference: ReadPreference.SECONDARY_PREFERRED\n        });\n        // Map function\n        var map = function () {\n          emit(this.user_id, 1); // eslint-disable-line\n        };\n\n        // Reduce function\n        var reduce = function /* k, vals */\n        () {\n          return 1;\n        };\n\n        // Perform the map reduce\n        collection.mapReduce(map, reduce, {\n          out: {\n            append: 'test'\n          }\n        }, function (err) {\n          test.notEqual(err, null);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply collection level read Preference to aggregate","suites":["ReadPreference"],"updatePoint":{"line":218,"column":74,"index":6500},"line":218,"code":"  it('Should correctly apply collection level read Preference to aggregate', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        // Set read preference\n        var collection = db.collection('read_pref_1', {\n          readPreference: ReadPreference.SECONDARY_PREFERRED\n        });\n        // Save checkout function\n        var command = client.topology.command;\n        // Set up our checker method\n        client.topology.command = function () {\n          var args = Array.prototype.slice.call(arguments, 0);\n          if (args[0] === 'integration_tests.$cmd') {\n            test.equal(ReadPreference.SECONDARY_PREFERRED, args[2].readPreference.mode);\n          }\n          return command.apply(db.s.topology, args);\n        };\n        const cursor = collection.aggregate([{\n          $project: {\n            author: 1,\n            tags: 1\n          }\n        }, {\n          $unwind: '$tags'\n        }, {\n          $group: {\n            _id: {\n              tags: '$tags'\n            },\n            authors: {\n              $addToSet: '$author'\n            }\n          }\n        }]);\n        cursor.toArray(function (err) {\n          expect(err).to.not.exist;\n          client.topology.command = command;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply collection level read Preference to stats","suites":["ReadPreference"],"updatePoint":{"line":272,"column":70,"index":8148},"line":272,"code":"  it('Should correctly apply collection level read Preference to stats', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        // Set read preference\n        var collection = db.collection('read_pref_1', {\n          readPreference: ReadPreference.SECONDARY_PREFERRED\n        });\n        // Save checkout function\n        var command = client.topology.command;\n        // Set up our checker method\n        client.topology.command = function () {\n          var args = Array.prototype.slice.call(arguments, 0);\n          if (args[0] === 'integration_tests.$cmd') {\n            test.equal(ReadPreference.SECONDARY_PREFERRED, args[2].readPreference.mode);\n          }\n          return command.apply(db.s.topology, args);\n        };\n\n        // Perform the map reduce\n        collection.stats(function /* err */\n        () {\n          // expect(err).to.not.exist;\n          client.topology.command = command;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly honor the readPreferences at DB and individual command level","suites":["ReadPreference"],"updatePoint":{"line":312,"column":83,"index":9508},"line":312,"code":"  it('Should correctly honor the readPreferences at DB and individual command level', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        w: 1,\n        readPreference: 'secondary'\n      }, {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        // Save checkout function\n        var command = client.topology.command;\n        // Set up our checker method\n        client.topology.command = function () {\n          var args = Array.prototype.slice.call(arguments, 0);\n          if (args[0] === 'integration_tests.$cmd') {\n            test.equal(ReadPreference.SECONDARY, args[2].readPreference.mode);\n          }\n          return command.apply(db.s.topology, args);\n        };\n        db.command({\n          dbStats: true\n        }, function (err) {\n          expect(err).to.not.exist;\n          client.topology.command = function () {\n            var args = Array.prototype.slice.call(arguments, 0);\n            if (args[0] === 'integration_tests.$cmd') {\n              test.equal(ReadPreference.SECONDARY_PREFERRED, args[2].readPreference.mode);\n            }\n            return command.apply(db.s.topology, args);\n          };\n          db.command({\n            dbStats: true\n          }, {\n            readPreference: 'secondaryPreferred'\n          }, function (err) {\n            expect(err).to.not.exist;\n            client.topology.command = command;\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply readPreferences specified as objects","suites":["ReadPreference"],"updatePoint":{"line":363,"column":65,"index":11195},"line":363,"code":"  it('Should correctly apply readPreferences specified as objects', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        // Create read preference object.\n        var mySecondaryPreferred = {\n          mode: 'secondaryPreferred',\n          tags: []\n        };\n        db.command({\n          dbStats: true\n        }, {\n          readPreference: mySecondaryPreferred\n        }, function (err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly pass readPreferences specified as objects to cursors","suites":["ReadPreference"],"updatePoint":{"line":394,"column":75,"index":12079},"line":394,"code":"  it('Should correctly pass readPreferences specified as objects to cursors', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        // Create read preference object.\n        var mySecondaryPreferred = {\n          mode: 'secondaryPreferred',\n          tags: []\n        };\n        db.listCollections({}, {\n          readPreference: mySecondaryPreferred\n        }).toArray(function (err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly pass readPreferences specified as objects to collection methods","suites":["ReadPreference"],"updatePoint":{"line":423,"column":86,"index":12957},"line":423,"code":"  it('Should correctly pass readPreferences specified as objects to collection methods', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        // Create read preference object.\n        var mySecondaryPreferred = {\n          mode: 'secondaryPreferred',\n          tags: []\n        };\n        var cursor = db.collection('test').find({}, {\n          readPreference: mySecondaryPreferred\n        });\n        cursor.toArray(function (err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly pass readPreferences on the Collection to listIndexes","suites":["ReadPreference"],"updatePoint":{"line":453,"column":76,"index":13862},"line":453,"code":"  it('Should correctly pass readPreferences on the Collection to listIndexes', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        var cursor = db.collection('test', {\n          readPreference: ReadPreference.SECONDARY_PREFERRED\n        }).listIndexes();\n        test.equal(cursor.readPreference.mode, 'secondaryPreferred');\n        client.close(done);\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should throw an error on an invalid readPreference","suites":["ReadPreference"],"updatePoint":{"line":476,"column":56,"index":14599},"line":476,"code":"  it('Should throw an error on an invalid readPreference', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient();\n    client.connect((err, client) => {\n      const db = client.db(configuration.db);\n      expect(db.collection.bind(db, 'test', {\n        readPreference: 'invalid'\n      })).to.throw('Invalid read preference mode \"invalid\"');\n      client.close(done);\n    });\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"should set hedge using [find option & empty hedge]","suites":["ReadPreference","hedge"],"updatePoint":{"line":488,"column":58,"index":15069},"line":488,"code":"    it('should set hedge using [find option & empty hedge]', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.6.0'\n        }\n      },\n      test: function (done) {\n        const events = [];\n        client.on('commandStarted', event => {\n          if (event.commandName === 'find') {\n            events.push(event);\n          }\n        });\n        const rp = new ReadPreference(ReadPreference.SECONDARY, null, {\n          hedge: {}\n        });\n        client.db(this.configuration.db).collection('test').find({}, {\n          readPreference: rp\n        }).toArray(err => {\n          expect(err).to.not.exist;\n          const expected = {\n            mode: ReadPreference.SECONDARY,\n            hedge: {}\n          };\n          expect(events[0]).nested.property('command.$readPreference').to.deep.equal(expected);\n          done();\n        });\n      }\n    });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"should set hedge using [.withReadPreference & empty hedge] ","suites":["ReadPreference","hedge"],"updatePoint":{"line":517,"column":67,"index":15951},"line":517,"code":"    it('should set hedge using [.withReadPreference & empty hedge] ', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.6.0'\n        }\n      },\n      test: function (done) {\n        const events = [];\n        client.on('commandStarted', event => {\n          if (event.commandName === 'find') {\n            events.push(event);\n          }\n        });\n        const rp = new ReadPreference(ReadPreference.SECONDARY, null, {\n          hedge: {}\n        });\n        client.db(this.configuration.db).collection('test').find({}).withReadPreference(rp).toArray(err => {\n          expect(err).to.not.exist;\n          const expected = {\n            mode: ReadPreference.SECONDARY,\n            hedge: {}\n          };\n          expect(events[0]).nested.property('command.$readPreference').to.deep.equal(expected);\n          done();\n        });\n      }\n    });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"should set hedge using [.withReadPreference & enabled hedge] ","suites":["ReadPreference","hedge"],"updatePoint":{"line":544,"column":69,"index":16816},"line":544,"code":"    it('should set hedge using [.withReadPreference & enabled hedge] ', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.6.0'\n        }\n      },\n      test: function (done) {\n        const events = [];\n        client.on('commandStarted', event => {\n          if (event.commandName === 'find') {\n            events.push(event);\n          }\n        });\n        const rp = new ReadPreference(ReadPreference.SECONDARY, null, {\n          hedge: {\n            enabled: true\n          }\n        });\n        client.db(this.configuration.db).collection('test').find({}).withReadPreference(rp).toArray(err => {\n          expect(err).to.not.exist;\n          const expected = {\n            mode: ReadPreference.SECONDARY,\n            hedge: {\n              enabled: true\n            }\n          };\n          expect(events[0]).nested.property('command.$readPreference').to.deep.equal(expected);\n          done();\n        });\n      }\n    });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"should set hedge using [.withReadPreference & disabled hedge] ","suites":["ReadPreference","hedge"],"updatePoint":{"line":575,"column":70,"index":17760},"line":575,"code":"    it('should set hedge using [.withReadPreference & disabled hedge] ', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.6.0'\n        }\n      },\n      test: function (done) {\n        const events = [];\n        client.on('commandStarted', event => {\n          if (event.commandName === 'find') {\n            events.push(event);\n          }\n        });\n        const rp = new ReadPreference(ReadPreference.SECONDARY, null, {\n          hedge: {\n            enabled: false\n          }\n        });\n        client.db(this.configuration.db).collection('test').find({}).withReadPreference(rp).toArray(err => {\n          expect(err).to.not.exist;\n          const expected = {\n            mode: ReadPreference.SECONDARY,\n            hedge: {\n              enabled: false\n            }\n          };\n          expect(events[0]).nested.property('command.$readPreference').to.deep.equal(expected);\n          done();\n        });\n      }\n    });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"should set hedge using [.withReadPreference & undefined hedge] ","suites":["ReadPreference","hedge"],"updatePoint":{"line":606,"column":71,"index":18707},"line":606,"code":"    it('should set hedge using [.withReadPreference & undefined hedge] ', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.6.0'\n        }\n      },\n      test: function (done) {\n        const events = [];\n        client.on('commandStarted', event => {\n          if (event.commandName === 'find') {\n            events.push(event);\n          }\n        });\n        const rp = new ReadPreference(ReadPreference.SECONDARY, null);\n        client.db(this.configuration.db).collection('test').find({}).withReadPreference(rp).toArray(err => {\n          expect(err).to.not.exist;\n          const expected = {\n            mode: ReadPreference.SECONDARY\n          };\n          expect(events[0]).nested.property('command.$readPreference').to.deep.equal(expected);\n          done();\n        });\n      }\n    });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"","suites":["ReadPreference","should enforce fixed primary read preference"],"updatePoint":{"line":671,"column":22,"index":20894},"line":671,"code":"      it(`${operation}`, {\n        metadata: {\n          requires: {\n            topology: ['replicaset', 'sharded']\n          }\n        },\n        test: async function () {\n          const configuration = this.configuration;\n          const db = client.db(configuration.db);\n          const args = methods[operation];\n          const [parentId, method] = operation.split('#');\n          const collection = db.collection(collectionName);\n          const parent = parentId === 'Collection' ? collection : parentId === 'Db' ? db : null;\n          const selectServerSpy = this.sinon.spy(Topology.prototype, 'selectServer');\n          expect(parent).to.have.property(method).that.is.a('function');\n          await parent[method](...args);\n          expect(selectServerSpy.called).to.equal(true);\n          const selectionCall = selectServerSpy.getCall(0);\n          expect(selectionCall.args[0]).to.not.be.a('function');\n          expect(selectionCall).nested.property('args[0].mode').to.equal(ReadPreference.PRIMARY);\n        }\n      });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"should respect readPreference from uri","suites":["ReadPreference","should enforce fixed primary read preference"],"updatePoint":{"line":695,"column":44,"index":21963},"line":695,"code":"  it('should respect readPreference from uri', {\n    metadata: {\n      requires: {\n        topology: 'replicaset',\n        mongodb: '>=3.6'\n      }\n    },\n    test: async function () {\n      const client = this.configuration.newClient({\n        readPreference: 'secondary',\n        monitorCommands: true\n      });\n      const events = [];\n      client.on('commandStarted', event => {\n        if (event.commandName === 'find') {\n          events.push(event);\n        }\n      });\n      expect(client.readPreference.mode).to.equal('secondary');\n      await client.db('test').collection('test').findOne({\n        a: 1\n      });\n      expect(events).to.be.an('array').with.lengthOf(1);\n      expect(events[0]).to.containSubset({\n        commandName: 'find',\n        command: {\n          $readPreference: {\n            mode: 'secondary'\n          }\n        }\n      });\n      await client.close();\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"needs to run on exactly two mongoses","suites":["operationCount-based Selection Within Latency Window - Prose Test"],"updatePoint":{"line":90,"column":42,"index":2826},"line":90,"code":"  it('needs to run on exactly two mongoses', TEST_METADATA, function () {\n    expect(seeds).to.have.lengthOf(2);\n  });","file":"integration/server-selection/server_selection.prose.operation_count.test.ts","skipped":false,"dir":"test"},{"name":"sends fewer requests to the overloaded server","suites":["operationCount-based Selection Within Latency Window - Prose Test","when one mongos is overloaded"],"updatePoint":{"line":117,"column":53,"index":3852},"line":117,"code":"    it('sends fewer requests to the overloaded server', TEST_METADATA, async function () {\n      const failingSeed = seeds[0];\n      const collection = client.db('test-db').collection('collection0');\n\n      // Step 5: Start 10 concurrent threads / tasks that each run 10 findOne operations with empty filters using that client.\n      await Promise.all(Array.from({\n        length: 10\n      }, () => runTaskGroup(collection, 10)));\n\n      // Step 6: Using command monitoring events, assert that fewer than 25% of the CommandStartedEvents\n      // occurred on the mongos that the failpoint was enabled on.\n      const port = failingSeed.split(':')[1];\n      const percentageSentToSlowHost = counts[port] / 100 * 100;\n      expect(percentageSentToSlowHost).to.be.lessThan(25);\n    });","file":"integration/server-selection/server_selection.prose.operation_count.test.ts","skipped":false,"dir":"test"},{"name":"equally distributes operations with both hosts are fine","suites":["operationCount-based Selection Within Latency Window - Prose Test","when one mongos is overloaded"],"updatePoint":{"line":133,"column":61,"index":4648},"line":133,"code":"  it('equally distributes operations with both hosts are fine', TEST_METADATA, async function () {\n    const collection = client.db('test-db').collection('collection0');\n    const numberTaskGroups = 10;\n    const numberOfTasks = 1000;\n    const totalNumberOfTasks = numberTaskGroups * numberOfTasks;\n\n    // This test has proved flakey, not just for Node.  The number of iterations for the test has been increased,\n    // to prevent the test from failing.\n    // Step 8: Start 10 concurrent threads / tasks that each run 100 findOne operations with empty filters using that client.\n    await Promise.all(Array.from({\n      length: numberTaskGroups\n    }, () => runTaskGroup(collection, numberOfTasks)));\n\n    // Step 9: Using command monitoring events, assert that each mongos was selected roughly 50% of the time (within +/- 10%).\n    const [host1, host2] = seeds.map(seed => seed.split(':')[1]);\n    const percentageToHost1 = counts[host1] / totalNumberOfTasks * 100;\n    const percentageToHost2 = counts[host2] / totalNumberOfTasks * 100;\n    expect(percentageToHost1).to.be.greaterThan(40).and.lessThan(60);\n    expect(percentageToHost2).to.be.greaterThan(40).and.lessThan(60);\n  });","file":"integration/server-selection/server_selection.prose.operation_count.test.ts","skipped":false,"dir":"test"},{"name":"equally distributes operations with both hosts when requests are in sequence","suites":["operationCount-based Selection Within Latency Window - Prose Test","when one mongos is overloaded"],"updatePoint":{"line":153,"column":82,"index":5857},"line":153,"code":"  it('equally distributes operations with both hosts when requests are in sequence', TEST_METADATA,\n  /**\n   * note that this test is NOT a prose test, but it lives in this file because it uses the\n   * same setup as the operation count prose tests\n   */\n  async function () {\n    const collection = client.db('test-db').collection('collection0');\n    const {\n      insertedId\n    } = await collection.insertOne({\n      name: 'bumpy'\n    });\n    const n = 1000;\n    for (let i = 0; i < n; ++i) {\n      await collection.findOne({\n        _id: insertedId\n      });\n    }\n    const [host1, host2] = seeds.map(seed => seed.split(':')[1]);\n    const percentageToHost1 = counts[host1] / n * 100;\n    const percentageToHost2 = counts[host2] / n * 100;\n    expect(percentageToHost1).to.be.greaterThan(40).and.lessThan(60);\n    expect(percentageToHost2).to.be.greaterThan(40).and.lessThan(60);\n  });","file":"integration/server-selection/server_selection.prose.operation_count.test.ts","skipped":false,"dir":"test"},{"name":"14. may reuse one server session for many operations","suites":["ServerSession"],"updatePoint":{"line":27,"column":58,"index":1252},"line":27,"code":"  it('14. may reuse one server session for many operations', async () => {\n    const events = [];\n    client.on('commandStarted', ev => events.push(ev));\n    const operations = [testCollection.insertOne({\n      _id: 1\n    }), testCollection.deleteOne({\n      _id: 2\n    }), testCollection.updateOne({\n      _id: 3\n    }, {\n      $set: {\n        a: 1\n      }\n    }), testCollection.bulkWrite([{\n      updateOne: {\n        filter: {\n          _id: 4\n        },\n        update: {\n          $set: {\n            a: 1\n          }\n        }\n      }\n    }]), testCollection.findOneAndDelete({\n      _id: 5\n    }), testCollection.findOneAndUpdate({\n      _id: 6\n    }, {\n      $set: {\n        a: 1\n      }\n    }), testCollection.findOneAndReplace({\n      _id: 7\n    }, {\n      a: 8\n    }), testCollection.find().toArray()];\n    const allResults = await Promise.all(operations);\n    expect(allResults).to.have.lengthOf(operations.length);\n    expect(events).to.have.lengthOf(operations.length);\n\n    // This is a guarantee in node, unless you are performing a transaction (which is not being done in this test)\n    expect(new Set(events.map(ev => ev.command.lsid.id.toString('hex')))).to.have.lengthOf(2);\n  });","file":"integration/sessions/sessions.spec.prose.test.ts","skipped":false,"dir":"test"},{"name":"should send endSessions for multiple sessions","suites":["Sessions Spec","Sessions - functional - old format","endSessions"],"updatePoint":{"line":66,"column":55,"index":2115},"line":66,"code":"      it('should send endSessions for multiple sessions', function (done) {\n        const client = test.client;\n        const sessions = [client.startSession(), client.startSession()].map(s => s.id);\n        client.close(err => {\n          expect(err).to.not.exist;\n          expect(test.commands.started).to.have.length(1);\n          expect(test.commands.started[0].commandName).to.equal('endSessions');\n          expect(test.commands.started[0].command.endSessions).to.include.deep.members(sessions);\n          expect(client.s.activeSessions.size).to.equal(0);\n          done();\n        });\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"supports passing options to ClientSession","suites":["Sessions Spec","Sessions - functional - old format","withSession"],"updatePoint":{"line":155,"column":51,"index":5650},"line":155,"code":"      it('supports passing options to ClientSession', async function () {\n        let sessionWasEnded = false;\n        await client.withSession({\n          causalConsistency: false\n        }, async session => {\n          session.on('ended', () => {\n            sessionWasEnded = true;\n          });\n          expect(session.supports.causalConsistency).to.be.false;\n          await client.db('test').collection('foo').find({}, {\n            session\n          }).toArray();\n        });\n        expect(client.s.sessionPool.sessions).to.have.length(1);\n        expect(sessionWasEnded).to.be.true;\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should not include session for unacknowledged writes","suites":["Sessions Spec","Sessions - functional - old format","unacknowledged writes"],"updatePoint":{"line":173,"column":62,"index":6317},"line":173,"code":"      it('should not include session for unacknowledged writes', async function () {\n        const events = [];\n        client.on('commandStarted', event => {\n          if (event.commandName === 'insert') {\n            events.push(event);\n          }\n        });\n        await client.db('test').collection('foo').insertOne({\n          foo: 'bar'\n        }, {\n          writeConcern: {\n            w: 0\n          }\n        });\n        const event = events[0];\n        expect(event).nested.property('command.writeConcern.w').to.equal(0);\n        expect(event).to.not.have.nested.property('command.lsid');\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should throw error with explicit session","suites":["Sessions Spec","Sessions - functional - old format","unacknowledged writes"],"updatePoint":{"line":191,"column":50,"index":6918},"line":191,"code":"      it('should throw error with explicit session', {\n        metadata: {\n          requires: {\n            topology: 'replicaset',\n            mongodb: '>=3.6.0'\n          }\n        },\n        test: async function () {\n          const events = [];\n          client.on('commandStarted', event => {\n            if (event.commandName === 'insert') {\n              events.push(event);\n            }\n          });\n          const session = client.startSession({\n            causalConsistency: true\n          });\n          const error = await client.db('test').collection('foo').insertOne({\n            foo: 'bar'\n          }, {\n            writeConcern: {\n              w: 0\n            },\n            session\n          }).catch(error => error);\n          expect(error.message).to.equal('Cannot have explicit session with unacknowledged writes');\n          await session.endSession();\n        }\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should result in a usable session when called with a valid cluster time and should not affect any other sessions","suites":["Sessions Spec","Sessions - functional - new format","advanceClusterTime()"],"updatePoint":{"line":271,"column":122,"index":9789},"line":271,"code":"      it('should result in a usable session when called with a valid cluster time and should not affect any other sessions', {\n        metadata: {\n          requires: {\n            mongodb: '>= 3.6.0',\n            topology: ['replicaset']\n          }\n        },\n        async test() {\n          // advance cluster time to a new valid value\n          testSession.advanceClusterTime(otherSession.clusterTime);\n          expect(testSession.clusterTime).to.deep.equal(otherSession.clusterTime);\n\n          // check control session\n          expect(controlSession.clusterTime).to.not.deep.equal(testSession.clusterTime);\n\n          // check that the session still works\n          expect(await collection.findOne({}, {\n            session: testSession\n          })).property('apple').to.equal('green');\n        }\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should not let an invalid cluster time impact existing sessions","suites":["Sessions Spec","Sessions - functional - new format","advanceClusterTime()"],"updatePoint":{"line":292,"column":73,"index":10557},"line":292,"code":"      it('should not let an invalid cluster time impact existing sessions', {\n        metadata: {\n          requires: {\n            mongodb: '>= 3.6.0',\n            topology: ['replicaset']\n          }\n        },\n        async test() {\n          // note, because of our validation, we can't use advanceClusterTime to set an invalid clusterTime\n          // so for testing, we have to set it directly\n          testSession.clusterTime = {\n            clusterTime: {\n              greaterThan: () => true\n            }\n          };\n          try {\n            await collection.findOne({}, {\n              session: testSession\n            });\n            expect.fail('expected findOne to fail, but it passed');\n          } catch (err) {\n            expect(err).to.be.instanceOf(MongoServerError);\n          }\n          expect(await collection.findOne({}, {\n            session: controlSession\n          })).property('apple').to.equal('green');\n        }\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should not let an invalid cluster time impact new sessions","suites":["Sessions Spec","Sessions - functional - new format","advanceClusterTime()"],"updatePoint":{"line":320,"column":68,"index":11513},"line":320,"code":"      it('should not let an invalid cluster time impact new sessions', {\n        metadata: {\n          requires: {\n            mongodb: '>= 3.6.0',\n            topology: ['replicaset']\n          }\n        },\n        async test() {\n          // note, because of our validation, we can't use advanceClusterTime to set an invalid clusterTime\n          // so for testing, we have to set it directly\n          testSession.clusterTime = {\n            clusterTime: {\n              greaterThan: () => true\n            }\n          };\n          try {\n            await collection.findOne({}, {\n              session: testSession\n            });\n            expect.fail('expected findOne to fail, but it passed');\n          } catch (err) {\n            expect(err).to.be.instanceOf(MongoServerError);\n          }\n          await otherSession.endSession();\n          otherSession = client.startSession();\n          expect(await collection.findOne({}, {\n            session: otherSession\n          })).property('apple').to.equal('green');\n        }\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should not let an invalid cluster time impact other uses of the client","suites":["Sessions Spec","Sessions - functional - new format","advanceClusterTime()"],"updatePoint":{"line":350,"column":80,"index":12570},"line":350,"code":"      it('should not let an invalid cluster time impact other uses of the client', {\n        metadata: {\n          requires: {\n            mongodb: '>= 3.6.0',\n            topology: ['replicaset']\n          }\n        },\n        async test() {\n          // note, because of our validation, we can't use advanceClusterTime to set an invalid clusterTime\n          // so for testing, we have to set it directly\n          testSession.clusterTime = {\n            clusterTime: {\n              greaterThan: () => true\n            }\n          };\n          try {\n            await collection.findOne({}, {\n              session: testSession\n            });\n            expect.fail('expected findOne to fail, but it passed');\n          } catch (err) {\n            expect(err).to.be.instanceOf(MongoServerError);\n          }\n          expect(await collection.findOne({})).property('apple').to.equal('green');\n        }\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should only use two sessions for many operations when maxPoolSize is 1","suites":["Sessions Spec","Session allocation"],"updatePoint":{"line":404,"column":78,"index":14354},"line":404,"code":"    it('should only use two sessions for many operations when maxPoolSize is 1', async () => {\n      const documents = Array.from({\n        length: 50\n      }).map((_, idx) => ({\n        _id: idx\n      }));\n      const events = [];\n      client.on('commandStarted', ev => events.push(ev));\n      const allResults = await Promise.all(documents.map(doc => testCollection.insertOne(doc)));\n      expect(allResults).to.have.lengthOf(documents.length);\n      expect(events).to.have.lengthOf(documents.length);\n      expect(new Set(events.map(ev => ev.command.lsid.id.toString('hex'))).size).to.equal(2);\n    });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should not send session","suites":["Sessions Spec","session support detection","when hasSessionSupport is false"],"updatePoint":{"line":438,"column":33,"index":15704},"line":438,"code":"      it('should not send session', async () => {\n        const events = [];\n        client.on('commandStarted', event => events.push(event));\n        await collection.insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }]);\n        const cursor = collection.find({\n          a: 1\n        }, {\n          batchSize: 1,\n          projection: {\n            _id: 0\n          }\n        });\n        const docs = [await cursor.next(),\n        // find\n        await cursor.next() // getMore\n        ];\n\n        await cursor.close();\n        expect(docs).to.deep.equal([{\n          a: 1\n        }, {\n          a: 1\n        }]);\n        expect(events.map(({\n          commandName\n        }) => commandName)).to.deep.equal(['insert', 'find', 'getMore', 'killCursors']);\n        for (const event of events) {\n          expect(event.command).to.not.have.property('lsid');\n        }\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should fail for an explicit session","suites":["Sessions Spec","session support detection","when hasSessionSupport is false"],"updatePoint":{"line":472,"column":45,"index":16608},"line":472,"code":"      it('should fail for an explicit session', async () => {\n        const session = client.startSession();\n        const error = await collection.insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }], {\n          session\n        }).catch(error => error);\n        expect(error).to.be.instanceOf(MongoCompatibilityError);\n        await session.endSession();\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should send session","suites":["Sessions Spec","session support detection","when hasSessionSupport is true"],"updatePoint":{"line":487,"column":29,"index":17132},"line":487,"code":"      it('should send session', async () => {\n        const events = [];\n        client.on('commandStarted', event => events.push(event));\n        await collection.insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }]);\n        const cursor = collection.find({\n          a: 1\n        }, {\n          batchSize: 1,\n          projection: {\n            _id: 0\n          }\n        });\n        const docs = [await cursor.next(), await cursor.next()];\n        expect(docs).to.deep.equal([{\n          a: 1\n        }, {\n          a: 1\n        }]);\n        expect(events.map(({\n          commandName\n        }) => commandName)).to.deep.equal(['insert', 'find', 'getMore']);\n        for (const event of events) {\n          expect(event.command).to.have.property('lsid');\n        }\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should provide a useful error if a Promise is not returned","suites":["Transactions","withTransaction"],"updatePoint":{"line":18,"column":66,"index":677},"line":18,"code":"    it('should provide a useful error if a Promise is not returned', {\n      metadata: {\n        requires: {\n          topology: ['replicaset', 'sharded'],\n          mongodb: '>=4.1.5',\n          serverless: 'forbid'\n        }\n      },\n      test: function (done) {\n        function fnThatDoesntReturnPromise() {\n          return false;\n        }\n\n        // @ts-expect-error: Testing that a non promise returning function is handled correctly\n        expect(() => session.withTransaction(fnThatDoesntReturnPromise)).to.throw(/must return a Promise/);\n        session.endSession(done);\n      }\n    });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should return readable error if promise rejected with no reason","suites":["Transactions","withTransaction"],"updatePoint":{"line":36,"column":71,"index":1284},"line":36,"code":"    it('should return readable error if promise rejected with no reason', {\n      metadata: {\n        requires: {\n          topology: ['replicaset', 'sharded'],\n          mongodb: '>=4.2.0',\n          serverless: 'forbid'\n        }\n      },\n      test: function (done) {\n        function fnThatReturnsBadPromise() {\n          return Promise.reject();\n        }\n        session.withTransaction(fnThatReturnsBadPromise).then(() => done(Error('Expected error'))).catch(err => {\n          expect(err).to.equal(undefined);\n          session.endSession(done);\n        });\n      }\n    });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should return undefined when transaction is aborted explicitly","suites":["Transactions","withTransaction","return value semantics"],"updatePoint":{"line":71,"column":72,"index":2395},"line":71,"code":"      it('should return undefined when transaction is aborted explicitly', async () => {\n        const session = client.startSession();\n        const withTransactionResult = await session.withTransaction(async session => {\n          await collection.insertOne({\n            a: 1\n          }, {\n            session\n          });\n          await collection.findOne({\n            a: 1\n          }, {\n            session\n          });\n          await session.abortTransaction();\n        }).finally(async () => await session.endSession());\n        expect(withTransactionResult).to.be.undefined;\n      });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should return raw command when transaction is successfully committed","suites":["Transactions","withTransaction","return value semantics"],"updatePoint":{"line":88,"column":78,"index":3001},"line":88,"code":"      it('should return raw command when transaction is successfully committed', async () => {\n        const session = client.startSession();\n        const withTransactionResult = await session.withTransaction(async session => {\n          await collection.insertOne({\n            a: 1\n          }, {\n            session\n          });\n          await collection.findOne({\n            a: 1\n          }, {\n            session\n          });\n        }).finally(async () => await session.endSession());\n        expect(withTransactionResult).to.exist;\n        expect(withTransactionResult).to.be.an('object');\n        expect(withTransactionResult).to.have.property('ok', 1);\n      });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should throw when transaction is aborted due to an error","suites":["Transactions","withTransaction","return value semantics"],"updatePoint":{"line":106,"column":66,"index":3667},"line":106,"code":"      it('should throw when transaction is aborted due to an error', async () => {\n        const session = client.startSession();\n        const withTransactionResult = await session.withTransaction(async session => {\n          await collection.insertOne({\n            a: 1\n          }, {\n            session\n          });\n          await collection.findOne({\n            a: 1\n          }, {\n            session\n          });\n          throw new Error(\"I don't wanna transact anymore!\");\n        }).catch(error => error).finally(async () => await session.endSession());\n        expect(withTransactionResult).to.be.instanceOf(Error);\n        expect(withTransactionResult.message).to.equal(\"I don't wanna transact anymore!\");\n      });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should error if transactions are not supported","suites":["Transactions","startTransaction"],"updatePoint":{"line":127,"column":54,"index":4447},"line":127,"code":"    it('should error if transactions are not supported', {\n      metadata: {\n        requires: {\n          topology: ['sharded'],\n          mongodb: '4.0.x'\n        }\n      },\n      test: function (done) {\n        const configuration = this.configuration;\n        const client = configuration.newClient(configuration.url());\n        client.connect((err, client) => {\n          const session = client.startSession();\n          const db = client.db(configuration.db);\n          const coll = db.collection('transaction_error_test');\n          coll.insertOne({\n            a: 1\n          }, err => {\n            expect(err).to.not.exist;\n            expect(() => session.startTransaction()).to.throw('Transactions are not supported on sharded clusters in MongoDB < 4.2.');\n            session.endSession(() => {\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should not error if transactions are supported","suites":["Transactions","startTransaction"],"updatePoint":{"line":153,"column":54,"index":5347},"line":153,"code":"    it('should not error if transactions are supported', {\n      metadata: {\n        requires: {\n          topology: ['sharded'],\n          mongodb: '>=4.1.0'\n        }\n      },\n      test: function (done) {\n        const configuration = this.configuration;\n        const client = configuration.newClient(configuration.url());\n        client.connect(err => {\n          expect(err).to.not.exist;\n          const session = client.startSession();\n          const db = client.db(configuration.db);\n          const coll = db.collection('transaction_error_test');\n          coll.insertOne({\n            a: 1\n          }, err => {\n            expect(err).to.not.exist;\n            expect(() => session.startTransaction()).to.not.throw();\n            session.abortTransaction(() => session.endSession(() => client.close(done)));\n          });\n        });\n      }\n    });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should have a TransientTransactionError label inside of a transaction","suites":["Transactions","TransientTransactionError"],"updatePoint":{"line":180,"column":77,"index":6293},"line":180,"code":"    it('should have a TransientTransactionError label inside of a transaction', {\n      metadata: {\n        requires: {\n          topology: 'replicaset',\n          mongodb: '>=4.0.0'\n        }\n      },\n      test: function (done) {\n        const configuration = this.configuration;\n        const client = configuration.newClient({\n          w: 1\n        });\n        client.connect(err => {\n          expect(err).to.not.exist;\n          const session = client.startSession();\n          const db = client.db(configuration.db);\n          db.collection('transaction_error_test_2').drop(() => {\n            db.createCollection('transaction_error_test_2', (err, coll) => {\n              expect(err).to.not.exist;\n              session.startTransaction();\n              coll.insertOne({\n                a: 1\n              }, {\n                session\n              }, err => {\n                expect(err).to.not.exist;\n                expect(session.inTransaction()).to.be.true;\n                client.db('admin').command({\n                  configureFailPoint: 'failCommand',\n                  mode: {\n                    times: 1\n                  },\n                  data: {\n                    failCommands: ['insert'],\n                    closeConnection: true\n                  }\n                }, err => {\n                  expect(err).to.not.exist;\n                  expect(session.inTransaction()).to.be.true;\n                  coll.insertOne({\n                    b: 2\n                  }, {\n                    session\n                  }, err => {\n                    expect(err).to.exist.and.to.be.an.instanceof(MongoNetworkError);\n                    if (err instanceof MongoNetworkError) {\n                      expect(err.hasErrorLabel('TransientTransactionError')).to.be.true;\n                    }\n                    session.abortTransaction(() => session.endSession(() => client.close(done)));\n                  });\n                });\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should not have a TransientTransactionError label outside of a transaction","suites":["Transactions","TransientTransactionError"],"updatePoint":{"line":237,"column":82,"index":8325},"line":237,"code":"    it('should not have a TransientTransactionError label outside of a transaction', {\n      metadata: {\n        requires: {\n          topology: 'replicaset',\n          mongodb: '>=4.0.0'\n        }\n      },\n      test: function (done) {\n        const configuration = this.configuration;\n        const client = configuration.newClient({\n          w: 1\n        });\n        client.connect(err => {\n          expect(err).to.not.exist;\n          const db = client.db(configuration.db);\n          const coll = db.collection('transaction_error_test1');\n          client.db('admin').command({\n            configureFailPoint: 'failCommand',\n            mode: {\n              times: 2\n            },\n            data: {\n              failCommands: ['insert'],\n              closeConnection: true\n            }\n          }, err => {\n            expect(err).to.not.exist;\n            coll.insertOne({\n              a: 1\n            }, err => {\n              expect(err).to.exist.and.to.be.an.instanceOf(MongoNetworkError);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should correctly allow for w:0 overriding on the connect url","suites":["URI"],"updatePoint":{"line":11,"column":66,"index":244},"line":11,"code":"  it('should correctly allow for w:0 overriding on the connect url', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      const authInformation = process.env.AUTH === 'auth' ? 'bob:pwd123@' : '';\n      // Connect using the connection string\n      const client = this.configuration.newClient(`mongodb://${authInformation}localhost:27017/?w=0`);\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(self.configuration.db);\n        db.collection('mongoclient_test').update({\n          a: 1\n        }, {\n          $set: {\n            b: 1\n          }\n        }, {\n          upsert: true\n        }, function (err, result) {\n          expect(err).to.not.exist;\n          expect(result).to.exist;\n          expect(result).property('acknowledged').to.be.false;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/uri-options/uri.test.js","skipped":false,"dir":"test"},{"name":"should correctly connect via domain socket","suites":["URI"],"updatePoint":{"line":44,"column":48,"index":1310},"line":44,"code":"  it('should correctly connect via domain socket', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      if (process.platform === 'win32') {\n        return done();\n      }\n      const client = this.configuration.newClient('mongodb://%2Ftmp%2Fmongodb-27017.sock');\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        client.close(done);\n      });\n    }\n  });","file":"integration/uri-options/uri.test.js","skipped":false,"dir":"test"},{"name":"should correctly connect via normal url using ip","suites":["URI"],"updatePoint":{"line":63,"column":54,"index":1899},"line":63,"code":"  it('should correctly connect via normal url using ip', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      const client = this.configuration.newClient('mongodb://127.0.0.1:27017/?fsync=true');\n      client.connect((err, client) => {\n        var db = client.db(this.configuration.db);\n        expect(db.writeConcern.fsync).to.be.true;\n        client.close(done);\n      });\n    }\n  });","file":"integration/uri-options/uri.test.js","skipped":false,"dir":"test"},{"name":"should correctly connect using uri encoded username and password","suites":["URI"],"updatePoint":{"line":80,"column":70,"index":2492},"line":80,"code":"  it('should correctly connect using uri encoded username and password', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      const configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var user = 'u$ser',\n          pass = '$specialch@rs';\n        var db = client.db(self.configuration.db);\n        db.addUser(user, pass, function (err) {\n          expect(err).to.not.exist;\n          var uri = 'mongodb://' + encodeURIComponent(user) + ':' + encodeURIComponent(pass) + '@localhost:27017/integration_tests';\n          configuration.newClient(uri).connect(function (err, c) {\n            expect(err).to.not.exist;\n            c.close(() => client.close(done));\n          });\n        });\n      });\n    }\n  });","file":"integration/uri-options/uri.test.js","skipped":false,"dir":"test"},{"name":"should correctly translate uri options","suites":["URI"],"updatePoint":{"line":108,"column":44,"index":3505},"line":108,"code":"  it('should correctly translate uri options', {\n    metadata: {\n      requires: {\n        topology: 'replicaset'\n      }\n    },\n    test: function (done) {\n      const config = this.configuration;\n      const uri = `mongodb://${config.host}:${config.port}/${config.db}?replicaSet=${config.replicasetName}`;\n      const client = this.configuration.newClient(uri);\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        expect(client).to.exist;\n        expect(client.options.replicaSet).to.exist.and.equal(config.replicasetName);\n        client.close(done);\n      });\n    }\n  });","file":"integration/uri-options/uri.test.js","skipped":false,"dir":"test"},{"name":"should generate valid credentials with X509","suites":["URI"],"updatePoint":{"line":126,"column":49,"index":4116},"line":126,"code":"  it('should generate valid credentials with X509', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      function validateConnect(options) {\n        expect(options).to.have.property('credentials');\n        expect(options.credentials.mechanism).to.eql('MONGODB-X509');\n        connectStub.restore();\n        done();\n      }\n      const topologyPrototype = Topology.prototype;\n      const connectStub = sinon.stub(topologyPrototype, 'connect').callsFake(validateConnect);\n      const uri = 'mongodb://some-hostname/test?ssl=true&authMechanism=MONGODB-X509&replicaSet=rs0';\n      const client = this.configuration.newClient(uri);\n      client.connect();\n    }\n  });","file":"integration/uri-options/uri.test.js","skipped":false,"dir":"test"},{"name":"","suites":["Atlas Connectivity"],"updatePoint":{"line":34,"column":19,"index":1142},"line":34,"code":"        it(`${name}`, makeConnectionTest(connectionString));","file":"manual/atlas_connectivity.test.js","skipped":false,"dir":"test"},{"name":"should authenticate with original uri","suites":["Kerberos"],"updatePoint":{"line":50,"column":43,"index":1533},"line":50,"code":"  it('should authenticate with original uri', function (done) {\n    const client = new MongoClient(krb5Uri);\n    client.connect(function (err, client) {\n      expect(err).to.not.exist;\n      verifyKerberosAuthentication(client, done);\n    });\n  });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"validate that gssapiCanonicalizeHostName can be passed in","suites":["Kerberos"],"updatePoint":{"line":57,"column":63,"index":1802},"line":57,"code":"  it('validate that gssapiCanonicalizeHostName can be passed in', function (done) {\n    if (process.platform === 'darwin') {\n      this.test.skipReason = 'DNS does not resolve with proper CNAME record on evergreen MacOS';\n      this.skip();\n    }\n    const client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:mongodb,gssapiCanonicalizeHostName:true&maxPoolSize=1`);\n    client.connect(function (err, client) {\n      if (err) return done(err);\n      expect(dns.resolveCname).to.be.calledOnceWith(host);\n      verifyKerberosAuthentication(client, done);\n    });\n  });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"authenticates with a forward cname lookup","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is forward"],"updatePoint":{"line":77,"column":51,"index":2714},"line":77,"code":"      it('authenticates with a forward cname lookup', function (done) {\n        const client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:mongodb,CANONICALIZE_HOST_NAME:forward&maxPoolSize=1`);\n        client.connect(function (err, client) {\n          if (err) return done(err);\n          expect(dns.resolveCname).to.be.calledOnceWith(host);\n          verifyKerberosAuthentication(client, done);\n        });\n      });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"authenticates with no dns lookups","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is "],"updatePoint":{"line":88,"column":45,"index":3259},"line":88,"code":"        it('authenticates with no dns lookups', function (done) {\n          const client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:mongodb,CANONICALIZE_HOST_NAME:${option}&maxPoolSize=1`);\n          client.connect(function (err, client) {\n            if (err) return done(err);\n            expect(dns.resolveCname).to.not.be.called;\n            // 2 calls when establishing connection - expect no third call.\n            expect(dns.lookup).to.be.calledTwice;\n            verifyKerberosAuthentication(client, done);\n          });\n        });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"authenticates with a forward dns lookup and a reverse ptr lookup","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is ","when the reverse lookup succeeds"],"updatePoint":{"line":110,"column":78,"index":4312},"line":110,"code":"          it('authenticates with a forward dns lookup and a reverse ptr lookup', function (done) {\n            const client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:mongodb,CANONICALIZE_HOST_NAME:${option}&maxPoolSize=1`);\n            client.connect(function (err, client) {\n              if (err) return done(err);\n              // 2 calls to establish connection, 1 call in canonicalization.\n              expect(dns.lookup).to.be.calledThrice;\n              expect(dns.resolvePtr).to.be.calledOnce;\n              verifyKerberosAuthentication(client, done);\n            });\n          });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"authenticates with a fallback cname lookup","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is ","when the reverse lookup is empty"],"updatePoint":{"line":129,"column":56,"index":5237},"line":129,"code":"          it('authenticates with a fallback cname lookup', function (done) {\n            const client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:mongodb,CANONICALIZE_HOST_NAME:${option}&maxPoolSize=1`);\n            client.connect(function (err, client) {\n              if (err) return done(err);\n              // 2 calls to establish connection, 1 call in canonicalization.\n              expect(dns.lookup).to.be.calledThrice;\n              // This fails.\n              expect(dns.resolvePtr).to.be.calledOnce;\n              // Expect the fallback to the host name.\n              expect(dns.resolveCname).to.not.be.called;\n              verifyKerberosAuthentication(client, done);\n            });\n          });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"authenticates with a fallback cname lookup","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is ","when the reverse lookup fails"],"updatePoint":{"line":151,"column":56,"index":6320},"line":151,"code":"          it('authenticates with a fallback cname lookup', function (done) {\n            const client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:mongodb,CANONICALIZE_HOST_NAME:${option}&maxPoolSize=1`);\n            client.connect(function (err, client) {\n              if (err) return done(err);\n              // 2 calls to establish connection, 1 call in canonicalization.\n              expect(dns.lookup).to.be.calledThrice;\n              // This fails.\n              expect(dns.resolvePtr).to.be.calledOnce;\n              // Expect the fallback to be called.\n              expect(dns.resolveCname).to.be.calledOnceWith(host);\n              verifyKerberosAuthentication(client, done);\n            });\n          });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"authenticates with a fallback host name","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is ","when the cname lookup fails"],"updatePoint":{"line":173,"column":53,"index":7408},"line":173,"code":"          it('authenticates with a fallback host name', function (done) {\n            const client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:mongodb,CANONICALIZE_HOST_NAME:${option}&maxPoolSize=1`);\n            client.connect(function (err, client) {\n              if (err) return done(err);\n              // 2 calls to establish connection, 1 call in canonicalization.\n              expect(dns.lookup).to.be.calledThrice;\n              // This fails.\n              expect(dns.resolvePtr).to.be.calledOnce;\n              // Expect the fallback to be called.\n              expect(dns.resolveCname).to.be.calledOnceWith(host);\n              verifyKerberosAuthentication(client, done);\n            });\n          });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"authenticates with a fallback host name","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is ","when the cname lookup is empty"],"updatePoint":{"line":195,"column":53,"index":8479},"line":195,"code":"          it('authenticates with a fallback host name', function (done) {\n            const client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:mongodb,CANONICALIZE_HOST_NAME:${option}&maxPoolSize=1`);\n            client.connect(function (err, client) {\n              if (err) return done(err);\n              // 2 calls to establish connection, 1 call in canonicalization.\n              expect(dns.lookup).to.be.calledThrice;\n              // This fails.\n              expect(dns.resolvePtr).to.be.calledOnce;\n              // Expect the fallback to be called.\n              expect(dns.resolveCname).to.be.calledOnceWith(host);\n              verifyKerberosAuthentication(client, done);\n            });\n          });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"validate that SERVICE_REALM and CANONICALIZE_HOST_NAME can be passed in","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is ","when the cname lookup is empty"],"line":214,"code":"  it.skip('validate that SERVICE_REALM and CANONICALIZE_HOST_NAME can be passed in', function (done) {","file":"manual/kerberos.test.js","skipped":true,"dir":"test"},{"name":"fails to authenticate","suites":["Kerberos","when passing SERVICE_HOST as an auth mech option","when the SERVICE_HOST is invalid"],"updatePoint":{"line":228,"column":31,"index":10002},"line":228,"code":"      it('fails to authenticate', async function () {\n        let expectedError;\n        await client.connect().catch(e => {\n          expectedError = e;\n        });\n        if (!expectedError) {\n          expect.fail('Expected connect with invalid SERVICE_HOST to fail');\n        }\n        expect(expectedError.message).to.match(/GSS failure|UNKNOWN_SERVER/);\n      });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"authenticates","suites":["Kerberos","when passing SERVICE_HOST as an auth mech option","when the SERVICE_HOST is valid"],"updatePoint":{"line":245,"column":23,"index":10599},"line":245,"code":"      it('authenticates', function (done) {\n        client.connect(function (err, client) {\n          expect(err).to.not.exist;\n          verifyKerberosAuthentication(client, done);\n        });\n      });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"as an option handed to the MongoClient","suites":["Kerberos","should use the SERVICE_NAME property"],"updatePoint":{"line":254,"column":46,"index":10905},"line":254,"code":"    it('as an option handed to the MongoClient', function (done) {\n      const client = new MongoClient(`${krb5Uri}&maxPoolSize=1`, {\n        authMechanismProperties: {\n          SERVICE_NAME: 'alternate'\n        }\n      });\n      client.connect(function (err) {\n        expect(err).to.exist;\n        expect(err.message).to.match(/(Error from KDC: LOOKING_UP_SERVER)|(not found in Kerberos database)|(UNKNOWN_SERVER)/);\n        done();\n      });\n    });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"as part of the query string parameters","suites":["Kerberos","should use the SERVICE_NAME property"],"updatePoint":{"line":266,"column":46,"index":11359},"line":266,"code":"    it('as part of the query string parameters', function (done) {\n      const client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:alternate&maxPoolSize=1`);\n      client.connect(function (err) {\n        expect(err).to.exist;\n        expect(err.message).to.match(/(Error from KDC: LOOKING_UP_SERVER)|(not found in Kerberos database)|(UNKNOWN_SERVER)/);\n        done();\n      });\n    });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"should fail to authenticate with bad credentials","suites":["Kerberos","should use the SERVICE_NAME property"],"updatePoint":{"line":275,"column":54,"index":11782},"line":275,"code":"  it('should fail to authenticate with bad credentials', function (done) {\n    const client = new MongoClient(krb5Uri.replace(encodeURIComponent(process.env.KRB5_PRINCIPAL), 'bad%40creds.cc'));\n    client.connect(function (err) {\n      expect(err).to.exist;\n      expect(err.message).to.match(/Authentication failed/);\n      done();\n    });\n  });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"Should correctly authenticate against ldap","suites":["LDAP"],"updatePoint":{"line":13,"column":48,"index":318},"line":13,"code":"  it('Should correctly authenticate against ldap', function (done) {\n    const client = new MongoClient(process.env.MONGODB_URI);\n    client.connect(function (err, client) {\n      expect(err).to.not.exist;\n      client.db('ldap').collection('test').findOne(function (err, doc) {\n        expect(err).to.not.exist;\n        expect(doc).property('ldap').to.equal(true);\n        client.close(done);\n      });\n    });\n  });","file":"manual/ldap.test.js","skipped":false,"dir":"test"},{"name":"should support OCSP with tlsInsecure","suites":["OCSP Support"],"updatePoint":{"line":29,"column":42,"index":923},"line":29,"code":"  it('should support OCSP with tlsInsecure', function (done) {\n    // should always succeed\n    connect('tls=true&tlsInsecure=true', done);\n  });","file":"manual/ocsp_support.test.js","skipped":false,"dir":"test"},{"name":"should support OCSP with tlsAllowInvalidCertificates","suites":["OCSP Support"],"updatePoint":{"line":33,"column":58,"index":1085},"line":33,"code":"  it('should support OCSP with tlsAllowInvalidCertificates', function (done) {\n    // should always succeed\n    connect('tls=true&tlsAllowInvalidCertificates=true', done);\n  });","file":"manual/ocsp_support.test.js","skipped":false,"dir":"test"},{"name":"should support OCSP with `tls=true`","suites":["OCSP Support"],"updatePoint":{"line":37,"column":41,"index":1246},"line":37,"code":"  it('should support OCSP with `tls=true`', function (done) {\n    connect('tls=true', err => {\n      if (OCSP_TLS_SHOULD_SUCCEED) {\n        expect(err).to.not.exist;\n        return done();\n      }\n      expect(err).to.exist;\n      expect(err).to.match(/invalid status response/);\n      done();\n    });\n  });","file":"manual/ocsp_support.test.js","skipped":false,"dir":"test"},{"name":"fails to connect to a single host (connection string)","suites":["Socks5 Connectivity","with missing required Socks5 auth configuration"],"updatePoint":{"line":36,"column":63,"index":1677},"line":36,"code":"      it('fails to connect to a single host (connection string)', async function () {\n        const cs = singleConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n        cs.searchParams.set('directConnection', 'true');\n        try {\n          await testConnection(cs.toString(), {});\n        } catch (err) {\n          expect(err.name).to.equal('MongoServerSelectionError');\n          expect(err.message).to.match(/Received invalid Socks5 initial handshake/);\n          return;\n        }\n        expect.fail('missed exception');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"fails to connect to a single host (config options)","suites":["Socks5 Connectivity","with missing required Socks5 auth configuration"],"updatePoint":{"line":50,"column":60,"index":2301},"line":50,"code":"      it('fails to connect to a single host (config options)', async function () {\n        try {\n          await testConnection(singleConnectionString.toString(), {\n            proxyHost,\n            proxyPort,\n            directConnection: true\n          });\n        } catch (err) {\n          expect(err.name).to.equal('MongoServerSelectionError');\n          expect(err.message).to.match(/Received invalid Socks5 initial handshake/);\n          return;\n        }\n        expect.fail('missed exception');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"fails to connect to a replica set (connection string)","suites":["Socks5 Connectivity","with missing required Socks5 auth configuration"],"updatePoint":{"line":64,"column":63,"index":2818},"line":64,"code":"      it('fails to connect to a replica set (connection string)', async function () {\n        const cs = rsConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n        try {\n          await testConnection(cs.toString(), {});\n        } catch (err) {\n          expect(err.name).to.equal('MongoServerSelectionError');\n          expect(err.message).to.match(/Received invalid Socks5 initial handshake/);\n          return;\n        }\n        expect.fail('missed exception');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"fails to connect to a replica set (config options)","suites":["Socks5 Connectivity","with missing required Socks5 auth configuration"],"updatePoint":{"line":77,"column":60,"index":3381},"line":77,"code":"      it('fails to connect to a replica set (config options)', async function () {\n        try {\n          await testConnection(rsConnectionString.toString(), {\n            proxyHost,\n            proxyPort\n          });\n        } catch (err) {\n          expect(err.name).to.equal('MongoServerSelectionError');\n          expect(err.message).to.match(/Received invalid Socks5 initial handshake/);\n          return;\n        }\n        expect.fail('missed exception');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"fails to connect to a single host (connection string) if auth is present but wrong","suites":["Socks5 Connectivity","with missing required Socks5 auth configuration"],"updatePoint":{"line":90,"column":92,"index":3887},"line":90,"code":"      it('fails to connect to a single host (connection string) if auth is present but wrong', async function () {\n        const cs = singleConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n        cs.searchParams.set('proxyUsername', 'nonexistentuser');\n        cs.searchParams.set('proxyPassword', 'badauth');\n        cs.searchParams.set('directConnection', 'true');\n        try {\n          await testConnection(cs.toString(), {});\n        } catch (err) {\n          expect(err.name).to.equal('MongoServerSelectionError');\n          expect(err.message).to.match(/Socket closed/);\n          return;\n        }\n        expect.fail('missed exception');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a single host (connection string)","suites":["Socks5 Connectivity","with extraneous Socks5 auth configuration"],"updatePoint":{"line":113,"column":58,"index":4785},"line":113,"code":"      it('can connect to a single host (connection string)', async function () {\n        const cs = singleConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n        cs.searchParams.set('proxyUsername', 'nonexistentuser');\n        cs.searchParams.set('proxyPassword', 'badauth');\n        cs.searchParams.set('directConnection', 'true');\n        await testConnection(cs.toString(), {});\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a single host (config options)","suites":["Socks5 Connectivity","with extraneous Socks5 auth configuration"],"updatePoint":{"line":122,"column":55,"index":5266},"line":122,"code":"      it('can connect to a single host (config options)', async function () {\n        await testConnection(singleConnectionString.toString(), {\n          proxyHost,\n          proxyPort,\n          ...(proxyUsername ? {} : {\n            proxyUsername: 'nonexistentuser',\n            proxyPassword: 'badauth'\n          }),\n          directConnection: true\n        });\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a replica set (connection string)","suites":["Socks5 Connectivity","with extraneous Socks5 auth configuration"],"updatePoint":{"line":133,"column":58,"index":5644},"line":133,"code":"      it('can connect to a replica set (connection string)', async function () {\n        const cs = rsConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n        cs.searchParams.set('proxyUsername', 'nonexistentuser');\n        cs.searchParams.set('proxyPassword', 'badauth');\n        await testConnection(cs.toString(), {});\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a replica set (config options)","suites":["Socks5 Connectivity","with extraneous Socks5 auth configuration"],"updatePoint":{"line":141,"column":55,"index":6064},"line":141,"code":"      it('can connect to a replica set (config options)', async function () {\n        await testConnection(rsConnectionString.toString(), {\n          proxyHost,\n          proxyPort,\n          ...(proxyUsername ? {} : {\n            proxyUsername: 'nonexistentuser',\n            proxyPassword: 'badauth'\n          })\n        });\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a single host (connection string, with directConnection)","suites":["Socks5 Connectivity","with matching socks5 authentication"],"updatePoint":{"line":153,"column":81,"index":6494},"line":153,"code":"      it('can connect to a single host (connection string, with directConnection)', async function () {\n        const cs = singleConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n        if (proxyUsername) {\n          cs.searchParams.set('proxyUsername', proxyUsername);\n          cs.searchParams.set('proxyPassword', proxyPassword);\n        }\n        cs.searchParams.set('directConnection', 'true');\n        expect(await testConnection(cs.toString(), {})).to.equal('Single');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a single host (config options, with directConnection)","suites":["Socks5 Connectivity","with matching socks5 authentication"],"updatePoint":{"line":164,"column":78,"index":7068},"line":164,"code":"      it('can connect to a single host (config options, with directConnection)', async function () {\n        expect(await testConnection(singleConnectionString.toString(), {\n          proxyHost,\n          proxyPort,\n          ...(proxyUsername ? {\n            proxyUsername,\n            proxyPassword\n          } : {}),\n          directConnection: true\n        })).to.equal('Single');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a single host (connection string, without directConnection)","suites":["Socks5 Connectivity","with matching socks5 authentication"],"updatePoint":{"line":175,"column":84,"index":7469},"line":175,"code":"      it('can connect to a single host (connection string, without directConnection)', async function () {\n        const cs = singleConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n        if (proxyUsername) {\n          cs.searchParams.set('proxyUsername', proxyUsername);\n          cs.searchParams.set('proxyPassword', proxyPassword);\n        }\n        cs.searchParams.set('directConnection', 'false');\n        expect(await testConnection(cs.toString(), {})).to.equal('ReplicaSetWithPrimary');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a single host (config options, without directConnection)","suites":["Socks5 Connectivity","with matching socks5 authentication"],"updatePoint":{"line":186,"column":81,"index":8062},"line":186,"code":"      it('can connect to a single host (config options, without directConnection)', async function () {\n        expect(await testConnection(singleConnectionString.toString(), {\n          proxyHost,\n          proxyPort,\n          ...(proxyUsername ? {\n            proxyUsername,\n            proxyPassword\n          } : {}),\n          directConnection: false\n        })).to.equal('ReplicaSetWithPrimary');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a replica set (connection string)","suites":["Socks5 Connectivity","with matching socks5 authentication"],"updatePoint":{"line":197,"column":58,"index":8453},"line":197,"code":"      it('can connect to a replica set (connection string)', async function () {\n        const cs = rsConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n        if (proxyUsername) {\n          cs.searchParams.set('proxyUsername', proxyUsername);\n          cs.searchParams.set('proxyPassword', proxyPassword);\n        }\n        expect(await testConnection(cs.toString(), {})).to.equal('ReplicaSetWithPrimary');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a replica set (config options)","suites":["Socks5 Connectivity","with matching socks5 authentication"],"updatePoint":{"line":207,"column":55,"index":8958},"line":207,"code":"      it('can connect to a replica set (config options)', async function () {\n        expect(await testConnection(rsConnectionString.toString(), {\n          proxyHost,\n          proxyPort,\n          ...(proxyUsername ? {\n            proxyUsername,\n            proxyPassword\n          } : {})\n        })).to.equal('ReplicaSetWithPrimary');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"does not mention the proxy in command monitoring events","suites":["Socks5 Connectivity","with matching socks5 authentication"],"updatePoint":{"line":217,"column":65,"index":9317},"line":217,"code":"      it('does not mention the proxy in command monitoring events', async function () {\n        const client = new MongoClient(singleConnectionString.toString(), {\n          proxyHost,\n          proxyPort,\n          ...(proxyUsername ? {\n            proxyUsername,\n            proxyPassword\n          } : {}),\n          directConnection: true,\n          monitorCommands: true\n        });\n        const seenCommandAddresses = new Set();\n        client.on('commandSucceeded', ev => seenCommandAddresses.add(ev.address));\n        await client.connect();\n        await client.db('admin').command({\n          [LEGACY_HELLO_COMMAND]: 1\n        });\n        await client.close();\n        expect([...seenCommandAddresses]).to.deep.equal(singleConnectionString.hosts);\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"rejects invalid MongoClient options ","suites":["Socks5 Connectivity","MongoClient option validation"],"updatePoint":{"line":257,"column":77,"index":10520},"line":257,"code":"      it(`rejects invalid MongoClient options ${JSON.stringify(proxyOptions)}`, () => {\n        expect(() => new MongoClient('mongodb://localhost', proxyOptions)).to.throw(MongoParseError);\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"should connect with tls via client options","suites":["TLS Support"],"updatePoint":{"line":24,"column":48,"index":695},"line":24,"code":"  it('should connect with tls via client options', makeConnectionTest(connectionString, tlsSettings));","file":"manual/tls_support.test.js","skipped":false,"dir":"test"},{"name":"should connect with tls via url options","suites":["TLS Support"],"updatePoint":{"line":25,"column":45,"index":795},"line":25,"code":"  it('should connect with tls via url options', makeConnectionTest(`${connectionString}?${Object.keys(tlsSettings).map(key => `${key}=${tlsSettings[key]}`).join('&')}`));","file":"manual/tls_support.test.js","skipped":false,"dir":"test"},{"name":"","suites":["Auth option spec tests"],"updatePoint":{"line":8,"column":31,"index":348},"line":8,"code":"        it(`${test.description}`, function () {\n          executeUriValidationTest(test);\n        });","file":"unit/assorted/auth.spec.test.ts","skipped":false,"dir":"test"},{"name":"should propagate errors","suites":["Bulk Writes"],"updatePoint":{"line":27,"column":29,"index":621},"line":27,"code":"  it('should propagate errors', function (done) {\n    const client = new MongoClient(`mongodb://${test.server.uri()}/test`);\n    let close = e => {\n      close = () => {};\n      client.close(() => done(e));\n    };\n    let hasErrored = false;\n    test.server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(Object.assign({}, mock.HELLO));\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      } else if (doc.insert) {\n        if (hasErrored) {\n          return request.reply({\n            ok: 1\n          });\n        }\n        hasErrored = true;\n        return request.reply({\n          ok: 0\n        });\n      } else {\n        close(`Received unknown command ${doc}`);\n      }\n    });\n    client.connect(function (err) {\n      expect(err).to.not.exist;\n      const coll = client.db('foo').collection('bar');\n      coll.insert(documents, {\n        ordered: false\n      }, function (err) {\n        try {\n          expect(err).to.be.an.instanceOf(Error);\n          close();\n        } catch (e) {\n          close(e);\n        }\n      });\n    });\n  });","file":"unit/assorted/bulk_write.test.js","skipped":false,"dir":"test"},{"name":"should let wrapping libraries amend the client metadata","suites":["Client (unit)"],"updatePoint":{"line":22,"column":61,"index":514},"line":22,"code":"  it('should let wrapping libraries amend the client metadata', function () {\n    let handshake;\n    server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        handshake = doc;\n        request.reply(Object.assign({}, mock.HELLO));\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    client = new MongoClient(`mongodb://${server.uri()}/`, {\n      driverInfo: {\n        name: 'mongoose',\n        version: '5.7.10',\n        platform: 'llama edition'\n      }\n    });\n    return client.connect().then(() => {\n      expect(handshake).to.have.nested.property('client.driver');\n      expect(handshake).nested.property('client.driver.name').to.equal('nodejs|mongoose');\n      expect(handshake).nested.property('client.driver.version').to.match(/|5.7.10/);\n      expect(handshake).nested.property('client.platform').to.match(/llama edition/);\n    });\n  });","file":"unit/assorted/client.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to count command","suites":["Collation"],"updatePoint":{"line":23,"column":58,"index":530},"line":23,"code":"  it('Successfully pass through collation to count command', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.count) {\n        commandResult = doc;\n        request.reply({\n          ok: 1,\n          result: {\n            n: 1\n          }\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_test');\n      return db.collection('test').estimatedDocumentCount({\n        collation: {\n          caseLevel: true\n        }\n      }).then(() => {\n        expect(commandResult).to.have.property('collation');\n        expect(commandResult.collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to aggregation command","suites":["Collation"],"updatePoint":{"line":60,"column":64,"index":1608},"line":60,"code":"  it('Successfully pass through collation to aggregation command', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.aggregate) {\n        commandResult = doc;\n        request.reply({\n          ok: 1,\n          cursor: {\n            id: 0,\n            firstBatch: [],\n            ns: 'collation_test'\n          }\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_test');\n      return db.collection('test').aggregate([{\n        $match: {}\n      }, {\n        $out: 'readConcernCollectionAggregate1Output'\n      }], {\n        collation: {\n          caseLevel: true\n        }\n      }).toArray().then(() => {\n        expect(commandResult).to.have.property('collation');\n        expect(commandResult.collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to distinct command","suites":["Collation"],"updatePoint":{"line":103,"column":61,"index":2844},"line":103,"code":"  it('Successfully pass through collation to distinct command', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      var doc = request.document;\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.distinct) {\n        commandResult = doc;\n        request.reply({\n          ok: 1\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').distinct('a', {}, {\n        collation: {\n          caseLevel: true\n        }\n      }).then(() => {\n        expect(commandResult).to.have.property('collation');\n        expect(commandResult.collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to mapReduce command","suites":["Collation"],"updatePoint":{"line":137,"column":62,"index":3864},"line":137,"code":"  it('Successfully pass through collation to mapReduce command', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      var doc = request.document;\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.mapReduce) {\n        commandResult = doc;\n        request.reply({\n          ok: 1,\n          result: 'tempCollection'\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      const map = new Code('function() { emit(this.user_id, 1); }');\n      const reduce = new Code('function(k,vals) { return 1; }');\n      return db.collection('test').mapReduce(map, reduce, {\n        out: {\n          replace: 'tempCollection'\n        },\n        collation: {\n          caseLevel: true\n        }\n      }).then(() => {\n        expect(commandResult).to.have.property('collation');\n        expect(commandResult.collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to remove command","suites":["Collation"],"updatePoint":{"line":177,"column":59,"index":5119},"line":177,"code":"  it('Successfully pass through collation to remove command', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      var doc = request.document;\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.delete) {\n        commandResult = doc;\n        request.reply({\n          ok: 1\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').deleteMany({}, {\n        collation: {\n          caseLevel: true\n        }\n      }).then(() => {\n        expect(commandResult.deletes).to.have.length.at.least(1);\n        expect(commandResult.deletes[0]).to.have.property('collation');\n        expect(commandResult.deletes[0].collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to update command","suites":["Collation"],"updatePoint":{"line":212,"column":59,"index":6219},"line":212,"code":"  it('Successfully pass through collation to update command', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.update) {\n        commandResult = doc;\n        request.reply({\n          ok: 1\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').updateOne({\n        a: 1\n      }, {\n        $set: {\n          b: 1\n        }\n      }, {\n        collation: {\n          caseLevel: true\n        }\n      }).then(() => {\n        expect(commandResult.updates).to.have.length.at.least(1);\n        expect(commandResult.updates[0]).to.have.property('collation');\n        expect(commandResult.updates[0].collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to find command via options","suites":["Collation"],"updatePoint":{"line":253,"column":69,"index":7402},"line":253,"code":"  it('Successfully pass through collation to find command via options', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.find) {\n        commandResult = doc;\n        request.reply({\n          ok: 1,\n          cursor: {\n            id: 0,\n            firstBatch: []\n          }\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').find({\n        a: 1\n      }, {\n        collation: {\n          caseLevel: true\n        }\n      }).toArray().then(() => {\n        expect(commandResult).to.have.property('collation');\n        expect(commandResult.collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to find command via cursor","suites":["Collation"],"updatePoint":{"line":293,"column":68,"index":8526},"line":293,"code":"  it('Successfully pass through collation to find command via cursor', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.find) {\n        commandResult = doc;\n        request.reply({\n          ok: 1,\n          cursor: {\n            id: 0,\n            firstBatch: []\n          }\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').find({\n        a: 1\n      }).collation({\n        caseLevel: true\n      }).toArray().then(() => {\n        expect(commandResult).to.have.property('collation');\n        expect(commandResult.collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to findOne","suites":["Collation"],"updatePoint":{"line":331,"column":52,"index":9611},"line":331,"code":"  it('Successfully pass through collation to findOne', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.find) {\n        commandResult = doc;\n        request.reply({\n          ok: 1,\n          cursor: {\n            id: 0,\n            firstBatch: []\n          }\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').findOne({\n        a: 1\n      }, {\n        collation: {\n          caseLevel: true\n        }\n      }).then(() => {\n        expect(commandResult).to.have.property('collation');\n        expect(commandResult.collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to createCollection","suites":["Collation"],"updatePoint":{"line":371,"column":61,"index":10721},"line":371,"code":"  it('Successfully pass through collation to createCollection', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.listCollections) {\n        request.reply({\n          ok: 1,\n          cursor: {\n            id: Long.fromNumber(0),\n            ns: 'test.cmd$.listCollections',\n            firstBatch: []\n          }\n        });\n      } else if (doc.create) {\n        commandResult = doc;\n        request.reply({\n          ok: 1\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.createCollection('test', {\n        collation: {\n          caseLevel: true\n        }\n      }).then(() => {\n        expect(commandResult).to.have.property('collation');\n        expect(commandResult.collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to bulkWrite command","suites":["Collation"],"updatePoint":{"line":414,"column":62,"index":11962},"line":414,"code":"  it('Successfully pass through collation to bulkWrite command', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.update) {\n        commandResult = doc;\n        request.reply({\n          ok: 1\n        });\n      } else if (doc.delete) {\n        request.reply({\n          ok: 1\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').bulkWrite([{\n        updateOne: {\n          filter: {\n            a: 2\n          },\n          update: {\n            $set: {\n              a: 2\n            }\n          },\n          upsert: true,\n          collation: {\n            caseLevel: true\n          }\n        }\n      }, {\n        deleteOne: {\n          filter: {\n            c: 1\n          }\n        }\n      }], {\n        ordered: true\n      }).then(() => {\n        expect(commandResult).to.exist;\n        expect(commandResult).to.have.property('updates');\n        expect(commandResult.updates).to.have.length.at.least(1);\n        expect(commandResult.updates[0]).to.have.property('collation');\n        expect(commandResult.updates[0].collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully create index with collation","suites":["Collation"],"updatePoint":{"line":474,"column":46,"index":13551},"line":474,"code":"  it('Successfully create index with collation', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.createIndexes) {\n        commandResult = doc;\n        request.reply({\n          ok: 1\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').createIndex({\n        a: 1\n      }, {\n        collation: {\n          caseLevel: true\n        }\n      }).then(() => {\n        expect(commandResult).to.containSubset({\n          createIndexes: 'test',\n          indexes: [{\n            name: 'a_1',\n            key: {\n              a: 1\n            },\n            collation: {\n              caseLevel: true\n            }\n          }]\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"multiple functions with the same deprecated options should both warn","suites":["Deprecation Warnings","Deprecation Warnings - unit","Mult functions with same options"],"updatePoint":{"line":57,"column":78,"index":1572},"line":57,"code":"      it('multiple functions with the same deprecated options should both warn', done => {\n        process.nextTick(() => {\n          expect(messages).to.deep.equal(['f1 option [maxScan]' + defaultMessage, 'f2 option [maxScan]' + defaultMessage]);\n          expect(messages).to.have.a.lengthOf(2);\n          done();\n        });\n      });","file":"unit/assorted/deprecate_warning.test.js","skipped":false,"dir":"test"},{"name":"should not warn if empty options object passed in","suites":["Deprecation Warnings","Deprecation Warnings - unit","Empty options object"],"updatePoint":{"line":74,"column":59,"index":2150},"line":74,"code":"      it('should not warn if empty options object passed in', done => {\n        process.nextTick(() => {\n          expect(messages).to.have.a.lengthOf(0);\n          done();\n        });\n      });","file":"unit/assorted/deprecate_warning.test.js","skipped":false,"dir":"test"},{"name":"should use user-specified message handler","suites":["Deprecation Warnings","Deprecation Warnings - unit","Custom Message Handler"],"updatePoint":{"line":98,"column":51,"index":2860},"line":98,"code":"      it('should use user-specified message handler', done => {\n        process.nextTick(() => {\n          expect(messages).to.deep.equal(['custom msg for function f and option maxScan', 'custom msg for function f and option snapshot', 'custom msg for function f and option fields']);\n          expect(messages).to.have.a.lengthOf(3);\n          done();\n        });\n      });","file":"unit/assorted/deprecate_warning.test.js","skipped":false,"dir":"test"},{"name":"each function should only warn once per deprecated option","suites":["Deprecation Warnings","Deprecation Warnings - unit","Warn once"],"updatePoint":{"line":122,"column":67,"index":3622},"line":122,"code":"      it('each function should only warn once per deprecated option', done => {\n        process.nextTick(() => {\n          expect(messages).to.deep.equal(['f option [maxScan]' + defaultMessage, 'f option [fields]' + defaultMessage]);\n          expect(messages).to.have.a.lengthOf(2);\n          done();\n        });\n      });","file":"unit/assorted/deprecate_warning.test.js","skipped":false,"dir":"test"},{"name":"wrapped functions should maintain original functionality","suites":["Deprecation Warnings","Deprecation Warnings - unit","Maintain functionality"],"updatePoint":{"line":155,"column":66,"index":4647},"line":155,"code":"      it('wrapped functions should maintain original functionality', done => {\n        process.nextTick(() => {\n          expect(messages).to.deep.equal(['f option [multiply]' + defaultMessage, 'f option [add]' + defaultMessage]);\n          expect(messages).to.have.a.lengthOf(2);\n          done();\n        });\n      });","file":"unit/assorted/deprecate_warning.test.js","skipped":false,"dir":"test"},{"name":"optionsIndex pointing to undefined should not error","suites":["Deprecation Warnings","Deprecation Warnings - unit","Maintain functionality"],"updatePoint":{"line":163,"column":59,"index":4969},"line":163,"code":"    it('optionsIndex pointing to undefined should not error', () => {\n      const f = makeTestFunction({\n        name: 'f',\n        deprecatedOptions: deprecatedOptions,\n        optionsIndex: 0\n      });\n      expect(f).to.not.throw();\n    });","file":"unit/assorted/deprecate_warning.test.js","skipped":false,"dir":"test"},{"name":"optionsIndex not pointing to object should not error","suites":["Deprecation Warnings","Deprecation Warnings - unit","Maintain functionality"],"updatePoint":{"line":171,"column":60,"index":5214},"line":171,"code":"    it('optionsIndex not pointing to object should not error', () => {\n      const f = makeTestFunction({\n        name: 'f',\n        deprecatedOptions: deprecatedOptions,\n        optionsIndex: 0\n      });\n      expect(() => f('not-an-object')).to.not.throw();\n    });","file":"unit/assorted/deprecate_warning.test.js","skipped":false,"dir":"test"},{"name":"test behavior for classes with an associated logger","suites":["Deprecation Warnings","Deprecation Warnings - functional"],"updatePoint":{"line":184,"column":59,"index":5627},"line":184,"code":"    it('test behavior for classes with an associated logger', function () {\n      const fakeClass = new ClassWithLogger();\n      const logger = fakeClass.getLogger();\n      const stub = sinon.stub(logger, 'warn');\n      fakeClass.f({\n        maxScan: 5,\n        snapshot: true\n      });\n      fakeClass.f({\n        maxScan: 5,\n        snapshot: true\n      });\n      expect(stub).to.have.been.calledTwice;\n      ensureCalledWith(stub, ['f option [maxScan] is deprecated and will be removed in a later version.', 'f option [snapshot] is deprecated and will be removed in a later version.']);\n    });","file":"unit/assorted/deprecate_warning.test.js","skipped":false,"dir":"test"},{"name":"test behavior for classes without an associated logger","suites":["Deprecation Warnings","Deprecation Warnings - functional"],"updatePoint":{"line":199,"column":62,"index":6228},"line":199,"code":"    it('test behavior for classes without an associated logger', function () {\n      const fakeClass = new ClassWithoutLogger();\n      function func() {\n        fakeClass.f({\n          maxScan: 5,\n          snapshot: true\n        });\n      }\n      expect(func).to.not.throw();\n    });","file":"unit/assorted/deprecate_warning.test.js","skipped":false,"dir":"test"},{"name":"test behavior for classes with an undefined logger","suites":["Deprecation Warnings","Deprecation Warnings - functional"],"updatePoint":{"line":209,"column":58,"index":6509},"line":209,"code":"    it('test behavior for classes with an undefined logger', function () {\n      const fakeClass = new ClassWithUndefinedLogger();\n      function func() {\n        fakeClass.f({\n          maxScan: 5,\n          snapshot: true\n        });\n      }\n      expect(func).to.not.throw();\n    });","file":"unit/assorted/deprecate_warning.test.js","skipped":false,"dir":"test"},{"name":"should import  directly without issue","suites":["importing mongodb driver"],"updatePoint":{"line":23,"column":75,"index":772},"line":23,"code":"    it(`should import ${sourceFile.slice(sliceFrom)} directly without issue`, () => {\n      execSync(`./node_modules/.bin/ts-node -e \"require('${sourceFile}')\"`);\n    });","file":"unit/assorted/imports.test.ts","skipped":false,"dir":"test"},{"name":"should error if not installed","suites":["optionalRequire","Snappy"],"updatePoint":{"line":32,"column":37,"index":714},"line":32,"code":"    it('should error if not installed', function () {\n      const moduleName = 'snappy';\n      if (moduleExistsSync(moduleName)) {\n        return this.skip();\n      }\n      compress({\n        options: {\n          agreedCompressor: 'snappy'\n        }\n      }, Buffer.alloc(1), error => {\n        expect(error).to.exist;\n        expect(error.message).includes('not found');\n      });\n    });","file":"unit/assorted/optional_require.test.js","skipped":false,"dir":"test"},{"name":"should error if not installed","suites":["optionalRequire","Kerberos"],"updatePoint":{"line":48,"column":37,"index":1146},"line":48,"code":"    it('should error if not installed', function () {\n      const moduleName = 'kerberos';\n      if (moduleExistsSync(moduleName)) {\n        return this.skip();\n      }\n      const gssapi = new GSSAPI();\n      gssapi.auth(new AuthContext(null, true, {\n        hostAddress: new HostAddress('a'),\n        credentials: true\n      }), error => {\n        expect(error).to.exist;\n        expect(error.message).includes('not found');\n      });\n    });","file":"unit/assorted/optional_require.test.js","skipped":false,"dir":"test"},{"name":"should error if not installed","suites":["optionalRequire","aws4"],"updatePoint":{"line":64,"column":37,"index":1629},"line":64,"code":"    it('should error if not installed', function () {\n      const moduleName = 'aws4';\n      if (moduleExistsSync(moduleName)) {\n        return this.skip();\n      }\n      const mdbAWS = new MongoDBAWS();\n      mdbAWS.auth(new AuthContext({\n        hello: {\n          maxWireVersion: 9\n        }\n      }, true, null), error => {\n        expect(error).to.exist;\n        expect(error.message).includes('not found');\n      });\n    });","file":"unit/assorted/optional_require.test.js","skipped":false,"dir":"test"},{"name":"should error if iteration count is less than 4096","suites":["SCRAM Iterations Tests"],"updatePoint":{"line":18,"column":55,"index":679},"line":18,"code":"  it('should error if iteration count is less than 4096', async function () {\n    const scramResponse = 'r=IE+xNFeOcslsupAA+zkDVzHd5HfwoRuP7Wi8S4py+erf8PcNm7XIdXQyT52Nj3+M,s=AzomrlMs99A7oFxDLpgFvVb+CSvdyXuNagoWVw==,i=4000';\n    const credentials = new MongoCredentials({\n      mechanism: 'DEFAULT',\n      source: 'db',\n      username: 'user',\n      password: 'pencil',\n      mechanismProperties: {}\n    });\n    client.s.options.credentials = credentials;\n    server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        return request.reply(Object.assign({}, mock.HELLO));\n      } else if (doc.saslStart) {\n        return request.reply({\n          ok: 1,\n          done: false,\n          payload: Buffer.from(scramResponse)\n        });\n      } else if (doc.saslContinue) {\n        throw new Error('should not be here');\n      }\n    });\n    const thrownError = await client.connect().catch(error => error);\n    expect(thrownError).to.be.instanceOf(MongoRuntimeError);\n    expect(thrownError).to.have.property('message').that.matches(/Server returned an invalid iteration count/);\n  });","file":"unit/assorted/scram_iterations.test.ts","skipped":false,"dir":"test"},{"name":"should error if server digest is invalid","suites":["SCRAM Iterations Tests"],"updatePoint":{"line":46,"column":46,"index":1802},"line":46,"code":"  it('should error if server digest is invalid', async function () {\n    const credentials = new MongoCredentials({\n      mechanism: 'DEFAULT',\n      source: 'db',\n      username: 'user',\n      password: 'pencil',\n      mechanismProperties: {}\n    });\n    client.s.options.credentials = credentials;\n    server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        return request.reply(Object.assign({}, mock.HELLO));\n      } else if (doc.saslStart) {\n        return request.reply({\n          ok: 1,\n          done: false,\n          payload: Buffer.from('r=VNnXkRqKflB5+rmfnFiisCWzgDLzez02iRpbvE5mQjMvizb+VkSPRZZ/pDmFzLxq,s=dZTyOb+KZqoeTFdsULiqow==,i=10000')\n        });\n      } else if (doc.saslContinue) {\n        return request.reply({\n          ok: 1,\n          done: false,\n          payload: Buffer.from('v=bWFsaWNpb3VzbWFsaWNpb3VzVzV')\n        });\n      }\n    });\n    const thrownError = await client.connect().catch(error => error);\n    expect(thrownError).to.be.instanceOf(MongoRuntimeError);\n    expect(thrownError).to.have.property('message').that.matches(/Server returned an invalid signature/);\n  });","file":"unit/assorted/scram_iterations.test.ts","skipped":false,"dir":"test"},{"name":"should properly handle network errors on `saslContinue`","suites":["SCRAM Iterations Tests"],"updatePoint":{"line":77,"column":61,"index":2978},"line":77,"code":"  it('should properly handle network errors on `saslContinue`', async function () {\n    const credentials = new MongoCredentials({\n      mechanism: 'DEFAULT',\n      source: 'db',\n      username: 'user',\n      password: 'pencil',\n      mechanismProperties: {}\n    });\n    client.s.options.credentials = credentials;\n    server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        return request.reply(Object.assign({}, mock.HELLO));\n      } else if (doc.saslStart) {\n        return request.reply({\n          ok: 1,\n          done: false,\n          payload: Buffer.from('r=VNnXkRqKflB5+rmfnFiisCWzgDLzez02iRpbvE5mQjMvizb+VkSPRZZ/pDmFzLxq,s=dZTyOb+KZqoeTFdsULiqow==,i=10000')\n        });\n      } else if (doc.saslContinue) {\n        request.connection.destroy();\n      }\n    });\n    const thrownError = await client.connect().catch(error => error);\n    expect(thrownError).to.be.instanceOf(MongoNetworkError);\n    expect(thrownError).to.have.property('message').that.matches(/connection(.+)closed/);\n  });","file":"unit/assorted/scram_iterations.test.ts","skipped":false,"dir":"test"},{"name":"should not throw a synchronous exception if sessions are not supported","suites":["Sessions - client/unit","Client"],"updatePoint":{"line":23,"column":78,"index":612},"line":23,"code":"    it('should not throw a synchronous exception if sessions are not supported', function () {\n      test.server.setMessageHandler(request => {\n        var doc = request.document;\n        if (isHello(doc)) {\n          request.reply(Object.assign({}, mock.HELLO));\n        } else if (doc.endSessions) {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      const client = new MongoClient(`mongodb://${test.server.uri()}/test`);\n      return client.connect().then(() => {\n        expect(() => client.startSession()).to.not.throw('Current topology does not support sessions');\n        return client.close();\n      });\n    });","file":"unit/assorted/sessions_client.test.js","skipped":false,"dir":"test"},{"name":"should throw an exception if sessions are not supported on some servers","suites":["Sessions - client/unit","Client"],"updatePoint":{"line":40,"column":79,"index":1266},"line":40,"code":"    it('should throw an exception if sessions are not supported on some servers', function () {\n      const replicaSetMock = new ReplSetFixture();\n      let testClient;\n      return replicaSetMock.setup({\n        doNotInitHandlers: true\n      }).then(() => {\n        replicaSetMock.firstSecondaryServer.setMessageHandler(request => {\n          var doc = request.document;\n          if (isHello(doc)) {\n            const hello = replicaSetMock.firstSecondaryStates[0];\n            hello.logicalSessionTimeoutMinutes = 20;\n            request.reply(hello);\n          } else if (doc.endSessions) {\n            request.reply({\n              ok: 1\n            });\n          }\n        });\n        replicaSetMock.secondSecondaryServer.setMessageHandler(request => {\n          var doc = request.document;\n          if (isHello(doc)) {\n            const hello = replicaSetMock.secondSecondaryStates[0];\n            hello.logicalSessionTimeoutMinutes = 10;\n            request.reply(hello);\n          } else if (doc.endSessions) {\n            request.reply({\n              ok: 1\n            });\n          }\n        });\n        replicaSetMock.arbiterServer.setMessageHandler(request => {\n          var doc = request.document;\n          if (isHello(doc)) {\n            const hello = replicaSetMock.arbiterStates[0];\n            hello.logicalSessionTimeoutMinutes = 30;\n            request.reply(hello);\n          } else if (doc.endSessions) {\n            request.reply({\n              ok: 1\n            });\n          }\n        });\n        replicaSetMock.primaryServer.setMessageHandler(request => {\n          var doc = request.document;\n          if (isHello(doc)) {\n            const hello = replicaSetMock.primaryStates[0];\n            hello.logicalSessionTimeoutMinutes = null;\n            request.reply(hello);\n          } else if (doc.endSessions) {\n            request.reply({\n              ok: 1\n            });\n          }\n        });\n        return replicaSetMock.uri();\n      }).then(uri => {\n        testClient = new MongoClient(uri);\n        return testClient.connect();\n      }).then(client => {\n        const session = client.startSession();\n        return client.db().collection('t').insertOne({\n          a: 1\n        }, {\n          session\n        });\n      }).then(() => {\n        expect.fail('Expected an error to be thrown about not supporting sessions');\n      }).catch(error => {\n        expect(error.message).to.equal('Current topology does not support sessions');\n      }).finally(() => testClient ? testClient.close() : null);\n    });","file":"unit/assorted/sessions_client.test.js","skipped":false,"dir":"test"},{"name":"should return a client session when requested if the topology supports it","suites":["Sessions - client/unit","Client"],"updatePoint":{"line":111,"column":81,"index":3816},"line":111,"code":"    it('should return a client session when requested if the topology supports it', function (done) {\n      test.server.setMessageHandler(request => {\n        var doc = request.document;\n        if (isHello(doc)) {\n          request.reply(Object.assign({}, mock.HELLO, {\n            logicalSessionTimeoutMinutes: 10\n          }));\n        } else if (doc.endSessions) {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      const client = new MongoClient(`mongodb://${test.server.uri()}/test`);\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        let session = client.startSession();\n        expect(session).to.exist;\n        session.endSession({\n          skipCommand: true\n        });\n        client.close(done);\n      });\n    });","file":"unit/assorted/sessions_client.test.js","skipped":false,"dir":"test"},{"name":"should include `afterClusterTime` in read command with causal consistency","suites":["Sessions - unit/sessions","Collection"],"updatePoint":{"line":25,"column":81,"index":601},"line":25,"code":"    it('should include `afterClusterTime` in read command with causal consistency', function () {\n      let findCommand;\n      let insertOperationTime = Timestamp.fromNumber(Date.now());\n      test.server.setMessageHandler(request => {\n        const doc = request.document;\n        if (isHello(doc)) {\n          request.reply(Object.assign({\n            logicalSessionTimeoutMinutes: 15\n          }, mock.HELLO));\n        } else if (doc.insert) {\n          request.reply({\n            ok: 1,\n            operationTime: insertOperationTime\n          });\n        } else if (doc.find) {\n          findCommand = doc;\n          request.reply({\n            ok: 1,\n            cursor: {\n              id: 0,\n              firstBatch: []\n            }\n          });\n        } else if (doc.endSessions) {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      const client = new MongoClient(`mongodb://${test.server.uri()}/test`);\n      return client.connect().then(client => {\n        const session = client.startSession({\n          causalConsistency: true\n        });\n        const coll = client.db('foo').collection('bar');\n        return coll.insert({\n          a: 42\n        }, {\n          session: session\n        }).then(() => coll.findOne({}, {\n          session: session,\n          readConcern: {\n            level: 'majority'\n          }\n        })).then(() => {\n          expect(findCommand.readConcern).to.have.keys(['level', 'afterClusterTime']);\n          expect(findCommand.readConcern.afterClusterTime).to.eql(insertOperationTime);\n          session.endSession({\n            skipCommand: true\n          });\n          return client.close();\n        });\n      });\n    });","file":"unit/assorted/sessions_collection.test.js","skipped":false,"dir":"test"},{"name":"does not mutate command options","suites":["Sessions - unit/sessions","Collection"],"updatePoint":{"line":79,"column":39,"index":2265},"line":79,"code":"    it('does not mutate command options', function () {\n      const options = Object.freeze({});\n      test.server.setMessageHandler(request => {\n        const doc = request.document;\n        if (isHello(doc)) {\n          request.reply(mock.HELLO);\n        } else if (doc.count || doc.aggregate || doc.endSessions) {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      const client = new MongoClient(`mongodb://${test.server.uri()}/test`);\n      return client.connect().then(client => {\n        const coll = client.db('foo').collection('bar');\n        return coll.countDocuments({}, options).then(() => {\n          expect(options).to.deep.equal({});\n          return client.close();\n        });\n      });\n    });","file":"unit/assorted/sessions_collection.test.js","skipped":false,"dir":"test"},{"name":"should compress messages sent with snappy ","suites":["Compression","Snappy"],"updatePoint":{"line":38,"column":66,"index":943},"line":38,"code":"    it(`should compress messages sent with snappy ${snappyVersion}`, async function () {\n      // the timeout is being set because the test should not take any longer than 5 seconds,\n      // and that if it doesn't complete, it will hang due to the callback never being called\n      this.timeout(5000);\n      server.setMessageHandler(request => {\n        const doc = request.document;\n        if (isHello(doc)) {\n          return request.reply({\n            ...mock.HELLO,\n            compression: ['snappy']\n          });\n        }\n        if (doc.insert === 'snappy') {\n          return request.reply({\n            ok: 1\n          });\n        }\n      });\n      // The mock server uses snappy to decode messages so\n      // if this passes we implicitly test snappy is working\n      // TODO(NODE-3560): Add more comprehensive round trip testing\n      await client.connect();\n      await client.db().collection('snappy').insertOne({\n        a: 1\n      });\n    });","file":"unit/assorted/snappy.test.js","skipped":false,"dir":"test"},{"name":"should define a version number on the optional import","suites":["Compression","Snappy"],"updatePoint":{"line":64,"column":61,"index":1901},"line":64,"code":"    it('should define a version number on the optional import', function () {\n      const {\n        Snappy,\n        PKG_VERSION\n      } = require('../../../src/deps');\n      const [major, minor, patch] = snappyVersion.split('.').map(n => +n);\n      expect(Snappy).to.have.property(PKG_VERSION).that.is.an('object');\n      expect(Snappy[PKG_VERSION]).to.have.property('major', major);\n      expect(Snappy[PKG_VERSION]).to.have.property('minor', minor);\n      expect(Snappy[PKG_VERSION]).to.have.property('patch', patch);\n    });","file":"unit/assorted/snappy.test.js","skipped":false,"dir":"test"},{"name":"","suites":["URI option spec tests"],"updatePoint":{"line":31,"column":31,"index":1595},"line":31,"code":"        it(`${test.description}`, function () {\n          if (skipTests.includes(test.description)) {\n            return this.skip();\n          }\n          executeUriValidationTest(test, testsThatDoNotThrowOnWarn.some(t => t === test.description));\n        });","file":"unit/assorted/uri_options.spec.test.ts","skipped":false,"dir":"test"},{"name":"should raise a compatibility error","suites":["Wire Protocol Version","minimum is greater than max supported"],"updatePoint":{"line":40,"column":42,"index":1179},"line":40,"code":"    it('should raise a compatibility error', async function () {\n      setWireProtocolMessageHandler(Number.MAX_SAFE_INTEGER - 1, Number.MAX_SAFE_INTEGER);\n\n      /** @type {MongoClient} */\n      client = new MongoClient(`mongodb://${server.uri()}/wireVersionTest?serverSelectionTimeoutMS=200`);\n      try {\n        await client.connect();\n        expect.fail('should fail to select server!');\n      } catch (error) {\n        expect(error).to.be.instanceOf(MongoServerSelectionError);\n        expect(error).to.have.property('message').that.includes(minCompatErrMsg);\n      }\n    });","file":"unit/assorted/wire_version.test.js","skipped":false,"dir":"test"},{"name":"should raise a compatibility error","suites":["Wire Protocol Version","maximum is less than min supported"],"updatePoint":{"line":55,"column":42,"index":1825},"line":55,"code":"    it('should raise a compatibility error', async function () {\n      setWireProtocolMessageHandler(1, 1);\n\n      /** @type {MongoClient} */\n      client = new MongoClient(`mongodb://${server.uri()}/wireVersionTest?serverSelectionTimeoutMS=200`);\n      try {\n        await client.connect();\n        expect.fail('should fail to select server!');\n      } catch (error) {\n        expect(error).to.be.instanceOf(MongoServerSelectionError);\n        expect(error).to.have.property('message').that.includes(maxCompatErrMsg);\n      }\n    });","file":"unit/assorted/wire_version.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to aggregate command","suites":["Command Write Concern"],"updatePoint":{"line":134,"column":65,"index":3787},"line":134,"code":"  it('successfully pass through writeConcern to aggregate command', () => writeConcernTest('aggregate', (db, writeConcernTestOptions) => db.collection('test').aggregate([{\n    $match: {}\n  }, {\n    $out: 'readConcernCollectionAggregate1Output'\n  }], writeConcernTestOptions).toArray()));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to create command","suites":["Command Write Concern"],"updatePoint":{"line":139,"column":62,"index":4072},"line":139,"code":"  it('successfully pass through writeConcern to create command', () => writeConcernTest('create', (db, writeConcernTestOptions) => db.createCollection('test_collection_methods', writeConcernTestOptions)));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to createIndexes command","suites":["Command Write Concern"],"updatePoint":{"line":140,"column":69,"index":4285},"line":140,"code":"  it('successfully pass through writeConcern to createIndexes command', () => writeConcernTest('createIndexes', (db, writeConcernTestOptions) => db.collection('indexOptionDefault').createIndex({\n    a: 1\n  }, Object.assign({\n    indexOptionDefaults: true\n  }, writeConcernTestOptions))));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to drop command","suites":["Command Write Concern"],"updatePoint":{"line":145,"column":60,"index":4565},"line":145,"code":"  it('successfully pass through writeConcern to drop command', () => writeConcernTest('drop', (db, writeConcernTestOptions) => db.collection('indexOptionDefault').drop(writeConcernTestOptions)));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to dropDatabase command","suites":["Command Write Concern"],"updatePoint":{"line":146,"column":68,"index":4769},"line":146,"code":"  it('successfully pass through writeConcern to dropDatabase command', () => writeConcernTest('dropDatabase', (db, writeConcernTestOptions) => db.dropDatabase(writeConcernTestOptions)));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to dropIndexes command","suites":["Command Write Concern"],"updatePoint":{"line":147,"column":67,"index":4955},"line":147,"code":"  it('successfully pass through writeConcern to dropIndexes command', () => writeConcernTest('dropIndexes', (db, writeConcernTestOptions) => db.collection('test').dropIndexes(writeConcernTestOptions)));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to mapReduce command","suites":["Command Write Concern"],"updatePoint":{"line":148,"column":65,"index":5156},"line":148,"code":"  it('successfully pass through writeConcern to mapReduce command', () => writeConcernTest('mapReduce', function (db, writeConcernTestOptions) {\n    const map = new Code('function() { emit(this.user_id, 1); }');\n    const reduce = new Code('function(k,vals) { return 1; }');\n    return db.collection('test').mapReduce(map, reduce, Object.assign({\n      out: {\n        replace: 'tempCollection'\n      }\n    }, writeConcernTestOptions));\n  }));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to createUser command","suites":["Command Write Concern"],"updatePoint":{"line":157,"column":66,"index":5600},"line":157,"code":"  it('successfully pass through writeConcern to createUser command', () => writeConcernTest('createUser', (db, writeConcernTestOptions) => db.admin().addUser('kay:kay', 'abc123', writeConcernTestOptions)));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to dropUser command","suites":["Command Write Concern"],"updatePoint":{"line":158,"column":64,"index":5805},"line":158,"code":"  it('successfully pass through writeConcern to dropUser command', () => writeConcernTest('dropUser', (db, writeConcernTestOptions) => db.admin().removeUser('kay:kay', writeConcernTestOptions)));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"should correctly round trip ","suites":["When importing BSON"],"updatePoint":{"line":22,"column":45,"index":742},"line":22,"code":"      it(`should correctly round trip ${type}`, function () {\n        const typeCtor = BSON[type];\n        expect(typeCtor).to.be.a('function');\n        const doc = {\n          key: new typeCtor(ctorArg)\n        };\n        const outputDoc = BSON.deserialize(BSON.serialize(doc), options);\n        expect(outputDoc).to.have.property('key').that.is.instanceOf(typeCtor);\n        expect(outputDoc).to.deep.equal(doc);\n      });","file":"unit/bson.test.js","skipped":false,"dir":"test"},{"name":"should correctly round trip Map","suites":["When importing BSON"],"updatePoint":{"line":33,"column":39,"index":1167},"line":33,"code":"    it('should correctly round trip Map', function () {\n      expect(BSON.Map).to.be.a('function');\n      const doc = {\n        key: new BSON.Map([['2', 2]])\n      };\n      const outputDoc = BSON.deserialize(BSON.serialize(doc));\n      expect(outputDoc).to.have.nested.property('key.2', 2);\n    });","file":"unit/bson.test.js","skipped":false,"dir":"test"},{"name":"should be imported if it exists","suites":["When importing BSON","bson-ext"],"updatePoint":{"line":48,"column":39,"index":1603},"line":48,"code":"    it('should be imported if it exists', function () {\n      expect(BSON.deserialize.toString()).to.include('[native code]');\n      expect(BSON.serialize.toString()).to.include('[native code]');\n      expect(BSON.calculateObjectSize.toString()).to.include('[native code]');\n    });","file":"unit/bson.test.js","skipped":false,"dir":"test"},{"name":"should be imported by default","suites":["When importing BSON","js-bson"],"updatePoint":{"line":61,"column":37,"index":2038},"line":61,"code":"    it('should be imported by default', function () {\n      expect(BSON.deserialize.toString()).to.not.include('[native code]');\n      expect(BSON.serialize.toString()).to.not.include('[native code]');\n      expect(BSON.calculateObjectSize.toString()).to.not.include('[native code]');\n    });","file":"unit/bson.test.js","skipped":false,"dir":"test"},{"name":"should include ObjectId","suites":["MongoDB export"],"updatePoint":{"line":71,"column":29,"index":2425},"line":71,"code":"  it('should include ObjectId', () => expect(mongodb).to.have.property('ObjectId').that.is.a('function'));","file":"unit/bson.test.js","skipped":false,"dir":"test"},{"name":"should include ObjectID","suites":["MongoDB export"],"updatePoint":{"line":72,"column":29,"index":2532},"line":72,"code":"  it('should include ObjectID', () => expect(mongodb).to.have.property('ObjectID').that.is.a('function'));","file":"unit/bson.test.js","skipped":false,"dir":"test"},{"name":"should have ObjectID and ObjectId equal each other","suites":["MongoDB export"],"updatePoint":{"line":73,"column":56,"index":2666},"line":73,"code":"  it('should have ObjectID and ObjectId equal each other', () => expect(mongodb.ObjectId).to.equal(mongodb.ObjectID));","file":"unit/bson.test.js","skipped":false,"dir":"test"},{"name":"replaces the opTime with the properly formatted object","suites":["bulk/common","#mergeBatchResults","when lastOp is an object","when the opTime is a Timestamp"],"updatePoint":{"line":58,"column":66,"index":1516},"line":58,"code":"        it('replaces the opTime with the properly formatted object', function () {\n          mergeBatchResults(batch, bulkResult, null, result);\n          expect(bulkResult.opTime).to.deep.equal({\n            ts: opTime,\n            t: Long.ZERO\n          });\n        });","file":"unit/bulk/common.test.js","skipped":false,"dir":"test"},{"name":"replaces the opTime with the new opTime","suites":["bulk/common","#mergeBatchResults","when lastOp is an object","when the opTime is an object","when the ts is greater"],"updatePoint":{"line":80,"column":53,"index":2216},"line":80,"code":"          it('replaces the opTime with the new opTime', function () {\n            mergeBatchResults(batch, bulkResult, null, result);\n            expect(bulkResult.opTime).to.deep.equal(opTime);\n          });","file":"unit/bulk/common.test.js","skipped":false,"dir":"test"},{"name":"replaces the opTime with the new opTime","suites":["bulk/common","#mergeBatchResults","when lastOp is an object","when the opTime is an object","when the ts is equal","when the t is greater"],"updatePoint":{"line":99,"column":55,"index":2889},"line":99,"code":"            it('replaces the opTime with the new opTime', function () {\n              mergeBatchResults(batch, bulkResult, null, result);\n              expect(bulkResult.opTime).to.deep.equal(opTime);\n            });","file":"unit/bulk/common.test.js","skipped":false,"dir":"test"},{"name":"does not replace the opTime with the new opTime","suites":["bulk/common","#mergeBatchResults","when lastOp is an object","when the opTime is an object","when the ts is equal","when the t is equal"],"updatePoint":{"line":117,"column":63,"index":3522},"line":117,"code":"            it('does not replace the opTime with the new opTime', function () {\n              mergeBatchResults(batch, bulkResult, null, result);\n              expect(bulkResult.opTime).to.deep.equal(lastOp);\n            });","file":"unit/bulk/common.test.js","skipped":false,"dir":"test"},{"name":"does not replace the opTime with the new opTime","suites":["bulk/common","#mergeBatchResults","when lastOp is an object","when the opTime is an object","when the ts is equal","when the t is less"],"updatePoint":{"line":135,"column":63,"index":4153},"line":135,"code":"            it('does not replace the opTime with the new opTime', function () {\n              mergeBatchResults(batch, bulkResult, null, result);\n              expect(bulkResult.opTime).to.deep.equal(lastOp);\n            });","file":"unit/bulk/common.test.js","skipped":false,"dir":"test"},{"name":"does not replace the opTime with the new opTime","suites":["bulk/common","#mergeBatchResults","when lastOp is an object","when the opTime is an object","when the ts is less"],"updatePoint":{"line":154,"column":61,"index":4770},"line":154,"code":"          it('does not replace the opTime with the new opTime', function () {\n            mergeBatchResults(batch, bulkResult, null, result);\n            expect(bulkResult.opTime).to.deep.equal(lastOp);\n          });","file":"unit/bulk/common.test.js","skipped":false,"dir":"test"},{"name":"copies all non-resume related options from the original cursor","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken"],"updatePoint":{"line":13,"column":72,"index":568},"line":13,"code":"      it('copies all non-resume related options from the original cursor', function () {\n        const cursor = new ChangeStreamCursor(new MongoClient('mongodb://localhost:27027'), new MongoDBNamespace('db', 'collection'), [], {\n          promoteBuffers: true,\n          promoteLongs: false,\n          maxAwaitTimeMS: 5000\n        });\n        cursor.resumeToken = 'resume token';\n        const options = cursor.resumeOptions;\n        expect(options).to.haveOwnProperty('promoteBuffers', true);\n        expect(options).to.haveOwnProperty('promoteLongs', false);\n        expect(options).to.haveOwnProperty('maxAwaitTimeMS', 5000);\n      });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"sets the startAfter option to the cached resumeToken","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was started with startAfter","when the cursor has not yet returned a document"],"updatePoint":{"line":37,"column":66,"index":1746},"line":37,"code":"          it('sets the startAfter option to the cached resumeToken', function () {\n            expect(cursor.resumeOptions).to.haveOwnProperty('startAfter', 'resume token');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the resumeAfter option","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was started with startAfter","when the cursor has not yet returned a document"],"updatePoint":{"line":40,"column":49,"index":1917},"line":40,"code":"          it('does NOT set the resumeAfter option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('resumeAfter');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAtOperationTime option","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was started with startAfter","when the cursor has not yet returned a document","when the startAtOperationTime option is NOT set"],"updatePoint":{"line":44,"column":60,"index":2171},"line":44,"code":"            it('does NOT set the startAtOperationTime option', function () {\n              expect(cursor.resumeOptions).not.to.haveOwnProperty('startAtOperationTime');\n            });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAtOperationTime option","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was started with startAfter","when the cursor has not yet returned a document","when the startAtOperationTime option is set"],"updatePoint":{"line":49,"column":60,"index":2448},"line":49,"code":"            it('does NOT set the startAtOperationTime option', function () {\n              cursor.startAtOperationTime = new Timestamp(Long.ZERO);\n              expect(cursor.resumeOptions).not.to.haveOwnProperty('startAtOperationTime');\n            });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAfter option","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was started with startAfter","when the cursor has returned a document"],"updatePoint":{"line":59,"column":48,"index":2877},"line":59,"code":"          it('does NOT set the startAfter option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('startAfter');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"sets the resumeAFter option to the cached resumeToken","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was started with startAfter","when the cursor has returned a document"],"updatePoint":{"line":62,"column":67,"index":3054},"line":62,"code":"          it('sets the resumeAFter option to the cached resumeToken', function () {\n            expect(cursor.resumeOptions).to.haveOwnProperty('resumeAfter', 'resume token');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAtOperationTime option","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was started with startAfter","when the cursor has returned a document","when the startAtOperationTime option is NOT set"],"updatePoint":{"line":66,"column":60,"index":3320},"line":66,"code":"            it('does NOT set the startAtOperationTime option', function () {\n              expect(cursor.resumeOptions).not.to.haveOwnProperty('startAtOperationTime');\n            });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAtOperationTime option","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was started with startAfter","when the cursor has returned a document","when the startAtOperationTime option is set"],"updatePoint":{"line":71,"column":60,"index":3597},"line":71,"code":"            it('does NOT set the startAtOperationTime option', function () {\n              cursor.startAtOperationTime = new Timestamp(Long.ZERO);\n              expect(cursor.resumeOptions).not.to.haveOwnProperty('startAtOperationTime');\n            });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"sets the resumeAfter option to the cached resumeToken","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was not initialized with startAfter set"],"updatePoint":{"line":84,"column":65,"index":4230},"line":84,"code":"        it('sets the resumeAfter option to the cached resumeToken', function () {\n          expect(cursor.resumeOptions).to.haveOwnProperty('resumeAfter', 'resume token');\n        });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAfter option","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was not initialized with startAfter set"],"updatePoint":{"line":87,"column":46,"index":4395},"line":87,"code":"        it('does NOT set the startAfter option', function () {\n          expect(cursor.resumeOptions).not.to.haveOwnProperty('startAfter');\n        });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAtOperationTime option","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was not initialized with startAfter set","when the startAtOperationTime option is NOT set"],"updatePoint":{"line":91,"column":58,"index":4640},"line":91,"code":"          it('does NOT set the startAtOperationTime option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('startAtOperationTime');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAtOperationTime option","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was not initialized with startAfter set","when the startAtOperationTime option is set"],"updatePoint":{"line":96,"column":58,"index":4907},"line":96,"code":"          it('does NOT set the startAtOperationTime option', function () {\n            cursor.startAtOperationTime = new Timestamp(Long.ZERO);\n            cursor.resumeToken = 'resume token';\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('startAtOperationTime');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"copies all non-resume related options from the original cursor","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor has a saved operation time"],"updatePoint":{"line":106,"column":74,"index":5387},"line":106,"code":"        it('copies all non-resume related options from the original cursor', function () {\n          const cursor = new ChangeStreamCursor(new MongoClient('mongodb://localhost:27027'), new MongoDBNamespace('db', 'collection'), [], {\n            startAfter: 'start after',\n            resumeAfter: 'resume after',\n            startAtOperationTime: new Timestamp(Long.ZERO),\n            promoteBuffers: true,\n            promoteLongs: false,\n            maxAwaitTimeMS: 5000\n          });\n          cursor.resumeToken = null;\n          const options = cursor.resumeOptions;\n          expect(options).to.haveOwnProperty('promoteBuffers', true);\n          expect(options).to.haveOwnProperty('promoteLongs', false);\n          expect(options).to.haveOwnProperty('maxAwaitTimeMS', 5000);\n        });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the resumeAfter option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor has a saved operation time","when the maxWireVersion >= 7"],"updatePoint":{"line":136,"column":49,"index":6770},"line":136,"code":"          it('does NOT set the resumeAfter option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('resumeAfter');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAfter option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor has a saved operation time","when the maxWireVersion >= 7"],"updatePoint":{"line":139,"column":48,"index":6929},"line":139,"code":"          it('does NOT set the startAfter option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('startAfter');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does set the startAtOperationTime option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor has a saved operation time","when the maxWireVersion >= 7"],"updatePoint":{"line":142,"column":54,"index":7093},"line":142,"code":"          it('does set the startAtOperationTime option', function () {\n            expect(cursor.resumeOptions).to.haveOwnProperty('startAtOperationTime');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the resumeAfter option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor has a saved operation time","when the maxWireVersion < 7"],"updatePoint":{"line":161,"column":49,"index":7884},"line":161,"code":"          it('does NOT set the resumeAfter option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('resumeAfter');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAfter option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor has a saved operation time","when the maxWireVersion < 7"],"updatePoint":{"line":164,"column":48,"index":8043},"line":164,"code":"          it('does NOT set the startAfter option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('startAfter');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAtOperationTime option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor has a saved operation time","when the maxWireVersion < 7"],"updatePoint":{"line":167,"column":58,"index":8211},"line":167,"code":"          it('does NOT set the startAtOperationTime option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('startAtOperationTime');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"copies all non-resume related options from the original cursor","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor does NOT have a saved operation time"],"updatePoint":{"line":173,"column":74,"index":8511},"line":173,"code":"        it('copies all non-resume related options from the original cursor', function () {\n          const cursor = new ChangeStreamCursor(new MongoClient('mongodb://localhost:27027'), new MongoDBNamespace('db', 'collection'), [], {\n            startAfter: 'start after',\n            resumeAfter: 'resume after',\n            promoteBuffers: true,\n            promoteLongs: false,\n            maxAwaitTimeMS: 5000\n          });\n          cursor.resumeToken = null;\n          const options = cursor.resumeOptions;\n          expect(options).to.haveOwnProperty('promoteBuffers', true);\n          expect(options).to.haveOwnProperty('promoteLongs', false);\n          expect(options).to.haveOwnProperty('maxAwaitTimeMS', 5000);\n        });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the resumeAfter option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor does NOT have a saved operation time","when the maxWireVersion >= 7"],"updatePoint":{"line":201,"column":49,"index":9772},"line":201,"code":"          it('does NOT set the resumeAfter option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('resumeAfter');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAfter option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor does NOT have a saved operation time","when the maxWireVersion >= 7"],"updatePoint":{"line":204,"column":48,"index":9931},"line":204,"code":"          it('does NOT set the startAfter option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('startAfter');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAtOperationTime option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor does NOT have a saved operation time","when the maxWireVersion >= 7"],"updatePoint":{"line":207,"column":58,"index":10099},"line":207,"code":"          it('does NOT set the startAtOperationTime option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('startAtOperationTime');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the resumeAfter option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor does NOT have a saved operation time","when the maxWireVersion < 7"],"updatePoint":{"line":226,"column":49,"index":10894},"line":226,"code":"          it('does NOT set the resumeAfter option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('resumeAfter');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAfter option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor does NOT have a saved operation time","when the maxWireVersion < 7"],"updatePoint":{"line":229,"column":48,"index":11053},"line":229,"code":"          it('does NOT set the startAfter option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('startAfter');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAtOperationTime option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor does NOT have a saved operation time","when the maxWireVersion < 7"],"updatePoint":{"line":232,"column":58,"index":11221},"line":232,"code":"          it('does NOT set the startAtOperationTime option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('startAtOperationTime');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"performs no dns lookups","suites":["GSSAPI",".performGSSAPICanonicalizeHostName","when the mode is "],"updatePoint":{"line":24,"column":35,"index":759},"line":24,"code":"        it('performs no dns lookups', done => {\n          performGSSAPICanonicalizeHostName(hostName, {\n            CANONICALIZE_HOST_NAME: mode\n          }, (error, host) => {\n            if (error) return done(error);\n            expect(host).to.equal(hostName);\n            expect(dns.lookup).to.not.be.called;\n            expect(dns.resolvePtr).to.not.be.called;\n            expect(dns.resolveCname).to.not.be.called;\n            done();\n          });\n        });","file":"unit/cmap/auth/gssapi.test.js","skipped":false,"dir":"test"},{"name":"performs a cname lookup","suites":["GSSAPI",".performGSSAPICanonicalizeHostName","when the mode is forward"],"updatePoint":{"line":47,"column":33,"index":1557},"line":47,"code":"      it('performs a cname lookup', done => {\n        performGSSAPICanonicalizeHostName(hostName, {\n          CANONICALIZE_HOST_NAME: GSSAPICanonicalizationValue.forward\n        }, (error, host) => {\n          if (error) return done(error);\n          expect(host).to.equal(resolved);\n          expect(dns.lookup).to.not.be.called;\n          expect(dns.resolvePtr).to.not.be.called;\n          expect(dns.resolveCname).to.be.calledOnceWith(hostName);\n          done();\n        });\n      });","file":"unit/cmap/auth/gssapi.test.js","skipped":false,"dir":"test"},{"name":"uses the reverse lookup host","suites":["GSSAPI",".performGSSAPICanonicalizeHostName","when the mode is ","when the forward lookup succeeds","when the reverse lookup succeeds","when there is 1 result"],"updatePoint":{"line":79,"column":46,"index":2975},"line":79,"code":"              it('uses the reverse lookup host', done => {\n                performGSSAPICanonicalizeHostName(hostName, {\n                  CANONICALIZE_HOST_NAME: mode\n                }, (error, host) => {\n                  if (error) return done(error);\n                  expect(host).to.equal(resolved);\n                  expect(dns.lookup).to.be.calledOnceWith(hostName);\n                  expect(dns.resolvePtr).to.be.calledOnceWith(lookedUp);\n                  expect(dns.resolveCname).to.not.be.called;\n                  done();\n                });\n              });","file":"unit/cmap/auth/gssapi.test.js","skipped":false,"dir":"test"},{"name":"uses the first found reverse lookup host","suites":["GSSAPI",".performGSSAPICanonicalizeHostName","when the mode is ","when the forward lookup succeeds","when the reverse lookup succeeds","when there is more than 1 result"],"updatePoint":{"line":103,"column":58,"index":4086},"line":103,"code":"              it('uses the first found reverse lookup host', done => {\n                performGSSAPICanonicalizeHostName(hostName, {\n                  CANONICALIZE_HOST_NAME: mode\n                }, (error, host) => {\n                  if (error) return done(error);\n                  expect(host).to.equal(resolved);\n                  expect(dns.lookup).to.be.calledOnceWith(hostName);\n                  expect(dns.resolvePtr).to.be.calledOnceWith(lookedUp);\n                  expect(dns.resolveCname).to.not.be.called;\n                  done();\n                });\n              });","file":"unit/cmap/auth/gssapi.test.js","skipped":false,"dir":"test"},{"name":"falls back to a cname lookup","suites":["GSSAPI",".performGSSAPICanonicalizeHostName","when the mode is ","when the forward lookup succeeds","when the reverse lookup fails"],"updatePoint":{"line":133,"column":44,"index":5384},"line":133,"code":"            it('falls back to a cname lookup', done => {\n              performGSSAPICanonicalizeHostName(hostName, {\n                CANONICALIZE_HOST_NAME: mode\n              }, (error, host) => {\n                if (error) return done(error);\n                expect(host).to.equal(cname);\n                expect(dns.lookup).to.be.calledOnceWith(hostName);\n                expect(dns.resolvePtr).to.be.calledOnceWith(lookedUp);\n                expect(dns.resolveCname).to.be.calledWith(hostName);\n                done();\n              });\n            });","file":"unit/cmap/auth/gssapi.test.js","skipped":false,"dir":"test"},{"name":"uses the provided host","suites":["GSSAPI",".performGSSAPICanonicalizeHostName","when the mode is ","when the forward lookup succeeds","when the reverse lookup is empty"],"updatePoint":{"line":156,"column":38,"index":6372},"line":156,"code":"            it('uses the provided host', done => {\n              performGSSAPICanonicalizeHostName(hostName, {\n                CANONICALIZE_HOST_NAME: mode\n              }, (error, host) => {\n                if (error) return done(error);\n                expect(host).to.equal(hostName);\n                expect(dns.lookup).to.be.calledOnceWith(hostName);\n                expect(dns.resolvePtr).to.be.calledOnceWith(lookedUp);\n                expect(dns.resolveCname).to.not.be.called;\n                done();\n              });\n            });","file":"unit/cmap/auth/gssapi.test.js","skipped":false,"dir":"test"},{"name":"fails with the error","suites":["GSSAPI",".performGSSAPICanonicalizeHostName","when the mode is ","when the forward lookup fails"],"updatePoint":{"line":178,"column":34,"index":7250},"line":178,"code":"          it('fails with the error', done => {\n            performGSSAPICanonicalizeHostName(hostName, {\n              CANONICALIZE_HOST_NAME: mode\n            }, error => {\n              expect(error.message).to.equal('failed');\n              expect(dns.lookup).to.be.calledOnceWith(hostName);\n              expect(dns.resolvePtr).to.not.be.called;\n              expect(dns.resolveCname).to.not.be.called;\n              done();\n            });\n          });","file":"unit/cmap/auth/gssapi.test.js","skipped":false,"dir":"test"},{"name":"falls back to the provided host name","suites":["GSSAPI",".resolveCname","when the cname call errors"],"updatePoint":{"line":203,"column":46,"index":8110},"line":203,"code":"      it('falls back to the provided host name', done => {\n        resolveCname(hostName, (error, host) => {\n          if (error) return done(error);\n          expect(host).to.equal(hostName);\n          expect(dns.resolveCname).to.be.calledOnceWith(hostName);\n          done();\n        });\n      });","file":"unit/cmap/auth/gssapi.test.js","skipped":false,"dir":"test"},{"name":"uses the result","suites":["GSSAPI",".resolveCname","when the cname call returns results","when there is one result"],"updatePoint":{"line":223,"column":27,"index":8832},"line":223,"code":"        it('uses the result', done => {\n          resolveCname(hostName, (error, host) => {\n            if (error) return done(error);\n            expect(host).to.equal(resolved);\n            expect(dns.resolveCname).to.be.calledOnceWith(hostName);\n            done();\n          });\n        });","file":"unit/cmap/auth/gssapi.test.js","skipped":false,"dir":"test"},{"name":"uses the first result","suites":["GSSAPI",".resolveCname","when the cname call returns results","when there is more than one result"],"updatePoint":{"line":242,"column":33,"index":9537},"line":242,"code":"        it('uses the first result', done => {\n          resolveCname(hostName, (error, host) => {\n            if (error) return done(error);\n            expect(host).to.equal(resolved);\n            expect(dns.resolveCname).to.be.calledOnceWith(hostName);\n            done();\n          });\n        });","file":"unit/cmap/auth/gssapi.test.js","skipped":false,"dir":"test"},{"name":"falls back to using the provided host","suites":["GSSAPI",".resolveCname","when the cname call returns no results"],"updatePoint":{"line":261,"column":47,"index":10195},"line":261,"code":"      it('falls back to using the provided host', done => {\n        resolveCname(hostName, (error, host) => {\n          if (error) return done(error);\n          expect(host).to.equal(hostName);\n          expect(dns.resolveCname).to.be.calledOnceWith(hostName);\n          done();\n        });\n      });","file":"unit/cmap/auth/gssapi.test.js","skipped":false,"dir":"test"},{"name":"should make a deep copy of object of type: ","suites":["Command Monitoring Events - unit/cmap"],"updatePoint":{"line":56,"column":78,"index":945},"line":56,"code":"    it(`should make a deep copy of object of type: ${command.constructor.name}`, () => {\n      const ev = new CommandStartedEvent({\n        id: 'someId',\n        address: 'someHost'\n      }, command);\n      if (command instanceof Query) {\n        if (command.ns === 'admin.$cmd') {\n          expect(ev.command !== command.query.$query).to.equal(true);\n          for (const k in command.query.$query) {\n            expect(ev.command[k]).to.deep.equal(command.query.$query[k]);\n          }\n        } else {\n          expect(ev.command.filter !== command.query.$query).to.equal(true);\n          for (const k in command.query.$query) {\n            expect(ev.command.filter[k]).to.deep.equal(command.query.$query[k]);\n          }\n        }\n      } else if (command instanceof Msg) {\n        expect(ev.command !== command.command).to.equal(true);\n        expect(ev.command).to.deep.equal(command.command);\n      } else if (typeof command === 'object') {\n        if (command.ns === 'admin.$cmd') {\n          expect(ev.command !== command.query.$query).to.equal(true);\n          for (const k in command.query.$query) {\n            expect(ev.command[k]).to.deep.equal(command.query.$query[k]);\n          }\n        }\n      }\n    });","file":"unit/cmap/command_monitoring_events.test.js","skipped":false,"dir":"test"},{"name":"should wrap a basic query option","suites":["Command Monitoring Events - unit/cmap","CommandStartedEvent"],"updatePoint":{"line":91,"column":40,"index":2263},"line":91,"code":"    it('should wrap a basic query option', function () {\n      const db = 'test1';\n      const coll = 'testingQuery';\n      const query = new Query(`${db}.${coll}`, {\n        testCmd: 1,\n        fizz: 'buzz',\n        star: 'trek'\n      }, {});\n      const startEvent = new CommandStartedEvent(conn, query);\n      expect(startEvent).to.have.property('commandName', 'testCmd');\n      expect(startEvent).to.have.property('databaseName', db);\n      expect(startEvent).to.have.property('requestId', query.requestId);\n      expect(startEvent).to.have.property('connectionId').that.is.a('string');\n      expect(startEvent).to.have.property('command').that.deep.equals(query.query);\n    });","file":"unit/cmap/command_monitoring_events.test.js","skipped":false,"dir":"test"},{"name":"should upconvert a Query wrapping a command into the corresponding command","suites":["Command Monitoring Events - unit/cmap","CommandStartedEvent"],"updatePoint":{"line":106,"column":82,"index":2988},"line":106,"code":"    it('should upconvert a Query wrapping a command into the corresponding command', function () {\n      const db = 'admin';\n      const coll = '$cmd';\n      const query = new Query(`${db}.${coll}`, {\n        $query: {\n          testCmd: 1,\n          fizz: 'buzz',\n          star: 'trek',\n          batchSize: 0,\n          skip: 0\n        }\n      }, {});\n      const startEvent = new CommandStartedEvent(conn, query);\n      expect(startEvent).to.have.property('commandName', 'testCmd');\n      expect(startEvent).to.have.property('databaseName', db);\n      expect(startEvent).to.have.property('requestId', query.requestId);\n      expect(startEvent).to.have.property('connectionId').that.is.a('string');\n      expect(startEvent).to.have.property('command').that.deep.equals(query.query.$query);\n    });","file":"unit/cmap/command_monitoring_events.test.js","skipped":false,"dir":"test"},{"name":"should upconvert a Query wrapping a query into a find command","suites":["Command Monitoring Events - unit/cmap","CommandStartedEvent"],"updatePoint":{"line":125,"column":69,"index":3776},"line":125,"code":"    it('should upconvert a Query wrapping a query into a find command', function () {\n      const db = 'test5';\n      const coll = 'testingFindCommand';\n      const query = new Query(`${db}.${coll}`, {\n        $query: {\n          testCmd: 1,\n          fizz: 'buzz',\n          star: 'trek'\n        }\n      }, {});\n      const startEvent = new CommandStartedEvent(conn, query);\n      expect(startEvent).to.have.property('commandName', 'find');\n      expect(startEvent).to.have.property('databaseName', db);\n      expect(startEvent).to.have.property('requestId', query.requestId);\n      expect(startEvent).to.have.property('connectionId').that.is.a('string');\n      expect(startEvent).to.have.property('command').that.deep.equals({\n        find: coll,\n        filter: query.query.$query,\n        batchSize: 0,\n        skip: 0\n      });\n    });","file":"unit/cmap/command_monitoring_events.test.js","skipped":false,"dir":"test"},{"name":"throws an exception","suites":["commands","Response","#parse","when the message body is invalid","when the buffer is empty"],"updatePoint":{"line":20,"column":33,"index":586},"line":20,"code":"          it('throws an exception', function () {\n            const response = new Response(message, header, body);\n            expect(() => response.parse()).to.throw(RangeError, /outside buffer bounds/);\n          });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"throws an exception","suites":["commands","Response","#parse","when the message body is invalid","when numReturned is invalid"],"updatePoint":{"line":35,"column":33,"index":1141},"line":35,"code":"          it('throws an exception', function () {\n            const response = new Response(message, header, body);\n            expect(() => response.parse()).to.throw(RangeError, /Invalid array length/);\n          });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not throw an exception","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":52,"column":39,"index":1708},"line":52,"code":"        it('does not throw an exception', function () {\n          let error;\n          try {\n            new Response(message, header, body);\n          } catch (err) {\n            error = err;\n          }\n          expect(error).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"initializes the documents to an empty array","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":61,"column":55,"index":1982},"line":61,"code":"        it('initializes the documents to an empty array', function () {\n          const response = new Response(message, header, body);\n          expect(response.documents).to.be.empty;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set the responseFlags","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":65,"column":42,"index":2167},"line":65,"code":"        it('does not set the responseFlags', function () {\n          const response = new Response(message, header, body);\n          expect(response.responseFlags).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set the cursorNotFound flag","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":69,"column":48,"index":2366},"line":69,"code":"        it('does not set the cursorNotFound flag', function () {\n          const response = new Response(message, header, body);\n          expect(response.cursorNotFound).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set the cursorId","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":73,"column":37,"index":2555},"line":73,"code":"        it('does not set the cursorId', function () {\n          const response = new Response(message, header, body);\n          expect(response.cursorId).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set startingFrom","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":77,"column":37,"index":2738},"line":77,"code":"        it('does not set startingFrom', function () {\n          const response = new Response(message, header, body);\n          expect(response.startingFrom).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set numberReturned","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":81,"column":39,"index":2927},"line":81,"code":"        it('does not set numberReturned', function () {\n          const response = new Response(message, header, body);\n          expect(response.numberReturned).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set queryFailure","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":85,"column":37,"index":3116},"line":85,"code":"        it('does not set queryFailure', function () {\n          const response = new Response(message, header, body);\n          expect(response.queryFailure).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set shardConfigStale","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":89,"column":41,"index":3307},"line":89,"code":"        it('does not set shardConfigStale', function () {\n          const response = new Response(message, header, body);\n          expect(response.shardConfigStale).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set awaitCapable","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":93,"column":37,"index":3498},"line":93,"code":"        it('does not set awaitCapable', function () {\n          const response = new Response(message, header, body);\n          expect(response.awaitCapable).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"should auth against a non-arbiter","suites":["Connect Tests"],"updatePoint":{"line":51,"column":39,"index":1208},"line":51,"code":"  it('should auth against a non-arbiter', function (done) {\n    const whatHappened = {};\n    test.server.setMessageHandler(request => {\n      const doc = request.document;\n      const $clusterTime = genClusterTime(Date.now());\n      if (isHello(doc)) {\n        whatHappened[LEGACY_HELLO_COMMAND] = true;\n        request.reply(Object.assign({}, mock.HELLO, {\n          $clusterTime\n        }));\n      } else if (doc.saslStart) {\n        whatHappened.saslStart = true;\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    connect(test.connectOptions, err => {\n      try {\n        expect(whatHappened).to.have.property(LEGACY_HELLO_COMMAND, true);\n        expect(whatHappened).to.have.property('saslStart', true);\n      } catch (_err) {\n        err = _err;\n      }\n      done(err);\n    });\n  });","file":"unit/cmap/connect.test.js","skipped":false,"dir":"test"},{"name":"should not auth against an arbiter","suites":["Connect Tests"],"updatePoint":{"line":78,"column":40,"index":2021},"line":78,"code":"  it('should not auth against an arbiter', function (done) {\n    const whatHappened = {};\n    test.server.setMessageHandler(request => {\n      const doc = request.document;\n      const $clusterTime = genClusterTime(Date.now());\n      if (isHello(doc)) {\n        whatHappened[LEGACY_HELLO_COMMAND] = true;\n        request.reply(Object.assign({}, mock.HELLO, {\n          $clusterTime,\n          arbiterOnly: true\n        }));\n      } else if (doc.saslStart) {\n        whatHappened.saslStart = true;\n        request.reply({\n          ok: 0\n        });\n      }\n    });\n    connect(test.connectOptions, err => {\n      try {\n        expect(whatHappened).to.have.property(LEGACY_HELLO_COMMAND, true);\n        expect(whatHappened).to.not.have.property('saslStart');\n      } catch (_err) {\n        err = _err;\n      }\n      done(err);\n    });\n  });","file":"unit/cmap/connect.test.js","skipped":false,"dir":"test"},{"name":"should emit `MongoNetworkError` for network errors","suites":["Connect Tests"],"updatePoint":{"line":106,"column":56,"index":2877},"line":106,"code":"  it('should emit `MongoNetworkError` for network errors', function (done) {\n    connect({\n      hostAddress: new HostAddress('non-existent:27018')\n    }, err => {\n      expect(err).to.be.instanceOf(MongoNetworkError);\n      done();\n    });\n  });","file":"unit/cmap/connect.test.js","skipped":false,"dir":"test"},{"name":"should allow a cancellaton token","suites":["Connect Tests"],"line":114,"code":"  it.skip('should allow a cancellaton token', function (done) {","file":"unit/cmap/connect.test.js","skipped":true,"dir":"test"},{"name":"does not set loadBalanced on the handshake document","suites":["Connect Tests","prepareHandshakeDocument","loadBalanced option","when loadBalanced is not set as an option"],"updatePoint":{"line":133,"column":63,"index":3949},"line":133,"code":"        it('does not set loadBalanced on the handshake document', async () => {\n          const options = {};\n          const authContext = {\n            connection: {},\n            options\n          };\n          const handshakeDocument = await prepareHandshakeDocument(authContext);\n          expect(handshakeDocument).not.to.have.property('loadBalanced');\n        });","file":"unit/cmap/connect.test.js","skipped":false,"dir":"test"},{"name":"does not set loadBalanced on the handshake document","suites":["Connect Tests","prepareHandshakeDocument","loadBalanced option","when loadBalanced is set to false"],"updatePoint":{"line":144,"column":63,"index":4388},"line":144,"code":"        it('does not set loadBalanced on the handshake document', async () => {\n          const options = {\n            loadBalanced: false\n          };\n          const authContext = {\n            connection: {},\n            options\n          };\n          const handshakeDocument = await prepareHandshakeDocument(authContext);\n          expect(handshakeDocument).not.to.have.property('loadBalanced');\n        });","file":"unit/cmap/connect.test.js","skipped":false,"dir":"test"},{"name":"does set loadBalanced on the handshake document","suites":["Connect Tests","prepareHandshakeDocument","loadBalanced option","when loadBalanced is set to true"],"updatePoint":{"line":157,"column":59,"index":4865},"line":157,"code":"        it('does set loadBalanced on the handshake document', async () => {\n          const options = {\n            loadBalanced: true\n          };\n          const authContext = {\n            connection: {},\n            options\n          };\n          const handshakeDocument = await prepareHandshakeDocument(authContext);\n          expect(handshakeDocument).to.have.property('loadBalanced', true);\n        });","file":"unit/cmap/connect.test.js","skipped":false,"dir":"test"},{"name":"should destroy connections which have been closed","suites":["Connection Pool"],"updatePoint":{"line":32,"column":55,"index":800},"line":32,"code":"  it('should destroy connections which have been closed', function (done) {\n    server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(mock.HELLO);\n      } else {\n        // destroy on any other command\n        request.connection.destroy();\n      }\n    });\n    const pool = new ConnectionPool(server, {\n      maxPoolSize: 1,\n      hostAddress: server.hostAddress()\n    });\n    pool.ready();\n    const events = [];\n    pool.on('connectionClosed', event => events.push(event));\n    pool.checkOut((err, conn) => {\n      expect(err).to.not.exist;\n      conn.command(ns('admin.$cmd'), {\n        ping: 1\n      }, undefined, (err, result) => {\n        expect(err).to.exist;\n        expect(result).to.not.exist;\n        pool.checkIn(conn);\n        expect(events).to.have.length(1);\n        const closeEvent = events[0];\n        expect(closeEvent).have.property('reason').equal('error');\n      });\n    });\n    pool.withConnection(undefined, (err, conn, cb) => {\n      expect(err).to.not.exist;\n      cb();\n    }, () => {\n      pool.close(done);\n    });\n  });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"should propagate socket timeouts to connections","suites":["Connection Pool"],"updatePoint":{"line":69,"column":53,"index":1915},"line":69,"code":"  it('should propagate socket timeouts to connections', function (done) {\n    server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(mock.HELLO);\n      } else {\n        // blackhole other requests\n      }\n    });\n    const pool = new ConnectionPool(server, {\n      maxPoolSize: 1,\n      socketTimeoutMS: 200,\n      hostAddress: server.hostAddress()\n    });\n    pool.ready();\n    pool.withConnection((err, conn, cb) => {\n      expect(err).to.not.exist;\n      conn.command(ns('admin.$cmd'), {\n        ping: 1\n      }, undefined, (err, result) => {\n        expect(err).to.exist;\n        expect(result).to.not.exist;\n        expect(err).to.match(/timed out/);\n        cb();\n      });\n    }, () => pool.close(done));\n  });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"should clear timed out wait queue members if no connections are available","suites":["Connection Pool"],"updatePoint":{"line":96,"column":79,"index":2726},"line":96,"code":"  it('should clear timed out wait queue members if no connections are available', function (done) {\n    server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(mock.HELLO);\n      }\n    });\n    const pool = new ConnectionPool(server, {\n      maxPoolSize: 1,\n      waitQueueTimeoutMS: 200,\n      hostAddress: server.hostAddress()\n    });\n    pool.ready();\n    pool.checkOut((err, conn) => {\n      expect(err).to.not.exist;\n      expect(conn).to.exist;\n      pool.checkOut(err => {\n        expect(err).to.exist.and.be.instanceOf(WaitQueueTimeoutError);\n\n        // We can only process the wait queue with `checkIn` and `checkOut`, so we\n        // force the pool here to think there are no available connections, even though\n        // we are checking the connection back in. This simulates a slow leak where\n        // incoming requests outpace the ability of the queue to fully process cancelled\n        // wait queue members\n        sinon.stub(pool, 'availableConnectionCount').get(() => 0);\n        pool.checkIn(conn);\n        setImmediate(() => expect(pool).property('waitQueueSize').to.equal(0));\n        done();\n      });\n    });\n  });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"should respect the minPoolSizeCheckFrequencyMS option","suites":["Connection Pool","minPoolSize population"],"updatePoint":{"line":140,"column":61,"index":4246},"line":140,"code":"    it('should respect the minPoolSizeCheckFrequencyMS option', function () {\n      const pool = new ConnectionPool(server, {\n        minPoolSize: 2,\n        minPoolSizeCheckFrequencyMS: 42,\n        hostAddress: server.hostAddress()\n      });\n      const ensureSpy = sinon.spy(pool, 'ensureMinPoolSize');\n\n      // return a fake connection that won't get identified as perished\n      const createConnStub = sinon.stub(pool, 'createConnection').yields(null, {\n        destroy: () => null,\n        generation: 0\n      });\n      pool.ready();\n\n      // expect ensureMinPoolSize to execute immediately\n      expect(ensureSpy).to.have.been.calledOnce;\n      expect(createConnStub).to.have.been.calledOnce;\n\n      // check that the successful connection return schedules another run\n      clock.tick(42);\n      expect(ensureSpy).to.have.been.calledTwice;\n      expect(createConnStub).to.have.been.calledTwice;\n\n      // check that the 2nd successful connection return schedules another run\n      // but don't expect to get a new connection since we are at minPoolSize\n      clock.tick(42);\n      expect(ensureSpy).to.have.been.calledThrice;\n      expect(createConnStub).to.have.been.calledTwice;\n\n      // check that the next scheduled check runs even after we're at minPoolSize\n      clock.tick(42);\n      expect(ensureSpy).to.have.callCount(4);\n      expect(createConnStub).to.have.been.calledTwice;\n    });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"should default minPoolSizeCheckFrequencyMS to 100ms","suites":["Connection Pool","minPoolSize population"],"updatePoint":{"line":175,"column":59,"index":5648},"line":175,"code":"    it('should default minPoolSizeCheckFrequencyMS to 100ms', function () {\n      const pool = new ConnectionPool(server, {\n        minPoolSize: 2,\n        hostAddress: server.hostAddress()\n      });\n      const ensureSpy = sinon.spy(pool, 'ensureMinPoolSize');\n\n      // return a fake connection that won't get identified as perished\n      const createConnStub = sinon.stub(pool, 'createConnection').yields(null, {\n        destroy: () => null,\n        generation: 0\n      });\n      pool.ready();\n\n      // expect ensureMinPoolSize to execute immediately\n      expect(ensureSpy).to.have.been.calledOnce;\n      expect(createConnStub).to.have.been.calledOnce;\n\n      // check that the successful connection return schedules another run\n      clock.tick(100);\n      expect(ensureSpy).to.have.been.calledTwice;\n      expect(createConnStub).to.have.been.calledTwice;\n\n      // check that the 2nd successful connection return schedules another run\n      // but don't expect to get a new connection since we are at minPoolSize\n      clock.tick(100);\n      expect(ensureSpy).to.have.been.calledThrice;\n      expect(createConnStub).to.have.been.calledTwice;\n\n      // check that the next scheduled check runs even after we're at minPoolSize\n      clock.tick(100);\n      expect(ensureSpy).to.have.callCount(4);\n      expect(createConnStub).to.have.been.calledTwice;\n    });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"should manage a connection for a successful operation","suites":["Connection Pool","withConnection"],"updatePoint":{"line":211,"column":61,"index":7063},"line":211,"code":"    it('should manage a connection for a successful operation', function (done) {\n      server.setMessageHandler(request => {\n        const doc = request.document;\n        if (isHello(doc)) {\n          request.reply(mock.HELLO);\n        }\n      });\n      const pool = new ConnectionPool(server, {\n        hostAddress: server.hostAddress()\n      });\n      pool.ready();\n      const callback = (err, result) => {\n        expect(err).to.not.exist;\n        expect(result).to.exist;\n        pool.close(done);\n      };\n      pool.withConnection((err, conn, cb) => {\n        expect(err).to.not.exist;\n        conn.command(ns('$admin.cmd'), {\n          [LEGACY_HELLO_COMMAND]: 1\n        }, undefined, (cmdErr, hello) => {\n          expect(cmdErr).to.not.exist;\n          cb(undefined, hello);\n        });\n      }, callback);\n    });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"should allow user interaction with an error","suites":["Connection Pool","withConnection"],"updatePoint":{"line":237,"column":51,"index":7878},"line":237,"code":"    it('should allow user interaction with an error', function (done) {\n      server.setMessageHandler(request => {\n        const doc = request.document;\n        if (isHello(doc)) {\n          request.connection.destroy();\n        }\n      });\n      const pool = new ConnectionPool(server, {\n        waitQueueTimeoutMS: 200,\n        hostAddress: server.hostAddress()\n      });\n      pool.ready();\n      const callback = err => {\n        expect(err).to.exist;\n        expect(err).to.match(/closed/);\n        pool.close(done);\n      };\n      pool.withConnection(undefined, (err, conn, cb) => {\n        expect(err).to.exist;\n        expect(err).to.match(/closed/);\n        cb(err);\n      }, callback);\n    });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"should return an error to the original callback","suites":["Connection Pool","withConnection"],"updatePoint":{"line":260,"column":55,"index":8587},"line":260,"code":"    it('should return an error to the original callback', function (done) {\n      server.setMessageHandler(request => {\n        const doc = request.document;\n        if (isHello(doc)) {\n          request.reply(mock.HELLO);\n        }\n      });\n      const pool = new ConnectionPool(server, {\n        hostAddress: server.hostAddress()\n      });\n      pool.ready();\n      const callback = (err, result) => {\n        expect(err).to.exist;\n        expect(result).to.not.exist;\n        expect(err).to.match(/my great error/);\n        pool.close(done);\n      };\n      pool.withConnection(undefined, (err, conn, cb) => {\n        expect(err).to.not.exist;\n        cb(new Error('my great error'));\n      }, callback);\n    });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"should still manage a connection if no callback is provided","suites":["Connection Pool","withConnection"],"updatePoint":{"line":282,"column":67,"index":9315},"line":282,"code":"    it('should still manage a connection if no callback is provided', function (done) {\n      server.setMessageHandler(request => {\n        const doc = request.document;\n        if (isHello(doc)) {\n          request.reply(mock.HELLO);\n        }\n      });\n      const pool = new ConnectionPool(server, {\n        maxPoolSize: 1,\n        hostAddress: server.hostAddress()\n      });\n      pool.ready();\n      const events = [];\n      pool.on('connectionCheckedOut', event => events.push(event));\n      pool.on('connectionCheckedIn', event => {\n        events.push(event);\n        expect(events).to.have.length(2);\n        expect(events[0]).to.be.instanceOf(cmapEvents.ConnectionCheckedOutEvent);\n        expect(events[1]).to.be.instanceOf(cmapEvents.ConnectionCheckedInEvent);\n        pool.close(done);\n      });\n      pool.withConnection(undefined, (err, conn, cb) => {\n        expect(err).to.not.exist;\n        cb();\n      });\n    });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"should support fire-and-forget messages","suites":["new Connection()"],"updatePoint":{"line":47,"column":45,"index":1492},"line":47,"code":"  it('should support fire-and-forget messages', function (done) {\n    server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(mock.HELLO);\n      }\n\n      // blackhole all other requests\n    });\n\n    const options = {\n      ...connectionOptionsDefaults,\n      connectionType: Connection,\n      hostAddress: server.hostAddress()\n    };\n    connect(options, (err, conn) => {\n      expect(err).to.not.exist;\n      expect(conn).to.exist;\n      conn.command(ns('$admin.cmd'), {\n        ping: 1\n      }, {\n        noResponse: true\n      }, (err, result) => {\n        expect(err).to.not.exist;\n        expect(result).to.not.exist;\n        done();\n      });\n    });\n  });","file":"unit/cmap/connection.test.ts","skipped":false,"dir":"test"},{"name":"should destroy streams which time out","suites":["new Connection()"],"updatePoint":{"line":76,"column":43,"index":2219},"line":76,"code":"  it('should destroy streams which time out', function (done) {\n    server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(mock.HELLO);\n      }\n\n      // blackhole all other requests\n    });\n\n    const options = {\n      ...connectionOptionsDefaults,\n      connectionType: Connection,\n      hostAddress: server.hostAddress()\n    };\n    connect(options, (err, conn) => {\n      expect(err).to.not.exist;\n      expect(conn).to.exist;\n      conn.command(ns('$admin.cmd'), {\n        ping: 1\n      }, {\n        socketTimeoutMS: 50\n      }, (err, result) => {\n        expect(err).to.be.instanceOf(MongoNetworkTimeoutError);\n        expect(result).to.not.exist;\n        expect(conn).property('stream').property('destroyed', true);\n        done();\n      });\n    });\n  });","file":"unit/cmap/connection.test.ts","skipped":false,"dir":"test"},{"name":"should throw a network error with kBeforeHandshake set to false on timeout after handshake","suites":["new Connection()"],"updatePoint":{"line":106,"column":96,"index":3101},"line":106,"code":"  it('should throw a network error with kBeforeHandshake set to false on timeout after handshake', function (done) {\n    server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(mock.HELLO);\n      }\n      // respond to no other requests to trigger timeout event\n    });\n\n    const options = {\n      hostAddress: server.hostAddress(),\n      ...connectionOptionsDefaults\n    };\n    connect(options, (err, conn) => {\n      expect(err).to.be.a('undefined');\n      expect(conn).to.be.instanceOf(Connection);\n      expect(conn).to.have.property('hello').that.is.a('object');\n      conn.command(ns('$admin.cmd'), {\n        ping: 1\n      }, {\n        socketTimeoutMS: 50\n      }, err => {\n        const beforeHandshakeSymbol = getSymbolFrom(err, 'beforeHandshake', false);\n        expect(beforeHandshakeSymbol).to.be.a('symbol');\n        expect(err).to.have.property(beforeHandshakeSymbol, false);\n        done();\n      });\n    });\n  });","file":"unit/cmap/connection.test.ts","skipped":false,"dir":"test"},{"name":"should throw a network error with kBeforeHandshake set to true on timeout before handshake","suites":["new Connection()"],"updatePoint":{"line":135,"column":96,"index":4096},"line":135,"code":"  it('should throw a network error with kBeforeHandshake set to true on timeout before handshake', function (done) {\n    server.setMessageHandler(() => {\n      // respond to no requests to trigger timeout event\n    });\n    const options = {\n      ...connectionOptionsDefaults,\n      hostAddress: server.hostAddress(),\n      socketTimeoutMS: 50\n    };\n    connect(options, (err, conn) => {\n      expect(conn).to.be.a('undefined');\n      const beforeHandshakeSymbol = getSymbolFrom(err, 'beforeHandshake');\n      expect(err).to.have.property(beforeHandshakeSymbol, true);\n      done();\n    });\n  });","file":"unit/cmap/connection.test.ts","skipped":false,"dir":"test"},{"name":"calls the callback with the last hello document","suites":["new Connection()","#onMessage","when the connection is a monitoring connection","when multiple hellos exist on the stream"],"updatePoint":{"line":192,"column":59,"index":6173},"line":192,"code":"        it('calls the callback with the last hello document', async function () {\n          const messages = await once(connection, 'message');\n          expect(messages[0].responseTo).to.equal(0);\n          expect(callbackSpy).to.be.calledOnceWith(undefined, last);\n        });","file":"unit/cmap/connection.test.ts","skipped":false,"dir":"test"},{"name":"calls the operation description callback with the document","suites":["new Connection()","#onMessage","when the connection is a monitoring connection","when requestId/responseTo do not match"],"updatePoint":{"line":233,"column":70,"index":7812},"line":233,"code":"        it('calls the operation description callback with the document', function () {\n          expect(callbackSpy).to.be.calledOnceWith(undefined, document);\n        });","file":"unit/cmap/connection.test.ts","skipped":false,"dir":"test"},{"name":"calls the operation description callback with the document","suites":["new Connection()","#onMessage","when the connection is a monitoring connection","when requestId/reponseTo match"],"updatePoint":{"line":271,"column":70,"index":9285},"line":271,"code":"        it('calls the operation description callback with the document', function () {\n          expect(callbackSpy).to.be.calledOnceWith(undefined, document);\n        });","file":"unit/cmap/connection.test.ts","skipped":false,"dir":"test"},{"name":"does not error","suites":["new Connection()","#onMessage","when the connection is a monitoring connection","when no operation description is in the queue"],"updatePoint":{"line":286,"column":26,"index":9951},"line":286,"code":"        it('does not error', function () {\n          const msg = generateOpMsgBuffer(document);\n          const msgHeader = {\n            length: msg.readInt32LE(0),\n            requestId: 2,\n            responseTo: 1,\n            opCode: msg.readInt32LE(12)\n          };\n          const msgBody = msg.subarray(16);\n          const message = new BinMsg(msg, msgHeader, msgBody);\n          expect(() => {\n            connection.onMessage(message);\n          }).to.not.throw();\n        });","file":"unit/cmap/connection.test.ts","skipped":false,"dir":"test"},{"name":"calls all operation description callbacks with an error","suites":["new Connection()","#onMessage","when the connection is a monitoring connection","when more than one operation description is in the queue"],"updatePoint":{"line":342,"column":67,"index":11970},"line":342,"code":"        it('calls all operation description callbacks with an error', function () {\n          expect(spyOne).to.be.calledOnce;\n          expect(spyTwo).to.be.calledOnce;\n          const errorOne = spyOne.firstCall.args[0];\n          const errorTwo = spyTwo.firstCall.args[0];\n          expect(errorOne).to.be.instanceof(MongoRuntimeError);\n          expect(errorTwo).to.be.instanceof(MongoRuntimeError);\n        });","file":"unit/cmap/connection.test.ts","skipped":false,"dir":"test"},{"name":"should delay timeout errors by one tick","suites":["new Connection()","onTimeout()"],"updatePoint":{"line":376,"column":47,"index":13280},"line":376,"code":"    it('should delay timeout errors by one tick', async () => {\n      expect(connection).to.have.property(kDelayedTimeoutId, null);\n      driverSocket.emit('timeout');\n      expect(connection.onTimeout).to.have.been.calledOnce;\n      expect(connection).to.have.property(kDelayedTimeoutId).that.is.instanceOf(NodeJSTimeoutClass);\n      expect(connection).to.have.property('closed', false);\n      expect(driverSocket.destroy).to.not.have.been.called;\n      clock.tick(1);\n      expect(driverSocket.destroy).to.have.been.calledOnce;\n      expect(connection).to.have.property('closed', true);\n    });","file":"unit/cmap/connection.test.ts","skipped":false,"dir":"test"},{"name":"should clear timeout errors if more data is available","suites":["new Connection()","onTimeout()"],"updatePoint":{"line":387,"column":61,"index":13891},"line":387,"code":"    it('should clear timeout errors if more data is available', () => {\n      expect(connection).to.have.property(kDelayedTimeoutId, null);\n      driverSocket.emit('timeout');\n      expect(connection.onTimeout).to.have.been.calledOnce;\n      expect(connection).to.have.property(kDelayedTimeoutId).that.is.instanceOf(NodeJSTimeoutClass);\n\n      // emit a message before the clock ticks even once\n      // onMessage ignores unknown 'responseTo' value\n      messageStream.emit('message', {\n        responseTo: null\n      });\n\n      // New message before clock ticks 1 will clear the timeout\n      expect(connection).to.have.property(kDelayedTimeoutId, null);\n\n      // ticking the clock should do nothing, there is no timeout anymore\n      clock.tick(1);\n      expect(driverSocket.destroy).to.not.have.been.called;\n      expect(connection).to.have.property('closed', false);\n      expect(connection).to.have.property(kDelayedTimeoutId, null);\n    });","file":"unit/cmap/connection.test.ts","skipped":false,"dir":"test"},{"name":"returns true","suites":["new Connection()",".hasSessionSupport","when logicalSessionTimeoutMinutes is present"],"updatePoint":{"line":421,"column":22,"index":15239},"line":421,"code":"      it('returns true', function () {\n        expect(hasSessionSupport(connection)).to.be.true;\n      });","file":"unit/cmap/connection.test.ts","skipped":false,"dir":"test"},{"name":"returns true","suites":["new Connection()",".hasSessionSupport","when logicalSessionTimeoutMinutes is not present","when in load balancing mode"],"updatePoint":{"line":435,"column":24,"index":15755},"line":435,"code":"        it('returns true', function () {\n          expect(hasSessionSupport(connection)).to.be.true;\n        });","file":"unit/cmap/connection.test.ts","skipped":false,"dir":"test"},{"name":"returns false","suites":["new Connection()",".hasSessionSupport","when logicalSessionTimeoutMinutes is not present","when not in load balancing mode"],"updatePoint":{"line":448,"column":25,"index":16205},"line":448,"code":"        it('returns false', function () {\n          expect(hasSessionSupport(connection)).to.be.false;\n        });","file":"unit/cmap/connection.test.ts","skipped":false,"dir":"test"},{"name":"only reads the last message in the buffer","suites":["MessageStream","when the stream is for a monitoring connection"],"updatePoint":{"line":44,"column":49,"index":1043},"line":44,"code":"    it('only reads the last message in the buffer', async function () {\n      const inputStream = bufferToStream(Buffer.concat([firstHello, secondHello, thirdHello]));\n      const messageStream = new MessageStream();\n      messageStream.isMonitoringConnection = true;\n      inputStream.pipe(messageStream);\n      const messages = await once(messageStream, 'message');\n      const msg = messages[0];\n      msg.parse();\n      expect(msg).to.have.property('documents').that.deep.equals([lastResponse]);\n      // Make sure there is nothing left in the buffer.\n      expect(messageStream.buffer.length).to.equal(0);\n    });","file":"unit/cmap/message_stream.test.js","skipped":false,"dir":"test"},{"name":"does not read partial messages","suites":["MessageStream","when the stream is for a monitoring connection"],"updatePoint":{"line":56,"column":38,"index":1651},"line":56,"code":"    it('does not read partial messages', async function () {\n      const inputStream = bufferToStream(Buffer.concat([firstHello, secondHello, thirdHello, partial]));\n      const messageStream = new MessageStream();\n      messageStream.isMonitoringConnection = true;\n      inputStream.pipe(messageStream);\n      const messages = await once(messageStream, 'message');\n      const msg = messages[0];\n      msg.parse();\n      expect(msg).to.have.property('documents').that.deep.equals([lastResponse]);\n      // Make sure the buffer wasn't read to the end.\n      expect(messageStream.buffer.length).to.equal(5);\n    });","file":"unit/cmap/message_stream.test.js","skipped":false,"dir":"test"},{"name":"reads all messages in the buffer","suites":["MessageStream","when the stream is not for a monitoring connection","when the messages are valid"],"updatePoint":{"line":83,"column":42,"index":2770},"line":83,"code":"      it('reads all messages in the buffer', async function () {\n        const inputStream = bufferToStream(Buffer.concat([firstHello, secondHello, thirdHello]));\n        const messageStream = new MessageStream();\n        inputStream.pipe(messageStream);\n        for await (const messages of on(messageStream, 'message')) {\n          messageCount++;\n          const msg = messages[0];\n          msg.parse();\n          expect(msg).to.have.property('documents').that.deep.equals([response]);\n          // Test will not complete until 3 messages processed.\n          if (messageCount === 3) {\n            return;\n          }\n        }\n      });","file":"unit/cmap/message_stream.test.js","skipped":false,"dir":"test"},{"name":"emits an error","suites":["MessageStream","when the stream is not for a monitoring connection","when the messages are invalid","when the message size is negative"],"updatePoint":{"line":101,"column":26,"index":3528},"line":101,"code":"        it('emits an error', async function () {\n          const inputStream = bufferToStream(Buffer.from('ffffffff', 'hex'));\n          const messageStream = new MessageStream();\n          inputStream.pipe(messageStream);\n          const errors = await once(messageStream, 'error');\n          const err = errors[0];\n          expect(err).to.have.property('message').that.equals('Invalid message size: -1');\n        });","file":"unit/cmap/message_stream.test.js","skipped":false,"dir":"test"},{"name":"emits an error","suites":["MessageStream","when the stream is not for a monitoring connection","when the messages are invalid","when the message size exceeds the bson maximum"],"updatePoint":{"line":111,"column":26,"index":4036},"line":111,"code":"        it('emits an error', async function () {\n          const inputStream = bufferToStream(Buffer.from('01000004', 'hex'));\n          const messageStream = new MessageStream();\n          inputStream.pipe(messageStream);\n          const errors = await once(messageStream, 'error');\n          const err = errors[0];\n          expect(err).to.have.property('message').that.equals('Invalid message size: 67108865, max allowed: 67108864');\n        });","file":"unit/cmap/message_stream.test.js","skipped":false,"dir":"test"},{"name":"pushes the message","suites":["MessageStream","when writing to the message stream"],"updatePoint":{"line":123,"column":26,"index":4571},"line":123,"code":"    it('pushes the message', function (done) {\n      const readableStream = new Readable({\n        read() {}\n      });\n      const writeableStream = new Writable({\n        write: (chunk, _, callback) => {\n          readableStream.push(chunk);\n          callback();\n        }\n      });\n      readableStream.on('data', data => {\n        expect(data.toString('hex')).to.eql('370000000300000000000000dd0700000000000000220000001069736d6173746572000100000002246462000600000061646d696e0000');\n        done();\n      });\n      const messageStream = new MessageStream();\n      messageStream.pipe(writeableStream);\n      const command = new Msg('admin.$cmd', {\n        [LEGACY_HELLO_COMMAND]: 1\n      }, {\n        requestId: 3\n      });\n      messageStream.writeCommand(command, null, err => {\n        done(err);\n      });\n    });","file":"unit/cmap/message_stream.test.js","skipped":false,"dir":"test"},{"name":"defaults txnConnections to zero","suites":["ConnectionPoolMetrics","#constructor"],"updatePoint":{"line":12,"column":39,"index":305},"line":12,"code":"    it('defaults txnConnections to zero', function () {\n      expect(metrics).property('txnConnections').to.equal(0);\n    });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"defaults cursorConnections to zero","suites":["ConnectionPoolMetrics","#constructor"],"updatePoint":{"line":15,"column":42,"index":434},"line":15,"code":"    it('defaults cursorConnections to zero', function () {\n      expect(metrics).property('cursorConnections').to.equal(0);\n    });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"defaults otherConnections to zero","suites":["ConnectionPoolMetrics","#constructor"],"updatePoint":{"line":18,"column":41,"index":565},"line":18,"code":"    it('defaults otherConnections to zero', function () {\n      expect(metrics).property('otherConnections').to.equal(0);\n    });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"returns the metrics information","suites":["ConnectionPoolMetrics","#info"],"updatePoint":{"line":24,"column":39,"index":782},"line":24,"code":"    it('returns the metrics information', function () {\n      expect(metrics.info(5)).to.equal('Timed out while checking out a connection from connection pool: ' + 'maxPoolSize: 5, ' + 'connections in use by cursors: 0, ' + 'connections in use by transactions: 0, ' + 'connections in use by other operations: 0');\n    });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"increments the txnConnections count","suites":["ConnectionPoolMetrics","#markPinned","when the type is TXN"],"updatePoint":{"line":35,"column":45,"index":1372},"line":35,"code":"      it('increments the txnConnections count', function () {\n        expect(metrics).to.deep.equal({\n          txnConnections: 1,\n          cursorConnections: 0,\n          otherConnections: 0\n        });\n      });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"increments the cursorConnections count","suites":["ConnectionPoolMetrics","#markPinned","when the type is CURSOR"],"updatePoint":{"line":48,"column":48,"index":1771},"line":48,"code":"      it('increments the cursorConnections count', function () {\n        expect(metrics).to.deep.equal({\n          txnConnections: 0,\n          cursorConnections: 1,\n          otherConnections: 0\n        });\n      });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"increments the otherConnections count","suites":["ConnectionPoolMetrics","#markPinned","when the type is OTHER"],"updatePoint":{"line":61,"column":47,"index":2167},"line":61,"code":"      it('increments the otherConnections count', function () {\n        expect(metrics).to.deep.equal({\n          txnConnections: 0,\n          cursorConnections: 0,\n          otherConnections: 1\n        });\n      });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"decrements the txnConnections count","suites":["ConnectionPoolMetrics","#markUnpinned","when the type is TXN"],"updatePoint":{"line":77,"column":45,"index":2656},"line":77,"code":"      it('decrements the txnConnections count', function () {\n        expect(metrics).to.deep.equal({\n          txnConnections: -1,\n          cursorConnections: 0,\n          otherConnections: 0\n        });\n      });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"decrements the cursorConnections count","suites":["ConnectionPoolMetrics","#markUnpinned","when the type is CURSOR"],"updatePoint":{"line":90,"column":48,"index":3058},"line":90,"code":"      it('decrements the cursorConnections count', function () {\n        expect(metrics).to.deep.equal({\n          txnConnections: 0,\n          cursorConnections: -1,\n          otherConnections: 0\n        });\n      });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"decrements the otherConnections count","suites":["ConnectionPoolMetrics","#markUnpinned","when the type is OTHER"],"updatePoint":{"line":103,"column":47,"index":3457},"line":103,"code":"      it('decrements the otherConnections count', function () {\n        expect(metrics).to.deep.equal({\n          txnConnections: 0,\n          cursorConnections: 0,\n          otherConnections: -1\n        });\n      });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"sets the property","suites":["StreamDescription - unit/cmap",".new","when options are provided","when logicalSessionTimeoutMinutes is in the options"],"updatePoint":{"line":17,"column":29,"index":541},"line":17,"code":"        it('sets the property', function () {\n          expect(description.logicalSessionTimeoutMinutes).to.eq(5);\n        });","file":"unit/cmap/stream_description.test.js","skipped":false,"dir":"test"},{"name":"sets logicalSessionTimeoutMinutes to undefined","suites":["StreamDescription - unit/cmap",".new","when options are provided","when logicalSessionTimeoutMinutes is not in the options"],"updatePoint":{"line":23,"column":58,"index":860},"line":23,"code":"        it('sets logicalSessionTimeoutMinutes to undefined', function () {\n          expect(description).to.have.property('logicalSessionTimeoutMinutes', undefined);\n        });","file":"unit/cmap/stream_description.test.js","skipped":false,"dir":"test"},{"name":"sets the property to true","suites":["StreamDescription - unit/cmap",".new","when options are provided","when loadBalanced is in the options","when the value is true"],"updatePoint":{"line":33,"column":39,"index":1297},"line":33,"code":"          it('sets the property to true', function () {\n            expect(description.loadBalanced).to.be.true;\n          });","file":"unit/cmap/stream_description.test.js","skipped":false,"dir":"test"},{"name":"sets the property to false","suites":["StreamDescription - unit/cmap",".new","when options are provided","when loadBalanced is in the options","when the value is false"],"updatePoint":{"line":42,"column":40,"index":1640},"line":42,"code":"          it('sets the property to false', function () {\n            expect(description.loadBalanced).to.be.false;\n          });","file":"unit/cmap/stream_description.test.js","skipped":false,"dir":"test"},{"name":"sets loadBalanced to false","suites":["StreamDescription - unit/cmap",".new","when options are provided","when loadBalanced is not in the options"],"updatePoint":{"line":49,"column":38,"index":1926},"line":49,"code":"        it('sets loadBalanced to false', function () {\n          expect(description.loadBalanced).to.be.false;\n        });","file":"unit/cmap/stream_description.test.js","skipped":false,"dir":"test"},{"name":"defaults logicalSessionTimeoutMinutes to undefined","suites":["StreamDescription - unit/cmap",".new","when options are not provided"],"updatePoint":{"line":56,"column":60,"index":2208},"line":56,"code":"      it('defaults logicalSessionTimeoutMinutes to undefined', function () {\n        expect(description).to.have.property('logicalSessionTimeoutMinutes', undefined);\n      });","file":"unit/cmap/stream_description.test.js","skipped":false,"dir":"test"},{"name":"defaults loadBalanced to false","suites":["StreamDescription - unit/cmap",".new","when options are not provided"],"updatePoint":{"line":59,"column":40,"index":2364},"line":59,"code":"      it('defaults loadBalanced to false', function () {\n        expect(description.loadBalanced).to.be.false;\n      });","file":"unit/cmap/stream_description.test.js","skipped":false,"dir":"test"},{"name":"compresses the data","suites":["compression",".compress()","when the compression library is zstd","when a level is not provided"],"updatePoint":{"line":13,"column":31,"index":515},"line":13,"code":"        it('compresses the data', function (done) {\n          compress(options, buffer, (error, data) => {\n            expect(error).to.not.exist;\n            const zstdMagicNumber = data.reverse().toString('hex').substring(16, 26);\n            // Zstd magic number first set of bytes is is 0xFD2FB528\n            expect(zstdMagicNumber).to.equal('00fd2fb528');\n            done();\n          });\n        });","file":"unit/cmap/wire_protocol/compression.test.ts","skipped":false,"dir":"test"},{"name":"compresses the data","suites":["compression",".compress()","when the compression library is zstd","when a level is provided"],"updatePoint":{"line":30,"column":31,"index":1133},"line":30,"code":"        it('compresses the data', function (done) {\n          compress(options, buffer, (error, data) => {\n            expect(error).to.not.exist;\n            const zstdMagicNumber = data.reverse().toString('hex').substring(16, 26);\n            // Zstd magic number first set of bytes is is 0xFD2FB528\n            expect(zstdMagicNumber).to.equal('00fd2fb528');\n            done();\n          });\n        });","file":"unit/cmap/wire_protocol/compression.test.ts","skipped":false,"dir":"test"},{"name":"decompresses the data","suites":["compression",".decompress()","when the compression library is zstd"],"updatePoint":{"line":50,"column":31,"index":1812},"line":50,"code":"      it('decompresses the data', function (done) {\n        compress(options, buffer, (error, data) => {\n          expect(error).to.not.exist;\n          decompress(Compressor.zstd, data, (err, decompressed) => {\n            expect(decompressed).to.deep.equal(buffer);\n            done();\n          });\n        });\n      });","file":"unit/cmap/wire_protocol/compression.test.ts","skipped":false,"dir":"test"},{"name":"returns 3.6","suites":["Wire Protocol Constants","MIN_SUPPORTED_SERVER_VERSION"],"updatePoint":{"line":12,"column":19,"index":357},"line":12,"code":"    it('returns 3.6', function () {\n      expect(MIN_SUPPORTED_SERVER_VERSION).to.equal('3.6');\n    });","file":"unit/cmap/wire_protocol/constants.test.js","skipped":false,"dir":"test"},{"name":"returns 6.0","suites":["Wire Protocol Constants","MAX_SUPPORTED_SERVER_VERSION"],"updatePoint":{"line":17,"column":19,"index":524},"line":17,"code":"    it('returns 6.0', function () {\n      expect(MAX_SUPPORTED_SERVER_VERSION).to.equal('6.0');\n    });","file":"unit/cmap/wire_protocol/constants.test.js","skipped":false,"dir":"test"},{"name":"returns 6","suites":["Wire Protocol Constants","MIN_SUPPORTED_WIRE_VERSION"],"updatePoint":{"line":22,"column":17,"index":687},"line":22,"code":"    it('returns 6', function () {\n      expect(MIN_SUPPORTED_WIRE_VERSION).to.equal(6);\n    });","file":"unit/cmap/wire_protocol/constants.test.js","skipped":false,"dir":"test"},{"name":"returns 17","suites":["Wire Protocol Constants","MAX_SUPPORTED_WIRE_VERSION"],"updatePoint":{"line":27,"column":18,"index":845},"line":27,"code":"    it('returns 17', function () {\n      expect(MAX_SUPPORTED_WIRE_VERSION).to.equal(17);\n    });","file":"unit/cmap/wire_protocol/constants.test.js","skipped":false,"dir":"test"},{"name":"","suites":["Connection String spec tests"],"updatePoint":{"line":15,"column":31,"index":759},"line":15,"code":"        it(`${test.description}`, function () {\n          if (skipTests.includes(test.description)) {\n            return this.skip();\n          }\n          executeUriValidationTest(test, testsThatDoNotThrowOnWarn.some(t => t === test.description));\n        });","file":"unit/connection_string.spec.test.ts","skipped":false,"dir":"test"},{"name":"should be false when readPreference is Primary","suites":["class Db","secondaryOk"],"updatePoint":{"line":10,"column":54,"index":456},"line":10,"code":"    it('should be false when readPreference is Primary', function () {\n      const options = {\n        readPreference: ReadPreference.PRIMARY\n      };\n      const mydb = new Db(client, 'mydb', options);\n      expect(mydb).property(secondary_ok).to.be.false;\n      expect(mydb).property(legacy_secondary_ok).to.be.false;\n    });","file":"unit/db.test.ts","skipped":false,"dir":"test"},{"name":"should be true when readPreference is Primary Preferred","suites":["class Db","secondaryOk"],"updatePoint":{"line":18,"column":63,"index":793},"line":18,"code":"    it('should be true when readPreference is Primary Preferred', function () {\n      const options = {\n        readPreference: ReadPreference.PRIMARY_PREFERRED\n      };\n      const mydb = new Db(client, 'mydb', options);\n      expect(mydb).property(secondary_ok).to.be.true;\n      expect(mydb).property(legacy_secondary_ok).to.be.true;\n    });","file":"unit/db.test.ts","skipped":false,"dir":"test"},{"name":"should be true when readPreference is Secondary","suites":["class Db","secondaryOk"],"updatePoint":{"line":26,"column":55,"index":1130},"line":26,"code":"    it('should be true when readPreference is Secondary', function () {\n      const options = {\n        readPreference: ReadPreference.SECONDARY\n      };\n      const mydb = new Db(client, 'mydb', options);\n      expect(mydb).property(secondary_ok).to.be.true;\n      expect(mydb).property(legacy_secondary_ok).to.be.true;\n    });","file":"unit/db.test.ts","skipped":false,"dir":"test"},{"name":"should be true when readPreference is Secondary Preferred","suites":["class Db","secondaryOk"],"updatePoint":{"line":34,"column":65,"index":1469},"line":34,"code":"    it('should be true when readPreference is Secondary Preferred', function () {\n      const options = {\n        readPreference: ReadPreference.SECONDARY_PREFERRED\n      };\n      const mydb = new Db(client, 'mydb', options);\n      expect(mydb).property(secondary_ok).to.be.true;\n      expect(mydb).property(legacy_secondary_ok).to.be.true;\n    });","file":"unit/db.test.ts","skipped":false,"dir":"test"},{"name":"should be true when readPreference is Nearest","suites":["class Db","secondaryOk"],"updatePoint":{"line":42,"column":53,"index":1806},"line":42,"code":"    it('should be true when readPreference is Nearest', function () {\n      const options = {\n        readPreference: ReadPreference.NEAREST\n      };\n      const mydb = new Db(client, 'mydb', options);\n      expect(mydb).property(secondary_ok).to.be.true;\n      expect(mydb).property(legacy_secondary_ok).to.be.true;\n    });","file":"unit/db.test.ts","skipped":false,"dir":"test"},{"name":"should export all and only the expected keys in expected_exports","suites":["mongodb entrypoint"],"updatePoint":{"line":12,"column":70,"index":2955},"line":12,"code":"  it('should export all and only the expected keys in expected_exports', () => {\n    expect(sorted(Object.keys(mongodb), byStrings)).to.deep.equal(sorted(EXPECTED_EXPORTS, byStrings));\n  });","file":"unit/index.test.ts","skipped":false,"dir":"test"},{"name":"should export keys added by ts-node as undefined","suites":["mongodb entrypoint"],"updatePoint":{"line":15,"column":54,"index":3130},"line":15,"code":"  it('should export keys added by ts-node as undefined', () => {\n    // If the array is empty, this test would be a no-op so we should remove it\n    expect(TS_NODE_EXPORTS).to.have.length.greaterThan(0);\n    for (const tsNodeExportKey of TS_NODE_EXPORTS) {\n      expect(mongodb).to.have.property(tsNodeExportKey, undefined);\n    }\n  });","file":"unit/index.test.ts","skipped":false,"dir":"test"},{"name":"MongoClient should always freeze public options","suites":["MongoOptions"],"updatePoint":{"line":36,"column":53,"index":749},"line":36,"code":"  it('MongoClient should always freeze public options', function () {\n    const client = new MongoClient('mongodb://localhost:27017');\n    expect(client.options).to.be.frozen;\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"programmatic options should override URI options","suites":["MongoOptions"],"updatePoint":{"line":40,"column":54,"index":932},"line":40,"code":"  it('programmatic options should override URI options', function () {\n    const options = parseOptions('mongodb://localhost:27017/test?directConnection=true', {\n      directConnection: false\n    });\n    expect(options.directConnection).to.be.false;\n    expect(options.hosts).has.length(1);\n    expect(options.dbName).to.equal('test');\n    expect(options.prototype).to.not.exist;\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should rename tls options correctly","suites":["MongoOptions"],"updatePoint":{"line":49,"column":41,"index":1305},"line":49,"code":"  it('should rename tls options correctly', function () {\n    const filename = `${os.tmpdir()}/tmp.pem`;\n    fs.closeSync(fs.openSync(filename, 'w'));\n    const options = parseOptions('mongodb://localhost:27017/?ssl=true', {\n      tlsCertificateKeyFile: filename,\n      tlsCertificateFile: filename,\n      tlsCAFile: filename,\n      sslCRL: filename,\n      tlsCertificateKeyFilePassword: 'tlsCertificateKeyFilePassword',\n      sslValidate: false\n    });\n    fs.unlinkSync(filename);\n\n    /*\n     * If set TLS enabled, equivalent to setting the ssl option.\n     *\n     * ### Additional options:\n     *\n     * |    nodejs option     | MongoDB equivalent                                 | type                                   |\n     * |:---------------------|----------------------------------------------------|:---------------------------------------|\n     * | `ca`                 | sslCA, tlsCAFile                                   | `string \\| Buffer \\| Buffer[]`         |\n     * | `crl`                | sslCRL                                             | `string \\| Buffer \\| Buffer[]`         |\n     * | `cert`               | sslCert, tlsCertificateFile                        | `string \\| Buffer \\| Buffer[]`         |\n     * | `key`                | sslKey, tlsCertificateKeyFile                      | `string \\| Buffer \\| KeyObject[]`      |\n     * | `passphrase`         | sslPass, tlsCertificateKeyFilePassword             | `string`                               |\n     * | `rejectUnauthorized` | sslValidate                                        | `boolean`                              |\n     *\n     */\n    expect(options).to.not.have.property('tlsCertificateKeyFile');\n    expect(options).to.not.have.property('tlsCAFile');\n    expect(options).to.not.have.property('sslCRL');\n    expect(options).to.not.have.property('tlsCertificateKeyFilePassword');\n    expect(options).has.property('ca', '');\n    expect(options).has.property('crl', '');\n    expect(options).has.property('cert', '');\n    expect(options).has.property('key');\n    expect(options.key).has.length(0);\n    expect(options).has.property('passphrase', 'tlsCertificateKeyFilePassword');\n    expect(options).has.property('rejectUnauthorized', false);\n    expect(options).has.property('tls', true);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should parse all options from the options object","suites":["MongoOptions"],"updatePoint":{"line":176,"column":54,"index":5648},"line":176,"code":"  it('should parse all options from the options object', function () {\n    const options = parseOptions('mongodb://localhost:27017/', ALL_OPTIONS);\n    // Check consolidated options\n    expect(options).has.property('writeConcern');\n    expect(options.writeConcern).has.property('w', 2);\n    expect(options.writeConcern).has.property('j', true);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should parse all options from the URI string","suites":["MongoOptions"],"updatePoint":{"line":184,"column":50,"index":6828},"line":184,"code":"  it('should parse all options from the URI string', function () {\n    const options = parseOptions(allURIOptions);\n    expect(options).has.property('zlibCompressionLevel', 2);\n    expect(options).has.property('writeConcern');\n    expect(options.writeConcern).has.property('w', 'majority');\n    expect(options.writeConcern).has.property('wtimeout', 2);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should ignore undefined and null values in the options object","suites":["MongoOptions"],"updatePoint":{"line":191,"column":67,"index":7204},"line":191,"code":"  it('should ignore undefined and null values in the options object', function () {\n    const options = parseOptions('mongodb://localhost:27017/', {\n      maxPoolSize: null,\n      servername: undefined,\n      randomopt: null,\n      otherrandomopt: undefined\n    });\n\n    // test valid option key with default value\n    expect(options).to.have.property('maxPoolSize', 100);\n\n    // test valid option key without default value\n    expect(options).not.to.have.property('servername');\n\n    // test invalid option keys that are null/undefined\n    expect(options).not.to.have.property('randomopt');\n    expect(options).not.to.have.property('otherrandomopt');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should throw an error on unrecognized keys in the options object if they are defined","suites":["MongoOptions"],"updatePoint":{"line":209,"column":90,"index":7886},"line":209,"code":"  it('should throw an error on unrecognized keys in the options object if they are defined', function () {\n    expect(() => parseOptions('mongodb://localhost:27017/', {\n      randomopt: 'test'\n    })).to.throw(MongoParseError, 'option randomopt is not supported');\n    expect(() => parseOptions('mongodb://localhost:27017/', {\n      randomopt: 'test',\n      randomopt2: 'test'\n    })).to.throw(MongoParseError, 'options randomopt, randomopt2 are not supported');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"srvHost saved to options for later resolution","suites":["MongoOptions"],"updatePoint":{"line":218,"column":51,"index":8316},"line":218,"code":"  it('srvHost saved to options for later resolution', function () {\n    const options = parseOptions('mongodb+srv://server.example.com/');\n    expect(options).has.property('srvHost', 'server.example.com');\n    expect(options).has.property('tls', true);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"ssl= can be used to set tls=false","suites":["MongoOptions"],"updatePoint":{"line":223,"column":39,"index":8563},"line":223,"code":"  it('ssl= can be used to set tls=false', function () {\n    const options = parseOptions('mongodb+srv://server.example.com/?ssl=false');\n    expect(options).has.property('srvHost', 'server.example.com');\n    expect(options).has.property('tls', false);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"tls= can be used to set tls=false","suites":["MongoOptions"],"updatePoint":{"line":228,"column":39,"index":8821},"line":228,"code":"  it('tls= can be used to set tls=false', function () {\n    const options = parseOptions('mongodb+srv://server.example.com/?tls=false');\n    expect(options).has.property('srvHost', 'server.example.com');\n    expect(options).has.property('tls', false);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"ssl= can be used to set tls=true","suites":["MongoOptions"],"updatePoint":{"line":233,"column":38,"index":9078},"line":233,"code":"  it('ssl= can be used to set tls=true', function () {\n    const options = parseOptions('mongodb+srv://server.example.com/?ssl=true');\n    expect(options).has.property('srvHost', 'server.example.com');\n    expect(options).has.property('tls', true);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"tls= can be used to set tls=true","suites":["MongoOptions"],"updatePoint":{"line":238,"column":38,"index":9333},"line":238,"code":"  it('tls= can be used to set tls=true', function () {\n    const options = parseOptions('mongodb+srv://server.example.com/?tls=true');\n    expect(options).has.property('srvHost', 'server.example.com');\n    expect(options).has.property('tls', true);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports ReadPreference option in url","suites":["MongoOptions"],"updatePoint":{"line":243,"column":43,"index":9593},"line":243,"code":"  it('supports ReadPreference option in url', function () {\n    const options = parseOptions('mongodb://localhost/?readPreference=nearest');\n    expect(options.readPreference).to.be.an.instanceof(ReadPreference);\n    expect(options.readPreference.mode).to.equal('nearest');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports ReadPreference option in object plain","suites":["MongoOptions"],"updatePoint":{"line":248,"column":52,"index":9882},"line":248,"code":"  it('supports ReadPreference option in object plain', function () {\n    const options = parseOptions('mongodb://localhost', {\n      readPreference: {\n        mode: 'nearest',\n        hedge: {\n          enabled: true\n        }\n      }\n    });\n    expect(options.readPreference).to.be.an.instanceof(ReadPreference);\n    expect(options.readPreference.mode).to.equal('nearest');\n    expect(options.readPreference.hedge).to.include({\n      enabled: true\n    });\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports ReadPreference option in object proper class","suites":["MongoOptions"],"updatePoint":{"line":263,"column":59,"index":10353},"line":263,"code":"  it('supports ReadPreference option in object proper class', function () {\n    const tag = {\n      rack: 1\n    };\n    const options = parseOptions('mongodb://localhost', {\n      readPreference: new ReadPreference('nearest', [tag], {\n        maxStalenessSeconds: 20\n      })\n    });\n    expect(options.readPreference).to.be.an.instanceof(ReadPreference);\n    expect(options.readPreference.mode).to.equal('nearest');\n    expect(options.readPreference.tags).to.be.an('array').that.includes(tag);\n    expect(options.readPreference.maxStalenessSeconds).to.equal(20);\n    // maxStalenessSeconds sets the minWireVersion\n    expect(options.readPreference.minWireVersion).to.be.at.least(5);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should throw when given a readpreference options with an unsupported type","suites":["MongoOptions"],"updatePoint":{"line":279,"column":79,"index":11062},"line":279,"code":"  it('should throw when given a readpreference options with an unsupported type', () => {\n    expect(() => new MongoClient('mongodb://blah', {\n      readPreference: 34\n    })).to.throw(MongoParseError, /Unknown ReadPreference value/);\n    // Passing readPreference in URI will always be string\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports WriteConcern option in url","suites":["MongoOptions"],"updatePoint":{"line":286,"column":41,"index":11325},"line":286,"code":"  it('supports WriteConcern option in url', function () {\n    const options = parseOptions('mongodb://localhost/?w=3');\n    expect(options.writeConcern).to.be.an.instanceof(WriteConcern);\n    expect(options.writeConcern.w).to.equal(3);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports WriteConcern option in object plain","suites":["MongoOptions"],"updatePoint":{"line":291,"column":50,"index":11576},"line":291,"code":"  it('supports WriteConcern option in object plain', function () {\n    const options = parseOptions('mongodb://localhost', {\n      writeConcern: {\n        w: 'majority',\n        wtimeoutMS: 300\n      }\n    });\n    expect(options.writeConcern).to.be.an.instanceof(WriteConcern);\n    expect(options.writeConcern.w).to.equal('majority');\n    expect(options.writeConcern.wtimeout).to.equal(300);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports WriteConcern option in object proper class","suites":["MongoOptions"],"updatePoint":{"line":302,"column":57,"index":11981},"line":302,"code":"  it('supports WriteConcern option in object proper class', function () {\n    const options = parseOptions('mongodb://localhost', {\n      writeConcern: new WriteConcern(5, 200, true)\n    });\n    expect(options.writeConcern).to.be.an.instanceof(WriteConcern);\n    expect(options.writeConcern.w).to.equal(5);\n    expect(options.writeConcern.wtimeout).to.equal(200);\n    expect(options.writeConcern.j).to.equal(true);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports ReadConcern option in url","suites":["MongoOptions"],"updatePoint":{"line":311,"column":40,"index":12385},"line":311,"code":"  it('supports ReadConcern option in url', function () {\n    const options = parseOptions('mongodb://localhost/?readConcernLevel=available');\n    expect(options.readConcern).to.be.an.instanceof(ReadConcern);\n    expect(options.readConcern.level).to.equal('available');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports ReadConcern option in object plain","suites":["MongoOptions"],"updatePoint":{"line":316,"column":49,"index":12669},"line":316,"code":"  it('supports ReadConcern option in object plain', function () {\n    const options = parseOptions('mongodb://localhost', {\n      readConcern: {\n        level: 'linearizable'\n      }\n    });\n    expect(options.readConcern).to.be.an.instanceof(ReadConcern);\n    expect(options.readConcern.level).to.equal('linearizable');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports ReadConcern option in object proper class","suites":["MongoOptions"],"updatePoint":{"line":325,"column":56,"index":13003},"line":325,"code":"  it('supports ReadConcern option in object proper class', function () {\n    const options = parseOptions('mongodb://localhost', {\n      readConcern: new ReadConcern('snapshot')\n    });\n    expect(options.readConcern).to.be.an.instanceof(ReadConcern);\n    expect(options.readConcern.level).to.equal('snapshot');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports Credentials option in url","suites":["MongoOptions"],"updatePoint":{"line":332,"column":40,"index":13305},"line":332,"code":"  it('supports Credentials option in url', function () {\n    const options = parseOptions('mongodb://USERNAME:PASSWORD@localhost/');\n    expect(options.credentials).to.be.an.instanceof(MongoCredentials);\n    expect(options.credentials.username).to.equal('USERNAME');\n    expect(options.credentials.password).to.equal('PASSWORD');\n    expect(options.credentials.source).to.equal('admin');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports Credentials option in url with db","suites":["MongoOptions"],"updatePoint":{"line":339,"column":48,"index":13707},"line":339,"code":"  it('supports Credentials option in url with db', function () {\n    const options = parseOptions('mongodb://USERNAME:PASSWORD@localhost/foo');\n    expect(options.credentials).to.be.an.instanceof(MongoCredentials);\n    expect(options.credentials.username).to.equal('USERNAME');\n    expect(options.credentials.password).to.equal('PASSWORD');\n    expect(options.credentials.source).to.equal('foo');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports Credentials option in auth object plain","suites":["MongoOptions"],"updatePoint":{"line":346,"column":54,"index":14116},"line":346,"code":"  it('supports Credentials option in auth object plain', function () {\n    const options = parseOptions('mongodb://localhost/', {\n      auth: {\n        username: 'USERNAME',\n        password: 'PASSWORD'\n      }\n    });\n    expect(options.credentials).to.be.an.instanceof(MongoCredentials);\n    expect(options.credentials.username).to.equal('USERNAME');\n    expect(options.credentials.password).to.equal('PASSWORD');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"transforms tlsAllowInvalidCertificates and tlsAllowInvalidHostnames correctly","suites":["MongoOptions"],"updatePoint":{"line":357,"column":83,"index":14567},"line":357,"code":"  it('transforms tlsAllowInvalidCertificates and tlsAllowInvalidHostnames correctly', function () {\n    const optionsTrue = parseOptions('mongodb://localhost/', {\n      tlsAllowInvalidCertificates: true,\n      tlsAllowInvalidHostnames: true\n    });\n    expect(optionsTrue.rejectUnauthorized).to.equal(false);\n    expect(optionsTrue.checkServerIdentity).to.be.a('function');\n    expect(optionsTrue.checkServerIdentity()).to.equal(undefined);\n    const optionsFalse = parseOptions('mongodb://localhost/', {\n      tlsAllowInvalidCertificates: false,\n      tlsAllowInvalidHostnames: false\n    });\n    expect(optionsFalse.rejectUnauthorized).to.equal(true);\n    expect(optionsFalse.checkServerIdentity).to.equal(undefined);\n    const optionsUndefined = parseOptions('mongodb://localhost/');\n    expect(optionsUndefined.rejectUnauthorized).to.equal(undefined);\n    expect(optionsUndefined.checkServerIdentity).to.equal(undefined);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"correctly sets the cert and key if only tlsCertificateKeyFile is provided","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":386,"column":81,"index":15870},"line":386,"code":"    it('correctly sets the cert and key if only tlsCertificateKeyFile is provided', function () {\n      const optsFromObject = parseOptions('mongodb://localhost/', {\n        tlsCertificateKeyFile: 'testCertKey.pem'\n      });\n      expect(optsFromObject).to.have.property('cert', 'cert key');\n      expect(optsFromObject).to.have.property('key', 'cert key');\n      const optsFromUri = parseOptions('mongodb://localhost?tlsCertificateKeyFile=testCertKey.pem');\n      expect(optsFromUri).to.have.property('cert', 'cert key');\n      expect(optsFromUri).to.have.property('key', 'cert key');\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"correctly sets the cert and key if both tlsCertificateKeyFile and tlsCertificateFile is provided","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":396,"column":104,"index":16487},"line":396,"code":"    it('correctly sets the cert and key if both tlsCertificateKeyFile and tlsCertificateFile is provided', function () {\n      const optsFromObject = parseOptions('mongodb://localhost/', {\n        tlsCertificateKeyFile: 'testKey.pem',\n        tlsCertificateFile: 'testCert.pem'\n      });\n      expect(optsFromObject).to.have.property('cert', 'test cert');\n      expect(optsFromObject).to.have.property('key', 'test key');\n      const optsFromUri = parseOptions('mongodb://localhost?tlsCertificateKeyFile=testKey.pem&tlsCertificateFile=testCert.pem');\n      expect(optsFromUri).to.have.property('cert', 'test cert');\n      expect(optsFromUri).to.have.property('key', 'test key');\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"throws an error if multiple tls parameters are not all set to the same value","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":408,"column":82,"index":17158},"line":408,"code":"  it('throws an error if multiple tls parameters are not all set to the same value', () => {\n    expect(() => parseOptions('mongodb://localhost?tls=true&tls=false')).to.throw('All values of tls/ssl must be the same.');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"throws an error if multiple ssl parameters are not all set to the same value","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":411,"column":82,"index":17383},"line":411,"code":"  it('throws an error if multiple ssl parameters are not all set to the same value', () => {\n    expect(() => parseOptions('mongodb://localhost?ssl=true&ssl=false')).to.throw('All values of tls/ssl must be the same.');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"throws an error if tls and ssl parameters are not all set to the same value","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":414,"column":81,"index":17607},"line":414,"code":"  it('throws an error if tls and ssl parameters are not all set to the same value', () => {\n    expect(() => parseOptions('mongodb://localhost?tls=true&ssl=false')).to.throw('All values of tls/ssl must be the same.');\n    expect(() => parseOptions('mongodb://localhost?tls=false&ssl=true')).to.throw('All values of tls/ssl must be the same.');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"correctly sets tls if multiple tls parameters are all set to the same value","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":418,"column":81,"index":17957},"line":418,"code":"  it('correctly sets tls if multiple tls parameters are all set to the same value', () => {\n    expect(parseOptions('mongodb://localhost?tls=true&tls=true')).to.have.property('tls', true);\n    expect(parseOptions('mongodb://localhost?tls=false&tls=false')).to.have.property('tls', false);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"correctly sets tls if multiple ssl parameters are all set to the same value","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":422,"column":81,"index":18252},"line":422,"code":"  it('correctly sets tls if multiple ssl parameters are all set to the same value', () => {\n    expect(parseOptions('mongodb://localhost?ssl=true&ssl=true')).to.have.property('tls', true);\n    expect(parseOptions('mongodb://localhost?ssl=false&ssl=false')).to.have.property('tls', false);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"correctly sets tls if tls and ssl parameters are all set to the same value","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":426,"column":80,"index":18546},"line":426,"code":"  it('correctly sets tls if tls and ssl parameters are all set to the same value', () => {\n    expect(parseOptions('mongodb://localhost?ssl=true&tls=true')).to.have.property('tls', true);\n    expect(parseOptions('mongodb://localhost?ssl=false&tls=false')).to.have.property('tls', false);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"transforms tlsInsecure correctly","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":430,"column":38,"index":18798},"line":430,"code":"  it('transforms tlsInsecure correctly', function () {\n    const optionsTrue = parseOptions('mongodb://localhost/', {\n      tlsInsecure: true\n    });\n    expect(optionsTrue.rejectUnauthorized).to.equal(false);\n    expect(optionsTrue.checkServerIdentity).to.be.a('function');\n    expect(optionsTrue.checkServerIdentity()).to.equal(undefined);\n    const optionsFalse = parseOptions('mongodb://localhost/', {\n      tlsInsecure: false\n    });\n    expect(optionsFalse.rejectUnauthorized).to.equal(true);\n    expect(optionsFalse.checkServerIdentity).to.equal(undefined);\n    const optionsUndefined = parseOptions('mongodb://localhost/');\n    expect(optionsUndefined.rejectUnauthorized).to.equal(undefined);\n    expect(optionsUndefined.checkServerIdentity).to.equal(undefined);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"can be set when passed in as an array in the options object","suites":["MongoOptions","compressors"],"updatePoint":{"line":447,"column":67,"index":19644},"line":447,"code":"    it('can be set when passed in as an array in the options object', function () {\n      const clientViaOpt = new MongoClient('mongodb://localhost', {\n        compressors: ['zlib', 'snappy']\n      });\n      expect(clientViaOpt.options).to.have.property('compressors').deep.equal(['zlib', 'snappy', 'none']);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"can be set when passed in as a comma-delimited string in the options object or URI","suites":["MongoOptions","compressors"],"updatePoint":{"line":453,"column":90,"index":19984},"line":453,"code":"    it('can be set when passed in as a comma-delimited string in the options object or URI', function () {\n      const clientViaOpt = new MongoClient('mongodb://localhost', {\n        compressors: 'zlib,snappy'\n      });\n      const clientViaUri = new MongoClient('mongodb://localhost?compressors=zlib,snappy');\n      expect(clientViaOpt.options).to.have.property('compressors').deep.equal(['zlib', 'snappy', 'none']);\n      expect(clientViaUri.options).to.have.property('compressors').deep.equal(['zlib', 'snappy', 'none']);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should validate that a string or an array of strings is provided as input","suites":["MongoOptions","compressors"],"updatePoint":{"line":461,"column":81,"index":20508},"line":461,"code":"    it('should validate that a string or an array of strings is provided as input', function () {\n      expect(() => new MongoClient('mongodb://localhost', {\n        compressors: {\n          zlib: true\n        }\n      })).to.throw(/^compressors must be an array or a comma-delimited list of strings/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if an unrecognized compressor is specified","suites":["MongoOptions","compressors"],"updatePoint":{"line":468,"column":72,"index":20809},"line":468,"code":"    it('should throw an error if an unrecognized compressor is specified', function () {\n      const expectedErrRegex = /not a valid compression mechanism/;\n      expect(() => new MongoClient('mongodb://localhost', {\n        compressors: ['invalid']\n      })).to.throw(expectedErrRegex);\n      expect(() => new MongoClient('mongodb://localhost', {\n        compressors: 'invalid'\n      })).to.throw(expectedErrRegex);\n      expect(() => new MongoClient('mongodb://localhost?compressors=invalid')).to.throw(expectedErrRegex);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"is supported as a client option when it is a valid ServerApiVersion string","suites":["MongoOptions","serverApi"],"updatePoint":{"line":480,"column":82,"index":21395},"line":480,"code":"    it('is supported as a client option when it is a valid ServerApiVersion string', function () {\n      const validVersions = Object.values(ServerApiVersion);\n      expect(validVersions.length).to.be.at.least(1);\n      for (const version of validVersions) {\n        const result = parseOptions('mongodb://localhost/', {\n          serverApi: version\n        });\n        expect(result).to.have.property('serverApi').deep.equal({\n          version\n        });\n      }\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"is supported as a client option when it is an object with a valid version property","suites":["MongoOptions","serverApi"],"updatePoint":{"line":492,"column":90,"index":21877},"line":492,"code":"    it('is supported as a client option when it is an object with a valid version property', function () {\n      const validVersions = Object.values(ServerApiVersion);\n      expect(validVersions.length).to.be.at.least(1);\n      for (const version of validVersions) {\n        const result = parseOptions('mongodb://localhost/', {\n          serverApi: {\n            version\n          }\n        });\n        expect(result).to.have.property('serverApi').deep.equal({\n          version\n        });\n      }\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"is not supported as a client option when it is an invalid string","suites":["MongoOptions","serverApi"],"updatePoint":{"line":506,"column":72,"index":22367},"line":506,"code":"    it('is not supported as a client option when it is an invalid string', function () {\n      expect(() => parseOptions('mongodb://localhost/', {\n        serverApi: 'bad'\n      })).to.throw(/^Invalid server API version=bad;/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"is not supported as a client option when it is a number","suites":["MongoOptions","serverApi"],"updatePoint":{"line":511,"column":63,"index":22594},"line":511,"code":"    it('is not supported as a client option when it is a number', function () {\n      expect(() => parseOptions('mongodb://localhost/', {\n        serverApi: 1\n      })).to.throw(/^Invalid `serverApi` property;/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"is not supported as a client option when it is an object without a specified version","suites":["MongoOptions","serverApi"],"updatePoint":{"line":516,"column":92,"index":22844},"line":516,"code":"    it('is not supported as a client option when it is an object without a specified version', function () {\n      expect(() => parseOptions('mongodb://localhost/', {\n        serverApi: {}\n      })).to.throw(/^Invalid `serverApi` property;/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"is not supported as a client option when it is an object with an invalid specified version","suites":["MongoOptions","serverApi"],"updatePoint":{"line":521,"column":98,"index":23101},"line":521,"code":"    it('is not supported as a client option when it is an object with an invalid specified version', function () {\n      expect(() => parseOptions('mongodb://localhost/', {\n        serverApi: {\n          version: 1\n        }\n      })).to.throw(/^Invalid server API version=1;/);\n      expect(() => parseOptions('mongodb://localhost/', {\n        serverApi: {\n          version: 'bad'\n        }\n      })).to.throw(/^Invalid server API version=bad;/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"is not supported as a URI option even when it is a valid ServerApiVersion string","suites":["MongoOptions","serverApi"],"updatePoint":{"line":533,"column":88,"index":23548},"line":533,"code":"    it('is not supported as a URI option even when it is a valid ServerApiVersion string', function () {\n      expect(() => parseOptions('mongodb://localhost/?serverApi=1')).to.throw('URI cannot contain `serverApi`, it can only be passed to the client');\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should define known defaults in client.options","suites":["MongoOptions","default options"],"updatePoint":{"line":549,"column":54,"index":24805},"line":549,"code":"    it(`should define known defaults in client.options`, () => {\n      const client = new MongoClient('mongodb://localhost');\n      const clientOptions = client.options;\n      for (const [optionName, value] of KNOWN_DEFAULTS) {\n        const camelCaseName = findMatchingKey(clientOptions, optionName);\n        expect(camelCaseName, `did not find a camelcase match for ${optionName}`).to.be.a('string');\n        expect(clientOptions).to.have.property(camelCaseName);\n        if (value !== doNotCheckEq) {\n          expect(clientOptions).to.have.property(camelCaseName).that.deep.equals(value);\n        }\n      }\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"set monitorCommands to false (NODE-3513)","suites":["MongoOptions","default options"],"updatePoint":{"line":561,"column":48,"index":25418},"line":561,"code":"    it('set monitorCommands to false (NODE-3513)', function () {\n      const client = new MongoClient('mongodb://localhost');\n      const clientOptions = client.options;\n      expect(clientOptions).to.have.property('monitorCommands', false);\n      expect(client.s.options).to.have.property('monitorCommands', false);\n      expect(client).to.have.property('monitorCommands', false);\n      const optionsSym = getSymbolFrom(client, 'options');\n      expect(client[optionsSym]).to.have.property('monitorCommands', false);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"respects monitorCommands option passed in","suites":["MongoOptions","default options"],"updatePoint":{"line":570,"column":49,"index":25945},"line":570,"code":"    it('respects monitorCommands option passed in', function () {\n      const clientViaOpt = new MongoClient('mongodb://localhost', {\n        monitorCommands: true\n      });\n      const clientViaUri = new MongoClient('mongodb://localhost?monitorCommands=true');\n      const testTable = [[clientViaOpt, clientViaOpt.options], [clientViaUri, clientViaUri.options]];\n      for (const [client, clientOptions] of testTable) {\n        expect(clientOptions).to.have.property('monitorCommands', true);\n        expect(client.s.options).to.have.property('monitorCommands', true);\n        expect(client).to.have.property('monitorCommands', true);\n        const optionsSym = getSymbolFrom(client, 'options');\n        expect(client[optionsSym]).to.have.property('monitorCommands', true);\n      }\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"sets the option","suites":["MongoOptions","when loadBalanced=true is in the URI"],"updatePoint":{"line":586,"column":23,"index":26780},"line":586,"code":"    it('sets the option', function () {\n      const options = parseOptions('mongodb://a/?loadBalanced=true');\n      expect(options.loadBalanced).to.be.true;\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"errors with multiple hosts","suites":["MongoOptions","when loadBalanced=true is in the URI"],"updatePoint":{"line":590,"column":34,"index":26956},"line":590,"code":"    it('errors with multiple hosts', function () {\n      const parse = () => {\n        parseOptions('mongodb://a,b/?loadBalanced=true');\n      };\n      expect(parse).to.throw(/single host/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"errors with a replicaSet option","suites":["MongoOptions","when loadBalanced=true is in the URI"],"updatePoint":{"line":596,"column":39,"index":27160},"line":596,"code":"    it('errors with a replicaSet option', function () {\n      const parse = () => {\n        parseOptions('mongodb://a/?loadBalanced=true&replicaSet=test');\n      };\n      expect(parse).to.throw(/replicaSet/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"errors with a directConnection option","suites":["MongoOptions","when loadBalanced=true is in the URI"],"updatePoint":{"line":602,"column":45,"index":27383},"line":602,"code":"    it('errors with a directConnection option', function () {\n      const parse = () => {\n        parseOptions('mongodb://a/?loadBalanced=true&directConnection=true');\n      };\n      expect(parse).to.throw(/directConnection/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"errors when the option is true","suites":["MongoOptions","when loadBalanced is in the options object"],"updatePoint":{"line":610,"column":38,"index":27687},"line":610,"code":"    it('errors when the option is true', function () {\n      const parse = () => {\n        parseOptions('mongodb://a/', {\n          loadBalanced: true\n        });\n      };\n      expect(parse).to.throw(/URI/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"errors when the option is false","suites":["MongoOptions","when loadBalanced is in the options object"],"updatePoint":{"line":618,"column":39,"index":27905},"line":618,"code":"    it('errors when the option is false', function () {\n      const parse = () => {\n        parseOptions('mongodb://a/', {\n          loadBalanced: false\n        });\n      };\n      expect(parse).to.throw(/URI/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"srvMaxHosts > 0 cannot be combined with LB or ReplicaSet","suites":["MongoOptions","when loadBalanced is in the options object"],"updatePoint":{"line":627,"column":62,"index":28153},"line":627,"code":"  it('srvMaxHosts > 0 cannot be combined with LB or ReplicaSet', () => {\n    expect(() => {\n      new MongoClient('mongodb+srv://localhost?srvMaxHosts=2&replicaSet=repl');\n    }).to.throw(MongoParseError, 'Cannot use srvMaxHosts option with replicaSet');\n    expect(() => {\n      new MongoClient('mongodb+srv://localhost?srvMaxHosts=2&loadBalanced=true');\n    }).to.throw(MongoParseError, 'Cannot limit srv hosts with loadBalanced enabled');\n    expect(() => {\n      new MongoClient('mongodb+srv://localhost', {\n        srvMaxHosts: 2,\n        replicaSet: 'blah'\n      });\n    }).to.throw(MongoParseError, 'Cannot use srvMaxHosts option with replicaSet');\n    expect(() => {\n      new MongoClient('mongodb+srv://localhost?loadBalanced=true', {\n        srvMaxHosts: 2\n      });\n    }).to.throw(MongoParseError, 'Cannot limit srv hosts with loadBalanced enabled');\n\n    // These should not throw.\n    new MongoClient('mongodb+srv://localhost?srvMaxHosts=0&replicaSet=repl');\n    new MongoClient('mongodb+srv://localhost', {\n      srvMaxHosts: 0,\n      replicaSet: 'blah'\n    });\n    new MongoClient('mongodb+srv://localhost?srvMaxHosts=0&loadBalanced=true');\n    new MongoClient('mongodb+srv://localhost?loadBalanced=true', {\n      srvMaxHosts: 0\n    });\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"srvServiceName and srvMaxHosts cannot be used on a non-srv connection string","suites":["MongoOptions","when loadBalanced is in the options object"],"updatePoint":{"line":657,"column":82,"index":29432},"line":657,"code":"  it('srvServiceName and srvMaxHosts cannot be used on a non-srv connection string', () => {\n    expect(() => {\n      new MongoClient('mongodb://localhost?srvMaxHosts=2');\n    }).to.throw(MongoParseError);\n    expect(() => {\n      new MongoClient('mongodb://localhost?srvMaxHosts=0');\n    }).to.throw(MongoParseError);\n    expect(() => {\n      new MongoClient('mongodb://localhost', {\n        srvMaxHosts: 0\n      });\n    }).to.throw(MongoParseError);\n    expect(() => {\n      new MongoClient('mongodb://localhost?srvServiceName=abc');\n    }).to.throw(MongoParseError);\n    expect(() => {\n      new MongoClient('mongodb://localhost', {\n        srvMaxHosts: 2\n      });\n    }).to.throw(MongoParseError);\n    expect(() => {\n      new MongoClient('mongodb://localhost', {\n        srvServiceName: 'abc'\n      });\n    }).to.throw(MongoParseError);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"srvServiceName should error if it is too long","suites":["MongoOptions","when loadBalanced is in the options object"],"updatePoint":{"line":683,"column":51,"index":30250},"line":683,"code":"  it('srvServiceName should error if it is too long', async () => {\n    const options = parseOptions('mongodb+srv://localhost.a.com', {\n      srvServiceName: 'a'.repeat(255)\n    });\n    const error = await resolveSRVRecord(options).catch(error => error);\n    expect(error).to.have.property('code', 'EBADNAME');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"srvServiceName should not error if it is greater than 15 characters as long as the DNS query limit is not surpassed","suites":["MongoOptions","when loadBalanced is in the options object"],"updatePoint":{"line":690,"column":121,"index":30637},"line":690,"code":"  it('srvServiceName should not error if it is greater than 15 characters as long as the DNS query limit is not surpassed', async () => {\n    const options = parseOptions('mongodb+srv://localhost.a.com', {\n      srvServiceName: 'a'.repeat(16)\n    });\n    const error = await resolveSRVRecord(options).catch(error => error);\n\n    // Nothing wrong with the name, just DNE\n    expect(error).to.have.property('code', 'ENOTFOUND');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should set the database name to the dbName in the uri","suites":["MongoOptions","dbName and authSource","in the URI"],"updatePoint":{"line":701,"column":63,"index":31091},"line":701,"code":"      it('should set the database name to the dbName in the uri', () => {\n        const client = new MongoClient('mongodb://u:p@host/myDb');\n        const db = client.db();\n        expect(db).to.have.property('databaseName', 'myDb');\n        expect(client).to.have.nested.property('options.credentials.source', 'myDb');\n      });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should set the database name to the uri pathname and respect the authSource option","suites":["MongoOptions","dbName and authSource","in the URI"],"updatePoint":{"line":707,"column":92,"index":31450},"line":707,"code":"      it('should set the database name to the uri pathname and respect the authSource option', () => {\n        const client = new MongoClient('mongodb://u:p@host/myDb?authSource=myAuthDb');\n        const db = client.db();\n        expect(db).to.have.property('databaseName', 'myDb');\n        expect(client).to.have.nested.property('options.credentials.source', 'myAuthDb');\n      });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should set the database name to the uri pathname and respect the authSource option in options object","suites":["MongoOptions","dbName and authSource","in the URI"],"updatePoint":{"line":713,"column":110,"index":31851},"line":713,"code":"      it('should set the database name to the uri pathname and respect the authSource option in options object', () => {\n        const client = new MongoClient('mongodb://u:p@host/myDb', {\n          authSource: 'myAuthDb'\n        });\n        const db = client.db();\n        expect(db).to.have.property('databaseName', 'myDb');\n        expect(client).to.have.nested.property('options.credentials.source', 'myAuthDb');\n      });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should set the database name to the dbName in the options object","suites":["MongoOptions","dbName and authSource","in the options object"],"updatePoint":{"line":723,"column":74,"index":32296},"line":723,"code":"      it('should set the database name to the dbName in the options object', () => {\n        const client = new MongoClient('mongodb://u:p@host', {\n          dbName: 'myDb'\n        });\n        const db = client.db();\n        expect(db).to.have.property('databaseName', 'myDb');\n        expect(client).to.have.nested.property('options.credentials.source', 'myDb');\n      });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should set the database name to dbName and respect the authSource option","suites":["MongoOptions","dbName and authSource","in the options object"],"updatePoint":{"line":731,"column":82,"index":32678},"line":731,"code":"      it('should set the database name to dbName and respect the authSource option', () => {\n        const client = new MongoClient('mongodb://u:p@host?authSource=myAuthDb', {\n          dbName: 'myDb'\n        });\n        const db = client.db();\n        expect(db).to.have.property('databaseName', 'myDb');\n        expect(client).to.have.nested.property('options.credentials.source', 'myAuthDb');\n      });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should set the database name to dbName and respect the authSource option in options object","suites":["MongoOptions","dbName and authSource","in the options object"],"updatePoint":{"line":739,"column":100,"index":33102},"line":739,"code":"      it('should set the database name to dbName and respect the authSource option in options object', () => {\n        const client = new MongoClient('mongodb://u:p@host', {\n          dbName: 'myDb',\n          authSource: 'myAuthDb'\n        });\n        const db = client.db();\n        expect(db).to.have.property('databaseName', 'myDb');\n        expect(client).to.have.nested.property('options.credentials.source', 'myAuthDb');\n      });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should set the database name to dbName in options object and respect the authSource option in options object","suites":["MongoOptions","dbName and authSource","in the options object"],"updatePoint":{"line":748,"column":118,"index":33558},"line":748,"code":"      it('should set the database name to dbName in options object and respect the authSource option in options object', () => {\n        const client = new MongoClient('mongodb://u:p@host/myIgnoredDb', {\n          dbName: 'myDb',\n          authSource: 'myAuthDb'\n        });\n        const db = client.db();\n        expect(db).to.have.property('databaseName', 'myDb');\n        expect(client).to.have.nested.property('options.credentials.source', 'myAuthDb');\n      });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"sets trySecondaryWrite to true","suites":["AggregateOperation","#constructor","when out is in the options"],"updatePoint":{"line":17,"column":40,"index":443},"line":17,"code":"      it('sets trySecondaryWrite to true', function () {\n        expect(operation.trySecondaryWrite).to.be.true;\n      });","file":"unit/operations/aggregate.test.js","skipped":false,"dir":"test"},{"name":"sets trySecondaryWrite to true","suites":["AggregateOperation","#constructor","when $out is the last stage"],"updatePoint":{"line":27,"column":40,"index":747},"line":27,"code":"      it('sets trySecondaryWrite to true', function () {\n        expect(operation.trySecondaryWrite).to.be.true;\n      });","file":"unit/operations/aggregate.test.js","skipped":false,"dir":"test"},{"name":"sets trySecondaryWrite to false","suites":["AggregateOperation","#constructor","when $out is not the last stage"],"updatePoint":{"line":41,"column":41,"index":1115},"line":41,"code":"      it('sets trySecondaryWrite to false', function () {\n        expect(operation.trySecondaryWrite).to.be.false;\n      });","file":"unit/operations/aggregate.test.js","skipped":false,"dir":"test"},{"name":"sets trySecondaryWrite to true","suites":["AggregateOperation","#constructor","when $merge is the last stage"],"updatePoint":{"line":53,"column":40,"index":1452},"line":53,"code":"      it('sets trySecondaryWrite to true', function () {\n        expect(operation.trySecondaryWrite).to.be.true;\n      });","file":"unit/operations/aggregate.test.js","skipped":false,"dir":"test"},{"name":"sets trySecondaryWrite to false","suites":["AggregateOperation","#constructor","when $merge is not the last stage"],"updatePoint":{"line":69,"column":41,"index":1852},"line":69,"code":"      it('sets trySecondaryWrite to false', function () {\n        expect(operation.trySecondaryWrite).to.be.false;\n      });","file":"unit/operations/aggregate.test.js","skipped":false,"dir":"test"},{"name":"sets trySecondaryWrite to false","suites":["AggregateOperation","#constructor","when no writable stages in empty pipeline"],"updatePoint":{"line":77,"column":41,"index":2142},"line":77,"code":"      it('sets trySecondaryWrite to false', function () {\n        expect(operation.trySecondaryWrite).to.be.false;\n      });","file":"unit/operations/aggregate.test.js","skipped":false,"dir":"test"},{"name":"sets trySecondaryWrite to false","suites":["AggregateOperation","#constructor","when no writable stages"],"updatePoint":{"line":89,"column":41,"index":2471},"line":89,"code":"      it('sets trySecondaryWrite to false', function () {\n        expect(operation.trySecondaryWrite).to.be.false;\n      });","file":"unit/operations/aggregate.test.js","skipped":false,"dir":"test"},{"name":"sets nameOnly to true","suites":["ListCollectionsOperation","#constructor","when nameOnly is provided","when nameOnly is true"],"updatePoint":{"line":18,"column":33,"index":524},"line":18,"code":"        it('sets nameOnly to true', function () {\n          expect(operation).to.have.property('nameOnly', true);\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets nameOnly to false","suites":["ListCollectionsOperation","#constructor","when nameOnly is provided","when nameOnly is false"],"updatePoint":{"line":27,"column":34,"index":840},"line":27,"code":"        it('sets nameOnly to false', function () {\n          expect(operation).to.have.property('nameOnly', false);\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets authorizedCollections to true","suites":["ListCollectionsOperation","#constructor","when authorizedCollections is provided","when authorizedCollections is true"],"updatePoint":{"line":38,"column":46,"index":1269},"line":38,"code":"        it('sets authorizedCollections to true', function () {\n          expect(operation).to.have.property('authorizedCollections', true);\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets authorizedCollections to false","suites":["ListCollectionsOperation","#constructor","when authorizedCollections is provided","when authorizedCollections is false"],"updatePoint":{"line":47,"column":47,"index":1637},"line":47,"code":"        it('sets authorizedCollections to false', function () {\n          expect(operation).to.have.property('authorizedCollections', false);\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets nameOnly to false","suites":["ListCollectionsOperation","#constructor","when no options are provided"],"updatePoint":{"line":56,"column":32,"index":1944},"line":56,"code":"      it('sets nameOnly to false', function () {\n        expect(operation).to.have.property('nameOnly', false);\n      });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets authorizedCollections to false","suites":["ListCollectionsOperation","#constructor","when no options are provided"],"updatePoint":{"line":59,"column":45,"index":2079},"line":59,"code":"      it('sets authorizedCollections to false', function () {\n        expect(operation).to.have.property('authorizedCollections', false);\n      });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"does not set a comment on the command","suites":["ListCollectionsOperation","#generateCommand","when comment is provided","when the wireVersion < 9"],"updatePoint":{"line":67,"column":49,"index":2400},"line":67,"code":"        it('does not set a comment on the command', function () {\n          const operation = new ListCollectionsOperation(db, {}, {\n            dbName: db,\n            comment: 'test comment'\n          });\n          const command = operation.generateCommand(8);\n          expect(command).not.to.haveOwnProperty('comment');\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets a comment on the command","suites":["ListCollectionsOperation","#generateCommand","when comment is provided","when the wireVersion >= 9"],"updatePoint":{"line":77,"column":41,"index":2795},"line":77,"code":"        it('sets a comment on the command', function () {\n          const operation = new ListCollectionsOperation(db, {}, {\n            dbName: db,\n            comment: 'test comment'\n          });\n          const command = operation.generateCommand(9);\n          expect(command).to.have.property('comment').that.equals('test comment');\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets nameOnly to true","suites":["ListCollectionsOperation","#generateCommand","when nameOnly is provided","when nameOnly is true"],"updatePoint":{"line":93,"column":33,"index":3387},"line":93,"code":"        it('sets nameOnly to true', function () {\n          expect(operation.generateCommand(8)).to.deep.equal({\n            listCollections: 1,\n            cursor: {},\n            filter: {},\n            nameOnly: true,\n            authorizedCollections: false\n          });\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets nameOnly to false","suites":["ListCollectionsOperation","#generateCommand","when nameOnly is provided","when nameOnly is false"],"updatePoint":{"line":108,"column":34,"index":3865},"line":108,"code":"        it('sets nameOnly to false', function () {\n          expect(operation.generateCommand(8)).to.deep.equal({\n            listCollections: 1,\n            cursor: {},\n            filter: {},\n            nameOnly: false,\n            authorizedCollections: false\n          });\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets authorizedCollections to true","suites":["ListCollectionsOperation","#generateCommand","when authorizedCollections is provided","when authorizedCollections is true"],"updatePoint":{"line":125,"column":46,"index":4456},"line":125,"code":"        it('sets authorizedCollections to true', function () {\n          expect(operation.generateCommand(8)).to.deep.equal({\n            listCollections: 1,\n            cursor: {},\n            filter: {},\n            nameOnly: false,\n            authorizedCollections: true\n          });\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets authorizedCollections to false","suites":["ListCollectionsOperation","#generateCommand","when authorizedCollections is provided","when authorizedCollections is false"],"updatePoint":{"line":140,"column":47,"index":4973},"line":140,"code":"        it('sets authorizedCollections to false', function () {\n          expect(operation.generateCommand(8)).to.deep.equal({\n            listCollections: 1,\n            cursor: {},\n            filter: {},\n            nameOnly: false,\n            authorizedCollections: false\n          });\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets nameOnly and authorizedCollections properties to false","suites":["ListCollectionsOperation","#generateCommand","when no options are provided"],"updatePoint":{"line":155,"column":69,"index":5466},"line":155,"code":"      it('sets nameOnly and authorizedCollections properties to false', function () {\n        expect(operation.generateCommand(8)).to.deep.equal({\n          listCollections: 1,\n          cursor: {},\n          filter: {},\n          nameOnly: false,\n          authorizedCollections: false\n        });\n      });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"should throw if given a null address","suites":["ServerDescription","constructor()"],"updatePoint":{"line":7,"column":44,"index":373},"line":7,"code":"    it('should throw if given a null address', () => {\n      // @ts-expect-error: Passing nullish value to prove error will be thrown\n      expect(() => new ServerDescription(null)).to.throw(MongoRuntimeError);\n      // @ts-expect-error: Passing nullish value to prove error will be thrown\n      expect(() => new ServerDescription()).to.throw(MongoRuntimeError);\n    });","file":"unit/sdam/server_description.test.ts","skipped":false,"dir":"test"},{"name":"should throw if given an empty string for an address","suites":["ServerDescription","constructor()"],"updatePoint":{"line":13,"column":60,"index":760},"line":13,"code":"    it('should throw if given an empty string for an address', () => {\n      expect(() => new ServerDescription('')).to.throw(MongoRuntimeError);\n    });","file":"unit/sdam/server_description.test.ts","skipped":false,"dir":"test"},{"name":"should normalize an IPv6 address with brackets and toLowered characters","suites":["ServerDescription","error equality"],"updatePoint":{"line":70,"column":77,"index":2628},"line":70,"code":"  it('should normalize an IPv6 address with brackets and toLowered characters', function () {\n    const description = new ServerDescription('[ABCD:f::abcd:abcd:abcd:abcd]:1234');\n    expect(description.host).to.equal('[abcd:f::abcd:abcd:abcd:abcd]'); // IPv6 Addresses must always be bracketed if there is a port\n    expect(description.port).to.equal(1234);\n  });","file":"unit/sdam/server_description.test.ts","skipped":false,"dir":"test"},{"name":"should normalize an IPv6 address with brackets and toLowered characters even when the port is omitted","suites":["ServerDescription","error equality"],"updatePoint":{"line":75,"column":107,"index":3022},"line":75,"code":"  it('should normalize an IPv6 address with brackets and toLowered characters even when the port is omitted', function () {\n    const description = new ServerDescription('[ABCD:f::abcd:abcd:abcd:abcd]');\n    expect(description.host).to.equal('[abcd:f::abcd:abcd:abcd:abcd]');\n    expect(description.port).to.equal(27017);\n  });","file":"unit/sdam/server_description.test.ts","skipped":false,"dir":"test"},{"name":"returns an empty array","suites":["server selection","#sameServerSelector","when the server is unknown"],"updatePoint":{"line":68,"column":32,"index":1849},"line":68,"code":"      it('returns an empty array', function () {\n        expect(servers).to.be.empty;\n      });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"returns the server","suites":["server selection","#sameServerSelector","when the server is not unknown"],"updatePoint":{"line":76,"column":28,"index":2094},"line":76,"code":"      it('returns the server', function () {\n        expect(servers).to.deep.equal([primary]);\n      });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"returns an empty array","suites":["server selection","#sameServerSelector","when no server description provided"],"updatePoint":{"line":84,"column":32,"index":2354},"line":84,"code":"      it('returns an empty array', function () {\n        expect(servers).to.be.empty;\n      });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"returns an empty array","suites":["server selection","#sameServerSelector","when the server is not the same"],"updatePoint":{"line":92,"column":32,"index":2606},"line":92,"code":"      it('returns an empty array', function () {\n        expect(servers).to.be.empty;\n      });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"uses the provided read preference","suites":["server selection","#secondaryWritableServerSelector","when the topology is a replica set","when the common server version is >= 5.0","when a read preference is provided"],"updatePoint":{"line":107,"column":47,"index":3583},"line":107,"code":"          it('uses the provided read preference', function () {\n            expect(servers).to.deep.equal([secondary]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a primary","suites":["server selection","#secondaryWritableServerSelector","when the topology is a replica set","when the common server version is >= 5.0","when a read preference is not provided"],"updatePoint":{"line":114,"column":31,"index":3977},"line":114,"code":"          it('selects a primary', function () {\n            expect(servers).to.deep.equal([primary]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a primary","suites":["server selection","#secondaryWritableServerSelector","when the topology is a replica set","when the common server version is < 5.0","when a read preference is provided"],"updatePoint":{"line":124,"column":31,"index":4689},"line":124,"code":"          it('selects a primary', function () {\n            expect(servers).to.deep.equal([primary]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a primary","suites":["server selection","#secondaryWritableServerSelector","when the topology is a replica set","when the common server version is < 5.0","when read preference is not provided"],"updatePoint":{"line":131,"column":31,"index":5083},"line":131,"code":"          it('selects a primary', function () {\n            expect(servers).to.deep.equal([primary]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a primary","suites":["server selection","#secondaryWritableServerSelector","when the topology is a replica set","when a common wire version is not provided"],"updatePoint":{"line":140,"column":29,"index":5693},"line":140,"code":"        it('selects a primary', function () {\n          expect(servers).to.deep.equal([primary]);\n        });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a mongos","suites":["server selection","#secondaryWritableServerSelector","when the topology is sharded","when the common server version is >= 5.0","when a read preference is provided"],"updatePoint":{"line":153,"column":30,"index":6531},"line":153,"code":"          it('selects a mongos', function () {\n            expect(servers).to.deep.equal([mongos]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a mongos","suites":["server selection","#secondaryWritableServerSelector","when the topology is sharded","when the common server version is >= 5.0","when a read preference is not provided"],"updatePoint":{"line":160,"column":30,"index":6921},"line":160,"code":"          it('selects a mongos', function () {\n            expect(servers).to.deep.equal([mongos]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a mongos","suites":["server selection","#secondaryWritableServerSelector","when the topology is sharded","when the common server version is < 5.0","when a read preference is provided"],"updatePoint":{"line":170,"column":30,"index":7617},"line":170,"code":"          it('selects a mongos', function () {\n            expect(servers).to.deep.equal([mongos]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a mongos","suites":["server selection","#secondaryWritableServerSelector","when the topology is sharded","when the common server version is < 5.0","when read preference is not provided"],"updatePoint":{"line":177,"column":30,"index":8009},"line":177,"code":"          it('selects a mongos', function () {\n            expect(servers).to.deep.equal([mongos]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a mongos","suites":["server selection","#secondaryWritableServerSelector","when the topology is sharded","when a common wire version is not provided"],"updatePoint":{"line":186,"column":28,"index":8568},"line":186,"code":"        it('selects a mongos', function () {\n          expect(servers).to.deep.equal([mongos]);\n        });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a load balancer","suites":["server selection","#secondaryWritableServerSelector","when the topology is load balanced","when the common server version is >= 5.0","when a read preference is provided"],"updatePoint":{"line":199,"column":37,"index":9435},"line":199,"code":"          it('selects a load balancer', function () {\n            expect(servers).to.deep.equal([loadBalancer]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a load balancer","suites":["server selection","#secondaryWritableServerSelector","when the topology is load balanced","when the common server version is >= 5.0","when a read preference is not provided"],"updatePoint":{"line":206,"column":37,"index":9838},"line":206,"code":"          it('selects a load balancer', function () {\n            expect(servers).to.deep.equal([loadBalancer]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a load balancer","suites":["server selection","#secondaryWritableServerSelector","when the topology is load balanced","when the common server version is < 5.0","when a read preference is provided"],"updatePoint":{"line":216,"column":37,"index":10552},"line":216,"code":"          it('selects a load balancer', function () {\n            expect(servers).to.deep.equal([loadBalancer]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a load balancer","suites":["server selection","#secondaryWritableServerSelector","when the topology is load balanced","when the common server version is < 5.0","when read preference is not provided"],"updatePoint":{"line":223,"column":37,"index":10957},"line":223,"code":"          it('selects a load balancer', function () {\n            expect(servers).to.deep.equal([loadBalancer]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a load balancer","suites":["server selection","#secondaryWritableServerSelector","when the topology is load balanced","when a common wire version is not provided"],"updatePoint":{"line":232,"column":35,"index":11534},"line":232,"code":"        it('selects a load balancer', function () {\n          expect(servers).to.deep.equal([loadBalancer]);\n        });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a standalone","suites":["server selection","#secondaryWritableServerSelector","when the topology is single","when the common server version is >= 5.0","when a read preference is provided"],"updatePoint":{"line":245,"column":34,"index":12379},"line":245,"code":"          it('selects a standalone', function () {\n            expect(servers).to.deep.equal([single]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a standalone","suites":["server selection","#secondaryWritableServerSelector","when the topology is single","when the common server version is >= 5.0","when a read preference is not provided"],"updatePoint":{"line":252,"column":34,"index":12773},"line":252,"code":"          it('selects a standalone', function () {\n            expect(servers).to.deep.equal([single]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a standalone","suites":["server selection","#secondaryWritableServerSelector","when the topology is single","when the common server version is < 5.0","when a read preference is provided"],"updatePoint":{"line":262,"column":34,"index":13472},"line":262,"code":"          it('selects a standalone', function () {\n            expect(servers).to.deep.equal([single]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a standalone","suites":["server selection","#secondaryWritableServerSelector","when the topology is single","when the common server version is < 5.0","when read preference is not provided"],"updatePoint":{"line":269,"column":34,"index":13868},"line":269,"code":"          it('selects a standalone', function () {\n            expect(servers).to.deep.equal([single]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a standalone","suites":["server selection","#secondaryWritableServerSelector","when the topology is single","when a common wire version is not provided"],"updatePoint":{"line":278,"column":32,"index":14430},"line":278,"code":"        it('selects a standalone', function () {\n          expect(servers).to.deep.equal([single]);\n        });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"includes servers inside the latency window with default localThresholdMS","suites":["server selection","#secondaryWritableServerSelector","localThresholdMS is respected as an option"],"updatePoint":{"line":312,"column":82,"index":15680},"line":312,"code":"      it('includes servers inside the latency window with default localThresholdMS', function () {\n        const topologyDescription = new TopologyDescription(TopologyType.Single, serverDescriptions, 'test', MIN_SECONDARY_WRITE_WIRE_VERSION, new ObjectId(), MIN_SECONDARY_WRITE_WIRE_VERSION);\n        const selector = secondaryWritableServerSelector();\n        const servers = selector(topologyDescription, Array.from(serverDescriptions.values()));\n        expect(servers).to.have.lengthOf(2);\n        const selectedAddresses = new Set(servers.map(({\n          address\n        }) => address));\n        expect(selectedAddresses.has(serverDescription1.address)).to.be.true;\n        expect(selectedAddresses.has(serverDescription2.address)).to.be.true;\n        expect(selectedAddresses.has(serverDescription3.address)).to.be.false;\n      });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"includes servers inside the latency window with custom localThresholdMS","suites":["server selection","#secondaryWritableServerSelector","localThresholdMS is respected as an option"],"updatePoint":{"line":324,"column":81,"index":16518},"line":324,"code":"      it('includes servers inside the latency window with custom localThresholdMS', function () {\n        const topologyDescription = new TopologyDescription(TopologyType.Single, serverDescriptions, 'test', MIN_SECONDARY_WRITE_WIRE_VERSION, new ObjectId(), MIN_SECONDARY_WRITE_WIRE_VERSION, {\n          localThresholdMS: 5\n        });\n        const selector = secondaryWritableServerSelector();\n        const servers = selector(topologyDescription, Array.from(serverDescriptions.values()));\n        expect(servers).to.have.lengthOf(1);\n        const selectedAddresses = new Set(servers.map(({\n          address\n        }) => address));\n        expect(selectedAddresses.has(serverDescription1.address)).to.be.true;\n        expect(selectedAddresses.has(serverDescription2.address)).to.be.false;\n        expect(selectedAddresses.has(serverDescription3.address)).to.be.false;\n      });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"should always return a valid value for `intervalMS`","suites":["Mongos SRV Polling","SrvPoller"],"updatePoint":{"line":45,"column":59,"index":1467},"line":45,"code":"    it('should always return a valid value for `intervalMS`', function () {\n      const poller = new SrvPoller({\n        srvHost: SRV_HOST\n      });\n      expect(poller).property('intervalMS').to.equal(60000);\n    });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should emit event, disable haMode, and schedule another poll","suites":["Mongos SRV Polling","SrvPoller","success"],"updatePoint":{"line":52,"column":70,"index":1734},"line":52,"code":"      it('should emit event, disable haMode, and schedule another poll', async function () {\n        const records = [srvRecord('jalad.tanagra.com'), srvRecord('thebeast.tanagra.com')];\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST,\n          heartbeatFrequencyMS: 100\n        });\n        const willBeDiscovery = once(poller, 'srvRecordDiscovery');\n        sinon.stub(poller, 'schedule');\n        poller.haMode = true;\n        expect(poller).to.have.property('haMode', true);\n        poller.success(records);\n        const [e] = await willBeDiscovery;\n        expect(e).to.be.an.instanceOf(SrvPollingEvent).and.to.have.property('srvRecords').that.deep.equals(records);\n        expect(poller.schedule).to.have.been.calledOnce;\n        expect(poller).to.have.property('haMode', false);\n      });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should enable haMode and schedule","suites":["Mongos SRV Polling","SrvPoller","failure"],"updatePoint":{"line":70,"column":43,"index":2568},"line":70,"code":"      it('should enable haMode and schedule', async () => {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        sinon.stub(poller, 'schedule');\n        poller.failure('Some kind of failure');\n        expect(poller.schedule).to.have.been.calledOnce;\n        expect(poller).to.have.property('haMode', true);\n      });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should do something if dns API breaks","suites":["Mongos SRV Polling","SrvPoller","failure"],"updatePoint":{"line":79,"column":47,"index":2923},"line":79,"code":"      it('should do something if dns API breaks', async function () {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST,\n          loggerLevel: 'error',\n          heartbeatFrequencyMS: 100\n        });\n\n        // set haMode to make the poller use the 100ms heartbeat, otherwise this test would take 60 secs\n        poller.haMode = true;\n\n        // @ts-expect-error: Testing what happens if node breaks DNS API\n        sinon.stub(dns.promises, 'resolveSrv').resolves(null);\n        const loggerError = sinon.stub(poller.logger, 'error').returns();\n        poller.schedule();\n        await sleep(130);\n        clearTimeout(poller._timeout);\n        expect(loggerError).to.have.been.calledOnceWith(sinon.match(/Unexpected MongoRuntimeError/));\n      });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should throw if srvHost is not passed in","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":99,"column":50,"index":3738},"line":99,"code":"      it('should throw if srvHost is not passed in', function () {\n        expect(() => new SrvPoller()).to.throw(MongoDriverError);\n        expect(() => new SrvPoller({})).to.throw(MongoDriverError);\n      });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should poll dns srv records","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":103,"column":37,"index":3936},"line":103,"code":"      it('should poll dns srv records', async function () {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        sinon.stub(dns.promises, 'resolveSrv').resolves([srvRecord('iLoveJavascript.lots')]);\n        await poller._poll();\n        clearTimeout(poller._timeout);\n        expect(dns.promises.resolveSrv).to.have.been.calledOnce.and.to.have.been.calledWith(`_mongodb._tcp.${SRV_HOST}`);\n      });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should not succeed or fail if poller was stopped","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":112,"column":58,"index":4391},"line":112,"code":"      it('should not succeed or fail if poller was stopped', async function () {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        stubDns(null, []);\n        stubPoller(poller);\n        const pollerPromise = poller._poll();\n        poller.generation += 1;\n        await pollerPromise;\n        expect(poller.success).to.not.have.been.called;\n        expect(poller.failure).to.not.have.been.called;\n        expect(poller.parentDomainMismatch).to.not.have.been.called;\n      });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should fail if dns returns error","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":125,"column":42,"index":4888},"line":125,"code":"      it('should fail if dns returns error', async () => {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        stubDns(new Error('Some Error'));\n        stubPoller(poller);\n        await poller._poll();\n        expect(poller.success).to.not.have.been.called;\n        expect(poller.failure).to.have.been.calledOnce.and.calledWith('DNS error');\n        expect(poller.parentDomainMismatch).to.not.have.been.called;\n      });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should fail if dns returns no records","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":136,"column":47,"index":5350},"line":136,"code":"      it('should fail if dns returns no records', async () => {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        stubDns(null, []);\n        stubPoller(poller);\n        await poller._poll();\n        expect(poller.success).to.not.have.been.called;\n        expect(poller.failure).to.have.been.calledOnce.and.calledWith('No valid addresses found at host');\n        expect(poller.parentDomainMismatch).to.not.have.been.called;\n      });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should fail if dns returns no records that match parent domain","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":147,"column":72,"index":5845},"line":147,"code":"      it('should fail if dns returns no records that match parent domain', async () => {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        const records = [srvRecord('jalad.tanagra.org'), srvRecord('shaka.walls.com')];\n        stubDns(null, records);\n        stubPoller(poller);\n        await poller._poll();\n        expect(poller.success).to.not.have.been.called;\n        expect(poller.failure).to.have.been.calledOnce.and.calledWith('No valid addresses found at host');\n        expect(poller.parentDomainMismatch).to.have.been.calledTwice.and.calledWith(records[0]).and.calledWith(records[1]);\n      });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should succeed when valid records are returned by dns","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":159,"column":63,"index":6479},"line":159,"code":"      it('should succeed when valid records are returned by dns', async () => {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        const records = [srvRecord('jalad.tanagra.com'), srvRecord('thebeast.tanagra.com')];\n        stubDns(null, records);\n        stubPoller(poller);\n        await poller._poll();\n        expect(poller.success).to.have.been.calledOnce.and.calledWithMatch(records);\n        expect(poller.failure).to.not.have.been.called;\n        expect(poller.parentDomainMismatch).to.not.have.been.called;\n      });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should succeed when some valid records are returned and some do not match parent domain","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":171,"column":97,"index":7075},"line":171,"code":"      it('should succeed when some valid records are returned and some do not match parent domain', async () => {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        const records = [srvRecord('jalad.tanagra.com'), srvRecord('thebeast.walls.com')];\n        stubDns(null, records);\n        stubPoller(poller);\n        await poller._poll();\n        expect(poller.success).to.have.been.calledOnce.and.calledWithMatch([records[0]]);\n        expect(poller.failure).to.not.have.been.called;\n        expect(poller.parentDomainMismatch).to.have.been.calledOnce.and.calledWith(records[1]);\n      });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should not make an srv poller if there is no srv host","suites":["Mongos SRV Polling","topology"],"updatePoint":{"line":197,"column":61,"index":7962},"line":197,"code":"    it('should not make an srv poller if there is no srv host', function () {\n      const srvPoller = new FakeSrvPoller({\n        srvHost: SRV_HOST\n      });\n      const topology = new Topology(['localhost:27017', 'localhost:27018'], {\n        srvPoller\n      });\n      expect(topology).to.not.have.property('srvPoller');\n    });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should make an srvPoller if there is an srvHost","suites":["Mongos SRV Polling","topology"],"updatePoint":{"line":206,"column":55,"index":8286},"line":206,"code":"    it('should make an srvPoller if there is an srvHost', function () {\n      const srvPoller = new FakeSrvPoller({\n        srvHost: SRV_HOST\n      });\n      const topology = new Topology(['localhost:27017', 'localhost:27018'], {\n        srvHost: SRV_HOST,\n        srvPoller\n      });\n      expect(topology.s).to.have.property('srvPoller').that.equals(srvPoller);\n    });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should only start polling if topology description changes to sharded","suites":["Mongos SRV Polling","topology"],"updatePoint":{"line":216,"column":76,"index":8679},"line":216,"code":"    it('should only start polling if topology description changes to sharded', function () {\n      const srvPoller = new FakeSrvPoller({\n        srvHost: SRV_HOST\n      });\n      sinon.stub(srvPoller, 'start');\n      const topology = new Topology(['localhost:27017', 'localhost:27018'], {\n        srvHost: SRV_HOST,\n        srvPoller\n      });\n      const topologyDescriptions = [new TopologyDescription(TopologyType.Unknown), new TopologyDescription(TopologyType.Unknown), new TopologyDescription(TopologyType.Sharded), new TopologyDescription(TopologyType.Sharded)];\n      function emit(prev, current) {\n        topology.emit('topologyDescriptionChanged', new sdamEvents.TopologyDescriptionChangedEvent(topology.s.id, prev, current));\n      }\n      expect(srvPoller.start).to.not.have.been.called;\n      emit(topologyDescriptions[0], topologyDescriptions[1]);\n      expect(srvPoller.start).to.not.have.been.called;\n      emit(topologyDescriptions[1], topologyDescriptions[2]);\n      expect(srvPoller.start).to.have.been.calledOnce;\n      emit(topologyDescriptions[2], topologyDescriptions[3]);\n      expect(srvPoller.start).to.have.been.calledOnce;\n    });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should correctly pass appname","suites":["Topology (unit)","client metadata"],"updatePoint":{"line":65,"column":37,"index":1481},"line":65,"code":"    it('should correctly pass appname', function (done) {\n      const server = new Topology([`localhost:27017`], {\n        metadata: makeClientMetadata({\n          appName: 'My application name'\n        })\n      });\n      expect(server.clientMetadata.application.name).to.equal('My application name');\n      done();\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should report the correct platform in client metadata","suites":["Topology (unit)","client metadata"],"updatePoint":{"line":74,"column":61,"index":1829},"line":74,"code":"    it('should report the correct platform in client metadata', function (done) {\n      const helloRequests = [];\n      mockServer.setMessageHandler(request => {\n        const doc = request.document;\n        if (isHello(doc)) {\n          helloRequests.push(doc);\n          request.reply(mock.HELLO);\n        } else {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      client = new MongoClient(`mongodb://${mockServer.uri()}/`);\n      client.connect(err => {\n        expect(err).to.not.exist;\n        client.db().command({\n          ping: 1\n        }, err => {\n          expect(err).to.not.exist;\n          expect(helloRequests).to.have.length.greaterThan(1);\n          helloRequests.forEach(helloRequest => expect(helloRequest).nested.property('client.platform').to.match(/unified/));\n          done();\n        });\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should check for sessions if connected to a single server and has no known servers","suites":["Topology (unit)","shouldCheckForSessionSupport"],"updatePoint":{"line":117,"column":90,"index":3299},"line":117,"code":"    it('should check for sessions if connected to a single server and has no known servers', function (done) {\n      const topology = new Topology('someserver:27019');\n      this.sinon.stub(Server.prototype, 'connect').callsFake(function () {\n        this.s.state = 'connected';\n        this.emit('connect');\n      });\n      topology.connect(() => {\n        expect(topology.shouldCheckForSessionSupport()).to.be.true;\n        topology.close(done);\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should not check for sessions if connected to a single server","suites":["Topology (unit)","shouldCheckForSessionSupport"],"updatePoint":{"line":128,"column":69,"index":3744},"line":128,"code":"    it('should not check for sessions if connected to a single server', function (done) {\n      const topology = new Topology('someserver:27019');\n      this.sinon.stub(Server.prototype, 'connect').callsFake(function () {\n        this.s.state = 'connected';\n        this.emit('connect');\n        setTimeout(() => {\n          this.emit('descriptionReceived', new ServerDescription('someserver:27019', {\n            ok: 1,\n            maxWireVersion: 6\n          }));\n        }, 20);\n      });\n      topology.connect(() => {\n        expect(topology.shouldCheckForSessionSupport()).to.be.false;\n        topology.close(done);\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should check for sessions if there are no data-bearing nodes","suites":["Topology (unit)","shouldCheckForSessionSupport"],"updatePoint":{"line":145,"column":68,"index":4383},"line":145,"code":"    it('should check for sessions if there are no data-bearing nodes', function (done) {\n      const topology = new Topology(['mongos:27019', 'mongos:27018', 'mongos:27017'], {});\n      this.sinon.stub(Server.prototype, 'connect').callsFake(function () {\n        this.s.state = 'connected';\n        this.emit('connect');\n        setTimeout(() => {\n          this.emit('descriptionReceived', new ServerDescription(this.name, {\n            ok: 1,\n            msg: 'isdbgrid',\n            maxWireVersion: 6\n          }));\n        }, 20);\n      });\n      topology.connect(() => {\n        expect(topology.shouldCheckForSessionSupport()).to.be.false;\n        topology.close(done);\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should time out operations against servers that have been blackholed","suites":["Topology (unit)","black holes"],"updatePoint":{"line":168,"column":76,"index":5266},"line":168,"code":"    it('should time out operations against servers that have been blackholed', function (done) {\n      mockServer.setMessageHandler(request => {\n        const doc = request.document;\n        let initialHelloSent = false;\n        if (isHello(doc) && !initialHelloSent) {\n          request.reply(mock.HELLO);\n          initialHelloSent = true;\n        } else {\n          // black hole all other operations\n        }\n      });\n      const topology = new Topology(mockServer.hostAddress());\n      topology.connect(err => {\n        expect(err).to.not.exist;\n        topology.selectServer('primary', {}, (err, server) => {\n          expect(err).to.not.exist;\n          server.command(ns('admin.$cmd'), {\n            ping: 1\n          }, {\n            socketTimeoutMS: 250\n          }, (err, result) => {\n            expect(result).to.not.exist;\n            expect(err).to.exist;\n            expect(err).to.match(/timed out/);\n            topology.close(done);\n          });\n        });\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"returns a MongoServerSelectionError","suites":["Topology (unit)","error handling","when server selection returns a server description but the description is not in the topology","when the topology originally only contained one server"],"updatePoint":{"line":237,"column":47,"index":7516},"line":237,"code":"        it('returns a MongoServerSelectionError', function (done) {\n          topology = new Topology([mockServer.hostAddress(), secondMockServer.hostAddress()]);\n          topology.connect(err => {\n            expect(err).to.not.exist;\n            sinon.stub(topology.s.servers, 'get').callsFake(() => {\n              return undefined;\n            });\n            topology.selectServer('primary', {}, (err, server) => {\n              expect(err).to.be.instanceOf(MongoServerSelectionError);\n              expect(server).not.to.exist;\n              done();\n            });\n          });\n        });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"returns a MongoServerSelectionError","suites":["Topology (unit)","error handling","when server selection returns a server description but the description is not in the topology","when the topology originally contained more than one server"],"updatePoint":{"line":253,"column":47,"index":8216},"line":253,"code":"        it('returns a MongoServerSelectionError', function (done) {\n          topology = new Topology([mockServer.hostAddress(), secondMockServer.hostAddress()]);\n          topology.connect(err => {\n            expect(err).to.not.exist;\n            sinon.stub(topology.s.servers, 'get').callsFake(() => {\n              return undefined;\n            });\n            topology.selectServer('primary', {}, (err, server) => {\n              expect(err).to.be.instanceOf(MongoServerSelectionError);\n              expect(server).not.to.exist;\n              done();\n            });\n          });\n        });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should set server to unknown and reset pool on `node is recovering` error","suites":["Topology (unit)","error handling","when server selection returns a server description but the description is not in the topology","when the topology originally contained more than one server"],"updatePoint":{"line":269,"column":81,"index":8867},"line":269,"code":"    it('should set server to unknown and reset pool on `node is recovering` error', function (done) {\n      mockServer.setMessageHandler(request => {\n        const doc = request.document;\n        if (isHello(doc)) {\n          request.reply(Object.assign({}, mock.HELLO, {\n            maxWireVersion: 9\n          }));\n        } else if (doc.insert) {\n          request.reply({\n            ok: 0,\n            message: 'node is recovering',\n            code: 11600\n          });\n        } else {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      topology = new Topology(mockServer.hostAddress());\n      topology.connect(err => {\n        expect(err).to.not.exist;\n        topology.selectServer('primary', {}, (err, server) => {\n          expect(err).to.not.exist;\n          let serverDescription;\n          server.on('descriptionReceived', sd => serverDescription = sd);\n          let poolCleared = false;\n          topology.on('connectionPoolCleared', () => poolCleared = true);\n          server.command(ns('test.test'), {\n            insert: {\n              a: 42\n            }\n          }, {}, (err, result) => {\n            expect(result).to.not.exist;\n            expect(err).to.exist;\n            expect(err).to.eql(serverDescription.error);\n            expect(poolCleared).to.be.true;\n            done();\n          });\n        });\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should set server to unknown and NOT reset pool on stepdown errors","suites":["Topology (unit)","error handling","when server selection returns a server description but the description is not in the topology","when the topology originally contained more than one server"],"updatePoint":{"line":311,"column":74,"index":10246},"line":311,"code":"    it('should set server to unknown and NOT reset pool on stepdown errors', function (done) {\n      mockServer.setMessageHandler(request => {\n        const doc = request.document;\n        if (isHello(doc)) {\n          request.reply(Object.assign({}, mock.HELLO, {\n            maxWireVersion: 9\n          }));\n        } else if (doc.insert) {\n          request.reply({\n            ok: 0,\n            message: LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE.source\n          });\n        } else {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      const topology = new Topology(mockServer.hostAddress());\n      topology.connect(err => {\n        expect(err).to.not.exist;\n        topology.selectServer('primary', {}, (err, server) => {\n          expect(err).to.not.exist;\n          let serverDescription;\n          server.on('descriptionReceived', sd => serverDescription = sd);\n          let poolCleared = false;\n          topology.on('connectionPoolCleared', () => poolCleared = true);\n          server.command(ns('test.test'), {\n            insert: {\n              a: 42\n            }\n          }, {}, (err, result) => {\n            expect(result).to.not.exist;\n            expect(err).to.exist;\n            expect(err).to.eql(serverDescription.error);\n            expect(poolCleared).to.be.false;\n            topology.close(done);\n          });\n        });\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should set server to unknown on non-timeout network error","suites":["Topology (unit)","error handling","when server selection returns a server description but the description is not in the topology","when the topology originally contained more than one server"],"updatePoint":{"line":352,"column":65,"index":11640},"line":352,"code":"    it('should set server to unknown on non-timeout network error', function (done) {\n      mockServer.setMessageHandler(request => {\n        const doc = request.document;\n        if (isHello(doc)) {\n          request.reply(Object.assign({}, mock.HELLO, {\n            maxWireVersion: 9\n          }));\n        } else if (doc.insert) {\n          request.connection.destroy();\n        } else {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      topology = new Topology(mockServer.hostAddress());\n      topology.connect(err => {\n        expect(err).to.not.exist;\n        topology.selectServer('primary', {}, (err, server) => {\n          expect(err).to.not.exist;\n          let serverDescription;\n          server.on('descriptionReceived', sd => serverDescription = sd);\n          server.command(ns('test.test'), {\n            insert: {\n              a: 42\n            }\n          }, {}, (err, result) => {\n            expect(result).to.not.exist;\n            expect(err).to.exist;\n            expect(err).to.eql(serverDescription.error);\n            expect(server.description.type).to.equal('Unknown');\n            done();\n          });\n        });\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should encounter a server selection timeout on garbled server responses","suites":["Topology (unit)","error handling","when server selection returns a server description but the description is not in the topology","when the topology originally contained more than one server"],"updatePoint":{"line":388,"column":79,"index":12850},"line":388,"code":"    it('should encounter a server selection timeout on garbled server responses', function (done) {\n      const server = net.createServer();\n      const p = Promise.resolve();\n      let unexpectedError, expectedError;\n      server.listen(0, 'localhost', 2, () => {\n        server.on('connection', c => c.on('data', () => c.write('garbage_data')));\n        const {\n          address,\n          port\n        } = server.address();\n        const client = new MongoClient(`mongodb://${address}:${port}`, {\n          serverSelectionTimeoutMS: 1000\n        });\n        p.then(() => client.connect().then(() => {\n          unexpectedError = new Error('Expected a server selection error but got none');\n        }).catch(error => {\n          expectedError = error;\n        }).then(() => {\n          server.close();\n          return client.close(err => {\n            if (!unexpectedError) {\n              unexpectedError = err;\n            }\n          });\n        }).finally(() => {\n          if (unexpectedError) {\n            return done(unexpectedError);\n          }\n          if (expectedError) {\n            return done();\n          }\n        }));\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should emit topologyDescriptionChange event","suites":["Topology (unit)","error handling","srv event listeners","srvRecordDiscovery event listener"],"updatePoint":{"line":457,"column":55,"index":15809},"line":457,"code":"        it('should emit topologyDescriptionChange event', function () {\n          topology.once(Topology.TOPOLOGY_DESCRIPTION_CHANGED, ev => {\n            // The first event we get here is caused by the srv record discovery event below\n            expect(ev).to.have.nested.property('newDescription.servers');\n            expect(ev.newDescription.servers.get('fake:2')).to.be.a('object').with.property('address', 'fake:2');\n          });\n          topology.s.srvPoller.emit(SrvPoller.SRV_RECORD_DISCOVERY, new SrvPollingEvent([{\n            priority: 1,\n            weight: 1,\n            port: 2,\n            name: 'fake'\n          }]));\n        });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should clean up listeners on close","suites":["Topology (unit)","error handling","srv event listeners","srvRecordDiscovery event listener"],"updatePoint":{"line":470,"column":46,"index":16451},"line":470,"code":"        it('should clean up listeners on close', function (done) {\n          topology.s.state = 'connected'; // fake state to test clean up logic\n          topology.close(e => {\n            const srvPollerListeners = topology.s.srvPoller.listeners(SrvPoller.SRV_RECORD_DISCOVERY);\n            expect(srvPollerListeners).to.have.lengthOf(0);\n            const topologyChangeListeners = topology.listeners(Topology.TOPOLOGY_DESCRIPTION_CHANGED);\n            expect(topologyChangeListeners).to.have.lengthOf(0);\n            done(e);\n          });\n        });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should not add more than one srvRecordDiscovery listener","suites":["Topology (unit)","error handling","srv event listeners","topologyDescriptionChange event listener"],"updatePoint":{"line":482,"column":68,"index":17112},"line":482,"code":"        it('should not add more than one srvRecordDiscovery listener', function () {\n          // fake a transition to Sharded\n          transitionTopology(topology, TopologyType.Unknown, TopologyType.Sharded); // Transition 1\n\n          const srvListenersFirstTransition = topology.s.srvPoller.listeners(SrvPoller.SRV_RECORD_DISCOVERY);\n          expect(srvListenersFirstTransition).to.have.lengthOf(1);\n          transitionTopology(topology, TopologyType.Unknown, TopologyType.Sharded); // Transition 2\n\n          const srvListenersSecondTransition = topology.s.srvPoller.listeners(SrvPoller.SRV_RECORD_DISCOVERY);\n          expect(srvListenersSecondTransition).to.have.lengthOf(1);\n        });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should not add srvRecordDiscovery listener if transition is not to Sharded topology","suites":["Topology (unit)","error handling","srv event listeners","topologyDescriptionChange event listener"],"updatePoint":{"line":493,"column":95,"index":17836},"line":493,"code":"        it('should not add srvRecordDiscovery listener if transition is not to Sharded topology', function () {\n          // fake a transition to **NOT** Sharded\n          transitionTopology(topology, TopologyType.Unknown, TopologyType.ReplicaSetWithPrimary);\n          const srvListeners = topology.s.srvPoller.listeners(SrvPoller.SRV_RECORD_DISCOVERY);\n          expect(srvListeners).to.have.lengthOf(0);\n        });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should schedule monitoring if no suitable server is found","suites":["Topology (unit)","selectServer()"],"updatePoint":{"line":509,"column":65,"index":18435},"line":509,"code":"    it('should schedule monitoring if no suitable server is found', function (done) {\n      const topology = new Topology('someserver:27019');\n      const requestCheck = this.sinon.stub(Server.prototype, 'requestCheck');\n\n      // satisfy the initial connect, then restore the original method\n      const selectServer = this.sinon.stub(Topology.prototype, 'selectServer').callsFake(function (selector, options, callback) {\n        const server = Array.from(this.s.servers.values())[0];\n        selectServer.restore();\n        callback(null, server);\n      });\n      this.sinon.stub(Server.prototype, 'connect').callsFake(function () {\n        this.s.state = 'connected';\n        this.emit('connect');\n      });\n      topology.connect(() => {\n        topology.selectServer(ReadPreference.secondary, {\n          serverSelectionTimeoutMS: 1000\n        }, err => {\n          expect(err).to.exist;\n          expect(err).to.match(/Server selection timed out/);\n          expect(err).to.have.property('reason');\n\n          // When server is created `connect` is called on the monitor. When server selection\n          // occurs `requestCheck` will be called for an immediate check.\n          expect(requestCheck).property('callCount').to.equal(1);\n          topology.close(done);\n        });\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should disallow selection when the topology is explicitly closed","suites":["Topology (unit)","selectServer()"],"updatePoint":{"line":538,"column":72,"index":19744},"line":538,"code":"    it('should disallow selection when the topology is explicitly closed', function (done) {\n      const topology = new Topology('someserver:27019');\n      this.sinon.stub(Server.prototype, 'connect').callsFake(function () {\n        this.s.state = 'connected';\n        this.emit('connect');\n      });\n      topology.close(() => {\n        topology.selectServer(ReadPreference.primary, {\n          serverSelectionTimeoutMS: 2000\n        }, err => {\n          expect(err).to.exist;\n          expect(err).to.match(/Topology is closed/);\n          done();\n        });\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should process all wait queue members, including selection with errors","suites":["Topology (unit)","selectServer()","waitQueue"],"updatePoint":{"line":555,"column":80,"index":20373},"line":555,"code":"      it('should process all wait queue members, including selection with errors', function (done) {\n        const topology = new Topology('someserver:27019');\n        const selectServer = this.sinon.stub(Topology.prototype, 'selectServer').callsFake(function (selector, options, callback) {\n          const server = Array.from(this.s.servers.values())[0];\n          selectServer.restore();\n          callback(null, server);\n        });\n        this.sinon.stub(Server.prototype, 'connect').callsFake(function () {\n          this.s.state = 'connected';\n          this.emit('connect');\n        });\n        const toSelect = 10;\n        let completed = 0;\n        function finish() {\n          completed++;\n          if (completed === toSelect) done();\n        }\n\n        // methodology:\n        //   - perform 9 server selections, a few with a selector that throws an error\n        //   - ensure each selection immediately returns an empty result (gated by a boolean)\n        //     guaranteeing tha the queue will be full before the last selection\n        //   - make one last selection, but ensure that all selections are no longer blocked from\n        //     returning their value\n        //   - verify that 10 callbacks were called\n\n        topology.connect(err => {\n          expect(err).to.not.exist;\n          let preventSelection = true;\n          const anySelector = td => {\n            if (preventSelection) return [];\n            const server = Array.from(td.servers.values())[0];\n            return [server];\n          };\n          const failingSelector = () => {\n            if (preventSelection) return [];\n            throw new TypeError('bad news!');\n          };\n          preventSelection = true;\n          for (let i = 0; i < toSelect - 1; ++i) {\n            topology.selectServer(i % 5 === 0 ? failingSelector : anySelector, {}, finish);\n          }\n          preventSelection = false;\n          topology.selectServer(anySelector, {}, finish);\n        });\n      });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if the session is snapshot enabled","suites":["Sessions - unit","class ClientSession","startTransaction()"],"updatePoint":{"line":44,"column":66,"index":1009},"line":44,"code":"      it('should throw an error if the session is snapshot enabled', function () {\n        session = new ClientSession(client, serverSessionPool, {\n          snapshot: true\n        });\n        expect(session.snapshotEnabled).to.equal(true);\n        expect(() => session.startTransaction()).to.throw('Transactions are not supported in snapshot sessions');\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if the input cluster time is not an object","suites":["Sessions - unit","class ClientSession","advanceClusterTime()"],"updatePoint":{"line":53,"column":74,"index":1435},"line":53,"code":"      it('should throw an error if the input cluster time is not an object', function () {\n        const invalidInputs = [undefined, null, 3, 'a'];\n        for (const input of invalidInputs) {\n          expect(() => session.advanceClusterTime(input)).to.throw('input cluster time must be an object');\n        }\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if the input cluster time is missing a valid clusterTime property","suites":["Sessions - unit","class ClientSession","advanceClusterTime()"],"updatePoint":{"line":59,"column":97,"index":1779},"line":59,"code":"      it('should throw an error if the input cluster time is missing a valid clusterTime property', function () {\n        const invalidInputs = Array(5).fill(1).map(time => genClusterTime(time));\n        delete invalidInputs[0].clusterTime;\n        invalidInputs[1].clusterTime = null;\n        invalidInputs[2].clusterTime = 5;\n        invalidInputs[3].clusterTime = 'not a timestamp';\n        invalidInputs[4].clusterTime = new Date('1');\n        for (const input of invalidInputs) {\n          expect(() => session.advanceClusterTime(input), `expected to fail on input: ${JSON.stringify(input)}`).to.throw('input cluster time \"clusterTime\" property must be a valid BSON Timestamp');\n        }\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if the input cluster time is missing a valid signature property","suites":["Sessions - unit","class ClientSession","advanceClusterTime()"],"updatePoint":{"line":70,"column":95,"index":2481},"line":70,"code":"      it('should throw an error if the input cluster time is missing a valid signature property', function () {\n        const invalidInputs = Array(9).fill(1).map(time => genClusterTime(time));\n\n        // null types\n        delete invalidInputs[0].signature;\n        delete invalidInputs[1].signature.hash;\n        delete invalidInputs[2].signature.keyId;\n        invalidInputs[3].signature.hash = null;\n        invalidInputs[4].signature.keyId = null;\n        // invalid non-null types\n        // keyId must be number or BSON long\n        // hash must be BSON binary\n        invalidInputs[5].signature.keyId = {};\n        invalidInputs[6].signature.keyId = 'not BSON Long';\n        invalidInputs[7].signature.hash = 123;\n        invalidInputs[8].signature.hash = 'not BSON Binary';\n        for (const input of invalidInputs) {\n          expect(() => session.advanceClusterTime(input), `expected to fail on input: ${JSON.stringify(input)}`).to.throw('input cluster time must have a valid \"signature\" property with BSON Binary hash and BSON Long keyId');\n        }\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should set the session clusterTime to the one provided if the existing session clusterTime is null","suites":["Sessions - unit","class ClientSession","advanceClusterTime()"],"updatePoint":{"line":90,"column":108,"index":3569},"line":90,"code":"      it('should set the session clusterTime to the one provided if the existing session clusterTime is null', () => {\n        expect(session).property('clusterTime').to.be.undefined;\n        const validTime = genClusterTime(100);\n        session.advanceClusterTime(validTime);\n        expect(session).property('clusterTime').to.equal(validTime);\n        session.clusterTime = null;\n        expect(session).property('clusterTime').to.be.null;\n        session.advanceClusterTime(validTime);\n        expect(session).property('clusterTime').to.equal(validTime);\n\n        // extra test case for valid alternative keyId type in signature\n        const alsoValidTime = genClusterTime(200);\n        alsoValidTime.signature.keyId = 10;\n        session.clusterTime = null;\n        expect(session).property('clusterTime').to.be.null;\n        session.advanceClusterTime(alsoValidTime);\n        expect(session).property('clusterTime').to.equal(alsoValidTime);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should set the session clusterTime to the one provided if it is greater than the the existing session clusterTime","suites":["Sessions - unit","class ClientSession","advanceClusterTime()"],"updatePoint":{"line":108,"column":123,"index":4542},"line":108,"code":"      it('should set the session clusterTime to the one provided if it is greater than the the existing session clusterTime', () => {\n        const validInitialTime = genClusterTime(100);\n        const validGreaterTime = genClusterTime(200);\n        session.advanceClusterTime(validInitialTime);\n        expect(session).property('clusterTime').to.equal(validInitialTime);\n        session.advanceClusterTime(validGreaterTime);\n        expect(session).property('clusterTime').to.equal(validGreaterTime);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should leave the session clusterTime unchanged if it is less than or equal to the the existing session clusterTime","suites":["Sessions - unit","class ClientSession","advanceClusterTime()"],"updatePoint":{"line":116,"column":124,"index":5055},"line":116,"code":"      it('should leave the session clusterTime unchanged if it is less than or equal to the the existing session clusterTime', () => {\n        const validInitialTime = genClusterTime(100);\n        const validEqualTime = genClusterTime(100);\n        const validLesserTime = genClusterTime(50);\n        session.advanceClusterTime(validInitialTime);\n        expect(session).property('clusterTime').to.equal(validInitialTime);\n        session.advanceClusterTime(validEqualTime);\n        expect(session).property('clusterTime').to.equal(validInitialTime); // the reference check ensures no update happened\n\n        session.advanceClusterTime(validLesserTime);\n        expect(session).property('clusterTime').to.equal(validInitialTime);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw errors with invalid parameters","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":130,"column":53,"index":5777},"line":130,"code":"      it('should throw errors with invalid parameters', function () {\n        expect(() => {\n          new ClientSession();\n        }).to.throw(/ClientSession requires a MongoClient/);\n        expect(() => {\n          new ClientSession({});\n        }).to.throw(/ClientSession requires a ServerSessionPool/);\n        expect(() => {\n          new ClientSession({}, {});\n        }).to.throw(/ClientSession requires a ServerSessionPool/);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if snapshot and causalConsistency options are both set to true","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":141,"column":94,"index":6263},"line":141,"code":"      it('should throw an error if snapshot and causalConsistency options are both set to true', function () {\n        expect(() => new ClientSession(client, serverSessionPool, {\n          causalConsistency: true,\n          snapshot: true\n        })).to.throw('Properties \"causalConsistency\" and \"snapshot\" are mutually exclusive');\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should default to `null` for `clusterTime`","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":147,"column":52,"index":6564},"line":147,"code":"      it('should default to `null` for `clusterTime`', function () {\n        const session = new ClientSession(client, serverSessionPool);\n        expect(session.clusterTime).to.not.exist;\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should set the internal clusterTime to `initialClusterTime` if provided","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":151,"column":81,"index":6792},"line":151,"code":"      it('should set the internal clusterTime to `initialClusterTime` if provided', function () {\n        const clusterTime = genClusterTime(Date.now());\n        const session = new ClientSession(client, serverSessionPool, {\n          initialClusterTime: clusterTime\n        });\n        expect(session.clusterTime).to.eql(clusterTime);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should acquire a serverSession in the constructor if the session is explicit","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":158,"column":86,"index":7143},"line":158,"code":"      it('should acquire a serverSession in the constructor if the session is explicit', () => {\n        const session = new ClientSession(client, serverSessionPool, {\n          explicit: true\n        });\n        const serverSessionSymbol = getSymbolFrom(session, 'serverSession');\n        expect(session).to.have.property(serverSessionSymbol).that.is.an.instanceOf(ServerSession);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should leave serverSession null if the session is implicit","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":165,"column":68,"index":7517},"line":165,"code":"      it('should leave serverSession null if the session is implicit', () => {\n        // implicit via false (this should not be allowed...)\n        let session = new ClientSession(client, serverSessionPool, {\n          explicit: false\n        });\n        const serverSessionSymbol = getSymbolFrom(session, 'serverSession');\n        expect(session).to.have.property(serverSessionSymbol, null);\n        // implicit via omission\n        session = new ClientSession(client, serverSessionPool, {});\n        expect(session).to.have.property(serverSessionSymbol, null);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should start the txnNumberIncrement at zero","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":176,"column":53,"index":8076},"line":176,"code":"      it('should start the txnNumberIncrement at zero', () => {\n        const session = new ClientSession(client, serverSessionPool);\n        const txnNumberIncrementSymbol = getSymbolFrom(session, 'txnNumberIncrement');\n        expect(session).to.have.property(txnNumberIncrementSymbol, 0);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should always have a non-null serverSession after construction","suites":["Sessions - unit","class ClientSession","get serverSession()","from an explicit session"],"updatePoint":{"line":188,"column":74,"index":8672},"line":188,"code":"        it('should always have a non-null serverSession after construction', () => {\n          const session = new ClientSession(client, serverSessionPool, {\n            explicit: true\n          });\n          expect(session).to.have.a.property(serverSessionSymbol).be.an.instanceOf(ServerSession);\n          expect(session.serverSession).be.an.instanceOf(ServerSession);\n        });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should always have non-null serverSession even if it is ended before getter called","suites":["Sessions - unit","class ClientSession","get serverSession()","from an explicit session"],"updatePoint":{"line":195,"column":94,"index":9075},"line":195,"code":"        it('should always have non-null serverSession even if it is ended before getter called', () => {\n          const session = new ClientSession(client, serverSessionPool, {\n            explicit: true\n          });\n          session.hasEnded = true;\n          expect(session).to.have.a.property(serverSessionSymbol).be.an.instanceOf(ServerSession);\n          expect(session.serverSession).be.an.instanceOf(ServerSession);\n        });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw if the serverSession at the symbol property goes missing","suites":["Sessions - unit","class ClientSession","get serverSession()","from an explicit session"],"updatePoint":{"line":203,"column":81,"index":9500},"line":203,"code":"        it('should throw if the serverSession at the symbol property goes missing', () => {\n          const session = new ClientSession(client, serverSessionPool, {\n            explicit: true\n          });\n          // We really want to make sure a ClientSession is not separated from its serverSession\n          session[serverSessionSymbol] = null;\n          expect(session).to.have.a.property(serverSessionSymbol).be.null;\n          expect(() => session.serverSession).throw(MongoRuntimeError);\n        });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw if the session ended before serverSession was acquired","suites":["Sessions - unit","class ClientSession","get serverSession()","from an implicit session"],"updatePoint":{"line":214,"column":79,"index":10068},"line":214,"code":"        it('should throw if the session ended before serverSession was acquired', () => {\n          const session = new ClientSession(client, serverSessionPool, {\n            explicit: false\n          }); // make an implicit session\n          expect(session).to.have.property(serverSessionSymbol, null);\n          session.hasEnded = true;\n          expect(() => session.serverSession).to.throw(MongoRuntimeError);\n        });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should acquire a serverSession if clientSession.hasEnded is false and serverSession is not set","suites":["Sessions - unit","class ClientSession","get serverSession()","from an implicit session"],"updatePoint":{"line":222,"column":106,"index":10521},"line":222,"code":"        it('should acquire a serverSession if clientSession.hasEnded is false and serverSession is not set', () => {\n          const session = new ClientSession(client, serverSessionPool, {\n            explicit: false\n          }); // make an implicit session\n          expect(session).to.have.property(serverSessionSymbol, null);\n          session.hasEnded = false;\n          const acquireSpy = sinon.spy(serverSessionPool, 'acquire');\n          expect(session.serverSession).to.be.instanceOf(ServerSession);\n          expect(acquireSpy.calledOnce).to.be.true;\n          acquireSpy.restore();\n        });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should return the existing serverSession and not acquire a new one if one is already set","suites":["Sessions - unit","class ClientSession","get serverSession()","from an implicit session"],"updatePoint":{"line":233,"column":100,"index":11121},"line":233,"code":"        it('should return the existing serverSession and not acquire a new one if one is already set', () => {\n          const session = new ClientSession(client, serverSessionPool, {\n            explicit: false\n          }); // make an implicit session\n          expect(session).to.have.property(serverSessionSymbol, null);\n          const acquireSpy = sinon.spy(serverSessionPool, 'acquire');\n          const firstServerSessionGetResult = session.serverSession;\n          expect(firstServerSessionGetResult).to.be.instanceOf(ServerSession);\n          expect(acquireSpy.calledOnce).to.be.true;\n\n          // call the getter a bunch more times\n          expect(session.serverSession).to.be.instanceOf(ServerSession);\n          expect(session.serverSession).to.be.instanceOf(ServerSession);\n          expect(session.serverSession).to.be.instanceOf(ServerSession);\n          expect(session.serverSession.id.id.buffer.toString('hex')).to.equal(firstServerSessionGetResult.id.id.buffer.toString('hex'));\n\n          // acquire never called again\n          expect(acquireSpy.calledOnce).to.be.true;\n          acquireSpy.restore();\n        });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should return the existing serverSession and not acquire a new one if one is already set and session is ended","suites":["Sessions - unit","class ClientSession","get serverSession()","from an implicit session"],"updatePoint":{"line":253,"column":121,"index":12279},"line":253,"code":"        it('should return the existing serverSession and not acquire a new one if one is already set and session is ended', () => {\n          const session = new ClientSession(client, serverSessionPool, {\n            explicit: false\n          }); // make an implicit session\n          expect(session).to.have.property(serverSessionSymbol, null);\n          const acquireSpy = sinon.spy(serverSessionPool, 'acquire');\n          const firstServerSessionGetResult = session.serverSession;\n          expect(firstServerSessionGetResult).to.be.instanceOf(ServerSession);\n          expect(acquireSpy.calledOnce).to.be.true;\n          session.hasEnded = true;\n\n          // call the getter a bunch more times\n          expect(session.serverSession).to.be.instanceOf(ServerSession);\n          expect(session.serverSession).to.be.instanceOf(ServerSession);\n          expect(session.serverSession).to.be.instanceOf(ServerSession);\n          expect(session.serverSession.id.id.buffer.toString('hex')).to.equal(firstServerSessionGetResult.id.id.buffer.toString('hex'));\n\n          // acquire never called again\n          expect(acquireSpy.calledOnce).to.be.true;\n          acquireSpy.restore();\n        });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should not allocate serverSession","suites":["Sessions - unit","class ClientSession","incrementTransactionNumber()"],"updatePoint":{"line":277,"column":43,"index":13465},"line":277,"code":"      it('should not allocate serverSession', () => {\n        const session = new ClientSession(client, serverSessionPool);\n        const txnNumberIncrementSymbol = getSymbolFrom(session, 'txnNumberIncrement');\n        session.incrementTransactionNumber();\n        expect(session).to.have.property(txnNumberIncrementSymbol, 1);\n        const serverSessionSymbol = getSymbolFrom(session, 'serverSession');\n        expect(session).to.have.property(serverSessionSymbol, null);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should save increments to txnNumberIncrement symbol","suites":["Sessions - unit","class ClientSession","incrementTransactionNumber()"],"updatePoint":{"line":285,"column":61,"index":13967},"line":285,"code":"      it('should save increments to txnNumberIncrement symbol', () => {\n        const session = new ClientSession(client, serverSessionPool);\n        const txnNumberIncrementSymbol = getSymbolFrom(session, 'txnNumberIncrement');\n        session.incrementTransactionNumber();\n        session.incrementTransactionNumber();\n        session.incrementTransactionNumber();\n        expect(session).to.have.property(txnNumberIncrementSymbol, 3);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should allocate serverSession","suites":["Sessions - unit","class ClientSession","applySession()"],"updatePoint":{"line":295,"column":39,"index":14440},"line":295,"code":"      it('should allocate serverSession', () => {\n        const session = new ClientSession(client, serverSessionPool);\n        const serverSessionSymbol = getSymbolFrom(session, 'serverSession');\n        const command = {\n          magic: 1\n        };\n        const result = applySession(session, command, {});\n        expect(result).to.not.exist;\n        expect(command).to.have.property('lsid');\n        expect(session).to.have.property(serverSessionSymbol).that.is.instanceOf(ServerSession);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should apply saved txnNumberIncrements","suites":["Sessions - unit","class ClientSession","applySession()"],"updatePoint":{"line":306,"column":48,"index":14955},"line":306,"code":"      it('should apply saved txnNumberIncrements', () => {\n        const session = new ClientSession(client, serverSessionPool);\n        const serverSessionSymbol = getSymbolFrom(session, 'serverSession');\n        session.incrementTransactionNumber();\n        session.incrementTransactionNumber();\n        session.incrementTransactionNumber();\n        const command = {\n          magic: 1\n        };\n        const result = applySession(session, command, {\n          // txnNumber will be applied for retryable write command\n          willRetryWrite: true\n        });\n        expect(result).to.not.exist;\n        expect(command).to.have.property('lsid');\n        expect(command).to.have.property('txnNumber').instanceOf(Long);\n        expect(command.txnNumber.toNumber()).to.equal(3);\n        expect(session).to.have.property(serverSessionSymbol).that.is.instanceOf(ServerSession);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw errors with invalid parameters","suites":["Sessions - unit","class ServerSessionPool"],"updatePoint":{"line":347,"column":51,"index":16472},"line":347,"code":"    it('should throw errors with invalid parameters', function () {\n      expect(() => new ServerSessionPool()).to.throw(MongoRuntimeError);\n    });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should create a new session if the pool is empty","suites":["Sessions - unit","class ServerSessionPool"],"updatePoint":{"line":350,"column":56,"index":16626},"line":350,"code":"    it('should create a new session if the pool is empty', function (done) {\n      const pool = new ServerSessionPool(client);\n      expect(pool.sessions).to.have.length(0);\n      const session = pool.acquire();\n      expect(session).to.exist;\n      expect(pool.sessions).to.have.length(0);\n      pool.release(session);\n      done();\n    });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should reuse sessions which have not timed out yet on acquire","suites":["Sessions - unit","class ServerSessionPool"],"updatePoint":{"line":359,"column":69,"index":16981},"line":359,"code":"    it('should reuse sessions which have not timed out yet on acquire', function (done) {\n      const oldSession = new ServerSession();\n      const pool = new ServerSessionPool(client);\n      pool.sessions.push(oldSession);\n      const session = pool.acquire();\n      expect(session).to.exist;\n      expect(session).to.eql(oldSession);\n      pool.release(session);\n      done();\n    });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should remove sessions which have timed out on acquire, and return a fresh session","suites":["Sessions - unit","class ServerSessionPool"],"updatePoint":{"line":369,"column":90,"index":17389},"line":369,"code":"    it('should remove sessions which have timed out on acquire, and return a fresh session', function (done) {\n      const oldSession = new ServerSession();\n      oldSession.lastUse = now() - 30 * 60 * 1000; // add 30min\n\n      const pool = new ServerSessionPool(client);\n      pool.sessions.push(oldSession);\n      const session = pool.acquire();\n      expect(session).to.exist;\n      expect(session).to.not.eql(oldSession);\n      pool.release(session);\n      done();\n    });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should remove old sessions if they are at the start of the pool","suites":["Sessions - unit","class ServerSessionPool","release()"],"updatePoint":{"line":387,"column":73,"index":18070},"line":387,"code":"      it('should remove old sessions if they are at the start of the pool', () => {\n        const pool = new ServerSessionPool(client);\n        // old sessions at the start\n        pool.sessions.pushMany(Array.from({\n          length: 3\n        }, () => makeOldSession()));\n        pool.sessions.pushMany([new ServerSession(), new ServerSession()]);\n        pool.release(new ServerSession());\n        expect(pool.sessions).to.have.lengthOf(3);\n        const anyTimedOutSessions = pool.sessions.toArray().some(s => s.hasTimedOut(30 * 60 * 1000));\n        expect(anyTimedOutSessions, 'Unexpected timed out sessions found in pool after release').to.be.false;\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should remove old sessions if they are in the middle of the pool","suites":["Sessions - unit","class ServerSessionPool","release()"],"updatePoint":{"line":399,"column":74,"index":18737},"line":399,"code":"      it('should remove old sessions if they are in the middle of the pool', () => {\n        const pool = new ServerSessionPool(client);\n        pool.sessions.push(new ServerSession()); // one fresh before\n        pool.sessions.pushMany(Array.from({\n          length: 3\n        }, () => makeOldSession()));\n        pool.sessions.push(new ServerSession()); // one fresh after\n\n        pool.release(new ServerSession());\n        expect(pool.sessions).to.have.lengthOf(3);\n        const anyTimedOutSessions = pool.sessions.toArray().some(s => s.hasTimedOut(30 * 60 * 1000));\n        expect(anyTimedOutSessions, 'Unexpected timed out sessions found in pool after release').to.be.false;\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should remove old sessions if they are at the end of the pool","suites":["Sessions - unit","class ServerSessionPool","release()"],"updatePoint":{"line":412,"column":71,"index":19426},"line":412,"code":"      it('should remove old sessions if they are at the end of the pool', () => {\n        const pool = new ServerSessionPool(client);\n        pool.sessions.pushMany([new ServerSession(), new ServerSession()]);\n        const oldSession = makeOldSession();\n        pool.sessions.push(oldSession);\n        pool.release(new ServerSession());\n        expect(pool.sessions).to.have.lengthOf(3);\n        const anyTimedOutSessions = pool.sessions.toArray().some(s => s.hasTimedOut(30 * 60 * 1000));\n        expect(anyTimedOutSessions, 'Unexpected timed out sessions found in pool after release').to.be.false;\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should remove old sessions that are not contiguous in the pool","suites":["Sessions - unit","class ServerSessionPool","release()"],"updatePoint":{"line":422,"column":72,"index":20038},"line":422,"code":"      it('should remove old sessions that are not contiguous in the pool', () => {\n        const pool = new ServerSessionPool(client);\n        pool.sessions.pushMany([makeOldSession(), new ServerSession(), makeOldSession(), new ServerSession(), makeOldSession()]);\n        pool.release(new ServerSession());\n        expect(pool.sessions).to.have.lengthOf(3);\n        const anyTimedOutSessions = pool.sessions.toArray().some(s => s.hasTimedOut(30 * 60 * 1000));\n        expect(anyTimedOutSessions, 'Unexpected timed out sessions found in pool after release').to.be.false;\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should not reintroduce a soon-to-expire session to the pool on release","suites":["Sessions - unit","class ServerSessionPool","release()"],"updatePoint":{"line":431,"column":78,"index":20633},"line":431,"code":"    it('should not reintroduce a soon-to-expire session to the pool on release', function (done) {\n      const session = new ServerSession();\n      session.lastUse = now() - 9.5 * 60 * 1000; // add 9.5min\n\n      const pool = new ServerSessionPool(client);\n      pool.release(session);\n      expect(pool.sessions).to.have.length(0);\n      done();\n    });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should maintain a LIFO queue of sessions","suites":["Sessions - unit","class ServerSessionPool","release()"],"updatePoint":{"line":440,"column":48,"index":20957},"line":440,"code":"    it('should maintain a LIFO queue of sessions', function (done) {\n      const pool = new ServerSessionPool(client);\n      const sessionA = new ServerSession();\n      const sessionB = new ServerSession();\n      pool.release(sessionA);\n      pool.release(sessionB);\n      const sessionC = pool.acquire();\n      const sessionD = pool.acquire();\n      expect(sessionC.id).to.eql(sessionB.id);\n      expect(sessionD.id).to.eql(sessionA.id);\n      pool.release(sessionC);\n      pool.release(sessionD);\n      done();\n    });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"does not configure the provider if none is given","suites":["parseOptions","aws providers"],"updatePoint":{"line":5,"column":56,"index":251},"line":5,"code":"    it('does not configure the provider if none is given', function () {\n      const parsedProviders = mergeKMSProviders({}, {});\n      expect(parsedProviders).not.to.have.property('aws');\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"configures the provider without credentials if an empty object is supplied","suites":["parseOptions","aws providers"],"updatePoint":{"line":9,"column":82,"index":474},"line":9,"code":"    it('configures the provider without credentials if an empty object is supplied', function () {\n      const parsedProviders = mergeKMSProviders({\n        aws: {}\n      }, {});\n      expect(parsedProviders.aws).deep.equal({});\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"replaces a $$placeholder value with the value from the environment","suites":["parseOptions","aws providers"],"updatePoint":{"line":15,"column":74,"index":703},"line":15,"code":"    it('replaces a $$placeholder value with the value from the environment', function () {\n      const parsedProviders = mergeKMSProviders({\n        aws: {\n          accessKeyId: {\n            $$placeholder: 1\n          },\n          secretAccessKey: 'secretAccessKey'\n        }\n      }, {\n        aws: {\n          accessKeyId: 'accessKeyId'\n        }\n      });\n      expect(parsedProviders.aws).deep.equal({\n        accessKeyId: 'accessKeyId',\n        secretAccessKey: 'secretAccessKey'\n      });\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"omits required fields if the field is not present in the kmsProviders","suites":["parseOptions","aws providers"],"updatePoint":{"line":33,"column":77,"index":1211},"line":33,"code":"    it('omits required fields if the field is not present in the kmsProviders', function () {\n      const parsedProviders = mergeKMSProviders({\n        aws: {\n          accessKeyId: {\n            $$placeholder: 1\n          }\n        }\n      }, {\n        aws: {\n          accessKeyId: 'accessKeyId'\n        }\n      });\n      expect(parsedProviders.aws).not.to.have.property('secretAccessKey');\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"configures the provider with the exact credentials from the test","suites":["parseOptions","aws providers"],"updatePoint":{"line":47,"column":72,"index":1607},"line":47,"code":"    it('configures the provider with the exact credentials from the test', function () {\n      const parsedProviders = mergeKMSProviders({\n        aws: {\n          accessKeyId: 'accessKeyId',\n          secretAccessKey: 'secretAccessKey',\n          sessionToken: 'sessionToken'\n        }\n      }, {\n        aws: {\n          accessKeyId: 'accessKeyIdFromEnvironment',\n          secretAccessKey: 'secretAccessKeyFromEnvironment',\n          sessionToken: 'sessionTokenFromEnvironment'\n        }\n      });\n      expect(parsedProviders.aws).deep.equal({\n        accessKeyId: 'accessKeyId',\n        secretAccessKey: 'secretAccessKey',\n        sessionToken: 'sessionToken'\n      });\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"does not configure the provider if none is given","suites":["parseOptions","local providers"],"updatePoint":{"line":69,"column":56,"index":2323},"line":69,"code":"    it('does not configure the provider if none is given', function () {\n      const parsedProviders = mergeKMSProviders({}, {});\n      expect(parsedProviders).not.to.have.property('local');\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"configures the provider without credentials if an empty object is supplied","suites":["parseOptions","local providers"],"updatePoint":{"line":73,"column":82,"index":2548},"line":73,"code":"    it('configures the provider without credentials if an empty object is supplied', function () {\n      const parsedProviders = mergeKMSProviders({\n        local: {}\n      }, {});\n      expect(parsedProviders.local).deep.equal({});\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"replaces a $$placeholder value with the value from the environment","suites":["parseOptions","local providers"],"updatePoint":{"line":79,"column":74,"index":2781},"line":79,"code":"    it('replaces a $$placeholder value with the value from the environment', function () {\n      const parsedProviders = mergeKMSProviders({\n        local: {\n          key: {\n            $$placeholder: 1\n          }\n        }\n      }, {\n        local: {\n          key: 'key'\n        }\n      });\n      expect(parsedProviders.local).deep.equal({\n        key: 'key'\n      });\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"configures the provider with the exact credentials from the test","suites":["parseOptions","local providers"],"updatePoint":{"line":95,"column":72,"index":3160},"line":95,"code":"    it('configures the provider with the exact credentials from the test', function () {\n      const parsedProviders = mergeKMSProviders({\n        local: {\n          key: 'key'\n        }\n      }, {\n        local: {\n          key: 'keyFromEnvironment'\n        }\n      });\n      expect(parsedProviders.local).deep.equal({\n        key: 'key'\n      });\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"does not configure the provider if none is given","suites":["parseOptions","azure"],"updatePoint":{"line":111,"column":56,"index":3540},"line":111,"code":"    it('does not configure the provider if none is given', function () {\n      const parsedProviders = mergeKMSProviders({}, {});\n      expect(parsedProviders).not.to.have.property('azure');\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"configures the provider without credentials if an empty object is supplied","suites":["parseOptions","azure"],"updatePoint":{"line":115,"column":82,"index":3765},"line":115,"code":"    it('configures the provider without credentials if an empty object is supplied', function () {\n      const parsedProviders = mergeKMSProviders({\n        azure: {}\n      }, {});\n      expect(parsedProviders.azure).deep.equal({});\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"replaces a $$placeholder value with the value from the environment","suites":["parseOptions","azure"],"updatePoint":{"line":121,"column":74,"index":3998},"line":121,"code":"    it('replaces a $$placeholder value with the value from the environment', function () {\n      const parsedProviders = mergeKMSProviders({\n        azure: {\n          tenantId: 'tenantId',\n          clientId: {\n            $$placeholder: 1\n          },\n          clientSecret: 'clientSecret',\n          identityPlatformEndpoint: 'identifyPlatformEndpoint'\n        }\n      }, {\n        azure: {\n          clientId: 'clientId'\n        }\n      });\n      expect(parsedProviders.azure).deep.equal({\n        tenantId: 'tenantId',\n        clientId: 'clientId',\n        clientSecret: 'clientSecret',\n        identityPlatformEndpoint: 'identifyPlatformEndpoint'\n      });\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"omits required fields if the field is not present in the kmsProviders","suites":["parseOptions","azure"],"updatePoint":{"line":143,"column":77,"index":4673},"line":143,"code":"    it('omits required fields if the field is not present in the kmsProviders', function () {\n      const parsedProviders = mergeKMSProviders({\n        azure: {\n          tenantId: 'tenantId',\n          clientSecret: 'clientSecret',\n          identityPlatformEndpoint: 'identifyPlatformEndpoint'\n        }\n      }, {});\n      expect(parsedProviders.azure).not.to.have.property('clientId');\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"configures the provider with the exact credentials from the test otherwise","suites":["parseOptions","azure"],"updatePoint":{"line":153,"column":82,"index":5076},"line":153,"code":"    it('configures the provider with the exact credentials from the test otherwise', function () {\n      const parsedProviders = mergeKMSProviders({\n        azure: {\n          tenantId: 'tenantId',\n          clientId: 'clientId',\n          clientSecret: 'clientSecret',\n          identityPlatformEndpoint: 'identifyPlatformEndpoint'\n        }\n      }, {\n        azure: {\n          tenantId: 'tenantIdFromEnvironment',\n          clientId: 'clientIdFromEnvironment',\n          clientSecret: 'clientSecretFromEnvironment',\n          identityPlatformEndpoint: 'identifyPlatformEndpointFromEnvironment'\n        }\n      });\n      expect(parsedProviders.azure).deep.equal({\n        tenantId: 'tenantId',\n        clientId: 'clientId',\n        clientSecret: 'clientSecret',\n        identityPlatformEndpoint: 'identifyPlatformEndpoint'\n      });\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"does not configure the provider if none is given","suites":["parseOptions","gcp"],"updatePoint":{"line":178,"column":56,"index":5931},"line":178,"code":"    it('does not configure the provider if none is given', function () {\n      const parsedProviders = mergeKMSProviders({}, {});\n      expect(parsedProviders).not.to.have.property('gcp');\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"configures the provider without credentials if an empty object is supplied","suites":["parseOptions","gcp"],"updatePoint":{"line":182,"column":82,"index":6154},"line":182,"code":"    it('configures the provider without credentials if an empty object is supplied', function () {\n      const parsedProviders = mergeKMSProviders({\n        gcp: {}\n      }, {});\n      expect(parsedProviders.gcp).deep.equal({});\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"replaces a $$placeholder value with the value from the environment","suites":["parseOptions","gcp"],"updatePoint":{"line":188,"column":74,"index":6383},"line":188,"code":"    it('replaces a $$placeholder value with the value from the environment', function () {\n      const parsedProviders = mergeKMSProviders({\n        gcp: {\n          email: 'email',\n          privateKey: {\n            $$placeholder: 1\n          },\n          endPoint: 'endPoint'\n        }\n      }, {\n        gcp: {\n          privateKey: 'privateKeyFromEnvironment'\n        }\n      });\n      expect(parsedProviders.gcp).deep.equal({\n        email: 'email',\n        privateKey: 'privateKeyFromEnvironment',\n        endPoint: 'endPoint'\n      });\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"omits required fields if the field is not present in the kmsProviders","suites":["parseOptions","gcp"],"updatePoint":{"line":208,"column":77,"index":6938},"line":208,"code":"    it('omits required fields if the field is not present in the kmsProviders', function () {\n      const parsedProviders = mergeKMSProviders({\n        gcp: {\n          email: 'email',\n          endPoint: 'endPoint'\n        }\n      }, {});\n      expect(parsedProviders.gcp).not.to.have.property('privateKey');\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"configures the provider with the exact credentials from the test otherwise","suites":["parseOptions","gcp"],"updatePoint":{"line":217,"column":82,"index":7261},"line":217,"code":"    it('configures the provider with the exact credentials from the test otherwise', function () {\n      const parsedProviders = mergeKMSProviders({\n        gcp: {\n          email: 'email',\n          privateKey: 'privateKey',\n          endPoint: 'endPoint'\n        }\n      }, {\n        gcp: {\n          email: 'emailFromEnvironment',\n          privateKey: 'privateKeyFromEnvironment',\n          endPoint: 'endPointFromEnvironment'\n        }\n      });\n      expect(parsedProviders.gcp).deep.equal({\n        email: 'email',\n        privateKey: 'privateKey',\n        endPoint: 'endPoint'\n      });\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"does not configure the provider if none is given","suites":["parseOptions","kmip"],"updatePoint":{"line":239,"column":56,"index":7876},"line":239,"code":"    it('does not configure the provider if none is given', function () {\n      const parsedProviders = mergeKMSProviders({}, {});\n      expect(parsedProviders).not.to.have.property('kmip');\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"configures the provider without credentials if an empty object is supplied","suites":["parseOptions","kmip"],"updatePoint":{"line":243,"column":82,"index":8100},"line":243,"code":"    it('configures the provider without credentials if an empty object is supplied', function () {\n      const parsedProviders = mergeKMSProviders({\n        kmip: {}\n      }, {});\n      expect(parsedProviders.kmip).deep.equal({});\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"replaces a $$placeholder value with the value from the environment","suites":["parseOptions","kmip"],"updatePoint":{"line":249,"column":74,"index":8331},"line":249,"code":"    it('replaces a $$placeholder value with the value from the environment', function () {\n      const parsedProviders = mergeKMSProviders({\n        kmip: {\n          endpoint: {\n            $$placeholder: 1\n          }\n        }\n      }, {\n        kmip: {\n          endpoint: 'endpointFromEnvironment'\n        }\n      });\n      expect(parsedProviders.kmip).deep.equal({\n        endpoint: 'endpointFromEnvironment'\n      });\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"configures the provider with the exact credentials from the test otherwise","suites":["parseOptions","kmip"],"updatePoint":{"line":265,"column":82,"index":8772},"line":265,"code":"    it('configures the provider with the exact credentials from the test otherwise', function () {\n      const parsedProviders = mergeKMSProviders({\n        kmip: {\n          endpoint: 'endpoint'\n        }\n      }, {\n        kmip: {\n          endpoint: 'endpointFromEnvironment'\n        }\n      });\n      expect(parsedProviders.kmip).deep.equal({\n        endpoint: 'endpoint'\n      });\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"uses ReadPreference instance","suites":["class Transaction","constructor()"],"updatePoint":{"line":6,"column":36,"index":240},"line":6,"code":"    it('uses ReadPreference instance', () => {\n      const transaction = new Transaction({\n        readPreference: ReadPreference.nearest\n      });\n      expect(transaction.options).to.have.property('readPreference').that.is.instanceOf(ReadPreference).that.has.property('mode', 'nearest');\n    });","file":"unit/transactions.test.ts","skipped":false,"dir":"test"},{"name":"transforms ReadPreferenceLike string","suites":["class Transaction","constructor()"],"updatePoint":{"line":12,"column":44,"index":546},"line":12,"code":"    it('transforms ReadPreferenceLike string', () => {\n      const transaction = new Transaction({\n        readPreference: 'nearest'\n      });\n      expect(transaction.options).to.have.property('readPreference').that.is.instanceOf(ReadPreference).that.has.property('mode', 'nearest');\n    });","file":"unit/transactions.test.ts","skipped":false,"dir":"test"}]}