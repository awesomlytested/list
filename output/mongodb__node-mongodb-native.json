{"repo":"mongodb/node-mongodb-native","url":"https://github.com/mongodb/node-mongodb-native","branch":"main","configs":[{"package":"mongodb","lang":"js","dir":"test","framework":"mocha","pattern":"**/*[._-]{test,spec,unittest,unit}.{ts,js}"}],"tests":[{"name":"only contains the expected dependencies","suites":["package.json","dependencies"],"updatePoint":{"line":10,"column":47,"index":554},"line":10,"code":"    it('only contains the expected dependencies', function () {\n      expect(dependencies).to.have.keys(EXPECTED_DEPENDENCIES);\n    });","file":"action/dependency.test.ts","skipped":false,"dir":"test"},{"name":"only contains the expected peerDependencies","suites":["package.json","peerDependencies"],"updatePoint":{"line":15,"column":51,"index":745},"line":15,"code":"    it('only contains the expected peerDependencies', function () {\n      expect(peerDependencies).to.have.keys(EXPECTED_PEER_DEPENDENCIES);\n    });","file":"action/dependency.test.ts","skipped":false,"dir":"test"},{"name":"has a meta field for each expected peer","suites":["package.json","peerDependencies"],"updatePoint":{"line":18,"column":47,"index":890},"line":18,"code":"    it('has a meta field for each expected peer', function () {\n      expect(peerDependenciesMeta).to.have.keys(EXPECTED_PEER_DEPENDENCIES);\n    });","file":"action/dependency.test.ts","skipped":false,"dir":"test"},{"name":"driver is importable","suites":["package.json","Optional Peer dependencies","when  is NOT installed"],"updatePoint":{"line":45,"column":32,"index":1963},"line":45,"code":"        it(`driver is importable`, () => {\n          expect(fs.existsSync(path.join(repoRoot, 'node_modules', depName))).to.be.false;\n          const result = execSync(`./node_modules/.bin/ts-node -e \"${testScript}\"`, {\n            encoding: 'utf8'\n          });\n          expect(result).to.include('import success!');\n        });","file":"action/dependency.test.ts","skipped":false,"dir":"test"},{"name":"driver is importable","suites":["package.json","Optional Peer dependencies","when  is installed"],"updatePoint":{"line":57,"column":32,"index":2473},"line":57,"code":"        it(`driver is importable`, () => {\n          expect(fs.existsSync(path.join(repoRoot, 'node_modules', depName))).to.be.true;\n          const result = execSync(`./node_modules/.bin/ts-node -e \"${testScript}\"`, {\n            encoding: 'utf8'\n          });\n          expect(result).to.include('import success!');\n        });","file":"action/dependency.test.ts","skipped":false,"dir":"test"},{"name":"should auth  when explicitly specifying ","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":97,"column":85,"index":3467},"line":97,"code":"          it(`should auth ${user.description} when explicitly specifying ${mechanism}`, {\n            metadata: {\n              requires: {\n                mongodb: '>=3.7.3'\n              }\n            },\n            test: function () {\n              const options = {\n                auth: {\n                  username: user.username,\n                  password: user.password\n                },\n                authMechanism: mechanism,\n                authSource: this.configuration.db\n              };\n              return withClient(this.configuration.newClient({}, options), client => {\n                return client.db(this.configuration.db).stats();\n              });\n            }\n          });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should auth  when explicitly specifying  in url","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":117,"column":92,"index":4179},"line":117,"code":"          it(`should auth ${user.description} when explicitly specifying ${mechanism} in url`, {\n            metadata: {\n              requires: {\n                mongodb: '>=3.7.3'\n              }\n            },\n            test: function () {\n              const username = encodeURIComponent(user.username);\n              const password = encodeURIComponent(user.password);\n              const url = `${makeConnectionString(this.configuration, username, password)}authMechanism=${mechanism}`;\n              const client = this.configuration.newClient(url);\n              return withClient(client, client => {\n                return client.db(this.configuration.db).stats();\n              });\n            }\n          });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should auth  using mechanism negotiaton","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":134,"column":70,"index":4892},"line":134,"code":"        it(`should auth ${user.description} using mechanism negotiaton`, {\n          metadata: {\n            requires: {\n              mongodb: '>=3.7.3'\n            }\n          },\n          test: function () {\n            const options = {\n              auth: {\n                username: user.username,\n                password: user.password\n              },\n              authSource: this.configuration.db\n            };\n            return withClient(this.configuration.newClient({}, options), client => {\n              return client.db(this.configuration.db).stats();\n            });\n          }\n        });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should auth  using mechanism negotiaton and url","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":153,"column":78,"index":5512},"line":153,"code":"        it(`should auth ${user.description} using mechanism negotiaton and url`, {\n          metadata: {\n            requires: {\n              mongodb: '>=3.7.3'\n            }\n          },\n          test: function () {\n            const username = encodeURIComponent(user.username);\n            const password = encodeURIComponent(user.password);\n            const url = makeConnectionString(this.configuration, username, password);\n            const client = this.configuration.newClient(url);\n            return withClient(client, client => {\n              return client.db(this.configuration.db).stats();\n            });\n          }\n        });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should select SCRAM-SHA-256 for a user that supports both auth mechanisms","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":176,"column":83,"index":6367},"line":176,"code":"      it('should select SCRAM-SHA-256 for a user that supports both auth mechanisms', {\n        metadata: {\n          requires: {\n            mongodb: '>=3.7.3'\n          }\n        },\n        test: function () {\n          const options = {\n            auth: {\n              username: userMap.both.username,\n              password: userMap.both.password\n            },\n            authSource: this.configuration.db\n          };\n          test.sandbox.spy(ScramSHA256.prototype, 'auth');\n          return withClient(this.configuration.newClient({}, options), () => {\n            expect(ScramSHA256.prototype.auth.called).to.equal(true);\n          });\n        }\n      });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should shorten SCRAM conversations if the server supports it","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":198,"column":70,"index":7048},"line":198,"code":"      it('should shorten SCRAM conversations if the server supports it', {\n        metadata: {\n          requires: {\n            mongodb: '>=4.4',\n            topology: ['single']\n          }\n        },\n        test: function () {\n          const options = {\n            auth: {\n              username: userMap.both.username,\n              password: userMap.both.password\n            },\n            authSource: this.configuration.db\n          };\n          let runCommandSpy;\n          test.sandbox.stub(ScramSHA256.prototype, 'auth').callsFake(function (authContext, callback) {\n            const connection = authContext.connection;\n            const auth = ScramSHA256.prototype.auth.wrappedMethod;\n            runCommandSpy = test.sandbox.spy(connection, 'command');\n            function _callback(err, res) {\n              runCommandSpy.restore();\n              callback(err, res);\n            }\n            auth.apply(this, [authContext, _callback]);\n          });\n          return withClient(this.configuration.newClient({}, options), () => {\n            expect(runCommandSpy.callCount).to.equal(1);\n          });\n        }\n      });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail to connect if incorrect auth mechanism is explicitly specified","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":234,"column":84,"index":8356},"line":234,"code":"      it('should fail to connect if incorrect auth mechanism is explicitly specified', {\n        metadata: {\n          requires: {\n            mongodb: '>=3.7.3'\n          }\n        },\n        test: function () {\n          const options = {\n            auth: {\n              username: userMap.sha256.username,\n              password: userMap.sha256.password\n            },\n            authSource: this.configuration.db,\n            authMechanism: 'SCRAM-SHA-1'\n          };\n          return withClient(this.configuration.newClient({}, options), () => Promise.reject(new Error('This request should have failed to authenticate')), err => expect(err).to.match(/Authentication failed/));\n        }\n      });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail for a nonexistent username with same error type as bad password","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":262,"column":85,"index":9655},"line":262,"code":"      it('should fail for a nonexistent username with same error type as bad password', {\n        metadata: {\n          requires: {\n            mongodb: '>=3.7.3'\n          }\n        },\n        test: function () {\n          const noUsernameOptions = {\n            auth: {\n              username: 'roth',\n              password: 'pencil'\n            },\n            authSource: 'admin'\n          };\n          const badPasswordOptions = {\n            auth: {\n              username: 'both',\n              password: 'pencil'\n            },\n            authSource: 'admin'\n          };\n          const getErrorMsg = options => withClient(this.configuration.newClient({}, options), () => Promise.reject(new Error('This request should have failed to authenticate')), err => expect(err).to.match(/Authentication failed/));\n          return Promise.all([getErrorMsg(noUsernameOptions), getErrorMsg(badPasswordOptions)]);\n        }\n      });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should send speculativeAuthenticate on initial handshake on MongoDB 4.4+","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":287,"column":82,"index":10584},"line":287,"code":"      it('should send speculativeAuthenticate on initial handshake on MongoDB 4.4+', {\n        metadata: {\n          requires: {\n            mongodb: '>=4.4',\n            topology: ['single']\n          }\n        },\n        test: function () {\n          const options = {\n            auth: {\n              username: userMap.both.username,\n              password: userMap.both.password\n            },\n            authSource: this.configuration.db\n          };\n          const commandSpy = test.sandbox.spy(Connection.prototype, 'command');\n          return withClient(this.configuration.newClient({}, options), () => {\n            const calls = commandSpy.getCalls().filter(c => c.thisValue.id !== '<monitor>') // ignore all monitor connections\n            .filter(c => c.args[1][LEGACY_HELLO_COMMAND]); // only consider handshakes\n\n            expect(calls).to.have.length(1);\n            const handshakeDoc = calls[0].args[1];\n            expect(handshakeDoc).to.have.property('speculativeAuthenticate');\n          });\n        }\n      });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should be able to login with username \"\" and password \"\"","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Step 4"],"updatePoint":{"line":384,"column":90,"index":14279},"line":384,"code":"        it(`should be able to login with username \"${username}\" and password \"${password}\"`, {\n          metadata: {\n            requires: {\n              mongodb: '>=3.7.3'\n            }\n          },\n          test: function () {\n            const options = {\n              auth: {\n                username,\n                password\n              },\n              authSource: 'admin',\n              authMechanism: 'SCRAM-SHA-256'\n            };\n            return withClient(this.configuration.newClient(options), client => {\n              return client.db('admin').stats();\n            });\n          }\n        });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should not authorize when not authenticated","suites":["MONGODB-AWS"],"updatePoint":{"line":19,"column":49,"index":716},"line":19,"code":"  it('should not authorize when not authenticated', async function () {\n    const url = removeAuthFromConnectionString(this.configuration.url());\n    client = this.configuration.newClient(url); // strip provided URI of credentials\n\n    const error = await client.db('aws').collection('aws_test').estimatedDocumentCount().catch(error => error);\n    expect(error).to.be.instanceOf(MongoServerError);\n    expect(error).to.have.property('code', 13);\n  });","file":"integration/auth/mongodb_aws.test.ts","skipped":false,"dir":"test"},{"name":"should authorize when successfully authenticated","suites":["MONGODB-AWS"],"updatePoint":{"line":27,"column":54,"index":1173},"line":27,"code":"  it('should authorize when successfully authenticated', async function () {\n    client = this.configuration.newClient(process.env.MONGODB_URI); // use the URI built by the test environment\n\n    const result = await client.db('aws').collection('aws_test').estimatedDocumentCount().catch(error => error);\n    expect(result).to.not.be.instanceOf(MongoServerError);\n    expect(result).to.be.a('number');\n  });","file":"integration/auth/mongodb_aws.test.ts","skipped":false,"dir":"test"},{"name":"should allow empty string in authMechanismProperties.AWS_SESSION_TOKEN to override AWS_SESSION_TOKEN environment variable","suites":["MONGODB-AWS"],"updatePoint":{"line":34,"column":127,"index":1653},"line":34,"code":"  it('should allow empty string in authMechanismProperties.AWS_SESSION_TOKEN to override AWS_SESSION_TOKEN environment variable', function () {\n    client = this.configuration.newClient(this.configuration.url(), {\n      authMechanismProperties: {\n        AWS_SESSION_TOKEN: ''\n      }\n    });\n    expect(client).to.have.nested.property('options.credentials.mechanismProperties.AWS_SESSION_TOKEN').that.equals('');\n  });","file":"integration/auth/mongodb_aws.test.ts","skipped":false,"dir":"test"},{"name":"should respect the default timeout of 10000ms","suites":["MONGODB-AWS","EC2 with missing credentials"],"updatePoint":{"line":64,"column":53,"index":2758},"line":64,"code":"    it('should respect the default timeout of 10000ms', async function () {\n      const config = this.configuration;\n      client = config.newClient(process.env.MONGODB_URI, {\n        authMechanism: 'MONGODB-AWS'\n      }); // use the URI built by the test environment\n      const startTime = performance.now();\n      const caughtError = await client.db().command({\n        ping: 1\n      }).catch(error => error);\n      const endTime = performance.now();\n      const timeTaken = endTime - startTime;\n      expect(caughtError).to.be.instanceOf(MongoAWSError);\n      expect(caughtError).property('message').match(/(timed out after)|(Could not load credentials)/);\n      // Credentials provider from the SDK does not allow to configure the timeout\n      // and defaults to 2 seconds - so we ensure this timeout happens below 12s\n      // instead of the 10s-12s range previously.\n      expect(timeTaken).to.be.below(12000);\n    });","file":"integration/auth/mongodb_aws.test.ts","skipped":false,"dir":"test"},{"name":"successfuly authenticates","suites":["SCRAM-SHA-1"],"updatePoint":{"line":15,"column":31,"index":653},"line":15,"code":"  it('successfuly authenticates', async () => {\n    const result = await client.db().admin().command({\n      ping: 1\n    });\n    expect(result).to.have.property('ok', 1);\n  });","file":"integration/auth/scram_sha_1.test.ts","skipped":false,"dir":"test"},{"name":"should shorten SCRAM conversations if the server supports it","suites":["SCRAM_SHA_256"],"updatePoint":{"line":67,"column":66,"index":2129},"line":67,"code":"  it('should shorten SCRAM conversations if the server supports it', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.4',\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const options = {\n        auth: {\n          username: userMap.both.username,\n          password: userMap.both.password\n        },\n        authSource: this.configuration.db\n      };\n      let runCommandSpy;\n      test.sandbox.stub(ScramSHA256.prototype, 'auth').callsFake(function (authContext, callback) {\n        const connection = authContext.connection;\n        const auth = ScramSHA256.prototype.auth.wrappedMethod;\n        runCommandSpy = test.sandbox.spy(connection, 'command');\n        function _callback(err, res) {\n          runCommandSpy.restore();\n          callback(err, res);\n        }\n        auth.apply(this, [authContext, _callback]);\n      });\n      return withClient(this.configuration.newClient({}, options), () => {\n        expect(runCommandSpy.callCount).to.equal(1);\n      });\n    }\n  });","file":"integration/auth/scram_sha_256.test.js","skipped":false,"dir":"test"},{"name":"should send speculativeAuthenticate on initial handshake on MongoDB 4.4+","suites":["SCRAM_SHA_256"],"updatePoint":{"line":98,"column":78,"index":3157},"line":98,"code":"  it('should send speculativeAuthenticate on initial handshake on MongoDB 4.4+', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.4',\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const options = {\n        auth: {\n          username: userMap.both.username,\n          password: userMap.both.password\n        },\n        authSource: this.configuration.db\n      };\n      const commandSpy = test.sandbox.spy(Connection.prototype, 'command');\n      return withClient(this.configuration.newClient({}, options), () => {\n        const calls = commandSpy.getCalls().filter(c => c.thisValue.id !== '<monitor>') // ignore all monitor connections\n        .filter(c => c.args[1][LEGACY_HELLO_COMMAND]); // only consider handshakes\n\n        expect(calls).to.have.length(1);\n        const handshakeDoc = calls[0].args[1];\n        expect(handshakeDoc).to.have.property('speculativeAuthenticate');\n      });\n    }\n  });","file":"integration/auth/scram_sha_256.test.js","skipped":false,"dir":"test"},{"name":"Should correctly authenticate using x509","suites":["SSL (x509)"],"updatePoint":{"line":21,"column":46,"index":389},"line":21,"code":"  it('Should correctly authenticate using x509', {\n    metadata: {\n      requires: {\n        topology: 'ssl'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var ServerManager = require('mongodb-topology-manager').Server;\n\n      // Read the cert and key\n      var cert = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n      var key = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n\n      // User name\n      var userName = 'CN=client,OU=kerneluser,O=10Gen,L=New York City,ST=New York,C=US';\n\n      // Create server manager\n      var serverManager = new ServerManager('mongod', {\n        bind_ip: 'server',\n        port: 27019,\n        dbpath: f('%s/../db/27019', __dirname),\n        sslPEMKeyFile: __dirname + '/ssl/x509/server.pem',\n        sslCAFile: __dirname + '/ssl/x509/ca.pem',\n        sslCRLFile: __dirname + '/ssl/x509/crl.pem',\n        sslMode: 'requireSSL',\n        sslWeakCertificateValidation: null\n      }, {\n        ssl: true,\n        host: 'server',\n        key: cert,\n        cert: cert,\n        rejectUnauthorized: false\n      });\n\n      // Purge the set\n      serverManager.purge().then(function () {\n        // Start the server\n        serverManager.start().then(function () {\n          // Connect and validate the server certificate\n          MongoClient.connect('mongodb://server:27019/test?ssl=true&maxPoolSize=1', {\n            server: {\n              sslKey: key,\n              sslCert: cert,\n              sslValidate: false\n            }\n          }, function (err, client) {\n            expect(err).to.not.exist;\n            var db = client.db(configuration.db);\n\n            // Execute build info\n            db.command({\n              buildInfo: 1\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              var version = parseInt(result.versionArray.slice(0, 3).join(''), 10);\n              if (version < 253) {\n                client.close();\n                return done();\n              }\n\n              // Add the X509 auth user to the $external db\n              var ext = client.db('$external');\n              ext.addUser(userName, {\n                roles: [{\n                  role: 'readWriteAnyDatabase',\n                  db: 'admin'\n                }, {\n                  role: 'userAdminAnyDatabase',\n                  db: 'admin'\n                }]\n              }, function (err, result) {\n                expect(err).to.not.exist;\n                test.equal(userName, result[0].user);\n                test.equal('', result[0].pwd);\n                client.close();\n\n                // Connect using X509 authentication\n                MongoClient.connect(f('mongodb://%s@server:27019/test?authMechanism=%s&ssl=true&maxPoolSize=1', encodeURIComponent(userName), 'MONGODB-X509'), {\n                  server: {\n                    sslKey: key,\n                    sslCert: cert,\n                    sslValidate: false\n                  }\n                }, function (err, client) {\n                  expect(err).to.not.exist;\n                  client.close();\n                  serverManager.stop().then(function () {\n                    done();\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/auth/ssl_x509_connect.test.js","skipped":false,"dir":"test"},{"name":"Should correctly handle bad x509 certificate","suites":["SSL (x509)"],"updatePoint":{"line":119,"column":50,"index":3694},"line":119,"code":"  it('Should correctly handle bad x509 certificate', {\n    metadata: {\n      requires: {\n        topology: 'ssl'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var ServerManager = require('mongodb-topology-manager').Server;\n\n      // Read the cert and key\n      var cert = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n      var key = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n      var serverPem = fs.readFileSync(__dirname + '/ssl/x509/server.pem');\n\n      // User name\n      var userName = 'CN=client,OU=kerneluser,O=10Gen,L=New York City,ST=New York,C=US';\n\n      // Create server manager\n      var serverManager = new ServerManager('mongod', {\n        bind_ip: 'server',\n        port: 27019,\n        dbpath: f('%s/../db/27019', __dirname),\n        sslPEMKeyFile: __dirname + '/ssl/x509/server.pem',\n        sslCAFile: __dirname + '/ssl/x509/ca.pem',\n        sslCRLFile: __dirname + '/ssl/x509/crl.pem',\n        sslMode: 'requireSSL',\n        sslWeakCertificateValidation: null\n      }, {\n        ssl: true,\n        host: 'server',\n        key: cert,\n        cert: cert,\n        rejectUnauthorized: false\n      });\n\n      // Purge the set\n      serverManager.purge().then(function () {\n        // Start the server\n        serverManager.start().then(function () {\n          // Connect and validate the server certificate\n          MongoClient.connect('mongodb://server:27019/test?ssl=true&maxPoolSize=1', {\n            server: {\n              sslKey: key,\n              sslCert: cert,\n              sslValidate: false\n            }\n          }, function (err, client) {\n            expect(err).to.not.exist;\n            var db = client.db(configuration.db);\n\n            // Execute build info\n            db.command({\n              buildInfo: 1\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              var version = parseInt(result.versionArray.slice(0, 3).join(''), 10);\n              if (version < 253) {\n                client.close();\n                return done();\n              }\n\n              // Add the X509 auth user to the $external db\n              var ext = client.db('$external');\n              ext.addUser(userName, {\n                roles: [{\n                  role: 'readWriteAnyDatabase',\n                  db: 'admin'\n                }, {\n                  role: 'userAdminAnyDatabase',\n                  db: 'admin'\n                }]\n              }, function (err, result) {\n                expect(err).to.not.exist;\n                test.equal(userName, result[0].user);\n                test.equal('', result[0].pwd);\n                client.close();\n\n                // Connect using X509 authentication\n                MongoClient.connect(f('mongodb://%s@server:27019/test?authMechanism=%s&ssl=true&maxPoolSize=1', encodeURIComponent(userName), 'MONGODB-X509'), {\n                  server: {\n                    sslKey: serverPem,\n                    sslCert: serverPem,\n                    sslValidate: false\n                  }\n                }, function (err) {\n                  test.equal(0, err.ok);\n                  test.equal('auth failed', err.errmsg);\n                  serverManager.stop().then(function () {\n                    done();\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/auth/ssl_x509_connect.test.js","skipped":false,"dir":"test"},{"name":"Should give reasonable error on x509 authentication failure","suites":["SSL (x509)"],"updatePoint":{"line":218,"column":65,"index":7112},"line":218,"code":"  it('Should give reasonable error on x509 authentication failure', {\n    metadata: {\n      requires: {\n        topology: 'ssl'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var ServerManager = require('mongodb-topology-manager').Server;\n\n      // Read the cert and key\n      var cert = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n      var key = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n\n      // User name\n      var userName = 'CN=client,OU=kerneluser,O=10Gen,L=New York City,ST=New York,C=US';\n\n      // Create server manager\n      var serverManager = new ServerManager('mongod', {\n        bind_ip: 'server',\n        port: 27019,\n        dbpath: f('%s/../db/27019', __dirname),\n        sslPEMKeyFile: __dirname + '/ssl/x509/server.pem',\n        sslCAFile: __dirname + '/ssl/x509/ca.pem',\n        sslCRLFile: __dirname + '/ssl/x509/crl.pem',\n        sslMode: 'requireSSL',\n        sslWeakCertificateValidation: null\n      }, {\n        ssl: true,\n        host: 'server',\n        key: cert,\n        cert: cert,\n        rejectUnauthorized: false\n      });\n\n      // Purge the set\n      serverManager.purge().then(function () {\n        // Start the server\n        serverManager.start().then(function () {\n          // Connect and validate the server certificate\n          MongoClient.connect('mongodb://server:27019/test?ssl=true&maxPoolSize=1', {\n            server: {\n              sslKey: key,\n              sslCert: cert,\n              sslValidate: false\n            }\n          }, function (err, client) {\n            expect(err).to.not.exist;\n            var db = client.db(configuration.db);\n\n            // Execute build info\n            db.command({\n              buildInfo: 1\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              var version = parseInt(result.versionArray.slice(0, 3).join(''), 10);\n              if (version < 253) {\n                client.close();\n                return done();\n              }\n\n              // Add the X509 auth user to the $external db\n              var ext = client.db('$external');\n              ext.addUser(userName, {\n                roles: [{\n                  role: 'readWriteAnyDatabase',\n                  db: 'admin'\n                }, {\n                  role: 'userAdminAnyDatabase',\n                  db: 'admin'\n                }]\n              }, function (err, result) {\n                expect(err).to.not.exist;\n                test.equal(userName, result[0].user);\n                test.equal('', result[0].pwd);\n                client.close();\n\n                // Connect using X509 authentication\n                MongoClient.connect(f('mongodb://%s@server:27019/test?authMechanism=%s&ssl=true&maxPoolSize=1', encodeURIComponent('WRONG_USERNAME'), 'MONGODB-X509'), {\n                  server: {\n                    sslKey: key,\n                    sslCert: cert,\n                    sslValidate: false\n                  }\n                }, function (err) {\n                  test.equal(0, err.ok);\n                  test.equal('auth failed', err.errmsg);\n                  serverManager.stop().then(function () {\n                    done();\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/auth/ssl_x509_connect.test.js","skipped":false,"dir":"test"},{"name":"Should give helpful error when attempting to use x509 without SSL","suites":["SSL (x509)"],"updatePoint":{"line":316,"column":71,"index":10458},"line":316,"code":"  it('Should give helpful error when attempting to use x509 without SSL', {\n    metadata: {\n      requires: {\n        topology: 'ssl'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var ServerManager = require('mongodb-topology-manager').Server;\n\n      // Read the cert and key\n      var cert = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n      var key = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n      var serverPem = fs.readFileSync(__dirname + '/ssl/x509/server.pem');\n\n      // User name\n      var userName = 'CN=client,OU=kerneluser,O=10Gen,L=New York City,ST=New York,C=US';\n\n      // Create server manager\n      var serverManager = new ServerManager('mongod', {\n        bind_ip: 'server',\n        port: 27019,\n        dbpath: f('%s/../db/27019', __dirname)\n      }, {});\n\n      // Purge the set\n      serverManager.purge().then(function () {\n        // Start the server\n        serverManager.start().then(function () {\n          // Connect and validate the server certificate\n          MongoClient.connect('mongodb://server:27019/test?ssl=false&maxPoolSize=1', {\n            server: {\n              sslKey: key,\n              sslCert: cert,\n              sslValidate: false\n            }\n          }, function (err, client) {\n            expect(err).to.not.exist;\n            var db = client.db(configuration.db);\n\n            // Execute build info\n            db.command({\n              buildInfo: 1\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              var version = parseInt(result.versionArray.slice(0, 3).join(''), 10);\n              if (version < 253) {\n                client.close();\n                return done();\n              }\n\n              // Add the X509 auth user to the $external db\n              var ext = client.db('$external');\n              ext.addUser(userName, {\n                roles: [{\n                  role: 'readWriteAnyDatabase',\n                  db: 'admin'\n                }, {\n                  role: 'userAdminAnyDatabase',\n                  db: 'admin'\n                }]\n              }, function (err, result) {\n                expect(err).to.not.exist;\n                test.equal(userName, result[0].user);\n                test.equal('', result[0].pwd);\n                client.close();\n\n                // Connect using X509 authentication\n                MongoClient.connect(f('mongodb://%s@server:27019/test?authMechanism=%s&ssl=false&maxPoolSize=1', encodeURIComponent(userName), 'MONGODB-X509'), {\n                  server: {\n                    sslKey: serverPem,\n                    sslCert: serverPem,\n                    sslValidate: false\n                  }\n                }, function (err) {\n                  test.ok(!!err);\n                  test.equal(0, err.ok);\n                  test.equal('SSL support is required for the MONGODB-X509 mechanism.', err.errmsg);\n                  serverManager.stop().then(function () {\n                    done();\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/auth/ssl_x509_connect.test.js","skipped":false,"dir":"test"},{"name":"Should correctly reauthenticate against x509","suites":["SSL (x509)"],"updatePoint":{"line":405,"column":50,"index":13580},"line":405,"code":"  it('Should correctly reauthenticate against x509', {\n    metadata: {\n      requires: {\n        topology: 'ssl'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var ServerManager = require('mongodb-topology-manager').Server;\n\n      // Read the cert and key\n      var cert = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n      var key = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n\n      // User name\n      var userName = 'CN=client,OU=kerneluser,O=10Gen,L=New York City,ST=New York,C=US';\n\n      // Create server manager\n      var serverManager = new ServerManager('mongod', {\n        bind_ip: 'server',\n        port: 27019,\n        dbpath: f('%s/../db/27019', __dirname),\n        sslPEMKeyFile: __dirname + '/ssl/x509/server.pem',\n        sslCAFile: __dirname + '/ssl/x509/ca.pem',\n        sslCRLFile: __dirname + '/ssl/x509/crl.pem',\n        sslMode: 'requireSSL',\n        sslWeakCertificateValidation: null\n      }, {\n        ssl: true,\n        host: 'server',\n        key: cert,\n        cert: cert,\n        rejectUnauthorized: false\n      });\n\n      // Purge the set\n      serverManager.purge().then(function () {\n        // Start the server\n        serverManager.start().then(function () {\n          // Connect and validate the server certificate\n          MongoClient.connect('mongodb://server:27019/test?ssl=true&maxPoolSize=1', {\n            server: {\n              sslKey: key,\n              sslCert: cert,\n              sslValidate: false\n            }\n          }, function (err, client) {\n            expect(err).to.not.exist;\n            var db = client.db(configuration.db);\n\n            // Execute build info\n            db.command({\n              buildInfo: 1\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              var version = parseInt(result.versionArray.slice(0, 3).join(''), 10);\n              if (version < 253) {\n                client.close();\n                return done();\n              }\n\n              // Add the X509 auth user to the $external db\n              var ext = client.db('$external');\n              ext.addUser(userName, {\n                roles: [{\n                  role: 'readWriteAnyDatabase',\n                  db: 'admin'\n                }, {\n                  role: 'userAdminAnyDatabase',\n                  db: 'admin'\n                }]\n              }, function (err, result) {\n                expect(err).to.not.exist;\n                test.equal(userName, result[0].user);\n                test.equal('', result[0].pwd);\n                client.close();\n\n                // Connect using X509 authentication\n                MongoClient.connect(f('mongodb://%s@server:27019/test?authMechanism=%s&ssl=true&maxPoolSize=1', encodeURIComponent(userName), 'MONGODB-X509'), {\n                  server: {\n                    sslKey: key,\n                    sslCert: cert,\n                    sslValidate: false\n                  }\n                }, function (err, client) {\n                  expect(err).to.not.exist;\n                  var db = client.db(configuration.db);\n                  db.collection('x509collection').insert({\n                    a: 1\n                  }, function (err) {\n                    expect(err).to.not.exist;\n                    db.collection('x509collection').findOne(function (err, doc) {\n                      expect(err).to.not.exist;\n                      test.equal(1, doc.a);\n                      client.topology.once('reconnect', function () {\n                        // Await reconnect and re-authentication\n                        db.collection('x509collection').findOne(function (err, doc) {\n                          expect(err).to.not.exist;\n                          test.equal(1, doc.a);\n\n                          // Attempt disconnect again\n                          client.topology.connections()[0].destroy();\n\n                          // Await reconnect and re-authentication\n                          db.collection('x509collection').findOne(function (err, doc) {\n                            expect(err).to.not.exist;\n                            test.equal(1, doc.a);\n                            client.close();\n                            serverManager.stop().then(function () {\n                              done();\n                            });\n                          });\n                        });\n                      });\n\n                      // Force close\n                      client.topology.connections()[0].destroy();\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/auth/ssl_x509_connect.test.js","skipped":false,"dir":"test"},{"name":"should correctly insert decimal128 value","suites":["Decimal128"],"updatePoint":{"line":19,"column":46,"index":362},"line":19,"code":"  it('should correctly insert decimal128 value', function (done) {\n    var configuration = this.configuration;\n    var client = configuration.newClient(configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    var db = client.db(configuration.db);\n    var object = {\n      id: 1,\n      value: Decimal128.fromString('1.28')\n    };\n    db.collection('decimal128').insertOne(object, function (err) {\n      expect(err).to.not.exist;\n      db.collection('decimal128').findOne({\n        id: 1\n      }, function (err, doc) {\n        expect(err).to.not.exist;\n        test.ok(doc.value instanceof Decimal128);\n        test.equal('1.28', doc.value.toString());\n        client.close(done);\n      });\n    });\n  });","file":"integration/bson-decimal128/decimal128.test.js","skipped":false,"dir":"test"},{"name":"2. The first read in a causally consistent session must not send afterClusterTime to the server","suites":["Causal Consistency - prose tests"],"updatePoint":{"line":52,"column":101,"index":1799},"line":52,"code":"  it('2. The first read in a causally consistent session must not send afterClusterTime to the server',\n  /**\n   * session = client.startSession(causalConsistency = true)\n   * document = collection.anyReadOperation(session, ...)\n   * capture the command sent to the server (using APM or other mechanism)\n   * assert that the command does not have an afterClusterTime\n   */\n  {\n    metadata: {\n      requires: {\n        topology: ['replicaset', 'sharded']\n      }\n    },\n    test: function () {\n      const session = test.client.startSession({\n        causalConsistency: true\n      });\n      const db = test.client.db(this.configuration.db);\n      return db.collection('causal_test').findOne({}, {\n        session: session\n      }).then(() => {\n        expect(test.commands.started).to.have.length(1);\n        expect(test.commands.succeeded).to.have.length(1);\n        const findCommand = test.commands.started[0].command;\n        expect(findCommand).to.have.property('find', 'causal_test');\n        expect(findCommand).to.not.have.key('readConcern');\n      });\n    }\n  });","file":"integration/causal-consistency/causal_consistency.prose.test.js","skipped":false,"dir":"test"},{"name":"case: successful read with causal consistency","suites":["Causal Consistency - prose tests","3. The first read or write on a ClientSession should update the operationTime of the ClientSession, even if there is an error"],"updatePoint":{"line":92,"column":53,"index":3516},"line":92,"code":"    it('case: successful read with causal consistency', {\n      metadata: {\n        requires: {\n          topology: ['replicaset', 'sharded']\n        }\n      },\n      test: function () {\n        const session = test.client.startSession({\n          causalConsistency: true\n        });\n        const db = test.client.db(this.configuration.db);\n        expect(session.operationTime).to.not.exist;\n        return db.collection('causal_test').findOne({}, {\n          session: session\n        }).then(() => {\n          expect(test.commands.started).to.have.length(1);\n          expect(test.commands.succeeded).to.have.length(1);\n          const lastReply = test.commands.succeeded[0].reply;\n          const maybeLong = val => typeof val.equals === 'function' ? val.toNumber() : val;\n          expect(maybeLong(session.operationTime)).to.equal(maybeLong(lastReply.operationTime));\n        });\n      }\n    });","file":"integration/causal-consistency/causal_consistency.prose.test.js","skipped":false,"dir":"test"},{"name":"case: second operation is findOne","suites":["Causal Consistency - prose tests","4. A findOne followed by any other read operation should include the operationTime returned by the server for the first operation in the afterClusterTime parameter of the second operation"],"updatePoint":{"line":126,"column":41,"index":5062},"line":126,"code":"    it('case: second operation is findOne', {\n      metadata: {\n        requires: {\n          topology: ['replicaset', 'sharded']\n        }\n      },\n      test: function () {\n        const session = test.client.startSession({\n          causalConsistency: true\n        });\n        const db = test.client.db(this.configuration.db);\n        expect(session.operationTime).to.not.exist;\n        let firstOperationTime;\n        return db.collection('causal_test').findOne({}, {\n          session: session\n        }).then(() => {\n          const firstFindCommand = test.commands.started[0].command;\n          expect(firstFindCommand).to.not.have.key('readConcern');\n          firstOperationTime = test.commands.succeeded[0].reply.operationTime;\n          return db.collection('causal_test').findOne({}, {\n            session: session\n          });\n        }).then(() => {\n          const secondFindCommand = test.commands.started[1].command;\n          expect(secondFindCommand).to.have.any.key('readConcern');\n          expect(secondFindCommand.readConcern).to.have.any.key('afterClusterTime');\n          expect(secondFindCommand.readConcern.afterClusterTime).to.eql(firstOperationTime);\n        });\n      }\n    });","file":"integration/causal-consistency/causal_consistency.prose.test.js","skipped":false,"dir":"test"},{"name":"case: successful insert","suites":["Causal Consistency - prose tests","5. Any write operation followed by a findOne operation should include the operationTime of the first operation in the afterClusterTime parameter of the second operation"],"updatePoint":{"line":168,"column":31,"index":6987},"line":168,"code":"    it('case: successful insert', {\n      metadata: {\n        requires: {\n          topology: ['replicaset', 'sharded']\n        }\n      },\n      test: function () {\n        const session = test.client.startSession({\n          causalConsistency: true\n        });\n        const db = test.client.db(this.configuration.db);\n        expect(session.operationTime).to.not.exist;\n        let firstOperationTime;\n        return db.collection('causal_test').insert({}, {\n          session: session\n        }).then(() => {\n          firstOperationTime = test.commands.succeeded[0].reply.operationTime;\n          return db.collection('causal_test').findOne({}, {\n            session: session\n          });\n        }).then(() => {\n          const secondFindCommand = test.commands.started[1].command;\n          expect(secondFindCommand).to.have.any.key('readConcern');\n          expect(secondFindCommand.readConcern).to.have.any.key('afterClusterTime');\n          expect(secondFindCommand.readConcern.afterClusterTime).to.eql(firstOperationTime);\n        });\n      }\n    });","file":"integration/causal-consistency/causal_consistency.prose.test.js","skipped":false,"dir":"test"},{"name":"6. A read operation in a ClientSession that is not causally consistent should not include the afterClusterTime parameter in the command sent to the server","suites":["Causal Consistency - prose tests","5. Any write operation followed by a findOne operation should include the operationTime of the first operation in the afterClusterTime parameter of the second operation"],"updatePoint":{"line":197,"column":160,"index":8184},"line":197,"code":"  it('6. A read operation in a ClientSession that is not causally consistent should not include the afterClusterTime parameter in the command sent to the server',\n  /**\n   * session = client.startSession(causalConsistency = false)\n   * collection.anyReadOperation(session, {})\n   * operationTime = session.operationTime\n   * capture the command sent to the server (using APM or other mechanism)\n   * assert that the command does not have an afterClusterTime field\n   */\n  {\n    metadata: {\n      requires: {\n        topology: ['replicaset', 'sharded']\n      }\n    },\n    test: function () {\n      const session = test.client.startSession({\n        causalConsistency: false\n      });\n      const db = test.client.db(this.configuration.db);\n      const coll = db.collection('causal_test', {\n        readConcern: {\n          level: 'majority'\n        }\n      });\n      return coll.findOne({}, {\n        session: session\n      }).then(() => coll.findOne({}, {\n        session: session\n      })).then(() => {\n        const commands = test.commands.started.map(command => command.command);\n        expect(commands).to.have.length(2);\n        for (const command of commands) {\n          expect(command).to.have.any.key('readConcern');\n          expect(command.readConcern).to.not.have.any.key('afterClusterTime');\n        }\n      });\n    }\n  });","file":"integration/causal-consistency/causal_consistency.prose.test.js","skipped":false,"dir":"test"},{"name":"7. A read operation in a causally consistent session against a deployment that does not support cluster times does not include the afterClusterTime parameter in the command sent to the server","suites":["Causal Consistency - prose tests","5. Any write operation followed by a findOne operation should include the operationTime of the first operation in the afterClusterTime parameter of the second operation"],"updatePoint":{"line":235,"column":197,"index":9560},"line":235,"code":"  it('7. A read operation in a causally consistent session against a deployment that does not support cluster times does not include the afterClusterTime parameter in the command sent to the server',\n  /**\n   * session = client.startSession(causalConsistency = true)\n   * collection.anyReadOperation(session, {})\n   * capture the command sent to the server (using APM or other mechanism)\n   * assert that the command does not have an afterClusterTime field\n   */\n  {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const db = test.client.db(this.configuration.db);\n      const coll = db.collection('causal_test', {\n        readConcern: {\n          level: 'local'\n        }\n      });\n      return coll.findOne({}).then(() => coll.findOne({})).then(() => {\n        const command = test.commands.started[1].command;\n        expect(command).to.have.any.key('readConcern');\n        expect(command.readConcern).to.not.have.any.key('afterClusterTime');\n      });\n    }\n  });","file":"integration/causal-consistency/causal_consistency.prose.test.js","skipped":false,"dir":"test"},{"name":"should pass corpus  client schema","suites":["Client Side Encryption Prose Corpus Test"],"updatePoint":{"line":202,"column":84,"index":8629},"line":202,"code":"    it(`should pass corpus ${useClientSideSchema ? 'with' : 'without'} client schema`, metadata, function () {\n      const corpusCopied = {};\n      return Promise.resolve().then(() => {\n        // 5. Load `corpus/corpus.json <../corpus/corpus.json>`_ to a variable named ``corpus``. The corpus contains subdocuments with the following fields:\n        //\n        //    - ``kms`` is either ``aws`` or ``local``\n        //    - ``type`` is a BSON type string `names coming from here <https://www.mongodb.com/docs/manual/reference/operator/query/type/>`_)\n        //    - ``algo`` is either ``rand`` or ``det`` for random or deterministic encryption\n        //    - ``method`` is either ``auto``, for automatic encryption or ``explicit`` for  explicit encryption\n        //    - ``identifier`` is either ``id`` or ``altname`` for the key identifier\n        //    - ``allowed`` is a boolean indicating whether the encryption for the given parameters is permitted.\n        //    - ``value`` is the value to be tested.\n        //\n        //    Create a new BSON document, named ``corpus_copied``.\n        //\n        //    Iterate over each field of ``corpus``.\n        //    - If the field name is ``_id``, ``altname_aws`` and ``altname_local``, copy the field to ``corpus_copied``.\n        //    - If ``method`` is ``auto``, copy the field to ``corpus_copied``.\n        //    - If ``method`` is ``explicit``, use ``client_encryption`` to explicitly encrypt the value.\n        //      - Encrypt with the algorithm described by ``algo``.\n        //      - If ``identifier`` is ``id``\n        //        - If ``kms`` is ``local`` set the key_id to the UUID with base64 value ``LOCALAAAAAAAAAAAAAAAAA==``.\n        //        - If ``kms`` is ``aws`` set the key_id to the UUID with base64 value ``AWSAAAAAAAAAAAAAAAAAAA==``.\n        //      - If ``identifier`` is ``altname``\n        //        - If ``kms`` is ``local`` set the key_alt_name to \"local\".\n        //        - If ``kms`` is ``aws`` set the key_alt_name to \"aws\".\n        //      If ``allowed`` is true, copy the field and encrypted value to ``corpus_copied``.\n        //      If ``allowed`` is false. verify that an exception is thrown. Copy the unencrypted value to to ``corpus_copied``.\n        return forEachP(Object.keys(corpus), key => {\n          const field = corpus[key];\n          if (copyOverValues.has(key)) {\n            corpusCopied[key] = field;\n            return;\n          }\n          if (field.method === 'auto') {\n            corpusCopied[key] = Object.assign({}, field);\n            return;\n          }\n          if (field.method === 'explicit') {\n            const encryptOptions = {\n              algorithm: algorithmMap.get(field.algo)\n            };\n            if (field.identifier === 'id') {\n              encryptOptions.keyId = identifierMap.get(field.kms);\n            } else if (field.identifier === 'altname') {\n              encryptOptions.keyAltName = keyAltNameMap.get(field.kms);\n            } else {\n              throw new Error('Unexpected identifier: ' + field.identifier);\n            }\n            return Promise.resolve().then(() => clientEncryption.encrypt(field.value, encryptOptions)).then(encryptedValue => {\n              if (field.allowed === true) {\n                corpusCopied[key] = Object.assign({}, field, {\n                  value: encryptedValue\n                });\n              } else {\n                throw new Error(`Expected encryption to fail for case ${key} on value ${field.value}`);\n              }\n            }, e => {\n              if (field.allowed === false) {\n                corpusCopied[key] = Object.assign({}, field);\n              } else {\n                throw e;\n              }\n            });\n          }\n          throw new Error('Unexpected method: ' + field.method);\n        });\n      }).then(() => {\n        // 6. Using ``client_encrypted``, insert ``corpus_copied`` into ``db.coll``.\n        return clientEncrypted.db(dataDbName).collection(dataCollName).insertOne(corpusCopied);\n      }).then(() => {\n        // 7. Using ``client_encrypted``, find the inserted document from ``db.coll`` to a variable named ``corpus_decrypted``.\n        // Since it should have been automatically decrypted, assert the document exactly matches ``corpus``.\n        return clientEncrypted.db(dataDbName).collection(dataCollName).findOne({\n          _id: corpusCopied._id\n        }, {\n          promoteLongs: false,\n          promoteValues: false\n        });\n      }).then(corpusDecrypted => {\n        expect(toComparableExtendedJSON(corpusDecrypted)).to.deep.equal(toComparableExtendedJSON(corpus));\n      }).then(() => {\n        // 8. Load `corpus/corpus_encrypted.json <../corpus/corpus-encrypted.json>`_ to a variable named ``corpus_encrypted_expected``.\n        //    Using ``client`` find the inserted document from ``db.coll`` to a variable named ``corpus_encrypted_actual``.\n\n        //    Iterate over each field of ``corpus_encrypted_expected`` and check the following:\n\n        //    - If the ``algo`` is ``det``, that the value equals the value of the corresponding field in ``corpus_encrypted_actual``.\n        //    - If the ``algo`` is ``rand`` and ``allowed`` is true, that the value does not equal the value of the corresponding field in ``corpus_encrypted_actual``.\n        //    - If ``allowed`` is true, decrypt the value with ``client_encryption``. Decrypt the value of the corresponding field of ``corpus_encrypted`` and validate that they are both equal.\n        //    - If ``allowed`` is false, validate the value exactly equals the value of the corresponding field of ``corpus`` (neither was encrypted).\n        return client.db(dataDbName).collection(dataCollName).findOne({\n          _id: corpusCopied._id\n        }, {\n          promoteLongs: false,\n          promoteValues: false\n        });\n      }).then(corpusEncryptedActual => {\n        return forEachP(Object.keys(corpusEncryptedExpected), key => {\n          return assertion(clientEncryption, key, corpusEncryptedExpected[key], corpusEncryptedActual[key]);\n        });\n      });\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.06.corpus.test.js","skipped":false,"dir":"test"},{"name":"expects an error and a command failed event","suites":["14. Decryption Events","Case 1: Command Error"],"updatePoint":{"line":134,"column":51,"index":5170},"line":134,"code":"    it('expects an error and a command failed event', async function () {\n      // Use ``encryptedClient`` to run an aggregate on ``db.decryption_events``.\n      // Expect an exception to be thrown from the command error. Expect a CommandFailedEvent.\n      const collection = encryptedClient.db('db').collection('decryption_events');\n      const error = await collection.aggregate([]).toArray().catch(error => error);\n      expect(error).to.have.property('code', 123);\n      expect(aggregateFailed).to.have.nested.property('failure.code', 123);\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.14.decryption_events.test.ts","skipped":false,"dir":"test"},{"name":"expects an error and a command failed event","suites":["14. Decryption Events","Case 2: Network Error"],"updatePoint":{"line":171,"column":51,"index":6559},"line":171,"code":"    it('expects an error and a command failed event', async function () {\n      // Use ``encryptedClient`` to run an aggregate on ``db.decryption_events``.\n      // Expect an exception to be thrown from the network error. Expect a CommandFailedEvent.\n      const collection = encryptedClient.db('db').collection('decryption_events');\n      const error = await collection.aggregate([]).toArray().catch(error => error);\n      expect(error).to.be.instanceOf(MongoNetworkError);\n      expect(aggregateFailed).to.have.nested.property('failure.message').to.include('closed');\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.14.decryption_events.test.ts","skipped":false,"dir":"test"},{"name":"errors on decryption but command succeeds","suites":["14. Decryption Events","Case 3: Decrypt Error"],"updatePoint":{"line":181,"column":49,"index":7200},"line":181,"code":"    it('errors on decryption but command succeeds', async function () {\n      // Use ``encryptedClient`` to insert the document ``{ \"encrypted\": <malformedCiphertext> }``\n      // into ``db.decryption_events``.\n      // Use ``encryptedClient`` to run an aggregate on ``db.decryption_events``.\n      // Expect an exception to be thrown from the decryption error.\n      // Expect a CommandSucceededEvent. Expect the CommandSucceededEvent.reply\n      // to contain BSON binary for the field\n      // ``cursor.firstBatch.encrypted``.\n      const collection = encryptedClient.db('db').collection('decryption_events');\n      await collection.insertOne({\n        encrypted: malformedCiphertext\n      }, {\n        writeConcern: {\n          w: 'majority'\n        }\n      });\n\n      /// Verify the malformedCiphertext was inserted with a plain client\n      const docs = await setupClient.db('db').collection('decryption_events').find({}).toArray();\n      expect(docs).to.have.lengthOf(1);\n      expect(docs).to.have.deep.nested.property('[0].encrypted', malformedCiphertext);\n      const error = await collection.aggregate([]).toArray().catch(error => error);\n      expect(error).to.have.property('message').to.include('HMAC validation failure');\n      expect(aggregateSucceeded).to.have.nested.property('reply.cursor.firstBatch[0].encrypted').to.be.instanceOf(Binary);\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.14.decryption_events.test.ts","skipped":false,"dir":"test"},{"name":"succeeds on decryption and command succeeds","suites":["14. Decryption Events","Case 4: Decrypt Success"],"updatePoint":{"line":208,"column":51,"index":8637},"line":208,"code":"    it('succeeds on decryption and command succeeds', async function () {\n      // Use ``encryptedClient`` to insert the document ``{ \"encrypted\": <ciphertext> }``\n      // into ``db.decryption_events``.\n      // Use ``encryptedClient`` to run an aggregate on ``db.decryption_events``.\n      // Expect no exception.\n      // Expect a CommandSucceededEvent. Expect the CommandSucceededEvent.reply\n      // to contain BSON binary for the field ``cursor.firstBatch.encrypted``.\n      const collection = encryptedClient.db('db').collection('decryption_events');\n      await collection.insertOne({\n        encrypted: cipherText\n      });\n      const result = await collection.aggregate([]).toArray();\n      expect(result).to.have.nested.property('[0].encrypted', 'hello');\n      expect(aggregateSucceeded).to.have.nested.property('reply.cursor.firstBatch[0].encrypted').to.be.instanceOf(Binary);\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.14.decryption_events.test.ts","skipped":false,"dir":"test"},{"name":"returns a properly formatted access token","suites":["Azure KMS Mock Server Tests","Case 1: Success"],"updatePoint":{"line":37,"column":49,"index":1384},"line":37,"code":"    it('returns a properly formatted access token', async () => {\n      const credentials = await fetchAzureKMSToken(new KMSRequestOptions());\n      expect(credentials).to.have.property('accessToken', 'magic-cookie');\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.18.azure_kms_mock_server.test.ts","skipped":false,"dir":"test"},{"name":"returns an error","suites":["Azure KMS Mock Server Tests","Case 2: Empty JSON"],"updatePoint":{"line":51,"column":24,"index":2077},"line":51,"code":"    it('returns an error', async () => {\n      const error = await fetchAzureKMSToken(new KMSRequestOptions('empty-json')).catch(e => e);\n      expect(error).to.be.instanceof(MongoCryptAzureKMSRequestError);\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.18.azure_kms_mock_server.test.ts","skipped":false,"dir":"test"},{"name":"returns an error","suites":["Azure KMS Mock Server Tests","Case 3: Bad JSON"],"updatePoint":{"line":64,"column":24,"index":2706},"line":64,"code":"    it('returns an error', async () => {\n      const error = await fetchAzureKMSToken(new KMSRequestOptions('bad-json')).catch(e => e);\n      expect(error).to.be.instanceof(MongoCryptAzureKMSRequestError);\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.18.azure_kms_mock_server.test.ts","skipped":false,"dir":"test"},{"name":"returns an error","suites":["Azure KMS Mock Server Tests","Case 4: HTTP 404"],"updatePoint":{"line":77,"column":24,"index":3394},"line":77,"code":"    it('returns an error', async () => {\n      const error = await fetchAzureKMSToken(new KMSRequestOptions('404')).catch(e => e);\n      expect(error).to.be.instanceof(MongoCryptAzureKMSRequestError);\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.18.azure_kms_mock_server.test.ts","skipped":false,"dir":"test"},{"name":"returns an error","suites":["Azure KMS Mock Server Tests","Case 5: HTTP 500"],"updatePoint":{"line":90,"column":24,"index":4073},"line":90,"code":"    it('returns an error', async () => {\n      const error = await fetchAzureKMSToken(new KMSRequestOptions('500')).catch(e => e);\n      expect(error).to.be.instanceof(MongoCryptAzureKMSRequestError);\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.18.azure_kms_mock_server.test.ts","skipped":false,"dir":"test"},{"name":"returns an error after the request times out","suites":["Azure KMS Mock Server Tests","Case 6: Slow Response"],"updatePoint":{"line":101,"column":52,"index":4729},"line":101,"code":"    it('returns an error after the request times out', async () => {\n      const error = await fetchAzureKMSToken(new KMSRequestOptions('slow')).catch(e => e);\n      expect(error).to.be.instanceof(MongoCryptAzureKMSRequestError);\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.18.azure_kms_mock_server.test.ts","skipped":false,"dir":"test"},{"name":"should work for local KMS provider","suites":["Client Side Encryption Prose Tests","Data key and double encryption"],"updatePoint":{"line":168,"column":42,"index":5884},"line":168,"code":"    it('should work for local KMS provider', metadata, function () {\n      let localDatakeyId;\n      let localEncrypted;\n      return Promise.resolve().then(() => {\n        // #. Call ``client_encryption.createDataKey()`` with the ``local`` KMS provider and keyAltNames set to ``[\"local_altname\"]``.\n        // - Expect a BSON binary with subtype 4 to be returned, referred to as ``local_datakey_id``.\n        // - Use ``client`` to run a ``find`` on ``keyvault.datakeys`` by querying with the ``_id`` set to the ``local_datakey_id``.\n        // - Expect that exactly one document is returned with the \"masterKey.provider\" equal to \"local\".\n        // - Check that ``client`` captured a command_started event for the ``insert`` command containing a majority writeConcern.\n        this.commandStartedEvents.clear();\n        return this.clientEncryption.createDataKey('local', {\n          keyAltNames: ['local_altname']\n        }).then(result => {\n          localDatakeyId = result;\n          expect(localDatakeyId).to.have.property('sub_type', 4);\n        }).then(() => {\n          return this.client.db(keyVaultDbName).collection(keyVaultCollName).find({\n            _id: localDatakeyId\n          }).toArray();\n        }).then(results => {\n          expect(results).to.have.a.lengthOf(1).and.to.have.nested.property('0.masterKey.provider', 'local');\n          expect(this.commandStartedEvents.events).to.containSubset([{\n            commandName: 'insert',\n            command: {\n              writeConcern: {\n                w: 'majority'\n              }\n            }\n          }]);\n        });\n      }).then(() => {\n        // #. Call ``client_encryption.encrypt()`` with the value \"hello local\", the algorithm ``AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic``, and the ``key_id`` of ``local_datakey_id``.\n        // - Expect the return value to be a BSON binary subtype 6, referred to as ``local_encrypted``.\n        // - Use ``client_encrypted`` to insert ``{ _id: \"local\", \"value\": <local_encrypted> }`` into ``db.coll``.\n        // - Use ``client_encrypted`` to run a find querying with ``_id`` of \"local\" and expect ``value`` to be \"hello local\".\n        const coll = this.clientEncrypted.db(dataDbName).collection(dataCollName);\n        return this.clientEncryption.encrypt('hello local', {\n          algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic',\n          keyId: localDatakeyId\n        }).then(value => {\n          localEncrypted = value;\n          expect(localEncrypted).to.have.property('sub_type', 6);\n        }).then(() => coll.insertOne({\n          _id: 'local',\n          value: localEncrypted\n        })).then(() => coll.findOne({\n          _id: 'local'\n        })).then(result => {\n          expect(result).to.have.property('value', 'hello local');\n        });\n      }).then(() => {\n        // #. Call ``client_encryption.encrypt()`` with the value \"hello local\", the algorithm ``AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic``, and the ``key_alt_name`` of ``local_altname``.\n        // - Expect the return value to be a BSON binary subtype 6. Expect the value to exactly match the value of ``local_encrypted``.\n        return this.clientEncryption.encrypt('hello local', {\n          algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic',\n          keyId: localDatakeyId\n        }).then(encrypted => {\n          expect(encrypted).to.deep.equal(localEncrypted);\n        });\n      });\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should work for aws KMS provider","suites":["Client Side Encryption Prose Tests","Data key and double encryption"],"updatePoint":{"line":229,"column":40,"index":9301},"line":229,"code":"    it('should work for aws KMS provider', metadata, function () {\n      // Then, repeat the above tests with the ``aws`` KMS provider:\n      let awsDatakeyId;\n      let awsEncrypted;\n      return Promise.resolve().then(() => {\n        // #. Call ``client_encryption.createDataKey()`` with the ``aws`` KMS provider, keyAltNames set to ``[\"aws_altname\"]``, and ``masterKey`` as follows:\n        //    .. code:: javascript\n        //       {\n        //         region: \"us-east-1\",\n        //         key: \"arn:aws:kms:us-east-1:579766882180:key/89fcc2c4-08b0-4bd9-9f25-e30687b580d0\"\n        //       }\n        //    - Expect a BSON binary with subtype 4 to be returned, referred to as ``aws_datakey_id``.\n        //    - Use ``client`` to run a ``find`` on ``keyvault.datakeys`` by querying with the ``_id`` set to the ``aws_datakey_id``.\n        //    - Expect that exactly one document is returned with the \"masterKey.provider\" equal to \"aws\".\n        //    - Check that ``client`` captured a command_started event for the ``insert`` command containing a majority writeConcern.\n        this.commandStartedEvents.clear();\n        const masterKey = {\n          region: 'us-east-1',\n          key: 'arn:aws:kms:us-east-1:579766882180:key/89fcc2c4-08b0-4bd9-9f25-e30687b580d0'\n        };\n        return this.clientEncryption.createDataKey('aws', {\n          masterKey,\n          keyAltNames: ['aws_altname']\n        }).then(result => {\n          awsDatakeyId = result;\n          expect(awsDatakeyId).to.have.property('sub_type', 4);\n        }).then(() => {\n          return this.client.db(keyVaultDbName).collection(keyVaultCollName).find({\n            _id: awsDatakeyId\n          }).toArray();\n        }).then(results => {\n          expect(results).to.have.a.lengthOf(1).and.to.have.nested.property('0.masterKey.provider', 'aws');\n          expect(this.commandStartedEvents.events).to.containSubset([{\n            commandName: 'insert',\n            command: {\n              writeConcern: {\n                w: 'majority'\n              }\n            }\n          }]);\n        });\n      }).then(() => {\n        // #. Call ``client_encryption.encrypt()`` with the value \"hello aws\", the algorithm ``AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic``, and the ``key_id`` of ``aws_datakey_id``.\n        //    - Expect the return value to be a BSON binary subtype 6, referred to as ``aws_encrypted``.\n        //    - Use ``client_encrypted`` to insert ``{ _id: \"aws\", \"value\": <aws_encrypted> }`` into ``db.coll``.\n        //    - Use ``client_encrypted`` to run a find querying with ``_id`` of \"aws\" and expect ``value`` to be \"hello aws\".\n        const coll = this.clientEncrypted.db(dataDbName).collection(dataCollName);\n        return this.clientEncryption.encrypt('hello aws', {\n          algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic',\n          keyId: awsDatakeyId\n        }).then(value => {\n          awsEncrypted = value;\n          expect(awsEncrypted).to.have.property('sub_type', 6);\n        }).then(() => coll.insertOne({\n          _id: 'aws',\n          value: awsEncrypted\n        })).then(() => coll.findOne({\n          _id: 'aws'\n        })).then(result => {\n          expect(result).to.have.property('value', 'hello aws');\n        });\n      }).then(() => {\n        // #. Call ``client_encryption.encrypt()`` with the value \"hello aws\", the algorithm ``AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic``, and the ``key_alt_name`` of ``aws_altname``.\n        //    - Expect the return value to be a BSON binary subtype 6. Expect the value to exactly match the value of ``aws_encrypted``.\n        return this.clientEncryption.encrypt('hello aws', {\n          algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic',\n          keyId: awsDatakeyId\n        }).then(encrypted => {\n          expect(encrypted).to.deep.equal(awsEncrypted);\n        });\n      });\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should error on an attempt to double-encrypt a value","suites":["Client Side Encryption Prose Tests","Data key and double encryption"],"updatePoint":{"line":301,"column":60,"index":13189},"line":301,"code":"    it('should error on an attempt to double-encrypt a value', metadata, function () {\n      // Then, run the following final tests:\n      // #. Test explicit encrypting an auto encrypted field.\n      //    - Use ``client_encrypted`` to attempt to insert ``{ \"encrypted_placeholder\": (local_encrypted) }``\n      //    - Expect an exception to be thrown, since this is an attempt to auto encrypt an already encrypted value.\n      return Promise.resolve().then(() => this.clientEncryption.createDataKey('local')).then(keyId => this.clientEncryption.encrypt('hello double', {\n        keyId,\n        algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic'\n      })).then(encrypted => this.clientEncrypted.db(dataDbName).collection(dataCollName).insertOne({\n        encrypted_placeholder: encrypted\n      }).then(() => {\n        throw new Error('Expected double-encryption to fail, but it has succeeded');\n      }, err => {\n        expect(err).to.be.an.instanceOf(Error);\n      }));\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should work  external key vault","suites":["Client Side Encryption Prose Tests","External Key Vault Test"],"updatePoint":{"line":352,"column":85,"index":16034},"line":352,"code":"      it(`should work ${withExternalKeyVault ? 'with' : 'without'} external key vault`, metadata, function () {\n        const ClientEncryption = this.configuration.mongodbClientEncryption.ClientEncryption;\n        return Promise.resolve().then(() => {\n          //    If ``withExternalKeyVault == true``, configure both objects with an external key vault client. The external client MUST connect to the same\n          //    MongoDB cluster that is being tested against, except it MUST use the username ``fake-user`` and password ``fake-pwd``.\n          this.externalClient = this.configuration.newClient(\n          // this.configuration.url('fake-user', 'fake-pwd'),\n          // TODO: Do this properly\n          {}, {\n            monitorCommands: true\n          });\n          this.commandStartedEvents = new APMEventCollector(this.externalClient, 'commandStarted', {\n            include: ['find']\n          });\n          return this.externalClient.connect();\n        })\n        // 3. Create the following:\n        //    - A MongoClient configured with auto encryption (referred to as ``client_encrypted``)\n        //    - A ``ClientEncryption`` object (referred to as ``client_encryption``)\n        //    Configure both objects with the ``local`` KMS providers as follows:\n        //    .. code:: javascript\n        //       { \"local\": { \"key\": <base64 decoding of LOCAL_MASTERKEY> } }\n        //    Configure both objects with ``keyVaultNamespace`` set to ``keyvault.datakeys``.\n        //    Configure ``client_encrypted`` to use the schema `external/external-schema.json <../external/external-schema.json>`_  for ``db.coll`` by setting a schema map like: ``{ \"db.coll\": <contents of external-schema.json>}``\n        .then(() => {\n          const options = {\n            bson: BSON,\n            keyVaultNamespace,\n            kmsProviders: getKmsProviders(LOCAL_KEY),\n            extraOptions: getEncryptExtraOptions()\n          };\n          if (withExternalKeyVault) {\n            options.keyVaultClient = this.externalClient;\n          }\n          this.clientEncryption = new ClientEncryption(this.client, Object.assign({}, options));\n          this.clientEncrypted = this.configuration.newClient({}, {\n            autoEncryption: Object.assign({}, options, {\n              schemaMap: {\n                'db.coll': externalSchema\n              }\n            })\n          });\n          return this.clientEncrypted.connect();\n        }).then(() => {\n          // 4. Use ``client_encrypted`` to insert the document ``{\"encrypted\": \"test\"}`` into ``db.coll``.\n          //    If ``withExternalKeyVault == true``, expect an authentication exception to be thrown. Otherwise, expect the insert to succeed.\n          this.commandStartedEvents.clear();\n          return this.clientEncrypted.db(dataDbName).collection(dataCollName).insertOne({\n            encrypted: 'test'\n          }).then(() => {\n            if (withExternalKeyVault) {\n              expect(this.commandStartedEvents.events).to.containSubset([{\n                commandName: 'find',\n                databaseName: keyVaultDbName,\n                command: {\n                  find: keyVaultCollName\n                }\n              }]);\n            } else {\n              expect(this.commandStartedEvents.events).to.not.containSubset([{\n                commandName: 'find',\n                databaseName: keyVaultDbName,\n                command: {\n                  find: keyVaultCollName\n                }\n              }]);\n            }\n          });\n          // TODO: Do this in the spec-compliant way using bad auth credentials\n          // .then(\n          //   () => {\n          //     if (withExternalKeyVault) {\n          //       throw new Error(\n          //         'expected insert to fail with authentication error, but it passed'\n          //       );\n          //     }\n          //   },\n          //   err => {\n          //     if (!withExternalKeyVault) {\n          //       throw err;\n          //     }\n          //     expect(err).to.be.an.instanceOf(Error);\n          //   }\n          // );\n        }).then(() => {\n          // 5. Use ``client_encryption`` to explicitly encrypt the string ``\"test\"`` with key ID ``LOCALAAAAAAAAAAAAAAAAA==`` and deterministic algorithm.\n          //    If ``withExternalKeyVault == true``, expect an authentication exception to be thrown. Otherwise, expect the insert to succeed.\n          this.commandStartedEvents.clear();\n          return this.clientEncryption.encrypt('test', {\n            keyId: externalKey._id,\n            algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic'\n          }).then(() => {\n            if (withExternalKeyVault) {\n              expect(this.commandStartedEvents.events).to.containSubset([{\n                commandName: 'find',\n                databaseName: keyVaultDbName,\n                command: {\n                  find: keyVaultCollName\n                }\n              }]);\n            } else {\n              expect(this.commandStartedEvents.events).to.not.containSubset([{\n                commandName: 'find',\n                databaseName: keyVaultDbName,\n                command: {\n                  find: keyVaultCollName\n                }\n              }]);\n            }\n          });\n          // TODO: Do this in the spec-compliant way using bad auth credentials\n          // .then(\n          //   () => {\n          //     if (withExternalKeyVault) {\n          //       throw new Error(\n          //         'expected insert to fail with authentication error, but it passed'\n          //       );\n          //     }\n          //   },\n          //   err => {\n          //     if (!withExternalKeyVault) {\n          //       throw err;\n          //     }\n          //     expect(err).to.be.an.instanceOf(Error);\n          //   }\n          // );\n        });\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should error when inserting into a view with autoEncryption","suites":["Client Side Encryption Prose Tests","Views are prohibited"],"updatePoint":{"line":723,"column":67,"index":32625},"line":723,"code":"    it('should error when inserting into a view with autoEncryption', metadata, function () {\n      return this.clientEncrypted.db(dataDbName).collection('view').insertOne({\n        a: 1\n      }).then(() => {\n        throw new Error('Expected insert to fail, but it succeeded');\n      }, err => {\n        expect(err).to.have.property('message').that.matches(/cannot auto encrypt a view/);\n      });\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"runs in a separate suite","suites":["Client Side Encryption Prose Tests","Corpus Test"],"updatePoint":{"line":734,"column":32,"index":33043},"line":734,"code":"    it('runs in a separate suite', () => {\n      expect(() => fs.statSync(path.resolve(__dirname, './client_side_encryption.prose.06.corpus.test.js'))).not.to.throw();\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"Via mongocryptdBypassSpawn","suites":["Client Side Encryption Prose Tests","Bypass spawning mongocryptd"],"line":960,"code":"    it.skip('Via mongocryptdBypassSpawn', () => {}).skipReason = 'TODO(NODE-2422): Implement \"Bypass spawning mongocryptd\" tests';","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":true,"dir":"test"},{"name":"Via bypassAutoEncryption","suites":["Client Side Encryption Prose Tests","Bypass spawning mongocryptd"],"line":961,"code":"    it.skip('Via bypassAutoEncryption', () => {}).skipReason = 'TODO(NODE-2422): Implement \"Bypass spawning mongocryptd\" tests';","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":true,"dir":"test"},{"name":"TBD","suites":["Client Side Encryption Prose Tests","KMS TLS Tests"],"line":969,"code":"    it.skip('TBD', () => {}).skipReason = 'TODO(NODE-3151): Implement \"KMS TLS Tests\"';","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":true,"dir":"test"},{"name":"should fail with no TLS","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 1: AWS"],"updatePoint":{"line":1113,"column":33,"index":47116},"line":1113,"code":"      it('should fail with no TLS', metadata, async function () {\n        try {\n          await clientEncryptionNoTls.createDataKey('aws', {\n            masterKey\n          });\n          expect.fail('it must fail with no tls');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed.\n          expect(e.originalError.message).to.include('certificate required');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should succeed with valid TLS options","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 1: AWS"],"updatePoint":{"line":1124,"column":47,"index":47540},"line":1124,"code":"      it('should succeed with valid TLS options', metadata, async function () {\n        try {\n          await clientEncryptionWithTls.createDataKey('aws', {\n            masterKey\n          });\n          expect.fail('it must fail to parse response');\n        } catch (e) {\n          // Expect an error from libmongocrypt with a message containing the string: \"parse error\".\n          // This implies TLS handshake succeeded.\n          expect(e.message).to.include('parse error');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an expired certificate","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 1: AWS"],"updatePoint":{"line":1136,"column":49,"index":48041},"line":1136,"code":"      it('should fail with an expired certificate', async function () {\n        try {\n          await clientEncryptionWithTlsExpired.createDataKey('aws', {\n            masterKey: masterKeyExpired\n          });\n          expect.fail('it must fail with invalid certificate');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an expired certificate.\n          expect(e.originalError.message).to.include('certificate has expired');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an invalid hostname","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 1: AWS"],"updatePoint":{"line":1147,"column":46,"index":48527},"line":1147,"code":"      it('should fail with an invalid hostname', metadata, async function () {\n        try {\n          await clientEncryptionWithInvalidHostname.createDataKey('aws', {\n            masterKey: masterKeyInvalidHostname\n          });\n          expect.fail('it must fail with invalid hostnames');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an invalid hostname.\n          expect(e.originalError.message).to.include('does not match certificate');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with no TLS","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 2: Azure"],"updatePoint":{"line":1166,"column":33,"index":49204},"line":1166,"code":"      it('should fail with no TLS', metadata, async function () {\n        try {\n          await clientEncryptionNoTls.createDataKey('azure', {\n            masterKey\n          });\n          expect.fail('it must fail with no tls');\n        } catch (e) {\n          //Expect an error indicating TLS handshake failed.\n          expect(e.originalError.message).to.include('certificate required');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should succeed with valid TLS options","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 2: Azure"],"updatePoint":{"line":1177,"column":47,"index":49629},"line":1177,"code":"      it('should succeed with valid TLS options', metadata, async function () {\n        try {\n          await clientEncryptionWithTls.createDataKey('azure', {\n            masterKey\n          });\n          expect.fail('it must fail with HTTP 404');\n        } catch (e) {\n          // Expect an error from libmongocrypt with a message containing the string: \"HTTP status=404\".\n          // This implies TLS handshake succeeded.\n          expect(e.message).to.include('HTTP status=404');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an expired certificate","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 2: Azure"],"updatePoint":{"line":1189,"column":49,"index":50136},"line":1189,"code":"      it('should fail with an expired certificate', async function () {\n        try {\n          await clientEncryptionWithTlsExpired.createDataKey('azure', {\n            masterKey\n          });\n          expect.fail('it must fail with expired certificates');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an expired certificate.\n          expect(e.originalError.message).to.include('certificate has expired');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an invalid hostname","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 2: Azure"],"updatePoint":{"line":1200,"column":46,"index":50607},"line":1200,"code":"      it('should fail with an invalid hostname', metadata, async function () {\n        try {\n          await clientEncryptionWithInvalidHostname.createDataKey('azure', {\n            masterKey\n          });\n          expect.fail('it must fail with invalid hostnames');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an invalid hostname.\n          expect(e.originalError.message).to.include('does not match certificate');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with no TLS","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 3: GCP"],"updatePoint":{"line":1221,"column":33,"index":51285},"line":1221,"code":"      it('should fail with no TLS', metadata, async function () {\n        try {\n          await clientEncryptionNoTls.createDataKey('gcp', {\n            masterKey\n          });\n          expect.fail('it must fail with no tls');\n        } catch (e) {\n          //Expect an error indicating TLS handshake failed.\n          expect(e.originalError.message).to.include('certificate required');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should succeed with valid TLS options","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 3: GCP"],"updatePoint":{"line":1232,"column":47,"index":51708},"line":1232,"code":"      it('should succeed with valid TLS options', metadata, async function () {\n        try {\n          await clientEncryptionWithTls.createDataKey('gcp', {\n            masterKey\n          });\n          expect.fail('it must fail with HTTP 404');\n        } catch (e) {\n          // Expect an error from libmongocrypt with a message containing the string: \"HTTP status=404\".\n          // This implies TLS handshake succeeded.\n          expect(e.message).to.include('HTTP status=404');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an expired certificate","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 3: GCP"],"updatePoint":{"line":1244,"column":49,"index":52213},"line":1244,"code":"      it('should fail with an expired certificate', async function () {\n        try {\n          await clientEncryptionWithTlsExpired.createDataKey('gcp', {\n            masterKey\n          });\n          expect.fail('it must fail with expired certificates');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an expired certificate.\n          expect(e.originalError.message).to.include('certificate has expired');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an invalid hostname","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 3: GCP"],"updatePoint":{"line":1255,"column":46,"index":52682},"line":1255,"code":"      it('should fail with an invalid hostname', metadata, async function () {\n        try {\n          await clientEncryptionWithInvalidHostname.createDataKey('gcp', {\n            masterKey\n          });\n          expect.fail('it must fail with invalid hostnames');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an invalid hostname.\n          expect(e.originalError.message).to.include('does not match certificate');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with no TLS","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 4: KMIP"],"updatePoint":{"line":1271,"column":33,"index":53254},"line":1271,"code":"      it('should fail with no TLS', metadata, async function () {\n        if (gte(coerce(process.version), coerce('19'))) {\n          this.skip('TODO(NODE-4942): fix failing csfle kmip test on Node19+');\n          return;\n        }\n        try {\n          await clientEncryptionNoTls.createDataKey('kmip', {\n            masterKey\n          });\n          expect.fail('it must fail with no tls');\n        } catch (e) {\n          //Expect an error indicating TLS handshake failed.\n          expect(e.originalError.message).to.match(/before secure TLS connection|handshake/);\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should succeed with valid TLS options","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 4: KMIP"],"updatePoint":{"line":1286,"column":47,"index":53860},"line":1286,"code":"      it('should succeed with valid TLS options', metadata, async function () {\n        const keyId = await clientEncryptionWithTls.createDataKey('kmip', {\n          masterKey\n        });\n        // expect success\n        expect(keyId).to.be.an('object');\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an expired certificate","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 4: KMIP"],"updatePoint":{"line":1293,"column":49,"index":54128},"line":1293,"code":"      it('should fail with an expired certificate', async function () {\n        try {\n          await clientEncryptionWithTlsExpired.createDataKey('kmip', {\n            masterKey\n          });\n          expect.fail('it must fail with expired certificates');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an expired certificate.\n          expect(e.originalError.message).to.include('certificate has expired');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an invalid hostname","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 4: KMIP"],"updatePoint":{"line":1304,"column":46,"index":54598},"line":1304,"code":"      it('should fail with an invalid hostname', metadata, async function () {\n        try {\n          await clientEncryptionWithInvalidHostname.createDataKey('kmip', {\n            masterKey\n          });\n          expect.fail('it must fail with invalid hostnames');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an invalid hostname.\n          expect(e.originalError.message).to.include('does not match certificate');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"returns the decrypted value","suites":["Client Side Encryption Prose Tests","12. Explicit Encryption","Case 1: can insert encrypted indexed and find"],"updatePoint":{"line":1425,"column":37,"index":59660},"line":1425,"code":"      it('returns the decrypted value', async function () {\n        // Use encryptedClient to run a \"find\" operation on the db.explicit_encryption\n        // collection with the filter { \"encryptedIndexed\": <findPayload> }.\n        // Assert one document is returned containing the field\n        // { \"encryptedIndexed\": \"encrypted indexed value\" }.\n        const collection = encryptedClient.db('db').collection('explicit_encryption');\n        const result = await collection.findOne({\n          encryptedIndexed: findPayload\n        });\n        expect(result).to.have.property('encryptedIndexed', 'encrypted indexed value');\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"returns less than the total documents with no contention","suites":["Client Side Encryption Prose Tests","12. Explicit Encryption","Case 2: can insert encrypted indexed and find with non-zero contention"],"updatePoint":{"line":1490,"column":66,"index":62574},"line":1490,"code":"      it('returns less than the total documents with no contention', async function () {\n        // Use encryptedClient to run a \"find\" operation on the db.explicit_encryption\n        // collection with the filter { \"encryptedIndexed\": <findPayload> }.\n        // Assert less than 10 documents are returned. 0 documents may be returned.\n        // Assert each returned document contains the field\n        // { \"encryptedIndexed\": \"encrypted indexed value\" }.\n        const collection = encryptedClient.db('db').collection('explicit_encryption');\n        const result = await collection.find({\n          encryptedIndexed: findPayload\n        }).toArray();\n        expect(result.length).to.be.below(10);\n        for (const doc of result) {\n          expect(doc).to.have.property('encryptedIndexed', 'encrypted indexed value');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"returns all documents with contention","suites":["Client Side Encryption Prose Tests","12. Explicit Encryption","Case 2: can insert encrypted indexed and find with non-zero contention"],"updatePoint":{"line":1505,"column":47,"index":63400},"line":1505,"code":"      it('returns all documents with contention', async function () {\n        // Use encryptedClient to run a \"find\" operation on the db.explicit_encryption\n        // collection with the filter { \"encryptedIndexed\": <findPayload2> }.\n        // Assert 10 documents are returned. Assert each returned document contains the\n        // field { \"encryptedIndexed\": \"encrypted indexed value\" }.\n        const collection = encryptedClient.db('db').collection('explicit_encryption');\n        const result = await collection.find({\n          encryptedIndexed: findPayload2\n        }).toArray();\n        expect(result.length).to.equal(10);\n        for (const doc of result) {\n          expect(doc).to.have.property('encryptedIndexed', 'encrypted indexed value');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"returns unindexed documents","suites":["Client Side Encryption Prose Tests","12. Explicit Encryption","Case 3: can insert encrypted unindexed"],"updatePoint":{"line":1540,"column":37,"index":65049},"line":1540,"code":"      it('returns unindexed documents', async function () {\n        // Use encryptedClient to run a \"find\" operation on the db.explicit_encryption\n        // collection with the filter { \"_id\": 1 }.\n        // Assert one document is returned containing the field\n        // { \"encryptedUnindexed\": \"encrypted unindexed value\" }.\n        const collection = encryptedClient.db('db').collection('explicit_encryption');\n        const result = await collection.findOne({\n          _id: 1\n        });\n        expect(result).to.have.property('encryptedUnindexed', 'encrypted unindexed value');\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"decrypts the value","suites":["Client Side Encryption Prose Tests","12. Explicit Encryption","Case 4: can roundtrip encrypted indexed"],"updatePoint":{"line":1567,"column":28,"index":66223},"line":1567,"code":"      it('decrypts the value', async function () {\n        // Use clientEncryption to decrypt payload. Assert the returned value\n        // equals \"encrypted indexed value\".\n        const result = await clientEncryption.decrypt(payload);\n        expect(result).equals('encrypted indexed value');\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"decrypts the value","suites":["Client Side Encryption Prose Tests","12. Explicit Encryption","Case 5: can roundtrip encrypted unindexed"],"updatePoint":{"line":1588,"column":28,"index":67094},"line":1588,"code":"      it('decrypts the value', async function () {\n        // Use clientEncryption to decrypt payload. Assert the returned value\n        // equals \"encrypted unindexed value\".\n        const result = await clientEncryption.decrypt(payload);\n        expect(result).equals('encrypted unindexed value');\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"createDataKey() handles duplicate key errors on the keyvault collection","suites":["Client Side Encryption Prose Tests","13. Unique Index on keyAltNames","Case 1"],"updatePoint":{"line":1637,"column":81,"index":68944},"line":1637,"code":"      it('createDataKey() handles duplicate key errors on the keyvault collection', async function () {\n        // 1. Use client_encryption to create a new local data key with a keyAltName \"abc\" and assert the operation does not fail.\n        await clientEncryption.createDataKey('local', {\n          keyAltNames: ['abc']\n        });\n\n        // 2. Repeat Step 1 and assert the operation fails due to a duplicate key server error (error code 11000).\n        const resultStep2 = await clientEncryption.createDataKey('local', {\n          keyAltNames: ['abc']\n        }).catch(e => e);\n        expect(resultStep2, 'Error in step 2) expected clientEncryption.createDataKey to throw duplicate key error but it did not').to.be.instanceof(MongoServerError);\n        expect(resultStep2).have.property('code', 11000);\n\n        // 3. Use client_encryption to create a new local data key with a keyAltName \"def\" and assert the operation fails due to a duplicate key server error (error code 11000).\n        const resultStep3 = await clientEncryption.createDataKey('local', {\n          keyAltNames: ['def']\n        }).catch(e => e);\n        expect(resultStep3, 'Error in step 3) expected clientEncryption.createDataKey to throw duplicate key error but it did not').to.be.instanceof(MongoServerError);\n        expect(resultStep3).have.property('code', 11000);\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"addKeyAltName() handles duplicate key errors on the keyvault collection","suites":["Client Side Encryption Prose Tests","13. Unique Index on keyAltNames","Case 2"],"updatePoint":{"line":1659,"column":81,"index":70355},"line":1659,"code":"      it('addKeyAltName() handles duplicate key errors on the keyvault collection', async function () {\n        // 1. Use client_encryption to create a new local data key and assert the operation does not fail.\n        const _id = await clientEncryption.createDataKey('local');\n\n        // 2. Use client_encryption to add a keyAltName \"abc\" to the key created in Step 1 and assert the operation does not fail.\n        await clientEncryption.addKeyAltName(_id, 'abc');\n\n        // 3. Repeat Step 2, assert the operation does not fail, and assert the returned key document contains the keyAltName \"abc\" added in Step 2.\n        const resultStep3 = await clientEncryption.addKeyAltName(_id, 'abc');\n        expect(resultStep3).to.have.property('keyAltNames').to.include('abc');\n\n        // 4. Use client_encryption to add a keyAltName \"def\" to the key created in Step 1 and assert the operation fails due to a duplicate key server error (error code 11000).\n        const resultStep4 = await clientEncryption.addKeyAltName(_id, 'def').catch(e => e);\n        expect(resultStep4, 'Error in step 4) expected clientEncryption.addKeyAltName to throw duplicate key error but it did not').to.be.instanceof(MongoServerError);\n        expect(resultStep4).to.have.property('code', 11000);\n\n        // 5. Use client_encryption to add a keyAltName \"def\" to the existing key, assert the operation does not fail, and assert the returned key document contains the keyAltName \"def\" added during Setup.\n        const resultStep5 = await clientEncryption.addKeyAltName(setupKeyId, 'def');\n        expect(resultStep5).to.have.property('keyAltNames').to.include('def');\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should rewrap data key from  to ","suites":["Client Side Encryption Prose Tests","16. Rewrap"],"updatePoint":{"line":1729,"column":70,"index":73385},"line":1729,"code":"      it(`should rewrap data key from ${srcProvider} to ${dstProvider}`, metadata, async function () {\n        // Step 1. Drop the collection ``keyvault.datakeys``\n        await client1.db('keyvault').dropCollection('datakeys').catch(() => null);\n\n        // Step 2. Create a ``ClientEncryption`` object named ``clientEncryption1``\n        const clientEncryption1 = new this.configuration.mongodbClientEncryption.ClientEncryption(client1, {\n          keyVaultNamespace: 'keyvault.datakeys',\n          kmsProviders: getKmsProviders(),\n          tlsOptions: {\n            kmip: {\n              tlsCAFile: process.env.KMIP_TLS_CA_FILE,\n              tlsCertificateKeyFile: process.env.KMIP_TLS_CERT_FILE\n            }\n          },\n          extraOptions: getEncryptExtraOptions(),\n          bson: BSON\n        });\n\n        // Step 3. Call ``clientEncryption1.createDataKey`` with ``srcProvider``\n        const keyId = await clientEncryption1.createDataKey(srcProvider, {\n          masterKey: masterKeys[srcProvider]\n        });\n\n        // Step 4. Call ``clientEncryption1.encrypt`` with the value \"test\"\n        const cipherText = await clientEncryption1.encrypt('test', {\n          keyId,\n          algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic'\n        });\n\n        // Step 5. Create a ``ClientEncryption`` object named ``clientEncryption2``\n        const clientEncryption2 = new this.configuration.mongodbClientEncryption.ClientEncryption(client2, {\n          keyVaultNamespace: 'keyvault.datakeys',\n          kmsProviders: getKmsProviders(),\n          tlsOptions: {\n            kmip: {\n              tlsCAFile: process.env.KMIP_TLS_CA_FILE,\n              tlsCertificateKeyFile: process.env.KMIP_TLS_CERT_FILE\n            }\n          },\n          extraOptions: getEncryptExtraOptions(),\n          bson: BSON\n        });\n\n        // Step 6. Call ``clientEncryption2.rewrapManyDataKey`` with an empty ``filter``\n        const rewrapManyDataKeyResult = await clientEncryption2.rewrapManyDataKey({}, {\n          provider: dstProvider,\n          masterKey: masterKeys[dstProvider]\n        });\n        expect(rewrapManyDataKeyResult).to.have.property('bulkWriteResult');\n        expect(rewrapManyDataKeyResult.bulkWriteResult).to.have.property('modifiedCount', 1);\n\n        // 7. Call ``clientEncryption1.decrypt`` with the ``ciphertext``. Assert the return value is \"test\".\n        const decryptResult1 = await clientEncryption1.decrypt(cipherText);\n        expect(decryptResult1).to.equal('test');\n\n        // 8. Call ``clientEncryption2.decrypt`` with the ``ciphertext``. Assert the return value is \"test\".\n        const decryptResult2 = await clientEncryption2.decrypt(cipherText);\n        expect(decryptResult2).to.equal('test');\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"cursor count method should return the correct number when used with collation set","suites":["Collation"],"updatePoint":{"line":13,"column":87,"index":302},"line":13,"code":"  it('cursor count method should return the correct number when used with collation set', async function () {\n    const configuration = this.configuration;\n    const client = configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    const db = client.db(configuration.db);\n    const docs = [{\n      _id: 0,\n      name: 'foo'\n    }, {\n      _id: 1,\n      name: 'Foo'\n    }];\n    const collation = {\n      locale: 'en_US',\n      strength: 2\n    };\n    await Promise.resolve();\n    await db.createCollection('cursor_collation_count');\n    const collection = db.collection('cursor_collation_count');\n    await collection.insertMany(docs);\n    const cursor = collection.find({\n      name: 'foo'\n    }).collation(collation);\n    const val = await cursor.count();\n    expect(val).to.equal(2);\n    await client.close();\n  });","file":"integration/collation/collations.test.js","skipped":false,"dir":"test"},{"name":"should correctly create index with collation","suites":["Collation"],"updatePoint":{"line":43,"column":50,"index":1104},"line":43,"code":"  it('should correctly create index with collation', async function () {\n    const configuration = this.configuration;\n    const client = configuration.newClient();\n    const db = client.db(configuration.db);\n    const col = db.collection('collation_test');\n    await col.createIndexes([{\n      key: {\n        a: 1\n      },\n      collation: {\n        locale: 'nn'\n      },\n      name: 'collation_test'\n    }]);\n    const r = await col.listIndexes().toArray();\n    const indexes = r.filter(i => i.name === 'collation_test');\n    expect(indexes).to.have.length(1);\n    expect(indexes[0]).to.have.property('collation');\n    expect(indexes[0].collation).to.exist;\n    await client.close();\n  });","file":"integration/collation/collations.test.js","skipped":false,"dir":"test"},{"name":"Should correctly create collection with collation","suites":["Collation"],"updatePoint":{"line":64,"column":55,"index":1801},"line":64,"code":"  it('Should correctly create collection with collation', async function () {\n    const configuration = this.configuration;\n    const client = configuration.newClient();\n    const db = client.db(configuration.db);\n    await db.createCollection('collation_test2', {\n      collation: {\n        locale: 'nn'\n      }\n    });\n    const collections = await db.listCollections({\n      name: 'collation_test2'\n    }).toArray();\n    expect(collections).to.have.length(1);\n    expect(collections[0].name).to.equal('collation_test2');\n    expect(collections[0].options.collation).to.exist;\n    await client.close();\n  });","file":"integration/collation/collations.test.js","skipped":false,"dir":"test"},{"name":"Should correctly createCollection using Promise","suites":["Collection Management and Db Management"],"updatePoint":{"line":6,"column":53,"index":254},"line":6,"code":"  it('Should correctly createCollection using Promise', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({}, {\n      maxPoolSize: 5\n    });\n    client.db(configuration.db).createCollection('promiseCollection').then(function (col) {\n      test.ok(col != null);\n      client.close(done);\n    }).catch(function (err) {\n      test.ok(err != null);\n    });\n  });","file":"integration/collection-management/collection_db_management.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly rename and drop collection using Promise","suites":["Collection Management and Db Management"],"updatePoint":{"line":18,"column":63,"index":680},"line":18,"code":"  it('Should correctly rename and drop collection using Promise', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({}, {\n      maxPoolSize: 5\n    });\n    const db = client.db(configuration.db);\n    db.createCollection('promiseCollection1').then(function (col) {\n      test.ok(col != null);\n      const db = client.db(configuration.db);\n      db.renameCollection('promiseCollection1', 'promiseCollection2').then(function (col) {\n        test.ok(col != null);\n        db.dropCollection('promiseCollection2').then(function (r) {\n          test.ok(r);\n          client.close(done);\n        });\n      });\n    });\n  });","file":"integration/collection-management/collection_db_management.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly drop database using Promise","suites":["Collection Management and Db Management"],"updatePoint":{"line":36,"column":50,"index":1339},"line":36,"code":"  it('Should correctly drop database using Promise', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({}, {\n      maxPoolSize: 5\n    });\n    client.db(configuration.db).dropDatabase().then(function (r) {\n      test.ok(r);\n      client.close(done);\n    }).catch(function (e) {\n      test.ok(e != null);\n    });\n  });","file":"integration/collection-management/collection_db_management.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly createCollections and call collections with Promise","suites":["Collection Management and Db Management"],"updatePoint":{"line":48,"column":74,"index":1737},"line":48,"code":"  it('Should correctly createCollections and call collections with Promise', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({}, {\n      maxPoolSize: 5\n    });\n    const db = client.db(configuration.db);\n    db.createCollection('promiseCollectionCollections1').then(function (col) {\n      test.ok(col != null);\n      db.createCollection('promiseCollectionCollections2').then(function (col) {\n        test.ok(col != null);\n        db.collections().then(function (r) {\n          test.ok(Array.isArray(r));\n          client.close(done);\n        });\n      });\n    });\n  });","file":"integration/collection-management/collection_db_management.test.ts","skipped":false,"dir":"test"},{"name":"should correctly receive the APM events for an insert","suites":["Command Monitoring"],"updatePoint":{"line":8,"column":59,"index":339},"line":8,"code":"  it('should correctly receive the APM events for an insert', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      client.on('commandStarted', filterForCommands('insert', started));\n      client.on('commandSucceeded', filterForCommands('insert', succeeded));\n      return client.db(this.configuration.db).collection('apm_test').insertOne({\n        a: 1\n      }).then(r => {\n        expect(r).property('insertedId').to.exist;\n        expect(started.length).to.equal(1);\n        expect(started[0].commandName).to.equal('insert');\n        expect(started[0].command.insert).to.equal('apm_test');\n        expect(succeeded.length).to.equal(1);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-logging-and-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly handle cursor.close when no cursor existed","suites":["Command Monitoring"],"updatePoint":{"line":39,"column":65,"index":1348},"line":39,"code":"  it('should correctly handle cursor.close when no cursor existed', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      client.on('commandStarted', filterForCommands('insert', started));\n      client.on('commandSucceeded', filterForCommands('insert', succeeded));\n      const db = client.db(this.configuration.db);\n      const collection = db.collection('apm_test_cursor');\n      return collection.insertMany([{\n        a: 1\n      }, {\n        a: 2\n      }, {\n        a: 3\n      }]).then(r => {\n        expect(r).property('insertedCount').to.equal(3);\n        const cursor = collection.find({});\n        return cursor.count().then(() => {\n          cursor.close(); // <-- Will cause error in APM module.\n          return client.close();\n        });\n      });\n    }\n  });","file":"integration/command-logging-and-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly receive the APM events for a listCollections command","suites":["Command Monitoring"],"updatePoint":{"line":76,"column":75,"index":2431},"line":76,"code":"  it('should correctly receive the APM events for a listCollections command', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.0.0'\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      client.on('commandStarted', filterForCommands('listCollections', started));\n      client.on('commandSucceeded', filterForCommands('listCollections', succeeded));\n      const db = client.db(this.configuration.db);\n      return db.collection('apm_test_list_collections').insertOne({\n        a: 1\n      }, this.configuration.writeConcernMax()).then(r => {\n        expect(r).property('insertedId').to.exist;\n        return db.listCollections({}, {\n          readPreference: ReadPreference.primary\n        }).toArray();\n      }).then(() => db.listCollections({}, {\n        readPreference: ReadPreference.secondary\n      }).toArray()).then(() => {\n        expect(started).to.have.lengthOf(2);\n        expect(started[0]).property('address').to.not.equal(started[1].address);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-logging-and-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly receive the APM events for a listIndexes command","suites":["Command Monitoring"],"line":115,"code":"  it.skip('should correctly receive the APM events for a listIndexes command', {","file":"integration/command-logging-and-monitoring/command_monitoring.test.ts","skipped":true,"dir":"test"},{"name":"should correctly receive the APM events for a find with getmore and killcursor","suites":["Command Monitoring"],"updatePoint":{"line":153,"column":84,"index":5108},"line":153,"code":"  it('should correctly receive the APM events for a find with getmore and killcursor', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const failed = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['find', 'getMore', 'killCursors'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      client.on('commandFailed', filterForCommands(desiredEvents, failed));\n      const db = client.db(this.configuration.db);\n\n      // Drop the collection\n      return db.collection('apm_test_2').drop().catch(ignoreNsNotFound).then(() => {\n        // Insert test documents\n        return db.collection('apm_test_2').insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        });\n      }).then(r => {\n        expect(r).property('insertedCount').to.equal(6);\n        return db.collection('apm_test_2').find({\n          a: 1\n        }).project({\n          _id: 1,\n          a: 1\n        }).hint({\n          _id: 1\n        }).skip(1).limit(100).batchSize(2).comment('some comment').maxTimeMS(5000).withReadPreference(ReadPreference.PRIMARY).addCursorFlag('noCursorTimeout', true).toArray();\n      }).then(docs => {\n        // Assert basic documents\n        expect(docs).to.have.length(5);\n        expect(started).to.have.length(3);\n        expect(succeeded).to.have.length(3);\n        expect(failed).to.have.length(0);\n\n        // Success messages\n        expect(succeeded[0].reply).to.not.be.null;\n        expect(succeeded[0].operationId).to.equal(succeeded[1].operationId);\n        expect(succeeded[0].operationId).to.equal(succeeded[2].operationId);\n        expect(succeeded[1].reply).to.not.be.null;\n        expect(succeeded[2].reply).to.not.be.null;\n\n        // Started\n        expect(started[0].operationId).to.equal(started[1].operationId);\n        expect(started[0].operationId).to.equal(started[2].operationId);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-logging-and-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly receive the APM failure event for find","suites":["Command Monitoring"],"updatePoint":{"line":228,"column":61,"index":7528},"line":228,"code":"  it('should correctly receive the APM failure event for find', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset'],\n        mongodb: '>=2.6.0'\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const failed = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['find', 'getMore', 'killCursors'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      client.on('commandFailed', filterForCommands(desiredEvents, failed));\n      const db = client.db(this.configuration.db);\n\n      // Drop the collection\n      return db.collection('apm_test_2').drop().catch(ignoreNsNotFound).then(() => {\n        // Insert test documents\n        return db.collection('apm_test_2').insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }]);\n      }).then(r => {\n        expect(r).property('insertedCount').to.equal(6);\n        return db.collection('apm_test_2').find({\n          $illegalfield: 1\n        }).project({\n          _id: 1,\n          a: 1\n        }).hint({\n          _id: 1\n        }).skip(1).limit(100).batchSize(2).comment('some comment').maxTimeMS(5000).withReadPreference(ReadPreference.PRIMARY).addCursorFlag('noCursorTimeout', true).toArray();\n      }).then(() => {\n        throw new Error('this should not happen');\n      }).catch(() => {\n        expect(failed).to.have.length(1);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-logging-and-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly receive the APM events for a bulk operation","suites":["Command Monitoring"],"updatePoint":{"line":287,"column":66,"index":9333},"line":287,"code":"  it('should correctly receive the APM events for a bulk operation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['insert', 'update', 'delete'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      const db = client.db(this.configuration.db);\n      return db.collection('apm_test_3').bulkWrite([{\n        insertOne: {\n          document: {\n            a: 1\n          }\n        }\n      }, {\n        updateOne: {\n          filter: {\n            a: 2\n          },\n          update: {\n            $set: {\n              a: 2\n            }\n          },\n          upsert: true\n        }\n      }, {\n        deleteOne: {\n          filter: {\n            c: 1\n          }\n        }\n      }], {\n        ordered: true\n      }).then(() => {\n        expect(started).to.have.length(3);\n        expect(succeeded).to.have.length(3);\n        expect(started[0].operationId).to.equal(started[1].operationId);\n        expect(started[0].operationId).to.equal(started[2].operationId);\n        expect(succeeded[0].operationId).to.equal(succeeded[1].operationId);\n        expect(succeeded[0].operationId).to.equal(succeeded[2].operationId);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-logging-and-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly receive the APM explain command","suites":["Command Monitoring"],"updatePoint":{"line":345,"column":54,"index":10934},"line":345,"code":"  it('should correctly receive the APM explain command', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const failed = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['find', 'getMore', 'killCursors', 'explain'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      client.on('commandFailed', filterForCommands(desiredEvents, failed));\n      const db = client.db(this.configuration.db);\n      return db.collection('apm_test_2').drop().catch(ignoreNsNotFound).then(() => db.collection('apm_test_2').insertMany([{\n        a: 1\n      }, {\n        a: 1\n      }, {\n        a: 1\n      }, {\n        a: 1\n      }, {\n        a: 1\n      }, {\n        a: 1\n      }], {\n        writeConcern: {\n          w: 1\n        }\n      })).then(r => {\n        expect(r).property('insertedCount').to.equal(6);\n        return db.collection('apm_test_2').find({\n          a: 1\n        }).explain();\n      }).then(explain => {\n        expect(explain).to.not.be.null;\n        expect(started).to.have.length(1);\n        expect(started[0].commandName).to.equal('explain');\n        expect(started[0].command.explain.find).to.equal('apm_test_2');\n        expect(succeeded).to.have.length(1);\n        expect(succeeded[0].commandName).to.equal('explain');\n        expect(started[0].operationId).to.equal(succeeded[0].operationId);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-logging-and-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly filter out sensitive commands","suites":["Command Monitoring"],"updatePoint":{"line":401,"column":52,"index":12686},"line":401,"code":"  it('should correctly filter out sensitive commands', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const failed = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['hello'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      client.on('commandFailed', filterForCommands(desiredEvents, failed));\n      return client.db(this.configuration.db).command({\n        hello: 1,\n        speculativeAuthenticate: {\n          saslStart: 1\n        }\n      }).then(r => {\n        expect(r).to.exist;\n        expect(started).to.have.length(1);\n        expect(succeeded).to.have.length(1);\n        expect(failed).to.have.length(0);\n        expect(started[0].command).to.eql({});\n        expect(succeeded[0].reply).to.eql({});\n        return client.close();\n      });\n    }\n  });","file":"integration/command-logging-and-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly receive the APM events for an updateOne","suites":["Command Monitoring"],"updatePoint":{"line":439,"column":62,"index":13867},"line":439,"code":"  it('should correctly receive the APM events for an updateOne', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['update'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      return client.db(this.configuration.db).collection('apm_test_u_1').updateOne({\n        a: 1\n      }, {\n        $set: {\n          b: 1\n        }\n      }, {\n        upsert: true\n      }).then(r => {\n        expect(r).to.exist;\n        expect(started).to.have.length(1);\n        expect(started[0].commandName).to.equal('update');\n        expect(started[0].command.update).to.equal('apm_test_u_1');\n        expect(succeeded).to.have.length(1);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-logging-and-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly receive the APM events for an updateMany","suites":["Command Monitoring"],"updatePoint":{"line":477,"column":63,"index":14980},"line":477,"code":"  it('should correctly receive the APM events for an updateMany', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['update'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      return client.db(this.configuration.db).collection('apm_test_u_2').updateMany({\n        a: 1\n      }, {\n        $set: {\n          b: 1\n        }\n      }, {\n        upsert: true\n      }).then(r => {\n        expect(r).to.exist;\n        expect(started).to.have.length(1);\n        expect(started[0].commandName).to.equal('update');\n        expect(started[0].command.update).to.equal('apm_test_u_2');\n        expect(succeeded).to.have.length(1);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-logging-and-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly receive the APM events for deleteOne","suites":["Command Monitoring"],"updatePoint":{"line":515,"column":59,"index":16090},"line":515,"code":"  it('should correctly receive the APM events for deleteOne', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['delete'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      return client.db(this.configuration.db).collection('apm_test_u_3').deleteOne({\n        a: 1\n      }).then(r => {\n        expect(r).to.exist;\n        expect(started).to.have.length(1);\n        expect(started[0].commandName).to.equal('delete');\n        expect(started[0].command.delete).to.equal('apm_test_u_3');\n        expect(succeeded).to.have.length(1);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-logging-and-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should ensure killcursor commands are sent on 3.0 or earlier when APM is enabled","suites":["Command Monitoring"],"updatePoint":{"line":547,"column":86,"index":17142},"line":547,"code":"  it('should ensure killcursor commands are sent on 3.0 or earlier when APM is enabled', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset'],\n        mongodb: '<=3.0.x'\n      }\n    },\n    test: function () {\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const db = client.db(this.configuration.db);\n      const admindb = db.admin();\n      let cursorCountBefore;\n      let cursorCountAfter;\n      const collection = db.collection('apm_killcursor_tests');\n\n      // make sure collection has records (more than 2)\n      return collection.insertMany([{\n        a: 1\n      }, {\n        a: 2\n      }, {\n        a: 3\n      }]).then(r => {\n        expect(r).to.exist;\n        return admindb.serverStatus();\n      }).then(result => {\n        cursorCountBefore = result.cursors.clientCursors_size;\n        const cursor = collection.find({}).limit(2);\n        return cursor.toArray().then(r => {\n          expect(r).to.exist;\n          return cursor.close();\n        });\n      }).then(() => admindb.serverStatus()).then(result => {\n        cursorCountAfter = result.cursors.clientCursors_size;\n        expect(cursorCountBefore).to.equal(cursorCountAfter);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-logging-and-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly decorate the apm result for aggregation with cursorId","suites":["Command Monitoring"],"updatePoint":{"line":593,"column":76,"index":18493},"line":593,"code":"  it('should correctly decorate the apm result for aggregation with cursorId', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset'],\n        mongodb: '>=3.0.0'\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n\n      // Generate docs\n      const docs = [];\n      for (let i = 0; i < 2500; i++) docs.push({\n        a: i\n      });\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['aggregate', 'getMore'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      const db = client.db(this.configuration.db);\n      return db.collection('apm_test_u_4').drop().catch(ignoreNsNotFound).then(() => db.collection('apm_test_u_4').insertMany(docs)).then(r => {\n        expect(r).to.exist;\n        return db.collection('apm_test_u_4').aggregate([{\n          $match: {}\n        }]).toArray();\n      }).then(r => {\n        expect(r).to.exist;\n        expect(started).to.have.length(4);\n        expect(succeeded).to.have.length(4);\n        const cursors = succeeded.map(x => x.reply.cursor);\n\n        // Check we have a cursor\n        expect(cursors[0].id).to.exist;\n        expect(cursors[0].id.toString()).to.equal(cursors[1].id.toString());\n        expect(cursors[3].id.toString()).to.equal('0');\n        return client.close();\n      });\n    }\n  });","file":"integration/command-logging-and-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should correctly decorate the apm result for listCollections with cursorId","suites":["Command Monitoring"],"updatePoint":{"line":640,"column":80,"index":20069},"line":640,"code":"  it('should correctly decorate the apm result for listCollections with cursorId', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset'],\n        mongodb: '>=3.0.0'\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['listCollections'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      const db = client.db(this.configuration.db);\n      const promises = [];\n      for (let i = 0; i < 20; i++) {\n        promises.push(db.collection('_mass_collection_' + i).insertOne({\n          a: 1\n        }));\n      }\n      return Promise.all(promises).then(r => {\n        expect(r).to.exist;\n        return db.listCollections().batchSize(10).toArray();\n      }).then(r => {\n        expect(r).to.exist;\n        expect(started).to.have.length(1);\n        expect(succeeded).to.have.length(1);\n        const cursors = succeeded.map(x => x.reply.cursor);\n        expect(cursors[0].id).to.exist;\n        return client.close();\n      });\n    }\n  });","file":"integration/command-logging-and-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"should not allow mutation of internal state from commands returned by event monitoring","suites":["Command Monitoring","Internal state references"],"updatePoint":{"line":698,"column":94,"index":21762},"line":698,"code":"    it('should not allow mutation of internal state from commands returned by event monitoring', function () {\n      const started = [];\n      const succeeded = [];\n      client.on('commandStarted', filterForCommands('insert', started));\n      client.on('commandSucceeded', filterForCommands('insert', succeeded));\n      const documentToInsert = {\n        a: {\n          b: 1\n        }\n      };\n      const db = client.db(this.configuration.db);\n      return db.collection('apm_test').insertOne(documentToInsert).then(r => {\n        expect(r).to.have.property('insertedId').that.is.an('object');\n        expect(started).to.have.lengthOf(1);\n        // Check if contents of returned document are equal to document inserted (by value)\n        expect(documentToInsert).to.deep.equal(started[0].command.documents[0]);\n        // Check if the returned document is a clone of the original. This confirms that the\n        // reference is not the same.\n        expect(documentToInsert !== started[0].command.documents[0]).to.equal(true);\n        expect(documentToInsert.a !== started[0].command.documents[0].a).to.equal(true);\n        started[0].command.documents[0].a.b = 2;\n        expect(documentToInsert.a.b).to.equal(1);\n        expect(started[0].commandName).to.equal('insert');\n        expect(started[0].command.insert).to.equal('apm_test');\n        expect(succeeded).to.have.lengthOf(1);\n      });\n    });","file":"integration/command-logging-and-monitoring/command_monitoring.test.ts","skipped":false,"dir":"test"},{"name":"getMore iteration","suites":[],"updatePoint":{"line":62,"column":23,"index":2334},"line":62,"code":"  it('getMore iteration', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.2.0',\n        topology: 'replicaset'\n      }\n    },\n    test: function () {\n      return collection.insertMany([{\n        a: 1\n      }, {\n        a: 2\n      }, {\n        a: 3\n      }, {\n        a: 4\n      }, {\n        a: 5\n      }], {\n        writeConcern: {\n          w: 'majority'\n        }\n      }).then(result => expect(result.insertedCount).to.equal(5)).then(() => {\n        const cursor = collection.find({}, {\n          batchSize: 2\n        });\n        deferred.push(() => cursor.close());\n        return cursor.next().then(item => expect(item.a).to.equal(1)).then(() => cursor.next()).then(item => expect(item.a).to.equal(2)).then(() => {\n          return connectionCount(checkClient).then(initialConnectionCount => {\n            return client.db('admin').command({\n              replSetFreeze: 0\n            }, {\n              readPreference: 'secondary'\n            }).then(result => expect(result).property('info').to.equal('unfreezing')).then(() => client.db('admin').command({\n              replSetStepDown: 30,\n              force: true\n            }, {\n              readPreference: 'primary'\n            })).then(() => cursor.next()).then(item => expect(item.a).to.equal(3)).then(() => connectionCount(checkClient).then(expectPoolWasNotCleared(initialConnectionCount)));\n          });\n        });\n      });\n    }\n  });","file":"integration/connections-survive-step-down/connections_survive_step_down.prose.test.ts","skipped":false,"dir":"test"},{"name":"Not Primary - Keep Connection Pool","suites":[],"updatePoint":{"line":130,"column":40,"index":4604},"line":130,"code":"  it('Not Primary - Keep Connection Pool', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.2.0',\n        topology: 'replicaset'\n      }\n    },\n    test: function () {\n      return runStepownScenario(10107, expectPoolWasNotCleared);\n    }\n  });","file":"integration/connections-survive-step-down/connections_survive_step_down.prose.test.ts","skipped":false,"dir":"test"},{"name":"Not Primary - Reset Connection Pool","suites":[],"updatePoint":{"line":141,"column":41,"index":4859},"line":141,"code":"  it('Not Primary - Reset Connection Pool', {\n    metadata: {\n      requires: {\n        mongodb: '4.0.x',\n        topology: 'replicaset'\n      }\n    },\n    test: function () {\n      return runStepownScenario(10107, expectPoolWasCleared);\n    }\n  });","file":"integration/connections-survive-step-down/connections_survive_step_down.prose.test.ts","skipped":false,"dir":"test"},{"name":"Shutdown in progress - Reset Connection Pool","suites":[],"updatePoint":{"line":152,"column":50,"index":5118},"line":152,"code":"  it('Shutdown in progress - Reset Connection Pool', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.0.0',\n        topology: 'replicaset'\n      }\n    },\n    test: function () {\n      return runStepownScenario(91, expectPoolWasCleared);\n    }\n  });","file":"integration/connections-survive-step-down/connections_survive_step_down.prose.test.ts","skipped":false,"dir":"test"},{"name":"Interrupted at shutdown - Reset Connection Pool","suites":[],"updatePoint":{"line":163,"column":53,"index":5379},"line":163,"code":"  it('Interrupted at shutdown - Reset Connection Pool', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.0.0',\n        topology: 'replicaset'\n      }\n    },\n    test: function () {\n      return runStepownScenario(11600, expectPoolWasCleared);\n    }\n  });","file":"integration/connections-survive-step-down/connections_survive_step_down.prose.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute simple aggregation pipeline using array","suites":["Aggregation"],"updatePoint":{"line":12,"column":70,"index":408},"line":12,"code":"  it('should correctly execute simple aggregation pipeline using array', function (done) {\n    const client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n      databaseName = this.configuration.db;\n    const db = client.db(databaseName);\n    // Some docs for insertion\n    const docs = [{\n      title: 'this is my title',\n      author: 'bob',\n      posted: new Date(),\n      pageViews: 5,\n      tags: ['fun', 'good', 'fun'],\n      other: {\n        foo: 5\n      },\n      comments: [{\n        author: 'joe',\n        text: 'this is cool'\n      }, {\n        author: 'sam',\n        text: 'this is bad'\n      }]\n    }];\n\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyExecuteSimpleAggregationPipelineUsingArray');\n    // Insert the docs\n    collection.insertMany(docs, {\n      writeConcern: {\n        w: 1\n      }\n    }, function (err, result) {\n      expect(result).to.exist;\n      expect(err).to.not.exist;\n\n      // Execute aggregate, notice the pipeline is expressed as an Array\n      const cursor = collection.aggregate([{\n        $project: {\n          author: 1,\n          tags: 1\n        }\n      }, {\n        $unwind: '$tags'\n      }, {\n        $group: {\n          _id: {\n            tags: '$tags'\n          },\n          authors: {\n            $addToSet: '$author'\n          }\n        }\n      }, {\n        $sort: {\n          _id: -1\n        }\n      }]);\n      cursor.toArray(function (err, result) {\n        expect(err).to.not.exist;\n        expect(result[0]._id.tags).to.equal('good');\n        expect(result[0].authors).to.eql(['bob']);\n        expect(result[1]._id.tags).to.equal('fun');\n        expect(result[1].authors).to.eql(['bob']);\n        client.close(done);\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute db.aggregate() with $currentOp","suites":["Aggregation"],"updatePoint":{"line":82,"column":61,"index":2170},"line":82,"code":"  it('should correctly execute db.aggregate() with $currentOp', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.0.0'\n      }\n    },\n    test: function (done) {\n      const client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      });\n      const db = client.db('admin');\n      const cursor = db.aggregate([{\n        $currentOp: {\n          localOps: true\n        }\n      }]);\n      cursor.toArray((err, result) => {\n        expect(err).to.not.exist;\n        const aggregateOperation = result.filter(op => op.command && op.command.aggregate)[0];\n        expect(aggregateOperation.command.aggregate).to.equal(1);\n        expect(aggregateOperation.command.pipeline).to.eql([{\n          $currentOp: {\n            localOps: true\n          }\n        }]);\n        expect(aggregateOperation.command.cursor).to.deep.equal({});\n        expect(aggregateOperation.command['$db']).to.equal('admin');\n        client.close(done);\n      });\n    }\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should fail when executing simple aggregation pipeline using arguments not an array","suites":["Aggregation"],"updatePoint":{"line":115,"column":89,"index":3180},"line":115,"code":"  it('should fail when executing simple aggregation pipeline using arguments not an array', function (done) {\n    const client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n      databaseName = this.configuration.db;\n    const db = client.db(databaseName);\n    // Some docs for insertion\n    const docs = [{\n      title: 'this is my title',\n      author: 'bob',\n      posted: new Date(),\n      pageViews: 5,\n      tags: ['fun', 'good', 'fun'],\n      other: {\n        foo: 5\n      },\n      comments: [{\n        author: 'joe',\n        text: 'this is cool'\n      }, {\n        author: 'sam',\n        text: 'this is bad'\n      }]\n    }];\n\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyExecuteSimpleAggregationPipelineUsingArguments');\n    // Insert the docs\n    collection.insertMany(docs, {\n      writeConcern: {\n        w: 1\n      }\n    }, function (err, result) {\n      expect(result).to.exist;\n      expect(err).to.not.exist;\n\n      // Execute aggregate, notice the pipeline is expressed as function call parameters\n      // instead of an Array.\n      const cursor = collection.aggregate([{\n        $project: {\n          author: 1,\n          tags: 1\n        }\n      }, {\n        $unwind: '$tags'\n      }, {\n        $group: {\n          _id: {\n            tags: '$tags'\n          },\n          authors: {\n            $addToSet: '$author'\n          }\n        }\n      }, {\n        $sort: {\n          _id: -1\n        }\n      }]);\n      cursor.toArray(function (err, result) {\n        expect(err).to.not.exist;\n        expect(result[0]._id.tags).to.equal('good');\n        expect(result[0].authors).to.eql(['bob']);\n        expect(result[1]._id.tags).to.equal('fun');\n        expect(result[1].authors).to.eql(['bob']);\n        client.close(done);\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should fail when executing simple aggregation pipeline using arguments using single object","suites":["Aggregation"],"updatePoint":{"line":186,"column":96,"index":5027},"line":186,"code":"  it('should fail when executing simple aggregation pipeline using arguments using single object', function (done) {\n    const client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n      databaseName = this.configuration.db;\n    const db = client.db(databaseName);\n    // Some docs for insertion\n    const docs = [{\n      title: 'this is my title',\n      author: 'bob',\n      posted: new Date(),\n      pageViews: 5,\n      tags: ['fun', 'good', 'fun'],\n      other: {\n        foo: 5\n      },\n      comments: [{\n        author: 'joe',\n        text: 'this is cool'\n      }, {\n        author: 'sam',\n        text: 'this is bad'\n      }]\n    }];\n\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyExecuteSimpleAggregationPipelineUsingArguments');\n    // Insert the docs\n    collection.insertMany(docs, {\n      writeConcern: {\n        w: 1\n      }\n    }, function (err, result) {\n      expect(result).to.exist;\n      expect(err).to.not.exist;\n\n      // Execute aggregate, notice the pipeline is expressed as function call parameters\n      // instead of an Array.\n      const cursor = collection.aggregate([{\n        $project: {\n          author: 1,\n          tags: 1\n        }\n      }, {\n        $unwind: '$tags'\n      }, {\n        $group: {\n          _id: {\n            tags: '$tags'\n          },\n          authors: {\n            $addToSet: '$author'\n          }\n        }\n      }, {\n        $sort: {\n          _id: -1\n        }\n      }]);\n      cursor.toArray(function (err, result) {\n        expect(err).to.not.exist;\n        expect(result[0]._id.tags).to.equal('good');\n        expect(result[0].authors).to.eql(['bob']);\n        expect(result[1]._id.tags).to.equal('fun');\n        expect(result[1].authors).to.eql(['bob']);\n        client.close(done);\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should correctly return and iterate over all the cursor results","suites":["Aggregation"],"updatePoint":{"line":257,"column":69,"index":6847},"line":257,"code":"  it('should correctly return and iterate over all the cursor results', function (done) {\n    const client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n      databaseName = this.configuration.db;\n    const db = client.db(databaseName);\n    // Some docs for insertion\n    const docs = [{\n      title: 'this is my title',\n      author: 'bob',\n      posted: new Date(),\n      pageViews: 5,\n      tags: ['fun', 'good', 'fun'],\n      other: {\n        foo: 5\n      },\n      comments: [{\n        author: 'joe',\n        text: 'this is cool'\n      }, {\n        author: 'sam',\n        text: 'this is bad'\n      }]\n    }];\n\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyDoAggWithCursorGet');\n    // Insert the docs\n    collection.insertMany(docs, {\n      writeConcern: {\n        w: 1\n      }\n    }, function (err, result) {\n      expect(err).to.not.exist;\n      expect(result).to.exist;\n\n      // Execute aggregate, notice the pipeline is expressed as an Array\n      const cursor = collection.aggregate([{\n        $project: {\n          author: 1,\n          tags: 1\n        }\n      }, {\n        $unwind: '$tags'\n      }, {\n        $group: {\n          _id: {\n            tags: '$tags'\n          },\n          authors: {\n            $addToSet: '$author'\n          }\n        }\n      }]);\n\n      // Iterate over all the items in the cursor\n      cursor.toArray(function (err, result) {\n        expect(err).to.not.exist;\n        expect(result).to.exist;\n        client.close(done);\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should correctly return a cursor and call explain","suites":["Aggregation"],"updatePoint":{"line":322,"column":55,"index":8400},"line":322,"code":"  it('should correctly return a cursor and call explain', function (done) {\n    const client = this.configuration.newClient({\n        maxPoolSize: 1\n      }),\n      databaseName = this.configuration.db;\n    const db = client.db(databaseName);\n    // Some docs for insertion\n    const docs = [{\n      title: 'this is my title',\n      author: 'bob',\n      posted: new Date(),\n      pageViews: 5,\n      tags: ['fun', 'good', 'fun'],\n      other: {\n        foo: 5\n      },\n      comments: [{\n        author: 'joe',\n        text: 'this is cool'\n      }, {\n        author: 'sam',\n        text: 'this is bad'\n      }]\n    }];\n\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyDoAggWithCursorGet');\n    // Insert the docs\n    collection.insertMany(docs, {\n      writeConcern: {\n        w: 1\n      }\n    }, function (err, result) {\n      expect(result).to.exist;\n      expect(err).to.not.exist;\n\n      // Execute aggregate, notice the pipeline is expressed as an Array\n      const cursor = collection.aggregate([{\n        $project: {\n          author: 1,\n          tags: 1\n        }\n      }, {\n        $unwind: '$tags'\n      }, {\n        $group: {\n          _id: {\n            tags: '$tags'\n          },\n          authors: {\n            $addToSet: '$author'\n          }\n        }\n      }], {\n        cursor: {\n          batchSize: 100\n        }\n      });\n\n      // Iterate over all the items in the cursor\n      cursor.explain(function (err, result) {\n        expect(err).to.not.exist;\n        expect(result.stages).to.have.lengthOf.at.least(1);\n        expect(result.stages[0]).to.have.property('$cursor');\n        client.close(done);\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should correctly return a cursor with batchSize 1 and call next","suites":["Aggregation"],"updatePoint":{"line":390,"column":69,"index":10096},"line":390,"code":"  it('should correctly return a cursor with batchSize 1 and call next', function (done) {\n    const client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n      databaseName = this.configuration.db;\n    this.defer(() => client.close());\n    const db = client.db(databaseName);\n    // Some docs for insertion\n    const docs = [{\n      title: 'this is my title',\n      author: 'bob',\n      posted: new Date(),\n      pageViews: 5,\n      tags: ['fun', 'good', 'fun'],\n      other: {\n        foo: 5\n      },\n      comments: [{\n        author: 'joe',\n        text: 'this is cool'\n      }, {\n        author: 'sam',\n        text: 'this is bad'\n      }]\n    }];\n\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyDoAggWithCursorGet');\n    // Insert the docs\n    collection.insertMany(docs, {\n      writeConcern: {\n        w: 1\n      }\n    }, (err, result) => {\n      expect(result).to.exist;\n      expect(err).to.not.exist;\n\n      // Execute aggregate, notice the pipeline is expressed as an Array\n      const cursor = collection.aggregate([{\n        $project: {\n          author: 1,\n          tags: 1\n        }\n      }, {\n        $unwind: '$tags'\n      }, {\n        $group: {\n          _id: {\n            tags: '$tags'\n          },\n          authors: {\n            $addToSet: '$author'\n          }\n        }\n      }, {\n        $sort: {\n          _id: -1\n        }\n      }], {\n        cursor: {\n          batchSize: 1\n        }\n      });\n      this.defer(() => cursor.close());\n\n      // Iterate over all the items in the cursor\n      cursor.next((err, result) => {\n        expect(err).to.not.exist;\n        expect(result._id.tags).to.equal('good');\n        expect(result.authors).to.eql(['bob']);\n        done();\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should correctly write the results out to a new collection","suites":["Aggregation"],"updatePoint":{"line":466,"column":64,"index":11892},"line":466,"code":"  it('should correctly write the results out to a new collection', function (done) {\n    const client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n      databaseName = this.configuration.db;\n    const db = client.db(databaseName);\n    // Some docs for insertion\n    const docs = [{\n      title: 'this is my title',\n      author: 'bob',\n      posted: new Date(),\n      pageViews: 5,\n      tags: ['fun', 'good', 'fun'],\n      other: {\n        foo: 5\n      },\n      comments: [{\n        author: 'joe',\n        text: 'this is cool'\n      }, {\n        author: 'sam',\n        text: 'this is bad'\n      }]\n    }];\n\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyDoAggWithCursorGet');\n    // Insert the docs\n    collection.insertMany(docs, {\n      writeConcern: {\n        w: 1\n      }\n    }, function (err, result) {\n      expect(result).to.exist;\n      expect(err).to.not.exist;\n\n      // Execute aggregate, notice the pipeline is expressed as an Array\n      const cursor = collection.aggregate([{\n        $project: {\n          author: 1,\n          tags: 1\n        }\n      }, {\n        $unwind: '$tags'\n      }, {\n        $group: {\n          _id: {\n            tags: '$tags'\n          },\n          authors: {\n            $addToSet: '$author'\n          }\n        }\n      }], {\n        out: 'testingOutCollectionForAggregation'\n      });\n      cursor.toArray(function (err, results) {\n        expect(err).to.not.exist;\n        expect(results).to.be.empty;\n        client.close(done);\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should correctly use allowDiskUse when performing an aggregation","suites":["Aggregation"],"updatePoint":{"line":531,"column":70,"index":13475},"line":531,"code":"  it('should correctly use allowDiskUse when performing an aggregation', function (done) {\n    const client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n      databaseName = this.configuration.db;\n    const db = client.db(databaseName);\n    // Some docs for insertion\n    const docs = [{\n      title: 'this is my title',\n      author: 'bob',\n      posted: new Date(),\n      pageViews: 5,\n      tags: ['fun', 'good', 'fun'],\n      other: {\n        foo: 5\n      },\n      comments: [{\n        author: 'joe',\n        text: 'this is cool'\n      }, {\n        author: 'sam',\n        text: 'this is bad'\n      }]\n    }];\n\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyDoAggWithCursorGet');\n    // Insert the docs\n    collection.insertMany(docs, {\n      writeConcern: {\n        w: 1\n      }\n    }, function (err, result) {\n      expect(result).to.exist;\n      expect(err).to.not.exist;\n\n      // Execute aggregate, notice the pipeline is expressed as an Array\n      const cursor = collection.aggregate([{\n        $project: {\n          author: 1,\n          tags: 1\n        }\n      }, {\n        $unwind: '$tags'\n      }, {\n        $group: {\n          _id: {\n            tags: '$tags'\n          },\n          authors: {\n            $addToSet: '$author'\n          }\n        }\n      }, {\n        $sort: {\n          _id: -1\n        }\n      }], {\n        allowDiskUse: true\n      });\n      cursor.toArray(function (err, results) {\n        expect(err).to.not.exist;\n        expect(results[0]._id.tags).to.equal('good');\n        expect(results[0].authors).to.eql(['bob']);\n        expect(results[1]._id.tags).to.equal('fun');\n        expect(results[1].authors).to.eql(['bob']);\n        client.close(done);\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should perform a simple group aggregation","suites":["Aggregation"],"updatePoint":{"line":603,"column":47,"index":15242},"line":603,"code":"  it('should perform a simple group aggregation', function (done) {\n    const databaseName = this.configuration.db;\n    const client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    const db = client.db(databaseName);\n    // Create a collection\n    const col = db.collection('shouldPerformSimpleGroupAggregation');\n    col.deleteMany({}, function (err) {\n      expect(err).to.not.exist;\n\n      // Insert a single document\n      col.insertMany([{\n        a: 1\n      }, {\n        a: 1\n      }, {\n        a: 1\n      }], function (err, r) {\n        expect(err).to.not.exist;\n        expect(r).property('insertedCount').to.equal(3);\n\n        // Get first two documents that match the query\n        col.aggregate([{\n          $match: {}\n        }, {\n          $group: {\n            _id: '$a',\n            total: {\n              $sum: '$a'\n            }\n          }\n        }]).toArray(function (err, docs) {\n          expect(err).to.not.exist;\n          expect(docs[0].total).to.equal(3);\n          client.close(done);\n        });\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should correctly perform an aggregation using a collection name with dot in it","suites":["Aggregation"],"updatePoint":{"line":643,"column":84,"index":16383},"line":643,"code":"  it('should correctly perform an aggregation using a collection name with dot in it', function (done) {\n    const databaseName = this.configuration.db;\n    const client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    const db = client.db(databaseName);\n    const col = db.collection('te.st');\n    let count = 0;\n    col.insertMany([{\n      a: 1\n    }, {\n      a: 1\n    }, {\n      a: 1\n    }], function (err, r) {\n      expect(err).to.not.exist;\n      expect(r).property('insertedCount').to.equal(3);\n      const cursor = col.aggregate([{\n        $project: {\n          a: 1\n        }\n      }]);\n      cursor.toArray(function (err, docs) {\n        expect(err).to.not.exist;\n        expect(docs.length).to.be.greaterThan(0);\n\n        //Using cursor - KO\n        col.aggregate([{\n          $project: {\n            a: 1\n          }\n        }], {\n          cursor: {\n            batchSize: 10000\n          }\n        }).forEach(function () {\n          count = count + 1;\n        }, function (err) {\n          expect(err).to.not.exist;\n          expect(count).to.be.greaterThan(0);\n          client.close(done);\n        });\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should fail aggregation due to illegal cursor option and streams","suites":["Aggregation"],"updatePoint":{"line":688,"column":70,"index":17566},"line":688,"code":"  it('should fail aggregation due to illegal cursor option and streams', async function () {\n    const db = client.db();\n    // Some docs for insertion\n    const docs = [{\n      title: 'this is my title',\n      author: 'bob',\n      posted: new Date(),\n      pageViews: 5,\n      tags: ['fun', 'good', 'fun'],\n      other: {\n        foo: 5\n      },\n      comments: [{\n        author: 'joe',\n        text: 'this is cool'\n      }, {\n        author: 'sam',\n        text: 'this is bad'\n      }]\n    }];\n\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyDoAggWithCursorGetStream');\n    // Insert the docs\n    const result = await collection.insertMany(docs, {\n      writeConcern: {\n        w: 1\n      }\n    });\n    expect(result).to.exist;\n\n    // Execute aggregate, notice the pipeline is expressed as an Array\n    const cursor = collection.aggregate([{\n      $project: {\n        author: 1,\n        tags: 1\n      }\n    }, {\n      $unwind: '$tags'\n    }, {\n      $group: {\n        _id: {\n          tags: '$tags'\n        },\n        authors: {\n          $addToSet: '$author'\n        }\n      }\n    }], {\n      cursor: 1\n    });\n    const error = await cursor.next().catch(error => error);\n    expect(error).to.be.instanceOf(MongoInvalidArgumentError);\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should fail if you try to use explain flag with { readConcern: { level: 'local' }, writeConcern: { j: true } }","suites":["Aggregation"],"updatePoint":{"line":742,"column":116,"index":18891},"line":742,"code":"  it(`should fail if you try to use explain flag with { readConcern: { level: 'local' }, writeConcern: { j: true } }`, async function () {\n    const db = client.db();\n    const collection = db.collection('foo');\n    Object.assign(collection.s, {\n      writeConcern: {\n        j: true\n      }\n    });\n    const error = await collection.aggregate([{\n      $project: {\n        _id: 0\n      }\n    }, {\n      $out: 'bar'\n    }], {\n      explain: true\n    }).toArray().catch(error => error);\n    expect(error).to.be.instanceOf(MongoInvalidArgumentError);\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should fail if you try to use explain flag with { writeConcern: { j: true } }","suites":["Aggregation"],"updatePoint":{"line":761,"column":83,"index":19413},"line":761,"code":"  it('should fail if you try to use explain flag with { writeConcern: { j: true } }', async function () {\n    const db = client.db();\n    const collection = db.collection('foo');\n    Object.assign(collection.s, {\n      writeConcern: {\n        j: true\n      }\n    });\n    const error = await collection.aggregate([{\n      $project: {\n        _id: 0\n      }\n    }, {\n      $out: 'bar'\n    }], {\n      explain: true\n    }).toArray().catch(error => error);\n    expect(error).to.be.instanceOf(MongoInvalidArgumentError);\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should ensure MaxTimeMS is correctly passed down into command execution when using a cursor","suites":["Aggregation"],"updatePoint":{"line":780,"column":97,"index":19949},"line":780,"code":"  it('should ensure MaxTimeMS is correctly passed down into command execution when using a cursor', function (done) {\n    const client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n      databaseName = this.configuration.db;\n    this.defer(() => client.close());\n    const db = client.db(databaseName);\n    const docs = [{\n      title: 'this is my title',\n      author: 'bob',\n      posted: new Date(),\n      pageViews: 5,\n      tags: ['fun', 'good', 'fun'],\n      other: {\n        foo: 5\n      },\n      comments: [{\n        author: 'joe',\n        text: 'this is cool'\n      }, {\n        author: 'sam',\n        text: 'this is bad'\n      }]\n    }];\n\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyDoAggWithCursorMaxTimeMSSet');\n    // Insert the docs\n    collection.insertMany(docs, {\n      writeConcern: {\n        w: 1\n      }\n    }, (err, result) => {\n      expect(result).to.exist;\n      expect(err).to.not.exist;\n\n      // Execute aggregate, notice the pipeline is expressed as an Array\n      const cursor = collection.aggregate([{\n        $project: {\n          author: 1,\n          tags: 1\n        }\n      }, {\n        $unwind: '$tags'\n      }, {\n        $group: {\n          _id: {\n            tags: '$tags'\n          },\n          authors: {\n            $addToSet: '$author'\n          }\n        }\n      }, {\n        $sort: {\n          _id: -1\n        }\n      }], {\n        cursor: {\n          batchSize: 1\n        },\n        maxTimeMS: 1000\n      });\n      this.defer(() => cursor.close());\n\n      // Override the db.command to validate the correct command\n      // is executed\n      const command = db.command.bind(db);\n      // Validate the command\n      db.command = function (...args) {\n        const c = args[0];\n        expect(err).to.not.exist;\n        expect(c.maxTimeMS).to.equal(1000);\n\n        // Apply to existing command\n        command(...args);\n      };\n\n      // Iterate over all the items in the cursor\n      cursor.next((err, result) => {\n        expect(err).to.not.exist;\n        expect(result._id.tags).to.equal('good');\n        expect(result.authors).to.eql(['bob']);\n\n        // Validate the command\n        db.command = function (...args) {\n          const c = args[0];\n          expect(err).to.not.exist;\n          expect(c.maxTimeMS).to.equal(1000);\n\n          // Apply to existing command\n          command(...args);\n        };\n\n        // Execute aggregate, notice the pipeline is expressed as an Array\n        const secondCursor = collection.aggregate([{\n          $project: {\n            author: 1,\n            tags: 1\n          }\n        }, {\n          $unwind: '$tags'\n        }, {\n          $group: {\n            _id: {\n              tags: '$tags'\n            },\n            authors: {\n              $addToSet: '$author'\n            }\n          }\n        }], {\n          maxTimeMS: 1000\n        });\n        this.defer(() => secondCursor.close());\n        expect(secondCursor).to.exist;\n\n        // Return the command\n        db.command = command;\n        done();\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should pass a comment down via the aggregation command","suites":["Aggregation"],"updatePoint":{"line":905,"column":60,"index":23012},"line":905,"code":"  it('should pass a comment down via the aggregation command', async function () {\n    const client = this.configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    const databaseName = this.configuration.db;\n    const comment = 'Darmok and Jalad at Tanagra';\n    const db = client.db(databaseName);\n    const collection = db.collection('testingPassingDownTheAggregationCommand');\n    const command = db.command.bind(db);\n    db.command = function (...args) {\n      const c = args[0];\n      expect(c).to.be.an('object');\n      expect(c.comment).to.be.a('string').and.to.equal('comment');\n      command(...args);\n    };\n    const cursor = collection.aggregate([{\n      $project: {\n        _id: 1\n      }\n    }], {\n      comment\n    });\n    expect(cursor).to.not.be.null;\n    await client.close();\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should correctly handle ISODate date matches in aggregation framework","suites":["Aggregation"],"updatePoint":{"line":932,"column":75,"index":23850},"line":932,"code":"  it('should correctly handle ISODate date matches in aggregation framework', function (done) {\n    const databaseName = this.configuration.db;\n    const client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    const db = client.db(databaseName);\n    const date1 = new Date();\n    date1.setHours(date1.getHours() - 1);\n\n    // Some docs for insertion\n    const docs = [{\n      a: date1,\n      b: 1\n    }, {\n      a: new Date(),\n      b: 2\n    }];\n\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyQueryUsingISODate');\n    // Insert the docs\n    collection.insertMany(docs, {\n      writeConcern: {\n        w: 1\n      }\n    }, function (err, result) {\n      expect(result).to.exist;\n      expect(err).to.not.exist;\n\n      // Execute aggregate, notice the pipeline is expressed as an Array\n      const cursor = collection.aggregate([{\n        $match: {\n          a: new Date(date1.toISOString())\n        }\n      }]);\n\n      // Iterate over all the items in the cursor\n      cursor.next(function (err, result) {\n        expect(err).to.not.exist;\n        expect(result.b).to.equal(1);\n        client.close(done);\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should correctly exercise hasNext function on aggregation cursor","suites":["Aggregation"],"updatePoint":{"line":976,"column":70,"index":25062},"line":976,"code":"  it('should correctly exercise hasNext function on aggregation cursor', function (done) {\n    const databaseName = this.configuration.db;\n    const client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    const db = client.db(databaseName);\n    // Create a collection\n    const collection = db.collection('shouldCorrectlyQueryUsingISODate3');\n    // Insert the docs\n    collection.insertMany([{\n      a: 1\n    }, {\n      b: 1\n    }], {\n      writeConcern: {\n        w: 1\n      }\n    }, function (err, result) {\n      expect(result).to.exist;\n      expect(err).to.not.exist;\n\n      // Execute aggregate, notice the pipeline is expressed as an Array\n      const cursor = collection.aggregate([{\n        $match: {}\n      }]);\n\n      // Iterate over all the items in the cursor\n      cursor.hasNext(function (err, result) {\n        expect(err).to.not.exist;\n        expect(result).to.equal(true);\n        client.close(done);\n      });\n    });\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should not send a batchSize for aggregations with an out stage","suites":["Aggregation"],"updatePoint":{"line":1010,"column":68,"index":26060},"line":1010,"code":"  it('should not send a batchSize for aggregations with an out stage', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    async test() {\n      const databaseName = this.configuration.db;\n      const client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const events = [];\n      client.on('commandStarted', filterForCommands(['aggregate'], events));\n      const coll1 = client.db(databaseName).collection('coll1');\n      const coll2 = client.db(databaseName).collection('coll2');\n      await Promise.all([coll1.deleteMany({}), coll2.deleteMany({})]).then(() => {\n        const docs = Array.from({\n          length: 10\n        }).map(() => ({\n          a: 1\n        }));\n        return Promise.all([coll1.insertMany(docs), client.db(databaseName).createCollection('coll2').catch(() => null)]);\n      }).then(() => {\n        return Promise.all([coll1.aggregate([{\n          $out: 'coll2'\n        }]), coll1.aggregate([{\n          $out: 'coll2'\n        }], {\n          batchSize: 0\n        }), coll1.aggregate([{\n          $out: 'coll2'\n        }], {\n          batchSize: 1\n        }), coll1.aggregate([{\n          $out: 'coll2'\n        }], {\n          batchSize: 30\n        }), coll1.aggregate([{\n          $match: {\n            a: 1\n          }\n        }, {\n          $out: 'coll2'\n        }]), coll1.aggregate([{\n          $match: {\n            a: 1\n          }\n        }, {\n          $out: 'coll2'\n        }], {\n          batchSize: 0\n        }), coll1.aggregate([{\n          $match: {\n            a: 1\n          }\n        }, {\n          $out: 'coll2'\n        }], {\n          batchSize: 1\n        }), coll1.aggregate([{\n          $match: {\n            a: 1\n          }\n        }, {\n          $out: 'coll2'\n        }], {\n          batchSize: 30\n        })].map(cursor => cursor.toArray()));\n      }).then(() => {\n        expect(events).to.be.an('array').with.a.lengthOf(8);\n        events.forEach(event => {\n          expect(event).to.have.property('commandName', 'aggregate');\n          expect(event).to.have.property('command').that.has.property('cursor').that.does.not.have.property('batchSize');\n        });\n      }).finally(() => client.close());\n    }\n  });","file":"integration/crud/aggregation.test.ts","skipped":false,"dir":"test"},{"name":"should use the same session for every operation","suites":["Bulk executeOperation"],"updatePoint":{"line":12,"column":53,"index":313},"line":12,"code":"  it('should use the same session for every operation', async () => {\n    const collection = client.db().collection('bulk_execute_operation');\n\n    // TODO(NODE-4263): Legacy bulk operations require connecting invocation\n    await client.db().command({\n      ping: 1\n    });\n    const batch = collection.initializeOrderedBulkOp();\n    const events = [];\n    client.on('commandStarted', ev => events.push(ev));\n    batch.insert({\n      a: 1\n    });\n    batch.find({\n      a: 1\n    }).update({\n      $set: {\n        b: 1\n      }\n    });\n    batch.find({\n      b: 1\n    }).deleteOne();\n    await batch.execute();\n    expect(events).to.have.lengthOf(3);\n    const sessions = events.map(ev => ev.command.lsid.id.toString('hex'));\n    expect(new Set(sessions)).to.have.property('size', 1);\n  });","file":"integration/crud/bulk_execute_operation.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute findOne method using crud api","suites":["CRUD API"],"updatePoint":{"line":29,"column":60,"index":1203},"line":29,"code":"  it('should correctly execute findOne method using crud api', async function () {\n    const db = client.db();\n    const collection = db.collection('t');\n    await collection.insertOne({\n      findOneTest: 1\n    });\n    const findOneResult = await collection.findOne({\n      findOneTest: 1\n    });\n    expect(findOneResult).to.have.property('findOneTest', 1);\n    expect(findOneResult).to.have.property('_id').that.is.instanceOf(ObjectId);\n    const findNoneResult = await collection.findOne({\n      findOneTest: 2\n    });\n    expect(findNoneResult).to.be.null;\n    await collection.drop();\n    await client.close();\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"returns the number of documents","suites":["CRUD API","when creating a cursor with find","#count()"],"updatePoint":{"line":76,"column":41,"index":2638},"line":76,"code":"      it('returns the number of documents', async () => {\n        const cursor = makeCursor();\n        const res = await cursor.count();\n        expect(res).to.equal(2);\n      });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"iterates all the documents","suites":["CRUD API","when creating a cursor with find","#forEach()"],"updatePoint":{"line":83,"column":36,"index":2856},"line":83,"code":"      it('iterates all the documents', async () => {\n        const cursor = makeCursor();\n        let count = 0;\n        await cursor.forEach(() => {\n          count += 1;\n        });\n        expect(count).to.equal(2);\n      });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"returns an array with all documents","suites":["CRUD API","when creating a cursor with find","#toArray()"],"updatePoint":{"line":93,"column":45,"index":3137},"line":93,"code":"      it('returns an array with all documents', async () => {\n        const cursor = makeCursor();\n        const res = await cursor.toArray();\n        expect(res).to.have.lengthOf(2);\n      });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"is callable without blocking","suites":["CRUD API","when creating a cursor with find","#next()"],"updatePoint":{"line":100,"column":38,"index":3364},"line":100,"code":"      it('is callable without blocking', async () => {\n        const cursor = makeCursor();\n        const doc0 = await cursor.next();\n        expect(doc0).to.exist;\n        const doc1 = await cursor.next();\n        expect(doc1).to.exist;\n        const doc2 = await cursor.next();\n        expect(doc2).to.not.exist;\n      });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"creates a node stream that emits data events","suites":["CRUD API","when creating a cursor with find","#stream()"],"updatePoint":{"line":111,"column":54,"index":3747},"line":111,"code":"      it('creates a node stream that emits data events', async () => {\n        const count = 0;\n        const cursor = makeCursor();\n        const stream = cursor.stream();\n        on(stream, 'data');\n        cursor.once('close', function () {\n          expect(count).to.equal(2);\n        });\n      });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"returns an explain document","suites":["CRUD API","when creating a cursor with find","#explain()"],"updatePoint":{"line":122,"column":37,"index":4076},"line":122,"code":"      it('returns an explain document', async () => {\n        const cursor = makeCursor();\n        const result = await cursor.explain();\n        expect(result).to.exist;\n      });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute aggregation method using crud api","suites":["CRUD API","when creating a cursor with find","#explain()"],"updatePoint":{"line":129,"column":64,"index":4298},"line":129,"code":"  it('should correctly execute aggregation method using crud api', function (done) {\n    const db = client.db();\n    db.collection('t1').insertMany([{\n      a: 1\n    }, {\n      a: 1\n    }, {\n      a: 2\n    }, {\n      a: 1\n    }], function (err) {\n      expect(err).to.not.exist;\n      const testAllMethods = function () {\n        // Get the cursor\n        const cursor = db.collection('t1').aggregate([{\n          $match: {}\n        }], {\n          allowDiskUse: true,\n          batchSize: 2,\n          maxTimeMS: 50\n        });\n\n        // Exercise all the options\n        cursor.geoNear({\n          geo: 1\n        }).group({\n          group: 1\n        }).limit(10).match({\n          match: 1\n        }).maxTimeMS(10).out('collection').project({\n          project: 1\n        }).redact({\n          redact: 1\n        }).skip(1).sort({\n          sort: 1\n        }).batchSize(10).unwind('name');\n\n        // Execute the command with all steps defined\n        // will fail\n        cursor.toArray(function (err) {\n          test.ok(err != null);\n          testToArray();\n        });\n      };\n\n      //\n      // Exercise toArray\n      // -------------------------------------------------\n      const testToArray = function () {\n        const cursor = db.collection('t1').aggregate();\n        cursor.match({\n          a: 1\n        });\n        cursor.toArray(function (err, docs) {\n          expect(err).to.not.exist;\n          test.equal(3, docs.length);\n          testNext();\n        });\n      };\n\n      //\n      // Exercise next\n      // -------------------------------------------------\n      const testNext = function () {\n        const cursor = db.collection('t1').aggregate();\n        cursor.match({\n          a: 1\n        });\n        cursor.next(function (err) {\n          expect(err).to.not.exist;\n          testEach();\n        });\n      };\n\n      //\n      // Exercise each\n      // -------------------------------------------------\n      const testEach = function () {\n        let count = 0;\n        const cursor = db.collection('t1').aggregate();\n        cursor.match({\n          a: 1\n        });\n        cursor.forEach(() => {\n          count = count + 1;\n        }, err => {\n          expect(err).to.not.exist;\n          test.equal(3, count);\n          testStream();\n        });\n      };\n\n      //\n      // Exercise stream\n      // -------------------------------------------------\n      const testStream = function () {\n        const cursor = db.collection('t1').aggregate();\n        let count = 0;\n        cursor.match({\n          a: 1\n        });\n        const stream = cursor.stream();\n        stream.on('data', function () {\n          count = count + 1;\n        });\n        stream.once('end', function () {\n          test.equal(3, count);\n          testExplain();\n        });\n      };\n\n      //\n      // Explain method\n      // -------------------------------------------------\n      const testExplain = function () {\n        const cursor = db.collection('t1').aggregate();\n        cursor.explain(function (err, result) {\n          expect(err).to.not.exist;\n          test.ok(result != null);\n          client.close(done);\n        });\n      };\n      testAllMethods();\n    });\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute insert methods using crud api","suites":["CRUD API","when creating a cursor with find","#explain()"],"updatePoint":{"line":254,"column":60,"index":7486},"line":254,"code":"  it('should correctly execute insert methods using crud api', function (done) {\n    client.connect(function (err, client) {\n      const db = client.db();\n\n      //\n      // Legacy insert method\n      // -------------------------------------------------\n      const legacyInsert = function () {\n        db.collection('t2_1').insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }], function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedCount').to.equal(2);\n          bulkAPIInsert();\n        });\n      };\n\n      //\n      // Bulk api insert method\n      // -------------------------------------------------\n      const bulkAPIInsert = function () {\n        const bulk = db.collection('t2_2').initializeOrderedBulkOp();\n        bulk.insert({\n          a: 1\n        });\n        bulk.insert({\n          a: 1\n        });\n        bulk.execute(function (err) {\n          expect(err).to.not.exist;\n          insertOne();\n        });\n      };\n\n      //\n      // Insert one method\n      // -------------------------------------------------\n      const insertOne = function () {\n        db.collection('t2_3').insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedId').to.exist;\n          insertMany();\n        });\n      };\n\n      //\n      // Insert many method\n      // -------------------------------------------------\n      const insertMany = function () {\n        const docs = [{\n          a: 1\n        }, {\n          a: 1\n        }];\n        db.collection('t2_4').insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedCount').to.equal(2);\n\n          // Ordered bulk unordered\n          bulkWriteUnOrdered();\n        });\n      };\n\n      //\n      // Bulk write method unordered\n      // -------------------------------------------------\n      const bulkWriteUnOrdered = function () {\n        db.collection('t2_5').insertMany([{\n          c: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedCount').to.equal(1);\n          db.collection('t2_5').bulkWrite([{\n            insertOne: {\n              document: {\n                a: 1\n              }\n            }\n          }, {\n            insertOne: {\n              document: {\n                g: 1\n              }\n            }\n          }, {\n            insertOne: {\n              document: {\n                g: 2\n              }\n            }\n          }, {\n            updateOne: {\n              filter: {\n                a: 2\n              },\n              update: {\n                $set: {\n                  a: 2\n                }\n              },\n              upsert: true\n            }\n          }, {\n            updateMany: {\n              filter: {\n                a: 2\n              },\n              update: {\n                $set: {\n                  a: 2\n                }\n              },\n              upsert: true\n            }\n          }, {\n            deleteOne: {\n              filter: {\n                c: 1\n              }\n            }\n          }, {\n            deleteMany: {\n              filter: {\n                c: 1\n              }\n            }\n          }], {\n            ordered: false,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            test.equal(3, r.insertedCount);\n            test.equal(1, r.upsertedCount);\n            test.equal(1, r.deletedCount);\n\n            // Crud fields\n            test.equal(3, r.insertedCount);\n            test.equal(3, Object.keys(r.insertedIds).length);\n            test.equal(1, r.matchedCount);\n            test.equal(1, r.deletedCount);\n            test.equal(1, r.upsertedCount);\n            test.equal(1, Object.keys(r.upsertedIds).length);\n\n            // Ordered bulk operation\n            bulkWriteUnOrderedSpec();\n          });\n        });\n      };\n\n      //\n      // Bulk write method unordered\n      // -------------------------------------------------\n      const bulkWriteUnOrderedSpec = function () {\n        db.collection('t2_6').insertMany([{\n          c: 1\n        }, {\n          c: 2\n        }, {\n          c: 3\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedCount').to.equal(3);\n          db.collection('t2_6').bulkWrite([{\n            insertOne: {\n              document: {\n                a: 1\n              }\n            }\n          }, {\n            updateOne: {\n              filter: {\n                a: 2\n              },\n              update: {\n                $set: {\n                  a: 2\n                }\n              },\n              upsert: true\n            }\n          }, {\n            updateMany: {\n              filter: {\n                a: 3\n              },\n              update: {\n                $set: {\n                  a: 3\n                }\n              },\n              upsert: true\n            }\n          }, {\n            deleteOne: {\n              filter: {\n                c: 1\n              }\n            }\n          }, {\n            deleteMany: {\n              filter: {\n                c: 2\n              }\n            }\n          }, {\n            replaceOne: {\n              filter: {\n                c: 3\n              },\n              replacement: {\n                c: 4\n              },\n              upsert: true\n            }\n          }], {\n            ordered: false,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            test.equal(1, r.insertedCount);\n            test.equal(2, r.upsertedCount);\n            test.equal(2, r.deletedCount);\n\n            // Crud fields\n            test.equal(1, r.insertedCount);\n            test.equal(1, Object.keys(r.insertedIds).length);\n            test.equal(1, r.matchedCount);\n            test.equal(2, r.deletedCount);\n            test.equal(2, r.upsertedCount);\n            test.equal(2, Object.keys(r.upsertedIds).length);\n\n            // Ordered bulk operation\n            bulkWriteOrdered();\n          });\n        });\n      };\n\n      //\n      // Bulk write method ordered\n      // -------------------------------------------------\n      const bulkWriteOrdered = function () {\n        db.collection('t2_7').insertMany([{\n          c: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedCount').to.equal(1);\n          db.collection('t2_7').bulkWrite([{\n            insertOne: {\n              document: {\n                a: 1\n              }\n            }\n          }, {\n            insertOne: {\n              document: {\n                g: 1\n              }\n            }\n          }, {\n            insertOne: {\n              document: {\n                g: 2\n              }\n            }\n          }, {\n            updateOne: {\n              filter: {\n                a: 2\n              },\n              update: {\n                $set: {\n                  a: 2\n                }\n              },\n              upsert: true\n            }\n          }, {\n            updateMany: {\n              filter: {\n                a: 2\n              },\n              update: {\n                $set: {\n                  a: 2\n                }\n              },\n              upsert: true\n            }\n          }, {\n            deleteOne: {\n              filter: {\n                c: 1\n              }\n            }\n          }, {\n            deleteMany: {\n              filter: {\n                c: 1\n              }\n            }\n          }], {\n            ordered: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            test.equal(3, r.insertedCount);\n            test.equal(1, r.upsertedCount);\n            test.equal(1, r.deletedCount);\n\n            // Crud fields\n            test.equal(3, r.insertedCount);\n            test.equal(3, Object.keys(r.insertedIds).length);\n            test.equal(1, r.matchedCount);\n            test.equal(1, r.deletedCount);\n            test.equal(1, r.upsertedCount);\n            test.equal(1, Object.keys(r.upsertedIds).length);\n            bulkWriteOrderedCrudSpec();\n          });\n        });\n      };\n\n      //\n      // Bulk write method ordered\n      // -------------------------------------------------\n      const bulkWriteOrderedCrudSpec = function () {\n        db.collection('t2_8').insertMany([{\n          c: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedCount').to.equal(1);\n          db.collection('t2_8').bulkWrite([{\n            insertOne: {\n              document: {\n                a: 1\n              }\n            }\n          }, {\n            updateOne: {\n              filter: {\n                a: 2\n              },\n              update: {\n                $set: {\n                  a: 2\n                }\n              },\n              upsert: true\n            }\n          }, {\n            updateMany: {\n              filter: {\n                a: 2\n              },\n              update: {\n                $set: {\n                  a: 2\n                }\n              },\n              upsert: true\n            }\n          }, {\n            deleteOne: {\n              filter: {\n                c: 1\n              }\n            }\n          }, {\n            deleteMany: {\n              filter: {\n                c: 1\n              }\n            }\n          }, {\n            replaceOne: {\n              filter: {\n                c: 3\n              },\n              replacement: {\n                c: 4\n              },\n              upsert: true\n            }\n          }], {\n            ordered: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            // expect(err).to.not.exist;\n            test.equal(1, r.insertedCount);\n            test.equal(2, r.upsertedCount);\n            test.equal(1, r.deletedCount);\n\n            // Crud fields\n            test.equal(1, r.insertedCount);\n            test.equal(1, Object.keys(r.insertedIds).length);\n            test.equal(1, r.matchedCount);\n            test.equal(1, r.deletedCount);\n            test.equal(2, r.upsertedCount);\n            test.equal(2, Object.keys(r.upsertedIds).length);\n            client.close(done);\n          });\n        });\n      };\n      legacyInsert();\n    });\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute update methods using crud api","suites":["CRUD API","when creating a cursor with find","#explain()"],"updatePoint":{"line":695,"column":60,"index":18446},"line":695,"code":"  it('should correctly execute update methods using crud api', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      client.connect(function (err, client) {\n        const db = client.db();\n\n        //\n        // Legacy update method\n        // -------------------------------------------------\n        const legacyUpdate = function () {\n          db.collection('t3_1').update({\n            a: 1\n          }, {\n            $set: {\n              a: 2\n            }\n          }, {\n            upsert: true\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('upsertedCount').to.equal(1);\n            updateOne();\n          });\n        };\n\n        //\n        // Update one method\n        // -------------------------------------------------\n        const updateOne = function () {\n          db.collection('t3_2').insertMany([{\n            c: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(1);\n            db.collection('t3_2').updateOne({\n              a: 1\n            }, {\n              $set: {\n                a: 1\n              }\n            }, {\n              upsert: true\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              expect(r).property('upsertedCount').to.equal(1);\n              test.equal(0, r.matchedCount);\n              test.ok(r.upsertedId != null);\n              db.collection('t3_2').updateOne({\n                c: 1\n              }, {\n                $set: {\n                  a: 1\n                }\n              }, function (err, r) {\n                expect(err).to.not.exist;\n                expect(r).property('modifiedCount').to.equal(1);\n                test.equal(1, r.matchedCount);\n                test.ok(r.upsertedId == null);\n                replaceOne();\n              });\n            });\n          });\n        };\n\n        //\n        // Replace one method\n        // -------------------------------------------------\n        const replaceOne = function () {\n          db.collection('t3_3').replaceOne({\n            a: 1\n          }, {\n            a: 2\n          }, {\n            upsert: true\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('upsertedCount').to.equal(1);\n            test.equal(0, r.matchedCount);\n            test.ok(r.upsertedId != null);\n            db.collection('t3_3').replaceOne({\n              a: 2\n            }, {\n              a: 3\n            }, {\n              upsert: true\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              expect(r).property('modifiedCount').to.equal(1);\n              expect(r).property('upsertedCount').to.equal(0);\n              expect(r).property('matchedCount').to.equal(1);\n              updateMany();\n            });\n          });\n        };\n\n        //\n        // Update many method\n        // -------------------------------------------------\n        const updateMany = function () {\n          db.collection('t3_4').insertMany([{\n            a: 1\n          }, {\n            a: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(2);\n            db.collection('t3_4').updateMany({\n              a: 1\n            }, {\n              $set: {\n                a: 2\n              }\n            }, {\n              upsert: true,\n              writeConcern: {\n                w: 1\n              }\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              expect(r).property('modifiedCount').to.equal(2);\n              test.equal(2, r.matchedCount);\n              test.ok(r.upsertedId == null);\n              db.collection('t3_4').updateMany({\n                c: 1\n              }, {\n                $set: {\n                  d: 2\n                }\n              }, {\n                upsert: true,\n                writeConcern: {\n                  w: 1\n                }\n              }, function (err, r) {\n                expect(err).to.not.exist;\n                test.equal(0, r.matchedCount);\n                test.ok(r.upsertedId != null);\n                client.close(done);\n              });\n            });\n          });\n        };\n        legacyUpdate();\n      });\n    }\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute findAndModify methods using crud api","suites":["CRUD API","when creating a cursor with find","#explain()"],"updatePoint":{"line":855,"column":67,"index":23184},"line":855,"code":"  it('should correctly execute findAndModify methods using crud api', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      client.connect(function (err, client) {\n        const db = client.db();\n\n        //\n        // findOneAndRemove method\n        // -------------------------------------------------\n        const findOneAndRemove = function () {\n          db.collection('t5_1').insertMany([{\n            a: 1,\n            b: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(1);\n            db.collection('t5_1').findOneAndDelete({\n              a: 1\n            }, {\n              projection: {\n                b: 1\n              },\n              sort: {\n                a: 1\n              }\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              test.equal(1, r.lastErrorObject.n);\n              test.equal(1, r.value.b);\n              findOneAndReplace();\n            });\n          });\n        };\n\n        //\n        // findOneAndRemove method\n        // -------------------------------------------------\n        const findOneAndReplace = function () {\n          db.collection('t5_2').insertMany([{\n            a: 1,\n            b: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(1);\n            db.collection('t5_2').findOneAndReplace({\n              a: 1\n            }, {\n              c: 1,\n              b: 1\n            }, {\n              projection: {\n                b: 1,\n                c: 1\n              },\n              sort: {\n                a: 1\n              },\n              returnDocument: ReturnDocument.AFTER,\n              upsert: true\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              test.equal(1, r.lastErrorObject.n);\n              test.equal(1, r.value.b);\n              test.equal(1, r.value.c);\n              findOneAndUpdate();\n            });\n          });\n        };\n\n        //\n        // findOneAndRemove method\n        // -------------------------------------------------\n        const findOneAndUpdate = function () {\n          db.collection('t5_3').insertMany([{\n            a: 1,\n            b: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(1);\n            db.collection('t5_3').findOneAndUpdate({\n              a: 1\n            }, {\n              $set: {\n                d: 1\n              }\n            }, {\n              projection: {\n                b: 1,\n                d: 1\n              },\n              sort: {\n                a: 1\n              },\n              returnDocument: ReturnDocument.AFTER,\n              upsert: true\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              test.equal(1, r.lastErrorObject.n);\n              test.equal(1, r.value.b);\n              test.equal(1, r.value.d);\n              client.close(done);\n            });\n          });\n        };\n        findOneAndRemove();\n      });\n    }\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute removeMany with no selector","suites":["CRUD API","when creating a cursor with find","#explain()"],"updatePoint":{"line":981,"column":58,"index":26782},"line":981,"code":"  it('should correctly execute removeMany with no selector', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      client.connect(function (err, client) {\n        const db = client.db();\n        expect(err).to.not.exist;\n\n        // Delete all items with no selector\n        db.collection('t6_1').deleteMany({}, function (err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute crud operations with w:0","suites":["CRUD API","when creating a cursor with find","#explain()"],"updatePoint":{"line":1002,"column":55,"index":27453},"line":1002,"code":"  it('should correctly execute crud operations with w:0', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      client.connect(function (err, client) {\n        const db = client.db();\n        expect(err).to.not.exist;\n        const col = db.collection('shouldCorrectlyExecuteInsertOneWithW0');\n        col.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 0\n          }\n        }, function (err, result) {\n          expect(err).to.not.exist;\n          expect(result).property('acknowledged').to.be.false;\n          expect(result).property('insertedId').to.exist;\n          col.insertMany([{\n            a: 1\n          }], {\n            writeConcern: {\n              w: 0\n            }\n          }, function (err, result) {\n            expect(err).to.not.exist;\n            expect(result).to.exist;\n            col.updateOne({\n              a: 1\n            }, {\n              $set: {\n                b: 1\n              }\n            }, {\n              writeConcern: {\n                w: 0\n              }\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              expect(result).to.exist;\n              col.updateMany({\n                a: 1\n              }, {\n                $set: {\n                  b: 1\n                }\n              }, {\n                writeConcern: {\n                  w: 0\n                }\n              }, function (err, result) {\n                expect(err).to.not.exist;\n                expect(result).to.exist;\n                col.deleteOne({\n                  a: 1\n                }, {\n                  writeConcern: {\n                    w: 0\n                  }\n                }, function (err, result) {\n                  expect(err).to.not.exist;\n                  expect(result).to.exist;\n                  col.deleteMany({\n                    a: 1\n                  }, {\n                    writeConcern: {\n                      w: 0\n                    }\n                  }, function (err, result) {\n                    expect(err).to.not.exist;\n                    expect(result).to.exist;\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute updateOne operations with w:0 and upsert","suites":["CRUD API","when creating a cursor with find","#explain()"],"updatePoint":{"line":1088,"column":71,"index":29977},"line":1088,"code":"  it('should correctly execute updateOne operations with w:0 and upsert', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      client.connect(function (err, client) {\n        const db = client.db();\n        expect(err).to.not.exist;\n        db.collection('try').updateOne({\n          _id: 1\n        }, {\n          $set: {\n            x: 1\n          }\n        }, {\n          upsert: true,\n          writeConcern: {\n            w: 0\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          test.ok(r != null);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"should correctly execute crud operations using w:0","suites":["CRUD API","when creating a cursor with find","#explain()"],"updatePoint":{"line":1119,"column":56,"index":30812},"line":1119,"code":"  it('should correctly execute crud operations using w:0', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      client.connect(function (err, client) {\n        const db = client.db();\n        expect(err).to.not.exist;\n        const collection = db.collection('w0crudoperations');\n        collection.insertOne({}, function (err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n\n        // collection.insertOne({a:1});\n        // collection.insertMany([{b:1}]);\n        // collection.updateOne({c:1}, {$set:{a:1}}, {upsert:true});\n\n        // db.collection('try').updateOne({_id:1}, {$set:{x:1}}, {upsert:true, w:0}, function(err, r) {\n        //   expect(err).to.not.exist;\n        //   test.ok(r != null);\n\n        //   client.close();\n        //   done();\n        // });\n      });\n    }\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"should correctly throw error on illegal callback when unordered bulkWrite encounters error","suites":["CRUD API","when creating a cursor with find","#explain()"],"updatePoint":{"line":1152,"column":96,"index":31925},"line":1152,"code":"  it('should correctly throw error on illegal callback when unordered bulkWrite encounters error', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: async function () {\n      const ops = [];\n      // Create a set of operations that go over the 1000 limit causing two messages\n      let i = 0;\n      for (; i < 1005; i++) {\n        ops.push({\n          insertOne: {\n            _id: i,\n            a: i\n          }\n        });\n      }\n      ops.push({\n        insertOne: {\n          _id: 0,\n          a: i\n        }\n      });\n      const db = client.db();\n      const error = await db.collection('t20_1').bulkWrite(ops, {\n        ordered: false,\n        writeConcern: {\n          w: 1\n        }\n      }).catch(error => error);\n      expect(error).to.be.instanceOf(MongoError);\n    }\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"should correctly throw error on illegal callback when ordered bulkWrite encounters error","suites":["CRUD API","when creating a cursor with find","#explain()"],"updatePoint":{"line":1188,"column":94,"index":32936},"line":1188,"code":"  it('should correctly throw error on illegal callback when ordered bulkWrite encounters error', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      const ops = [];\n      // Create a set of operations that go over the 1000 limit causing two messages\n      let i = 0;\n      for (; i < 1005; i++) {\n        ops.push({\n          insertOne: {\n            _id: i,\n            a: i\n          }\n        });\n      }\n      ops.push({\n        insertOne: {\n          _id: 0,\n          a: i\n        }\n      });\n      client.connect(function (err, client) {\n        const db = client.db();\n        expect(err).to.not.exist;\n        db.collection('t20_1').bulkWrite(ops, {\n          ordered: true,\n          writeConcern: {\n            w: 1\n          }\n        }, function (err) {\n          test.ok(err !== null);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/crud_api.test.ts","skipped":false,"dir":"test"},{"name":"1. WriteConcernError.details exposes writeConcernError.errInfo","suites":["CRUD Prose Spec Tests"],"line":27,"code":"  it.skip('1. WriteConcernError.details exposes writeConcernError.errInfo', {","file":"integration/crud/crud.prose.test.js","skipped":true,"dir":"test"},{"name":"test case: insert MongoServerError","suites":["CRUD Prose Spec Tests","2. WriteError.details exposes writeErrors[].errInfo"],"updatePoint":{"line":97,"column":42,"index":3036},"line":97,"code":"    it('test case: insert MongoServerError', {\n      metadata: {\n        requires: {\n          mongodb: '>=5.0.0'\n        }\n      },\n      async test() {\n        const evCapture = once(client, 'commandSucceeded');\n        let errInfoFromError;\n        try {\n          await collection.insertOne({\n            x: /not a string/\n          });\n          expect.fail('The insert should fail the validation that x must be a string');\n        } catch (error) {\n          expect(error).to.be.instanceOf(MongoServerError);\n          expect(error).to.have.property('code', 121);\n          expect(error).to.have.property('errInfo').that.is.an('object');\n          errInfoFromError = error.errInfo;\n        }\n        const commandSucceededEvents = await evCapture;\n        expect(commandSucceededEvents).to.have.lengthOf(1);\n        const ev = commandSucceededEvents[0];\n        expect(ev).to.have.nested.property('reply.writeErrors[0].errInfo').that.is.an('object');\n        const errInfoFromEvent = ev.reply.writeErrors[0].errInfo;\n        expect(errInfoFromError).to.deep.equal(errInfoFromEvent);\n      }\n    });","file":"integration/crud/crud.prose.test.js","skipped":false,"dir":"test"},{"name":"test case: insertMany MongoBulkWriteError","suites":["CRUD Prose Spec Tests","2. WriteError.details exposes writeErrors[].errInfo"],"updatePoint":{"line":125,"column":49,"index":4148},"line":125,"code":"    it('test case: insertMany MongoBulkWriteError', {\n      metadata: {\n        requires: {\n          mongodb: '>=5.0.0'\n        }\n      },\n      async test() {\n        const evCapture = once(client, 'commandSucceeded');\n        let errInfoFromError;\n        try {\n          await collection.insertMany([{\n            x: /not a string/\n          }]);\n          expect.fail('The insert should fail the validation that x must be a string');\n        } catch (error) {\n          expect(error).to.be.instanceOf(MongoBulkWriteError);\n          expect(error).to.have.property('code', 121);\n          expect(error).to.have.property('writeErrors').that.is.an('array');\n          expect(error.writeErrors[0]).to.have.property('errInfo').that.is.an('object');\n          errInfoFromError = error.writeErrors[0].errInfo;\n        }\n        const commandSucceededEvents = await evCapture;\n        expect(commandSucceededEvents).to.have.lengthOf(1);\n        const ev = commandSucceededEvents[0];\n        expect(ev).to.have.nested.property('reply.writeErrors[0].errInfo').that.is.an('object');\n        const errInfoFromEvent = ev.reply.writeErrors[0].errInfo;\n        expect(errInfoFromError).to.deep.equal(errInfoFromEvent);\n      }\n    });","file":"integration/crud/crud.prose.test.js","skipped":false,"dir":"test"},{"name":"should allow bypassing document validation in 3.2 or higher on inserts","suites":["Document Validation"],"updatePoint":{"line":14,"column":76,"index":317},"line":14,"code":"  it('should allow bypassing document validation in 3.2 or higher on inserts', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>=3.1.7',\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n\n        // Get collection\n        var col = db.collection('createValidationCollection');\n\n        // Drop the collection\n        col.drop(function () {\n          // Create a collection with a validator\n          db.createCollection('createValidationCollection', {\n            validator: {\n              a: {\n                $exists: true\n              }\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n\n            // Ensure validation was correctly applied\n            col.insert({\n              b: 1\n            }, function (err) {\n              test.ok(err != null);\n\n              // Ensure validation was correctly applied\n              col.insert({\n                b: 1\n              }, {\n                bypassDocumentValidation: true\n              }, function (err) {\n                expect(err).to.not.exist;\n\n                // Bypass valiation on insert\n                col.insertOne({\n                  b: 1\n                }, {\n                  bypassDocumentValidation: true\n                }, function (err) {\n                  expect(err).to.not.exist;\n\n                  // Bypass valiation on insert\n                  col.insertMany([{\n                    b: 1\n                  }], {\n                    bypassDocumentValidation: true\n                  }, function (err) {\n                    expect(err).to.not.exist;\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/document_validation.test.js","skipped":false,"dir":"test"},{"name":"should allow bypassing document validation in 3.2 or higher on updates","suites":["Document Validation"],"updatePoint":{"line":86,"column":76,"index":2509},"line":86,"code":"  it('should allow bypassing document validation in 3.2 or higher on updates', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>=3.1.7',\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n\n        // Get collection\n        var col = db.collection('createValidationCollection');\n\n        // Drop the collection\n        col.drop(function () {\n          // Create a collection with a validator\n          db.createCollection('createValidationCollection', {\n            validator: {\n              a: {\n                $exists: true\n              }\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n\n            // Should fail\n            col.update({\n              b: 1\n            }, {\n              $set: {\n                b: 1\n              }\n            }, {\n              upsert: true\n            }, function (err) {\n              expect(err).to.exist;\n\n              // Ensure validation was correctly applied\n              col.update({\n                b: 1\n              }, {\n                $set: {\n                  b: 1\n                }\n              }, {\n                upsert: true,\n                bypassDocumentValidation: true\n              }, function (err) {\n                expect(err).to.not.exist;\n\n                // updateOne\n                col.updateOne({\n                  c: 1\n                }, {\n                  $set: {\n                    c: 1\n                  }\n                }, {\n                  upsert: true,\n                  bypassDocumentValidation: true\n                }, function (err) {\n                  expect(err).to.not.exist;\n\n                  // updateMany\n                  col.updateMany({\n                    d: 1\n                  }, {\n                    $set: {\n                      d: 1\n                    }\n                  }, {\n                    upsert: true,\n                    bypassDocumentValidation: true\n                  }, function (err) {\n                    expect(err).to.not.exist;\n\n                    // updateMany\n                    col.replaceOne({\n                      e: 1\n                    }, {\n                      e: 1\n                    }, {\n                      upsert: true,\n                      bypassDocumentValidation: true\n                    }, function (err) {\n                      expect(err).to.not.exist;\n                      client.close(done);\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/document_validation.test.js","skipped":false,"dir":"test"},{"name":"should allow bypassing document validation in 3.2 or higher on bulkWrite","suites":["Document Validation"],"updatePoint":{"line":191,"column":78,"index":5511},"line":191,"code":"  it('should allow bypassing document validation in 3.2 or higher on bulkWrite', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>=3.1.7',\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n\n        // Get collection\n        var col = db.collection('createValidationCollection');\n\n        // Drop the collection\n        col.drop(function () {\n          // Create a collection with a validator\n          db.createCollection('createValidationCollection', {\n            validator: {\n              a: {\n                $exists: true\n              }\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n\n            // Should fail\n            col.bulkWrite([{\n              insertOne: {\n                b: 1\n              }\n            }], function (err) {\n              test.ok(err != null);\n              col.bulkWrite([{\n                insertOne: {\n                  b: 1\n                }\n              }], {\n                bypassDocumentValidation: true\n              }, function (err) {\n                expect(err).to.not.exist;\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/document_validation.test.js","skipped":false,"dir":"test"},{"name":"should allow bypassing document validation in 3.2 or higher on findAndModify","suites":["Document Validation"],"updatePoint":{"line":247,"column":82,"index":7160},"line":247,"code":"  it('should allow bypassing document validation in 3.2 or higher on findAndModify', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>=3.1.7',\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n\n        // Get collection\n        var col = db.collection('createValidationCollection');\n\n        // Drop the collection\n        col.drop(function () {\n          // Create a collection with a validator\n          db.createCollection('createValidationCollection', {\n            validator: {\n              a: {\n                $exists: true\n              }\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n\n            // Should fail\n            col.findOneAndUpdate({\n              b: 1\n            }, {\n              $set: {\n                b: 1\n              }\n            }, {\n              upsert: true\n            }, function (err) {\n              test.ok(err != null);\n\n              // Should pass\n              col.findOneAndUpdate({\n                b: 1\n              }, {\n                $set: {\n                  b: 1\n                }\n              }, {\n                upsert: true,\n                bypassDocumentValidation: true\n              }, function (err) {\n                expect(err).to.not.exist;\n\n                // Should pass\n                col.findOneAndReplace({\n                  c: 1\n                }, {\n                  c: 1\n                }, {\n                  upsert: true,\n                  bypassDocumentValidation: true\n                }, function (err) {\n                  expect(err).to.not.exist;\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/document_validation.test.js","skipped":false,"dir":"test"},{"name":"should correctly bypass validation for aggregation using out","suites":["Document Validation"],"updatePoint":{"line":324,"column":66,"index":9316},"line":324,"code":"  it('should correctly bypass validation for aggregation using out', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>=3.1.7',\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        // Some docs for insertion\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }];\n\n        // Get collection\n        var col = db.collection('createValidationCollectionOut');\n\n        // Drop the collection\n        col.drop(function () {\n          // Create a collection with a validator\n          db.createCollection('createValidationCollectionOut', {\n            validator: {\n              a: {\n                $exists: true\n              }\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n\n            // Insert the docs\n            col.insertMany(docs, {\n              writeConcern: {\n                w: 1\n              },\n              bypassDocumentValidation: true\n            }, function (err) {\n              expect(err).to.not.exist;\n\n              // Execute aggregate, notice the pipeline is expressed as an Array\n              const cursor = col.aggregate([{\n                $project: {\n                  author: 1,\n                  tags: 1\n                }\n              }, {\n                $unwind: '$tags'\n              }, {\n                $group: {\n                  _id: {\n                    tags: '$tags'\n                  },\n                  authors: {\n                    $addToSet: '$author'\n                  }\n                }\n              }, {\n                $out: 'createValidationCollectionOut'\n              }], {\n                bypassDocumentValidation: true\n              });\n              cursor.toArray(function (err) {\n                expect(err).to.not.exist;\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/document_validation.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with delete one","suites":["Explain"],"updatePoint":{"line":22,"column":50,"index":502},"line":22,"code":"  it('should honor boolean explain with delete one', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorBooleanExplainWithDeleteOne');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.deleteOne({\n          a: 1\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with delete many","suites":["Explain"],"updatePoint":{"line":49,"column":51,"index":1216},"line":49,"code":"  it('should honor boolean explain with delete many', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorBooleanExplainWithDeleteMany');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.deleteMany({\n          a: 1\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with update one","suites":["Explain"],"updatePoint":{"line":76,"column":50,"index":1931},"line":76,"code":"  it('should honor boolean explain with update one', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorBooleanExplainWithUpdateOne');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.updateOne({\n          a: 1\n        }, {\n          $inc: {\n            a: 2\n          }\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with update many","suites":["Explain"],"updatePoint":{"line":107,"column":51,"index":2705},"line":107,"code":"  it('should honor boolean explain with update many', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorBooleanExplainWithUpdateMany');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.updateMany({\n          a: 1\n        }, {\n          $inc: {\n            a: 2\n          }\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).nested.property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with remove one","suites":["Explain"],"updatePoint":{"line":138,"column":50,"index":3487},"line":138,"code":"  it('should honor boolean explain with remove one', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorBooleanExplainWithRemoveOne');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.deleteOne({\n          a: 1\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with remove many","suites":["Explain"],"updatePoint":{"line":165,"column":51,"index":4201},"line":165,"code":"  it('should honor boolean explain with remove many', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorBooleanExplainWithRemoveMany');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.deleteMany({\n          a: 1\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with distinct","suites":["Explain"],"updatePoint":{"line":192,"column":48,"index":4914},"line":192,"code":"  it('should honor boolean explain with distinct', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.2'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorBooleanExplainWithDistinct');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.distinct('a', {}, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with findOneAndModify","suites":["Explain"],"updatePoint":{"line":217,"column":56,"index":5612},"line":217,"code":"  it('should honor boolean explain with findOneAndModify', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.2'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorBooleanExplainWithFindOneAndModify');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.findOneAndDelete({\n          a: 1\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should use allPlansExecution as true explain verbosity","suites":["Explain"],"updatePoint":{"line":244,"column":60,"index":6349},"line":244,"code":"  it('should use allPlansExecution as true explain verbosity', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldUseAllPlansExecutionAsTrueExplainVerbosity');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n\n        // Verify explanation result contains properties of allPlansExecution output\n        collection.deleteOne({\n          a: 1\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).nested.property('executionStats.allPlansExecution').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should use queryPlanner as false explain verbosity","suites":["Explain"],"updatePoint":{"line":274,"column":56,"index":7256},"line":274,"code":"  it('should use queryPlanner as false explain verbosity', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldUseQueryPlannerAsFalseExplainVerbosity');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n\n        // Verify explanation result contains properties of queryPlanner output\n        collection.deleteOne({\n          a: 1\n        }, {\n          explain: false\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).to.not.have.property('executionStats');\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor queryPlanner string explain","suites":["Explain"],"updatePoint":{"line":304,"column":46,"index":8123},"line":304,"code":"  it('should honor queryPlanner string explain', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorQueryPlannerStringExplain');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n\n        // Verify explanation result contains properties of queryPlanner output\n        collection.deleteOne({\n          a: 1\n        }, {\n          explain: 'queryPlanner'\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).to.not.have.property('executionStats');\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor executionStats string explain","suites":["Explain"],"updatePoint":{"line":334,"column":48,"index":8993},"line":334,"code":"  it('should honor executionStats string explain', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorExecutionStatsStringExplain');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n\n        // Verify explanation result contains properties of executionStats output\n        collection.deleteMany({\n          a: 1\n        }, {\n          explain: 'executionStats'\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).property('executionStats').to.exist;\n          expect(explanation.executionStats).to.not.have.property('allPlansExecution');\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor allPlansExecution string explain","suites":["Explain"],"updatePoint":{"line":365,"column":51,"index":9958},"line":365,"code":"  it('should honor allPlansExecution string explain', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorAllPlansStringExplain');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n\n        // Verify explanation result contains properties of allPlansExecution output\n        collection.deleteOne({\n          a: 1\n        }, {\n          explain: 'allPlansExecution'\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).nested.property('executionStats.allPlansExecution').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor string explain with distinct","suites":["Explain"],"updatePoint":{"line":395,"column":47,"index":10855},"line":395,"code":"  it('should honor string explain with distinct', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.2'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorStringExplainWithDistinct');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.distinct('a', {}, {\n          explain: 'executionStats'\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).property('executionStats').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor string explain with findOneAndModify","suites":["Explain"],"updatePoint":{"line":421,"column":55,"index":11630},"line":421,"code":"  it('should honor string explain with findOneAndModify', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.2'\n      }\n    },\n    test: function (done) {\n      var db = client.db('shouldHonorStringExplainWithFindOneAndModify');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.findOneAndReplace({\n          a: 1\n        }, {\n          a: 2\n        }, {\n          explain: 'queryPlanner'\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with find","suites":["Explain"],"updatePoint":{"line":450,"column":44,"index":12389},"line":450,"code":"  it('should honor boolean explain with find', async () => {\n    const db = client.db('shouldHonorBooleanExplainWithFind');\n    const collection = db.collection('test');\n    await collection.insertOne({\n      a: 1\n    });\n    const [explanation] = await collection.find({\n      a: 1\n    }, {\n      explain: true\n    }).toArray();\n    expect(explanation).to.exist;\n    expect(explanation).property('queryPlanner').to.exist;\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor string explain with find","suites":["Explain"],"updatePoint":{"line":464,"column":43,"index":12817},"line":464,"code":"  it('should honor string explain with find', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      const db = client.db('shouldHonorStringExplainWithFind');\n      const collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.find({\n          a: 1\n        }, {\n          explain: 'executionStats'\n        }).toArray((err, docs) => {\n          expect(err).to.not.exist;\n          const explanation = docs[0];\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).property('executionStats').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with findOne","suites":["Explain"],"updatePoint":{"line":493,"column":47,"index":13639},"line":493,"code":"  it('should honor boolean explain with findOne', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      const db = client.db('shouldHonorBooleanExplainWithFindOne');\n      const collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.findOne({\n          a: 1\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor string explain with findOne","suites":["Explain"],"updatePoint":{"line":520,"column":46,"index":14348},"line":520,"code":"  it('should honor string explain with findOne', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      const db = client.db('shouldHonorStringExplainWithFindOne');\n      const collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.findOne({\n          a: 1\n        }, {\n          explain: 'executionStats'\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).property('executionStats').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain specified on cursor with find","suites":["Explain"],"updatePoint":{"line":548,"column":64,"index":15153},"line":548,"code":"  it('should honor boolean explain specified on cursor with find', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      const db = client.db('shouldHonorBooleanExplainSpecifiedOnCursor');\n      const collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.find({\n          a: 1\n        }).explain(false, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor string explain specified on cursor with find","suites":["Explain"],"updatePoint":{"line":573,"column":63,"index":15860},"line":573,"code":"  it('should honor string explain specified on cursor with find', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: function (done) {\n      const db = client.db('shouldHonorStringExplainSpecifiedOnCursor');\n      const collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.find({\n          a: 1\n        }).explain('allPlansExecution', (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).property('executionStats').to.exist;\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor legacy explain with find","suites":["Explain"],"updatePoint":{"line":599,"column":43,"index":16627},"line":599,"code":"  it('should honor legacy explain with find', {\n    metadata: {\n      requires: {\n        mongodb: '<3.0'\n      }\n    },\n    test: function (done) {\n      const db = client.db('shouldHonorLegacyExplainWithFind');\n      const collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.find({\n          a: 1\n        }).explain((err, result) => {\n          expect(err).to.not.exist;\n          expect(result).to.have.property('allPlans');\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with aggregate","suites":["Explain"],"updatePoint":{"line":623,"column":49,"index":17247},"line":623,"code":"  it('should honor boolean explain with aggregate', async function () {\n    const db = client.db('shouldHonorBooleanExplainWithAggregate');\n    const collection = db.collection('test');\n    await collection.insertOne({\n      a: 1\n    });\n    const aggResult = await collection.aggregate([{\n      $project: {\n        a: 1\n      }\n    }, {\n      $group: {\n        _id: '$a'\n      }\n    }], {\n      explain: true\n    }).toArray();\n    if (aggResult[0].stages) {\n      expect(aggResult[0].stages).to.have.length.gte(1);\n      expect(aggResult[0].stages[0]).to.have.property('$cursor');\n      expect(aggResult[0].stages[0].$cursor).to.have.property('queryPlanner');\n      expect(aggResult[0].stages[0].$cursor).to.have.property('executionStats');\n    } else if (aggResult[0].$cursor) {\n      expect(aggResult[0].$cursor).to.have.property('queryPlanner');\n      expect(aggResult[0].$cursor).to.have.property('executionStats');\n    } else {\n      expect(aggResult[0]).to.have.property('queryPlanner');\n      expect(aggResult[0]).to.have.property('executionStats');\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor string explain with aggregate","suites":["Explain"],"updatePoint":{"line":653,"column":48,"index":18316},"line":653,"code":"  it('should honor string explain with aggregate', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.6.0'\n      }\n    },\n    test: async function () {\n      const db = client.db('shouldHonorStringExplainWithAggregate');\n      const collection = db.collection('test');\n      await collection.insertOne({\n        a: 1\n      });\n      const aggResult = await collection.aggregate([{\n        $project: {\n          a: 1\n        }\n      }, {\n        $group: {\n          _id: '$a'\n        }\n      }], {\n        explain: 'executionStats'\n      }).toArray();\n      if (aggResult[0].stages) {\n        expect(aggResult[0].stages).to.have.length.gte(1);\n        expect(aggResult[0].stages[0]).to.have.property('$cursor');\n        expect(aggResult[0].stages[0].$cursor).to.have.property('queryPlanner');\n        expect(aggResult[0].stages[0].$cursor).to.have.property('executionStats');\n      } else if (aggResult[0].$cursor) {\n        expect(aggResult[0].$cursor).to.have.property('queryPlanner');\n        expect(aggResult[0].$cursor).to.have.property('executionStats');\n      } else {\n        expect(aggResult[0]).to.have.property('queryPlanner');\n        expect(aggResult[0]).to.have.property('executionStats');\n      }\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain specified on cursor with aggregate","suites":["Explain"],"updatePoint":{"line":690,"column":69,"index":19567},"line":690,"code":"  it('should honor boolean explain specified on cursor with aggregate', async function () {\n    const db = client.db('shouldHonorBooleanExplainSpecifiedOnCursor');\n    const collection = db.collection('test');\n    await collection.insertOne({\n      a: 1\n    });\n    const aggResult = await collection.aggregate([{\n      $project: {\n        a: 1\n      }\n    }, {\n      $group: {\n        _id: '$a'\n      }\n    }]).explain(false);\n    if (aggResult && aggResult.stages) {\n      expect(aggResult.stages).to.have.length.gte(1);\n      expect(aggResult.stages[0]).to.have.property('$cursor');\n      expect(aggResult.stages[0].$cursor).to.have.property('queryPlanner');\n      expect(aggResult.stages[0].$cursor).to.not.have.property('executionStats');\n    } else if (aggResult.$cursor) {\n      expect(aggResult.$cursor).to.have.property('queryPlanner');\n      expect(aggResult.$cursor).to.not.have.property('executionStats');\n    } else {\n      expect(aggResult).to.have.property('queryPlanner');\n      expect(aggResult).to.not.have.property('executionStats');\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor string explain specified on cursor with aggregate","suites":["Explain"],"updatePoint":{"line":718,"column":68,"index":20631},"line":718,"code":"  it('should honor string explain specified on cursor with aggregate', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.6'\n      }\n    },\n    test: async function () {\n      const db = client.db('shouldHonorStringExplainSpecifiedOnCursor');\n      const collection = db.collection('test');\n      await collection.insertOne({\n        a: 1\n      });\n      const aggResult = await collection.aggregate([{\n        $project: {\n          a: 1\n        }\n      }, {\n        $group: {\n          _id: '$a'\n        }\n      }]).explain('allPlansExecution');\n      if (aggResult && aggResult.stages) {\n        expect(aggResult.stages).to.have.length.gte(1);\n        expect(aggResult.stages[0]).to.have.property('$cursor');\n        expect(aggResult.stages[0].$cursor).to.have.property('queryPlanner');\n        expect(aggResult.stages[0].$cursor).to.have.property('executionStats');\n      } else {\n        expect(aggResult).to.have.property('queryPlanner');\n        expect(aggResult).to.have.property('executionStats');\n      }\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor legacy explain with aggregate","suites":["Explain"],"updatePoint":{"line":750,"column":48,"index":21644},"line":750,"code":"  it('should honor legacy explain with aggregate', async function () {\n    const db = client.db('shouldHonorLegacyExplainWithAggregate');\n    const collection = db.collection('test');\n    await collection.insertOne({\n      a: 1\n    });\n    const aggResult = await collection.aggregate([{\n      $project: {\n        a: 1\n      }\n    }, {\n      $group: {\n        _id: '$a'\n      }\n    }]).explain();\n    if (aggResult && aggResult.stages) {\n      expect(aggResult.stages).to.have.length.gte(1);\n      expect(aggResult.stages[0]).to.have.property('$cursor');\n      expect(aggResult.stages[0].$cursor).to.have.property('queryPlanner');\n      expect(aggResult.stages[0].$cursor).to.have.property('executionStats');\n    } else {\n      expect(aggResult).to.have.property('queryPlanner');\n      expect(aggResult).to.have.property('executionStats');\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should throw a catchable error with invalid explain string","suites":["Explain"],"updatePoint":{"line":775,"column":64,"index":22512},"line":775,"code":"  it('should throw a catchable error with invalid explain string', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.4'\n      }\n    },\n    test: async function () {\n      const db = client.db('shouldThrowCatchableError');\n      const collection = db.collection('test');\n      try {\n        await collection.find({\n          a: 1\n        }).explain('invalidExplain');\n        expect.fail(new Error('Expected explain to fail but it succeeded'));\n      } catch (e) {\n        expect(e).to.exist;\n        expect(e).to.be.instanceOf(MongoServerError);\n      }\n    }\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndDelete operation and no options passed in","suites":["Find and Modify"],"updatePoint":{"line":21,"column":82,"index":429},"line":21,"code":"  it('Should correctly execute findOneAndDelete operation and no options passed in', function (done) {\n    var configuration = this.configuration;\n    var client = configuration.newClient(configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    client.connect().then(function (client) {\n      const db = client.db(configuration.db);\n      const col = db.collection('find_one_and_delete_with_promise_no_option');\n      col.insertMany([{\n        a: 1,\n        b: 1\n      }], {\n        writeConcern: {\n          w: 1\n        }\n      }).then(function (r) {\n        expect(r).property('insertedCount').to.equal(1);\n        col.findOneAndDelete({\n          a: 1\n        }).then(function (r) {\n          test.equal(1, r.lastErrorObject.n);\n          test.equal(1, r.value.b);\n          client.close(done);\n        }).catch(function (err) {\n          test.ok(err != null);\n        });\n      });\n    });\n  });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndUpate operation and no options passed in","suites":["Find and Modify"],"updatePoint":{"line":50,"column":81,"index":1340},"line":50,"code":"  it('Should correctly execute findOneAndUpate operation and no options passed in', function (done) {\n    var configuration = this.configuration;\n    var client = configuration.newClient(configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    client.connect().then(function (client) {\n      const db = client.db(configuration.db);\n      const col = db.collection('find_one_and_update_with_promise_no_option');\n      col.insertMany([{\n        a: 1,\n        b: 1\n      }], {\n        writeConcern: {\n          w: 1\n        }\n      }).then(function (r) {\n        expect(r).property('insertedCount').to.equal(1);\n        col.findOneAndUpdate({\n          a: 1\n        }, {\n          $set: {\n            a: 1\n          }\n        }).then(function (r) {\n          test.equal(1, r.lastErrorObject.n);\n          test.equal(1, r.value.b);\n          client.close(done);\n        }).catch(function (err) {\n          test.ok(err != null);\n        });\n      });\n    });\n  });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndReplace operation and no options passed in","suites":["Find and Modify"],"updatePoint":{"line":83,"column":83,"index":2313},"line":83,"code":"  it('Should correctly execute findOneAndReplace operation and no options passed in', function (done) {\n    var configuration = this.configuration;\n    var client = configuration.newClient(configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    client.connect().then(function (client) {\n      const db = client.db(configuration.db);\n      const col = db.collection('find_one_and_replace_with_promise_no_option');\n      col.insertMany([{\n        a: 1,\n        b: 1\n      }], {\n        writeConcern: {\n          w: 1\n        }\n      }).then(function (r) {\n        expect(r).property('insertedCount').to.equal(1);\n        col.findOneAndReplace({\n          a: 1\n        }, {\n          a: 1\n        }).then(function (r) {\n          test.equal(1, r.lastErrorObject.n);\n          test.equal(1, r.value.b);\n          client.close(done);\n        }).catch(function (err) {\n          test.ok(err != null);\n        });\n      });\n    });\n  });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"should pass through writeConcern to all findAndModify commands at command level","suites":["Find and Modify"],"updatePoint":{"line":114,"column":85,"index":3258},"line":114,"code":"  it('should pass through writeConcern to all findAndModify commands at command level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var started = [];\n      var succeeded = [];\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      client.on('commandStarted', function (event) {\n        if (event.commandName === 'findAndModify') started.push(event);\n      });\n      client.on('commandSucceeded', function (event) {\n        if (event.commandName === 'findAndModify') succeeded.push(event);\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        var collection = db.collection('findAndModifyTEST');\n        // Execute findOneAndUpdate\n        collection.findOneAndUpdate({}, {\n          $set: {\n            a: 1\n          }\n        }, {\n          writeConcern: {\n            fsync: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          test.deepEqual({\n            fsync: 1\n          }, started[0].command.writeConcern);\n\n          // Cleanup\n          started = [];\n          succeeded = [];\n\n          // Execute findOneAndReplace\n          collection.findOneAndReplace({}, {\n            b: 1\n          }, {\n            writeConcern: {\n              fsync: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n            test.deepEqual({\n              fsync: 1\n            }, started[0].command.writeConcern);\n\n            // Cleanup\n            started = [];\n            succeeded = [];\n\n            // Execute findOneAndReplace\n            collection.findOneAndDelete({}, {\n              writeConcern: {\n                fsync: 1\n              }\n            }, function (err) {\n              expect(err).to.not.exist;\n              test.deepEqual({\n                fsync: 1\n              }, started[0].command.writeConcern);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"should pass through writeConcern to all findAndModify at collection level","suites":["Find and Modify"],"updatePoint":{"line":193,"column":79,"index":5625},"line":193,"code":"  it('should pass through writeConcern to all findAndModify at collection level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var started = [];\n      var succeeded = [];\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      client.on('commandStarted', function (event) {\n        if (event.commandName === 'findAndModify') started.push(event);\n      });\n      client.on('commandSucceeded', function (event) {\n        if (event.commandName === 'findAndModify') succeeded.push(event);\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        var collection = db.collection('findAndModifyTEST', {\n          writeConcern: {\n            fsync: 1\n          }\n        });\n        // Execute findOneAndUpdate\n        collection.findOneAndUpdate({}, {\n          $set: {\n            a: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          test.deepEqual({\n            fsync: 1\n          }, started[0].command.writeConcern);\n\n          // Cleanup\n          started = [];\n          succeeded = [];\n\n          // Execute findOneAndReplace\n          collection.findOneAndReplace({}, {\n            b: 1\n          }, function (err) {\n            expect(err).to.not.exist;\n            test.deepEqual({\n              fsync: 1\n            }, started[0].command.writeConcern);\n\n            // Cleanup\n            started = [];\n            succeeded = [];\n\n            // Execute findOneAndReplace\n            collection.findOneAndDelete({}, function (err) {\n              expect(err).to.not.exist;\n              test.deepEqual({\n                fsync: 1\n              }, started[0].command.writeConcern);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"should pass through writeConcern to all findAndModify at db level","suites":["Find and Modify"],"updatePoint":{"line":264,"column":71,"index":7816},"line":264,"code":"  it('should pass through writeConcern to all findAndModify at db level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var started = [];\n      var succeeded = [];\n      var url = configuration.url();\n      url = url.indexOf('?') !== -1 ? f('%s&%s', url, 'fsync=true') : f('%s?%s', url, 'fsync=true');\n\n      // Establish connection to db\n      const client = configuration.newClient(url, {\n        sslValidate: false,\n        monitorCommands: true\n      });\n      client.on('commandStarted', function (event) {\n        if (event.commandName === 'findAndModify') started.push(event);\n      });\n      client.on('commandSucceeded', function (event) {\n        if (event.commandName === 'findAndModify') succeeded.push(event);\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(configuration.db);\n        var collection = db.collection('findAndModifyTEST');\n        // Execute findOneAndUpdate\n        collection.findOneAndUpdate({}, {\n          $set: {\n            a: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          test.deepEqual({\n            fsync: true\n          }, started[0].command.writeConcern);\n\n          // Cleanup\n          started = [];\n          succeeded = [];\n\n          // Execute findOneAndReplace\n          collection.findOneAndReplace({}, {\n            b: 1\n          }, function (err) {\n            expect(err).to.not.exist;\n            test.deepEqual({\n              fsync: true\n            }, started[0].command.writeConcern);\n\n            // Cleanup\n            started = [];\n            succeeded = [];\n\n            // Execute findOneAndReplace\n            collection.findOneAndDelete({}, function (err) {\n              expect(err).to.not.exist;\n              test.deepEqual({\n                fsync: true\n              }, started[0].command.writeConcern);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"should allow all findAndModify commands with non-primary readPreference","suites":["Find and Modify"],"updatePoint":{"line":335,"column":77,"index":10103},"line":335,"code":"  it('should allow all findAndModify commands with non-primary readPreference', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'replicaset'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient({\n        readPreference: 'secondary'\n      }, {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        const db = client.db(configuration.db);\n        const collection = db.collection('findAndModifyTEST');\n        // Execute findOneAndUpdate\n        collection.findOneAndUpdate({}, {\n          $set: {\n            a: 1\n          }\n        }, err => {\n          expect(err).to.not.exist;\n          client.close(true, done);\n        });\n      });\n    }\n  });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"should not allow atomic operators for findOneAndReplace","suites":["Find and Modify"],"updatePoint":{"line":366,"column":61,"index":11019},"line":366,"code":"  it('should not allow atomic operators for findOneAndReplace', async function () {\n    const client = this.configuration.newClient();\n    const db = client.db('fakeDb');\n    const collection = db.collection('test');\n    const error = await collection.findOneAndReplace({\n      a: 1\n    }, {\n      $set: {\n        a: 14\n      }\n    }).catch(error => error);\n    expect(error.message).to.match(/must not contain atomic operators/);\n    await client.close();\n  });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"sets the query to be the ObjectId instance","suites":["Find and Modify","when passed an ObjectId instance as the filter","findOneAndDelete(oid)"],"updatePoint":{"line":397,"column":52,"index":12037},"line":397,"code":"      it('sets the query to be the ObjectId instance', async () => {\n        const collection = client.db('test').collection('test');\n        const oid = new ObjectId();\n        const error = await collection.findOneAndDelete(oid).catch(error => error);\n        expect(error).to.be.instanceOf(MongoServerError);\n        expect(findAndModifyStarted).to.have.lengthOf(1);\n        expect(findAndModifyStarted[0]).to.have.property('query', oid);\n      });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"sets the query to be the ObjectId instance","suites":["Find and Modify","when passed an ObjectId instance as the filter","findOneAndReplace(oid)"],"updatePoint":{"line":407,"column":52,"index":12543},"line":407,"code":"      it('sets the query to be the ObjectId instance', async () => {\n        const collection = client.db('test').collection('test');\n        const oid = new ObjectId();\n        const error = await collection.findOneAndReplace(oid, {}).catch(error => error);\n        expect(error).to.be.instanceOf(MongoServerError);\n        expect(findAndModifyStarted).to.have.lengthOf(1);\n        expect(findAndModifyStarted[0]).to.have.property('query', oid);\n      });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"sets the query to be the ObjectId instance","suites":["Find and Modify","when passed an ObjectId instance as the filter","findOneAndUpdate(oid)"],"updatePoint":{"line":417,"column":52,"index":13053},"line":417,"code":"      it('sets the query to be the ObjectId instance', async () => {\n        const collection = client.db('test').collection('test');\n        const oid = new ObjectId();\n        const error = await collection.findOneAndUpdate(oid, {\n          $set: {\n            a: 1\n          }\n        }).catch(error => error);\n        expect(error).to.be.instanceOf(MongoServerError);\n        expect(findAndModifyStarted).to.have.lengthOf(1);\n        expect(findAndModifyStarted[0]).to.have.property('query', oid);\n      });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"should support a batch size","suites":["Find Cursor","#next"],"updatePoint":{"line":42,"column":35,"index":928},"line":42,"code":"    it('should support a batch size', function (done) {\n      const commands = [];\n      client.on('commandStarted', filterForCommands(['getMore'], commands));\n      const coll = client.db().collection('abstract_cursor');\n      const cursor = coll.find({}, {\n        batchSize: 2\n      });\n      this.defer(() => cursor.close());\n      cursor.toArray((err, docs) => {\n        expect(err).to.not.exist;\n        expect(docs).to.have.length(6);\n        expect(commands).to.have.length(3);\n        done();\n      });\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should remove buffered documents from subsequent cursor iterations","suites":["Find Cursor","#readBufferedDocuments"],"updatePoint":{"line":68,"column":74,"index":1772},"line":68,"code":"    it('should remove buffered documents from subsequent cursor iterations', async () => {\n      const [doc] = cursor.readBufferedDocuments(1);\n      expect(doc).to.have.property('a', 1);\n      const nextDoc = await cursor.next();\n      expect(nextDoc).to.have.property('a', 2);\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should return the amount of documents requested","suites":["Find Cursor","#readBufferedDocuments"],"updatePoint":{"line":74,"column":55,"index":2040},"line":74,"code":"    it('should return the amount of documents requested', async () => {\n      const buf1 = cursor.readBufferedDocuments(1);\n      expect(buf1).to.be.lengthOf(1);\n      const buf2 = cursor.readBufferedDocuments(3);\n      expect(buf2).to.be.lengthOf(3);\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should bound the request by the maximum amount of documents currently buffered","suites":["Find Cursor","#readBufferedDocuments"],"updatePoint":{"line":80,"column":86,"index":2331},"line":80,"code":"    it('should bound the request by the maximum amount of documents currently buffered', async () => {\n      const buf1 = cursor.readBufferedDocuments(1000);\n      expect(buf1).to.be.lengthOf(5);\n      const buf2 = cursor.readBufferedDocuments(23);\n      expect(buf2).to.be.lengthOf(0);\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should return all buffered documents when no argument is passed","suites":["Find Cursor","#readBufferedDocuments"],"updatePoint":{"line":86,"column":71,"index":2611},"line":86,"code":"    it('should return all buffered documents when no argument is passed', async () => {\n      const buf1 = cursor.readBufferedDocuments();\n      expect(buf1).to.be.lengthOf(5);\n      const buf2 = cursor.readBufferedDocuments();\n      expect(buf2).to.be.lengthOf(0);\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should return empty array for size zero or less","suites":["Find Cursor","#readBufferedDocuments"],"updatePoint":{"line":92,"column":55,"index":2869},"line":92,"code":"    it('should return empty array for size zero or less', async () => {\n      const buf1 = cursor.readBufferedDocuments(0);\n      expect(buf1).to.be.lengthOf(0);\n      const buf2 = cursor.readBufferedDocuments(-23);\n      expect(buf2).to.be.lengthOf(0);\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should return the same amount of documents reported by bufferedCount","suites":["Find Cursor","#readBufferedDocuments"],"updatePoint":{"line":98,"column":76,"index":3152},"line":98,"code":"    it('should return the same amount of documents reported by bufferedCount', async function () {\n      const doc = await cursor.next();\n      expect(doc).property('a', 1);\n      const bufferedCount = cursor.bufferedCount();\n      expect(bufferedCount).to.equal(4);\n\n      // Read the buffered Count\n      const bufferedDocs = cursor.readBufferedDocuments(bufferedCount);\n      expect(bufferedDocs.map(({\n        a\n      }) => a)).to.deep.equal([2, 3, 4, 5]);\n      const doc2 = await cursor.next();\n      expect(doc2).to.have.property('a', 6);\n      const doc3 = await cursor.next();\n      expect(doc3).to.be.null;\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"sends a killCursors command","suites":["Find Cursor","#close","when closed before completely iterated"],"updatePoint":{"line":134,"column":37,"index":4240},"line":134,"code":"      it('sends a killCursors command', async () => {\n        const killCursorsCommands = [];\n        client.on('commandStarted', filterForCommands(['killCursors'], killCursorsCommands));\n        const cursor = collection.find({}, {\n          batchSize: 2\n        });\n        const doc = await cursor.next();\n        expect(doc).property('a', 1);\n        expect(killCursorsCommands).to.have.length(0);\n        await cursor.close();\n        expect(killCursorsCommands).to.have.length(1);\n      });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"does not send a killCursors command","suites":["Find Cursor","#close","when closed after completely iterated"],"updatePoint":{"line":148,"column":45,"index":4814},"line":148,"code":"      it('does not send a killCursors command', async () => {\n        const killCursorsCommands = [];\n        client.on('commandStarted', filterForCommands(['killCursors'], killCursorsCommands));\n        const cursor = collection.find();\n        await cursor.toArray();\n        expect(killCursorsCommands).to.have.length(0);\n        await cursor.close();\n        expect(killCursorsCommands).to.have.length(0);\n      });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"does not send a killCursors command","suites":["Find Cursor","#close","when closed before initialization"],"updatePoint":{"line":159,"column":45,"index":5299},"line":159,"code":"      it('does not send a killCursors command', async () => {\n        const killCursorsCommands = [];\n        client.on('commandStarted', filterForCommands(['killCursors'], killCursorsCommands));\n        const cursor = collection.find();\n        expect(killCursorsCommands).to.have.length(0);\n        await cursor.close();\n        expect(killCursorsCommands).to.have.length(0);\n      });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should iterate each document in a cursor","suites":["Find Cursor","#forEach"],"updatePoint":{"line":170,"column":48,"index":5740},"line":170,"code":"    it('should iterate each document in a cursor', function (done) {\n      const coll = client.db().collection('abstract_cursor');\n      const cursor = coll.find({}, {\n        batchSize: 2\n      });\n      const bag = [];\n      cursor.forEach(doc => bag.push(doc), err => {\n        expect(err).to.not.exist;\n        expect(bag).to.have.lengthOf(6);\n        done();\n      });\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should return control to the user if an empty batch is returned","suites":["Find Cursor","#tryNext"],"updatePoint":{"line":184,"column":71,"index":6187},"line":184,"code":"    it('should return control to the user if an empty batch is returned', function (done) {\n      const db = client.db();\n      db.createCollection('try_next', {\n        capped: true,\n        size: 10000000\n      }, () => {\n        const coll = db.collection('try_next');\n        coll.insertMany([{}, {}], err => {\n          expect(err).to.not.exist;\n          const cursor = coll.find({}, {\n            tailable: true,\n            awaitData: true\n          });\n          this.defer(() => cursor.close());\n          cursor.tryNext((err, doc) => {\n            expect(err).to.not.exist;\n            expect(doc).to.exist;\n            cursor.tryNext((err, doc) => {\n              expect(err).to.not.exist;\n              expect(doc).to.exist;\n              cursor.tryNext((err, doc) => {\n                expect(err).to.not.exist;\n                expect(doc).to.be.null;\n                done();\n              });\n            });\n          });\n        });\n      });\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should clone a find cursor","suites":["Find Cursor","#clone"],"updatePoint":{"line":216,"column":34,"index":7157},"line":216,"code":"    it('should clone a find cursor', async function () {\n      const coll = client.db().collection('abstract_cursor');\n      const cursor = coll.find({});\n      const docsFromOriginal = await cursor.toArray();\n      expect(docsFromOriginal).to.have.length(6);\n      expect(cursor).property('closed').to.be.true;\n      const clonedCursor = cursor.clone();\n      const docsFromCloned = await clonedCursor.toArray();\n      expect(docsFromCloned).to.have.length(6);\n      expect(cursor).property('closed').to.be.true;\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should clone an aggregate cursor","suites":["Find Cursor","#clone"],"updatePoint":{"line":227,"column":40,"index":7685},"line":227,"code":"    it('should clone an aggregate cursor', async function () {\n      const coll = client.db().collection('abstract_cursor');\n      const cursor = coll.aggregate([{\n        $match: {}\n      }]);\n      const docsFromOriginal = await cursor.toArray();\n      expect(docsFromOriginal).to.have.length(6);\n      expect(cursor).property('closed').to.be.true;\n      const clonedCursor = cursor.clone();\n      const docsFromCloned = await clonedCursor.toArray();\n      expect(docsFromCloned).to.have.length(6);\n      expect(cursor).property('closed').to.be.true;\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should rewind a cursor","suites":["Find Cursor","#rewind"],"updatePoint":{"line":242,"column":30,"index":8277},"line":242,"code":"    it('should rewind a cursor', function (done) {\n      const coll = client.db().collection('abstract_cursor');\n      const cursor = coll.find({});\n      this.defer(() => cursor.close());\n      cursor.toArray((err, docs) => {\n        expect(err).to.not.exist;\n        expect(docs).to.have.length(6);\n        cursor.rewind();\n        cursor.toArray((err, docs) => {\n          expect(err).to.not.exist;\n          expect(docs).to.have.length(6);\n          done();\n        });\n      });\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should end an implicit session on rewind","suites":["Find Cursor","#rewind"],"updatePoint":{"line":257,"column":48,"index":8787},"line":257,"code":"    it('should end an implicit session on rewind', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.6'\n        }\n      },\n      test: function (done) {\n        const coll = client.db().collection('abstract_cursor');\n        const cursor = coll.find({}, {\n          batchSize: 1\n        });\n        this.defer(() => cursor.close());\n        cursor.next((err, doc) => {\n          expect(err).to.not.exist;\n          expect(doc).to.exist;\n          const session = cursor.session;\n          expect(session).property('hasEnded').to.be.false;\n          cursor.rewind();\n          expect(session).property('hasEnded').to.be.true;\n          done();\n        });\n      }\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should not end an explicit session on rewind","suites":["Find Cursor","#rewind"],"updatePoint":{"line":280,"column":52,"index":9476},"line":280,"code":"    it('should not end an explicit session on rewind', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.6'\n        }\n      },\n      test: function (done) {\n        const coll = client.db().collection('abstract_cursor');\n        const session = client.startSession();\n        const cursor = coll.find({}, {\n          batchSize: 1,\n          session\n        });\n        this.defer(() => cursor.close());\n        cursor.next((err, doc) => {\n          expect(err).to.not.exist;\n          expect(doc).to.exist;\n          const session = cursor.session;\n          expect(session).property('hasEnded').to.be.false;\n          cursor.rewind();\n          expect(session).property('hasEnded').to.be.false;\n          session.endSession(done);\n        });\n      }\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should set allowDiskUse to true by default","suites":["Find Cursor","#allowDiskUse"],"updatePoint":{"line":307,"column":50,"index":10295},"line":307,"code":"    it('should set allowDiskUse to true by default', {\n      metadata: {\n        requires: {\n          mongodb: '>=4.4'\n        }\n      },\n      test: function (done) {\n        const commands = [];\n        client.on('commandStarted', filterForCommands(['find'], commands));\n        const coll = client.db().collection('abstract_cursor');\n        const cursor = coll.find({}, {\n          sort: 'foo'\n        });\n        cursor.allowDiskUse();\n        this.defer(() => cursor.close());\n        cursor.toArray(err => {\n          expect(err).to.not.exist;\n          expect(commands).to.have.length(1);\n          expect(commands[0].command.allowDiskUse).to.equal(true);\n          done();\n        });\n      }\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should set allowDiskUse to false if specified","suites":["Find Cursor","#allowDiskUse"],"updatePoint":{"line":330,"column":53,"index":11009},"line":330,"code":"    it('should set allowDiskUse to false if specified', {\n      metadata: {\n        requires: {\n          mongodb: '>=4.4'\n        }\n      },\n      test: function (done) {\n        const commands = [];\n        client.on('commandStarted', filterForCommands(['find'], commands));\n        const coll = client.db().collection('abstract_cursor');\n        const cursor = coll.find({}, {\n          sort: 'foo'\n        });\n        cursor.allowDiskUse(false);\n        this.defer(() => cursor.close());\n        cursor.toArray(err => {\n          expect(err).to.not.exist;\n          expect(commands).to.have.length(1);\n          expect(commands[0].command.allowDiskUse).to.equal(false);\n          done();\n        });\n      }\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"throws if the query does not have sort specified","suites":["Find Cursor","#allowDiskUse"],"updatePoint":{"line":353,"column":56,"index":11732},"line":353,"code":"    it('throws if the query does not have sort specified', {\n      metadata: {\n        requires: {\n          mongodb: '>=4.4'\n        }\n      },\n      test: function (done) {\n        const coll = client.db().collection('abstract_cursor');\n        const cursor = coll.find({});\n        expect(() => cursor.allowDiskUse(false)).to.throw('Option \"allowDiskUse\" requires a sort specification');\n        done();\n      }\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformSimpleFind","suites":["Find"],"updatePoint":{"line":32,"column":38,"index":540},"line":32,"code":"  it('shouldCorrectlyPerformSimpleFind', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(configuration.db);\n        const collection = db.collection('test_find_simple');\n        const docs = [{\n          a: 2\n        }, {\n          b: 3\n        }];\n\n        // Insert some test documents\n        collection.insert(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n\n          // Ensure correct insertion testing via the cursor and the count function\n          collection.find().toArray(function (err, documents) {\n            expect(err).to.not.exist;\n            test.equal(2, documents.length);\n            collection.count(function (err, count) {\n              expect(err).to.not.exist;\n              test.equal(2, count);\n\n              // Fetch values by selection\n              collection.find({\n                a: docs[0].a\n              }).toArray(function (err, documents) {\n                expect(err).to.not.exist;\n                test.equal(1, documents.length);\n                test.equal(docs[0].a, documents[0].a);\n                // Let's close the db\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformSimpleChainedFind","suites":["Find"],"updatePoint":{"line":85,"column":45,"index":2189},"line":85,"code":"  it('shouldCorrectlyPerformSimpleChainedFind', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_simple_chained', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_find_simple_chained');\n          const docs = [{\n            a: 2\n          }, {\n            b: 3\n          }];\n\n          // Insert some test documents\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n\n            // Ensure correct insertion testing via the cursor and the count function\n            collection.find().toArray(function (err, documents) {\n              test.equal(2, documents.length);\n              collection.count(function (err, count) {\n                test.equal(2, count);\n\n                // Fetch values by selection\n                collection.find({\n                  a: docs[0].a\n                }).toArray(function (err, documents) {\n                  test.equal(1, documents.length);\n                  test.equal(docs[0].a, documents[0].a);\n                  // Let's close the db\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformAdvancedFinds","suites":["Find"],"updatePoint":{"line":137,"column":41,"index":3853},"line":137,"code":"  it('shouldCorrectlyPerformAdvancedFinds', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('test_find_advanced');\n        const docs = [{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          b: 3\n        }];\n\n        // Insert some test documents\n        collection.insert(docs, configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n\n          // Locate by less than\n          collection.find({\n            a: {\n              $lt: 10\n            }\n          }).toArray(function (err, documents) {\n            test.equal(2, documents.length);\n            // Check that the correct documents are returned\n            var results = [];\n            // Check that we have all the results we want\n            documents.forEach(function (doc) {\n              if (doc.a === 1 || doc.a === 2) results.push(1);\n            });\n            test.equal(2, results.length);\n\n            // Locate by greater than\n            collection.find({\n              a: {\n                $gt: 1\n              }\n            }).toArray(function (err, documents) {\n              test.equal(1, documents.length);\n              test.equal(2, documents[0].a);\n\n              // Locate by less than or equal to\n              collection.find({\n                a: {\n                  $lte: 1\n                }\n              }).toArray(function (err, documents) {\n                test.equal(1, documents.length);\n                test.equal(1, documents[0].a);\n\n                // Locate by greater than or equal to\n                collection.find({\n                  a: {\n                    $gte: 1\n                  }\n                }).toArray(function (err, documents) {\n                  test.equal(2, documents.length);\n                  // Check that the correct documents are returned\n                  var results = [];\n                  // Check that we have all the results we want\n                  documents.forEach(function (doc) {\n                    if (doc.a === 1 || doc.a === 2) results.push(1);\n                  });\n                  test.equal(2, results.length);\n\n                  // Locate by between\n                  collection.find({\n                    a: {\n                      $gt: 1,\n                      $lt: 3\n                    }\n                  }).toArray(function (err, documents) {\n                    test.equal(1, documents.length);\n                    test.equal(2, documents[0].a);\n\n                    // Locate in clause\n                    collection.find({\n                      a: {\n                        $in: [1, 2]\n                      }\n                    }).toArray(function (err, documents) {\n                      test.equal(2, documents.length);\n                      // Check that the correct documents are returned\n                      var results = [];\n                      // Check that we have all the results we want\n                      documents.forEach(function (doc) {\n                        if (doc.a === 1 || doc.a === 2) results.push(1);\n                      });\n                      test.equal(2, results.length);\n\n                      // Locate in _id clause\n                      collection.find({\n                        _id: {\n                          $in: [docs[0]['_id'], docs[1]['_id']]\n                        }\n                      }).toArray(function (err, documents) {\n                        test.equal(2, documents.length);\n                        // Check that the correct documents are returned\n                        var results = [];\n                        // Check that we have all the results we want\n                        documents.forEach(function (doc) {\n                          if (doc.a === 1 || doc.a === 2) results.push(1);\n                        });\n                        test.equal(2, results.length);\n                        // Let's close the db\n                        client.close(done);\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformFindWithSort","suites":["Find"],"updatePoint":{"line":267,"column":40,"index":8397},"line":267,"code":"  it('shouldCorrectlyPerformFindWithSort', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_sorting', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_find_sorting');\n          // Insert some test documents\n          collection.insert([{\n            a: 1,\n            b: 2\n          }, {\n            a: 2,\n            b: 1\n          }, {\n            a: 3,\n            b: 2\n          }, {\n            a: 4,\n            b: 1\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Test sorting (ascending)\n            collection.find({\n              a: {\n                $lt: 10\n              }\n            }, {\n              sort: [['a', 1]]\n            }).toArray(function (err, documents) {\n              test.equal(4, documents.length);\n              test.equal(1, documents[0].a);\n              test.equal(2, documents[1].a);\n              test.equal(3, documents[2].a);\n              test.equal(4, documents[3].a);\n\n              // Test sorting (descending)\n              collection.find({\n                a: {\n                  $lt: 10\n                }\n              }, {\n                sort: [['a', -1]]\n              }).toArray(function (err, documents) {\n                test.equal(4, documents.length);\n                test.equal(4, documents[0].a);\n                test.equal(3, documents[1].a);\n                test.equal(2, documents[2].a);\n                test.equal(1, documents[3].a);\n\n                // Test sorting (descending), sort is hash\n                collection.find({\n                  a: {\n                    $lt: 10\n                  }\n                }, {\n                  sort: {\n                    a: -1\n                  }\n                }).toArray(function (err, documents) {\n                  test.equal(4, documents.length);\n                  test.equal(4, documents[0].a);\n                  test.equal(3, documents[1].a);\n                  test.equal(2, documents[2].a);\n                  test.equal(1, documents[3].a);\n\n                  // Sorting using array of names, assumes ascending order\n                  collection.find({\n                    a: {\n                      $lt: 10\n                    }\n                  }, {\n                    sort: ['a']\n                  }).toArray(function (err, documents) {\n                    test.equal(4, documents.length);\n                    test.equal(1, documents[0].a);\n                    test.equal(2, documents[1].a);\n                    test.equal(3, documents[2].a);\n                    test.equal(4, documents[3].a);\n\n                    // Sorting using single name, assumes ascending order\n                    collection.find({\n                      a: {\n                        $lt: 10\n                      }\n                    }, {\n                      sort: 'a'\n                    }).toArray(function (err, documents) {\n                      test.equal(4, documents.length);\n                      test.equal(1, documents[0].a);\n                      test.equal(2, documents[1].a);\n                      test.equal(3, documents[2].a);\n                      test.equal(4, documents[3].a);\n\n                      // Sorting using single name, assumes ascending order, sort is hash\n                      collection.find({\n                        a: {\n                          $lt: 10\n                        }\n                      }, {\n                        sort: {\n                          a: 1\n                        }\n                      }).toArray(function (err, documents) {\n                        test.equal(4, documents.length);\n                        test.equal(1, documents[0].a);\n                        test.equal(2, documents[1].a);\n                        test.equal(3, documents[2].a);\n                        test.equal(4, documents[3].a);\n                        collection.find({\n                          a: {\n                            $lt: 10\n                          }\n                        }, {\n                          sort: ['b', 'a']\n                        }).toArray(function (err, documents) {\n                          test.equal(4, documents.length);\n                          test.equal(2, documents[0].a);\n                          test.equal(4, documents[1].a);\n                          test.equal(1, documents[2].a);\n                          test.equal(3, documents[3].a);\n\n                          // Sorting using empty array, no order guarantee should not blow up\n                          collection.find({\n                            a: {\n                              $lt: 10\n                            }\n                          }, {\n                            sort: []\n                          }).toArray(function (err, documents) {\n                            test.equal(4, documents.length);\n\n                            /* NONACTUAL */\n                            // Sorting using ordered hash\n                            collection.find({\n                              a: {\n                                $lt: 10\n                              }\n                            }, {\n                              sort: {\n                                a: -1\n                              }\n                            }).toArray(function (err, documents) {\n                              // Fail test if not an error\n                              test.equal(4, documents.length);\n                              // Let's close the db\n                              client.close(done);\n                            });\n                          });\n                        });\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformFindWithLimit","suites":["Find"],"updatePoint":{"line":442,"column":41,"index":14685},"line":442,"code":"  it('shouldCorrectlyPerformFindWithLimit', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_limits', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_find_limits');\n          // Insert some test documents\n          collection.insert([{\n            a: 1\n          }, {\n            b: 2\n          }, {\n            c: 3\n          }, {\n            d: 4\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Test limits\n            collection.find({}, {\n              limit: 1\n            }).toArray(function (err, documents) {\n              test.equal(1, documents.length);\n              collection.find({}, {\n                limit: 2\n              }).toArray(function (err, documents) {\n                test.equal(2, documents.length);\n                collection.find({}, {\n                  limit: 3\n                }).toArray(function (err, documents) {\n                  test.equal(3, documents.length);\n                  collection.find({}, {\n                    limit: 4\n                  }).toArray(function (err, documents) {\n                    test.equal(4, documents.length);\n                    collection.find({}, {}).toArray(function (err, documents) {\n                      test.equal(4, documents.length);\n                      collection.find({}, {\n                        limit: 99\n                      }).toArray(function (err, documents) {\n                        test.equal(4, documents.length);\n                        // Let's close the db\n                        client.close(done);\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyFindWithNonQuotedValues","suites":["Find"],"updatePoint":{"line":510,"column":44,"index":16947},"line":510,"code":"  it('shouldCorrectlyFindWithNonQuotedValues', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_non_quoted_values', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_find_non_quoted_values');\n          // insert test document\n          collection.insert([{\n            a: 19,\n            b: 'teststring',\n            c: 59920303\n          }, {\n            a: '19',\n            b: 'teststring',\n            c: 3984929\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.find({\n              a: 19\n            }).toArray(function (err, documents) {\n              test.equal(1, documents.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyFindEmbeddedDocument","suites":["Find"],"updatePoint":{"line":552,"column":41,"index":18248},"line":552,"code":"  it('shouldCorrectlyFindEmbeddedDocument', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_embedded_document', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_find_embedded_document');\n          // insert test document\n          collection.insert([{\n            a: {\n              id: 10,\n              value: 'foo'\n            },\n            b: 'bar',\n            c: {\n              id: 20,\n              value: 'foobar'\n            }\n          }, {\n            a: {\n              id: 11,\n              value: 'foo'\n            },\n            b: 'bar2',\n            c: {\n              id: 20,\n              value: 'foobar'\n            }\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // test using integer value\n            collection.find({\n              'a.id': 10\n            }).toArray(function (err, documents) {\n              test.equal(1, documents.length);\n              test.equal('bar', documents[0].b);\n\n              // test using string value\n              collection.find({\n                'a.value': 'foo'\n              }).toArray(function (err, documents) {\n                // should yield 2 documents\n                test.equal(2, documents.length);\n                test.equal('bar', documents[0].b);\n                test.equal('bar2', documents[1].b);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyFindNoRecords","suites":["Find"],"updatePoint":{"line":619,"column":34,"index":20189},"line":619,"code":"  it('shouldCorrectlyFindNoRecords', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_one_no_records', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_find_one_no_records');\n          expect(err).to.not.exist;\n          collection.find({\n            a: 1\n          }, {}).toArray(function (err, documents) {\n            test.equal(0, documents.length);\n            // Let's close the db\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformFindByWhere","suites":["Find"],"updatePoint":{"line":647,"column":39,"index":21116},"line":647,"code":"  it('shouldCorrectlyPerformFindByWhere', {\n    metadata: {\n      requires: {\n        mongodb: '<=4.2.x',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_where', function (err, collection) {\n          collection.insert([{\n            a: 1\n          }, {\n            a: 2\n          }, {\n            a: 3\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.count(function (err, count) {\n              expect(err).to.not.exist;\n              test.equal(3, count);\n\n              // Let's test usage of the $where statement\n              collection.find({\n                $where: new Code('this.a > 2')\n              }).count(function (err, count) {\n                expect(err).to.not.exist;\n                test.equal(1, count);\n                collection.find({\n                  $where: new Code('this.a > i', {\n                    i: 1\n                  })\n                }).count(function (err, count) {\n                  expect(err).to.not.exist;\n                  test.equal(2, count);\n\n                  // Let's close the db\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformFindsWithHintTurnedOn","suites":["Find"],"updatePoint":{"line":698,"column":49,"index":22731},"line":698,"code":"  it('shouldCorrectlyPerformFindsWithHintTurnedOn', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_hint', function (err, collection) {\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            db.createIndex(collection.collectionName, 'a', configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist;\n              collection.find({\n                a: 1\n              }, {\n                hint: 'a'\n              }).toArray(function (err) {\n                test.ok(err != null);\n                collection.find({\n                  a: 1\n                }, {\n                  hint: ['a']\n                }).toArray(function (err, items) {\n                  expect(err).to.not.exist;\n                  test.equal(1, items.length);\n                  collection.find({\n                    a: 1\n                  }, {\n                    hint: {\n                      a: 1\n                    }\n                  }).toArray(function (err, items) {\n                    test.equal(1, items.length);\n\n                    // Modify hints\n                    collection.hint = 'a_1';\n                    test.equal('a_1', collection.hint);\n                    collection.find({\n                      a: 1\n                    }).toArray(function (err, items) {\n                      test.equal(1, items.length);\n                      collection.hint = ['a'];\n                      test.equal(1, collection.hint['a']);\n                      collection.find({\n                        a: 1\n                      }).toArray(function (err, items) {\n                        test.equal(1, items.length);\n                        collection.hint = {\n                          a: 1\n                        };\n                        test.equal(1, collection.hint['a']);\n                        collection.find({\n                          a: 1\n                        }).toArray(function (err, items) {\n                          test.equal(1, items.length);\n                          collection.hint = null;\n                          test.ok(collection.hint == null);\n                          collection.find({\n                            a: 1\n                          }).toArray(function (err, items) {\n                            test.equal(1, items.length);\n                            // Let's close the db\n                            client.close(done);\n                          });\n                        });\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformFindByObjectId","suites":["Find"],"updatePoint":{"line":782,"column":42,"index":25824},"line":782,"code":"  it('shouldCorrectlyPerformFindByObjectId', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_by_oid', (err, collection) => {\n          collection.insertOne({\n            hello: 'mike'\n          }, configuration.writeConcernMax(), (err, r) => {\n            expect(err).to.not.exist;\n            expect(r).property('insertedId').to.exist;\n            collection.findOne({\n              _id: r.insertedId\n            }, (err, doc) => {\n              test.equal('mike', doc.hello);\n              var id = doc._id.toString();\n              collection.findOne({\n                _id: new ObjectId(id)\n              }, (err, doc) => {\n                test.equal('mike', doc.hello);\n                // Let's close the db\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyReturnDocumentWithOriginalStructure","suites":["Find"],"updatePoint":{"line":820,"column":56,"index":27098},"line":820,"code":"  it('shouldCorrectlyReturnDocumentWithOriginalStructure', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_by_oid_with_subdocs', function (err, collection) {\n          var c1 = {\n            _id: new ObjectId(),\n            comments: [],\n            title: 'number 1'\n          };\n          var c2 = {\n            _id: new ObjectId(),\n            comments: [],\n            title: 'number 2'\n          };\n          var doc = {\n            numbers: [],\n            owners: [],\n            comments: [c1, c2],\n            _id: new ObjectId()\n          };\n          collection.insert(doc, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.findOne({\n              _id: doc._id\n            }, {\n              writeConcern: {\n                w: 1\n              },\n              projection: undefined\n            }, function (err, doc) {\n              expect(err).to.not.exist;\n              test.equal(2, doc.comments.length);\n              test.equal('number 1', doc.comments[0].title);\n              test.equal('number 2', doc.comments[1].title);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveSingleRecord","suites":["Find"],"updatePoint":{"line":871,"column":41,"index":28686},"line":871,"code":"  it('shouldCorrectlyRetrieveSingleRecord', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var p_client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      p_client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_should_correctly_retrieve_one_record', function (err, collection) {\n          collection.insert({\n            a: 0\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            const usercollection = db.collection('test_should_correctly_retrieve_one_record');\n            usercollection.findOne({\n              a: 0\n            }, function (err) {\n              expect(err).to.not.exist;\n              p_client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleError","suites":["Find"],"updatePoint":{"line":901,"column":32,"index":29709},"line":901,"code":"  it('shouldCorrectlyHandleError', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_one_error_handling', function (err, collection) {\n          // Try to fetch an object using a totally invalid and wrong hex string... what we're interested in here\n          // is the error handling of the findOne Method\n          try {\n            collection.findOne({\n              _id: ObjectId.createFromHexString('5e9bd59248305adf18ebc15703a1')\n            }, function () {});\n          } catch (err) {\n            client.close(done);\n          }\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformFindWithOptions","suites":["Find"],"updatePoint":{"line":932,"column":43,"index":30740},"line":932,"code":"  it('shouldCorrectlyPerformFindWithOptions', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_field_select_with_options', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_field_select_with_options');\n          var docCount = 25,\n            docs = [];\n\n          // Insert some test documents\n          while (docCount--) docs.push({\n            a: docCount,\n            b: docCount\n          });\n          collection.insert(docs, configuration.writeConcernMax(), function (err, retDocs) {\n            docs = retDocs;\n            collection.find({}, {\n              limit: 3,\n              sort: [['a', -1]],\n              projection: {\n                a: 1\n              }\n            }).toArray(function (err, documents) {\n              test.equal(3, documents.length);\n              documents.forEach(function (doc, idx) {\n                expect(doc.b).to.not.exist; // making sure field select works\n                test.equal(24 - idx, doc.a); // checking limit sort object with field select\n              });\n\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyfindOneAndUpdateDocument","suites":["Find"],"updatePoint":{"line":982,"column":45,"index":32357},"line":982,"code":"  it('shouldCorrectlyfindOneAndUpdateDocument', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var db = client.db(configuration.db);\n      db.dropCollection('test_find_and_modify_a_document_1').catch(() => null).finally(() => {\n        db.createCollection('test_find_and_modify_a_document_1', function (err, collection) {\n          expect(err).to.not.exist;\n\n          // Test return new document on change\n          collection.insert({\n            a: 1,\n            b: 2\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Let's modify the document in place\n            collection.findOneAndUpdate({\n              a: 1\n            }, {\n              $set: {\n                b: 3\n              }\n            }, {\n              returnDocument: ReturnDocument.AFTER\n            }, function (err, updated_doc) {\n              expect(err).to.not.exist;\n              test.equal(1, updated_doc.value.a);\n              test.equal(3, updated_doc.value.b);\n\n              // Test return old document on change\n              collection.insert({\n                a: 2,\n                b: 2\n              }, configuration.writeConcernMax(), function (err) {\n                expect(err).to.not.exist;\n\n                // Let's modify the document in place\n                collection.findOneAndUpdate({\n                  a: 2\n                }, {\n                  $set: {\n                    b: 3\n                  }\n                }, configuration.writeConcernMax(), function (err, result) {\n                  expect(err).to.not.exist;\n                  test.equal(2, result.value.a);\n                  test.equal(2, result.value.b);\n\n                  // Test remove object on change\n                  collection.insert({\n                    a: 3,\n                    b: 2\n                  }, configuration.writeConcernMax(), function (err) {\n                    expect(err).to.not.exist;\n                    // Let's modify the document in place\n                    collection.findOneAndUpdate({\n                      a: 3\n                    }, {\n                      $set: {\n                        b: 3\n                      }\n                    }, {\n                      remove: true\n                    }, function (err, updated_doc) {\n                      expect(err).to.not.exist;\n                      test.equal(3, updated_doc.value.a);\n                      test.equal(2, updated_doc.value.b);\n\n                      // Let's upsert!\n                      collection.findOneAndUpdate({\n                        a: 4\n                      }, {\n                        $set: {\n                          b: 3\n                        }\n                      }, {\n                        returnDocument: ReturnDocument.AFTER,\n                        upsert: true\n                      }, function (err, updated_doc) {\n                        expect(err).to.not.exist;\n                        test.equal(4, updated_doc.value.a);\n                        test.equal(3, updated_doc.value.b);\n\n                        // Test selecting a subset of fields\n                        collection.insert({\n                          a: 100,\n                          b: 101\n                        }, configuration.writeConcernMax(), function (err, r) {\n                          expect(err).to.not.exist;\n                          collection.findOneAndUpdate({\n                            a: 100\n                          }, {\n                            $set: {\n                              b: 5\n                            }\n                          }, {\n                            returnDocument: ReturnDocument.AFTER,\n                            projection: {\n                              b: 1\n                            }\n                          }, function (err, updated_doc) {\n                            expect(err).to.not.exist;\n                            test.equal(2, Object.keys(updated_doc.value).length);\n                            test.equal(r.insertedIds[0].toHexString(), updated_doc.value._id.toHexString());\n                            test.equal(5, updated_doc.value.b);\n                            test.equal('undefined', typeof updated_doc.value.a);\n                            client.close(done);\n                          });\n                        });\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyfindOneAndUpdateDocumentAndReturnSelectedFieldsOnly","suites":["Find"],"updatePoint":{"line":1111,"column":72,"index":37128},"line":1111,"code":"  it('shouldCorrectlyfindOneAndUpdateDocumentAndReturnSelectedFieldsOnly', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_and_modify_a_document_2', function (err, collection) {\n          // Test return new document on change\n          collection.insert({\n            a: 1,\n            b: 2\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Let's modify the document in place\n            collection.findOneAndUpdate({\n              a: 1\n            }, {\n              $set: {\n                b: 3\n              }\n            }, {\n              returnDocument: ReturnDocument.AFTER,\n              projection: {\n                a: 1\n              }\n            }, function (err, updated_doc) {\n              test.equal(2, Object.keys(updated_doc.value).length);\n              test.equal(1, updated_doc.value.a);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"ShouldCorrectlyLocatePostAndIncValues","suites":["Find"],"updatePoint":{"line":1154,"column":43,"index":38476},"line":1154,"code":"  it('ShouldCorrectlyLocatePostAndIncValues', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var db = client.db(configuration.db);\n      db.createCollection('shouldCorrectlyExecuteFindOneWithAnInSearchTag', function (err, collection) {\n        // Test return new document on change\n        collection.insert({\n          title: 'Tobi',\n          author: 'Brian',\n          newTitle: 'Woot',\n          meta: {\n            visitors: 0\n          }\n        }, configuration.writeConcernMax(), function (err, r) {\n          // Fetch the id\n          var id = r.insertedIds[0];\n          collection.update({\n            _id: id\n          }, {\n            $inc: {\n              'meta.visitors': 1\n            }\n          }, configuration.writeConcernMax(), function (err, r) {\n            expect(r).property('matchedCount').to.equal(1);\n            expect(err).to.not.exist;\n            collection.findOne({\n              _id: id\n            }, function (err, item) {\n              test.equal(1, item.meta.visitors);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly Handle findOneAndUpdate Duplicate Key Error","suites":["Find"],"updatePoint":{"line":1199,"column":66,"index":39824},"line":1199,"code":"  it('Should Correctly Handle findOneAndUpdate Duplicate Key Error', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(configuration.db);\n        db.createCollection('findOneAndUpdateDuplicateKeyError', function (err, collection) {\n          expect(err).to.not.exist;\n          collection.createIndex(['name', 1], {\n            unique: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n            // Test return new document on change\n            collection.insert([{\n              name: 'test1'\n            }, {\n              name: 'test2'\n            }], configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist;\n              // Let's modify the document in place\n              collection.findOneAndUpdate({\n                name: 'test1'\n              }, {\n                $set: {\n                  name: 'test2'\n                }\n              }, {}, function (err, updated_doc) {\n                expect(err).to.exist;\n                expect(updated_doc).to.not.exist;\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly return null when attempting to modify a non-existing document","suites":["Find"],"updatePoint":{"line":1247,"column":84,"index":41427},"line":1247,"code":"  it('Should correctly return null when attempting to modify a non-existing document', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('AttemptTofindOneAndUpdateNonExistingDocument', function (err, collection) {\n          // Let's modify the document in place\n          collection.findOneAndUpdate({\n            name: 'test1'\n          }, {\n            $set: {\n              name: 'test2'\n            }\n          }, {}, function (err, updated_doc) {\n            expect(updated_doc.value).to.not.exist;\n            test.ok(err == null || err.errmsg.match('No matching object found'));\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly handle chained skip and limit on find with toArray","suites":["Find"],"updatePoint":{"line":1277,"column":73,"index":42471},"line":1277,"code":"  it('Should correctly handle chained skip and limit on find with toArray', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('skipAndLimitOnFindWithToArray', function (err, collection) {\n          collection.insert([{\n            a: 1\n          }, {\n            b: 2\n          }, {\n            c: 3\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.find().skip(1).limit(-1).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(1, items.length);\n              test.equal(2, items[0].b);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly handle chained skip and negative limit on find with toArray","suites":["Find"],"updatePoint":{"line":1310,"column":82,"index":43573},"line":1310,"code":"  it('Should correctly handle chained skip and negative limit on find with toArray', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('skipAndNegativeLimitOnFindWithToArray', function (err, collection) {\n          collection.insert([{\n            a: 1\n          }, {\n            b: 2\n          }, {\n            c: 3\n          }, {\n            d: 4\n          }, {\n            e: 5\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.find().skip(1).limit(-3).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(3, items.length);\n              test.equal(2, items[0].b);\n              test.equal(3, items[1].c);\n              test.equal(4, items[2].d);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"should support a timeout option for find operations","suites":["Find"],"updatePoint":{"line":1349,"column":57,"index":44804},"line":1349,"code":"  it('should support a timeout option for find operations', async function () {\n    const client = this.configuration.newClient({\n      monitorCommands: true\n    });\n    const events = [];\n    client.on('commandStarted', event => {\n      if (event.commandName === 'find') {\n        events.push(event);\n      }\n    });\n    const db = client.db(this.configuration.db);\n    const collection = await db.createCollection('cursor_timeout_false_0');\n    await collection.find({}, {\n      timeout: false\n    }).toArray();\n    expect(events[0]).nested.property('command.noCursorTimeout').to.equal(true);\n    await client.close();\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"should correctly findOneAndUpdate document with DB strict","suites":["Find"],"updatePoint":{"line":1367,"column":63,"index":45437},"line":1367,"code":"  it('should correctly findOneAndUpdate document with DB strict', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var p_client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      p_client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('shouldCorrectlyfindOneAndUpdateDocumentWithDBStrict', function (err, collection) {\n          // Test return old document on change\n          collection.insert({\n            a: 2,\n            b: 2\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Let's modify the document in place\n            collection.findOneAndUpdate({\n              a: 2\n            }, {\n              $set: {\n                b: 3\n              }\n            }, {\n              returnDocument: ReturnDocument.AFTER\n            }, function (err, result) {\n              test.equal(2, result.value.a);\n              test.equal(3, result.value.b);\n              p_client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyfindOneAndUpdateDocumentThatFailsInFirstStep","suites":["Find"],"updatePoint":{"line":1411,"column":65,"index":46820},"line":1411,"code":"  it('shouldCorrectlyfindOneAndUpdateDocumentThatFailsInFirstStep', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(configuration.db);\n        db.createCollection('shouldCorrectlyfindOneAndUpdateDocumentThatFailsInFirstStep', function (err, collection) {\n          expect(err).to.not.exist;\n          // Set up an index to force duplicate index erro\n          collection.createIndex([['failIndex', 1]], {\n            unique: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n\n            // Setup a new document\n            collection.insert({\n              a: 2,\n              b: 2,\n              failIndex: 2\n            }, configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist;\n\n              // Let's attempt to upsert with a duplicate key error\n              collection.findOneAndUpdate({\n                c: 2\n              }, {\n                $set: {\n                  a: 10,\n                  b: 10,\n                  failIndex: 2\n                }\n              }, {\n                writeConcern: {\n                  w: 1\n                },\n                upsert: true\n              }, function (err, result) {\n                expect(result).to.not.exist;\n                expect(err).property('errmsg').to.match(/duplicate key/);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly return new modified document","suites":["Find"],"updatePoint":{"line":1469,"column":51,"index":48662},"line":1469,"code":"  it('Should correctly return new modified document', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('Should_correctly_return_new_modified_document', function (err, collection) {\n          var id = new ObjectId();\n          var doc = {\n            _id: id,\n            a: 1,\n            b: 1,\n            c: {\n              a: 1,\n              b: 1\n            }\n          };\n          collection.insert(doc, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Find and modify returning the new object\n            collection.findOneAndUpdate({\n              _id: id\n            }, {\n              $set: {\n                'c.c': 100\n              }\n            }, {\n              returnDocument: ReturnDocument.AFTER\n            }, function (err, item) {\n              test.equal(doc._id.toString(), item.value._id.toString());\n              test.equal(doc.a, item.value.a);\n              test.equal(doc.b, item.value.b);\n              test.equal(doc.c.a, item.value.c.a);\n              test.equal(doc.c.b, item.value.c.b);\n              test.equal(100, item.value.c.c);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecutefindOneAndUpdate","suites":["Find"],"updatePoint":{"line":1523,"column":44,"index":50352},"line":1523,"code":"  it('shouldCorrectlyExecutefindOneAndUpdate', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('execute_find_and_modify', function (err, collection) {\n          var self = {\n            _id: new ObjectId()\n          };\n          var _uuid = 'sddffdss';\n          collection.findOneAndUpdate({\n            _id: self._id,\n            'plays.uuid': _uuid\n          }, {\n            $set: {\n              'plays.$.active': true\n            }\n          }, {\n            returnDocument: ReturnDocument.AFTER,\n            projection: {\n              plays: 0,\n              results: 0\n            },\n            safe: true\n          }, function (err) {\n            expect(err).to.not.exist;\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly return record with 64-bit id","suites":["Find"],"updatePoint":{"line":1563,"column":51,"index":51514},"line":1563,"code":"  it('Should correctly return record with 64-bit id', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('should_correctly_return_record_with_64bit_id', function (err, collection) {\n          var _lowerId = new ObjectId();\n          var _higherId = new ObjectId();\n          var lowerId = Long.fromString('133118461172916224', 10);\n          var higherId = Long.fromString('133118461172916225', 10);\n          var lowerDoc = {\n            _id: _lowerId,\n            id: lowerId\n          };\n          var higherDoc = {\n            _id: _higherId,\n            id: higherId\n          };\n          collection.insert([lowerDoc, higherDoc], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Select record with id of 133118461172916225 using $gt directive\n            collection.find({\n              id: {\n                $gt: lowerId\n              }\n            }, {}).toArray(function (err, arr) {\n              test.ok(err == null);\n              test.equal(arr.length, 1, 'Selecting record via $gt directive on 64-bit integer should return a record with higher Id');\n              test.equal(arr[0].id.toString(), '133118461172916225', 'Returned Id should be equal to 133118461172916225');\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly find a Document using findOne excluding _id field","suites":["Find"],"updatePoint":{"line":1608,"column":72,"index":53263},"line":1608,"code":"  it('Should Correctly find a Document using findOne excluding _id field', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var p_client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      p_client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('Should_Correctly_find_a_Document_using_findOne_excluding__id_field', function (err, collection) {\n          var doc = {\n            _id: new ObjectId(),\n            a: 1,\n            c: 2\n          };\n          // insert doc\n          collection.insert(doc, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Get one document, excluding the _id field\n            collection.findOne({\n              a: 1\n            }, {\n              projection: {\n                _id: 0\n              }\n            }, function (err, item) {\n              expect(item._id).to.not.exist;\n              test.equal(1, item.a);\n              test.equal(2, item.c);\n              collection.find({\n                a: 1\n              }, {\n                projection: {\n                  _id: 0\n                }\n              }).toArray(function (err, items) {\n                var item = items[0];\n                expect(item._id).to.not.exist;\n                test.equal(1, item.a);\n                test.equal(2, item.c);\n                p_client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute find queries with selector set to null","suites":["Find"],"updatePoint":{"line":1661,"column":69,"index":54952},"line":1661,"code":"  it('Should correctly execute find queries with selector set to null', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('Should_correctly_execute_find_and_findOne_queries_in_the_same_way', function (err, collection) {\n          var doc = {\n            _id: new ObjectId(),\n            a: 1,\n            c: 2,\n            comments: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n          };\n          // insert doc\n          collection.insert(doc, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.find({\n              _id: doc._id\n            }).project({\n              comments: {\n                $slice: -5\n              }\n            }).toArray(function (err, docs) {\n              test.equal(5, docs[0].comments.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandlerErrorForfindOneAndUpdateWhenNoRecordExists","suites":["Find"],"updatePoint":{"line":1699,"column":70,"index":56213},"line":1699,"code":"  it('shouldCorrectlyHandlerErrorForfindOneAndUpdateWhenNoRecordExists', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('shouldCorrectlyHandlerErrorForfindOneAndUpdateWhenNoRecordExists', function (err, collection) {\n          collection.findOneAndUpdate({\n            a: 1\n          }, {\n            $set: {\n              b: 3\n            }\n          }, {\n            returnDocument: ReturnDocument.AFTER\n          }, function (err, updated_doc) {\n            expect(err).to.not.exist;\n            expect(updated_doc.value).to.not.exist;\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecutefindOneAndUpdateShouldGenerateCorrectBSON","suites":["Find"],"updatePoint":{"line":1730,"column":69,"index":57223},"line":1730,"code":"  it('shouldCorrectlyExecutefindOneAndUpdateShouldGenerateCorrectBSON', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var db = client.db(configuration.db);\n      var transaction = {};\n      transaction.document = {};\n      transaction.document.type = 'documentType';\n      transaction.document.id = new ObjectId();\n      transaction.transactionId = new ObjectId();\n      transaction.amount = 12.3333;\n      var transactions = [];\n      transactions.push(transaction);\n      // Wrapping object\n      var wrapingObject = {\n        funds: {\n          remaining: 100.5\n        },\n        transactions: transactions\n      };\n      db.createCollection('find_and_modify_generate_correct_bson', function (err, collection) {\n        expect(err).to.not.exist;\n        collection.insert(wrapingObject, configuration.writeConcernMax(), function (err, r) {\n          expect(err).to.not.exist;\n          collection.findOne({\n            _id: r.insertedIds[0],\n            'funds.remaining': {\n              $gte: 3.0\n            },\n            'transactions.id': {\n              $ne: transaction.transactionId\n            }\n          }, function (err, item) {\n            test.ok(item != null);\n            collection.findOneAndUpdate({\n              _id: r.insertedIds[0],\n              'funds.remaining': {\n                $gte: 3.0\n              },\n              'transactions.id': {\n                $ne: transaction.transactionId\n              }\n            }, {\n              $push: {\n                transactions: transaction\n              }\n            }, {\n              returnDocument: ReturnDocument.AFTER,\n              safe: true\n            }, function (err) {\n              expect(err).to.not.exist;\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteMultipleFindsInParallel","suites":["Find"],"updatePoint":{"line":1792,"column":51,"index":59171},"line":1792,"code":"  it('shouldCorrectlyExecuteMultipleFindsInParallel', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var p_client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      p_client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('tasks', function (err, collection) {\n          var numberOfOperations = 0;\n\n          // Test return old document on change\n          collection.insert({\n            a: 2,\n            b: 2\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.find({\n              user_id: '4e9fc8d55883d90100000003',\n              lc_status: {\n                $ne: 'deleted'\n              },\n              owner_rating: {\n                $exists: false\n              }\n            }, {\n              skip: 0,\n              limit: 10,\n              sort: {\n                updated: -1\n              }\n            }).count(function (err) {\n              expect(err).to.not.exist;\n              numberOfOperations = numberOfOperations + 1;\n              if (numberOfOperations === 2) {\n                p_client.close(done);\n              }\n            });\n            collection.find({\n              user_id: '4e9fc8d55883d90100000003',\n              lc_status: {\n                $ne: 'deleted'\n              },\n              owner_rating: {\n                $exists: false\n              }\n            }, {\n              skip: 0,\n              limit: 10,\n              sort: {\n                updated: -1\n              }\n            }).count(function (err) {\n              expect(err).to.not.exist;\n              numberOfOperations = numberOfOperations + 1;\n              if (numberOfOperations === 2) {\n                p_client.close(done);\n              }\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyReturnErrorFromMongodbOnfindOneAndUpdateForcedError","suites":["Find"],"updatePoint":{"line":1861,"column":72,"index":61262},"line":1861,"code":"  it('shouldCorrectlyReturnErrorFromMongodbOnfindOneAndUpdateForcedError', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('shouldCorrectlyReturnErrorFromMongodbOnfindOneAndUpdateForcedError', function (err, collection) {\n          var q = {\n            x: 1\n          };\n          var set = {\n            y: 2,\n            _id: new ObjectId()\n          };\n          var opts = {\n            returnDocument: ReturnDocument.AFTER,\n            upsert: true\n          };\n          // Original doc\n          var doc = {\n            _id: new ObjectId(),\n            x: 1\n          };\n\n          // Insert original doc\n          collection.insert(doc, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.findOneAndUpdate(q, {\n              $set: set\n            }, opts, function /* err */\n            () {\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecutefindOneAndUpdateUnderConcurrentLoad","suites":["Find"],"updatePoint":{"line":1906,"column":63,"index":62602},"line":1906,"code":"  it('shouldCorrectlyExecutefindOneAndUpdateUnderConcurrentLoad', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var p_client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var running = true;\n      p_client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        // Create a collection\n        db.createCollection('collection1', function (err, collection) {\n          // Wait a bit and then execute something that will throw a duplicate error\n          setTimeout(function () {\n            var id = new ObjectId();\n            collection.insert({\n              _id: id,\n              a: 1\n            }, configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist;\n              collection.insert({\n                _id: id,\n                a: 1\n              }, configuration.writeConcernMax(), function (err) {\n                test.ok(err !== null);\n                running = false;\n                p_client.close(done);\n              });\n            });\n          }, 200);\n        });\n        db.createCollection('collection2', function (err, collection) {\n          // Keep hammering in inserts\n          var insert;\n          insert = function () {\n            process.nextTick(function () {\n              collection.insert({\n                a: 1\n              });\n              if (running) process.nextTick(insert);\n            });\n          };\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyIterateOverCollection","suites":["Find"],"line":1958,"code":"  it.skip('shouldCorrectlyIterateOverCollection', {","file":"integration/crud/find.test.js","skipped":true,"dir":"test"},{"name":"shouldCorrectlyErrorOutfindOneAndUpdateOnDuplicateRecord","suites":["Find"],"updatePoint":{"line":2008,"column":62,"index":65838},"line":2008,"code":"  it('shouldCorrectlyErrorOutfindOneAndUpdateOnDuplicateRecord', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var p_client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      p_client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        db.createCollection('shouldCorrectlyErrorOutfindOneAndUpdateOnDuplicateRecord', function (err, collection) {\n          expect(err).to.not.exist;\n\n          // Test return old document on change\n          collection.insert([{\n            login: 'user1'\n          }, {\n            login: 'user2'\n          }], configuration.writeConcernMax(), function (err, r) {\n            expect(err).to.not.exist;\n            var id = r.insertedIds[1];\n            // Set an index\n            collection.createIndex('login', {\n              unique: true,\n              writeConcern: {\n                w: 1\n              }\n            }, function (err) {\n              expect(err).to.not.exist;\n\n              // Attemp to modify document\n              collection.findOneAndUpdate({\n                _id: id\n              }, {\n                $set: {\n                  login: 'user1'\n                }\n              }, {}, function (err) {\n                test.ok(err !== null);\n                p_client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformSimpleFindInArray","suites":["Find"],"updatePoint":{"line":2063,"column":36,"index":67490},"line":2063,"code":"  it('shouldPerformSimpleFindInArray', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n\n        // Create a collection we want to drop later\n        db.createCollection('simple_find_in_array', function (err, collection) {\n          expect(err).to.not.exist;\n          var docs = [];\n          for (var i = 0; i < 100; i++) docs.push({\n            a: i\n          });\n\n          // Insert some test documentations\n          collection.insert(docs, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Find all the variables in a specific array\n            for (var i = 0; i < 100; i++) docs.push(i);\n\n            // Fin all in\n            collection.find({\n              a: {\n                $in: docs\n              }\n            }).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(100, items.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldReturnInstanceofErrorWithBadFieldSelection","suites":["Find"],"updatePoint":{"line":2107,"column":54,"index":68868},"line":2107,"code":"  it('shouldReturnInstanceofErrorWithBadFieldSelection', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        var col = db.collection('bad_field_selection');\n        col.insert([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          col.find({}, {\n            skip: 1,\n            limit: 1,\n            projection: {\n              a: 1,\n              b: 0\n            }\n          }).toArray(function (err) {\n            test.ok(err instanceof Error);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleLimitSkipFindWithFields","suites":["Find"],"updatePoint":{"line":2152,"column":49,"index":70023},"line":2152,"code":"  it('shouldPerformASimpleLimitSkipFindWithFields', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n\n        // Create a collection we want to drop later\n        db.createCollection('simple_find_with_fields', function (err, collection) {\n          expect(err).to.not.exist;\n\n          // Insert a bunch of documents for the testing\n          collection.insert([{\n            a: 1,\n            b: 1\n          }, {\n            a: 2,\n            b: 2\n          }, {\n            a: 3,\n            b: 3\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Perform a simple find and return all the documents\n            collection.find({\n              a: 2\n            }).project({\n              b: 1\n            }).toArray(function (err, docs) {\n              expect(err).to.not.exist;\n              test.equal(1, docs.length);\n              expect(docs[0].a).to.not.exist;\n              test.equal(2, docs[0].b);\n\n              // Perform a simple find and return all the documents\n              collection.find({\n                a: 2\n              }).project({\n                b: 1\n              }).toArray(function (err, docs) {\n                expect(err).to.not.exist;\n                test.equal(1, docs.length);\n                expect(docs[0].a).to.not.exist;\n                test.equal(2, docs[0].b);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleLimitSkipFindWithFields2","suites":["Find"],"updatePoint":{"line":2216,"column":50,"index":71928},"line":2216,"code":"  it('shouldPerformASimpleLimitSkipFindWithFields2', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n\n        // Create a collection we want to drop later\n        db.createCollection('simple_find_with_fields_2', function (err, collection) {\n          expect(err).to.not.exist;\n\n          // Insert a bunch of documents for the testing\n          collection.insert([{\n            a: 1,\n            b: 1\n          }, {\n            a: 2,\n            b: 2\n          }, {\n            a: 3,\n            b: 3\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Perform a simple find and return all the documents\n            collection.find({\n              a: 2\n            }).project({\n              b: 1\n            }).toArray(function (err, docs) {\n              expect(err).to.not.exist;\n              test.equal(1, docs.length);\n              expect(docs[0].a).to.not.exist;\n              test.equal(2, docs[0].b);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformQueryWithBatchSizeDifferentToStandard","suites":["Find"],"updatePoint":{"line":2268,"column":56,"index":73432},"line":2268,"code":"  it('shouldPerformQueryWithBatchSizeDifferentToStandard', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n\n        // Create a collection we want to drop later\n        db.createCollection('shouldPerformQueryWithBatchSizeDifferentToStandard', function (err, collection) {\n          expect(err).to.not.exist;\n          var docs = [];\n          for (var i = 0; i < 1000; i++) {\n            docs.push({\n              a: i\n            });\n          }\n\n          // Insert a bunch of documents for the testing\n          collection.insert(docs, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Perform a simple find and return all the documents\n            collection.find({}, {\n              batchSize: 1000\n            }).toArray(function (err, docs) {\n              expect(err).to.not.exist;\n              test.equal(1000, docs.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformNegativeLimit","suites":["Find"],"updatePoint":{"line":2313,"column":41,"index":74820},"line":2313,"code":"  it('shouldCorrectlyPerformNegativeLimit', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n\n        // Create a collection we want to drop later\n        const collection = db.collection('shouldCorrectlyPerformNegativeLimit');\n        var docs = [];\n        for (var i = 0; i < 1000; i++) {\n          docs.push({\n            a: 1,\n            b: 'helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld'\n          });\n        }\n\n        // Insert a bunch of documents\n        collection.insert(docs, configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n\n          // Perform a simple find and return all the documents\n          collection.find({}).limit(-10).toArray(function (err, docs) {\n            expect(err).to.not.exist;\n            test.equal(10, docs.length);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteExhaustQuery","suites":["Find"],"updatePoint":{"line":2355,"column":40,"index":76173},"line":2355,"code":"  it('shouldCorrectlyExecuteExhaustQuery', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n\n        // Create a collection we want to drop later\n        db.createCollection('shouldCorrectlyExecuteExhaustQuery', function (err, collection) {\n          expect(err).to.not.exist;\n          var docs1 = [];\n          for (var i = 0; i < 1000; i++) {\n            docs1.push({\n              a: 1,\n              b: 'helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld',\n              c: new Binary(Buffer.alloc(1024))\n            });\n          }\n\n          // Insert a bunch of documents\n          collection.insert(docs1, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            for (var i = 0; i < 1000; i++) {\n              var docs2 = [];\n              docs2.push({\n                a: 1,\n                b: 'helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld',\n                c: new Binary(Buffer.alloc(1024))\n              });\n            }\n            collection.insert(docs2, configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist;\n\n              // Perform a simple find and return all the documents\n              collection.find({}, {\n                exhaust: true\n              }).toArray(function (err, docs3) {\n                expect(err).to.not.exist;\n                test.equal(docs1.length + docs2.length, docs3.length);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Readpreferences should work fine when using a single server instance","suites":["Find"],"updatePoint":{"line":2409,"column":74,"index":78171},"line":2409,"code":"  it('Readpreferences should work fine when using a single server instance', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        var docs = [];\n        for (var i = 0; i < 1; i++) {\n          docs.push({\n            a: 1,\n            b: 'helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld'\n          });\n        }\n\n        // Create a collection we want to drop later\n        db.createCollection('Readpreferencesshouldworkfine', function (err, collection) {\n          // Insert a bunch of documents\n          collection.insert(docs, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            // Perform a simple find and return all the documents\n            collection.find({}, {\n              exhaust: true\n            }).toArray(function (err, docs2) {\n              expect(err).to.not.exist;\n              test.equal(docs.length, docs2.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Each should not hang on iterating over no results","suites":["Find"],"updatePoint":{"line":2449,"column":55,"index":79599},"line":2449,"code":"  it('Each should not hang on iterating over no results', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        // Create a collection we want to drop later\n        const collection = db.collection('noresultAvailableForEachToIterate');\n        // Perform a simple find and return all the documents\n        collection.find({}).forEach(doc => {\n          expect(doc).to.not.exist;\n        }, err => {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyFindDocumentsByRegExp","suites":["Find"],"updatePoint":{"line":2475,"column":42,"index":80484},"line":2475,"code":"  it('shouldCorrectlyFindDocumentsByRegExp', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        // Serialized regexes contain extra trailing chars. Sometimes these trailing chars contain / which makes\n        // the original regex invalid, and leads to segmentation fault.\n        db.createCollection('test_regex_serialization', function (err, collection) {\n          collection.insert({\n            keywords: ['test', 'segmentation', 'fault', 'regex', 'serialization', 'native']\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            let count = 0;\n            for (let i = 0; i <= 20; ++i) {\n              // search by regex\n              collection.findOne({\n                keywords: {\n                  $all: [/ser/, /test/, /seg/, /fault/, /nat/]\n                }\n              }, function (err, item) {\n                expect(err).to.not.exist;\n                expect(item).property('keywords').to.have.length(6);\n                if (count++ === 20) {\n                  client.close(done);\n                }\n              });\n            }\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDoFindMinMax","suites":["Find"],"updatePoint":{"line":2515,"column":33,"index":81957},"line":2515,"code":"  it('shouldCorrectlyDoFindMinMax', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        // Serialized regexes contain extra trailing chars. Sometimes these trailing chars contain / which makes\n        // the original regex invalid, and leads to segmentation fault.\n        db.createCollection('shouldCorrectlyDoFindMinMax', function (err, collection) {\n          collection.insert({\n            _id: 123,\n            name: 'some name',\n            min: 1,\n            max: 10\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.find({\n              _id: {\n                $in: ['some', 'value', 123]\n              }\n            }).project({\n              _id: 1,\n              max: 1\n            }).toArray(function (err, docs) {\n              expect(err).to.not.exist;\n              test.equal(10, docs[0].max);\n              collection.find({\n                _id: {\n                  $in: ['some', 'value', 123]\n                }\n              }, {\n                projection: {\n                  _id: 1,\n                  max: 1\n                }\n              }).toArray(function (err, docs) {\n                expect(err).to.not.exist;\n                test.equal(10, docs[0].max);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly sort using text search on 2.6 or higher in find","suites":["Find"],"updatePoint":{"line":2568,"column":70,"index":83736},"line":2568,"code":"  it('Should correctly sort using text search on 2.6 or higher in find', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.5.5',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n\n        // Get the collection\n        var collection = db.collection('textSearchWithSort');\n        collection.createIndex({\n          s: 'text'\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.insert([{\n            s: 'spam'\n          }, {\n            s: 'spam eggs and spam'\n          }, {\n            s: 'sausage and eggs'\n          }], function (err) {\n            expect(err).to.not.exist;\n            collection.find({\n              $text: {\n                $search: 'spam'\n              }\n            }, {\n              projection: {\n                _id: false,\n                s: true,\n                score: {\n                  $meta: 'textScore'\n                }\n              }\n            }).sort({\n              score: {\n                $meta: 'textScore'\n              }\n            }).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal('spam eggs and spam', items[0].s);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldNotMutateUserOptions","suites":["Find"],"updatePoint":{"line":2625,"column":32,"index":85408},"line":2625,"code":"  it('shouldNotMutateUserOptions', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('shouldNotMutateUserOptions');\n        var options = {\n          raw: 'TEST'\n        };\n        collection.find({}, options);\n        expect(options.skip).to.not.exist;\n        expect(options.limit).to.not.exist;\n        test.equal('TEST', options.raw);\n        client.close(done);\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute a findOneAndUpdateWithAWriteConcern","suites":["Find"],"updatePoint":{"line":2654,"column":66,"index":86314},"line":2654,"code":"  it('should correctly execute a findOneAndUpdateWithAWriteConcern', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_and_modify_a_document_3', function (err, collection) {\n          // Test return new document on change\n          collection.insert({\n            a: 1,\n            b: 2\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Let's modify the document in place\n            collection.findOneAndUpdate({\n              a: 1\n            }, {\n              $set: {\n                b: 3\n              }\n            }, {\n              returnDocument: ReturnDocument.AFTER\n            }, function (err, updated_doc) {\n              test.equal(1, updated_doc.value.a);\n              test.equal(3, updated_doc.value.b);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"should execute query using batchSize of 0","suites":["Find"],"updatePoint":{"line":2698,"column":47,"index":87619},"line":2698,"code":"  it('should execute query using batchSize of 0', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        const collection = db.collection('test_find_simple_batchsize_0');\n        // Insert some test documents\n        collection.insert([{\n          a: 2\n        }, {\n          b: 3\n        }, {\n          b: 4\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          // Ensure correct insertion testing via the cursor and the count function\n          collection.find().batchSize(-5).toArray(function (err, documents) {\n            expect(err).to.not.exist;\n            test.equal(3, documents.length);\n            // Let's close the db\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"should execute query using limit of 0","suites":["Find"],"updatePoint":{"line":2736,"column":43,"index":88782},"line":2736,"code":"  it('should execute query using limit of 0', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        const collection = db.collection('test_find_simple_limit_0');\n\n        // Insert some test documents\n        collection.insert([{\n          a: 2\n        }, {\n          b: 3\n        }, {\n          b: 4\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          // Ensure correct insertion testing via the cursor and the count function\n          collection.find().limit(-5).toArray(function (err, documents) {\n            expect(err).to.not.exist;\n            test.equal(3, documents.length);\n\n            // Let's close the db\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"should execute query using $elemMatch","suites":["Find"],"updatePoint":{"line":2776,"column":43,"index":89939},"line":2776,"code":"  it('should execute query using $elemMatch', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        const collection = db.collection('elem_match_test');\n        // Insert some test documents\n        collection.insert([{\n          _id: 1,\n          results: [82, 85, 88]\n        }, {\n          _id: 2,\n          results: [75, 88, 89]\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n\n          // Ensure correct insertion testing via the cursor and the count function\n          collection.find({\n            results: {\n              $elemMatch: {\n                $gte: 80,\n                $lt: 85\n              }\n            }\n          }).toArray(function (err, documents) {\n            expect(err).to.not.exist;\n            test.deepEqual([{\n              _id: 1,\n              results: [82, 85, 88]\n            }], documents);\n\n            // Let's close the db\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"should execute query using limit of 101","suites":["Find"],"updatePoint":{"line":2826,"column":45,"index":91336},"line":2826,"code":"  it('should execute query using limit of 101', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        const collection = db.collection('test_find_simple_limit_101');\n        function clone(obj) {\n          var o = {};\n          for (var name in obj) o[name] = obj[name];\n          return o;\n        }\n        var template = {\n          linkid: '12633170',\n          advertisercid: '4612127',\n          websitename: 'Car Rental 8',\n          destinationurl: 'https://www.carrental8.com/en/',\n          who: '8027061-12633170-1467924618000',\n          href: 'http://www.tkqlhce.com',\n          src: 'http://www.awltovhc.com',\n          r1: 3,\n          r2: 44,\n          r3: 24,\n          r4: 58\n        };\n        var docs = [];\n        for (var i = 0; i < 1000; i++) {\n          docs.push(clone(template));\n        }\n\n        // Insert some test documents\n        collection.insertMany(docs, configuration.writeConcernMax(), function (err, r) {\n          expect(err).to.not.exist;\n          test.ok(r);\n\n          // Ensure correct insertion testing via the cursor and the count function\n          collection.find().limit(200).toArray(function (err, documents) {\n            expect(err).to.not.exist;\n            test.equal(200, documents.length);\n            // Let's close the db\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply db level options to find cursor","suites":["Find"],"updatePoint":{"line":2883,"column":60,"index":93115},"line":2883,"code":"  it('Should correctly apply db level options to find cursor', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient({}, {\n        ignoreUndefined: true\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('test_find_simple_cursor_inheritance');\n\n        // Insert some test documents\n        collection.insert([{\n          a: 2\n        }, {\n          b: 3,\n          c: undefined\n        }], function (err) {\n          expect(err).to.not.exist;\n          // Ensure correct insertion testing via the cursor and the count function\n          var cursor = collection.find({\n            c: undefined\n          });\n          cursor.toArray(function (err, documents) {\n            test.equal(2, documents.length);\n            // Let's close the db\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"should respect client-level read preference","suites":["Find"],"updatePoint":{"line":2919,"column":49,"index":94159},"line":2919,"code":"  it('should respect client-level read preference', {\n    metadata: {\n      requires: {\n        topology: ['replicaset']\n      }\n    },\n    test: function (done) {\n      const config = this.configuration;\n      const client = config.newClient({}, {\n        monitorCommands: true,\n        readPreference: 'secondary'\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        let selectedServer;\n        const topology = client.topology;\n        const selectServerStub = sinon.stub(topology, 'selectServer').callsFake(function () {\n          const args = Array.prototype.slice.call(arguments);\n          const originalCallback = args.pop();\n          args.push((err, server) => {\n            selectedServer = server;\n            originalCallback(err, server);\n          });\n          return topology.selectServer.wrappedMethod.apply(this, args);\n        });\n        const collection = client.db().collection('test_read_preference');\n        collection.find().toArray(err => {\n          expect(err).to.not.exist;\n          expect(selectedServer.description.type).to.eql('RSSecondary');\n          client.close(err => {\n            selectServerStub.restore();\n            done(err);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"wraps the objectId in a document with _id as the only key","suites":["Find","when passed an ObjectId instance as the filter","find(oid)"],"updatePoint":{"line":2973,"column":67,"index":95948},"line":2973,"code":"      it('wraps the objectId in a document with _id as the only key', async () => {\n        const collection = client.db('test').collection('test');\n        const oid = new ObjectId();\n        await collection.find(oid).toArray();\n        expect(findsStarted).to.have.lengthOf(1);\n        expect(findsStarted[0]).to.have.nested.property('filter._id', oid);\n        expect(findsStarted[0].filter).to.have.all.keys('_id');\n      });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"wraps the objectId in a document with _id as the only key","suites":["Find","when passed an ObjectId instance as the filter","findOne(oid)"],"updatePoint":{"line":2983,"column":67,"index":96423},"line":2983,"code":"      it('wraps the objectId in a document with _id as the only key', async () => {\n        const collection = client.db('test').collection('test');\n        const oid = new ObjectId();\n        await collection.findOne(oid);\n        expect(findsStarted).to.have.lengthOf(1);\n        expect(findsStarted[0]).to.have.nested.property('filter._id', oid);\n        expect(findsStarted[0].filter).to.have.all.keys('_id');\n      });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute Collection.prototype.insertOne","suites":["crud - insert"],"updatePoint":{"line":67,"column":61,"index":1768},"line":67,"code":"  it('Should correctly execute Collection.prototype.insertOne', function (done) {\n    const configuration = this.configuration;\n    let url = configuration.url();\n    url = url.indexOf('?') !== -1 ? f('%s&%s', url, 'maxPoolSize=100') : f('%s?%s', url, 'maxPoolSize=100');\n    const client = configuration.newClient(url);\n    client.connect().then(function (client) {\n      const db = client.db(configuration.db);\n      db.collection('insertOne').insertOne({\n        a: 1\n      }).then(function (r) {\n        expect(r).property('insertedId').to.exist;\n        client.close(done);\n      });\n    });\n  });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"rejects when insertMany is passed a non array object","suites":["crud - insert"],"updatePoint":{"line":82,"column":58,"index":2368},"line":82,"code":"  it('rejects when insertMany is passed a non array object', async function () {\n    const db = client.db();\n    const error = await db.collection('insertMany_Promise_error').insertMany({\n      a: 1\n    }).catch(error => error);\n    expect(error).to.be.instanceOf(MongoInvalidArgumentError);\n    expect(error.message).to.match(/must be an array/);\n  });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformSingleInsert","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":94,"column":42,"index":2835},"line":94,"code":"    it('shouldCorrectlyPerformSingleInsert', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyPerformSingleInsert');\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.findOne(function (err, item) {\n              test.equal(1, item.a);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"insertMany returns the insertedIds and we can look up the documents","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":122,"column":75,"index":3894},"line":122,"code":"    it('insertMany returns the insertedIds and we can look up the documents', async function () {\n      const db = client.db();\n      const collection = db.collection('test_multiple_insert');\n      const docs = [{\n        a: 1\n      }, {\n        a: 2\n      }];\n      const r = await collection.insertMany(docs);\n      expect(r).property('insertedCount').to.equal(2);\n      expect(r.insertedIds[0]).to.have.property('_bsontype', 'ObjectId');\n      expect(r.insertedIds[1]).to.have.property('_bsontype', 'ObjectId');\n      const foundDocs = await collection.find().toArray();\n      expect(foundDocs).to.have.lengthOf(2);\n      expect(foundDocs).to.have.nested.property('[0].a', 1);\n      expect(foundDocs).to.have.nested.property('[1].a', 2);\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertAndRetrieveLargeIntegratedArrayDocument","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":139,"column":68,"index":4636},"line":139,"code":"    it('shouldCorrectlyInsertAndRetrieveLargeIntegratedArrayDocument', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_should_deserialize_large_integrated_array');\n          var doc = {\n            a: 0,\n            b: ['tmp1', 'tmp2', 'tmp3', 'tmp4', 'tmp5', 'tmp6', 'tmp7', 'tmp8', 'tmp9', 'tmp10', 'tmp11', 'tmp12', 'tmp13', 'tmp14', 'tmp15', 'tmp16']\n          };\n          // Insert the collection\n          collection.insert(doc, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            // Fetch and check the collection\n            collection.findOne({\n              a: 0\n            }, function (err, result) {\n              test.deepEqual(doc.a, result.a);\n              test.deepEqual(doc.b, result.b);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertAndRetrieveDocumentWithAllTypes","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":174,"column":60,"index":6045},"line":174,"code":"    it('shouldCorrectlyInsertAndRetrieveDocumentWithAllTypes', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_all_serialization_types');\n          var date = new Date();\n          var oid = new ObjectId();\n          var string = 'binstring';\n          var bin = new Binary();\n          for (var index = 0; index < string.length; index++) {\n            bin.put(string.charAt(index));\n          }\n          var motherOfAllDocuments = {\n            string: 'hello',\n            array: [1, 2, 3],\n            hash: {\n              a: 1,\n              b: 2\n            },\n            date: date,\n            oid: oid,\n            binary: bin,\n            int: 42,\n            float: 33.3333,\n            regexp: /regexp/,\n            boolean: true,\n            long: date.getTime(),\n            where: new Code('this.a > i', {\n              i: 1\n            }),\n            dbref: new DBRef('namespace', oid, 'integration_tests_')\n          };\n          collection.insert(motherOfAllDocuments, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.findOne(function (err, doc) {\n              // Assert correct deserialization of the values\n              test.equal(motherOfAllDocuments.string, doc.string);\n              test.deepEqual(motherOfAllDocuments.array, doc.array);\n              test.equal(motherOfAllDocuments.hash.a, doc.hash.a);\n              test.equal(motherOfAllDocuments.hash.b, doc.hash.b);\n              test.equal(date.getTime(), doc.long);\n              test.equal(date.toString(), doc.date.toString());\n              test.equal(date.getTime(), doc.date.getTime());\n              test.equal(motherOfAllDocuments.oid.toHexString(), doc.oid.toHexString());\n              test.equal(motherOfAllDocuments.binary.value(), doc.binary.value());\n              test.equal(motherOfAllDocuments.int, doc.int);\n              test.equal(motherOfAllDocuments.long, doc.long);\n              test.equal(motherOfAllDocuments.float, doc.float);\n              test.equal(motherOfAllDocuments.regexp.toString(), doc.regexp.toString());\n              test.equal(motherOfAllDocuments.boolean, doc.boolean);\n              test.equal(motherOfAllDocuments.where.code, doc.where.code);\n              test.equal(motherOfAllDocuments.where.scope['i'], doc.where.scope.i);\n              test.equal(motherOfAllDocuments.dbref.namespace, doc.dbref.namespace);\n              test.equal(motherOfAllDocuments.dbref.oid.toHexString(), doc.dbref.oid.toHexString());\n              test.equal(motherOfAllDocuments.dbref.db, doc.dbref.db);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertAndUpdateDocumentWithNewScriptContext","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":246,"column":66,"index":9288},"line":246,"code":"    it('shouldCorrectlyInsertAndUpdateDocumentWithNewScriptContext', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n\n          //convience curried handler for functions of type 'a -> (err, result)\n          function getResult(callback) {\n            return function (error, result) {\n              test.ok(error == null);\n              return callback(result);\n            };\n          }\n          db.createCollection('users', getResult(function (user_collection) {\n            user_collection.deleteMany({}, configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist;\n\n              //first, create a user object\n              var newUser = {\n                name: 'Test Account',\n                settings: {}\n              };\n              user_collection.insert([newUser], configuration.writeConcernMax(), getResult(function () {\n                var scriptCode = \"settings.block = []; settings.block.push('test');\";\n                var context = {\n                  settings: {\n                    thisOneWorks: 'somestring'\n                  }\n                };\n                Script.runInNewContext(scriptCode, context, 'testScript');\n\n                //now create update command and issue it\n                var updateCommand = {\n                  $set: context\n                };\n                user_collection.update({\n                  _id: newUser._id\n                }, updateCommand, configuration.writeConcernMax(), getResult(function () {\n                  // Fetch the object and check that the changes are persisted\n                  user_collection.findOne({\n                    _id: newUser._id\n                  }, function (err, doc) {\n                    test.ok(err == null);\n                    test.equal('Test Account', doc.name);\n                    test.equal('somestring', doc.settings.thisOneWorks);\n                    test.equal('test', doc.settings.block[0]);\n                    client.close(done);\n                  });\n                }));\n              }));\n            });\n          }));\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlySerializeDocumentWithAllTypesInNewContext","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":311,"column":64,"index":11895},"line":311,"code":"    it('shouldCorrectlySerializeDocumentWithAllTypesInNewContext', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_all_serialization_types_new_context');\n          var date = new Date();\n          var scriptCode = \"var string = 'binstring'\\n\" + 'var bin = new mongo.Binary()\\n' + 'for(var index = 0; index < string.length; index++) {\\n' + '  bin.put(string.charAt(index))\\n' + '}\\n' + \"motherOfAllDocuments['string'] = 'hello';\" + \"motherOfAllDocuments['array'] = [1,2,3];\" + \"motherOfAllDocuments['hash'] = {'a':1, 'b':2};\" + \"motherOfAllDocuments['date'] = date;\" + \"motherOfAllDocuments['oid'] = new mongo.ObjectId();\" + \"motherOfAllDocuments['binary'] = bin;\" + \"motherOfAllDocuments['int'] = 42;\" + \"motherOfAllDocuments['float'] = 33.3333;\" + \"motherOfAllDocuments['regexp'] = /regexp/;\" + \"motherOfAllDocuments['boolean'] = true;\" + \"motherOfAllDocuments['long'] = motherOfAllDocuments['date'].getTime();\" + \"motherOfAllDocuments['where'] = new mongo.Code('this.a > i', {i:1});\" + \"motherOfAllDocuments['dbref'] = new mongo.DBRef('namespace', motherOfAllDocuments['oid'], 'integration_tests_');\";\n          var context = {\n            motherOfAllDocuments: {},\n            mongo: {\n              ObjectId: ObjectId,\n              Binary: Binary,\n              Code: Code,\n              DBRef: DBRef\n            },\n            date: date\n          };\n\n          // Execute function in context\n          Script.runInNewContext(scriptCode, context, 'testScript');\n          // sys.puts(sys.inspect(context.motherOfAllDocuments))\n          var motherOfAllDocuments = context.motherOfAllDocuments;\n          collection.insert(context.motherOfAllDocuments, configuration.writeConcernMax(), function (err, docs) {\n            test.ok(docs);\n            collection.findOne(function (err, doc) {\n              // Assert correct deserialization of the values\n              test.equal(motherOfAllDocuments.string, doc.string);\n              test.deepEqual(motherOfAllDocuments.array, doc.array);\n              test.equal(motherOfAllDocuments.hash.a, doc.hash.a);\n              test.equal(motherOfAllDocuments.hash.b, doc.hash.b);\n              test.equal(date.getTime(), doc.long);\n              test.equal(date.toString(), doc.date.toString());\n              test.equal(date.getTime(), doc.date.getTime());\n              test.equal(motherOfAllDocuments.oid.toHexString(), doc.oid.toHexString());\n              test.equal(motherOfAllDocuments.binary.value(), doc.binary.value());\n              test.equal(motherOfAllDocuments.int, doc.int);\n              test.equal(motherOfAllDocuments.long, doc.long);\n              test.equal(motherOfAllDocuments.float, doc.float);\n              test.equal(motherOfAllDocuments.regexp.toString(), doc.regexp.toString());\n              test.equal(motherOfAllDocuments.boolean, doc.boolean);\n              test.equal(motherOfAllDocuments.where.code, doc.where.code);\n              test.equal(motherOfAllDocuments.where.scope['i'], doc.where.scope.i);\n              test.equal(motherOfAllDocuments.dbref.namespace, doc.dbref.namespace);\n              test.equal(motherOfAllDocuments.dbref.oid.toHexString(), doc.dbref.oid.toHexString());\n              test.equal(motherOfAllDocuments.dbref.db, doc.dbref.db);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDoToJsonForLongValue","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":373,"column":43,"index":15774},"line":373,"code":"    it('shouldCorrectlyDoToJsonForLongValue', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: async function () {\n        const configuration = this.configuration;\n        const client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        await client.connect();\n        const db = client.db(configuration.db);\n        const collection = db.collection('test_to_json_for_long');\n        await collection.insert([{\n          value: Long.fromNumber(32222432)\n        }], configuration.writeConcernMax());\n        const findResult = await collection.findOne({});\n        expect(findResult.value).to.deep.equal(32222432);\n        await client.close();\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldInsertAndQueryTimestamp","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":397,"column":37,"index":16726},"line":397,"code":"    it('shouldInsertAndQueryTimestamp', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: async function () {\n        const configuration = this.configuration;\n        const client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        await client.connect();\n        const db = client.db(configuration.db);\n        const collection = db.collection('test_insert_and_query_timestamp');\n        await collection.insertOne({\n          i: Timestamp.fromNumber(100),\n          j: Long.fromNumber(200)\n        }, configuration.writeConcernMax());\n        const findResult = await collection.findOne({});\n        expect(findResult.i._bsontype).equals('Timestamp');\n        expect(findResult.i.toInt(), 100);\n        expect(findResult.j, 200);\n        await client.close();\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertAndQueryUndefined","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":424,"column":46,"index":17809},"line":424,"code":"    it('shouldCorrectlyInsertAndQueryUndefined', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_insert_and_query_undefined');\n\n          // Insert the update\n          collection.insert({\n            i: undefined\n          }, configuration.writeConcernMax(), function (err, r) {\n            expect(err).to.not.exist;\n            test.ok(r);\n\n            // Locate document\n            collection.findOne({}, function (err, item) {\n              expect(item.i).to.not.exist;\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlySerializeDBRefToJSON","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":457,"column":43,"index":18942},"line":457,"code":"    it('shouldCorrectlySerializeDBRefToJSON', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var dbref = new DBRef('foo', ObjectId.createFromHexString('fc24a04d4560531f00000000'), null);\n        JSON.stringify(dbref);\n        done();\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertDocumentWithUUID","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":471,"column":45,"index":19464},"line":471,"code":"    it('shouldCorrectlyInsertDocumentWithUUID', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('insert_doc_with_uuid');\n          collection.insert({\n            _id: '12345678123456781234567812345678',\n            field: '1'\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.find({\n              _id: '12345678123456781234567812345678'\n            }).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(items[0]._id, '12345678123456781234567812345678');\n              test.equal(items[0].field, '1');\n\n              // Generate a binary id\n              var binaryUUID = new Binary(Buffer.from('00000078123456781234567812345678', 'hex'), Binary.SUBTYPE_UUID);\n\n              // UUID must be 16 bytes\n              expect(binaryUUID.buffer).to.have.property('byteLength', 16);\n              collection.insert({\n                _id: binaryUUID,\n                field: '2'\n              }, configuration.writeConcernMax(), function (err, result) {\n                expect(err).to.not.exist;\n                test.ok(result);\n                collection.find({\n                  _id: binaryUUID\n                }).toArray(function (err, items) {\n                  expect(err).to.not.exist;\n                  test.equal(items[0].field, '2');\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCallCallbackWithDbDriverInStrictMode","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":524,"column":59,"index":21567},"line":524,"code":"    it('shouldCorrectlyCallCallbackWithDbDriverInStrictMode', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_insert_and_update_no_callback_strict');\n          collection.insert({\n            _id: '12345678123456781234567812345678',\n            field: '1'\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.updateOne({\n              _id: '12345678123456781234567812345678'\n            }, {\n              $set: {\n                field: 0\n              }\n            }, configuration.writeConcernMax(), function (err, r) {\n              expect(err).to.not.exist;\n              expect(r).property('matchedCount').to.equal(1);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertDBRefWithDbNotDefined","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":561,"column":50,"index":22952},"line":561,"code":"    it('shouldCorrectlyInsertDBRefWithDbNotDefined', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyInsertDBRefWithDbNotDefined');\n          var doc = {\n            _id: new ObjectId()\n          };\n          var doc2 = {\n            _id: new ObjectId()\n          };\n          var doc3 = {\n            _id: new ObjectId()\n          };\n          collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n\n            // Create object with dbref\n            doc2.ref = new DBRef('shouldCorrectlyInsertDBRefWithDbNotDefined', doc._id);\n            doc3.ref = new DBRef('shouldCorrectlyInsertDBRefWithDbNotDefined', doc._id, configuration.db_name);\n            collection.insert([doc2, doc3], configuration.writeConcernMax(), function (err, result) {\n              expect(err).to.not.exist;\n              test.ok(result);\n\n              // Get all items\n              collection.find().toArray(function (err, items) {\n                test.equal('shouldCorrectlyInsertDBRefWithDbNotDefined', items[1].ref.namespace);\n                test.equal(doc._id.toString(), items[1].ref.oid.toString());\n                expect(items[1].ref.db).to.not.exist;\n                test.equal('shouldCorrectlyInsertDBRefWithDbNotDefined', items[2].ref.namespace);\n                test.equal(doc._id.toString(), items[2].ref.oid.toString());\n                expect(items[2].ref.db).to.not.exist;\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertUpdateRemoveWithNoOptions","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":612,"column":54,"index":25109},"line":612,"code":"    it('shouldCorrectlyInsertUpdateRemoveWithNoOptions', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyInsertUpdateRemoveWithNoOptions');\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.update({\n              a: 1\n            }, {\n              $set: {\n                a: 2\n              }\n            }, configuration.writeConcernMax(), function (err, result) {\n              expect(err).to.not.exist;\n              test.ok(result);\n              collection.deleteMany({\n                a: 2\n              }, configuration.writeConcernMax(), function (err, result) {\n                expect(err).to.not.exist;\n                test.ok(result);\n                collection.count(function (err, count) {\n                  test.equal(0, count);\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteMultipleFetches","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":657,"column":45,"index":26715},"line":657,"code":"    it('shouldCorrectlyExecuteMultipleFetches', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        // Search parameter\n        var to = 'ralph';\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyExecuteMultipleFetches');\n          // Execute query\n          collection.insert({\n            addresses: {\n              localPart: 'ralph'\n            }\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n\n            // Let's find our user\n            collection.findOne({\n              'addresses.localPart': to\n            }, function (err, doc) {\n              expect(err).to.not.exist;\n              test.equal(to, doc.addresses.localPart);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyFailWhenNoObjectToUpdate","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":696,"column":47,"index":28072},"line":696,"code":"    it('shouldCorrectlyFailWhenNoObjectToUpdate', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyFailWhenNoObjectToUpdate');\n          collection.update({\n            _id: new ObjectId()\n          }, {\n            $set: {\n              email: 'update'\n            }\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            expect(result).property('matchedCount').to.equal(0);\n            client.close(done);\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should correctly insert object and retrieve it when containing array and IsoDate","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":726,"column":88,"index":29207},"line":726,"code":"    it('Should correctly insert object and retrieve it when containing array and IsoDate', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var doc = {\n          _id: new ObjectId('4e886e687ff7ef5e00000162'),\n          str: 'foreign',\n          type: 2,\n          timestamp: ISODate('2011-10-02T14:00:08.383Z'),\n          links: ['http://www.reddit.com/r/worldnews/comments/kybm0/uk_home_secretary_calls_for_the_scrapping_of_the/']\n        };\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('Should_correctly_insert_object_and_retrieve_it_when_containing_array_and_IsoDate');\n          collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n            test.ok(err == null);\n            test.ok(result);\n            collection.findOne(function (err, item) {\n              test.ok(err == null);\n              test.deepEqual(doc, item);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"inserts and retrieves objects with timestamps","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":761,"column":53,"index":30647},"line":761,"code":"    it('inserts and retrieves objects with timestamps', async function () {\n      const doc = {\n        _id: new ObjectId('4e886e687ff7ef5e00000162'),\n        str: 'foreign',\n        type: 2,\n        timestamp: new Timestamp({\n          i: 10000,\n          t: 0\n        }),\n        links: ['http://www.reddit.com/r/worldnews/comments/kybm0/uk_home_secretary_calls_for_the_scrapping_of_the/'],\n        timestamp2: new Timestamp({\n          i: 33333,\n          t: 0\n        })\n      };\n      const db = client.db();\n      const collection = db.collection('Should_correctly_insert_object_with_timestamps');\n      const {\n        insertedId\n      } = await collection.insertOne(doc);\n      expect(insertedId.equals(doc._id)).to.be.true;\n      const result = await collection.findOne({\n        timestamp: new Timestamp({\n          i: 10000,\n          t: 0\n        })\n      });\n      expect(result).to.deep.equal(doc);\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly allow for control of serialization of functions on command level","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":790,"column":89,"index":31604},"line":790,"code":"    it('Should Correctly allow for control of serialization of functions on command level', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var doc = {\n          str: 'String',\n          func: function () {}\n        };\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('Should_Correctly_allow_for_control_of_serialization_of_functions_on_command_level');\n          collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.update({\n              str: 'String'\n            }, {\n              $set: {\n                c: 1,\n                d: function () {}\n              }\n            }, {\n              writeConcern: {\n                w: 1\n              },\n              serializeFunctions: false\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              expect(result).property('matchedCount').to.equal(1);\n              collection.findOne({\n                str: 'String'\n              }, function (err, item) {\n                expect(item.d).to.not.exist;\n\n                // Execute a safe insert with replication to two servers\n                collection.findOneAndUpdate({\n                  str: 'String'\n                }, {\n                  $set: {\n                    f: function () {}\n                  }\n                }, {\n                  returnDocument: ReturnDocument.AFTER,\n                  safe: true,\n                  serializeFunctions: true\n                }, function (err, result) {\n                  test.ok(result.value.f._bsontype === 'Code');\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly allow for control of serialization of functions on collection level","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":854,"column":92,"index":33883},"line":854,"code":"    it('Should Correctly allow for control of serialization of functions on collection level', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var doc = {\n          str: 'String',\n          func: function () {}\n        };\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('Should_Correctly_allow_for_control_of_serialization_of_functions_on_collection_level', {\n            serializeFunctions: true\n          });\n          collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({\n              str: 'String'\n            }, function (err, item) {\n              test.ok(item.func._bsontype === 'Code');\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly allow for using a Date object as _id","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":889,"column":61,"index":35190},"line":889,"code":"    it('Should Correctly allow for using a Date object as _id', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var doc = {\n          _id: new Date(),\n          str: 'hello'\n        };\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('Should_Correctly_allow_for_using_a_Date_object_as__id');\n          collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({\n              str: 'hello'\n            }, function (err, item) {\n              test.ok(item._id instanceof Date);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly fail to update returning 0 results","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":922,"column":59,"index":36399},"line":922,"code":"    it('Should Correctly fail to update returning 0 results', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('Should_Correctly_fail_to_update_returning_0_results');\n          collection.updateMany({\n            a: 1\n          }, {\n            $set: {\n              a: 1\n            }\n          }, configuration.writeConcernMax(), function (err, r) {\n            expect(r).property('matchedCount').to.equal(0);\n            client.close(done);\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly update two fields including a sub field","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":951,"column":64,"index":37452},"line":951,"code":"    it('Should Correctly update two fields including a sub field', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var doc = {\n          _id: new ObjectId(),\n          Prop1: 'p1',\n          Prop2: 'p2',\n          More: {\n            Sub1: 's1',\n            Sub2: 's2',\n            Sub3: 's3'\n          }\n        };\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('Should_Correctly_update_two_fields_including_a_sub_field');\n          collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n\n            // Update two fields\n            collection.update({\n              _id: doc._id\n            }, {\n              $set: {\n                Prop1: 'p1_2',\n                'More.Sub2': 's2_2'\n              }\n            }, configuration.writeConcernMax(), function (err, r) {\n              expect(err).to.not.exist;\n              expect(r).property('matchedCount').to.equal(1);\n              collection.findOne({\n                _id: doc._id\n              }, function (err, item) {\n                expect(err).to.not.exist;\n                test.equal('p1_2', item.Prop1);\n                test.equal('s2_2', item.More.Sub2);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should correctly fail due to duplicate key for _id","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1005,"column":58,"index":39295},"line":1005,"code":"    it('Should correctly fail due to duplicate key for _id', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('Should_Correctly_update_two_fields_including_a_sub_field_2');\n          collection.insertOne({\n            _id: 1\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n\n            // Update two fields\n            collection.insertOne({\n              _id: 1\n            }, configuration.writeConcernMax(), function (err, r) {\n              expect(err).to.exist;\n              expect(r).to.not.exist;\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertDocWithCustomId","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1039,"column":44,"index":40530},"line":1039,"code":"    it('shouldCorrectlyInsertDocWithCustomId', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyInsertDocWithCustomId');\n          // Insert the update\n          collection.insert({\n            _id: 0,\n            test: 'hello'\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({\n              _id: 0\n            }, function (err, item) {\n              test.equal(0, item._id);\n              test.equal('hello', item.test);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformUpsertAgainstNewDocumentAndExistingOne","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1073,"column":68,"index":41767},"line":1073,"code":"    it('shouldCorrectlyPerformUpsertAgainstNewDocumentAndExistingOne', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyPerformUpsertAgainstNewDocumentAndExistingOne');\n\n          // Upsert a new doc\n          collection.update({\n            a: 1\n          }, {\n            $set: {\n              a: 1\n            }\n          }, {\n            upsert: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, result) {\n            expect(err).to.not.exist;\n            expect(result).property('upsertedCount').to.equal(1);\n\n            // Upsert an existing doc\n            collection.update({\n              a: 1\n            }, {\n              $set: {\n                a: 1\n              }\n            }, {\n              upsert: true,\n              writeConcern: {\n                w: 1\n              }\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              expect(result).property('matchedCount').to.equal(1);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformLargeTextInsert","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1127,"column":45,"index":43398},"line":1127,"code":"    it('shouldCorrectlyPerformLargeTextInsert', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyPerformLargeTextInsert');\n\n          // Create large string, insert and then retrive\n          var string = '';\n          // Create large text field\n          for (var i = 0; i < 50000; i++) {\n            string = string + 'a';\n          }\n          collection.insert({\n            a: 1,\n            string: string\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({\n              a: 1\n            }, function (err, doc) {\n              expect(err).to.not.exist;\n              test.equal(50000, doc.string.length);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformInsertOfObjectsUsingToBSON","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1167,"column":56,"index":44810},"line":1167,"code":"    it('shouldCorrectlyPerformInsertOfObjectsUsingToBSON', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyPerformInsertOfObjectsUsingToBSON');\n\n          // Create document with toBSON method\n          var doc = {\n            a: 1,\n            b: 1\n          };\n          doc.toBSON = function () {\n            return {\n              c: this.a\n            };\n          };\n          collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({\n              c: 1\n            }, function (err, doc) {\n              expect(err).to.not.exist;\n              test.deepEqual(1, doc.c);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldAttempToForceBsonSize","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1208,"column":35,"index":46160},"line":1208,"code":"    it('shouldAttempToForceBsonSize', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: 'single'\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          db.createCollection('shouldAttempToForceBsonSize', function (err, collection) {\n            // var doc = {a:1, b:new Binary(Buffer.alloc(16777216)/5)}\n            var doc = [{\n              a: 1,\n              b: new Binary(Buffer.alloc(16777216 / 3))\n            }, {\n              a: 1,\n              b: new Binary(Buffer.alloc(16777216 / 3))\n            }, {\n              a: 1,\n              b: new Binary(Buffer.alloc(16777216 / 3))\n            }];\n            collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n              expect(err).to.not.exist;\n              test.ok(result);\n              collection.findOne({\n                a: 1\n              }, function (err, doc) {\n                expect(err).to.not.exist;\n                test.deepEqual(1, doc.a);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUseCustomObjectToUpdateDocument","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1250,"column":54,"index":47650},"line":1250,"code":"    it('shouldCorrectlyUseCustomObjectToUpdateDocument', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyUseCustomObjectToUpdateDocument');\n          collection.insert({\n            a: {\n              b: {\n                c: 1\n              }\n            }\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n\n            // Dynamically build query\n            var query = {};\n            query['a'] = {};\n            query.a['b'] = {};\n            query.a.b['c'] = 1;\n\n            // Update document\n            collection.update(query, {\n              $set: {\n                'a.b.d': 1\n              }\n            }, configuration.writeConcernMax(), function (err, r) {\n              expect(err).to.not.exist;\n              expect(r).property('matchedCount').to.equal(1);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldExecuteInsertWithNoCallbackAndWriteConcern","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1296,"column":56,"index":49184},"line":1296,"code":"    it('shouldExecuteInsertWithNoCallbackAndWriteConcern', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldExecuteInsertWithNoCallbackAndWriteConcern');\n          collection.insert({\n            a: {\n              b: {\n                c: 1\n              }\n            }\n          }).then(() => {\n            client.close(done);\n          }, err => {\n            client.close(err2 => done(err || err2));\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"executesCallbackOnceWithOveriddenDefaultDbWriteConcern","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1326,"column":62,"index":50205},"line":1326,"code":"    it('executesCallbackOnceWithOveriddenDefaultDbWriteConcern', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        function cb(err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        }\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('gh-completely2');\n          collection.insert({\n            a: 1\n          }, {\n            writeConcern: {\n              w: 0\n            }\n          }, cb);\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"executesCallbackOnceWithOveriddenDefaultDbWriteConcernWithUpdate","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1356,"column":72,"index":51171},"line":1356,"code":"    it('executesCallbackOnceWithOveriddenDefaultDbWriteConcernWithUpdate', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        function cb(err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        }\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('gh-completely3');\n          collection.update({\n            a: 1\n          }, {\n            $set: {\n              a: 2\n            }\n          }, {\n            upsert: true,\n            writeConcern: {\n              w: 0\n            }\n          }, cb);\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"executesCallbackOnceWithOveriddenDefaultDbWriteConcernWithRemove","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1391,"column":72,"index":52231},"line":1391,"code":"    it('executesCallbackOnceWithOveriddenDefaultDbWriteConcernWithRemove', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        function cb(err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        }\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('gh-completely1');\n          collection.deleteMany({\n            a: 1\n          }, {\n            writeConcern: {\n              w: 0\n            }\n          }, cb);\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"handleBSONTypeInsertsCorrectly","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1421,"column":38,"index":53167},"line":1421,"code":"    it('handleBSONTypeInsertsCorrectly', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger'],\n          mongodb: '<2.8.0'\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('bson_types_insert');\n          var document = {\n            symbol: new BSONSymbol('abcdefghijkl'),\n            objid: new ObjectId('abcdefghijkl'),\n            double: new Double(1),\n            binary: new Binary(Buffer.from('hello world')),\n            minkey: new MinKey(),\n            maxkey: new MaxKey(),\n            code: new Code('function () {}', {\n              a: 55\n            })\n          };\n          collection.insert(document, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({\n              symbol: new BSONSymbol('abcdefghijkl')\n            }, function (err, doc) {\n              expect(err).to.not.exist;\n              test.equal('abcdefghijkl', doc.symbol.toString());\n              collection.findOne({\n                objid: new ObjectId('abcdefghijkl')\n              }, function (err, doc) {\n                expect(err).to.not.exist;\n                test.equal('6162636465666768696a6b6c', doc.objid.toString());\n                collection.findOne({\n                  double: new Double(1)\n                }, function (err, doc) {\n                  expect(err).to.not.exist;\n                  test.equal(1, doc.double);\n                  collection.findOne({\n                    binary: new Binary(Buffer.from('hello world'))\n                  }, function (err, doc) {\n                    expect(err).to.not.exist;\n                    test.equal('hello world', doc.binary.toString());\n                    collection.findOne({\n                      minkey: new MinKey()\n                    }, function (err, doc) {\n                      expect(err).to.not.exist;\n                      test.ok(doc.minkey._bsontype === 'MinKey');\n                      collection.findOne({\n                        maxkey: new MaxKey()\n                      }, function (err, doc) {\n                        expect(err).to.not.exist;\n                        test.ok(doc.maxkey._bsontype === 'MaxKey');\n                        collection.findOne({\n                          code: new Code('function () {}', {\n                            a: 55\n                          })\n                        }, function (err, doc) {\n                          expect(err).to.not.exist;\n                          test.ok(doc != null);\n                          client.close(done);\n                        });\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"handleBSONTypeInsertsCorrectlyFor28OrHigher","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1501,"column":51,"index":56423},"line":1501,"code":"    it('handleBSONTypeInsertsCorrectlyFor28OrHigher', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger'],\n          mongodb: '>=2.8.0'\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('bson_types_insert_1');\n          var document = {\n            string: 'abcdefghijkl',\n            objid: new ObjectId('abcdefghijkl'),\n            double: new Double(1),\n            binary: new Binary(Buffer.from('hello world')),\n            minkey: new MinKey(),\n            maxkey: new MaxKey(),\n            code: new Code('function () {}', {\n              a: 55\n            })\n          };\n          collection.insert(document, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({\n              string: 'abcdefghijkl'\n            }, function (err, doc) {\n              expect(err).to.not.exist;\n              test.equal('abcdefghijkl', doc.string.toString());\n              collection.findOne({\n                objid: new ObjectId('abcdefghijkl')\n              }, function (err, doc) {\n                expect(err).to.not.exist;\n                test.equal('6162636465666768696a6b6c', doc.objid.toString());\n                collection.findOne({\n                  double: new Double(1)\n                }, function (err, doc) {\n                  expect(err).to.not.exist;\n                  test.equal(1, doc.double);\n                  collection.findOne({\n                    binary: new Binary(Buffer.from('hello world'))\n                  }, function (err, doc) {\n                    expect(err).to.not.exist;\n                    test.equal('hello world', doc.binary.toString());\n                    collection.findOne({\n                      minkey: new MinKey()\n                    }, function (err, doc) {\n                      expect(err).to.not.exist;\n                      test.ok(doc.minkey._bsontype === 'MinKey');\n                      collection.findOne({\n                        maxkey: new MaxKey()\n                      }, function (err, doc) {\n                        expect(err).to.not.exist;\n                        test.ok(doc.maxkey._bsontype === 'MaxKey');\n                        collection.findOne({\n                          code: new Code('function () {}', {\n                            a: 55\n                          })\n                        }, function (err, doc) {\n                          expect(err).to.not.exist;\n                          test.ok(doc != null);\n                          client.close(done);\n                        });\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"lookups for timestamp and date work","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1581,"column":43,"index":59642},"line":1581,"code":"    it('lookups for timestamp and date work', async function () {\n      const db = client.db();\n      const collection = db.collection('timestamp_date');\n      const d = new Date();\n      const documents = [{\n        x: new Timestamp({\n          i: 1,\n          t: 2\n        })\n      }, {\n        x: d\n      }];\n      const result = await collection.insertMany(documents);\n      test.ok(result);\n      const doc = await collection.findOne({\n        x: new Timestamp({\n          i: 1,\n          t: 2\n        })\n      });\n      expect(doc).to.not.be.null;\n      const docDate = await collection.findOne({\n        x: d\n      });\n      expect(docDate).to.not.be.null;\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"positiveAndNegativeInfinity","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1607,"column":35,"index":60306},"line":1607,"code":"    it('positiveAndNegativeInfinity', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('negative_pos');\n          var document = {\n            pos: Number.POSITIVE_INFINITY,\n            neg: Number.NEGATIVE_INFINITY\n          };\n          collection.insert(document, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({}, function (err, doc) {\n              expect(err).to.not.exist;\n              test.equal(Number.POSITIVE_INFINITY, doc.pos);\n              test.equal(Number.NEGATIVE_INFINITY, doc.neg);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertSimpleRegExpDocument","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1640,"column":49,"index":61585},"line":1640,"code":"    it('shouldCorrectlyInsertSimpleRegExpDocument', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var regexp = /foobar/i;\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          db.createCollection('test_regex', function (err, collection) {\n            collection.insert({\n              b: regexp\n            }, configuration.writeConcernMax(), function (err, ids) {\n              expect(err).to.not.exist;\n              test.ok(ids);\n              collection.find({}).project({\n                b: 1\n              }).toArray(function (err, items) {\n                test.equal('' + regexp, '' + items[0].b);\n                // Let's close the db\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertSimpleUTF8Regexp","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1674,"column":45,"index":62824},"line":1674,"code":"    it('shouldCorrectlyInsertSimpleUTF8Regexp', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var regexp = /foobaré/;\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyInsertSimpleUTF8Regexp');\n          collection.insert({\n            b: regexp\n          }, configuration.writeConcernMax(), function (err, ids) {\n            expect(err).to.not.exist;\n            test.ok(ids);\n            collection.find({}).project({\n              b: 1\n            }).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal('' + regexp, '' + items[0].b);\n              // Let's close the db\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyThrowDueToIllegalCollectionName","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1708,"column":54,"index":64082},"line":1708,"code":"    it('shouldCorrectlyThrowDueToIllegalCollectionName', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var k = Buffer.alloc(15);\n          for (var i = 0; i < 15; i++) k[i] = 0;\n          k.write('hello');\n          k[6] = 0x06;\n          k.write('world', 10);\n          try {\n            db.collection(k.toString());\n            test.fail(false);\n          } catch (err) {} // eslint-disable-line\n\n          client.close(done);\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHonorPromoteLongFalseNativeBSON","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1737,"column":54,"index":65073},"line":1737,"code":"    it('shouldCorrectlyHonorPromoteLongFalseNativeBSON', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: async function () {\n        const configuration = this.configuration;\n        const o = configuration.writeConcernMax();\n        o.promoteLongs = false;\n        const client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1,\n          promoteLongs: false\n        });\n        await client.connect();\n        const db = client.db(configuration.db);\n        await db.collection('shouldCorrectlyHonorPromoteLong').insertOne({\n          doc: Long.fromNumber(10),\n          array: [[Long.fromNumber(10)]]\n        });\n        const doc = await db.collection('shouldCorrectlyHonorPromoteLong').findOne();\n        expect(doc.doc._bsontype === 'Long');\n        expect(doc.array[0][0]._bsontype === 'Long');\n        await client.close();\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHonorPromoteLongFalseNativeBSONWithGetMore","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1765,"column":65,"index":66211},"line":1765,"code":"    it('shouldCorrectlyHonorPromoteLongFalseNativeBSONWithGetMore', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: async function () {\n        const configuration = this.configuration;\n        const o = configuration.writeConcernMax();\n        o.promoteLongs = false;\n        const client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1,\n          promoteLongs: false\n        });\n        await client.connect();\n        const db = client.db(configuration.db);\n        await db.collection('shouldCorrectlyHonorPromoteLongFalseNativeBSONWithGetMore').insertMany([{\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }]);\n        const docs = await db.collection('shouldCorrectlyHonorPromoteLongFalseNativeBSONWithGetMore').find({}).batchSize(2).toArray();\n        const doc = docs.pop();\n        expect(doc.a._bsontype).to.equal('Long');\n        client.close();\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInheritPromoteLongFalseNativeBSONWithGetMore","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1838,"column":67,"index":68419},"line":1838,"code":"    it('shouldCorrectlyInheritPromoteLongFalseNativeBSONWithGetMore', {\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: async function () {\n        const db = client.db('shouldCorrectlyInheritPromoteLongFalseNativeBSONWithGetMore', {\n          promoteLongs: true\n        });\n        const collection = db.collection('test', {\n          promoteLongs: false\n        });\n        const doc = await collection.insertMany([{\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }]);\n        test.ok(doc);\n        const docs = await collection.find({}).batchSize(2).toArray();\n        docs.forEach((d, i) => {\n          expect(d.a, `Failed on the document at index ${i}`).to.not.be.a('number');\n          expect(d.a, `Failed on the document at index ${i}`).to.have.property('_bsontype');\n          expect(d.a._bsontype, `Failed on the document at index ${i}`).to.be.equal('Long');\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHonorPromoteLongTrueNativeBSON","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1909,"column":53,"index":70459},"line":1909,"code":"    it('shouldCorrectlyHonorPromoteLongTrueNativeBSON', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          db.collection('shouldCorrectlyHonorPromoteLongTrueNativeBSON').insert({\n            doc: Long.fromNumber(10),\n            array: [[Long.fromNumber(10)]]\n          }, function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc);\n            db.collection('shouldCorrectlyHonorPromoteLongTrueNativeBSON').findOne(function (err, doc) {\n              expect(err).to.not.exist;\n              expect(err).to.not.exist;\n              test.ok('number', typeof doc.doc);\n              test.ok('number', typeof doc.array[0][0]);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHonorPromoteLongFalseJSBSON","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1941,"column":50,"index":71727},"line":1941,"code":"    it('shouldCorrectlyHonorPromoteLongFalseJSBSON', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: async function () {\n        const configuration = this.configuration;\n        const client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1,\n          promoteLongs: false\n        });\n        await client.connect();\n        const db = client.db(configuration.db);\n        await db.collection('shouldCorrectlyHonorPromoteLongFalseJSBSON').insertOne({\n          doc: Long.fromNumber(10),\n          array: [[Long.fromNumber(10)]]\n        });\n        const doc = await db.collection('shouldCorrectlyHonorPromoteLongFalseJSBSON').findOne({});\n        expect(doc.doc._bsontype).to.equal('Long');\n        expect(doc.array[0][0]._bsontype).to.equal('Long');\n        await client.close();\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHonorPromoteLongTrueJSBSON","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1967,"column":49,"index":72802},"line":1967,"code":"    it('shouldCorrectlyHonorPromoteLongTrueJSBSON', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          db.collection('shouldCorrectlyHonorPromoteLongTrueJSBSON').insert({\n            doc: Long.fromNumber(10),\n            array: [[Long.fromNumber(10)]]\n          }, function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc);\n            db.collection('shouldCorrectlyHonorPromoteLongTrueJSBSON').findOne(function (err, doc) {\n              expect(err).to.not.exist;\n              expect(err).to.not.exist;\n              test.ok('number', typeof doc.doc);\n              test.ok('number', typeof doc.array[0][0]);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyWorkWithCheckKeys","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1999,"column":40,"index":74052},"line":1999,"code":"    it('shouldCorrectlyWorkWithCheckKeys', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          db.collection('shouldCorrectlyOverrideCheckKeysJSOnUpdate').update({\n            'ps.op.t': 1\n          }, {\n            $set: {\n              b: 1\n            }\n          }, {\n            checkKeys: false\n          }, function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc);\n            client.close(done);\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyApplyBitOperator","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2030,"column":39,"index":75053},"line":2030,"code":"    it('shouldCorrectlyApplyBitOperator', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var col = db.collection('shouldCorrectlyApplyBitOperator');\n          col.insert({\n            a: 1,\n            b: 1\n          }, function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            col.update({\n              a: 1\n            }, {\n              $bit: {\n                b: {\n                  and: 0\n                }\n              }\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              test.ok(result);\n              col.findOne({\n                a: 1\n              }, function (err, doc) {\n                expect(err).to.not.exist;\n                test.equal(1, doc.a);\n                test.equal(0, doc.b);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformInsertAndUpdateWithFunctionSerialization","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2079,"column":70,"index":76607},"line":2079,"code":"    it('shouldCorrectlyPerformInsertAndUpdateWithFunctionSerialization', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var col = db.collection('shouldCorrectlyPerformInsertAndUpdateWithFunctionSerialization', {\n            serializeFunctions: true\n          });\n          col.insert({\n            a: 1,\n            f: function (x) {\n              return x;\n            }\n          }, function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc);\n            col.update({\n              a: 1\n            }, {\n              $set: {\n                f: function (y) {\n                  return y;\n                }\n              }\n            }, function (err, doc) {\n              expect(err).to.not.exist;\n              test.ok(doc);\n              col.findOne({\n                a: 1\n              }, function (err, doc) {\n                expect(err).to.not.exist;\n                test.equal(trim('function (y){return y;}'), trim(doc.f.code));\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"should correctly insert > 1000 docs using insert and insertMany","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2128,"column":71,"index":78217},"line":2128,"code":"    it('should correctly insert > 1000 docs using insert and insertMany', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var col = db.collection('shouldCorrectlyAllowforMoreThanAThousandDocsInsert', {\n            serializeFunctions: true\n          });\n          var docs = [];\n          for (var i = 0; i < 2000; i++) {\n            docs.push({\n              a: i\n            });\n          }\n          col.insertMany(docs, function (err, result) {\n            expect(err).to.not.exist;\n            expect(result).property('insertedCount').to.equal(2000);\n            docs = [];\n            for (var i = 0; i < 2000; i++) {\n              docs.push({\n                a: i\n              });\n            }\n            col.insertMany(docs, function (err, res) {\n              expect(err).to.not.exist;\n              expect(res).property('insertedCount').to.equal(2000);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"should return error on unordered insertMany with multiple unique key constraints","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2170,"column":88,"index":79723},"line":2170,"code":"    it('should return error on unordered insertMany with multiple unique key constraints', async () => {\n      const col = client.db().collection('insertManyMultipleWriteErrors');\n      await col.drop().catch(() => null);\n      const createIndexRes = await col.createIndex({\n        a: 1\n      }, {\n        unique: true\n      });\n      expect(createIndexRes).to.equal('a_1');\n      const insertManyRes = await col.insertMany([{\n        a: 1\n      }, {\n        a: 2\n      }, {\n        a: 1\n      }, {\n        a: 3\n      }, {\n        a: 1\n      }], {\n        ordered: false\n      }).catch(error => error);\n      expect(insertManyRes).to.be.instanceOf(MongoBulkWriteError);\n      expect(insertManyRes.result).to.exist;\n      // Unordered will hit both the a:1 inserts\n      expect(insertManyRes.result.getWriteErrors()).to.have.length(2);\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"should return error on ordered insertMany with multiple unique key constraints","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2197,"column":86,"index":80565},"line":2197,"code":"    it('should return error on ordered insertMany with multiple unique key constraints', async () => {\n      const col = client.db().collection('insertManyMultipleWriteErrors');\n      await col.drop().catch(() => null);\n      const createIndexRes = await col.createIndex({\n        a: 1\n      }, {\n        unique: true\n      });\n      expect(createIndexRes).to.equal('a_1');\n      const insertManyRes = await col.insertMany([{\n        a: 1\n      }, {\n        a: 2\n      }, {\n        a: 1\n      }, {\n        a: 3\n      }, {\n        a: 1\n      }], {\n        ordered: true\n      }).catch(error => error);\n      expect(insertManyRes).to.be.instanceOf(MongoBulkWriteError);\n      expect(insertManyRes.result).to.exist;\n      // Ordered will hit only the second a:1 insert\n      expect(insertManyRes.result.getWriteErrors()).to.have.length(1);\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Correctly allow forceServerObjectId for insertOne","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2224,"column":57,"index":81381},"line":2224,"code":"    it('Correctly allow forceServerObjectId for insertOne', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n      test: function (done) {\n        var started = [];\n        var succeeded = [];\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1,\n          monitorCommands: true\n        });\n        client.on('commandStarted', function (event) {\n          if (event.commandName === 'insert') started.push(event);\n        });\n        client.on('commandSucceeded', function (event) {\n          if (event.commandName === 'insert') succeeded.push(event);\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          expect(err).to.not.exist;\n          db.collection('apm_test').insertOne({\n            a: 1\n          }, {\n            forceServerObjectId: true\n          }).then(function () {\n            expect(started[0].command.documents[0]._id).to.not.exist;\n            client.close(done);\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Correctly allow forceServerObjectId for insertMany","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2258,"column":58,"index":82512},"line":2258,"code":"    it('Correctly allow forceServerObjectId for insertMany', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n      test: function (done) {\n        var started = [];\n        var succeeded = [];\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1,\n          monitorCommands: true\n        });\n        client.on('commandStarted', function (event) {\n          if (event.commandName === 'insert') started.push(event);\n        });\n        client.on('commandSucceeded', function (event) {\n          if (event.commandName === 'insert') succeeded.push(event);\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          expect(err).to.not.exist;\n          db.collection('apm_test').insertMany([{\n            a: 1\n          }], {\n            forceServerObjectId: true\n          }).then(function () {\n            expect(started[0].command.documents[0]._id).to.not.exist;\n            client.close(done);\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"should return correct number of ids for insertMany { ordered: true }","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2292,"column":76,"index":83664},"line":2292,"code":"    it('should return correct number of ids for insertMany { ordered: true }', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          expect(err).to.not.exist;\n          db.collection('inserted_ids_test').insertMany([{}, {}, {}], {\n            ordered: true\n          }).then(function (r) {\n            expect(r).property('insertedCount').to.equal(3);\n            client.close(done);\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"should return correct number of ids for insertMany { ordered: false }","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2315,"column":77,"index":84427},"line":2315,"code":"    it('should return correct number of ids for insertMany { ordered: false }', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          expect(err).to.not.exist;\n          db.collection('inserted_ids_test').insertMany([{}, {}, {}], {\n            ordered: false\n          }).then(function (r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(3);\n            client.close(done);\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Insert document including sub documents","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2339,"column":47,"index":85199},"line":2339,"code":"    it('Insert document including sub documents', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          expect(err).to.not.exist;\n          var shipment = {\n            shipment1: 'a'\n          };\n          var supplier = {\n            shipments: [shipment]\n          };\n          var product = {\n            suppliers: [supplier]\n          };\n          var doc = {\n            a: 1,\n            products: [product]\n          };\n          db.collection('sub_documents').insertOne(doc, function (err, r) {\n            expect(err).to.not.exist;\n            test.ok(r);\n            db.collection('sub_documents').find({}).next(function (err, v) {\n              expect(err).to.not.exist;\n              test.equal('a', v.products[0].suppliers[0].shipments[0].shipment1);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"MongoBulkWriteError and BulkWriteResult should respect BulkWrite","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2378,"column":72,"index":86419},"line":2378,"code":"    it('MongoBulkWriteError and BulkWriteResult should respect BulkWrite', function () {\n      return client.connect().then(() => {\n        return client.db().collection('test_insertMany_bulkResult').drop();\n      }).catch(ignoreNsNotFound).then(() => {\n        const collection = client.db().collection('test_insertMany_bulkResult');\n        return collection.insertMany([{\n          _id: 2,\n          x: 22\n        }, {\n          _id: 2,\n          x: 22\n        }, {\n          _id: 3,\n          x: 33\n        }], {\n          ordered: false\n        });\n      }).then(() => {\n        expect.fail('InsertMany should fail with multi key error');\n      }).catch(error => {\n        expect(error).to.be.instanceOf(MongoBulkWriteError);\n        expect(error.insertedCount, 'MongoBulkWriteError.insertedCount did not respect BulkResult.nInserted').to.equal(error.result.result.nInserted);\n        expect(error.result.insertedCount, 'BulkWriteResult.insertedCount did not respect BulkResult.nInserted').to.equal(error.result.result.nInserted);\n        expect(error.result.result.nInserted, 'BulkWrite did not correctly represent the operation').to.equal(2);\n      }).finally(() => client.db().collection('test_insertMany_bulkResult').drop()).finally(() => client.close());\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"should not throw an error when toArray and forEach are called after cursor is closed","suites":["Cursor"],"updatePoint":{"line":57,"column":90,"index":1207},"line":57,"code":"  it('should not throw an error when toArray and forEach are called after cursor is closed', async function () {\n    const db = client.db();\n    const collection = await db.collection('test_to_a');\n    await collection.insertMany([{\n      a: 1\n    }]);\n    const cursor = collection.find({});\n    const firstToArray = await cursor.toArray().catch(error => error);\n    expect(firstToArray).to.be.an('array');\n    expect(cursor.closed).to.be.true;\n    const secondToArray = await cursor.toArray().catch(error => error);\n    expect(secondToArray).to.be.an('array');\n    expect(secondToArray).to.have.lengthOf(0);\n    const forEachResult = await cursor.forEach(() => {\n      expect.fail('should not run forEach on an empty/closed cursor');\n    }).catch(error => error);\n    expect(forEachResult).to.be.undefined;\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"cursor should close after first next operation","suites":["Cursor"],"updatePoint":{"line":75,"column":52,"index":1984},"line":75,"code":"  it('cursor should close after first next operation', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('close_on_next', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert([{\n            a: 1\n          }, {\n            a: 1\n          }, {\n            a: 1\n          }], configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            var cursor = collection.find({});\n            this.defer(() => cursor.close());\n            cursor.batchSize(2);\n            cursor.next(err => {\n              expect(err).to.not.exist;\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"cursor should trigger getMore","suites":["Cursor"],"updatePoint":{"line":111,"column":35,"index":3092},"line":111,"code":"  it('cursor should trigger getMore', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('trigger_get_more', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert([{\n            a: 1\n          }, {\n            a: 1\n          }, {\n            a: 1\n          }], configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find({}).batchSize(2);\n            this.defer(() => cursor.close());\n            cursor.toArray(err => {\n              expect(err).to.not.exist;\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteCursorExplain","suites":["Cursor"],"updatePoint":{"line":146,"column":41,"index":4194},"line":146,"code":"  it('shouldCorrectlyExecuteCursorExplain', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_explain', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            collection.find({\n              a: 1\n            }).explain((err, explanation) => {\n              expect(err).to.not.exist;\n              expect(explanation).to.exist;\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteCursorCount","suites":["Cursor"],"updatePoint":{"line":178,"column":39,"index":5221},"line":178,"code":"  it('shouldCorrectlyExecuteCursorCount', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_count', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.find().count(err => {\n            expect(err).to.not.exist;\n            function insert(callback) {\n              var total = 10;\n              for (var i = 0; i < 10; i++) {\n                collection.insert({\n                  x: i\n                }, configuration.writeConcernMax(), e => {\n                  expect(e).to.not.exist;\n                  total = total - 1;\n                  if (total === 0) callback();\n                });\n              }\n            }\n            function finished() {\n              collection.find().count((err, count) => {\n                expect(err).to.not.exist;\n                test.equal(10, count);\n                test.ok(count.constructor === Number);\n                collection.find({}, {\n                  limit: 5\n                }).count((err, count) => {\n                  expect(err).to.not.exist;\n                  test.equal(5, count);\n                  collection.find({}, {\n                    skip: 5\n                  }).count((err, count) => {\n                    expect(err).to.not.exist;\n                    test.equal(5, count);\n                    db.collection('acollectionthatdoesn').count((err, count) => {\n                      expect(err).to.not.exist;\n                      test.equal(0, count);\n                      var cursor = collection.find();\n                      cursor.count((err, count) => {\n                        expect(err).to.not.exist;\n                        test.equal(10, count);\n                        cursor.forEach(() => {}, err => {\n                          expect(err).to.not.exist;\n                          cursor.count((err, count2) => {\n                            expect(err).to.not.exist;\n                            expect(count2).to.equal(10);\n                            expect(count2).to.equal(count);\n                            done();\n                          });\n                        });\n                      });\n                    });\n                  });\n                });\n              });\n            }\n            insert(function () {\n              finished();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute cursor count with secondary readPreference","suites":["Cursor"],"updatePoint":{"line":253,"column":73,"index":8041},"line":253,"code":"  it('should correctly execute cursor count with secondary readPreference', {\n    metadata: {\n      requires: {\n        topology: 'replicaset'\n      }\n    },\n    async test() {\n      const bag = [];\n      client.on('commandStarted', filterForCommands(['count'], bag));\n      const cursor = client.db().collection('countTEST').find({\n        qty: {\n          $gt: 4\n        }\n      });\n      await cursor.count({\n        readPreference: ReadPreference.SECONDARY\n      });\n      const selectedServerAddress = bag[0].address.replace('127.0.0.1', 'localhost').replace('[::1]', 'localhost');\n      const selectedServer = client.topology.description.servers.get(selectedServerAddress);\n      expect(selectedServer).property('type').to.equal(ServerType.RSSecondary);\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteCursorCountWithDottedCollectionName","suites":["Cursor"],"updatePoint":{"line":275,"column":63,"index":8803},"line":275,"code":"  it('shouldCorrectlyExecuteCursorCountWithDottedCollectionName', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_count.ext', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.find().count(err => {\n            expect(err).to.not.exist;\n            function insert(callback) {\n              var total = 10;\n              for (var i = 0; i < 10; i++) {\n                collection.insert({\n                  x: i\n                }, configuration.writeConcernMax(), e => {\n                  expect(e).to.not.exist;\n                  total = total - 1;\n                  if (total === 0) callback();\n                });\n              }\n            }\n            function finished() {\n              collection.find().count((err, count) => {\n                expect(err).to.not.exist;\n                test.equal(10, count);\n                test.ok(count.constructor === Number);\n                collection.find({}, {\n                  limit: 5\n                }).count((err, count) => {\n                  expect(err).to.not.exist;\n                  test.equal(5, count);\n                  collection.find({}, {\n                    skip: 5\n                  }).count((err, count) => {\n                    expect(err).to.not.exist;\n                    test.equal(5, count);\n                    db.collection('acollectionthatdoesn').count((err, count) => {\n                      expect(err).to.not.exist;\n                      test.equal(0, count);\n                      var cursor = collection.find();\n                      cursor.count((err, count) => {\n                        expect(err).to.not.exist;\n                        test.equal(10, count);\n                        cursor.forEach(() => {}, err => {\n                          expect(err).to.not.exist;\n                          cursor.count((err, count2) => {\n                            expect(err).to.not.exist;\n                            expect(count2).to.equal(10);\n                            expect(count2).to.equal(count);\n                            done();\n                          });\n                        });\n                      });\n                    });\n                  });\n                });\n              });\n            }\n            insert(function () {\n              finished();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldThrowErrorOnEachWhenMissingCallback","suites":["Cursor"],"updatePoint":{"line":350,"column":47,"index":11601},"line":350,"code":"  it('shouldThrowErrorOnEachWhenMissingCallback', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_each', (err, collection) => {\n          expect(err).to.not.exist;\n          function insert(callback) {\n            var total = 10;\n            for (var i = 0; i < 10; i++) {\n              collection.insert({\n                x: i\n              }, configuration.writeConcernMax(), e => {\n                expect(e).to.not.exist;\n                total = total - 1;\n                if (total === 0) callback();\n              });\n            }\n          }\n          function finished() {\n            const cursor = collection.find();\n            test.throws(function () {\n              cursor.forEach();\n            });\n            done();\n          }\n          insert(function () {\n            finished();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleLimitOnCursor","suites":["Cursor"],"updatePoint":{"line":392,"column":40,"index":12904},"line":392,"code":"  it('shouldCorrectlyHandleLimitOnCursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_cursor_limit', (err, collection) => {\n          function insert(callback) {\n            var total = 10;\n            for (var i = 0; i < 10; i++) {\n              collection.insert({\n                x: i\n              }, configuration.writeConcernMax(), e => {\n                expect(e).to.not.exist;\n                total = total - 1;\n                if (total === 0) callback();\n              });\n            }\n          }\n          function finished() {\n            collection.find().limit(5).toArray((err, items) => {\n              test.equal(5, items.length);\n\n              // Let's close the db\n              expect(err).to.not.exist;\n              done();\n            });\n          }\n          insert(function () {\n            finished();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleNegativeOneLimitOnCursor","suites":["Cursor"],"updatePoint":{"line":435,"column":51,"index":14261},"line":435,"code":"  it('shouldCorrectlyHandleNegativeOneLimitOnCursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_cursor_negative_one_limit', (err, collection) => {\n          expect(err).to.not.exist;\n          function insert(callback) {\n            var total = 10;\n            for (var i = 0; i < 10; i++) {\n              collection.insert({\n                x: i\n              }, configuration.writeConcernMax(), e => {\n                expect(e).to.not.exist;\n                total = total - 1;\n                if (total === 0) callback();\n              });\n            }\n          }\n          function finished() {\n            collection.find().limit(-1).toArray((err, items) => {\n              expect(err).to.not.exist;\n              test.equal(1, items.length);\n\n              // Let's close the db\n              done();\n            });\n          }\n          insert(function () {\n            finished();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleAnyNegativeLimitOnCursor","suites":["Cursor"],"updatePoint":{"line":479,"column":51,"index":15668},"line":479,"code":"  it('shouldCorrectlyHandleAnyNegativeLimitOnCursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_cursor_any_negative_limit', (err, collection) => {\n          expect(err).to.not.exist;\n          function insert(callback) {\n            var total = 10;\n            for (var i = 0; i < 10; i++) {\n              collection.insert({\n                x: i\n              }, configuration.writeConcernMax(), e => {\n                expect(e).to.not.exist;\n                total = total - 1;\n                if (total === 0) callback();\n              });\n            }\n          }\n          function finished() {\n            collection.find().limit(-5).toArray((err, items) => {\n              expect(err).to.not.exist;\n              test.equal(5, items.length);\n\n              // Let's close the db\n              done();\n            });\n          }\n          insert(function () {\n            finished();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyReturnErrorsOnIllegalLimitValuesNotAnInt","suites":["Cursor"],"updatePoint":{"line":523,"column":61,"index":17085},"line":523,"code":"  it('shouldCorrectlyReturnErrorsOnIllegalLimitValuesNotAnInt', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_limit_exceptions_2', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find();\n            this.defer(() => cursor.close());\n            try {\n              cursor.limit('not-an-integer');\n            } catch (err) {\n              test.equal('Operation \"limit\" requires an integer', err.message);\n            }\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyReturnErrorsOnIllegalLimitValuesIsClosedWithinNext","suites":["Cursor"],"updatePoint":{"line":556,"column":71,"index":18235},"line":556,"code":"  it('shouldCorrectlyReturnErrorsOnIllegalLimitValuesIsClosedWithinNext', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_limit_exceptions', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find();\n            this.defer(() => cursor.close());\n            cursor.next(err => {\n              expect(err).to.not.exist;\n              expect(() => {\n                cursor.limit(1);\n              }).to.throw(/Cursor is already initialized/);\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyReturnErrorsOnIllegalLimitValuesIsClosedWithinClose","suites":["Cursor"],"line":592,"code":"  it.skip('shouldCorrectlyReturnErrorsOnIllegalLimitValuesIsClosedWithinClose', {","file":"integration/crud/misc_cursors.test.js","skipped":true,"dir":"test"},{"name":"shouldCorrectlySkipRecordsOnCursor","suites":["Cursor"],"updatePoint":{"line":625,"column":40,"index":20564},"line":625,"code":"  it('shouldCorrectlySkipRecordsOnCursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_skip', (err, collection) => {\n          expect(err).to.not.exist;\n          const insert = callback => {\n            var total = 10;\n            for (var i = 0; i < 10; i++) {\n              collection.insert({\n                x: i\n              }, configuration.writeConcernMax(), e => {\n                expect(e).to.not.exist;\n                total = total - 1;\n                if (total === 0) callback();\n              });\n            }\n          };\n          insert(() => {\n            const cursor = collection.find();\n            this.defer(() => cursor.close());\n            cursor.count((err, count) => {\n              expect(err).to.not.exist;\n              test.equal(10, count);\n            });\n            const cursor2 = collection.find();\n            this.defer(() => cursor2.close());\n            cursor2.toArray((err, items) => {\n              expect(err).to.not.exist;\n              test.equal(10, items.length);\n              collection.find().skip(2).toArray((err, items2) => {\n                expect(err).to.not.exist;\n                test.equal(8, items2.length);\n\n                // Check that we have the same elements\n                var numberEqual = 0;\n                var sliced = items.slice(2, 10);\n                for (var i = 0; i < sliced.length; i++) {\n                  if (sliced[i].x === items2[i].x) numberEqual = numberEqual + 1;\n                }\n                test.equal(8, numberEqual);\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyReturnErrorsOnIllegalSkipValues","suites":["Cursor"],"updatePoint":{"line":684,"column":52,"index":22665},"line":684,"code":"  it('shouldCorrectlyReturnErrorsOnIllegalSkipValues', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_skip_exceptions', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            try {\n              collection.find().skip('not-an-integer');\n            } catch (err) {\n              test.equal('Operation \"skip\" requires an integer', err.message);\n            }\n            const cursor = collection.find();\n            cursor.next(err => {\n              expect(err).to.not.exist;\n\n              // NOTE: who cares what you set when closed, if not initialized\n              // expect(() => {\n              //   cursor.skip(1);\n              // }).to.throw(/not extensible/);\n\n              const cursor2 = collection.find();\n              cursor2.close(err => {\n                expect(err).to.not.exist;\n\n                // NOTE: who cares what you set when closed, if not initialized\n                // expect(() => {\n                //   cursor2.skip(1);\n                // }).to.throw(/not extensible/);\n\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldReturnErrorsOnIllegalBatchSizes","suites":["Cursor"],"updatePoint":{"line":735,"column":43,"index":24385},"line":735,"code":"  it('shouldReturnErrorsOnIllegalBatchSizes', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_batchSize_exceptions', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            let cursor = collection.find();\n            try {\n              cursor.batchSize('not-an-integer');\n              test.ok(false);\n            } catch (err) {\n              test.equal('Operation \"batchSize\" requires an integer', err.message);\n            }\n            cursor = collection.find();\n            cursor.next(err => {\n              expect(err).to.not.exist;\n              cursor.next(err => {\n                expect(err).to.not.exist;\n\n                // NOTE: who cares what you set when closed, if not initialized\n                // expect(() => {\n                //   cursor.batchSize(1);\n                // }).to.throw(/not extensible/);\n\n                const cursor2 = collection.find();\n                cursor2.close(err => {\n                  expect(err).to.not.exist;\n\n                  // NOTE: who cares what you set when closed, if not initialized\n                  // expect(() => {\n                  //   cursor2.batchSize(1);\n                  // }).to.throw(/not extensible/);\n\n                  done();\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleBatchSize","suites":["Cursor"],"updatePoint":{"line":791,"column":36,"index":26301},"line":791,"code":"  it('shouldCorrectlyHandleBatchSize', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_multiple_batch_size', (err, collection) => {\n          expect(err).to.not.exist;\n\n          //test with the last batch that is a multiple of batchSize\n          var records = 4;\n          var batchSize = 2;\n          var docs = [];\n          for (var i = 0; i < records; i++) {\n            docs.push({\n              a: i\n            });\n          }\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find({}, {\n              batchSize: batchSize\n            });\n\n            //1st\n            cursor.next((err, items) => {\n              expect(err).to.not.exist;\n              test.equal(1, cursor.bufferedCount());\n              test.ok(items != null);\n\n              //2nd\n              cursor.next((err, items) => {\n                expect(err).to.not.exist;\n                test.equal(0, cursor.bufferedCount());\n                test.ok(items != null);\n\n                //3rd\n                cursor.next((err, items) => {\n                  expect(err).to.not.exist;\n                  test.equal(1, cursor.bufferedCount());\n                  test.ok(items != null);\n\n                  //4th\n                  cursor.next((err, items) => {\n                    expect(err).to.not.exist;\n                    test.equal(0, cursor.bufferedCount());\n                    test.ok(items != null);\n\n                    //No more\n                    cursor.next((err, items) => {\n                      expect(err).to.not.exist;\n                      test.ok(items == null);\n                      test.ok(cursor.closed);\n                      done();\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldHandleWhenLimitBiggerThanBatchSize","suites":["Cursor"],"updatePoint":{"line":863,"column":46,"index":28650},"line":863,"code":"  it('shouldHandleWhenLimitBiggerThanBatchSize', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_limit_greater_than_batch_size', (err, collection) => {\n          expect(err).to.not.exist;\n          var limit = 4;\n          var records = 10;\n          var batchSize = 3;\n          var docs = [];\n          for (var i = 0; i < records; i++) {\n            docs.push({\n              a: i\n            });\n          }\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            var cursor = collection.find({}, {\n              batchSize: batchSize,\n              limit: limit\n            });\n            //1st\n            cursor.next(err => {\n              expect(err).to.not.exist;\n              test.equal(2, cursor.bufferedCount());\n\n              //2nd\n              cursor.next(err => {\n                expect(err).to.not.exist;\n                test.equal(1, cursor.bufferedCount());\n\n                //3rd\n                cursor.next(err => {\n                  expect(err).to.not.exist;\n                  test.equal(0, cursor.bufferedCount());\n\n                  //4th\n                  cursor.next(err => {\n                    expect(err).to.not.exist;\n\n                    //No more\n                    cursor.next((err, items) => {\n                      expect(err).to.not.exist;\n                      test.ok(items == null);\n                      test.ok(cursor.closed);\n                      done();\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldHandleLimitLessThanBatchSize","suites":["Cursor"],"updatePoint":{"line":929,"column":40,"index":30725},"line":929,"code":"  it('shouldHandleLimitLessThanBatchSize', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_limit_less_than_batch_size', (err, collection) => {\n          expect(err).to.not.exist;\n          var limit = 2;\n          var records = 10;\n          var batchSize = 4;\n          var docs = [];\n          for (var i = 0; i < records; i++) {\n            docs.push({\n              a: i\n            });\n          }\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            var cursor = collection.find({}, {\n              batchSize: batchSize,\n              limit: limit\n            });\n            //1st\n            cursor.next(err => {\n              expect(err).to.not.exist;\n              test.equal(1, cursor.bufferedCount());\n\n              //2nd\n              cursor.next(err => {\n                expect(err).to.not.exist;\n                test.equal(0, cursor.bufferedCount());\n\n                //No more\n                cursor.next((err, items) => {\n                  expect(err).to.not.exist;\n                  test.ok(items == null);\n                  test.ok(cursor.closed);\n                  done();\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldHandleSkipLimitChaining","suites":["Cursor"],"updatePoint":{"line":984,"column":35,"index":32451},"line":984,"code":"  it('shouldHandleSkipLimitChaining', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var collection = db.collection('shouldHandleSkipLimitChaining');\n        function insert(callback) {\n          var total = 10;\n          for (var i = 0; i < 10; i++) {\n            collection.insert({\n              x: i\n            }, configuration.writeConcernMax(), e => {\n              expect(e).to.not.exist;\n              total = total - 1;\n              if (total === 0) callback();\n            });\n          }\n        }\n        function finished() {\n          collection.find().toArray((err, items) => {\n            expect(err).to.not.exist;\n            test.equal(10, items.length);\n            collection.find().limit(5).skip(3).toArray(function (err, items2) {\n              expect(err).to.not.exist;\n              test.equal(5, items2.length);\n\n              // Check that we have the same elements\n              var numberEqual = 0;\n              var sliced = items.slice(3, 8);\n              for (var i = 0; i < sliced.length; i++) {\n                if (sliced[i].x === items2[i].x) numberEqual = numberEqual + 1;\n              }\n              test.equal(5, numberEqual);\n              done();\n            });\n          });\n        }\n        insert(function () {\n          finished();\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleLimitSkipChainingInline","suites":["Cursor"],"updatePoint":{"line":1036,"column":50,"index":34219},"line":1036,"code":"  it('shouldCorrectlyHandleLimitSkipChainingInline', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_limit_skip_chaining_inline', (err, collection) => {\n          expect(err).to.not.exist;\n          function insert(callback) {\n            var total = 10;\n            for (var i = 0; i < 10; i++) {\n              collection.insert({\n                x: i\n              }, configuration.writeConcernMax(), e => {\n                expect(e).to.not.exist;\n                total = total - 1;\n                if (total === 0) callback();\n              });\n            }\n          }\n          function finished() {\n            collection.find().toArray((err, items) => {\n              expect(err).to.not.exist;\n              test.equal(10, items.length);\n              collection.find().limit(5).skip(3).toArray(function (err, items2) {\n                expect(err).to.not.exist;\n                test.equal(5, items2.length);\n\n                // Check that we have the same elements\n                var numberEqual = 0;\n                var sliced = items.slice(3, 8);\n                for (var i = 0; i < sliced.length; i++) {\n                  if (sliced[i].x === items2[i].x) numberEqual = numberEqual + 1;\n                }\n                test.equal(5, numberEqual);\n                done();\n              });\n            });\n          }\n          insert(function () {\n            finished();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCloseCursorNoQuerySent","suites":["Cursor"],"updatePoint":{"line":1090,"column":34,"index":36098},"line":1090,"code":"  it('shouldCloseCursorNoQuerySent', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_close_no_query_sent', (err, collection) => {\n          expect(err).to.not.exist;\n          const cursor = collection.find();\n          cursor.close(err => {\n            expect(err).to.not.exist;\n            test.equal(true, cursor.closed);\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRefillViaGetMoreCommand","suites":["Cursor"],"updatePoint":{"line":1116,"column":44,"index":36963},"line":1116,"code":"  it('shouldCorrectlyRefillViaGetMoreCommand', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var COUNT = 1000;\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_refill_via_get_more', (err, collection) => {\n          expect(err).to.not.exist;\n          function insert(callback) {\n            var docs = [];\n            for (var i = 0; i < COUNT; i++) {\n              docs.push({\n                a: i\n              });\n            }\n            collection.insertMany(docs, configuration.writeConcernMax(), callback);\n          }\n          function finished() {\n            collection.count((err, count) => {\n              expect(err).to.not.exist;\n              test.equal(COUNT, count);\n            });\n            var total = 0;\n            collection.find({}, {}).forEach(item => {\n              total = total + item.a;\n            }, err => {\n              expect(err).to.not.exist;\n              test.equal(499500, total);\n              collection.count((err, count) => {\n                expect(err).to.not.exist;\n                test.equal(COUNT, count);\n              });\n              collection.count((err, count) => {\n                expect(err).to.not.exist;\n                test.equal(COUNT, count);\n                var total2 = 0;\n                collection.find().forEach(item => {\n                  total2 = total2 + item.a;\n                }, err => {\n                  expect(err).to.not.exist;\n                  test.equal(499500, total2);\n                  collection.count((err, count) => {\n                    expect(err).to.not.exist;\n                    test.equal(COUNT, count);\n                    test.equal(total, total2);\n                    done();\n                  });\n                });\n              });\n            });\n          }\n          insert(function () {\n            finished();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRefillViaGetMoreAlternativeCollection","suites":["Cursor"],"updatePoint":{"line":1183,"column":58,"index":39265},"line":1183,"code":"  it('shouldCorrectlyRefillViaGetMoreAlternativeCollection', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_refill_via_get_more_alt_coll', (err, collection) => {\n          expect(err).to.not.exist;\n          var COUNT = 1000;\n          function insert(callback) {\n            var docs = [];\n            for (var i = 0; i < COUNT; i++) {\n              docs.push({\n                a: i\n              });\n            }\n            collection.insertMany(docs, configuration.writeConcernMax(), callback);\n          }\n          function finished() {\n            collection.count((err, count) => {\n              expect(err).to.not.exist;\n              test.equal(1000, count);\n            });\n            var total = 0;\n            collection.find().forEach(doc => {\n              total = total + doc.a;\n            }, err => {\n              expect(err).to.not.exist;\n              test.equal(499500, total);\n              collection.count((err, count) => {\n                expect(err).to.not.exist;\n                test.equal(1000, count);\n              });\n              collection.count((err, count) => {\n                expect(err).to.not.exist;\n                test.equal(1000, count);\n                var total2 = 0;\n                collection.find().forEach(doc => {\n                  total2 = total2 + doc.a;\n                }, err => {\n                  expect(err).to.not.exist;\n                  expect(total2).to.equal(499500);\n                  collection.count((err, count) => {\n                    expect(err).to.not.exist;\n                    expect(count).to.equal(1000);\n                    expect(total2).to.equal(total);\n                    done();\n                  });\n                });\n              });\n            });\n          }\n          insert(function () {\n            finished();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCloseCursorAfterQueryHasBeenSent","suites":["Cursor"],"updatePoint":{"line":1250,"column":44,"index":41567},"line":1250,"code":"  it('shouldCloseCursorAfterQueryHasBeenSent', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_close_after_query_sent', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find({\n              a: 1\n            });\n            cursor.next(err => {\n              expect(err).to.not.exist;\n              cursor.close(err => {\n                expect(err).to.not.exist;\n                test.equal(true, cursor.closed);\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteCursorCountWithFields","suites":["Cursor"],"updatePoint":{"line":1286,"column":49,"index":42739},"line":1286,"code":"  it('shouldCorrectlyExecuteCursorCountWithFields', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_count_with_fields', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insertOne({\n            x: 1,\n            a: 2\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            collection.find({}).project({\n              a: 1\n            }).toArray((err, items) => {\n              expect(err).to.not.exist;\n              test.equal(1, items.length);\n              test.equal(2, items[0].a);\n              expect(items[0].x).to.not.exist;\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCountWithFieldsUsingExclude","suites":["Cursor"],"updatePoint":{"line":1321,"column":48,"index":43899},"line":1321,"code":"  it('shouldCorrectlyCountWithFieldsUsingExclude', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_count_with_fields_using_exclude', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insertOne({\n            x: 1,\n            a: 2\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            collection.find({}, {\n              projection: {\n                x: 0\n              }\n            }).toArray((err, items) => {\n              expect(err).to.not.exist;\n              test.equal(1, items.length);\n              test.equal(2, items[0].a);\n              expect(items[0].x).to.not.exist;\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute count on cursor","suites":["Cursor"],"updatePoint":{"line":1358,"column":46,"index":45109},"line":1358,"code":"  it('Should correctly execute count on cursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      for (var i = 0; i < 1000; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('Should_correctly_execute_count_on_cursor_1', (err, collection) => {\n          expect(err).to.not.exist;\n\n          // insert all docs\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            let total = 0;\n            // Create a cursor for the content\n            const cursor = collection.find({});\n            this.defer(() => cursor.close());\n            cursor.count(err => {\n              expect(err).to.not.exist;\n              // Ensure each returns all documents\n              cursor.forEach(() => {\n                total++;\n              }, err => {\n                expect(err).to.not.exist;\n                cursor.count((err, c) => {\n                  expect(err).to.not.exist;\n                  expect(c).to.equal(1000);\n                  expect(total).to.equal(1000);\n                  done();\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"does not auto destroy streams","suites":["Cursor"],"updatePoint":{"line":1410,"column":35,"index":46827},"line":1410,"code":"  it('does not auto destroy streams', function (done) {\n    const docs = [];\n    for (var i = 0; i < 10; i++) {\n      docs.push({\n        a: i + 1\n      });\n    }\n    const configuration = this.configuration;\n    client.connect((err, client) => {\n      expect(err).to.not.exist;\n      const db = client.db(configuration.db);\n      db.createCollection('does_not_autodestroy_streams', (err, collection) => {\n        expect(err).to.not.exist;\n        collection.insertMany(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n          const cursor = collection.find();\n          const stream = cursor.stream();\n          stream.on('close', () => {\n            expect.fail('extra close event must not be called');\n          });\n          stream.on('end', () => {\n            client.close();\n            done();\n          });\n          stream.on('data', doc => {\n            expect(doc).to.exist;\n          });\n          stream.resume();\n        });\n      });\n    });\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should be able to stream documents","suites":["Cursor"],"updatePoint":{"line":1442,"column":40,"index":47833},"line":1442,"code":"  it('should be able to stream documents', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      for (var i = 0; i < 1000; i++) {\n        docs[i] = {\n          a: i + 1\n        };\n      }\n      var count = 0;\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('Should_be_able_to_stream_documents', (err, collection) => {\n          expect(err).to.not.exist;\n\n          // insert all docs\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            var paused = 0,\n              closed = 0,\n              resumed = 0,\n              i = 0;\n            const cursor = collection.find();\n            const stream = cursor.stream();\n            stream.on('data', function (doc) {\n              test.equal(true, !!doc);\n              test.equal(true, !!doc.a);\n              count = count + 1;\n              if (paused > 0 && 0 === resumed) {\n                err = new Error('data emitted during pause');\n                return testDone();\n              }\n              if (++i === 3) {\n                stream.pause();\n                paused++;\n                setTimeout(function () {\n                  stream.resume();\n                  resumed++;\n                }, 20);\n              }\n            });\n            stream.once('error', function (er) {\n              err = er;\n              testDone();\n            });\n            stream.once('end', function () {\n              closed++;\n              testDone();\n            });\n            function testDone() {\n              expect(err).to.not.exist;\n              test.equal(i, docs.length);\n              test.equal(1, closed);\n              test.equal(1, paused);\n              test.equal(1, resumed);\n              test.strictEqual(cursor.closed, true);\n              done();\n            }\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"immediately destroying a stream prevents the query from executing","suites":["Cursor"],"updatePoint":{"line":1514,"column":71,"index":50146},"line":1514,"code":"  it('immediately destroying a stream prevents the query from executing', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var i = 0,\n        docs = [{\n          b: 2\n        }, {\n          b: 3\n        }],\n        doneCalled = 0;\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('immediately_destroying_a_stream_prevents_the_query_from_executing', (err, collection) => {\n          expect(err).to.not.exist;\n\n          // insert all docs\n          collection.insertMany(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find();\n            const stream = cursor.stream();\n            stream.on('data', function () {\n              i++;\n            });\n            cursor.once('close', testDone('close'));\n            stream.once('error', testDone('error'));\n            stream.destroy();\n            function testDone() {\n              return err => {\n                ++doneCalled;\n                if (doneCalled === 1) {\n                  expect(err).to.not.exist;\n                  test.strictEqual(0, i);\n                  test.strictEqual(true, cursor.closed);\n                  done();\n                }\n              };\n            }\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"removes session when cloning an find cursor","suites":["Cursor"],"updatePoint":{"line":1565,"column":49,"index":51797},"line":1565,"code":"  it('removes session when cloning an find cursor', async function () {\n    const collection = await client.db().collection('test');\n    const cursor = collection.find({});\n    const clonedCursor = cursor.clone();\n    expect(cursor).to.have.property('session');\n    expect(clonedCursor).to.have.property('session');\n    expect(cursor.session).to.not.equal(clonedCursor.session);\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"removes session when cloning an aggregation cursor","suites":["Cursor"],"updatePoint":{"line":1573,"column":56,"index":52189},"line":1573,"code":"  it('removes session when cloning an aggregation cursor', async function () {\n    const collection = await client.db().collection('test');\n    const cursor = collection.aggregate([{\n      $match: {}\n    }]);\n    const clonedCursor = cursor.clone();\n    expect(cursor).to.have.property('session');\n    expect(clonedCursor).to.have.property('session');\n    expect(cursor.session).to.not.equal(clonedCursor.session);\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"destroying a stream stops it","suites":["Cursor"],"updatePoint":{"line":1583,"column":34,"index":52588},"line":1583,"code":"  it('destroying a stream stops it', async function () {\n    const db = client.db();\n    await db.dropCollection('destroying_a_stream_stops_it').catch(() => null);\n    const collection = await db.createCollection('destroying_a_stream_stops_it');\n    const docs = Array.from({\n      length: 10\n    }, (_, i) => ({\n      b: i + 1\n    }));\n    await collection.insertMany(docs);\n    const cursor = collection.find();\n    const stream = cursor.stream();\n    expect(cursor).property('closed', false);\n    const willClose = once(cursor, 'close');\n    const willEnd = once(stream, 'end');\n    const dataEvents = on(stream, 'data');\n    for (let i = 0; i < 5; i++) {\n      let {\n        value: [doc]\n      } = await dataEvents.next();\n      expect(doc).property('b', i + 1);\n    }\n\n    // After 5 successful data events, destroy stream\n    stream.destroy();\n\n    // We should get an end event on the stream and a close event on the cursor\n    // We should **not** get an 'error' event,\n    // the following will throw if either stream or cursor emitted an 'error' event\n    await Promise.race([willEnd, sleep(100).then(() => Promise.reject(new Error('end event never emitted')))]);\n    await Promise.race([willClose, sleep(100).then(() => Promise.reject(new Error('close event never emitted')))]);\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"cursor stream errors","suites":["Cursor"],"line":1617,"code":"  it.skip('cursor stream errors', {","file":"integration/crud/misc_cursors.test.js","skipped":true,"dir":"test"},{"name":"cursor stream pipe","suites":["Cursor"],"updatePoint":{"line":1675,"column":24,"index":55809},"line":1675,"code":"  it('cursor stream pipe', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('cursor_stream_pipe', (err, collection) => {\n          expect(err).to.not.exist;\n          var docs = [];\n          'Aaden Aaron Adrian Aditya Bob Joe'.split(' ').forEach(function (name) {\n            docs.push({\n              name: name\n            });\n          });\n\n          // insert all docs\n          collection.insertMany(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const filename = path.join(os.tmpdir(), '_nodemongodbnative_stream_out.txt');\n            const out = fs.createWriteStream(filename);\n            const stream = collection.find().stream({\n              transform: doc => JSON.stringify(doc)\n            });\n            stream.pipe(out);\n            // Wait for output stream to close\n            out.on('close', testDone);\n            function testDone(err) {\n              // Object.prototype.toString = toString;\n              test.strictEqual(undefined, err);\n              var contents = fs.readFileSync(filename, 'utf8');\n              test.ok(/Aaden/.test(contents));\n              test.ok(/Aaron/.test(contents));\n              test.ok(/Adrian/.test(contents));\n              test.ok(/Aditya/.test(contents));\n              test.ok(/Bob/.test(contents));\n              test.ok(/Joe/.test(contents));\n              fs.unlinkSync(filename);\n              done();\n            }\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"closes cursors when client is closed even if it has not been exhausted","suites":["Cursor"],"updatePoint":{"line":1727,"column":76,"index":57799},"line":1727,"code":"  it('closes cursors when client is closed even if it has not been exhausted', async function () {\n    await client.db().dropCollection('test_cleanup_tailable').catch(() => null);\n    const collection = await client.db().createCollection('test_cleanup_tailable', {\n      capped: true,\n      size: 1000,\n      max: 3\n    });\n\n    // insert only 2 docs in capped coll of 3\n    await collection.insertMany([{\n      a: 1\n    }, {\n      a: 1\n    }]);\n    const cursor = collection.find({}, {\n      tailable: true,\n      awaitData: true,\n      maxAwaitTimeMS: 2000\n    });\n    await cursor.next();\n    await cursor.next();\n    // will block for maxAwaitTimeMS (except we are closing the client)\n    const rejectedEarlyBecauseClientClosed = cursor.next().catch(error => error);\n    await client.close();\n    expect(cursor).to.have.property('killed', true);\n    const error = await rejectedEarlyBecauseClientClosed;\n    expect(error).to.be.instanceOf(MongoExpiredSessionError);\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldAwaitData","suites":["Cursor"],"updatePoint":{"line":1755,"column":21,"index":58720},"line":1755,"code":"  it('shouldAwaitData', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      // www.mongodb.com/docs/display/DOCS/Tailable+Cursors\n\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        const options = {\n          capped: true,\n          size: 8\n        };\n        db.createCollection('should_await_data_retry_tailable_cursor', options, (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n\n            // Create cursor with awaitData, and timeout after the period specified\n            const cursor = collection.find({}, {\n              tailable: true,\n              awaitData: true\n            });\n            this.defer(() => cursor.close());\n\n            // Execute each\n            cursor.forEach(() => cursor.close(), () => {\n              // Even though cursor is exhausted, should not close session\n              // unless cursor is manually closed, due to awaitData / tailable\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldAwaitDataWithDocumentsAvailable","suites":["Cursor"],"updatePoint":{"line":1800,"column":43,"index":60243},"line":1800,"code":"  it('shouldAwaitDataWithDocumentsAvailable', function (done) {\n    // www.mongodb.com/docs/display/DOCS/Tailable+Cursors\n\n    const configuration = this.configuration;\n    const client = configuration.newClient({\n      maxPoolSize: 1\n    });\n    client.connect((err, client) => {\n      expect(err).to.not.exist;\n      this.defer(() => client.close());\n      const db = client.db(configuration.db);\n      const options = {\n        capped: true,\n        size: 8\n      };\n      db.createCollection('should_await_data_no_docs', options, (err, collection) => {\n        expect(err).to.not.exist;\n\n        // Create cursor with awaitData, and timeout after the period specified\n        const cursor = collection.find({}, {\n          tailable: true,\n          awaitData: true\n        });\n        this.defer(() => cursor.close());\n        cursor.forEach(() => {}, err => {\n          expect(err).to.not.exist;\n          done();\n        });\n      });\n    });\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should block waiting for new data to arrive when the cursor reaches the end of the capped collection","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":1841,"column":108,"index":61566},"line":1841,"code":"    it('should block waiting for new data to arrive when the cursor reaches the end of the capped collection', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.2'\n        }\n      },\n      async test() {\n        const db = client.db('cursor_tailable');\n        try {\n          await db.collection('cursor_tailable').drop();\n          // eslint-disable-next-line no-empty\n        } catch (_) {}\n        const collection = await db.createCollection('cursor_tailable', {\n          capped: true,\n          size: 10000\n        });\n        const res = await collection.insertOne({\n          a: 1\n        });\n        expect(res).property('insertedId').to.exist;\n        cursor = collection.find({}, {\n          batchSize: 2,\n          tailable: true,\n          awaitData: true\n        });\n        const doc0 = await cursor.next();\n        expect(doc0).to.have.property('a', 1);\n\n        // After 300ms make an insert\n        const later = runLater(async () => {\n          const res = await collection.insertOne({\n            b: 2\n          });\n          expect(res).property('insertedId').to.exist;\n        }, 300);\n        const start = new Date();\n        const doc1 = await cursor.next();\n        expect(doc1).to.have.property('b', 2);\n        const end = new Date();\n        await later; // make sure this finished, without a failure\n\n        // We should see here that cursor.next blocked for at least 300ms\n        expect(end.getTime() - start.getTime()).to.be.at.least(300);\n      }\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly retry tailable cursor connection","suites":["Cursor","awaiting data core tailable cursor test"],"line":1889,"code":"  it.skip('Should correctly retry tailable cursor connection', {","file":"integration/crud/misc_cursors.test.js","skipped":true,"dir":"test"},{"name":"shouldCorrectExecuteExplainHonoringLimit","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":1930,"column":46,"index":64449},"line":1930,"code":"  it('shouldCorrectExecuteExplainHonoringLimit', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      docs[0] = {\n        _keywords: ['compact', 'ii2gd', 'led', '24-48v', 'presse-etoupe', 'bexbgl1d24483', 'flash', '48v', 'eexd', 'feu', 'presse', 'compris', 'rouge', 'etoupe', 'iic', 'ii2gdeexdiict5', 'red', 'aet']\n      };\n      docs[1] = {\n        _keywords: ['reducteur', '06212', 'd20/16', 'manch', 'd20', 'manchon', 'ard', 'sable', 'irl', 'red']\n      };\n      docs[2] = {\n        _keywords: ['reducteur', '06214', 'manch', 'd25/20', 'd25', 'manchon', 'ard', 'sable', 'irl', 'red']\n      };\n      docs[3] = {\n        _keywords: ['bar', 'rac', 'boite', '6790178', '50-240/4-35', '240', 'branch', 'coulee', 'ddc', 'red', 'ip2x']\n      };\n      docs[4] = {\n        _keywords: ['bar', 'ip2x', 'boite', '6790158', 'ddi', '240', 'branch', 'injectee', '50-240/4-35?', 'red']\n      };\n      docs[5] = {\n        _keywords: ['bar', 'ip2x', 'boite', '6790179', 'coulee', '240', 'branch', 'sdc', '50-240/4-35?', 'red', 'rac']\n      };\n      docs[6] = {\n        _keywords: ['bar', 'ip2x', 'boite', '6790159', '240', 'branch', 'injectee', '50-240/4-35?', 'sdi', 'red']\n      };\n      docs[7] = {\n        _keywords: ['6000', 'r-6000', 'resin', 'high', '739680', 'red', 'performance', 'brd', 'with', 'ribbon', 'flanges']\n      };\n      docs[8] = {\n        _keywords: ['804320', 'for', 'paint', 'roads', 'brd', 'red']\n      };\n      docs[9] = {\n        _keywords: ['38mm', 'padlock', 'safety', '813594', 'brd', 'red']\n      };\n      docs[10] = {\n        _keywords: ['114551', 'r6900', 'for', 'red', 'bmp71', 'brd', 'ribbon']\n      };\n      docs[11] = {\n        _keywords: ['catena', 'diameter', '621482', 'rings', 'brd', 'legend', 'red', '2mm']\n      };\n      docs[12] = {\n        _keywords: ['catena', 'diameter', '621491', 'rings', '5mm', 'brd', 'legend', 'red']\n      };\n      docs[13] = {\n        _keywords: ['catena', 'diameter', '621499', 'rings', '3mm', 'brd', 'legend', 'red']\n      };\n      docs[14] = {\n        _keywords: ['catena', 'diameter', '621508', 'rings', '5mm', 'brd', 'legend', 'red']\n      };\n      docs[15] = {\n        _keywords: ['insert', 'for', 'cable', '3mm', 'carrier', '621540', 'blank', 'brd', 'ademark', 'red']\n      };\n      docs[16] = {\n        _keywords: ['insert', 'for', 'cable', '621544', '3mm', 'carrier', 'brd', 'ademark', 'legend', 'red']\n      };\n      docs[17] = {\n        _keywords: ['catena', 'diameter', '6mm', '621518', 'rings', 'brd', 'legend', 'red']\n      };\n      docs[18] = {\n        _keywords: ['catena', 'diameter', '621455', '8mm', 'rings', 'brd', 'legend', 'red']\n      };\n      docs[19] = {\n        _keywords: ['catena', 'diameter', '621464', 'rings', '5mm', 'brd', 'legend', 'red']\n      };\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        // Insert all the docs\n        var collection = db.collection('shouldCorrectExecuteExplainHonoringLimit');\n        collection.insert(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n          collection.createIndex({\n            _keywords: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            collection.find({\n              _keywords: 'red'\n            }).limit(10).toArray(function (err, result) {\n              expect(err).to.not.exist;\n              test.ok(result != null);\n              collection.find({\n                _keywords: 'red'\n              }, {}).limit(10).explain(function (err, result) {\n                expect(err).to.not.exist;\n                test.ok(result != null);\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldNotExplainWhenFalse","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2031,"column":31,"index":68513},"line":2031,"code":"  it('shouldNotExplainWhenFalse', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var doc = {\n        name: 'camera',\n        _keywords: ['compact', 'ii2gd', 'led', 'red', 'aet']\n      };\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var collection = db.collection('shouldNotExplainWhenFalse');\n        collection.insert(doc, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n          collection.find({\n            _keywords: 'red'\n          }).limit(10).toArray(function (err, result) {\n            expect(err).to.not.exist;\n            test.equal('camera', result[0].name);\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldFailToSetReadPreferenceOnCursor","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2063,"column":43,"index":69594},"line":2063,"code":"  it('shouldFailToSetReadPreferenceOnCursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        try {\n          db.collection('shouldFailToSetReadPreferenceOnCursor').find().withReadPreference('notsecondary');\n          test.ok(false);\n        } catch (err) {} // eslint-disable-line\n\n        db.collection('shouldFailToSetReadPreferenceOnCursor').find().withReadPreference('secondary');\n        done();\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should allow setting the cursors readConcern through a builder","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2087,"column":68,"index":70479},"line":2087,"code":"  it('should allow setting the cursors readConcern through a builder', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.2'\n      }\n    },\n    test: function (done) {\n      const client = this.configuration.newClient({\n        monitorCommands: true\n      });\n      const events = [];\n      client.on('commandStarted', event => {\n        if (event.commandName === 'find') {\n          events.push(event);\n        }\n      });\n      const db = client.db(this.configuration.db);\n      const cursor = db.collection('foo').find().withReadConcern('local');\n      expect(cursor).property('readConcern').to.have.property('level').equal('local');\n      cursor.toArray(err => {\n        expect(err).to.not.exist;\n        expect(events).to.have.length(1);\n        const findCommand = events[0];\n        expect(findCommand).nested.property('command.readConcern').to.eql({\n          level: 'local'\n        });\n        client.close(done);\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldNotFailDueToStackOverflowEach","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2117,"column":41,"index":71404},"line":2117,"code":"  it('shouldNotFailDueToStackOverflowEach', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('shouldNotFailDueToStackOverflowEach', (err, collection) => {\n          expect(err).to.not.exist;\n          var docs = [];\n          var total = 0;\n          for (var i = 0; i < 30000; i++) docs.push({\n            a: i\n          });\n          var allDocs = [];\n          var left = 0;\n          while (docs.length > 0) {\n            allDocs.push(docs.splice(0, 1000));\n          }\n          // Get all batches we must insert\n          left = allDocs.length;\n          var totalI = 0;\n\n          // Execute inserts\n          for (i = 0; i < left; i++) {\n            collection.insert(allDocs.shift(), configuration.writeConcernMax(), function (err, d) {\n              expect(err).to.not.exist;\n              left = left - 1;\n              totalI = totalI + d.length;\n              if (left === 0) {\n                collection.find({}).forEach(() => {\n                  total++;\n                }, err => {\n                  expect(err).to.not.exist;\n                  expect(total).to.equal(30000);\n                  done();\n                });\n              }\n            });\n          }\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should not fail due to stack overflow toArray","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2168,"column":51,"index":73084},"line":2168,"code":"  it('should not fail due to stack overflow toArray', async function () {\n    const configuration = this.configuration;\n    const db = client.db(configuration.db);\n    const collection = await db.createCollection('shouldNotFailDueToStackOverflowToArray');\n    var docs = Array.from({\n      length: 30000\n    }, (_, i) => ({\n      a: i\n    }));\n    var allDocs = [];\n    var left = 0;\n    while (docs.length > 0) {\n      allDocs.push(docs.splice(0, 1000));\n    }\n    // Get all batches we must insert\n    left = allDocs.length;\n    var totalI = 0;\n    var timeout = 0;\n\n    // Execute inserts\n    for (let i = 0; i < left; i++) {\n      await sleep(timeout);\n      const d = await collection.insert(allDocs.shift());\n      left = left - 1;\n      totalI = totalI + d.length;\n      if (left === 0) {\n        const items = await collection.find({}).toArray();\n        expect(items).to.have.a.lengthOf(3000);\n      }\n      timeout = timeout + 100;\n    }\n    await client.close();\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should correctly skip and limit","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2201,"column":37,"index":74050},"line":2201,"code":"  it('should correctly skip and limit', function (done) {\n    const configuration = this.configuration;\n    client.connect((err, client) => {\n      expect(err).to.not.exist;\n      const db = client.db(configuration.db);\n      var collection = db.collection('shouldCorrectlySkipAndLimit');\n      var docs = [];\n      for (var i = 0; i < 100; i++) docs.push({\n        a: i,\n        OrderNumber: i\n      });\n      collection.insert(docs, configuration.writeConcernMax(), err => {\n        expect(err).to.not.exist;\n        collection.find({}, {\n          OrderNumber: 1\n        }).skip(10).limit(10).toArray((err, items) => {\n          expect(err).to.not.exist;\n          test.equal(10, items[0].OrderNumber);\n          collection.find({}, {\n            OrderNumber: 1\n          }).skip(10).limit(10).count().then(count => {\n            test.equal(10, count);\n            client.close(done);\n          });\n        });\n      });\n    });\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldFailToTailANormalCollection","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2229,"column":39,"index":74990},"line":2229,"code":"  it('shouldFailToTailANormalCollection', function (done) {\n    const configuration = this.configuration;\n    client.connect((err, client) => {\n      expect(err).to.not.exist;\n      this.defer(() => client.close());\n      const db = client.db(configuration.db);\n      var collection = db.collection('shouldFailToTailANormalCollection');\n      var docs = [];\n      for (var i = 0; i < 100; i++) docs.push({\n        a: i,\n        OrderNumber: i\n      });\n      collection.insert(docs, configuration.writeConcernMax(), err => {\n        expect(err).to.not.exist;\n        const cursor = collection.find({}, {\n          tailable: true\n        });\n        cursor.forEach(() => {}, err => {\n          test.ok(err instanceof Error);\n          test.ok(typeof err.code === 'number');\n\n          // Close cursor b/c we did not exhaust cursor\n          cursor.close();\n          done();\n        });\n      });\n    });\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUseFindAndCursorCount","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2257,"column":42,"index":75903},"line":2257,"code":"  it('shouldCorrectlyUseFindAndCursorCount', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n\n      // DOC_LINE var client = new MongoClient(new Server('localhost', 27017));\n      // DOC_START\n      // Establish connection to db\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n\n        // Create a lot of documents to insert\n        var docs = [];\n        for (var i = 0; i < 100; i++) {\n          docs.push({\n            a: i\n          });\n        }\n\n        // Create a collection\n        db.createCollection('test_close_function_on_cursor_2', (err, collection) => {\n          expect(err).to.not.exist;\n\n          // Insert documents into collection\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find({});\n            cursor.count((err, count) => {\n              expect(err).to.not.exist;\n              test.equal(100, count);\n              done();\n            });\n          });\n        });\n      });\n      // DOC_END\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should correctly apply hint to count command for cursor","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2304,"column":61,"index":77341},"line":2304,"code":"  it('should correctly apply hint to count command for cursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded'],\n        mongodb: '>2.5.5'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n\n      // DOC_LINE var client = new MongoClient(new Server('localhost', 27017));\n      // DOC_START\n      // Establish connection to db\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var col = db.collection('count_hint');\n        col.insert([{\n          i: 1\n        }, {\n          i: 2\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, err => {\n          expect(err).to.not.exist;\n          col.createIndex({\n            i: 1\n          }, err => {\n            expect(err).to.not.exist;\n            col.find({\n              i: 1\n            }, {\n              hint: '_id_'\n            }).count((err, count) => {\n              expect(err).to.not.exist;\n              test.equal(1, count);\n              col.find({}, {\n                hint: '_id_'\n              }).count((err, count) => {\n                expect(err).to.not.exist;\n                test.equal(2, count);\n                col.find({\n                  i: 1\n                }, {\n                  hint: 'BAD HINT'\n                }).count(err => {\n                  test.ok(err != null);\n                  col.createIndex({\n                    x: 1\n                  }, {\n                    sparse: true\n                  }, err => {\n                    expect(err).to.not.exist;\n                    col.find({\n                      i: 1\n                    }, {\n                      hint: 'x_1'\n                    }).count((err, count) => {\n                      expect(err).to.not.exist;\n                      test.equal(0, count);\n                      col.find({}, {\n                        hint: 'i_1'\n                      }).count((err, count) => {\n                        expect(err).to.not.exist;\n                        test.equal(2, count);\n                        done();\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n      // DOC_END\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Terminate each after first document by returning false","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2388,"column":60,"index":79836},"line":2388,"code":"  it('Terminate each after first document by returning false', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n\n        // Create a lot of documents to insert\n        var docs = [];\n        for (var i = 0; i < 100; i++) {\n          docs.push({\n            a: i\n          });\n        }\n\n        // Create a collection\n        db.createCollection('terminate_each_returning_false', (err, collection) => {\n          expect(err).to.not.exist;\n\n          // Insert documents into collection\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            var finished = false;\n            collection.find({}).forEach(doc => {\n              expect(doc).to.exist;\n              test.equal(finished, false);\n              finished = true;\n              done();\n              return false;\n            }, err => {\n              expect(err).to.not.exist;\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly handle maxTimeMS as part of findOne options","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2433,"column":66,"index":81240},"line":2433,"code":"  it('Should correctly handle maxTimeMS as part of findOne options', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var donkey = {\n          color: 'brown'\n        };\n        db.collection('donkies').insertOne(donkey, function (err, result) {\n          expect(err).to.not.exist;\n          var query = {\n            _id: result.insertedId\n          };\n          var options = {\n            maxTimeMS: 1000\n          };\n          db.collection('donkies').findOne(query, options, function (err, doc) {\n            expect(err).to.not.exist;\n            test.equal('brown', doc.color);\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly handle batchSize of 2","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2467,"column":44,"index":82304},"line":2467,"code":"  it('Should correctly handle batchSize of 2', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        const collectionName = 'should_correctly_handle_batchSize_2';\n        db.collection(collectionName).insert([{\n          x: 1\n        }, {\n          x: 2\n        }, {\n          x: 3\n        }], err => {\n          expect(err).to.not.exist;\n          const cursor = db.collection(collectionName).find({}, {\n            batchSize: 2\n          });\n          this.defer(() => cursor.close());\n          cursor.next(err => {\n            expect(err).to.not.exist;\n            cursor.next(err => {\n              expect(err).to.not.exist;\n              cursor.next(err => {\n                expect(err).to.not.exist;\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should report database name and collection name","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2508,"column":53,"index":83556},"line":2508,"code":"  it('Should report database name and collection name', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        const cursor = db.collection('myCollection').find({});\n        test.equal('myCollection', cursor.namespace.collection);\n        test.equal('integration_tests', cursor.namespace.db);\n        done();\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute count on cursor with maxTimeMS","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2527,"column":61,"index":84168},"line":2527,"code":"  it('Should correctly execute count on cursor with maxTimeMS', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      for (var i = 0; i < 1000; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('Should_correctly_execute_count_on_cursor_2', function (err, collection) {\n          expect(err).to.not.exist;\n\n          // insert all docs\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n\n            // Create a cursor for the content\n            var cursor = collection.find({});\n            cursor.limit(100);\n            cursor.skip(10);\n            cursor.count({\n              maxTimeMS: 1000\n            }, err => {\n              expect(err).to.not.exist;\n\n              // Create a cursor for the content\n              var cursor = collection.find({});\n              cursor.limit(100);\n              cursor.skip(10);\n              cursor.maxTimeMS(100);\n              cursor.count(err => {\n                expect(err).to.not.exist;\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute count on cursor with maxTimeMS set using legacy method","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2580,"column":85,"index":85870},"line":2580,"code":"  it('Should correctly execute count on cursor with maxTimeMS set using legacy method', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      for (var i = 0; i < 1000; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('Should_correctly_execute_count_on_cursor_3', function (err, collection) {\n          expect(err).to.not.exist;\n\n          // insert all docs\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n\n            // Create a cursor for the content\n            var cursor = collection.find({}, {\n              maxTimeMS: 100\n            });\n            cursor.toArray(err => {\n              expect(err).to.not.exist;\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply map to toArray","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2622,"column":43,"index":87174},"line":2622,"code":"  it('Should correctly apply map to toArray', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      for (var i = 0; i < 1000; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var collection = db.collection('map_toArray');\n\n        // insert all docs\n        collection.insert(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n\n          // Create a cursor for the content\n          var cursor = collection.find({}).map(function () {\n            return {\n              a: 1\n            };\n          }).batchSize(5).limit(10);\n          cursor.toArray(function (err, docs) {\n            expect(err).to.not.exist;\n            test.equal(10, docs.length);\n\n            // Ensure all docs where mapped\n            docs.forEach(doc => {\n              expect(doc).property('a').to.equal(1);\n            });\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply map to next","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2670,"column":40,"index":88625},"line":2670,"code":"  it('Should correctly apply map to next', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const docs = [];\n      for (var i = 0; i < 1000; i++) {\n        const d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        const collection = db.collection('map_next');\n\n        // insert all docs\n        collection.insert(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n\n          // Create a cursor for the content\n          const cursor = collection.find({}).map(function () {\n            return {\n              a: 1\n            };\n          }).batchSize(5).limit(10);\n          this.defer(() => cursor.close());\n          cursor.next((err, doc) => {\n            expect(err).to.not.exist;\n            test.equal(1, doc.a);\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply map to each","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2714,"column":40,"index":89960},"line":2714,"code":"  it('Should correctly apply map to each', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      for (var i = 0; i < 1000; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        const collection = db.collection('map_each');\n\n        // insert all docs\n        collection.insert(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n\n          // Create a cursor for the content\n          var cursor = collection.find({}).map(function () {\n            return {\n              a: 1\n            };\n          }).batchSize(5).limit(10);\n          cursor.forEach(doc => {\n            test.equal(1, doc.a);\n          }, err => {\n            expect(err).to.not.exist;\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply map to forEach","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2758,"column":43,"index":91266},"line":2758,"code":"  it('Should correctly apply map to forEach', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      for (var i = 0; i < 1000; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var collection = db.collection('map_forEach');\n\n        // insert all docs\n        collection.insert(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n\n          // Create a cursor for the content\n          var cursor = collection.find({}).map(function () {\n            return {\n              a: 2\n            };\n          }).map(function (x) {\n            return {\n              a: x.a * x.a\n            };\n          }).batchSize(5).limit(10);\n          cursor.forEach(doc => {\n            test.equal(4, doc.a);\n          }, err => {\n            expect(err).to.not.exist;\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply multiple uses of map and apply forEach","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2806,"column":67,"index":92692},"line":2806,"code":"  it('Should correctly apply multiple uses of map and apply forEach', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      for (var i = 0; i < 1000; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var collection = db.collection('map_mapmapforEach');\n\n        // insert all docs\n        collection.insert(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n\n          // Create a cursor for the content\n          var cursor = collection.find({}).map(function () {\n            return {\n              a: 1\n            };\n          }).batchSize(5).limit(10);\n          cursor.forEach(doc => {\n            expect(doc).property('a').to.equal(1);\n          }, err => {\n            expect(err).to.not.exist;\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply skip and limit to large set of documents","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2850,"column":69,"index":94048},"line":2850,"code":"  it('Should correctly apply skip and limit to large set of documents', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var collection = db.collection('cursor_limit_skip_correctly');\n\n        // Insert x number of docs\n        var ordered = collection.initializeUnorderedBulkOp();\n        for (var i = 0; i < 6000; i++) {\n          ordered.insert({\n            a: i\n          });\n        }\n        ordered.execute({\n          writeConcern: {\n            w: 1\n          }\n        }, err => {\n          expect(err).to.not.exist;\n\n          // Let's attempt to skip and limit\n          collection.find({}).limit(2016).skip(2016).toArray(function (err, docs) {\n            expect(err).to.not.exist;\n            test.equal(2016, docs.length);\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should tail cursor using maxAwaitTimeMS for 3.2 or higher","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2890,"column":63,"index":95273},"line":2890,"code":"  it('should tail cursor using maxAwaitTimeMS for 3.2 or higher', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '<7.0.0'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var options = {\n          capped: true,\n          size: 8\n        };\n        db.createCollection('should_await_data_max_awaittime_ms', options, function (err, collection) {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n\n            // Create cursor with awaitData, and timeout after the period specified\n            var cursor = collection.find({}).addCursorFlag('tailable', true).addCursorFlag('awaitData', true).maxAwaitTimeMS(500);\n            const s = new Date();\n            cursor.forEach(() => {\n              setTimeout(() => cursor.close(), 300);\n            }, () => {\n              test.ok(new Date().getTime() - s.getTime() >= 500);\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should not emit any events after close event emitted due to cursor killed","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2931,"column":79,"index":96751},"line":2931,"code":"  it('Should not emit any events after close event emitted due to cursor killed', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var collection = db.collection('cursor_limit_skip_correctly');\n\n        // Insert x number of docs\n        var ordered = collection.initializeUnorderedBulkOp();\n        for (var i = 0; i < 100; i++) {\n          ordered.insert({\n            a: i\n          });\n        }\n        ordered.execute({\n          writeConcern: {\n            w: 1\n          }\n        }, err => {\n          expect(err).to.not.exist;\n\n          // Let's attempt to skip and limit\n          var cursor = collection.find({}).batchSize(10);\n          const stream = cursor.stream();\n          stream.on('data', function () {\n            stream.destroy();\n          });\n          cursor.on('close', function () {\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteEnsureIndexWithNoCallback","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2974,"column":53,"index":98029},"line":2974,"code":"  it('shouldCorrectlyExecuteEnsureIndexWithNoCallback', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      for (var i = 0; i < 1; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          createdAt: new Date(d)\n        };\n      }\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('shouldCorrectlyExecuteEnsureIndexWithNoCallback', function (err, collection) {\n          expect(err).to.not.exist;\n\n          // ensure index of createdAt index\n          collection.createIndex({\n            createdAt: 1\n          }, err => {\n            expect(err).to.not.exist;\n\n            // insert all docs\n            collection.insert(docs, configuration.writeConcernMax(), err => {\n              expect(err).to.not.exist;\n\n              // Find with sort\n              collection.find().sort(['createdAt', 'asc']).toArray((err, items) => {\n                expect(err).to.not.exist;\n                test.equal(1, items.length);\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute count on cursor with limit and skip","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3020,"column":66,"index":99523},"line":3020,"code":"  it('Should correctly execute count on cursor with limit and skip', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      for (var i = 0; i < 50; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n      const configuration = this.configuration;\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('negative_batch_size_and_limit_set', (err, collection) => {\n          expect(err).to.not.exist;\n\n          // insert all docs\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n\n            // Create a cursor for the content\n            var cursor = collection.find({});\n            cursor.limit(100).skip(0).count(function (err, c) {\n              expect(err).to.not.exist;\n              test.equal(50, c);\n              var cursor = collection.find({});\n              cursor.limit(100).skip(0).toArray(err => {\n                expect(err).to.not.exist;\n                test.equal(50, c);\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly handle negative batchSize and set the limit","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3066,"column":66,"index":101050},"line":3066,"code":"  it('Should correctly handle negative batchSize and set the limit', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      const configuration = this.configuration;\n      for (var i = 0; i < 50; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('Should_correctly_execute_count_on_cursor_1_', function (err, collection) {\n          expect(err).to.not.exist;\n\n          // insert all docs\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n\n            // Create a cursor for the content\n            var cursor = collection.find({});\n            cursor.batchSize(-10).next(err => {\n              expect(err).to.not.exist;\n              test.ok(cursor.id.equals(BSON.Long.ZERO));\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Correctly decorate the cursor count command with skip, limit, hint, readConcern","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3107,"column":85,"index":102418},"line":3107,"code":"  it('Correctly decorate the cursor count command with skip, limit, hint, readConcern', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var started = [];\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      client.on('commandStarted', function (event) {\n        if (event.commandName === 'count') started.push(event);\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.collection('cursor_count_test', {\n          readConcern: {\n            level: 'local'\n          }\n        }).find({\n          project: '123'\n        }).limit(5).skip(5).hint({\n          project: 1\n        }).count(err => {\n          expect(err).to.not.exist;\n          test.equal(1, started.length);\n          if (started[0].command.readConcern) test.deepEqual({\n            level: 'local'\n          }, started[0].command.readConcern);\n          test.deepEqual({\n            project: 1\n          }, started[0].command.hint);\n          test.equal(5, started[0].command.skip);\n          test.equal(5, started[0].command.limit);\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Correctly decorate the collection count command with skip, limit, hint, readConcern","suites":["Cursor","awaiting data core tailable cursor test"],"line":3153,"code":"  it.skip('Correctly decorate the collection count command with skip, limit, hint, readConcern', {","file":"integration/crud/misc_cursors.test.js","skipped":true,"dir":"test"},{"name":"Should properly kill a cursor","suites":["Cursor","awaiting data core tailable cursor test"],"line":3204,"code":"  it.skip('Should properly kill a cursor', {","file":"integration/crud/misc_cursors.test.js","skipped":true,"dir":"test"},{"name":"should return implicit session to pool when client-side cursor exhausts results on initial query","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3263,"column":102,"index":107782},"line":3263,"code":"  it('should return implicit session to pool when client-side cursor exhausts results on initial query', async function () {\n    const configuration = this.configuration;\n    const client = configuration.newClient();\n    await client.connect();\n    const db = client.db(configuration.db);\n    const collection = db.collection('cursor_session_tests');\n    await collection.insertMany([{\n      a: 1,\n      b: 2\n    }]);\n    const cursor = collection.find({});\n    await cursor.next(); // implicit close, cursor is exhausted\n    expect(client.s.activeSessions.size).to.equal(0);\n    await cursor.close();\n    await client.close();\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should return implicit session to pool when client-side cursor exhausts results after a getMore","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3279,"column":101,"index":108415},"line":3279,"code":"  it('should return implicit session to pool when client-side cursor exhausts results after a getMore', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    const db = client.db(configuration.db);\n    const collection = db.collection('cursor_session_tests2');\n    const docs = [{\n      a: 1,\n      b: 2\n    }, {\n      a: 3,\n      b: 4\n    }, {\n      a: 5,\n      b: 6\n    }, {\n      a: 7,\n      b: 8\n    }, {\n      a: 9,\n      b: 10\n    }];\n    collection.insertMany(docs, err => {\n      expect(err).to.not.exist;\n      const cursor = collection.find({}, {\n        batchSize: 3\n      });\n      cursor.next(function () {\n        expect(client.s.activeSessions.size).to.equal(1);\n        cursor.next(function () {\n          expect(client.s.activeSessions.size).to.equal(1);\n          cursor.next(function () {\n            expect(client.s.activeSessions.size).to.equal(1);\n            cursor.next(function () {\n              expect(client.s.activeSessions.size).to.equal(0);\n              cursor.close(() => {\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    });\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"removes the existing session from the cloned cursor","suites":["Cursor","#clone","when executing on a find cursor"],"updatePoint":{"line":3343,"column":61,"index":110078},"line":3343,"code":"      it('removes the existing session from the cloned cursor', function () {\n        const docs = [{\n          name: 'test1'\n        }, {\n          name: 'test2'\n        }];\n        return collection.insertMany(docs).then(() => {\n          const cursor = collection.find({}, {\n            batchSize: 1\n          });\n          return cursor.next().then(doc => {\n            expect(doc).to.exist;\n            const clonedCursor = cursor.clone();\n            expect(clonedCursor.cursorOptions.session).to.not.exist;\n            const kServerSession = getSymbolFrom(clonedCursor.session, 'serverSession');\n            expect(clonedCursor.session).to.have.property(kServerSession, null); // session is brand new and has not been used\n          }).finally(() => {\n            return cursor.close();\n          });\n        });\n      });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"removes the existing session from the cloned cursor","suites":["Cursor","#clone","when executing on an aggregation cursor"],"updatePoint":{"line":3366,"column":61,"index":110985},"line":3366,"code":"      it('removes the existing session from the cloned cursor', function () {\n        const docs = [{\n          name: 'test1'\n        }, {\n          name: 'test2'\n        }];\n        return collection.insertMany(docs).then(() => {\n          const cursor = collection.aggregate([{\n            $match: {}\n          }], {\n            batchSize: 1\n          });\n          return cursor.next().then(doc => {\n            expect(doc).to.exist;\n            const clonedCursor = cursor.clone();\n            expect(clonedCursor.cursorOptions.session).to.not.exist;\n            const kServerSession = getSymbolFrom(clonedCursor.session, 'serverSession');\n            expect(clonedCursor.session).to.have.property(kServerSession, null); // session is brand new and has not been used\n          }).finally(() => {\n            return cursor.close();\n          });\n        });\n      });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should propagate error when exceptions are thrown from an awaited forEach call","suites":["Cursor","Cursor forEach Error propagation"],"updatePoint":{"line":3414,"column":86,"index":112519},"line":3414,"code":"    it('should propagate error when exceptions are thrown from an awaited forEach call', async function () {\n      const docs = [{\n        unique_key_2035: 1\n      }, {\n        unique_key_2035: 2\n      }, {\n        unique_key_2035: 3\n      }];\n      await collection.insertMany(docs).catch(() => {\n        expect.fail('Failed to insert documents');\n      });\n      cursor = collection.find({\n        unique_key_2035: {\n          $exists: true\n        }\n      });\n      await cursor.forEach(() => {\n        throw new Error('FAILURE IN FOREACH CALL');\n      }).then(() => {\n        expect.fail('Error in forEach call not caught');\n      }).catch(err => {\n        expect(err.message).to.deep.equal('FAILURE IN FOREACH CALL');\n      });\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should return a promise when no callback supplied to forEach method","suites":["Cursor","Cursor forEach Error propagation"],"updatePoint":{"line":3439,"column":73,"index":113253},"line":3439,"code":"  it('should return a promise when no callback supplied to forEach method', function () {\n    const configuration = this.configuration;\n    const client = configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    return client.connect().then(() => {\n      this.defer(() => client.close());\n      const db = client.db(configuration.db);\n      const collection = db.collection('cursor_session_tests2');\n      const cursor = collection.find();\n      this.defer(() => cursor.close());\n      const promise = cursor.forEach(() => {});\n      expect(promise).to.exist.and.to.be.an.instanceof(Promise);\n      return promise;\n    });\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should return false when exhausted and hasNext called more than once","suites":["Cursor","Cursor forEach Error propagation"],"updatePoint":{"line":3457,"column":74,"index":113905},"line":3457,"code":"  it('should return false when exhausted and hasNext called more than once', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    client.connect((err, client) => {\n      expect(err).to.not.exist;\n      this.defer(() => client.close());\n      const db = client.db(configuration.db);\n      db.createCollection('cursor_hasNext_test').then(() => {\n        const cursor = db.collection('cursor_hasNext_test').find();\n        this.defer(() => cursor.close());\n        cursor.hasNext().then(val1 => {\n          expect(val1).to.equal(false);\n          return cursor.hasNext();\n        }).then(val2 => {\n          expect(val2).to.equal(false);\n          done();\n        });\n      });\n    });\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"stream should apply the supplied transformation function to each document in the stream","suites":["Cursor","Cursor forEach Error propagation"],"updatePoint":{"line":3533,"column":93,"index":116260},"line":3533,"code":"  it('stream should apply the supplied transformation function to each document in the stream', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    const expectedDocs = [{\n      _id: 0,\n      b: 1,\n      c: 0\n    }, {\n      _id: 1,\n      b: 1,\n      c: 0\n    }, {\n      _id: 2,\n      b: 1,\n      c: 0\n    }];\n    const config = {\n      client: client,\n      configuration: configuration,\n      collectionName: 'stream-test-transform',\n      transformFunc: doc => ({\n        _id: doc._id,\n        b: doc.a.b,\n        c: doc.a.c\n      }),\n      expectedSet: new Set(expectedDocs)\n    };\n    testTransformStream(config, done);\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"stream should return a stream of unmodified docs if no transform function applied","suites":["Cursor","Cursor forEach Error propagation"],"updatePoint":{"line":3566,"column":87,"index":116994},"line":3566,"code":"  it('stream should return a stream of unmodified docs if no transform function applied', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    const expectedDocs = [{\n      _id: 0,\n      a: {\n        b: 1,\n        c: 0\n      }\n    }, {\n      _id: 1,\n      a: {\n        b: 1,\n        c: 0\n      }\n    }, {\n      _id: 2,\n      a: {\n        b: 1,\n        c: 0\n      }\n    }];\n    const config = {\n      client: client,\n      configuration: configuration,\n      collectionName: 'transformStream-test-notransform',\n      transformFunc: null,\n      expectedSet: new Set(expectedDocs)\n    };\n    testTransformStream(config, done);\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should apply parent read preference to count command","suites":["Cursor","Cursor forEach Error propagation"],"line":3601,"code":"  it.skip('should apply parent read preference to count command', function (done) {","file":"integration/crud/misc_cursors.test.js","skipped":true,"dir":"test"},{"name":"should not consume first document on hasNext when streaming","suites":["Cursor","Cursor forEach Error propagation"],"updatePoint":{"line":3622,"column":65,"index":118976},"line":3622,"code":"  it('should not consume first document on hasNext when streaming', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    client.connect(err => {\n      expect(err).to.not.exist;\n      this.defer(() => client.close());\n      const collection = client.db().collection('documents');\n      collection.drop(() => {\n        const docs = [{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }];\n        collection.insertMany(docs, err => {\n          expect(err).to.not.exist;\n          const cursor = collection.find({}, {\n            sort: {\n              a: 1\n            }\n          });\n          cursor.hasNext((err, hasNext) => {\n            expect(err).to.not.exist;\n            expect(hasNext).to.be.true;\n            const collected = [];\n            const stream = new Writable({\n              objectMode: true,\n              write: (chunk, encoding, next) => {\n                collected.push(chunk);\n                next(undefined, chunk);\n              }\n            });\n            const cursorStream = cursor.stream();\n            cursorStream.on('end', () => {\n              expect(collected).to.have.length(3);\n              expect(collected).to.eql(docs);\n              done();\n            });\n            cursorStream.pipe(stream);\n          });\n        });\n      });\n    });\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should correctly apply map transform to cursor as readable stream","suites":["Cursor","transforms"],"updatePoint":{"line":3672,"column":73,"index":120452},"line":3672,"code":"    it('should correctly apply map transform to cursor as readable stream', function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect(err => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const docs = 'Aaden Aaron Adrian Aditya Bob Joe'.split(' ').map(x => ({\n          name: x\n        }));\n        const coll = client.db(configuration.db).collection('cursor_stream_mapping');\n        coll.insertMany(docs, err => {\n          expect(err).to.not.exist;\n          const bag = [];\n          const stream = coll.find().project({\n            _id: 0,\n            name: 1\n          }).map(doc => ({\n            mapped: doc\n          })).stream().on('data', doc => bag.push(doc));\n          stream.on('error', done).on('end', () => {\n            expect(bag.map(x => x.mapped)).to.eql(docs.map(x => ({\n              name: x.name\n            })));\n            done();\n          });\n        });\n      });\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should correctly apply map transform when converting cursor to array","suites":["Cursor","transforms"],"updatePoint":{"line":3700,"column":76,"index":121473},"line":3700,"code":"    it('should correctly apply map transform when converting cursor to array', function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect(err => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const docs = 'Aaden Aaron Adrian Aditya Bob Joe'.split(' ').map(x => ({\n          name: x\n        }));\n        const coll = client.db(configuration.db).collection('cursor_toArray_mapping');\n        coll.insertMany(docs, err => {\n          expect(err).to.not.exist;\n          coll.find().project({\n            _id: 0,\n            name: 1\n          }).map(doc => ({\n            mapped: doc\n          })).toArray((err, mappedDocs) => {\n            expect(err).to.not.exist;\n            expect(mappedDocs.map(x => x.mapped)).to.eql(docs.map(x => ({\n              name: x.name\n            })));\n            done();\n          });\n        });\n      });\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use find options object","suites":["Cursor","sort"],"updatePoint":{"line":3771,"column":38,"index":123885},"line":3771,"code":"    it('should use find options object', findSort({\n      alpha: 1\n    }, new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use find options string","suites":["Cursor","sort"],"updatePoint":{"line":3774,"column":38,"index":123986},"line":3774,"code":"    it('should use find options string', findSort('alpha', new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use find options shallow array","suites":["Cursor","sort"],"updatePoint":{"line":3775,"column":45,"index":124079},"line":3775,"code":"    it('should use find options shallow array', findSort(['alpha', 1], new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use find options deep array","suites":["Cursor","sort"],"updatePoint":{"line":3776,"column":42,"index":124174},"line":3776,"code":"    it('should use find options deep array', findSort([['alpha', 1]], new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use cursor.sort object","suites":["Cursor","sort"],"updatePoint":{"line":3777,"column":37,"index":124266},"line":3777,"code":"    it('should use cursor.sort object', cursorSort({\n      alpha: 1\n    }, new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use cursor.sort string","suites":["Cursor","sort"],"updatePoint":{"line":3780,"column":37,"index":124368},"line":3780,"code":"    it('should use cursor.sort string', cursorSort('alpha', new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use cursor.sort shallow array","suites":["Cursor","sort"],"updatePoint":{"line":3781,"column":44,"index":124462},"line":3781,"code":"    it('should use cursor.sort shallow array', cursorSort(['alpha', 1], new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use cursor.sort deep array","suites":["Cursor","sort"],"updatePoint":{"line":3782,"column":41,"index":124558},"line":3782,"code":"    it('should use cursor.sort deep array', cursorSort([['alpha', 1]], new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"formatSort - one key","suites":["Cursor","sort"],"updatePoint":{"line":3783,"column":28,"index":124643},"line":3783,"code":"    it('formatSort - one key', () => {\n      // TODO (NODE-3236): These are unit tests for a standalone function and should be moved out of the cursor context file\n      expect(formatSort('alpha')).to.deep.equal(new Map([['alpha', 1]]));\n      expect(formatSort(['alpha'])).to.deep.equal(new Map([['alpha', 1]]));\n      expect(formatSort('alpha', 1)).to.deep.equal(new Map([['alpha', 1]]));\n      expect(formatSort('alpha', 'asc')).to.deep.equal(new Map([['alpha', 1]]));\n      expect(formatSort([['alpha', 'asc']])).to.deep.equal(new Map([['alpha', 1]]));\n      expect(formatSort('alpha', 'ascending')).to.deep.equal(new Map([['alpha', 1]]));\n      expect(formatSort({\n        alpha: 1\n      })).to.deep.equal(new Map([['alpha', 1]]));\n      expect(formatSort('beta')).to.deep.equal(new Map([['beta', 1]]));\n      expect(formatSort(['beta'])).to.deep.equal(new Map([['beta', 1]]));\n      expect(formatSort('beta', -1)).to.deep.equal(new Map([['beta', -1]]));\n      expect(formatSort('beta', 'desc')).to.deep.equal(new Map([['beta', -1]]));\n      expect(formatSort('beta', 'descending')).to.deep.equal(new Map([['beta', -1]]));\n      expect(formatSort({\n        beta: -1\n      })).to.deep.equal(new Map([['beta', -1]]));\n      expect(formatSort({\n        alpha: {\n          $meta: 'hi'\n        }\n      })).to.deep.equal(new Map([['alpha', {\n        $meta: 'hi'\n      }]]));\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"formatSort - multi key","suites":["Cursor","sort"],"updatePoint":{"line":3810,"column":30,"index":126027},"line":3810,"code":"    it('formatSort - multi key', () => {\n      expect(formatSort(['alpha', 'beta'])).to.deep.equal(new Map([['alpha', 1], ['beta', 1]]));\n      expect(formatSort({\n        alpha: 1,\n        beta: 1\n      })).to.deep.equal(new Map([['alpha', 1], ['beta', 1]]));\n      expect(formatSort([['alpha', 'asc'], ['beta', 'ascending']])).to.deep.equal(new Map([['alpha', 1], ['beta', 1]]));\n      expect(formatSort(new Map([['alpha', 'asc'], ['beta', 'ascending']]))).to.deep.equal(new Map([['alpha', 1], ['beta', 1]]));\n      expect(formatSort([['3', 'asc'], ['1', 'ascending']])).to.deep.equal(new Map([['3', 1], ['1', 1]]));\n      expect(formatSort({\n        alpha: {\n          $meta: 'hi'\n        },\n        beta: 'ascending'\n      })).to.deep.equal(new Map([['alpha', {\n        $meta: 'hi'\n      }], ['beta', 1]]));\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use allowDiskUse option on sort","suites":["Cursor","sort"],"updatePoint":{"line":3828,"column":46,"index":126863},"line":3828,"code":"    it('should use allowDiskUse option on sort', {\n      metadata: {\n        requires: {\n          mongodb: '>=4.4'\n        }\n      },\n      test: async function () {\n        const events = [];\n        client.on('commandStarted', event => {\n          if (event.commandName === 'find') {\n            events.push(event);\n          }\n        });\n        const db = client.db('test');\n        const collection = db.collection('test_sort_allow_disk_use');\n        const cursor = collection.find({}).sort(['alpha', 1]).allowDiskUse();\n        await cursor.next();\n        const {\n          command\n        } = events.shift();\n        expect(command.sort).to.deep.equal(new Map([['alpha', 1]]));\n        expect(command.allowDiskUse).to.be.true;\n      }\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should error if allowDiskUse option used without sort","suites":["Cursor","sort"],"updatePoint":{"line":3852,"column":61,"index":127632},"line":3852,"code":"    it('should error if allowDiskUse option used without sort', {\n      metadata: {\n        requires: {\n          mongodb: '>=4.4'\n        }\n      },\n      test: async function () {\n        const client = this.configuration.newClient();\n        const db = client.db('test');\n        const collection = db.collection('test_sort_allow_disk_use');\n        expect(() => collection.find({}).allowDiskUse()).to.throw(/Option \"allowDiskUse\" requires a sort specification/);\n        await client.close();\n      }\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should create records with custom PK factory","suites":["PkFactory"],"updatePoint":{"line":16,"column":50,"index":329},"line":16,"code":"  it('should create records with custom PK factory', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n\n      // Custom factory (need to provide a 12 byte array);\n      var CustomPKFactory = {\n        createPk() {\n          return new ObjectId('aaaaaaaaaaaa');\n        }\n      };\n      var client = configuration.newClient({\n        writeConcern: {\n          w: 1\n        },\n        maxPoolSize: 1\n      }, {\n        pkFactory: CustomPKFactory\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('test_custom_key');\n        collection.insert({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.find({\n            _id: new ObjectId('aaaaaaaaaaaa')\n          }).toArray(function (err, items) {\n            expect(items.length).to.equal(1);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/pk_factory.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute stats using Promise","suites":["stats"],"updatePoint":{"line":12,"column":50,"index":273},"line":12,"code":"  it('Should correctly execute stats using Promise', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var url = configuration.url();\n      url = url.indexOf('?') !== -1 ? f('%s&%s', url, 'maxPoolSize=5') : f('%s?%s', url, 'maxPoolSize=5');\n      const client = configuration.newClient(url);\n      client.connect().then(function (client) {\n        client.db(configuration.db).stats().then(function (stats) {\n          test.ok(stats != null);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/promise_stats.test.js","skipped":false,"dir":"test"},{"name":"should correctly clear out collection","suites":["Remove"],"updatePoint":{"line":14,"column":43,"index":292},"line":14,"code":"  it('should correctly clear out collection', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      const db = client.db();\n      db.createCollection('test_clear', function (err) {\n        expect(err).to.not.exist;\n        const collection = db.collection('test_clear');\n        collection.insert({\n          i: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.insert({\n            i: 2\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n            collection.count(function (err, count) {\n              expect(err).to.not.exist;\n              expect(count).to.equal(2);\n\n              // Clear the collection\n              collection.deleteMany({}, {\n                writeConcern: {\n                  w: 1\n                }\n              }, function (err, r) {\n                expect(err).to.not.exist;\n                expect(r).property('deletedCount').to.equal(2);\n                collection.count(function (err, count) {\n                  expect(err).to.not.exist;\n                  expect(count).to.equal(0);\n\n                  // Let's close the db\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/remove.test.js","skipped":false,"dir":"test"},{"name":"should correctly remove document using RegExp","suites":["Remove"],"updatePoint":{"line":67,"column":51,"index":1809},"line":67,"code":"  it('should correctly remove document using RegExp', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      const self = this;\n      const client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(self.configuration.db);\n        expect(err).to.not.exist;\n        db.createCollection('test_remove_regexp', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_remove_regexp');\n          collection.insert({\n            address: '485 7th ave new york'\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n\n            // Clear the collection\n            collection.deleteMany({\n              address: /485 7th ave/\n            }, {\n              writeConcern: {\n                w: 1\n              }\n            }, function (err, r) {\n              expect(r).property('deletedCount').to.equal(1);\n              collection.count(function (err, count) {\n                expect(err).to.not.exist;\n                expect(count).to.equal(0);\n\n                // Let's close the db\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/remove.test.js","skipped":false,"dir":"test"},{"name":"should not error on empty remove","suites":["Remove"],"updatePoint":{"line":115,"column":38,"index":3268},"line":115,"code":"  it('should not error on empty remove', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      const self = this;\n      const client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(self.configuration.db);\n        expect(err).to.not.exist;\n        const collection = db.collection('remove_test');\n        collection.deleteMany({}).then(() => {\n          client.close(done);\n        }, err => {\n          client.close(err2 => done(err || err2));\n        });\n      });\n    }\n  });","file":"integration/crud/remove.test.js","skipped":false,"dir":"test"},{"name":"should fail insert due to unique index","suites":["Errors"],"updatePoint":{"line":27,"column":44,"index":641},"line":27,"code":"  it('should fail insert due to unique index', function (done) {\n    const db = client.db(this.configuration.db);\n    db.createCollection('test_failing_insert_due_to_unique_index', (err, collection) => {\n      expect(err).to.not.exist;\n      collection.createIndexes([{\n        name: 'test_failing_insert_due_to_unique_index',\n        key: {\n          a: 1\n        },\n        unique: true\n      }], {\n        writeConcern: {\n          w: 1\n        }\n      }, err => {\n        expect(err).to.not.exist;\n        collection.insertOne({\n          a: 2\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, err => {\n          expect(err).to.not.exist;\n          collection.insertOne({\n            a: 2\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, err => {\n            expect(err.code).to.equal(11000);\n            done();\n          });\n        });\n      });\n    });\n  });","file":"integration/crud/server_errors.test.js","skipped":false,"dir":"test"},{"name":"should fail insert due to unique index strict","suites":["Errors"],"updatePoint":{"line":65,"column":51,"index":1584},"line":65,"code":"  it('should fail insert due to unique index strict', function (done) {\n    const db = client.db(this.configuration.db);\n    db.dropCollection('test_failing_insert_due_to_unique_index_strict', () => {\n      db.createCollection('test_failing_insert_due_to_unique_index_strict', err => {\n        expect(err).to.not.exist;\n        const collection = db.collection('test_failing_insert_due_to_unique_index_strict');\n        collection.createIndexes([{\n          name: 'test_failing_insert_due_to_unique_index_strict',\n          key: {\n            a: 1\n          },\n          unique: true\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, err => {\n          expect(err).to.not.exist;\n          collection.insertOne({\n            a: 2\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, err => {\n            expect(err).to.not.exist;\n            collection.insertOne({\n              a: 2\n            }, {\n              writeConcern: {\n                w: 1\n              }\n            }, err => {\n              expect(err.code).to.equal(11000);\n              done();\n            });\n          });\n        });\n      });\n    });\n  });","file":"integration/crud/server_errors.test.js","skipped":false,"dir":"test"},{"name":"should return an error object with message when mixing included and excluded fields","suites":["Errors"],"updatePoint":{"line":107,"column":89,"index":2972},"line":107,"code":"  it('should return an error object with message when mixing included and excluded fields', async () => {\n    const db = client.db();\n    const c = db.collection('test_error_object_should_include_message');\n    await c.insertOne({\n      a: 2,\n      b: 5\n    }, {\n      writeConcern: {\n        w: 1\n      }\n    });\n    const error = await c.findOne({\n      a: 2\n    }, {\n      projection: {\n        a: 1,\n        b: 0\n      }\n    }).catch(error => error);\n    expect(error).to.be.instanceOf(MongoServerError);\n    expect(PROJECTION_ERRORS).to.include(error.errmsg);\n  });","file":"integration/crud/server_errors.test.js","skipped":false,"dir":"test"},{"name":"should reject promise with projection errors","suites":["Errors"],"updatePoint":{"line":129,"column":50,"index":3504},"line":129,"code":"  it('should reject promise with projection errors', async () => {\n    const db = client.db();\n    const c = db.collection('test_error_object_should_include_message');\n    const error = await c.findOne({}, {\n      projection: {\n        a: 1,\n        b: 0\n      }\n    }).catch(error => error);\n    expect(error).to.be.instanceOf(MongoServerError);\n    expect(PROJECTION_ERRORS).to.include(error.errmsg);\n  });","file":"integration/crud/server_errors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertUnicodeContainingDocument","suites":["Unicode"],"updatePoint":{"line":14,"column":52,"index":281},"line":14,"code":"  it('shouldCorrectlyInsertUnicodeContainingDocument', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var doc = {\n          statuses_count: 1687,\n          created_at: 'Mon Oct 22 14:55:08 +0000 2007',\n          description: 'NodeJS hacker, Cofounder of Debuggable, CakePHP core alumnus',\n          favourites_count: 6,\n          profile_sidebar_fill_color: 'EADEAA',\n          screen_name: 'felixge',\n          status: {\n            created_at: 'Fri Mar 12 08:59:44 +0000 2010',\n            in_reply_to_screen_name: null,\n            truncated: false,\n            in_reply_to_user_id: null,\n            source: '<a href=\"http://www.atebits.com/\" rel=\"nofollow\">Tweetie</a>',\n            favorited: false,\n            in_reply_to_status_id: null,\n            id: 10364119169,\n            text: '#berlin #snow = #fail : ('\n          },\n          contributors_enabled: false,\n          following: null,\n          geo_enabled: false,\n          time_zone: 'Eastern Time (US & Canada)',\n          profile_sidebar_border_color: 'D9B17E',\n          url: 'http://debuggable.com',\n          verified: false,\n          location: 'Berlin',\n          profile_text_color: '333333',\n          notifications: null,\n          profile_background_image_url: 'http://s.twimg.com/a/1268354287/images/themes/theme8/bg.gif',\n          protected: false,\n          profile_link_color: '9D582E',\n          followers_count: 840,\n          name: 'Felix Geisend\\u00f6rfer',\n          profile_background_tile: false,\n          id: 9599342,\n          lang: 'en',\n          utc_offset: -18000,\n          friends_count: 450,\n          profile_background_color: '8B542B',\n          profile_image_url: 'http://a3.twimg.com/profile_images/107142257/passbild-square_normal.jpg'\n        };\n        db.createCollection('test_should_correctly_insert_unicode_containing_document', function (err, collection) {\n          doc['_id'] = 'felixge';\n          collection.insertOne(doc, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n            collection.findOne(function (err, doc) {\n              test.equal('felixge', doc._id);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/unicode.test.js","skipped":false,"dir":"test"},{"name":"should Correctly Insert Unicode Characters","suites":["Unicode"],"updatePoint":{"line":85,"column":48,"index":2917},"line":85,"code":"  it('should Correctly Insert Unicode Characters', function (done) {\n    const client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    client.connect((err, client) => {\n      expect(err).to.not.exist;\n      const db = client.db(this.configuration.db);\n      db.createCollection('unicode_test_collection', (err, collection) => {\n        expect(err).to.not.exist;\n        const test_strings = ['ouooueauiOUOOUEAUI', 'öüóőúéáűíÖÜÓŐÚÉÁŰÍ', '本荘由利地域に洪水警報'];\n        collection.insert({\n          id: 0,\n          text: test_strings[0]\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, err => {\n          expect(err).to.not.exist;\n          collection.insert({\n            id: 1,\n            text: test_strings[1]\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, err => {\n            expect(err).to.not.exist;\n            collection.find().forEach(doc => {\n              expect(doc).property('text').to.equal(test_strings[doc.id]);\n            }, err => {\n              expect(err).to.not.exist;\n              client.close(done);\n            });\n          });\n        });\n      });\n    });\n  });","file":"integration/crud/unicode.test.js","skipped":false,"dir":"test"},{"name":"shouldCreateObjectWithChineseObjectName","suites":["Unicode"],"updatePoint":{"line":124,"column":45,"index":4127},"line":124,"code":"  it('shouldCreateObjectWithChineseObjectName', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var object = {\n        客家话: 'Hello'\n      };\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('create_object_with_chinese_object_name', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('create_object_with_chinese_object_name');\n          collection.insert(object, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n            collection.findOne(function (err, item) {\n              test.equal(object['客家话'], item['客家话']);\n              collection.find().toArray(function (err, items) {\n                test.equal(object['客家话'], items[0]['客家话']);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/unicode.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleUT8KeyNames","suites":["Unicode"],"updatePoint":{"line":161,"column":38,"index":5356},"line":161,"code":"  it('shouldCorrectlyHandleUT8KeyNames', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_utf8_key_name', function (err, collection) {\n          collection.insert({\n            šđžčćŠĐŽČĆ: 1\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n            collection.find({}).project({\n              šđžčćŠĐŽČĆ: 1\n            }).toArray(function (err, items) {\n              test.equal(1, items[0]['šđžčćŠĐŽČĆ']);\n              // Let's close the db\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/unicode.test.js","skipped":false,"dir":"test"},{"name":"Verify that the method returns an Iterable of Document types","suites":["listDatabases() spec prose"],"updatePoint":{"line":37,"column":66,"index":1379},"line":37,"code":"  it('Verify that the method returns an Iterable of Document types', async () => {\n    const dbInfo = await client.db().admin().listDatabases();\n    expect(dbInfo).to.have.property('databases');\n    expect(dbInfo.databases).to.be.an('array');\n    expect(dbInfo.databases).to.have.lengthOf(ENTIRE_DB_LIST.length);\n    for (const db of dbInfo.databases) {\n      expect(db).to.be.a('object');\n    }\n  });","file":"integration/enumerate_databases.prose.test.ts","skipped":false,"dir":"test"},{"name":"Verify that all databases on the server are present in the result set","suites":["listDatabases() spec prose"],"updatePoint":{"line":46,"column":75,"index":1790},"line":46,"code":"  it('Verify that all databases on the server are present in the result set', async () => {\n    const dbInfo = await client.db().admin().listDatabases();\n    const namesFromHelper = dbInfo.databases.map(({\n      name\n    }) => name);\n    namesFromHelper.sort();\n    expect(namesFromHelper).to.have.lengthOf(ENTIRE_DB_LIST.length);\n    expect(namesFromHelper).to.deep.equal(ENTIRE_DB_LIST);\n    expect(namesFromHelper).to.include(DB_NAME);\n  });","file":"integration/enumerate_databases.prose.test.ts","skipped":false,"dir":"test"},{"name":"Verify that the result set does not contain duplicates","suites":["listDatabases() spec prose"],"updatePoint":{"line":56,"column":60,"index":2220},"line":56,"code":"  it('Verify that the result set does not contain duplicates', async () => {\n    const dbInfo = await client.db().admin().listDatabases();\n    const databaseNames = dbInfo.databases.map(({\n      name\n    }) => name);\n    const databaseNamesSet = new Set(databaseNames);\n    expect(databaseNames).to.have.lengthOf(databaseNamesSet.size);\n  });","file":"integration/enumerate_databases.prose.test.ts","skipped":false,"dir":"test"},{"name":"should list all databases when admin client sets authorizedDatabases to true","suites":["listDatabases()","authorizedDatabases option"],"updatePoint":{"line":44,"column":84,"index":1611},"line":44,"code":"    it('should list all databases when admin client sets authorizedDatabases to true', metadata, async function () {\n      const adminListDbs = await adminClient.db().admin().listDatabases({\n        authorizedDatabases: true\n      });\n      const adminDbs = adminListDbs.databases.map(({\n        name\n      }) => name);\n\n      // no change in the dbs listed since we're using the admin user\n      expect(adminDbs).to.have.length.greaterThan(1);\n      expect(adminDbs.filter(db => db === mockAuthorizedDb)).to.have.lengthOf(1);\n      expect(adminDbs.filter(db => db !== mockAuthorizedDb)).to.have.length.greaterThan(1);\n    });","file":"integration/enumerate_databases.test.ts","skipped":false,"dir":"test"},{"name":"should list all databases when admin client sets authorizedDatabases to false","suites":["listDatabases()","authorizedDatabases option"],"updatePoint":{"line":57,"column":85,"index":2239},"line":57,"code":"    it('should list all databases when admin client sets authorizedDatabases to false', metadata, async function () {\n      const adminListDbs = await adminClient.db().admin().listDatabases({\n        authorizedDatabases: false\n      });\n      const adminDbs = adminListDbs.databases.map(({\n        name\n      }) => name);\n\n      // no change in the dbs listed since we're using the admin user\n      expect(adminDbs).to.have.length.greaterThan(1);\n      expect(adminDbs.filter(db => db === mockAuthorizedDb)).to.have.lengthOf(1);\n      expect(adminDbs.filter(db => db !== mockAuthorizedDb)).to.have.length.greaterThan(1);\n    });","file":"integration/enumerate_databases.test.ts","skipped":false,"dir":"test"},{"name":"should list authorized databases with authorizedDatabases set to true","suites":["listDatabases()","authorizedDatabases option"],"updatePoint":{"line":70,"column":77,"index":2860},"line":70,"code":"    it('should list authorized databases with authorizedDatabases set to true', metadata, async function () {\n      const adminListDbs = await adminClient.db().admin().listDatabases();\n      const authorizedListDbs = await authorizedClient.db().admin().listDatabases({\n        authorizedDatabases: true\n      });\n      const adminDbs = adminListDbs.databases;\n      const authorizedDbs = authorizedListDbs.databases;\n      expect(adminDbs).to.have.length.greaterThan(1);\n      expect(authorizedDbs).to.have.lengthOf(1);\n      expect(adminDbs.filter(db => db.name === mockAuthorizedDb)).to.have.lengthOf(1);\n      expect(adminDbs.filter(db => db.name !== mockAuthorizedDb)).to.have.length.greaterThan(1);\n      expect(authorizedDbs.filter(db => db.name === mockAuthorizedDb)).to.have.lengthOf(1);\n    });","file":"integration/enumerate_databases.test.ts","skipped":false,"dir":"test"},{"name":"should list authorized databases by default with authorizedDatabases unspecified","suites":["listDatabases()","authorizedDatabases option"],"updatePoint":{"line":83,"column":88,"index":3675},"line":83,"code":"    it('should list authorized databases by default with authorizedDatabases unspecified', metadata, async function () {\n      const adminListDbs = await adminClient.db().admin().listDatabases();\n      const authorizedListDbs = await authorizedClient.db().admin().listDatabases();\n      const adminDbs = adminListDbs.databases;\n      const authorizedDbs = authorizedListDbs.databases;\n      expect(adminDbs).to.have.length.greaterThan(1);\n      expect(authorizedDbs).to.have.lengthOf(1);\n      expect(adminDbs.filter(db => db.name === mockAuthorizedDb)).to.have.lengthOf(1);\n      expect(adminDbs.filter(db => db.name !== mockAuthorizedDb)).to.have.length.greaterThan(1);\n      expect(authorizedDbs.filter(db => db.name === mockAuthorizedDb)).to.have.lengthOf(1);\n    });","file":"integration/enumerate_databases.test.ts","skipped":false,"dir":"test"},{"name":"should not show authorized databases with authorizedDatabases set to false","suites":["listDatabases()","authorizedDatabases option"],"updatePoint":{"line":94,"column":82,"index":4441},"line":94,"code":"    it('should not show authorized databases with authorizedDatabases set to false', metadata, async function () {\n      let thrownError;\n      try {\n        await authorizedClient.db().admin().listDatabases({\n          authorizedDatabases: false\n        });\n      } catch (error) {\n        thrownError = error;\n      }\n\n      // check correctly produces an 'Insufficient permissions to list all databases' error\n      expect(thrownError).to.be.instanceOf(MongoServerError);\n      expect(thrownError).to.have.property('message').that.includes('list');\n    });","file":"integration/enumerate_databases.test.ts","skipped":false,"dir":"test"},{"name":"should upload from file stream","suites":["GridFS Stream"],"updatePoint":{"line":34,"column":36,"index":700},"line":34,"code":"  it('should upload from file stream', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        db.dropDatabase(function (error) {\n          expect(error).to.not.exist;\n          const bucket = new GridFSBucket(db);\n          const readStream = fs.createReadStream('./LICENSE.md');\n          const uploadStream = bucket.openUploadStream('test.dat');\n          const license = fs.readFileSync('./LICENSE.md');\n          const id = uploadStream.id;\n\n          // Wait for stream to finish\n          uploadStream.once('finish', function () {\n            const chunksColl = db.collection('fs.chunks');\n            const chunksQuery = chunksColl.find({\n              files_id: id\n            });\n\n            // Get all the chunks\n            chunksQuery.toArray(function (error, docs) {\n              expect(error).to.not.exist;\n              expect(docs.length).to.equal(1);\n              expect(docs[0].data.toString('hex')).to.equal(license.toString('hex'));\n              const filesColl = db.collection('fs.files');\n              const filesQuery = filesColl.find({\n                _id: id\n              });\n              filesQuery.toArray(function (error, docs) {\n                expect(error).to.not.exist;\n                expect(docs.length).to.equal(1);\n                expect(docs[0]).to.not.have.property('md5');\n\n                // make sure we created indexes\n                filesColl.listIndexes().toArray(function (error, indexes) {\n                  expect(error).to.not.exist;\n                  expect(indexes.length).to.equal(2);\n                  expect(indexes[1].name).to.equal('filename_1_uploadDate_1');\n                  chunksColl.listIndexes().toArray(function (error, indexes) {\n                    expect(error).to.not.exist;\n                    expect(indexes.length).to.equal(2);\n                    expect(indexes[1].name).to.equal('files_id_1_n_1');\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n          readStream.pipe(uploadStream);\n        });\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"destroy publishes provided error","suites":["GridFS Stream"],"updatePoint":{"line":96,"column":38,"index":3090},"line":96,"code":"  it('destroy publishes provided error', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        db.dropDatabase(function (error) {\n          expect(error).to.not.exist;\n          const bucket = new GridFSBucket(db);\n          const readStream = fs.createReadStream('./LICENSE.md');\n          const uploadStream = bucket.openUploadStream('test.dat');\n          const errorMessage = 'error';\n          uploadStream.once('error', function (e) {\n            expect(e).to.equal(errorMessage);\n            client.close(done);\n          });\n          uploadStream.once('finish', function () {\n            uploadStream.destroy(errorMessage);\n          });\n          readStream.pipe(uploadStream);\n        });\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should upload from file stream with custom id","suites":["GridFS Stream"],"updatePoint":{"line":134,"column":51,"index":4300},"line":134,"code":"  it('should upload from file stream with custom id', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        db.dropDatabase(function (error) {\n          expect(error).to.not.exist;\n          const bucket = new GridFSBucket(db);\n          const readStream = fs.createReadStream('./LICENSE.md');\n          const uploadStream = bucket.openUploadStreamWithId(1, 'test.dat');\n          const license = fs.readFileSync('./LICENSE.md');\n          const id = uploadStream.id;\n          expect(id).to.equal(1);\n\n          // Wait for stream to finish\n          uploadStream.once('finish', function () {\n            const chunksColl = db.collection('fs.chunks');\n            const chunksQuery = chunksColl.find({\n              files_id: id\n            });\n\n            // Get all the chunks\n            chunksQuery.toArray(function (error, docs) {\n              expect(error).to.not.exist;\n              expect(docs.length).to.equal(1);\n              expect(docs[0].data.toString('hex')).to.equal(license.toString('hex'));\n              const filesColl = db.collection('fs.files');\n              const filesQuery = filesColl.find({\n                _id: id\n              });\n              filesQuery.toArray(function (error, docs) {\n                expect(error).to.not.exist;\n                expect(docs.length).to.equal(1);\n                expect(docs[0]).to.not.have.property('md5');\n\n                // make sure we created indexes\n                filesColl.listIndexes().toArray(function (error, indexes) {\n                  expect(error).to.not.exist;\n                  expect(indexes.length).to.equal(2);\n                  expect(indexes[1].name).to.equal('filename_1_uploadDate_1');\n                  chunksColl.listIndexes().toArray(function (error, indexes) {\n                    expect(error).to.not.exist;\n                    expect(indexes.length).to.equal(2);\n                    expect(indexes[1].name).to.equal('files_id_1_n_1');\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n          readStream.pipe(uploadStream);\n        });\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should download to upload stream","suites":["GridFS Stream"],"updatePoint":{"line":204,"column":38,"index":6896},"line":204,"code":"  it('should download to upload stream', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload'\n        });\n        const CHUNKS_COLL = 'gridfsdownload.chunks';\n        const FILES_COLL = 'gridfsdownload.files';\n        const readStream = fs.createReadStream('./LICENSE.md');\n        let uploadStream = bucket.openUploadStream('test.dat');\n        const license = fs.readFileSync('./LICENSE.md');\n        let id = uploadStream.id;\n        uploadStream.once('finish', function () {\n          const downloadStream = bucket.openDownloadStream(id);\n          uploadStream = bucket.openUploadStream('test2.dat');\n          id = uploadStream.id;\n          downloadStream.pipe(uploadStream).once('finish', function () {\n            const chunksQuery = db.collection(CHUNKS_COLL).find({\n              files_id: id\n            });\n            chunksQuery.toArray(function (error, docs) {\n              expect(error).to.not.exist;\n              expect(docs.length).to.equal(1);\n              expect(docs[0].data.toString('hex')).to.equal(license.toString('hex'));\n              const filesQuery = db.collection(FILES_COLL).find({\n                _id: id\n              });\n              filesQuery.toArray(function (error, docs) {\n                expect(error).to.not.exist;\n                expect(docs.length).to.equal(1);\n                expect(docs[0]).to.not.have.property('md5');\n                client.close(done);\n              });\n            });\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should fail to locate gridfs stream","suites":["GridFS Stream"],"updatePoint":{"line":258,"column":41,"index":8868},"line":258,"code":"  it('should fail to locate gridfs stream', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload'\n        });\n\n        // Get an unknown file\n        const downloadStream = bucket.openDownloadStream(new ObjectId());\n        downloadStream.on('data', function () {});\n        downloadStream.on('error', function (err) {\n          expect(err.code).to.equal('ENOENT');\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"openDownloadStreamByName","suites":["GridFS Stream"],"updatePoint":{"line":292,"column":30,"index":9813},"line":292,"code":"  it('openDownloadStreamByName', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload'\n        });\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('test.dat');\n        uploadStream.once('finish', function () {\n          const downloadStream = bucket.openDownloadStreamByName('test.dat');\n          let gotData = false;\n          downloadStream.on('data', function (data) {\n            expect(gotData).to.equal(false);\n            gotData = true;\n            expect(data.toString('utf8').indexOf('TERMS AND CONDITIONS') !== -1).to.equal(true);\n          });\n          downloadStream.on('end', function () {\n            expect(gotData).to.equal(true);\n            client.close(done);\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"start/end options for openDownloadStream","suites":["GridFS Stream"],"updatePoint":{"line":334,"column":46,"index":11265},"line":334,"code":"  it('start/end options for openDownloadStream', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload',\n          chunkSizeBytes: 2\n        });\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('teststart.dat');\n        uploadStream.once('finish', function () {\n          const downloadStream = bucket.openDownloadStreamByName('teststart.dat', {\n            start: 1\n          }).end(6);\n          downloadStream.on('error', function (error) {\n            expect(error).to.not.exist;\n          });\n          let gotData = 0;\n          let str = '';\n          downloadStream.on('data', function (data) {\n            ++gotData;\n            str += data.toString('utf8');\n          });\n          downloadStream.on('end', function () {\n            // Depending on different versions of node, we may get\n            // different amounts of 'data' events. node 0.10 gives 2,\n            // node >= 0.12 gives 3. Either is correct, but we just\n            // care that we got between 1 and 3, and got the right result\n            expect(gotData >= 1 && gotData <= 3).to.equal(true);\n            expect(str).to.equal('pache');\n            client.close(done);\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should emit close after all chunks are received","suites":["GridFS Stream"],"updatePoint":{"line":380,"column":53,"index":12959},"line":380,"code":"  it('should emit close after all chunks are received', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const db = client.db();\n      const bucket = new GridFSBucket(db, {\n        bucketName: 'gridfsdownload',\n        chunkSizeBytes: 6000\n      });\n      const readStream = fs.createReadStream('./LICENSE.md');\n      const uploadStream = bucket.openUploadStream('teststart.dat');\n      uploadStream.once('finish', function () {\n        const downloadStream = bucket.openDownloadStreamByName('teststart.dat');\n        const events = [];\n        downloadStream.on('data', () => events.push('data'));\n        downloadStream.on('close', () => events.push('close'));\n        downloadStream.on('end', () => {\n          expect(events).to.deep.equal(['data', 'data', 'close']);\n          expect(downloadStream).to.exist;\n          client.close(done);\n        });\n      });\n      readStream.pipe(uploadStream);\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"Deleting a file","suites":["GridFS Stream"],"updatePoint":{"line":415,"column":21,"index":14008},"line":415,"code":"  it('Deleting a file', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload'\n        });\n        const CHUNKS_COLL = 'gridfsdownload.chunks';\n        const FILES_COLL = 'gridfsdownload.files';\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const id = uploadStream.id;\n        uploadStream.once('finish', function () {\n          bucket.delete(id, function (err) {\n            expect(err).to.not.exist;\n            const chunksQuery = db.collection(CHUNKS_COLL).find({\n              files_id: id\n            });\n            chunksQuery.toArray(function (error, docs) {\n              expect(error).to.not.exist;\n              expect(docs.length).to.equal(0);\n              const filesQuery = db.collection(FILES_COLL).find({\n                _id: id\n              });\n              filesQuery.toArray(function (error, docs) {\n                expect(error).to.not.exist;\n                expect(docs.length).to.equal(0);\n                client.close(done);\n              });\n            });\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"Aborting an upload","suites":["GridFS Stream"],"updatePoint":{"line":467,"column":24,"index":15671},"line":467,"code":"  it('Aborting an upload', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsabort',\n          chunkSizeBytes: 1\n        });\n        const CHUNKS_COLL = 'gridfsabort.chunks';\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const id = uploadStream.id;\n        const query = {\n          files_id: id\n        };\n        uploadStream.write('a', 'utf8', function (error) {\n          expect(error).to.not.exist;\n          db.collection(CHUNKS_COLL).count(query, function (error, c) {\n            expect(error).to.not.exist;\n            expect(c).to.equal(1);\n            uploadStream.abort(function (error) {\n              expect(error).to.not.exist;\n              db.collection(CHUNKS_COLL).count(query, function (error, c) {\n                expect(error).to.not.exist;\n                expect(c).to.equal(0);\n                uploadStream.write('b', 'utf8', function (error) {\n                  expect(error.toString()).to.equal('MongoAPIError: Stream has been aborted');\n                  uploadStream.end('c', 'utf8', function (error) {\n                    expect(error.toString()).to.equal('MongoAPIError: Stream has been aborted');\n                    // Fail if user tries to abort an aborted stream\n                    uploadStream.abort().then(null, function (error) {\n                      expect(error.toString()).to.equal(\n                      // TODO(NODE-3485): Replace with MongoGridFSStreamClosedError\n                      'MongoAPIError: Cannot call abort() on a stream twice');\n                      client.close(done);\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"Destroy an upload","suites":["GridFS Stream"],"updatePoint":{"line":524,"column":23,"index":17790},"line":524,"code":"  it('Destroy an upload', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsabort',\n          chunkSizeBytes: 1\n        });\n        const CHUNKS_COLL = 'gridfsabort.chunks';\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const id = uploadStream.id;\n        const query = {\n          files_id: id\n        };\n        uploadStream.write('a', 'utf8', function (error) {\n          expect(error).to.not.exist;\n          db.collection(CHUNKS_COLL).count(query, function (error, c) {\n            expect(error).to.not.exist;\n            expect(c).to.equal(1);\n            uploadStream.abort(function (error) {\n              expect(error).to.not.exist;\n              db.collection(CHUNKS_COLL).count(query, function (error, c) {\n                expect(error).to.not.exist;\n                expect(c).to.equal(0);\n                uploadStream.write('b', 'utf8', function (error) {\n                  expect(error.toString()).to.equal('MongoAPIError: Stream has been aborted');\n                  uploadStream.end('c', 'utf8', function (error) {\n                    expect(error.toString()).to.equal('MongoAPIError: Stream has been aborted');\n                    // Fail if user tries to abort an aborted stream\n                    uploadStream.abort().then(null, function (error) {\n                      expect(error.toString()).to.equal(\n                      // TODO(NODE-3485): Replace with MongoGridFSStreamClosedError\n                      'MongoAPIError: Cannot call abort() on a stream twice');\n                      client.close(done);\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"Destroying a download stream","suites":["GridFS Stream"],"updatePoint":{"line":584,"column":34,"index":20020},"line":584,"code":"  it('Destroying a download stream', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        apiVersion: false\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdestroy',\n          chunkSizeBytes: 10\n        });\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('test.dat');\n\n        // Wait for stream to finish\n        uploadStream.once('finish', function () {\n          const id = uploadStream.id;\n          const downloadStream = bucket.openDownloadStream(id);\n          const finished = {};\n          downloadStream.on('data', function () {\n            expect.fail('Should be unreachable');\n          });\n          downloadStream.on('error', function () {\n            expect.fail('Should be unreachable');\n          });\n          downloadStream.on('end', function () {\n            expect(downloadStream.s.cursor).to.not.exist;\n            if (finished.close) {\n              client.close(done);\n              return;\n            }\n            finished.end = true;\n          });\n          downloadStream.on('close', function () {\n            if (finished.end) {\n              client.close(done);\n              return;\n            }\n            finished.close = true;\n          });\n          downloadStream.abort(function (error) {\n            expect(error).to.not.exist;\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"Deleting a file using promises","suites":["GridFS Stream"],"updatePoint":{"line":646,"column":36,"index":21908},"line":646,"code":"  it('Deleting a file using promises', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient(configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    client.connect(function (err, client) {\n      const db = client.db(configuration.db);\n      const bucket = new GridFSBucket(db, {\n        bucketName: 'gridfsdownload'\n      });\n      const CHUNKS_COLL = 'gridfsdownload.chunks';\n      const FILES_COLL = 'gridfsdownload.files';\n      const readStream = fs.createReadStream('./LICENSE.md');\n      const uploadStream = bucket.openUploadStream('test.dat');\n      const id = uploadStream.id;\n      uploadStream.once('finish', function () {\n        bucket.delete(id).then(function () {\n          const chunksQuery = db.collection(CHUNKS_COLL).find({\n            files_id: id\n          });\n          chunksQuery.toArray(function (error, docs) {\n            expect(error).to.not.exist;\n            expect(docs.length).to.equal(0);\n            const filesQuery = db.collection(FILES_COLL).find({\n              _id: id\n            });\n            filesQuery.toArray(function (error, docs) {\n              expect(error).to.not.exist;\n              expect(docs.length).to.equal(0);\n              client.close(done);\n            });\n          });\n        });\n      });\n      readStream.pipe(uploadStream);\n    });\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"find()","suites":["GridFS Stream"],"updatePoint":{"line":683,"column":12,"index":23255},"line":683,"code":"  it('find()', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient(configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    client.connect(function (err, client) {\n      const db = client.db(configuration.db);\n      const bucket = new GridFSBucket(db, {\n        bucketName: 'fs'\n      });\n\n      // We're only making sure this doesn't throw\n      bucket.find({\n        batchSize: 1,\n        limit: 2,\n        maxTimeMS: 3,\n        noCursorTimeout: true,\n        skip: 4,\n        sort: {\n          _id: 1\n        }\n      });\n      client.close(done);\n    });\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"drop example","suites":["GridFS Stream"],"updatePoint":{"line":708,"column":18,"index":23891},"line":708,"code":"  it('drop example', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient(configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    client.connect(function (err, client) {\n      const db = client.db(configuration.db);\n      const bucket = new GridFSBucket(db, {\n        bucketName: 'gridfsdownload'\n      });\n      const CHUNKS_COLL = 'gridfsdownload.chunks';\n      const FILES_COLL = 'gridfsdownload.files';\n      const readStream = fs.createReadStream('./LICENSE.md');\n      const uploadStream = bucket.openUploadStream('test.dat');\n      const id = uploadStream.id;\n      uploadStream.once('finish', function () {\n        bucket.drop(function (err) {\n          expect(err).to.not.exist;\n          const chunksQuery = db.collection(CHUNKS_COLL).find({\n            files_id: id\n          });\n          chunksQuery.toArray(function (error, docs) {\n            expect(error).to.not.exist;\n            expect(docs.length).to.equal(0);\n            const filesQuery = db.collection(FILES_COLL).find({\n              _id: id\n            });\n            filesQuery.toArray(function (error, docs) {\n              expect(error).to.not.exist;\n              expect(docs.length).to.equal(0);\n              client.close(done);\n            });\n          });\n        });\n      });\n      readStream.pipe(uploadStream);\n    });\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"drop using promises","suites":["GridFS Stream"],"updatePoint":{"line":753,"column":25,"index":25416},"line":753,"code":"  it('drop using promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload'\n        });\n        const CHUNKS_COLL = 'gridfsdownload.chunks';\n        const FILES_COLL = 'gridfsdownload.files';\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const id = uploadStream.id;\n        uploadStream.once('finish', function () {\n          bucket.drop().then(function () {\n            const chunksQuery = db.collection(CHUNKS_COLL).find({\n              files_id: id\n            });\n            chunksQuery.toArray(function (error, docs) {\n              expect(error).to.not.exist;\n              expect(docs.length).to.equal(0);\n              const filesQuery = db.collection(FILES_COLL).find({\n                _id: id\n              });\n              filesQuery.toArray(function (error, docs) {\n                expect(error).to.not.exist;\n                expect(docs.length).to.equal(0);\n                client.close(done);\n              });\n            });\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"find example","suites":["GridFS Stream"],"updatePoint":{"line":804,"column":18,"index":27041},"line":804,"code":"  it('find example', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload_2'\n        });\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('test.dat');\n        uploadStream.once('finish', function () {\n          bucket.find({}, {\n            batchSize: 1\n          }).toArray(function (err, files) {\n            expect(err).to.not.exist;\n            expect(1).to.equal(files.length);\n            client.close(done);\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"rename example","suites":["GridFS Stream"],"updatePoint":{"line":842,"column":20,"index":28094},"line":842,"code":"  it('rename example', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload_3'\n        });\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const id = uploadStream.id;\n        uploadStream.once('finish', function () {\n          // Rename the file\n          bucket.rename(id, 'renamed_it.dat', function (err) {\n            expect(err).to.not.exist;\n            client.close(done);\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"download empty doc","suites":["GridFS Stream"],"updatePoint":{"line":872,"column":24,"index":29037},"line":872,"code":"  it('download empty doc', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'fs'\n        });\n        db.collection('fs.files').insertMany([{\n          length: 0\n        }], function (error, result) {\n          expect(error).to.not.exist;\n          expect(Object.keys(result.insertedIds).length).to.equal(1);\n          const id = result.insertedIds[0];\n          const stream = bucket.openDownloadStream(id);\n          stream.on('error', function (error) {\n            expect(error).to.not.exist;\n          });\n          stream.on('data', function () {\n            expect.fail('Should be unreachable');\n          });\n          stream.on('end', function () {\n            // As per spec, make sure we didn't actually fire a query\n            // because the document length is 0\n            expect(stream.s.cursor).to.not.exist;\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should use chunkSize for download","suites":["GridFS Stream"],"updatePoint":{"line":911,"column":39,"index":30328},"line":911,"code":"  it('should use chunkSize for download', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      if (typeof stream.pipeline !== 'function') {\n        this.skip();\n      }\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfs'\n        });\n        const uploadStream = bucket.openUploadStream('test');\n        uploadStream.end(Buffer.alloc(40 * 1024 * 1024), err => {\n          expect(err).to.not.exist;\n          const range = {\n            start: 35191617,\n            end: 35192831\n          };\n          const downloadStream = bucket.openDownloadStreamByName('test', range);\n          const outputStream = fs.createWriteStream('output');\n          stream.pipeline(downloadStream, outputStream, err => {\n            expect(err).to.not.exist;\n            client.close(() => {\n              fs.stat('output', (err, stats) => {\n                expect(err).to.not.exist;\n                expect(range.end - range.start).to.equal(stats.size);\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should correctly handle calling end function with only a callback","suites":["GridFS Stream"],"updatePoint":{"line":957,"column":71,"index":31827},"line":957,"code":"  it('should correctly handle calling end function with only a callback', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsabort',\n          chunkSizeBytes: 1\n        });\n        const CHUNKS_COLL = 'gridfsabort.chunks';\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const id = uploadStream.id;\n        const query = {\n          files_id: id\n        };\n        uploadStream.write('a', 'utf8', function (error) {\n          expect(error).to.not.exist;\n          db.collection(CHUNKS_COLL).count(query, function (error, c) {\n            expect(error).to.not.exist;\n            expect(c).to.equal(1);\n            uploadStream.abort(function (error) {\n              expect(error).to.not.exist;\n              db.collection(CHUNKS_COLL).count(query, function (error, c) {\n                expect(error).to.not.exist;\n                expect(c).to.equal(0);\n                uploadStream.write('b', 'utf8', function (error) {\n                  expect(error.toString()).to.equal('MongoAPIError: Stream has been aborted');\n                  uploadStream.end(function (error) {\n                    expect(error.toString()).to.equal('MongoAPIError: Stream has been aborted');\n\n                    // Fail if user tries to abort an aborted stream\n                    uploadStream.abort().then(null, function (error) {\n                      expect(error.toString()).to.equal(\n                      // TODO(NODE-3485): Replace with MongoGridFSStreamClosedError\n                      'MongoAPIError: Cannot call abort() on a stream twice');\n                      client.close(done);\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should not call the callback on repeat calls to end","suites":["GridFS Stream","upload stream end()"],"updatePoint":{"line":1017,"column":59,"index":34082},"line":1017,"code":"    it('should not call the callback on repeat calls to end', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n      async test() {\n        const configuration = this.configuration;\n        client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        await client.connect();\n        db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsabort',\n          chunkSizeBytes: 1\n        });\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const endPromise = new Promise(resolve => {\n          uploadStream.end('1', resolve);\n        });\n        const endPromise2 = new Promise((resolve, reject) => {\n          uploadStream.end('2', () => {\n            reject(new Error('Expected callback to not be called on duplicate end'));\n          });\n        });\n        await endPromise;\n        // in the fail case, the callback would be called when the actual write is finished,\n        // so we need to give it a moment\n        await Promise.race([endPromise2, sleep(100)]);\n      }\n    });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should not write a chunk on repeat calls to end","suites":["GridFS Stream","upload stream end()"],"updatePoint":{"line":1049,"column":55,"index":35230},"line":1049,"code":"    it('should not write a chunk on repeat calls to end', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n      async test() {\n        const configuration = this.configuration;\n        client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        await client.connect();\n        db = client.db(this.configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsabort',\n          chunkSizeBytes: 1\n        });\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const spy = sinon.spy(uploadStream, 'write');\n        const endPromise = new Promise(resolve => {\n          uploadStream.end('1', resolve);\n        });\n        await endPromise;\n        expect(spy).to.have.been.calledWith('1');\n        uploadStream.end('2');\n\n        // wait for potential async calls to happen before we close the client\n        // so that we don't get a client not connected failure in the afterEach\n        // in the failure case since it would be confusing and unnecessary\n        // given the assertions we already have for this case\n        await sleep(100);\n        expect(spy).not.to.have.been.calledWith('2');\n        expect(spy.calledOnce).to.be.true;\n      }\n    });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should return only end - start bytes when the end is within a chunk","suites":["GridFS Stream","upload stream end()"],"updatePoint":{"line":1085,"column":73,"index":36557},"line":1085,"code":"  it('should return only end - start bytes when the end is within a chunk', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test(done) {\n      // Provide start and end parameters for file download to skip\n      // ahead x bytes and limit the total amount of bytes read to n\n      const db = client.db();\n      const start = 1;\n      const end = 6;\n      const bucket = new GridFSBucket(db, {\n        bucketName: 'gridfsdownload',\n        chunkSizeBytes: 20\n      });\n      const readStream = fs.createReadStream('./LICENSE.md');\n      const uploadStream = bucket.openUploadStream('teststart.dat');\n      uploadStream.once('finish', function () {\n        const downloadStream = bucket.openDownloadStreamByName('teststart.dat', {\n          start\n        }).end(end);\n        downloadStream.on('error', done);\n        let str = '';\n        downloadStream.on('data', function (data) {\n          str += data.toString('utf8');\n        });\n        downloadStream.on('end', function () {\n          expect(str).to.equal('pache');\n          expect(str).to.have.lengthOf(end - start);\n          client.close(done);\n        });\n      });\n      readStream.pipe(uploadStream);\n    }\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should correctly handle indexes create with BSON.Double","suites":["GridFS Stream","upload stream end()"],"updatePoint":{"line":1121,"column":61,"index":37756},"line":1121,"code":"  it('should correctly handle indexes create with BSON.Double', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient();\n    client.connect((err, client) => {\n      expect(err).to.not.exist;\n      const db = client.db(configuration.db);\n      const col = db.collection('fs.files');\n      col.createIndex({\n        filename: new Double(1.0),\n        uploadDate: new Double(1.0)\n      }, err => {\n        expect(err).to.not.exist;\n        col.listIndexes().toArray((err, indexes) => {\n          expect(err).to.not.exist;\n          const names = indexes.map(i => i.name);\n          expect(names).to.eql(['_id_', 'filename_1_uploadDate_1']);\n          client.close(done);\n        });\n      });\n    });\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"NODE-2623 downloadStream should emit error on end > size","suites":["GridFS Stream","upload stream end()"],"updatePoint":{"line":1142,"column":62,"index":38514},"line":1142,"code":"  it('NODE-2623 downloadStream should emit error on end > size', function (done) {\n    const configuration = this.configuration;\n    const client = this.configuration.newClient({\n      monitorCommands: true\n    });\n    const db = client.db(configuration.db);\n    const bucket = new GridFSBucket(db, {\n      bucketName: 'gridfsdownload'\n    });\n    const readStream = fs.createReadStream('./LICENSE.md');\n    const uploadStream = bucket.openUploadStream('test.dat');\n    const actualSize = fs.fstatSync(fs.openSync('./LICENSE.md', 'r')).size;\n    const wrongExpectedSize = Math.floor(actualSize * 1.1);\n    const id = uploadStream.id;\n    uploadStream.once('finish', function () {\n      const downloadStream = bucket.openDownloadStream(id, {\n        end: wrongExpectedSize\n      });\n      downloadStream.on('data', function () {});\n      downloadStream.on('error', function (err) {\n        expect(err.message).to.equal(`Stream end (${wrongExpectedSize}) must not be more than the length of the file (${actualSize})`);\n        client.close(done);\n      });\n    });\n    readStream.pipe(uploadStream);\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"ensures chunks and files collection have required indexes when namespace does not exist","suites":["GridFS","class GridFSBucket"],"updatePoint":{"line":41,"column":95,"index":1859},"line":41,"code":"    it('ensures chunks and files collection have required indexes when namespace does not exist', async () => {\n      // Ensure the namespace does not exist; beforeEach should drop the Db, keeping this true\n      expect((await db.collections()).filter(({\n        namespace\n      }) => namespace.startsWith('fs'))).to.have.lengthOf(0);\n      const upload = bucket.openUploadStream('test.txt');\n      await once(bucket, 'index');\n      await upload.abort();\n      assertIndexesExist();\n    });","file":"integration/gridfs/gridfs.test.ts","skipped":false,"dir":"test"},{"name":"ensures chunks and files collection have required indexes when namespace does","suites":["GridFS","class GridFSBucket"],"updatePoint":{"line":51,"column":85,"index":2341},"line":51,"code":"    it('ensures chunks and files collection have required indexes when namespace does', async () => {\n      // Ensure the namespace does exist\n      await db.createCollection('fs.files');\n      await db.createCollection('fs.chunks');\n      const upload = bucket.openUploadStream('test.txt');\n      await once(bucket, 'index');\n      await upload.abort();\n      assertIndexesExist();\n    });","file":"integration/gridfs/gridfs.test.ts","skipped":false,"dir":"test"},{"name":"skips creating required indexes if they already exist","suites":["GridFS","class GridFSBucket"],"updatePoint":{"line":60,"column":61,"index":2708},"line":60,"code":"    it('skips creating required indexes if they already exist', async () => {\n      const files = await db.createCollection('fs.files');\n      const chunks = await db.createCollection('fs.chunks');\n      await files.createIndex(new Map([['filename', 1], ['uploadDate', 1]]));\n      await chunks.createIndex(new Map([['files_id', 1], ['n', 1]]));\n\n      // reset events array\n      commandStartedEvents = [];\n      const upload = bucket.openUploadStream('test.txt');\n      await once(bucket, 'index');\n      await upload.abort();\n\n      // Still listed indexes\n      const listIndexes = commandStartedEvents.filter(e => e.commandName === 'listIndexes');\n      expect(listIndexes).to.have.lengthOf(2);\n\n      // But since it found them, we didn't attempt creation\n      const createIndexes = commandStartedEvents.filter(e => e.commandName === 'createIndexes');\n      expect(createIndexes).to.have.lengthOf(0);\n    });","file":"integration/gridfs/gridfs.test.ts","skipped":false,"dir":"test"},{"name":"wraps the objectId in a document with _id as the only key","suites":["GridFS","class GridFSBucket","find(oid)","when passed an ObjectId instance as the filter"],"updatePoint":{"line":93,"column":69,"index":4067},"line":93,"code":"        it('wraps the objectId in a document with _id as the only key', async () => {\n          const oid = new ObjectId();\n          await bucket.find(oid).toArray();\n          expect(findsStarted).to.have.lengthOf(1);\n          expect(findsStarted[0]).to.have.nested.property('filter._id', oid);\n          expect(findsStarted[0].filter).to.have.all.keys('_id');\n        });","file":"integration/gridfs/gridfs.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly execute createIndex","suites":["Indexes"],"updatePoint":{"line":15,"column":42,"index":315},"line":15,"code":"  it('Should correctly execute createIndex', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient({\n        maxPoolSize: 5\n      });\n      // Create an index\n      client.db(configuration.db).createIndex('promiseCollectionCollections1', {\n        a: 1\n      }).then(function (r) {\n        test.ok(r != null);\n        client.close(done);\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute ensureIndex using Promise","suites":["Indexes"],"updatePoint":{"line":35,"column":56,"index":834},"line":35,"code":"  it('Should correctly execute ensureIndex using Promise', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient({\n        maxPoolSize: 5\n      });\n\n      // Create an index\n      client.db(configuration.db).createIndex('promiseCollectionCollections2', {\n        a: 1\n      }).then(function (r) {\n        test.ok(r != null);\n        client.close(done);\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExtractIndexInformation","suites":["Indexes"],"updatePoint":{"line":56,"column":44,"index":1342},"line":56,"code":"  it('shouldCorrectlyExtractIndexInformation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.createCollection('test_index_information', function (err, collection) {\n        collection.insertMany([{\n          a: 1\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n\n          // Create an index on the collection\n          db.createIndex(collection.collectionName, 'a', configuration.writeConcernMax(), function (err, indexName) {\n            expect(err).to.not.exist;\n            test.equal('a_1', indexName);\n\n            // Let's fetch the index information\n            db.indexInformation(collection.collectionName, function (err, collectionInfo) {\n              expect(err).to.not.exist;\n              test.ok(collectionInfo['_id_'] != null);\n              test.equal('_id', collectionInfo['_id_'][0][0]);\n              test.ok(collectionInfo['a_1'] != null);\n              test.deepEqual([['a', 1]], collectionInfo['a_1']);\n              db.indexInformation(collection.collectionName, function (err, collectionInfo2) {\n                var count1 = Object.keys(collectionInfo).length,\n                  count2 = Object.keys(collectionInfo2).length;\n\n                // Tests\n                test.ok(count2 >= count1);\n                test.ok(collectionInfo2['_id_'] != null);\n                test.equal('_id', collectionInfo2['_id_'][0][0]);\n                test.ok(collectionInfo2['a_1'] != null);\n                test.deepEqual([['a', 1]], collectionInfo2['a_1']);\n                test.ok(collectionInfo[indexName] != null);\n                test.deepEqual([['a', 1]], collectionInfo[indexName]);\n\n                // Let's close the db\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleMultipleColumnIndexes","suites":["Indexes"],"updatePoint":{"line":108,"column":48,"index":3478},"line":108,"code":"  it('shouldCorrectlyHandleMultipleColumnIndexes', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.createCollection('test_multiple_index_cols', function (err, collection) {\n        collection.insert({\n          a: 1\n        }, function (err) {\n          expect(err).to.not.exist;\n          // Create an index on the collection\n          db.createIndex(collection.collectionName, [['a', -1], ['b', 1], ['c', -1]], configuration.writeConcernMax(), function (err, indexName) {\n            expect(err).to.not.exist;\n            test.equal('a_-1_b_1_c_-1', indexName);\n            // Let's fetch the index information\n            db.indexInformation(collection.collectionName, function (err, collectionInfo) {\n              var count1 = Object.keys(collectionInfo).length;\n\n              // Test\n              test.equal(2, count1);\n              test.ok(collectionInfo[indexName] != null);\n              test.deepEqual([['a', -1], ['b', 1], ['c', -1]], collectionInfo[indexName]);\n\n              // Let's close the db\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleUniqueIndex","suites":["Indexes"],"updatePoint":{"line":146,"column":38,"index":4904},"line":146,"code":"  it('shouldCorrectlyHandleUniqueIndex', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      // Create a non-unique index and test inserts\n      db.createCollection('test_unique_index', function (err, collection) {\n        db.createIndex(collection.collectionName, 'hello', configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          // Insert some docs\n          collection.insert([{\n            hello: 'world'\n          }, {\n            hello: 'mike'\n          }, {\n            hello: 'world'\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            // Create a unique index and test that insert fails\n            db.createCollection('test_unique_index2', function (err, collection) {\n              db.createIndex(collection.collectionName, 'hello', {\n                unique: true,\n                writeConcern: {\n                  w: 1\n                }\n              }, function (err) {\n                expect(err).to.not.exist;\n                // Insert some docs\n                collection.insert([{\n                  hello: 'world'\n                }, {\n                  hello: 'mike'\n                }, {\n                  hello: 'world'\n                }], configuration.writeConcernMax(), function (err) {\n                  test.ok(err != null);\n                  test.equal(11000, err.code);\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateSubfieldIndex","suites":["Indexes"],"updatePoint":{"line":202,"column":40,"index":6835},"line":202,"code":"  it('shouldCorrectlyCreateSubfieldIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      // Create a non-unique index and test inserts\n      db.createCollection('test_index_on_subfield', function (err, collection) {\n        collection.insert([{\n          hello: {\n            a: 4,\n            b: 5\n          }\n        }, {\n          hello: {\n            a: 7,\n            b: 2\n          }\n        }, {\n          hello: {\n            a: 4,\n            b: 10\n          }\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n\n          // Create a unique subfield index and test that insert fails\n          db.createCollection('test_index_on_subfield2', function (err, collection) {\n            db.createIndex(collection.collectionName, 'hello_a', {\n              writeConcern: {\n                w: 1\n              },\n              unique: true\n            }, function (err) {\n              expect(err).to.not.exist;\n              collection.insert([{\n                hello: {\n                  a: 4,\n                  b: 5\n                }\n              }, {\n                hello: {\n                  a: 7,\n                  b: 2\n                }\n              }, {\n                hello: {\n                  a: 4,\n                  b: 10\n                }\n              }], configuration.writeConcernMax(), function (err) {\n                // Assert that we have erros\n                test.ok(err != null);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDropIndexes","suites":["Indexes"],"updatePoint":{"line":269,"column":32,"index":8723},"line":269,"code":"  it('shouldCorrectlyDropIndexes', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.createCollection('test_drop_indexes', function (err, collection) {\n        collection.insert({\n          a: 1\n        }, configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          // Create an index on the collection\n          db.createIndex(collection.collectionName, 'a', configuration.writeConcernMax(), function (err, indexName) {\n            test.equal('a_1', indexName);\n            // Drop all the indexes\n            collection.dropIndexes(function (err, result) {\n              test.equal(true, result);\n              collection.indexInformation(function (err, result) {\n                test.ok(result['a_1'] == null);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleDistinctIndexes","suites":["Indexes"],"updatePoint":{"line":302,"column":42,"index":9923},"line":302,"code":"  it('shouldCorrectlyHandleDistinctIndexes', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.createCollection('test_distinct_queries', function (err, collection) {\n        collection.insert([{\n          a: 0,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'b'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'c'\n          }\n        }, {\n          a: 2,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 3\n        }, {\n          a: 3\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          collection.distinct('a', function (err, docs) {\n            test.deepEqual([0, 1, 2, 3], docs.sort());\n            collection.distinct('b.c', function (err, docs) {\n              test.deepEqual(['a', 'b', 'c'], docs.sort());\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteEnsureIndex","suites":["Indexes"],"updatePoint":{"line":352,"column":39,"index":11211},"line":352,"code":"  it('shouldCorrectlyExecuteEnsureIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.createCollection('test_ensure_index', function (err, collection) {\n        expect(err).to.not.exist;\n        // Create an index on the collection\n        db.createIndex(collection.collectionName, 'a', configuration.writeConcernMax(), function (err, indexName) {\n          expect(err).to.not.exist;\n          test.equal('a_1', indexName);\n          // Let's fetch the index information\n          db.indexInformation(collection.collectionName, function (err, collectionInfo) {\n            test.ok(collectionInfo['_id_'] != null);\n            test.equal('_id', collectionInfo['_id_'][0][0]);\n            test.ok(collectionInfo['a_1'] != null);\n            test.deepEqual([['a', 1]], collectionInfo['a_1']);\n            db.createIndex(collection.collectionName, 'a', configuration.writeConcernMax(), function (err, indexName) {\n              test.equal('a_1', indexName);\n              // Let's fetch the index information\n              db.indexInformation(collection.collectionName, function (err, collectionInfo) {\n                test.ok(collectionInfo['_id_'] != null);\n                test.equal('_id', collectionInfo['_id_'][0][0]);\n                test.ok(collectionInfo['a_1'] != null);\n                test.deepEqual([['a', 1]], collectionInfo['a_1']);\n                // Let's close the db\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateAndUseSparseIndex","suites":["Indexes"],"updatePoint":{"line":393,"column":44,"index":13044},"line":393,"code":"  it('shouldCorrectlyCreateAndUseSparseIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.createCollection('create_and_use_sparse_index_test', function (err) {\n        expect(err).to.not.exist;\n        const collection = db.collection('create_and_use_sparse_index_test');\n        collection.createIndex({\n          title: 1\n        }, {\n          sparse: true,\n          writeConcern: {\n            w: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.insert([{\n            name: 'Jim'\n          }, {\n            name: 'Sarah',\n            title: 'Princess'\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.find({\n              title: {\n                $ne: null\n              }\n            }).sort({\n              title: 1\n            }).toArray(function (err, items) {\n              test.equal(1, items.length);\n              test.equal('Sarah', items[0].name);\n\n              // Fetch the info for the indexes\n              collection.indexInformation({\n                full: true\n              }, function (err, indexInfo) {\n                expect(err).to.not.exist;\n                test.equal(2, indexInfo.length);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleGeospatialIndexes","suites":["Indexes"],"updatePoint":{"line":448,"column":44,"index":14736},"line":448,"code":"  it('shouldCorrectlyHandleGeospatialIndexes', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.6.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.createCollection('geospatial_index_test', function (err) {\n        expect(err).to.not.exist;\n        const collection = db.collection('geospatial_index_test');\n        collection.createIndex({\n          loc: '2d'\n        }, configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          collection.insert({\n            loc: [-100, 100]\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.insert({\n              loc: [200, 200]\n            }, configuration.writeConcernMax(), function (err) {\n              test.ok(err.errmsg.indexOf('point not in interval of') !== -1);\n              test.ok(err.errmsg.indexOf('-180') !== -1);\n              test.ok(err.errmsg.indexOf('180') !== -1);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleGeospatialIndexesAlteredRange","suites":["Indexes"],"updatePoint":{"line":487,"column":56,"index":16213},"line":487,"code":"  it('shouldCorrectlyHandleGeospatialIndexesAlteredRange', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.6.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.createCollection('geospatial_index_altered_test', function (err) {\n        expect(err).to.not.exist;\n        const collection = db.collection('geospatial_index_altered_test');\n        collection.createIndex({\n          loc: '2d'\n        }, {\n          min: 0,\n          max: 1024,\n          writeConcern: {\n            w: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.insert({\n            loc: [100, 100]\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.insert({\n              loc: [200, 200]\n            }, configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist;\n              collection.insert({\n                loc: [-200, -200]\n              }, configuration.writeConcernMax(), function (err) {\n                test.ok(err.errmsg.indexOf('point not in interval of') !== -1);\n                test.ok(err.errmsg.indexOf('0') !== -1);\n                test.ok(err.errmsg.indexOf('1024') !== -1);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldThrowDuplicateKeyErrorWhenCreatingIndex","suites":["Indexes"],"updatePoint":{"line":537,"column":51,"index":17973},"line":537,"code":"  it('shouldThrowDuplicateKeyErrorWhenCreatingIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.createCollection('shouldThrowDuplicateKeyErrorWhenCreatingIndex', function (err, collection) {\n        collection.insert([{\n          a: 1\n        }, {\n          a: 1\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          collection.createIndex({\n            a: 1\n          }, {\n            unique: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            test.ok(err != null);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldThrowDuplicateKeyErrorWhenDriverInStrictMode","suites":["Indexes"],"updatePoint":{"line":571,"column":56,"index":18967},"line":571,"code":"  it('shouldThrowDuplicateKeyErrorWhenDriverInStrictMode', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.createCollection('shouldThrowDuplicateKeyErrorWhenDriverInStrictMode', function (err, collection) {\n        collection.insert([{\n          a: 1\n        }, {\n          a: 1\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          collection.createIndex({\n            a: 1\n          }, {\n            unique: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            test.ok(err != null);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUseMinMaxForSettingRangeInEnsureIndex","suites":["Indexes"],"updatePoint":{"line":605,"column":58,"index":19968},"line":605,"code":"  it('shouldCorrectlyUseMinMaxForSettingRangeInEnsureIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      // Establish connection to db\n      db.createCollection('shouldCorrectlyUseMinMaxForSettingRangeInEnsureIndex', function (err, collection) {\n        expect(err).to.not.exist;\n        collection.createIndex({\n          loc: '2d'\n        }, {\n          min: 200,\n          max: 1400,\n          writeConcern: {\n            w: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.insert({\n            loc: [600, 600]\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"Should correctly create an index with overriden name","suites":["Indexes"],"updatePoint":{"line":640,"column":58,"index":21038},"line":640,"code":"  it('Should correctly create an index with overriden name', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      // Establish connection to db\n      db.createCollection('shouldCorrectlyCreateAnIndexWithOverridenName', function (err, collection) {\n        expect(err).to.not.exist;\n        collection.createIndex('name', {\n          name: 'myfunky_name'\n        }, function (err) {\n          expect(err).to.not.exist;\n\n          // Fetch full index information\n          collection.indexInformation({\n            full: false\n          }, function (err, indexInformation) {\n            test.ok(indexInformation['myfunky_name'] != null);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should handle index declarations using objects from other contexts","suites":["Indexes"],"updatePoint":{"line":671,"column":72,"index":22084},"line":671,"code":"  it('should handle index declarations using objects from other contexts', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.collection('indexcontext').createIndex(shared.object, {\n        background: true\n      }, function (err) {\n        expect(err).to.not.exist;\n        db.collection('indexcontext').createIndex(shared.array, {\n          background: true\n        }, function (err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly return error message when applying unique index to duplicate documents","suites":["Indexes"],"updatePoint":{"line":696,"column":93,"index":22914},"line":696,"code":"  it('should correctly return error message when applying unique index to duplicate documents', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      var collection = db.collection('should_throw_error_due_to_duplicates');\n      collection.insert([{\n        a: 1\n      }, {\n        a: 1\n      }, {\n        a: 1\n      }], configuration.writeConcernMax(), function (err) {\n        expect(err).to.not.exist;\n        collection.createIndex({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          },\n          unique: true\n        }, function (err) {\n          test.ok(err != null);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly drop index with no callback","suites":["Indexes"],"updatePoint":{"line":731,"column":50,"index":23854},"line":731,"code":"  it('should correctly drop index with no callback', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      var collection = db.collection('should_correctly_drop_index');\n      collection.insert([{\n        a: 1\n      }], configuration.writeConcernMax(), function (err) {\n        expect(err).to.not.exist;\n        collection.createIndex({\n          a: 1\n        }, configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          collection.dropIndex('a_1').then(() => {\n            client.close(done);\n          }).catch(err => {\n            client.close();\n            done(err);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly apply hint to find","suites":["Indexes"],"updatePoint":{"line":762,"column":41,"index":24819},"line":762,"code":"  it('should correctly apply hint to find', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      var collection = db.collection('should_correctly_apply_hint');\n      collection.insert([{\n        a: 1\n      }], configuration.writeConcernMax(), function (err) {\n        expect(err).to.not.exist;\n        collection.createIndex({\n          a: 1\n        }, configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          collection.indexInformation({\n            full: false\n          }, function (err) {\n            expect(err).to.not.exist;\n            collection.find({}, {\n              hint: 'a_1'\n            }).toArray(function (err, docs) {\n              expect(err).to.not.exist;\n              test.equal(1, docs[0].a);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly set language_override option","suites":["Indexes"],"updatePoint":{"line":799,"column":51,"index":26000},"line":799,"code":"  it('should correctly set language_override option', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      var collection = db.collection('should_correctly_set_language_override');\n      collection.insert([{\n        text: 'Lorem ipsum dolor sit amet.',\n        langua: 'italian'\n      }], function (err) {\n        expect(err).to.not.exist;\n        collection.createIndex({\n          text: 'text'\n        }, {\n          language_override: 'langua',\n          name: 'language_override_index'\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.indexInformation({\n            full: true\n          }, function (err, indexInformation) {\n            expect(err).to.not.exist;\n            for (var i = 0; i < indexInformation.length; i++) {\n              if (indexInformation[i].name === 'language_override_index') test.equal(indexInformation[i].language_override, 'langua');\n            }\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly use listIndexes to retrieve index list","suites":["Indexes"],"updatePoint":{"line":838,"column":61,"index":27350},"line":838,"code":"  it('should correctly use listIndexes to retrieve index list', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.4.0',\n        topology: ['single', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.collection('testListIndexes').createIndex({\n        a: 1\n      }, function (err) {\n        expect(err).to.not.exist;\n\n        // Get the list of indexes\n        db.collection('testListIndexes').listIndexes().toArray(function (err, indexes) {\n          expect(err).to.not.exist;\n          test.equal(2, indexes.length);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly use listIndexes to retrieve index list using hasNext","suites":["Indexes"],"updatePoint":{"line":865,"column":75,"index":28186},"line":865,"code":"  it('should correctly use listIndexes to retrieve index list using hasNext', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.4.0',\n        topology: ['single', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.collection('testListIndexes_2').createIndex({\n        a: 1\n      }, function (err) {\n        expect(err).to.not.exist;\n\n        // Get the list of indexes\n        db.collection('testListIndexes_2').listIndexes().hasNext(function (err, result) {\n          expect(err).to.not.exist;\n          test.equal(true, result);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly ensureIndex for nested style index name c.d","suites":["Indexes"],"updatePoint":{"line":892,"column":66,"index":29011},"line":892,"code":"  it('should correctly ensureIndex for nested style index name c.d', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.4.0',\n        topology: ['single', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.collection('ensureIndexWithNestedStyleIndex').createIndex({\n        'c.d': 1\n      }, function (err) {\n        expect(err).to.not.exist;\n\n        // Get the list of indexes\n        db.collection('ensureIndexWithNestedStyleIndex').listIndexes().toArray(function (err, indexes) {\n          expect(err).to.not.exist;\n          test.equal(2, indexes.length);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute createIndexes with multiple indexes","suites":["Indexes"],"updatePoint":{"line":919,"column":66,"index":29874},"line":919,"code":"  it('should correctly execute createIndexes with multiple indexes', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.collection('createIndexes').createIndexes([{\n        key: {\n          a: 1\n        }\n      }, {\n        key: {\n          b: 1\n        },\n        name: 'hello1'\n      }], function (err, r) {\n        expect(err).to.not.exist;\n        expect(r).to.deep.equal(['a_1', 'hello1']);\n        db.collection('createIndexes').listIndexes().toArray(function (err, docs) {\n          expect(err).to.not.exist;\n          var keys = {};\n          for (var i = 0; i < docs.length; i++) {\n            keys[docs[i].name] = true;\n          }\n          test.ok(keys['a_1']);\n          test.ok(keys['hello1']);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute createIndexes with one index","suites":["Indexes"],"updatePoint":{"line":957,"column":59,"index":30935},"line":957,"code":"  it('should correctly execute createIndexes with one index', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.collection('createIndexes').createIndexes([{\n        key: {\n          a: 1\n        }\n      }], function (err, r) {\n        expect(err).to.not.exist;\n        expect(r).to.deep.equal(['a_1']);\n        db.collection('createIndexes').listIndexes().toArray(function (err, docs) {\n          expect(err).to.not.exist;\n          var keys = {};\n          for (var i = 0; i < docs.length; i++) {\n            keys[docs[i].name] = true;\n          }\n          test.ok(keys['a_1']);\n          test.ok(keys['hello1']);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateTextIndex","suites":["Indexes"],"updatePoint":{"line":990,"column":36,"index":31888},"line":990,"code":"  it('shouldCorrectlyCreateTextIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      db.collection('text_index').createIndex({\n        '$**': 'text'\n      }, {\n        name: 'TextIndex'\n      }, function (err, r) {\n        expect(err).to.not.exist;\n        test.equal('TextIndex', r);\n        // Let's close the db\n        client.close(done);\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly pass partialIndexes through to createIndexCommand","suites":["Indexes"],"updatePoint":{"line":1014,"column":72,"index":32612},"line":1014,"code":"  it('should correctly pass partialIndexes through to createIndexCommand', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger'],\n        mongodb: '>=3.1.8'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var started = [];\n      var succeeded = [];\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      client.on('commandStarted', function (event) {\n        if (event.commandName === 'createIndexes') started.push(event);\n      });\n      client.on('commandSucceeded', function (event) {\n        if (event.commandName === 'createIndexes') succeeded.push(event);\n      });\n      var db = client.db(configuration.db);\n      db.collection('partialIndexes').createIndex({\n        a: 1\n      }, {\n        partialFilterExpression: {\n          a: 1\n        }\n      }, function (err) {\n        expect(err).to.not.exist;\n        test.deepEqual({\n          a: 1\n        }, started[0].command.indexes[0].partialFilterExpression);\n        client.close(done);\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should not retry partial index expression error","suites":["Indexes"],"updatePoint":{"line":1051,"column":53,"index":33767},"line":1051,"code":"  it('should not retry partial index expression error', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded'],\n        mongodb: '>=3.1.8'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      // Can't use $exists: false in partial filter expression, see\n      // https://jira.mongodb.org/browse/SERVER-17853\n      var opts = {\n        partialFilterExpression: {\n          a: {\n            $exists: false\n          }\n        }\n      };\n      db.collection('partialIndexes').createIndex({\n        a: 1\n      }, opts, function (err) {\n        test.ok(err);\n        test.equal(err.code, 67);\n        var msg = \"key $exists must not start with '$'\";\n        test.ok(err.toString().indexOf(msg) === -1);\n        client.close(done);\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly create index on embedded key","suites":["Indexes"],"updatePoint":{"line":1084,"column":51,"index":34745},"line":1084,"code":"  it('should correctly create index on embedded key', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      var collection = db.collection('embedded_key_indes');\n      collection.insertMany([{\n        a: {\n          a: 1\n        }\n      }, {\n        a: {\n          a: 2\n        }\n      }], function (err) {\n        expect(err).to.not.exist;\n        collection.createIndex({\n          'a.a': 1\n        }, function (err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly create index using . keys","suites":["Indexes"],"updatePoint":{"line":1116,"column":48,"index":35578},"line":1116,"code":"  it('should correctly create index using . keys', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      var collection = db.collection('embedded_key_indes_1');\n      collection.createIndex({\n        'key.external_id': 1,\n        'key.type': 1\n      }, {\n        unique: true,\n        sparse: true,\n        name: 'indexname'\n      }, function (err) {\n        expect(err).to.not.exist;\n        client.close(done);\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"error on duplicate key index","suites":["Indexes"],"updatePoint":{"line":1142,"column":34,"index":36314},"line":1142,"code":"  it('error on duplicate key index', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      var collection = db.collection('embedded_key_indes_2');\n      collection.insertMany([{\n        key: {\n          external_id: 1,\n          type: 1\n        }\n      }, {\n        key: {\n          external_id: 1,\n          type: 1\n        }\n      }], function (err) {\n        expect(err).to.not.exist;\n        collection.createIndex({\n          'key.external_id': 1,\n          'key.type': 1\n        }, {\n          unique: true,\n          sparse: true,\n          name: 'indexname'\n        }, function (err) {\n          test.equal(11000, err.code);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly create Index with sub element","suites":["Indexes"],"updatePoint":{"line":1181,"column":52,"index":37344},"line":1181,"code":"  it('should correctly create Index with sub element', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      // insert a doc\n      db.collection('messed_up_index').createIndex({\n        temporary: 1,\n        'store.addressLines': 1,\n        lifecycleStatus: 1\n      }, configuration.writeConcernMax(), function (err) {\n        expect(err).to.not.exist;\n        client.close(done);\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly fail detect error code 85 when performing createIndex","suites":["Indexes"],"updatePoint":{"line":1204,"column":76,"index":38086},"line":1204,"code":"  it('should correctly fail detect error code 85 when performing createIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger'],\n        mongodb: '>=3.0.0 <=4.8.0'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      var collection = db.collection('messed_up_options');\n      collection.createIndex({\n        'a.one': 1,\n        'a.two': 1\n      }, {\n        name: 'n1',\n        sparse: false\n      }, function (err) {\n        expect(err).to.not.exist;\n        collection.createIndex({\n          'a.one': 1,\n          'a.two': 1\n        }, {\n          name: 'n2',\n          sparse: true\n        }, function (err) {\n          test.ok(err);\n          test.equal(85, err.code);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly fail by detecting error code 86 when performing createIndex","suites":["Indexes"],"updatePoint":{"line":1240,"column":82,"index":39098},"line":1240,"code":"  it('should correctly fail by detecting error code 86 when performing createIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger'],\n        mongodb: '>=3.0.0'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      var collection = db.collection('messed_up_options');\n      collection.createIndex({\n        'b.one': 1,\n        'b.two': 1\n      }, {\n        name: 'test'\n      }, function (err) {\n        expect(err).to.not.exist;\n        collection.createIndex({\n          'b.one': -1,\n          'b.two': -1\n        }, {\n          name: 'test'\n        }, function (err) {\n          test.ok(err);\n          test.equal(86, err.code);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly create Index with sub element running in background","suites":["Indexes"],"updatePoint":{"line":1274,"column":74,"index":40053},"line":1274,"code":"  it('should correctly create Index with sub element running in background', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var db = client.db(configuration.db);\n      // insert a doc\n      db.collection('messed_up_index_2').createIndex({\n        'accessControl.get': 1\n      }, {\n        background: true\n      }, function (err) {\n        expect(err).to.not.exist;\n        client.close(done);\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if commitQuorum specified on db.createIndex","suites":["Indexes","commitQuorum"],"updatePoint":{"line":1326,"column":73,"index":41593},"line":1326,"code":"    it('should throw an error if commitQuorum specified on db.createIndex', throwErrorTest((db, collection, cb) => db.createIndex(collection.collectionName, 'a', {\n      commitQuorum: 'all'\n    }, cb)));","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if commitQuorum specified on collection.createIndex","suites":["Indexes","commitQuorum"],"updatePoint":{"line":1329,"column":81,"index":41805},"line":1329,"code":"    it('should throw an error if commitQuorum specified on collection.createIndex', throwErrorTest((db, collection, cb) => collection.createIndex('a', {\n      commitQuorum: 'all'\n    }, cb)));","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if commitQuorum specified on collection.createIndexes","suites":["Indexes","commitQuorum"],"updatePoint":{"line":1332,"column":83,"index":42000},"line":1332,"code":"    it('should throw an error if commitQuorum specified on collection.createIndexes', throwErrorTest((db, collection, cb) => collection.createIndexes([{\n      key: {\n        a: 1\n      }\n    }, {\n      key: {\n        b: 1\n      }\n    }], {\n      commitQuorum: 'all'\n    }, cb)));","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should run command with commitQuorum if specified on db.createIndex","suites":["Indexes","commitQuorum"],"updatePoint":{"line":1375,"column":75,"index":43309},"line":1375,"code":"    it('should run command with commitQuorum if specified on db.createIndex', commitQuorumTest((db, collection, cb) => db.createIndex(collection.collectionName, 'a', {\n      writeConcern: {\n        w: 'majority'\n      },\n      commitQuorum: 0\n    }, cb)));","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should run command with commitQuorum if specified on collection.createIndex","suites":["Indexes","commitQuorum"],"updatePoint":{"line":1381,"column":83,"index":43574},"line":1381,"code":"    it('should run command with commitQuorum if specified on collection.createIndex', commitQuorumTest((db, collection, cb) => collection.createIndex('a', {\n      writeConcern: {\n        w: 'majority'\n      },\n      commitQuorum: 0\n    }, cb)));","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should run command with commitQuorum if specified on collection.createIndexes","suites":["Indexes","commitQuorum"],"updatePoint":{"line":1387,"column":85,"index":43822},"line":1387,"code":"    it('should run command with commitQuorum if specified on collection.createIndexes', commitQuorumTest((db, collection, cb) => collection.createIndexes([{\n      key: {\n        a: 1\n      }\n    }], {\n      writeConcern: {\n        w: 'majority'\n      },\n      commitQuorum: 0\n    }, cb)));","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should create index hidden","suites":["Indexes","commitQuorum"],"updatePoint":{"line":1398,"column":32,"index":44065},"line":1398,"code":"  it('should create index hidden', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.4',\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      const db = client.db(configuration.db);\n      db.createCollection('hidden_index_collection', (err, collection) => {\n        expect(err).to.not.exist;\n        collection.createIndex('a', {\n          hidden: true\n        }, (err, index) => {\n          expect(err).to.not.exist;\n          expect(index).to.equal('a_1');\n          collection.listIndexes().toArray((err, indexes) => {\n            expect(err).to.not.exist;\n            expect(indexes).to.deep.equal([{\n              v: 2,\n              key: {\n                _id: 1\n              },\n              name: '_id_'\n            }, {\n              v: 2,\n              key: {\n                a: 1\n              },\n              name: 'a_1',\n              hidden: true\n            }]);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly set maxStalenessSeconds on Mongos query on connect","suites":["Max Staleness"],"updatePoint":{"line":54,"column":73,"index":1382},"line":54,"code":"  it('should correctly set maxStalenessSeconds on Mongos query on connect', {\n    metadata: {\n      requires: {\n        generators: true,\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      const configuration = this.configuration;\n      const client = configuration.newClient(`mongodb://${test.server.uri()}/test?readPreference=secondary&maxStalenessSeconds=250`);\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(self.configuration.db);\n        db.collection('test').find({}).toArray(function (err) {\n          expect(err).to.not.exist;\n          expect(test.checkCommand).to.containSubset({\n            $query: {\n              find: 'test',\n              filter: {}\n            },\n            $readPreference: {\n              mode: 'secondary',\n              maxStalenessSeconds: 250\n            }\n          });\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/max-staleness/max_staleness.test.js","skipped":false,"dir":"test"},{"name":"should correctly set maxStalenessSeconds on Mongos query using db level readPreference","suites":["Max Staleness"],"updatePoint":{"line":85,"column":92,"index":2385},"line":85,"code":"  it('should correctly set maxStalenessSeconds on Mongos query using db level readPreference', {\n    metadata: {\n      requires: {\n        generators: true,\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(`mongodb://${test.server.uri()}/test`);\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n\n        // Get a db with a new readPreference\n        var db1 = client.db('test', {\n          readPreference: new ReadPreference('secondary', null, {\n            maxStalenessSeconds: 250\n          })\n        });\n        db1.collection('test').find({}).toArray(function (err) {\n          expect(err).to.not.exist;\n          expect(test.checkCommand).to.containSubset({\n            $query: {\n              find: 'test',\n              filter: {}\n            },\n            $readPreference: {\n              mode: 'secondary',\n              maxStalenessSeconds: 250\n            }\n          });\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/max-staleness/max_staleness.test.js","skipped":false,"dir":"test"},{"name":"should correctly set maxStalenessSeconds on Mongos query using collection level readPreference","suites":["Max Staleness"],"updatePoint":{"line":121,"column":100,"index":3487},"line":121,"code":"  it('should correctly set maxStalenessSeconds on Mongos query using collection level readPreference', {\n    metadata: {\n      requires: {\n        generators: true,\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      const configuration = this.configuration;\n      const client = configuration.newClient(`mongodb://${test.server.uri()}/test`);\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(self.configuration.db);\n\n        // Get a db with a new readPreference\n        db.collection('test', {\n          readPreference: new ReadPreference('secondary', null, {\n            maxStalenessSeconds: 250\n          })\n        }).find({}).toArray(function (err) {\n          expect(err).to.not.exist;\n          expect(test.checkCommand).to.containSubset({\n            $query: {\n              find: 'test',\n              filter: {}\n            },\n            $readPreference: {\n              mode: 'secondary',\n              maxStalenessSeconds: 250\n            }\n          });\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/max-staleness/max_staleness.test.js","skipped":false,"dir":"test"},{"name":"should correctly set maxStalenessSeconds on Mongos query using cursor level readPreference","suites":["Max Staleness"],"updatePoint":{"line":158,"column":96,"index":4621},"line":158,"code":"  it('should correctly set maxStalenessSeconds on Mongos query using cursor level readPreference', {\n    metadata: {\n      requires: {\n        generators: true,\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      const configuration = this.configuration;\n      const client = configuration.newClient(`mongodb://${test.server.uri()}/test`);\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(self.configuration.db);\n        var readPreference = new ReadPreference('secondary', null, {\n          maxStalenessSeconds: 250\n        });\n\n        // Get a db with a new readPreference\n        db.collection('test').find({}).withReadPreference(readPreference).toArray(function (err) {\n          expect(err).to.not.exist;\n          expect(test.checkCommand).to.containSubset({\n            $query: {\n              find: 'test',\n              filter: {}\n            },\n            $readPreference: {\n              mode: 'secondary',\n              maxStalenessSeconds: 250\n            }\n          });\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/max-staleness/max_staleness.test.js","skipped":false,"dir":"test"},{"name":"metadata confirmation test for ","suites":["Handshake Prose Tests"],"updatePoint":{"line":57,"column":48,"index":1971},"line":57,"code":"      it(`metadata confirmation test for ${name}`, function () {\n        expect(getFAASEnv()?.get('name')).to.equal(expectedProvider, 'determined the wrong cloud provider');\n      });","file":"integration/mongodb-handshake/mongodb-handshake.prose.test.ts","skipped":false,"dir":"test"},{"name":"runs a hello successfully","suites":["Handshake Prose Tests"],"updatePoint":{"line":60,"column":35,"index":2142},"line":60,"code":"      it('runs a hello successfully', async function () {\n        client = this.configuration.newClient({\n          // if the handshake is not truncated, the `hello`s fail and the client does\n          // not connect.  Lowering the server selection timeout causes the tests\n          // to fail more quickly in that scenario.\n          serverSelectionTimeoutMS: 3000\n        });\n        await client.connect();\n      });","file":"integration/mongodb-handshake/mongodb-handshake.prose.test.ts","skipped":false,"dir":"test"},{"name":"should fail with an error relating to size","suites":["MongoDB Handshake","when hello is too large"],"updatePoint":{"line":26,"column":50,"index":995},"line":26,"code":"    it('should fail with an error relating to size', async function () {\n      client = this.configuration.newClient({\n        serverSelectionTimeoutMS: 2000\n      });\n      const error = await client.connect().catch(error => error);\n      if (this.configuration.isLoadBalanced) {\n        expect(error).to.be.instanceOf(MongoServerError);\n      } else {\n        expect(error).to.be.instanceOf(MongoServerSelectionError);\n      }\n      expect(error).to.match(/client metadata document must be less/);\n    });","file":"integration/mongodb-handshake/mongodb-handshake.test.ts","skipped":false,"dir":"test"},{"name":"constructs a handshake with the specified compressors","suites":["MongoDB Handshake","when compressors are provided on the mongo client"],"updatePoint":{"line":45,"column":61,"index":1721},"line":45,"code":"    it('constructs a handshake with the specified compressors', async function () {\n      client = this.configuration.newClient({\n        compressors: ['snappy']\n      });\n      await client.connect();\n      expect(spy.called).to.be.true;\n      const handshakeDoc = spy.getCall(0).args[1];\n      expect(handshakeDoc).to.have.property('compression').to.deep.equal(['snappy']);\n    });","file":"integration/mongodb-handshake/mongodb-handshake.test.ts","skipped":false,"dir":"test"},{"name":"supports mapping to falsey value ''","suites":["class AbstractCursor","toArray() with custom transforms"],"updatePoint":{"line":23,"column":62,"index":804},"line":23,"code":"      it(`supports mapping to falsey value '${inspect(value)}'`, async function () {\n        const cursor = collection.find();\n        cursor.map(() => value);\n        const result = await cursor.toArray();\n        const expected = Array.from({\n          length: 5\n        }, () => value);\n        expect(result).to.deep.equal(expected);\n      });","file":"integration/node-specific/abstract_cursor.test.ts","skipped":false,"dir":"test"},{"name":"throws when mapping to `null` and cleans up cursor","suites":["class AbstractCursor","toArray() with custom transforms"],"updatePoint":{"line":33,"column":58,"index":1154},"line":33,"code":"    it('throws when mapping to `null` and cleans up cursor', async function () {\n      const cursor = collection.find();\n      cursor.map(() => null);\n      const error = await cursor.toArray().catch(e => e);\n      expect(error).be.instanceOf(MongoAPIError);\n      expect(cursor.closed).to.be.true;\n    });","file":"integration/node-specific/abstract_cursor.test.ts","skipped":false,"dir":"test"},{"name":"supports mapping to falsey value ''","suites":["class AbstractCursor","Symbol.asyncIterator() with custom transforms"],"updatePoint":{"line":43,"column":62,"index":1584},"line":43,"code":"      it(`supports mapping to falsey value '${inspect(value)}'`, async function () {\n        const cursor = collection.find();\n        cursor.map(() => value);\n        let count = 0;\n        for await (const document of cursor) {\n          expect(document).to.deep.equal(value);\n          count++;\n        }\n        expect(count).to.equal(5);\n      });","file":"integration/node-specific/abstract_cursor.test.ts","skipped":false,"dir":"test"},{"name":"throws when mapping to `null` and cleans up cursor","suites":["class AbstractCursor","Symbol.asyncIterator() with custom transforms"],"updatePoint":{"line":54,"column":58,"index":1939},"line":54,"code":"    it('throws when mapping to `null` and cleans up cursor', async function () {\n      const cursor = collection.find();\n      cursor.map(() => null);\n      try {\n        // eslint-disable-next-line @typescript-eslint/no-unused-vars\n        for await (const document of cursor) {\n          expect.fail('Expected error to be thrown');\n        }\n      } catch (error) {\n        expect(error).to.be.instanceOf(MongoAPIError);\n        expect(cursor.closed).to.be.true;\n      }\n    });","file":"integration/node-specific/abstract_cursor.test.ts","skipped":false,"dir":"test"},{"name":"supports mapping to falsey value ''","suites":["class AbstractCursor","forEach() with custom transforms"],"updatePoint":{"line":70,"column":62,"index":2530},"line":70,"code":"      it(`supports mapping to falsey value '${inspect(value)}'`, async function () {\n        const cursor = collection.find();\n        cursor.map(() => value);\n        let count = 0;\n        function transform(value) {\n          expect(value).to.deep.equal(value);\n          count++;\n        }\n        await cursor.forEach(transform);\n        expect(count).to.equal(5);\n      });","file":"integration/node-specific/abstract_cursor.test.ts","skipped":false,"dir":"test"},{"name":"throws when mapping to `null` and cleans up cursor","suites":["class AbstractCursor","forEach() with custom transforms"],"updatePoint":{"line":82,"column":58,"index":2912},"line":82,"code":"    it('throws when mapping to `null` and cleans up cursor', async function () {\n      const cursor = collection.find();\n      cursor.map(() => null);\n      function iterator() {\n        expect.fail('Expected no documents from cursor, received at least one.');\n      }\n      const error = await cursor.forEach(iterator).catch(e => e);\n      expect(error).to.be.instanceOf(MongoAPIError);\n      expect(cursor.closed).to.be.true;\n    });","file":"integration/node-specific/abstract_cursor.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Admin","#addUser()"],"updatePoint":{"line":19,"column":35,"index":816},"line":19,"code":"      it('should connect the client', async () => {\n        const admin = client.db().admin();\n        await admin.addUser('neal', 'iLoveJavaScript', {\n          roles: ['root']\n        }).catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Admin","#buildInfo()"],"updatePoint":{"line":28,"column":35,"index":1161},"line":28,"code":"      it('should connect the client', async () => {\n        const admin = client.db().admin();\n        await admin.buildInfo();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Admin","#command()"],"updatePoint":{"line":35,"column":35,"index":1424},"line":35,"code":"      it('should connect the client', async () => {\n        const admin = client.db().admin();\n        await admin.command({\n          ping: 1\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Admin","#listDatabases()"],"updatePoint":{"line":44,"column":35,"index":1720},"line":44,"code":"      it('should connect the client', async () => {\n        const admin = client.db().admin();\n        await admin.listDatabases();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Admin","#ping()"],"updatePoint":{"line":51,"column":35,"index":1984},"line":51,"code":"      it('should connect the client', async () => {\n        const admin = client.db().admin();\n        await admin.ping();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Admin","#removeUser()"],"updatePoint":{"line":58,"column":35,"index":2245},"line":58,"code":"      it('should connect the client', async () => {\n        const admin = client.db().admin();\n        await admin.removeUser('neal').catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Admin","#replSetGetStatus()"],"updatePoint":{"line":65,"column":35,"index":2542},"line":65,"code":"      it('should connect the client', {\n        requires: {\n          topology: 'replicaset'\n        }\n      }, async () => {\n        const admin = client.db().admin();\n        await admin.replSetGetStatus();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Admin","#serverInfo()"],"updatePoint":{"line":76,"column":35,"index":2889},"line":76,"code":"      it('should connect the client', async () => {\n        const admin = client.db().admin();\n        await admin.serverInfo();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Admin","#serverStatus()"],"updatePoint":{"line":83,"column":35,"index":3158},"line":83,"code":"      it('should connect the client', async () => {\n        const admin = client.db().admin();\n        await admin.serverStatus();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Admin","#validateCollection()"],"updatePoint":{"line":90,"column":35,"index":3435},"line":90,"code":"      it('should connect the client', async () => {\n        const admin = client.db().admin();\n        await admin.validateCollection('test').catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class AggregationCursor","#explain()"],"updatePoint":{"line":106,"column":35,"index":3899},"line":106,"code":"      it('should connect the client', async () => {\n        const agg = client.db().collection('test').aggregate(pipeline);\n        await agg.explain().catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class AggregationCursor","#close()"],"updatePoint":{"line":113,"column":35,"index":4203},"line":113,"code":"      it('should connect the client', async () => {\n        const agg = client.db().collection('test').aggregate(pipeline);\n        await agg.close().catch(error => {\n          expect.fail('cursor.close should work without connecting: ' + error.message);\n        });\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class AggregationCursor","#forEach()"],"updatePoint":{"line":121,"column":35,"index":4523},"line":121,"code":"      it('should connect the client', async () => {\n        const agg = client.db().collection('test').aggregate(pipeline);\n        await agg.forEach(item => {\n          expect(item).to.be.a('object');\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class AggregationCursor","#hasNext()"],"updatePoint":{"line":130,"column":35,"index":4872},"line":130,"code":"      it('should connect the client', async () => {\n        const agg = client.db().collection('test').aggregate(pipeline);\n        await agg.hasNext();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class AggregationCursor","#next()"],"updatePoint":{"line":137,"column":35,"index":5157},"line":137,"code":"      it('should connect the client', async () => {\n        const agg = client.db().collection('test').aggregate(pipeline);\n        await agg.next();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class AggregationCursor","#toArray()"],"updatePoint":{"line":144,"column":35,"index":5442},"line":144,"code":"      it('should connect the client', async () => {\n        const agg = client.db().collection('test').aggregate(pipeline);\n        await agg.toArray();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class AggregationCursor","#tryNext()"],"updatePoint":{"line":151,"column":35,"index":5730},"line":151,"code":"      it('should connect the client', async () => {\n        const agg = client.db().collection('test').aggregate(pipeline);\n        await agg.tryNext();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class AggregationCursor","#stream()"],"updatePoint":{"line":158,"column":35,"index":6017},"line":158,"code":"      it('should connect the client', async () => {\n        const agg = client.db().collection('test').aggregate(pipeline);\n        const stream = agg.stream();\n        await once(stream, 'readable');\n        await stream.read();\n        stream.destroy();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should not connect the client","suites":["When executing an operation for the first time","class OrderedBulkOperation","#execute()"],"updatePoint":{"line":170,"column":39,"index":6467},"line":170,"code":"      it('should not connect the client', async () => {\n        expect(() => client.db().collection('test').initializeOrderedBulkOp()).to.throw(MongoNotConnectedError);\n        expect(client).to.not.have.property('topology');\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should not connect the client","suites":["When executing an operation for the first time","class UnorderedBulkOperation","#execute()"],"updatePoint":{"line":178,"column":39,"index":6803},"line":178,"code":"      it('should not connect the client', async () => {\n        expect(() => client.db().collection('test').initializeUnorderedBulkOp()).to.throw(MongoNotConnectedError);\n        expect(client).to.not.have.property('topology');\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ChangeStream","#close()"],"updatePoint":{"line":208,"column":35,"index":7914},"line":208,"code":"      it('should connect the client', async () => {\n        await cs.close().catch(error => {\n          expect.fail('cs.close should work without connecting: ' + error.message);\n        });\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ChangeStream","#hasNext()"],"updatePoint":{"line":219,"column":35,"index":8220},"line":219,"code":"      it('should connect the client', async () => {\n        const willHaveNext = cs.hasNext();\n        await once(cs.cursor, 'init');\n        await changeCausingCollection.insertOne({\n          a: 1\n        });\n        await willHaveNext;\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ChangeStream","#next()"],"updatePoint":{"line":234,"column":35,"index":8654},"line":234,"code":"      it('should connect the client', async () => {\n        const willBeNext = cs.next();\n        await once(cs.cursor, 'init');\n        await changeCausingCollection.insertOne({\n          a: 1\n        });\n        await willBeNext;\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ChangeStream","#tryNext()"],"updatePoint":{"line":249,"column":35,"index":9084},"line":249,"code":"      it('should connect the client', async () => {\n        await cs.tryNext();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ChangeStream","#stream()"],"updatePoint":{"line":259,"column":35,"index":9361},"line":259,"code":"      it('should connect the client', async () => {\n        const stream = cs.stream();\n        const willBeNext = stream[Symbol.asyncIterator]().next();\n        await once(cs.cursor, 'init');\n        await changeCausingCollection.insertOne({\n          a: 1\n        });\n        await willBeNext;\n        stream.destroy();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ClientSession","#abortTransaction()"],"updatePoint":{"line":274,"column":35,"index":9875},"line":274,"code":"      it('should connect the client', async () => {\n        const session = client.startSession();\n        session.startTransaction();\n        await session.abortTransaction(); // Abort transaction will not connect (as expected)\n        expect(client).to.not.have.property('topology');\n        await session.endSession();\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ClientSession","#commitTransaction()"],"updatePoint":{"line":283,"column":35,"index":10260},"line":283,"code":"      it('should connect the client', async () => {\n        const session = client.startSession();\n        session.startTransaction();\n        await session.commitTransaction(); // Commit transaction will not connect (as expected)\n        expect(client).to.not.have.property('topology');\n        await session.endSession();\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ClientSession","#endSession()"],"updatePoint":{"line":292,"column":35,"index":10640},"line":292,"code":"      it('should connect the client', async () => {\n        const session = client.startSession();\n        await session.endSession();\n        expect(client).to.not.have.property('topology');\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ClientSession","#withTransaction()"],"updatePoint":{"line":299,"column":35,"index":10893},"line":299,"code":"      it('should connect the client', async () => {\n        const session = client.startSession();\n        await session.withTransaction(async () => {\n          // withTransaction will not connect (as expected)\n        });\n        await session.endSession();\n        expect(client).to.not.have.property('topology');\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#bulkWrite()"],"updatePoint":{"line":311,"column":35,"index":11309},"line":311,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.bulkWrite([{\n          insertOne: {\n            document: {\n              a: 1\n            }\n          }\n        }]);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#count()"],"updatePoint":{"line":324,"column":35,"index":11678},"line":324,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.count();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#countDocuments()"],"updatePoint":{"line":331,"column":35,"index":11947},"line":331,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.countDocuments();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#createIndex()"],"updatePoint":{"line":338,"column":35,"index":12222},"line":338,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.createIndex({\n          a: 1\n        }).catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#createIndexes()"],"updatePoint":{"line":347,"column":35,"index":12540},"line":347,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.createIndexes([{\n          key: {\n            a: 1\n          }\n        }]).catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#deleteMany()"],"updatePoint":{"line":358,"column":35,"index":12890},"line":358,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.deleteMany({\n          a: 1\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#deleteOne()"],"updatePoint":{"line":367,"column":35,"index":13185},"line":367,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.deleteOne({\n          a: 1\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#distinct()"],"updatePoint":{"line":376,"column":35,"index":13478},"line":376,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.distinct('a');\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#drop()"],"updatePoint":{"line":383,"column":35,"index":13743},"line":383,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.drop();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#dropIndex()"],"updatePoint":{"line":390,"column":35,"index":14006},"line":390,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.dropIndex('a_1').catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#dropIndexes()"],"updatePoint":{"line":397,"column":35,"index":14299},"line":397,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.dropIndexes().catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#estimatedDocumentCount()"],"updatePoint":{"line":404,"column":35,"index":14600},"line":404,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.estimatedDocumentCount();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#findOne()"],"updatePoint":{"line":411,"column":35,"index":14879},"line":411,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.findOne();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#findOneAndDelete()"],"updatePoint":{"line":418,"column":35,"index":15152},"line":418,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.findOneAndDelete({\n          a: 1\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#findOneAndReplace()"],"updatePoint":{"line":427,"column":35,"index":15461},"line":427,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.findOneAndReplace({\n          a: 1\n        }, {\n          a: 2\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#findOneAndUpdate()"],"updatePoint":{"line":438,"column":35,"index":15798},"line":438,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.findOneAndUpdate({\n          a: 1\n        }, {\n          $set: {\n            a: 2\n          }\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#indexes()"],"updatePoint":{"line":451,"column":35,"index":16157},"line":451,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.indexes().catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#indexExists()"],"updatePoint":{"line":458,"column":35,"index":16443},"line":458,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.indexExists('a_1').catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#indexInformation()"],"updatePoint":{"line":465,"column":35,"index":16743},"line":465,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.indexInformation().catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#insertMany()"],"updatePoint":{"line":472,"column":35,"index":17037},"line":472,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.insertMany([{\n          a: 1\n        }]);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#insertOne()"],"updatePoint":{"line":481,"column":35,"index":17334},"line":481,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.insertOne({\n          a: 1\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#isCapped()"],"updatePoint":{"line":490,"column":35,"index":17627},"line":490,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.isCapped();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#options()"],"updatePoint":{"line":497,"column":35,"index":17892},"line":497,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.options();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#rename()"],"updatePoint":{"line":504,"column":35,"index":18155},"line":504,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test0');\n        await c.rename('test1').catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#replaceOne()"],"updatePoint":{"line":511,"column":35,"index":18447},"line":511,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.replaceOne({\n          a: 1\n        }, {\n          a: 2\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#stats()"],"updatePoint":{"line":522,"column":35,"index":18766},"line":522,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.stats();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#updateMany()"],"updatePoint":{"line":529,"column":35,"index":19031},"line":529,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.updateMany({\n          a: 1\n        }, {\n          $set: {\n            a: 2\n          }\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Collection","#updateOne()"],"updatePoint":{"line":542,"column":35,"index":19386},"line":542,"code":"      it('should connect the client', async () => {\n        const c = client.db().collection('test');\n        await c.updateOne({\n          a: 1\n        }, {\n          $set: {\n            a: 2\n          }\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#addUser()"],"updatePoint":{"line":557,"column":35,"index":19775},"line":557,"code":"      it('should connect the client', async () => {\n        const db = client.db();\n        await db.addUser('neal', 'iLoveJavaScript', {\n          roles: ['dbAdmin']\n        }).catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#collections()"],"updatePoint":{"line":566,"column":35,"index":20111},"line":566,"code":"      it('should connect the client', async () => {\n        const db = client.db();\n        await db.collections();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#command()"],"updatePoint":{"line":573,"column":35,"index":20362},"line":573,"code":"      it('should connect the client', async () => {\n        const db = client.db();\n        await db.command({\n          ping: 1\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#createCollection()"],"updatePoint":{"line":582,"column":35,"index":20647},"line":582,"code":"      it('should connect the client', async () => {\n        const db = client.db();\n        await db.createCollection('test4');\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#createIndex()"],"updatePoint":{"line":589,"column":35,"index":20914},"line":589,"code":"      it('should connect the client', async () => {\n        const db = client.db();\n        await db.createIndex('test', {\n          a: 1\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#dropCollection()"],"updatePoint":{"line":598,"column":35,"index":21206},"line":598,"code":"      it('should connect the client', async () => {\n        const db = client.db();\n        await db.dropCollection('test');\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#dropDatabase()"],"updatePoint":{"line":605,"column":35,"index":21471},"line":605,"code":"      it('should connect the client', async () => {\n        const db = client.db();\n        await db.dropDatabase();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#indexInformation()"],"updatePoint":{"line":612,"column":35,"index":21732},"line":612,"code":"      it('should connect the client', async () => {\n        const db = client.db();\n        await db.indexInformation('test').catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#profilingLevel()"],"updatePoint":{"line":619,"column":35,"index":22019},"line":619,"code":"      it('should connect the client', async () => {\n        const db = client.db('admin');\n        await db.profilingLevel().catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#removeUser()"],"updatePoint":{"line":626,"column":35,"index":22301},"line":626,"code":"      it('should connect the client', async () => {\n        const db = client.db();\n        await db.removeUser('neal').catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#renameCollection()"],"updatePoint":{"line":633,"column":35,"index":22584},"line":633,"code":"      it('should connect the client', async () => {\n        const db = client.db();\n        await db.renameCollection('test0', 'test1').catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#setProfilingLevel()"],"updatePoint":{"line":640,"column":35,"index":22884},"line":640,"code":"      it('should connect the client', async () => {\n        const db = client.db('admin');\n        await db.setProfilingLevel(ProfilingLevel.off).catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class Db","#stats()"],"updatePoint":{"line":647,"column":35,"index":23182},"line":647,"code":"      it('should connect the client', async () => {\n        const db = client.db();\n        await db.stats();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class FindCursor","#count()"],"updatePoint":{"line":656,"column":35,"index":23470},"line":656,"code":"      it('should connect the client', async () => {\n        const find = client.db().collection('test').find();\n        await find.count();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class FindCursor","#explain()"],"updatePoint":{"line":663,"column":35,"index":23745},"line":663,"code":"      it('should connect the client', async () => {\n        const find = client.db().collection('test').find();\n        await find.explain().catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class FindCursor","#close()"],"updatePoint":{"line":670,"column":35,"index":24038},"line":670,"code":"      it('should connect the client', async () => {\n        const find = client.db().collection('test').find();\n        await find.close();\n        expect(client).to.not.have.property('topology');\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class FindCursor","#forEach()"],"updatePoint":{"line":677,"column":35,"index":24288},"line":677,"code":"      it('should connect the client', async () => {\n        const find = client.db().collection('test').find();\n        await find.forEach(item => {\n          expect(item).to.be.a('object');\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class FindCursor","#hasNext()"],"updatePoint":{"line":686,"column":35,"index":24626},"line":686,"code":"      it('should connect the client', async () => {\n        const find = client.db().collection('test').find();\n        await find.hasNext();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class FindCursor","#next()"],"updatePoint":{"line":693,"column":35,"index":24900},"line":693,"code":"      it('should connect the client', async () => {\n        const find = client.db().collection('test').find();\n        await find.next();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class FindCursor","#toArray()"],"updatePoint":{"line":700,"column":35,"index":25174},"line":700,"code":"      it('should connect the client', async () => {\n        const find = client.db().collection('test').find();\n        await find.toArray();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class FindCursor","#tryNext()"],"updatePoint":{"line":707,"column":35,"index":25451},"line":707,"code":"      it('should connect the client', async () => {\n        const find = client.db().collection('test').find();\n        await find.tryNext();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class FindCursor","#stream()"],"updatePoint":{"line":714,"column":35,"index":25727},"line":714,"code":"      it('should connect the client', async () => {\n        const find = client.db().collection('test').find();\n        const stream = find.stream();\n        await once(stream, 'readable');\n        await stream.read();\n        stream.destroy();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ListCollectionsCursor","#forEach()"],"updatePoint":{"line":729,"column":35,"index":26235},"line":729,"code":"      it('should connect the client', async () => {\n        const collections = client.db().listCollections();\n        await collections.forEach(item => {\n          expect(item).is.an('object');\n        });\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ListCollectionsCursor","#hasNext()"],"updatePoint":{"line":738,"column":35,"index":26577},"line":738,"code":"      it('should connect the client', async () => {\n        const collections = client.db().listCollections();\n        await collections.hasNext();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ListCollectionsCursor","#next()"],"updatePoint":{"line":745,"column":35,"index":26857},"line":745,"code":"      it('should connect the client', async () => {\n        const collections = client.db().listCollections();\n        await collections.next();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ListCollectionsCursor","#toArray()"],"updatePoint":{"line":752,"column":35,"index":27137},"line":752,"code":"      it('should connect the client', async () => {\n        const collections = client.db().listCollections();\n        await collections.toArray();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ListCollectionsCursor","#tryNext()"],"updatePoint":{"line":759,"column":35,"index":27420},"line":759,"code":"      it('should connect the client', async () => {\n        const collections = client.db().listCollections();\n        await collections.tryNext();\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ListIndexesCursor","#forEach()"],"updatePoint":{"line":768,"column":35,"index":27755},"line":768,"code":"      it('should connect the client', async () => {\n        const indexes = client.db().collection('test').listIndexes();\n        await indexes.forEach(item => {\n          expect(item).is.an('object');\n        }).catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ListIndexesCursor","#hasNext()"],"updatePoint":{"line":777,"column":35,"index":28122},"line":777,"code":"      it('should connect the client', async () => {\n        const indexes = client.db().collection('test').listIndexes();\n        await indexes.hasNext().catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ListIndexesCursor","#next()"],"updatePoint":{"line":784,"column":35,"index":28427},"line":784,"code":"      it('should connect the client', async () => {\n        const indexes = client.db().collection('test').listIndexes();\n        await indexes.next().catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ListIndexesCursor","#toArray()"],"updatePoint":{"line":791,"column":35,"index":28732},"line":791,"code":"      it('should connect the client', async () => {\n        const indexes = client.db().collection('test').listIndexes();\n        await indexes.toArray().catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should connect the client","suites":["When executing an operation for the first time","class ListIndexesCursor","#tryNext()"],"updatePoint":{"line":798,"column":35,"index":29040},"line":798,"code":"      it('should connect the client', async () => {\n        const indexes = client.db().collection('test').listIndexes();\n        await indexes.tryNext().catch(() => null);\n        expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should not connect the client","suites":["When executing an operation for the first time","class MongoClient","#withSession()"],"updatePoint":{"line":807,"column":39,"index":29402},"line":807,"code":"      it('should not connect the client', async () => {\n        await client.withSession(async session => {\n          expect(session).to.be.instanceOf(ClientSession);\n        });\n        expect(client).to.not.have.property('topology'); // withSession won't connect, that's expected\n      });","file":"integration/node-specific/auto_connect.test.ts","skipped":false,"dir":"test"},{"name":"should respond with BSONRegExp class with option passed to ","suites":["BSONRegExp","bsonRegExp option"],"updatePoint":{"line":17,"column":84,"index":457},"line":17,"code":"      it(`should respond with BSONRegExp class with option passed to ${passOptionTo}`, async function () {\n        try {\n          client = this.configuration.newClient(passOptionTo === 'client' ? option : undefined);\n          await client.connect();\n          const db = client.db('bson_regex_db', passOptionTo === 'db' ? option : undefined);\n          const collection = db.collection('bson_regex_coll', passOptionTo === 'collection' ? option : undefined);\n          await collection.insertOne({\n            regex: new BSONRegExp('abc', 'imx')\n          });\n          const res = await collection.findOne({\n            regex: new BSONRegExp('abc', 'imx')\n          }, passOptionTo === 'operation' ? option : undefined);\n          expect(res).has.property('regex').that.is.instanceOf(BSONRegExp);\n        } finally {\n          await client.close();\n        }\n      });","file":"integration/node-specific/bson-options/bsonRegExp.test.js","skipped":false,"dir":"test"},{"name":"Should correctly insert document ignoring undefined field","suites":["Ignore Undefined"],"updatePoint":{"line":24,"column":63,"index":518},"line":24,"code":"  it('Should correctly insert document ignoring undefined field', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        ignoreUndefined: true\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('shouldCorrectlyIgnoreUndefinedValue');\n\n        // Ignore the undefined field\n        collection.insert({\n          a: 1,\n          b: undefined\n        }, configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n\n          // Locate the doument\n          collection.findOne(function (err, item) {\n            test.equal(1, item.a);\n            test.ok(item.b === undefined);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"Should correctly connect using MongoClient and perform insert document ignoring undefined field","suites":["Ignore Undefined"],"updatePoint":{"line":57,"column":101,"index":1535},"line":57,"code":"  it('Should correctly connect using MongoClient and perform insert document ignoring undefined field', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient({}, {\n        ignoreUndefined: true,\n        sslValidate: false\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('shouldCorrectlyIgnoreUndefinedValue1');\n        collection.insert({\n          a: 1,\n          b: undefined\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.findOne(function (err, item) {\n            test.equal(1, item.a);\n            test.ok(item.b === undefined);\n            collection.insertOne({\n              a: 2,\n              b: undefined\n            }, function (err) {\n              expect(err).to.not.exist;\n              collection.findOne({\n                a: 2\n              }, function (err, item) {\n                test.equal(2, item.a);\n                test.ok(item.b === undefined);\n                collection.insertMany([{\n                  a: 3,\n                  b: undefined\n                }], function (err) {\n                  expect(err).to.not.exist;\n                  collection.findOne({\n                    a: 3\n                  }, function (err, item) {\n                    test.equal(3, item.a);\n                    test.ok(item.b === undefined);\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"Should correctly update document ignoring undefined field","suites":["Ignore Undefined"],"updatePoint":{"line":110,"column":63,"index":3186},"line":110,"code":"  it('Should correctly update document ignoring undefined field', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        ignoreUndefined: true\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('shouldCorrectlyIgnoreUndefinedValue2');\n        var id = new ObjectId();\n        collection.updateOne({\n          _id: id,\n          a: 1,\n          b: undefined\n        }, {\n          $set: {\n            a: 1,\n            b: undefined\n          }\n        }, {\n          upsert: true\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.findOne({\n            _id: id\n          }, function (err, item) {\n            test.equal(1, item.a);\n            test.ok(item.b === undefined);\n            var id = new ObjectId();\n            collection.updateMany({\n              _id: id,\n              a: 1,\n              b: undefined\n            }, {\n              $set: {\n                a: 1,\n                b: undefined\n              }\n            }, {\n              upsert: true\n            }, function (err) {\n              expect(err).to.not.exist;\n              collection.findOne({\n                _id: id\n              }, function (err, item) {\n                test.equal(1, item.a);\n                test.ok(item.b === undefined);\n                var id = new ObjectId();\n                collection.update({\n                  _id: id,\n                  a: 1,\n                  b: undefined\n                }, {\n                  $set: {\n                    a: 1,\n                    b: undefined\n                  }\n                }, {\n                  upsert: true\n                }, function (err) {\n                  expect(err).to.not.exist;\n                  collection.findOne({\n                    _id: id\n                  }, function (err, item) {\n                    test.equal(1, item.a);\n                    test.ok(item.b === undefined);\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"Should correctly inherit ignore undefined field from db during insert","suites":["Ignore Undefined"],"updatePoint":{"line":192,"column":75,"index":5541},"line":192,"code":"  it('Should correctly inherit ignore undefined field from db during insert', async function () {\n    const configuration = this.configuration;\n    const client = configuration.newClient(configuration.writeConcernMax(), {\n      maxPoolSize: 1,\n      ignoreUndefined: false\n    });\n    const db = client.db(configuration.db, {\n      ignoreUndefined: true\n    });\n    const collection = db.collection('shouldCorrectlyIgnoreUndefinedValue3');\n    await collection.insert({\n      a: 1,\n      b: undefined\n    });\n    const item = await collection.findOne();\n    expect(item).to.have.property('a', 1);\n    expect(item).to.not.have.property('b');\n    await client.close();\n  });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"Should correctly inherit ignore undefined field from collection during insert","suites":["Ignore Undefined"],"updatePoint":{"line":211,"column":83,"index":6222},"line":211,"code":"  it('Should correctly inherit ignore undefined field from collection during insert', function (done) {\n    const db = client.db('shouldCorrectlyIgnoreUndefinedValue4', {\n      ignoreUndefined: false\n    });\n    const collection = db.collection('shouldCorrectlyIgnoreUndefinedValue4', {\n      ignoreUndefined: true\n    });\n\n    // Ignore the undefined field\n    collection.insert({\n      a: 1,\n      b: undefined\n    }, err => {\n      expect(err).to.not.exist;\n\n      // Locate the doument\n      collection.findOne((err, item) => {\n        expect(err).to.not.exist;\n        expect(item).to.have.property('a', 1);\n        expect(item).to.not.have.property('b');\n        done();\n      });\n    });\n  });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"Should correctly inherit ignore undefined field from operation during insert","suites":["Ignore Undefined"],"updatePoint":{"line":235,"column":82,"index":6922},"line":235,"code":"  it('Should correctly inherit ignore undefined field from operation during insert', function (done) {\n    const db = client.db('shouldCorrectlyIgnoreUndefinedValue5');\n    const collection = db.collection('shouldCorrectlyIgnoreUndefinedValue5', {\n      ignoreUndefined: false\n    });\n\n    // Ignore the undefined field\n    collection.insert({\n      a: 1,\n      b: undefined\n    }, {\n      ignoreUndefined: true\n    }, err => {\n      expect(err).to.not.exist;\n\n      // Locate the doument\n      collection.findOne({}, (err, item) => {\n        expect(err).to.not.exist;\n        expect(item).to.have.property('a', 1);\n        expect(item).to.not.have.property('b');\n        done();\n      });\n    });\n  });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"Should correctly inherit ignore undefined field from operation during findOneAndReplace","suites":["Ignore Undefined"],"updatePoint":{"line":259,"column":93,"index":7637},"line":259,"code":"  it('Should correctly inherit ignore undefined field from operation during findOneAndReplace', function (done) {\n    const db = client.db('shouldCorrectlyIgnoreUndefinedValue6');\n    const collection = db.collection('shouldCorrectlyIgnoreUndefinedValue6', {\n      ignoreUndefined: false\n    });\n    collection.insert({\n      a: 1,\n      b: 2\n    }, err => {\n      expect(err).to.not.exist;\n\n      // Replace the doument, ignoring undefined fields\n      collection.findOneAndReplace({}, {\n        a: 1,\n        b: undefined\n      }, {\n        ignoreUndefined: true\n      }, err => {\n        expect(err).to.not.exist;\n\n        // Locate the doument\n        collection.findOne((err, item) => {\n          expect(err).to.not.exist;\n          expect(item).to.have.property('a', 1);\n          expect(item).to.not.have.property('b');\n          done();\n        });\n      });\n    });\n  });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"Should correctly ignore undefined field during bulk write","suites":["Ignore Undefined"],"updatePoint":{"line":289,"column":63,"index":8488},"line":289,"code":"  it('Should correctly ignore undefined field during bulk write', function (done) {\n    const db = client.db('shouldCorrectlyIgnoreUndefinedValue7');\n    const collection = db.collection('shouldCorrectlyIgnoreUndefinedValue7');\n\n    // Ignore the undefined field\n    collection.bulkWrite([{\n      insertOne: {\n        a: 1,\n        b: undefined\n      }\n    }], {\n      ignoreUndefined: true\n    }, err => {\n      expect(err).to.not.exist;\n\n      // Locate the doument\n      collection.findOne((err, item) => {\n        expect(err).to.not.exist;\n        expect(item).to.have.property('a', 1);\n        expect(item).to.not.have.property('b');\n        done();\n      });\n    });\n  });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute insert culling undefined","suites":["Ignore Undefined","ignoreUndefined A server"],"updatePoint":{"line":314,"column":57,"index":9214},"line":314,"code":"    it('should correctly execute insert culling undefined', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.2'\n        }\n      },\n      test: function (done) {\n        const coll = client.db().collection('insert1');\n        coll.drop(() => {\n          const objectId = new ObjectId();\n          coll.insertOne({\n            _id: objectId,\n            a: 1,\n            b: undefined\n          }, {\n            ignoreUndefined: true\n          }, (err, res) => {\n            expect(err).to.not.exist;\n            expect(res).property('insertedId').to.exist;\n            const cursor = coll.find({\n              _id: objectId\n            });\n            this.defer(() => cursor.close());\n            cursor.next((err, doc) => {\n              expect(err).to.not.exist;\n              expect(doc).to.not.have.property('b');\n              done();\n            });\n          });\n        });\n      }\n    });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute update culling undefined","suites":["Ignore Undefined","ignoreUndefined A server"],"updatePoint":{"line":346,"column":57,"index":10127},"line":346,"code":"    it('should correctly execute update culling undefined', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.2'\n        }\n      },\n      test: function (done) {\n        const coll = client.db().collection('update1');\n        coll.drop(() => {\n          const objectId = new ObjectId();\n          coll.updateOne({\n            _id: objectId,\n            a: 1,\n            b: undefined\n          }, {\n            $set: {\n              a: 1,\n              b: undefined\n            }\n          }, {\n            ignoreUndefined: true,\n            upsert: true\n          }, (err, res) => {\n            expect(err).to.not.exist;\n            expect(res).property('upsertedCount').to.equal(1);\n            const cursor = coll.find({\n              _id: objectId\n            });\n            this.defer(() => cursor.close());\n            cursor.next((err, doc) => {\n              expect(err).to.not.exist;\n              expect(doc).to.not.have.property('b');\n              done();\n            });\n          });\n        });\n      }\n    });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute remove culling undefined","suites":["Ignore Undefined","ignoreUndefined A server"],"updatePoint":{"line":384,"column":57,"index":11168},"line":384,"code":"    it('should correctly execute remove culling undefined', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.2'\n        }\n      },\n      test: function (done) {\n        const coll = client.db().collection('remove1');\n        coll.drop(() => {\n          const objectId = new ObjectId();\n          coll.insertMany([{\n            id: objectId,\n            a: 1,\n            b: undefined\n          }, {\n            id: objectId,\n            a: 2,\n            b: 1\n          }], (err, res) => {\n            expect(err).to.not.exist;\n            expect(res).property('insertedCount').to.equal(2);\n            coll.deleteMany({\n              b: undefined\n            }, {\n              ignoreUndefined: true\n            }, (err, res) => {\n              expect(err).to.not.exist;\n              expect(res).property('deletedCount').to.equal(2);\n              done();\n            });\n          });\n        });\n      }\n    });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute remove not culling undefined","suites":["Ignore Undefined","ignoreUndefined A server"],"updatePoint":{"line":418,"column":61,"index":12103},"line":418,"code":"    it('should correctly execute remove not culling undefined', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.2'\n        }\n      },\n      test: function (done) {\n        const coll = client.db().collection('remove1');\n        coll.drop(() => {\n          const objectId = new ObjectId();\n          coll.insertMany([{\n            id: objectId,\n            a: 1,\n            b: undefined\n          }, {\n            id: objectId,\n            a: 2,\n            b: 1\n          }], (err, res) => {\n            expect(err).to.not.exist;\n            expect(res).property('insertedCount').to.equal(2);\n            coll.deleteMany({\n              b: null\n            }, (err, res) => {\n              expect(err).to.not.exist;\n              expect(res).property('deletedCount').to.equal(1);\n              done();\n            });\n          });\n        });\n      }\n    });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteBuffers when creating an instance using Db","suites":["Promote Buffers"],"updatePoint":{"line":14,"column":78,"index":318},"line":14,"code":"  it('should correctly honor promoteBuffers when creating an instance using Db', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        promoteBuffers: true\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteBuffer1').insert({\n          doc: Buffer.alloc(256)\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteBuffer1').findOne(function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc.doc instanceof Buffer);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_buffers.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteBuffers when creating an instance using MongoClient","suites":["Promote Buffers"],"updatePoint":{"line":43,"column":87,"index":1404},"line":43,"code":"  it('should correctly honor promoteBuffers when creating an instance using MongoClient', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient({}, {\n        promoteBuffers: true\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteBuffer2').insert({\n          doc: Buffer.alloc(256)\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteBuffer2').findOne(function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc.doc instanceof Buffer);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_buffers.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteBuffers at cursor level","suites":["Promote Buffers"],"updatePoint":{"line":71,"column":59,"index":2411},"line":71,"code":"  it('should correctly honor promoteBuffers at cursor level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient({}, {\n        promoteBuffers: true\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteBuffer3').insert({\n          doc: Buffer.alloc(256)\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteBuffer3').find().next(function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc.doc instanceof Buffer);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_buffers.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteBuffers at cursor find level","suites":["Promote Buffers"],"updatePoint":{"line":99,"column":64,"index":3427},"line":99,"code":"  it('should correctly honor promoteBuffers at cursor find level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteBuffer4').insert({\n          doc: Buffer.alloc(256)\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteBuffer4').find({}, {\n            promoteBuffers: true\n          }).next(function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc.doc instanceof Buffer);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_buffers.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteBuffers at aggregate level","suites":["Promote Buffers"],"updatePoint":{"line":127,"column":62,"index":4449},"line":127,"code":"  it('should correctly honor promoteBuffers at aggregate level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger'],\n        mongodb: '>=2.4.0'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteBuffer5').insert({\n          doc: Buffer.alloc(256)\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteBuffer5').aggregate([{\n            $match: {}\n          }], {\n            promoteBuffers: true\n          }).next(function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc.doc instanceof Buffer);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_buffers.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteValues when creating an instance using Db","suites":["Promote Values"],"updatePoint":{"line":19,"column":77,"index":383},"line":19,"code":"  it('should correctly honor promoteValues when creating an instance using Db', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: async function () {\n      let configuration = this.configuration;\n      let client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        promoteValues: false\n      });\n      await client.connect();\n      let db = client.db(configuration.db);\n      await db.collection('shouldCorrectlyHonorPromoteValues').insertOne({\n        doc: Long.fromNumber(10),\n        int: 10,\n        double: 2.2222,\n        array: [[Long.fromNumber(10)]]\n      });\n      let doc = await db.collection('shouldCorrectlyHonorPromoteValues').findOne();\n      expect(Long.fromNumber(10)).deep.equals(doc.doc);\n      expect(new Int32(10)).deep.equals(doc.int);\n      expect(new Double(2.2222)).deep.equals(doc.double);\n      await client.close();\n    }\n  });","file":"integration/node-specific/bson-options/promote_values.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteValues when creating an instance using MongoClient","suites":["Promote Values"],"updatePoint":{"line":48,"column":86,"index":1515},"line":48,"code":"  it('should correctly honor promoteValues when creating an instance using MongoClient', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: async function () {\n      var configuration = this.configuration;\n      const client = configuration.newClient({}, {\n        promoteValues: false\n      });\n      await client.connect();\n      const db = client.db(configuration.db);\n      await db.collection('shouldCorrectlyHonorPromoteValues').insertOne({\n        doc: Long.fromNumber(10),\n        int: 10,\n        double: 2.2222,\n        array: [[Long.fromNumber(10)]]\n      });\n      const doc = await db.collection('shouldCorrectlyHonorPromoteValues').findOne();\n      expect(Long.fromNumber(10)).deep.equals(doc.doc);\n      expect(new Int32(10)).deep.equals(doc.int);\n      expect(new Double(2.2222)).deep.equals(doc.double);\n      await client.close();\n    }\n  });","file":"integration/node-specific/bson-options/promote_values.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteValues at cursor level","suites":["Promote Values"],"updatePoint":{"line":76,"column":58,"index":2572},"line":76,"code":"  it('should correctly honor promoteValues at cursor level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: async function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient({}, {\n        promoteValues: false\n      });\n      await client.connect();\n      const db = client.db(configuration.db);\n      await db.collection('shouldCorrectlyHonorPromoteValues').insertOne({\n        doc: Long.fromNumber(10),\n        int: 10,\n        double: 2.2222,\n        array: [[Long.fromNumber(10)]]\n      });\n      const doc = await db.collection('shouldCorrectlyHonorPromoteValues').find().next();\n      expect(doc.doc).to.deep.equal(Long.fromNumber(10));\n      expect(doc.int).to.deep.equal(new Int32(10));\n      expect(doc.double).to.deep.equal(new Double(2.2222));\n      await client.close();\n    }\n  });","file":"integration/node-specific/bson-options/promote_values.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteValues at cursor find level","suites":["Promote Values"],"updatePoint":{"line":104,"column":63,"index":3646},"line":104,"code":"  it('should correctly honor promoteValues at cursor find level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: async function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient();\n      await client.connect();\n      const db = client.db(configuration.db);\n      await db.collection('shouldCorrectlyHonorPromoteValues').insertOne({\n        doc: Long.fromNumber(10),\n        int: 10,\n        double: 2.2222,\n        array: [[Long.fromNumber(10)]]\n      });\n      const doc = await db.collection('shouldCorrectlyHonorPromoteValues').find({}, {\n        promoteValues: false\n      }).next();\n      expect(doc.doc).to.deep.equal(Long.fromNumber(10));\n      expect(doc.int).to.deep.equal(new Int32(10));\n      expect(doc.double).to.deep.equal(new Double(2.2222));\n      await client.close();\n    }\n  });","file":"integration/node-specific/bson-options/promote_values.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteValues at aggregate level","suites":["Promote Values"],"updatePoint":{"line":132,"column":61,"index":4718},"line":132,"code":"  it('should correctly honor promoteValues at aggregate level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: async function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient();\n      await client.connect();\n      const db = client.db(configuration.db);\n      await db.collection('shouldCorrectlyHonorPromoteValues2').insertOne({\n        doc: Long.fromNumber(10),\n        int: 10,\n        double: 2.2222,\n        array: [[Long.fromNumber(10)]]\n      });\n      const doc = await db.collection('shouldCorrectlyHonorPromoteValues2').aggregate([{\n        $match: {}\n      }], {\n        promoteValues: false\n      }).next();\n      expect(doc.doc, Long.fromNumber(10));\n      expect(doc.int, new Int32(10));\n      expect(doc.double, new Double(2.2222));\n      await client.close();\n    }\n  });","file":"integration/node-specific/bson-options/promote_values.test.js","skipped":false,"dir":"test"},{"name":"Should correctly promoteValues when calling getMore on queries","suites":["Promote Values"],"updatePoint":{"line":162,"column":68,"index":5790},"line":162,"code":"  it('Should correctly promoteValues when calling getMore on queries', {\n    metadata: {\n      requires: {\n        topology: ['single', 'ssl', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect(function (err, client) {\n        var docs = new Array(150).fill(0).map(function (_, i) {\n          return {\n            _id: 'needle_' + i,\n            is_even: i % 2,\n            long: Long.fromString('1234567890'),\n            double: 0.23456,\n            int: 1234\n          };\n        });\n        var db = client.db(configuration.db);\n        db.collection('haystack').insertMany(docs, function (errInsert) {\n          if (errInsert) throw errInsert;\n          // change limit from 102 to 101 and this test passes.\n          // seems to indicate that the promoteValues flag is used for the\n          // initial find, but not for subsequent getMores\n          db.collection('haystack').find({}, {\n            limit: 102,\n            promoteValues: false\n          }).stream().on('data', function (doc) {\n            test.equal(typeof doc.int, 'object');\n            test.equal(doc.int._bsontype, 'Int32');\n            test.equal(typeof doc.long, 'object');\n            test.equal(doc.long._bsontype, 'Long');\n            test.equal(typeof doc.double, 'object');\n            test.equal(doc.double._bsontype, 'Double');\n          }).on('end', function () {\n            db.dropCollection('haystack', function () {\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_values.test.js","skipped":false,"dir":"test"},{"name":"is set to driver default (useBigInt64=false)","suites":["useBigInt64 option","when not provided to client"],"updatePoint":{"line":22,"column":52,"index":662},"line":22,"code":"    it('is set to driver default (useBigInt64=false)', async function () {\n      expect(client.s.bsonOptions.useBigInt64).to.exist;\n      expect(client.s.bsonOptions.useBigInt64).to.be.false;\n    });","file":"integration/node-specific/bson-options/use_bigint_64.test.ts","skipped":false,"dir":"test"},{"name":"supercedes driver level","suites":["useBigInt64 option","when set at client level"],"updatePoint":{"line":33,"column":31,"index":1045},"line":33,"code":"    it('supercedes driver level', function () {\n      expect(client.s.bsonOptions.useBigInt64).to.exist;\n      expect(client.s.bsonOptions.useBigInt64).to.be.true;\n    });","file":"integration/node-specific/bson-options/use_bigint_64.test.ts","skipped":false,"dir":"test"},{"name":"supercedes client level","suites":["useBigInt64 option","when set at DB level"],"updatePoint":{"line":47,"column":31,"index":1500},"line":47,"code":"    it('supercedes client level', async function () {\n      expect(db.s.bsonOptions.useBigInt64).to.exist;\n      expect(db.s.bsonOptions.useBigInt64).to.be.true;\n    });","file":"integration/node-specific/bson-options/use_bigint_64.test.ts","skipped":false,"dir":"test"},{"name":"supercedes db level","suites":["useBigInt64 option","when set at collection level"],"updatePoint":{"line":63,"column":27,"index":2082},"line":63,"code":"    it('supercedes db level', function () {\n      expect(coll.s.bsonOptions.useBigInt64).to.exist;\n      expect(coll.s.bsonOptions.useBigInt64).to.be.true;\n    });","file":"integration/node-specific/bson-options/use_bigint_64.test.ts","skipped":false,"dir":"test"},{"name":"supercedes collection level when set to false at operation level","suites":["useBigInt64 option","when set to true at collection level"],"updatePoint":{"line":75,"column":72,"index":2600},"line":75,"code":"    it('supercedes collection level when set to false at operation level', async function () {\n      coll = await db.createCollection('useBigInt64Test', {\n        useBigInt64: true\n      });\n      await coll.insertMany([{\n        a: 1n\n      }, {\n        a: 2n\n      }, {\n        a: 3n\n      }, {\n        a: 4n\n      }]);\n      res = await coll.findOne({}, {\n        useBigInt64: false\n      });\n      expect(res).to.exist;\n      expect(typeof res?.a).to.equal('number');\n    });","file":"integration/node-specific/bson-options/use_bigint_64.test.ts","skipped":false,"dir":"test"},{"name":"supercedes collection level when set to true at operation level","suites":["useBigInt64 option","when set to false at collection level"],"updatePoint":{"line":102,"column":71,"index":3389},"line":102,"code":"    it('supercedes collection level when set to true at operation level', async function () {\n      coll = await db.createCollection('useBigInt64Test', {\n        useBigInt64: false\n      });\n      await coll.insertMany([{\n        a: 1n\n      }, {\n        a: 2n\n      }, {\n        a: 3n\n      }, {\n        a: 4n\n      }]);\n      res = await coll.findOne({}, {\n        useBigInt64: true\n      });\n      expect(res).to.exist;\n      expect(typeof res?.a).to.equal('bigint');\n    });","file":"integration/node-specific/bson-options/use_bigint_64.test.ts","skipped":false,"dir":"test"},{"name":"deserializes Long to bigint","suites":["useBigInt64 option","when set to true"],"updatePoint":{"line":138,"column":35,"index":4337},"line":138,"code":"    it('deserializes Long to bigint', async function () {\n      expect(res).to.exist;\n      expect(typeof res?.a).to.equal('bigint');\n      expect(res?.a).to.equal(1n);\n    });","file":"integration/node-specific/bson-options/use_bigint_64.test.ts","skipped":false,"dir":"test"},{"name":"throws a MongoAPIError","suites":["useBigInt64 option","when useBigInt64=true and promoteLongs=false","when set at client level"],"updatePoint":{"line":146,"column":32,"index":4645},"line":146,"code":"      it('throws a MongoAPIError', async function () {\n        expect(() => {\n          client = this.configuration.newClient({}, {\n            useBigInt64: true,\n            promoteLongs: false\n          });\n        }).to.throw(MongoAPIError, /Must request either bigint or Long for int64 deserialization/);\n      });","file":"integration/node-specific/bson-options/use_bigint_64.test.ts","skipped":false,"dir":"test"},{"name":"throws a BSONError","suites":["useBigInt64 option","when useBigInt64=true and promoteLongs=false","when set at DB level"],"updatePoint":{"line":163,"column":28,"index":5242},"line":163,"code":"      it('throws a BSONError', async function () {\n        const e = await db.createCollection('bsonError').catch(e => e);\n        expect(e).to.be.instanceOf(BSON.BSONError);\n      });","file":"integration/node-specific/bson-options/use_bigint_64.test.ts","skipped":false,"dir":"test"},{"name":"throws a BSONError","suites":["useBigInt64 option","when useBigInt64=true and promoteLongs=false","when set at collection level"],"updatePoint":{"line":173,"column":28,"index":5645},"line":173,"code":"      it('throws a BSONError', async function () {\n        const e = await db.createCollection('bsonError', {\n          promoteLongs: false,\n          useBigInt64: true\n        }).catch(e => e);\n        expect(e).to.be.instanceOf(BSON.BSONError);\n      });","file":"integration/node-specific/bson-options/use_bigint_64.test.ts","skipped":false,"dir":"test"},{"name":"throws a BSONError","suites":["useBigInt64 option","when useBigInt64=true and promoteLongs=false","when set at the operation level"],"updatePoint":{"line":187,"column":28,"index":6166},"line":187,"code":"      it('throws a BSONError', async function () {\n        const e = await coll.insertOne({\n          a: 10n\n        }, {\n          promoteLongs: false,\n          useBigInt64: true\n        }).catch(e => e);\n        expect(e).to.be.instanceOf(BSON.BSONError);\n      });","file":"integration/node-specific/bson-options/use_bigint_64.test.ts","skipped":false,"dir":"test"},{"name":"throws a MongoAPIError","suites":["useBigInt64 option","when useBigInt64=true and promoteValues=false","when set at client level"],"updatePoint":{"line":200,"column":32,"index":6582},"line":200,"code":"      it('throws a MongoAPIError', async function () {\n        expect(() => {\n          client = this.configuration.newClient({}, {\n            useBigInt64: true,\n            promoteValues: false\n          });\n        }).to.throw(MongoAPIError, /Must request either bigint or Long for int64 deserialization/);\n      });","file":"integration/node-specific/bson-options/use_bigint_64.test.ts","skipped":false,"dir":"test"},{"name":"throws a BSONError","suites":["useBigInt64 option","when useBigInt64=true and promoteValues=false","when set at DB level"],"updatePoint":{"line":217,"column":28,"index":7181},"line":217,"code":"      it('throws a BSONError', async function () {\n        const e = await db.createCollection('bsonError').catch(e => e);\n        expect(e).to.be.instanceOf(BSON.BSONError);\n      });","file":"integration/node-specific/bson-options/use_bigint_64.test.ts","skipped":false,"dir":"test"},{"name":"throws a BSONError","suites":["useBigInt64 option","when useBigInt64=true and promoteValues=false","when set at collection level"],"updatePoint":{"line":227,"column":28,"index":7584},"line":227,"code":"      it('throws a BSONError', async function () {\n        const e = await db.createCollection('bsonError', {\n          promoteValues: false,\n          useBigInt64: true\n        }).catch(e => e);\n        expect(e).to.be.instanceOf(BSON.BSONError);\n      });","file":"integration/node-specific/bson-options/use_bigint_64.test.ts","skipped":false,"dir":"test"},{"name":"throws a BSONError","suites":["useBigInt64 option","when useBigInt64=true and promoteValues=false","when set at the operation level"],"updatePoint":{"line":241,"column":28,"index":8106},"line":241,"code":"      it('throws a BSONError', async function () {\n        const e = await coll.insertOne({\n          a: 10n\n        }, {\n          promoteValues: false,\n          useBigInt64: true\n        }).catch(e => e);\n        expect(e).to.be.instanceOf(BSON.BSONError);\n      });","file":"integration/node-specific/bson-options/use_bigint_64.test.ts","skipped":false,"dir":"test"},{"name":"should disable validation with option passed to ","suites":["class BinMsg","enableUtf8Validation option set to false"],"updatePoint":{"line":31,"column":73,"index":908},"line":31,"code":"      it(`should disable validation with option passed to ${passOptionTo}`, async function () {\n        client = this.configuration.newClient(passOptionTo === 'client' ? option : undefined);\n        const db = client.db('bson_utf8Validation_db', passOptionTo === 'db' ? option : undefined);\n        const collection = db.collection('bson_utf8Validation_coll', passOptionTo === 'collection' ? option : undefined);\n        await collection.insertOne({\n          name: 'John Doe'\n        }, passOptionTo === 'operation' ? option : {});\n        expect(onMessageSpy).to.have.been.called;\n        const binMsg = onMessageSpy.lastCall.firstArg;\n        const result = binMsg.parseBsonSerializationOptions(option);\n        expect(result).to.deep.equal(EXPECTED_VALIDATION_DISABLED_ARGUMENT);\n      });","file":"integration/node-specific/bson-options/utf8_validation.test.ts","skipped":false,"dir":"test"},{"name":"should enable validation with option passed to ","suites":["class BinMsg","enableUtf8Validation option set to true"],"updatePoint":{"line":51,"column":72,"index":1963},"line":51,"code":"      it(`should enable validation with option passed to ${passOptionTo}`, async function () {\n        client = this.configuration.newClient(passOptionTo === 'client' ? option : undefined);\n        await client.connect();\n        const db = client.db('bson_utf8Validation_db', passOptionTo === 'db' ? option : undefined);\n        const collection = db.collection('bson_utf8Validation_coll', passOptionTo === 'collection' ? option : undefined);\n        await collection.insertOne({\n          name: 'John Doe'\n        }, passOptionTo === 'operation' ? option : {});\n        expect(onMessageSpy).to.have.been.called;\n        const binMsg = onMessageSpy.lastCall.firstArg;\n        const result = binMsg.parseBsonSerializationOptions(option);\n        expect(result).to.deep.equal(EXPECTED_VALIDATION_ENABLED_ARGUMENT);\n      });","file":"integration/node-specific/bson-options/utf8_validation.test.ts","skipped":false,"dir":"test"},{"name":"should default to enabled with option passed to ","suites":["class BinMsg","enableUtf8Validation option not set"],"updatePoint":{"line":69,"column":73,"index":2959},"line":69,"code":"      it(`should default to enabled with option passed to ${passOptionTo}`, async function () {\n        client = this.configuration.newClient(passOptionTo === 'client' ? option : undefined);\n        await client.connect();\n        const db = client.db('bson_utf8Validation_db', passOptionTo === 'db' ? option : undefined);\n        const collection = db.collection('bson_utf8Validation_coll', passOptionTo === 'collection' ? option : undefined);\n        await collection.insertOne({\n          name: 'John Doe'\n        }, passOptionTo === 'operation' ? option : {});\n        expect(onMessageSpy).to.have.been.called;\n        const binMsg = onMessageSpy.lastCall.firstArg;\n        const result = binMsg.parseBsonSerializationOptions(option);\n        expect(result).to.deep.equal(EXPECTED_VALIDATION_ENABLED_ARGUMENT);\n      });","file":"integration/node-specific/bson-options/utf8_validation.test.ts","skipped":false,"dir":"test"},{"name":"should be able to use a for-await loop on a find command cursor","suites":["Cursor Async Iterator Tests","default promise library"],"updatePoint":{"line":30,"column":71,"index":972},"line":30,"code":"    it('should be able to use a for-await loop on a find command cursor', async function () {\n      const cursor = collection.find({\n        bar: 1\n      });\n      let counter = 0;\n      for await (const doc of cursor) {\n        expect(doc).to.have.property('bar', 1);\n        counter += 1;\n      }\n      expect(counter).to.equal(1000);\n      expect(cursor.closed).to.be.true;\n    });","file":"integration/node-specific/cursor_async_iterator.test.js","skipped":false,"dir":"test"},{"name":"should be able to use a for-await loop on an aggregation cursor","suites":["Cursor Async Iterator Tests","default promise library"],"updatePoint":{"line":42,"column":71,"index":1357},"line":42,"code":"    it('should be able to use a for-await loop on an aggregation cursor', async function () {\n      const cursor = collection.aggregate([{\n        $match: {\n          bar: 1\n        }\n      }]);\n      let counter = 0;\n      for await (const doc of cursor) {\n        expect(doc).to.have.property('bar', 1);\n        counter += 1;\n      }\n      expect(counter).to.equal(1000);\n      expect(cursor.closed).to.be.true;\n    });","file":"integration/node-specific/cursor_async_iterator.test.js","skipped":false,"dir":"test"},{"name":"should be able to use a for-await loop on a command cursor","suites":["Cursor Async Iterator Tests","default promise library"],"updatePoint":{"line":56,"column":66,"index":1774},"line":56,"code":"    it('should be able to use a for-await loop on a command cursor', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.0.0'\n        }\n      },\n      test: async function () {\n        const cursor1 = collection.listIndexes();\n        const cursor2 = collection.listIndexes();\n        const indexes = await cursor1.toArray();\n        let counter = 0;\n        for await (const doc of cursor2) {\n          expect(doc).to.exist;\n          counter += 1;\n        }\n        expect(counter).to.equal(indexes.length);\n        expect(cursor1.closed).to.be.true;\n        expect(cursor2.closed).to.be.true;\n      }\n    });","file":"integration/node-specific/cursor_async_iterator.test.js","skipped":false,"dir":"test"},{"name":"should properly stop when cursor is closed","suites":["Cursor Async Iterator Tests","default promise library"],"updatePoint":{"line":76,"column":50,"index":2382},"line":76,"code":"    it('should properly stop when cursor is closed', async function () {\n      const cursor = collection.find();\n      let count = 0;\n      for await (const doc of cursor) {\n        expect(doc).to.exist;\n        count++;\n        await cursor.close();\n      }\n      expect(count).to.equal(1);\n      expect(cursor.closed).to.be.true;\n    });","file":"integration/node-specific/cursor_async_iterator.test.js","skipped":false,"dir":"test"},{"name":"cleans up cursor when breaking out of for await of loops","suites":["Cursor Async Iterator Tests","default promise library"],"updatePoint":{"line":87,"column":64,"index":2736},"line":87,"code":"    it('cleans up cursor when breaking out of for await of loops', async function () {\n      const cursor = collection.find();\n      for await (const doc of cursor) {\n        expect(doc).to.exist;\n        break;\n      }\n      expect(cursor.closed).to.be.true;\n    });","file":"integration/node-specific/cursor_async_iterator.test.js","skipped":false,"dir":"test"},{"name":"returns when attempting to reuse the cursor after a break","suites":["Cursor Async Iterator Tests","default promise library"],"updatePoint":{"line":95,"column":65,"index":3005},"line":95,"code":"    it('returns when attempting to reuse the cursor after a break', async function () {\n      const cursor = collection.find();\n      const spy = sinon.spy(cursor);\n      for await (const doc of cursor) {\n        expect(doc).to.exist;\n        break;\n      }\n      expect(cursor.closed).to.be.true;\n      for await (const doc of cursor) {\n        expect.fail('Async generator returns immediately if cursor is closed', doc);\n      }\n      // cursor.close() should only be called once.\n      expect(spy.close.calledOnce).to.be.true;\n    });","file":"integration/node-specific/cursor_async_iterator.test.js","skipped":false,"dir":"test"},{"name":"should stream documents with pause and resume for fetching","suites":["Cursor Streams"],"updatePoint":{"line":21,"column":64,"index":428},"line":21,"code":"  it('should stream documents with pause and resume for fetching', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var docs = [];\n      var j = 0;\n      for (var i = 0; i < 3000; i++) {\n        docs.push({\n          a: i\n        });\n      }\n      var allDocs = [];\n      while (docs.length > 0) {\n        allDocs.push(docs.splice(0, 1000));\n      }\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        db.createCollection('test_streaming_function_with_limit_for_fetching2', function (err, collection) {\n          var left = allDocs.length;\n          for (var i = 0; i < allDocs.length; i++) {\n            collection.insert(allDocs[i], {\n              writeConcern: {\n                w: 1\n              }\n            }, function (err) {\n              expect(err).to.not.exist;\n              left = left - 1;\n              if (left === 0) {\n                // Perform a find to get a cursor\n                var stream = collection.find({}).stream();\n                var data = [];\n\n                // For each data item\n                stream.on('data', function () {\n                  data.push(1);\n                  j = j + 1;\n                  stream.pause();\n                  collection.findOne({}, function (err) {\n                    expect(err).to.not.exist;\n                    stream.resume();\n                  });\n                });\n\n                // When the stream is done\n                stream.on('end', function () {\n                  setTimeout(() => {\n                    let err;\n                    try {\n                      expect(data).to.have.length(3000);\n                    } catch (e) {\n                      err = e;\n                    }\n                    client.close(() => done(err));\n                  }, 1000);\n                });\n              }\n            });\n          }\n        });\n      });\n    }\n  });","file":"integration/node-specific/cursor_stream.test.js","skipped":false,"dir":"test"},{"name":"should stream 10K documents","suites":["Cursor Streams"],"updatePoint":{"line":90,"column":33,"index":2561},"line":90,"code":"  it('should stream 10K documents', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var docs = [];\n      for (var i = 0; i < 10000; i++) {\n        docs.push({\n          a: i,\n          bin: new Binary(Buffer.alloc(256))\n        });\n      }\n      var j = 0;\n      var allDocs = [];\n      while (docs.length > 0) {\n        allDocs.push(docs.splice(0, 1000));\n      }\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        db.createCollection('test_streaming_function_with_limit_for_fetching_2', function (err, collection) {\n          var left = allDocs.length;\n          for (var i = 0; i < allDocs.length; i++) {\n            collection.insert(allDocs[i], {\n              writeConcern: {\n                w: 1\n              }\n            }, function (err) {\n              expect(err).to.not.exist;\n              left = left - 1;\n              if (left === 0) {\n                // Perform a find to get a cursor\n                var stream = collection.find({}).stream();\n                var data = [];\n\n                // For each data item\n                stream.on('data', function () {\n                  j = j + 1;\n                  stream.pause();\n                  data.push(1);\n                  collection.findOne({}, function (err) {\n                    expect(err).to.not.exist;\n                    stream.resume();\n                  });\n                });\n\n                // When the stream is done\n                stream.on('end', function () {\n                  setTimeout(() => {\n                    let err;\n                    try {\n                      expect(data).to.have.length(10000);\n                    } catch (e) {\n                      err = e;\n                    }\n                    client.close(err2 => done(err || err2));\n                  }, 1000);\n                });\n              }\n            });\n          }\n        });\n      });\n    }\n  });","file":"integration/node-specific/cursor_stream.test.js","skipped":false,"dir":"test"},{"name":"should trigger massive amount of getMores","suites":["Cursor Streams"],"updatePoint":{"line":160,"column":47,"index":4767},"line":160,"code":"  it('should trigger massive amount of getMores', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var docs = [];\n      var counter = 0;\n      var counter2 = 0;\n      for (var i = 0; i < 1000; i++) {\n        docs.push({\n          a: i,\n          bin: new Binary(Buffer.alloc(256))\n        });\n      }\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        db.createCollection('test_streaming_function_with_limit_for_fetching_3', function (err, collection) {\n          collection.insert(docs, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n\n            // Perform a find to get a cursor\n            var stream = collection.find({}).stream();\n\n            // For each data item\n            stream.on('data', function () {\n              counter++;\n              stream.pause();\n              stream.resume();\n              counter2++;\n            });\n\n            // When the stream is done\n            stream.on('end', function () {\n              expect(counter).to.equal(1000);\n              expect(counter2).to.equal(1000);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/cursor_stream.test.js","skipped":false,"dir":"test"},{"name":"should stream documents across getMore command and count correctly","suites":["Cursor Streams"],"updatePoint":{"line":212,"column":72,"index":6311},"line":212,"code":"  it('should stream documents across getMore command and count correctly', async function () {\n    if (process.platform === 'darwin') {\n      this.skipReason = 'TODO(NODE-3819): Unskip flaky MacOS tests.';\n      return this.skip();\n    }\n    const db = client.db();\n    const collection = db.collection('streaming');\n    const updateCollection = db.collection('update_within_streaming');\n    await collection.drop().catch(() => null);\n    await updateCollection.drop().catch(() => null);\n    const docs = Array.from({\n      length: 10\n    }, (_, i) => ({\n      _id: i,\n      b: new Binary(Buffer.alloc(1024))\n    }));\n    await collection.insertMany(docs);\n    // Set the batchSize to be a 5th of the total docCount to make getMores happen\n    const stream = collection.find({}, {\n      batchSize: 2\n    }).stream();\n    let done;\n    const end = new Promise((resolve, reject) => {\n      done = error => error != null ? reject(error) : resolve();\n    });\n    stream.on('end', () => {\n      updateCollection.findOne({\n        id: 1\n      }).then(function (doc) {\n        expect(doc.count).to.equal(9);\n        done();\n      }).catch(done).finally(() => client.close());\n    });\n    let docCount = 0;\n    stream.on('data', data => {\n      stream.pause();\n      try {\n        expect(data).to.have.property('_id', docCount);\n      } catch (assertionError) {\n        return done(assertionError);\n      }\n      if (docCount++ === docs.length - 1) {\n        stream.resume();\n        return;\n      }\n      updateCollection.updateMany({\n        id: 1\n      }, {\n        $inc: {\n          count: 1\n        }\n      }, {\n        writeConcern: {\n          w: 1\n        },\n        upsert: true\n      }).then(() => {\n        stream.resume();\n      }).catch(done);\n    });\n    return end;\n  });","file":"integration/node-specific/cursor_stream.test.js","skipped":false,"dir":"test"},{"name":"should correctly error out stream","suites":["Cursor Streams"],"updatePoint":{"line":274,"column":39,"index":8057},"line":274,"code":"  it('should correctly error out stream', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        const db = client.db(self.configuration.db);\n        const cursor = db.collection('myCollection').find({\n          timestamp: {\n            $ltx: '1111'\n          } // Error in query.\n        });\n\n        let error;\n        const stream = cursor.stream();\n        stream.on('error', err => error = err);\n        cursor.on('close', function () {\n          // NOTE: use `setImmediate` here because the stream implementation uses `nextTick` to emit the error\n          setImmediate(() => {\n            expect(error).to.exist;\n            client.close(done);\n          });\n        });\n        stream.pipe(process.stdout);\n      });\n    }\n  });","file":"integration/node-specific/cursor_stream.test.js","skipped":false,"dir":"test"},{"name":"should correctly stream cursor after stream","suites":["Cursor Streams"],"updatePoint":{"line":307,"column":49,"index":9103},"line":307,"code":"  it('should correctly stream cursor after stream', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var docs = [];\n        var received = [];\n        for (var i = 0; i < 1000; i++) {\n          docs.push({\n            a: i,\n            field: 'hello world'\n          });\n        }\n        db.collection('cursor_sort_stream').insertMany(docs, function (err) {\n          expect(err).to.not.exist;\n          var cursor = db.collection('cursor_sort_stream').find({}).project({\n            a: 1\n          }).sort({\n            a: -1\n          });\n          const stream = cursor.stream();\n          stream.on('end', function () {\n            expect(received).to.have.length(1000);\n            client.close(done);\n          });\n          stream.on('data', function (d) {\n            received.push(d);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/cursor_stream.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleIllegalDbNames","suites":["Db"],"updatePoint":{"line":18,"column":41,"index":323},"line":18,"code":"  it('shouldCorrectlyHandleIllegalDbNames', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: done => {\n      const client = {\n        bsonOptions: {}\n      };\n      expect(() => new Db(client, 5)).to.throw('Database name must be a string');\n      expect(() => new Db(client, '')).to.throw('Database name cannot be the empty string');\n      expect(() => new Db(client, 'te$t')).to.throw(\"database names cannot contain the character '$'\");\n      expect(() => new Db(client, '.test', function () {})).to.throw(\"database names cannot contain the character '.'\");\n      expect(() => new Db(client, '\\\\test', function () {})).to.throw(\"database names cannot contain the character '\\\\'\");\n      expect(() => new Db(client, 'test test', function () {})).to.throw(\"database names cannot contain the character ' '\");\n      done();\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleFailedConnection","suites":["Db"],"updatePoint":{"line":37,"column":43,"index":1224},"line":37,"code":"  it('shouldCorrectlyHandleFailedConnection', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var fs_client = configuration.newClient('mongodb://127.0.0.1:25117/test', {\n        serverSelectionTimeoutMS: 10\n      });\n      fs_client.connect(function (err) {\n        test.ok(err != null);\n        done();\n      });\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyGetErrorDroppingNonExistingDb","suites":["Db"],"updatePoint":{"line":54,"column":50,"index":1694},"line":54,"code":"  it('shouldCorrectlyGetErrorDroppingNonExistingDb', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var _db = client.db('nonexistingdb');\n        _db.dropDatabase(function (err, result) {\n          expect(err).to.not.exist;\n          test.equal(true, result);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyThrowWhenTryingToReOpenConnection","suites":["Db"],"line":75,"code":"  it.skip('shouldCorrectlyThrowWhenTryingToReOpenConnection', {","file":"integration/node-specific/db.test.js","skipped":true,"dir":"test"},{"name":"should not cut collection name when it is the same as the database","suites":["Db"],"updatePoint":{"line":97,"column":72,"index":2921},"line":97,"code":"  it('should not cut collection name when it is the same as the database', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db1 = client.db('node972');\n        db1.collection('node972.test').insertOne({\n          a: 1\n        }, function (err) {\n          expect(err).to.not.exist;\n          db1.collections(function (err, collections) {\n            expect(err).to.not.exist;\n            collections = collections.map(function (c) {\n              return c.collectionName;\n            });\n            test.notEqual(-1, collections.indexOf('node972.test'));\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUseCursorWithListCollectionsCommand","suites":["Db"],"updatePoint":{"line":127,"column":56,"index":3874},"line":127,"code":"  it('shouldCorrectlyUseCursorWithListCollectionsCommand', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n\n        // Get a db we that does not have any collections\n        var db1 = client.db('shouldCorrectlyUseCursorWithListCollectionsCommand');\n\n        // Create a collection\n        db1.collection('test').insertOne({\n          a: 1\n        }, function (err) {\n          expect(err).to.not.exist;\n\n          // Create a collection\n          db1.collection('test1').insertOne({\n            a: 1\n          }, function () {\n            expect(err).to.not.exist;\n\n            // Get listCollections filtering out the name\n            var cursor = db1.listCollections({\n              name: 'test1'\n            });\n            cursor.toArray(function (err, names) {\n              expect(err).to.not.exist;\n              test.equal(1, names.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUseCursorWithListCollectionsCommandAndBatchSize","suites":["Db"],"updatePoint":{"line":170,"column":68,"index":5155},"line":170,"code":"  it('shouldCorrectlyUseCursorWithListCollectionsCommandAndBatchSize', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n\n        // Get a db we that does not have any collections\n        var db1 = client.db('shouldCorrectlyUseCursorWithListCollectionsCommandAndBatchSize');\n\n        // Create a collection\n        db1.collection('test').insertOne({\n          a: 1\n        }, function (err) {\n          expect(err).to.not.exist;\n\n          // Create a collection\n          db1.collection('test1').insertOne({\n            a: 1\n          }, function () {\n            expect(err).to.not.exist;\n\n            // Get listCollections filtering out the name\n            var cursor = db1.listCollections({\n              name: 'test'\n            }, {\n              batchSize: 1\n            });\n            cursor.toArray(function (err, names) {\n              expect(err).to.not.exist;\n              test.equal(1, names.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"should correctly list collection names with . in the middle","suites":["Db"],"updatePoint":{"line":215,"column":65,"index":6488},"line":215,"code":"  it('should correctly list collection names with . in the middle', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n\n        // Get a db we that does not have any collections\n        var db1 = client.db('shouldCorrectlyListCollectionsWithDotsOnThem');\n\n        // Create a collection\n        db1.collection('test.collection1').insertOne({\n          a: 1\n        }, function (err) {\n          expect(err).to.not.exist;\n\n          // Create a collection\n          db1.collection('test.collection2').insertOne({\n            a: 1\n          }, function () {\n            expect(err).to.not.exist;\n\n            // Get listCollections filtering out the name\n            var cursor = db1.listCollections({\n              name: /test.collection/\n            });\n            cursor.toArray(function (err, names) {\n              expect(err).to.not.exist;\n              test.equal(2, names.length);\n\n              // Get listCollections filtering out the name\n              var cursor = db1.listCollections({\n                name: 'test.collection1'\n              }, {});\n              cursor.toArray(function (err, names) {\n                expect(err).to.not.exist;\n                test.equal(1, names.length);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"should correctly list collection names with batchSize 1 for 2.8 or higher","suites":["Db"],"updatePoint":{"line":267,"column":79,"index":8140},"line":267,"code":"  it('should correctly list collection names with batchSize 1 for 2.8 or higher', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n\n        // Get a db we that does not have any collections\n        var db1 = client.db('shouldCorrectlyListCollectionsWithDotsOnThemFor28');\n\n        // Create a collection\n        db1.collection('test.collection1').insertOne({\n          a: 1\n        }, function (err) {\n          expect(err).to.not.exist;\n\n          // Create a collection\n          db1.collection('test.collection2').insertOne({\n            a: 1\n          }, function () {\n            expect(err).to.not.exist;\n\n            // Get listCollections filtering out the name\n            var cursor = db1.listCollections({\n              name: /test.collection/\n            }, {\n              batchSize: 1\n            });\n            cursor.toArray(function (err, names) {\n              expect(err).to.not.exist;\n              test.equal(2, names.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"should throw if Db.collection is passed a deprecated callback argument","suites":["Db"],"updatePoint":{"line":313,"column":76,"index":9534},"line":313,"code":"  it('should throw if Db.collection is passed a deprecated callback argument', () => {\n    const client = new MongoClient('mongodb://iLoveJavascript');\n    expect(() => client.db('test').collection('test', () => {})).to.throw('The callback form of this helper has been removed.');\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"supports simple aggregation","suites":["examples.aggregaton:"],"updatePoint":{"line":20,"column":33,"index":603},"line":20,"code":"  it('supports simple aggregation', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.8.0',\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // Start aggregate example 1\n      const cursor = collection.aggregate([{\n        $match: {\n          'items.fruit': 'banana'\n        }\n      }, {\n        $sort: {\n          date: 1\n        }\n      }]);\n      // End aggregate example 1\n    }\n  });","file":"integration/node-specific/examples/aggregate.test.js","skipped":false,"dir":"test"},{"name":"supports $match, $group, $project, $unwind, $sum, $sort, $dayOfWeek","suites":["examples.aggregaton:"],"updatePoint":{"line":42,"column":73,"index":1072},"line":42,"code":"  it('supports $match, $group, $project, $unwind, $sum, $sort, $dayOfWeek', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.8.0',\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // Start aggregate example 2\n      const cursor = collection.aggregate([{\n        $unwind: '$items'\n      }, {\n        $match: {\n          'items.fruit': 'banana'\n        }\n      }, {\n        $group: {\n          _id: {\n            day: {\n              $dayOfWeek: '$date'\n            }\n          },\n          count: {\n            $sum: '$items.quantity'\n          }\n        }\n      }, {\n        $project: {\n          dayOfWeek: '$_id.day',\n          numberSold: '$count',\n          _id: 0\n        }\n      }, {\n        $sort: {\n          numberSold: 1\n        }\n      }]);\n      // End aggregate example 2\n    }\n  });","file":"integration/node-specific/examples/aggregate.test.js","skipped":false,"dir":"test"},{"name":"supports $unwind, $group, $sum, $dayOfWeek, $multiply, $project, $cond","suites":["examples.aggregaton:"],"updatePoint":{"line":83,"column":76,"index":1913},"line":83,"code":"  it('supports $unwind, $group, $sum, $dayOfWeek, $multiply, $project, $cond', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.8.0',\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // Start aggregate example 3\n      const cursor = collection.aggregate([{\n        $unwind: '$items'\n      }, {\n        $group: {\n          _id: {\n            day: {\n              $dayOfWeek: '$date'\n            }\n          },\n          items_sold: {\n            $sum: '$items.quantity'\n          },\n          revenue: {\n            $sum: {\n              $multiply: ['$items.quantity', '$items.price']\n            }\n          }\n        }\n      }, {\n        $project: {\n          day: '$_id.day',\n          revenue: 1,\n          items_sold: 1,\n          discount: {\n            $cond: {\n              if: {\n                $lte: ['$revenue', 250]\n              },\n              then: 25,\n              else: 0\n            }\n          }\n        }\n      }]);\n      // End aggregate example 3\n    }\n  });","file":"integration/node-specific/examples/aggregate.test.js","skipped":false,"dir":"test"},{"name":"supports $lookup, $filter, $match","suites":["examples.aggregaton:"],"updatePoint":{"line":130,"column":39,"index":2900},"line":130,"code":"  it('supports $lookup, $filter, $match', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.6.0',\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // Start aggregate example 4\n      const cursor = collection.aggregate([{\n        $lookup: {\n          from: 'air_airlines',\n          let: {\n            constituents: '$airlines'\n          },\n          pipeline: [{\n            $match: {\n              $expr: {\n                $in: ['$name', '$$constituents']\n              }\n            }\n          }],\n          as: 'airlines'\n        }\n      }, {\n        $project: {\n          _id: 0,\n          name: 1,\n          airlines: {\n            $filter: {\n              input: '$airlines',\n              as: 'airline',\n              cond: {\n                $eq: ['$$airline.country', 'Canada']\n              }\n            }\n          }\n        }\n      }]);\n      // End aggregate example 4\n    }\n  });","file":"integration/node-specific/examples/aggregate.test.js","skipped":false,"dir":"test"},{"name":"supports array filters when updating","suites":["examples(array filters):"],"updatePoint":{"line":19,"column":42,"index":588},"line":19,"code":"  it('supports array filters when updating', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.6.x',\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // 3. Exploiting the power of arrays\n      await collection.updateOne({\n        _id: 1\n      }, {\n        $set: {\n          'a.$[i].b': 2\n        }\n      }, {\n        arrayFilters: [{\n          'i.b': 0\n        }]\n      });\n    }\n  });","file":"integration/node-specific/examples/array_filters.test.js","skipped":false,"dir":"test"},{"name":"returns the databases","suites":["AWS Lambda Examples","#handler","when using aws environment variable authentication"],"updatePoint":{"line":18,"column":31,"index":462},"line":18,"code":"      it('returns the databases', async function () {\n        expect(response.databases).to.exist;\n      });","file":"integration/node-specific/examples/aws_handler.test.js","skipped":false,"dir":"test"},{"name":"returns the status code","suites":["AWS Lambda Examples","#handler","when using aws environment variable authentication"],"updatePoint":{"line":21,"column":33,"index":573},"line":21,"code":"      it('returns the status code', async function () {\n        expect(response.statusCode).to.equal(200);\n      });","file":"integration/node-specific/examples/aws_handler.test.js","skipped":false,"dir":"test"},{"name":"supports causal consistency","suites":["examples(causal-consistency):"],"updatePoint":{"line":25,"column":33,"index":724},"line":25,"code":"  it('supports causal consistency', async function () {\n    const session = client.startSession({\n      causalConsistency: true\n    });\n    collection.insertOne({\n      darmok: 'jalad'\n    }, {\n      session\n    });\n    collection.updateOne({\n      darmok: 'jalad'\n    }, {\n      $set: {\n        darmok: 'tanagra'\n      }\n    }, {\n      session\n    });\n    const results = await collection.find({}, {\n      session\n    }).toArray();\n    expect(results).to.exist;\n    await session.endSession();\n  });","file":"integration/node-specific/examples/causal_consistency.test.js","skipped":false,"dir":"test"},{"name":"Open A Change Stream","suites":[],"updatePoint":{"line":54,"column":26,"index":1412},"line":54,"code":"  it('Open A Change Stream', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.6.0'\n      }\n    },\n    test: async function () {\n      const looper = new Looper(() => db.collection('inventory').insertOne({\n        a: 1\n      }));\n      looper.run();\n\n      // Start Changestream Example 1\n      const collection = db.collection('inventory');\n      const changeStream = collection.watch();\n      changeStream.on('change', next => {\n        // process next document\n      });\n      // End Changestream Example 1\n\n      // Start Changestream Example 1 Alternative\n      const changeStreamIterator = collection.watch();\n      const next = await changeStreamIterator.next();\n      // End Changestream Example 1 Alternative\n\n      await changeStream.close();\n      await changeStreamIterator.close();\n      await looper.stop();\n      expect(next).to.have.property('operationType').that.equals('insert');\n    }\n  });","file":"integration/node-specific/examples/change_streams.test.js","skipped":false,"dir":"test"},{"name":"Lookup Full Document for Update Operations","suites":[],"updatePoint":{"line":86,"column":48,"index":2386},"line":86,"code":"  it('Lookup Full Document for Update Operations', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.6.0'\n      }\n    },\n    test: async function () {\n      await db.collection('inventory').insertOne({\n        a: 1,\n        b: 2\n      });\n      const looper = new Looper(() => db.collection('inventory').updateOne({\n        a: 1\n      }, {\n        $set: {\n          a: 2\n        }\n      }));\n      looper.run();\n\n      // Start Changestream Example 2\n      const collection = db.collection('inventory');\n      const changeStream = collection.watch([], {\n        fullDocument: 'updateLookup'\n      });\n      changeStream.on('change', next => {\n        // process next document\n      });\n      // End Changestream Example 2\n\n      // Start Changestream Example 2 Alternative\n      const changeStreamIterator = collection.watch([], {\n        fullDocument: 'updateLookup'\n      });\n      const next = await changeStreamIterator.next();\n      // End Changestream Example 2 Alternative\n\n      await changeStream.close();\n      await changeStreamIterator.close();\n      await looper.stop();\n      expect(next).to.have.property('operationType').that.equals('update');\n      expect(next).to.have.property('fullDocument').that.has.all.keys(['_id', 'a', 'b']);\n    }\n  });","file":"integration/node-specific/examples/change_streams.test.js","skipped":false,"dir":"test"},{"name":"Resume a Change Stream","suites":[],"updatePoint":{"line":131,"column":28,"index":3670},"line":131,"code":"  it('Resume a Change Stream', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.6.0'\n      }\n    },\n    test: async function () {\n      const looper = new Looper(async () => {\n        await db.collection('inventory').insertOne({\n          a: 1\n        });\n        await db.collection('inventory').insertOne({\n          b: 2\n        });\n      });\n      looper.run();\n      let processChange;\n      const streamExampleFinished = new Promise(resolve => {\n        processChange = resolve;\n      });\n\n      // Start Changestream Example 3\n      const collection = db.collection('inventory');\n      const changeStream = collection.watch();\n      let newChangeStream;\n      changeStream.once('change', next => {\n        const resumeToken = changeStream.resumeToken;\n        changeStream.close();\n        newChangeStream = collection.watch([], {\n          resumeAfter: resumeToken\n        });\n        newChangeStream.on('change', next => {\n          processChange(next);\n        });\n      });\n      // End Changestream Example 3\n\n      // Start Changestream Example 3 Alternative\n      const changeStreamIterator = collection.watch();\n      const change1 = await changeStreamIterator.next();\n      const resumeToken = changeStreamIterator.resumeToken;\n      changeStreamIterator.close();\n      const newChangeStreamIterator = collection.watch([], {\n        resumeAfter: resumeToken\n      });\n      const change2 = await newChangeStreamIterator.next();\n      // End Changestream Example 3 Alternative\n\n      await newChangeStreamIterator.close();\n      await streamExampleFinished;\n      await newChangeStream.close();\n      await looper.stop();\n      expect(change1).to.have.nested.property('fullDocument.a', 1);\n      expect(change2).to.have.nested.property('fullDocument.b', 2);\n    }\n  });","file":"integration/node-specific/examples/change_streams.test.js","skipped":false,"dir":"test"},{"name":"Modify Change Stream Output","suites":[],"updatePoint":{"line":188,"column":33,"index":5503},"line":188,"code":"  it('Modify Change Stream Output', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.6.0'\n      }\n    },\n    test: async function () {\n      const looper = new Looper(async () => {\n        await db.collection('inventory').insertOne({\n          username: 'alice'\n        });\n      });\n      looper.run();\n\n      // Start Changestream Example 4\n      const pipeline = [{\n        $match: {\n          'fullDocument.username': 'alice'\n        }\n      }, {\n        $addFields: {\n          newField: 'this is an added field!'\n        }\n      }];\n      const collection = db.collection('inventory');\n      const changeStream = collection.watch(pipeline);\n      changeStream.on('change', next => {\n        // process next document\n      });\n      // End Changestream Example 4\n\n      // Start Changestream Example 4 Alternative\n      const changeStreamIterator = collection.watch(pipeline);\n      const next = await changeStreamIterator.next();\n      // End Changestream Example 4 Alternative\n\n      await changeStream.close();\n      await changeStreamIterator.close();\n      await looper.stop();\n      expect(next).to.have.nested.property('fullDocument.username', 'alice');\n      expect(next).to.have.property('newField', 'this is an added field!');\n    }\n  });","file":"integration/node-specific/examples/change_streams.test.js","skipped":false,"dir":"test"},{"name":"supports building simple ascending index","suites":["examples.createIndex:"],"updatePoint":{"line":19,"column":46,"index":583},"line":19,"code":"  it('supports building simple ascending index', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // Start createIndex example 1\n      await collection.createIndex({\n        score: 1\n      });\n      // End createIndex example 1\n    }\n  });","file":"integration/node-specific/examples/create_index.test.js","skipped":false,"dir":"test"},{"name":"supports building multikey index with partial filter expression","suites":["examples.createIndex:"],"updatePoint":{"line":34,"column":69,"index":914},"line":34,"code":"  it('supports building multikey index with partial filter expression', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>=3.2.x'\n      }\n    },\n    test: async function () {\n      // Start createIndex example 2\n      await collection.createIndex({\n        cuisine: 1,\n        name: 1\n      }, {\n        partialFilterExpression: {\n          rating: {\n            $gt: 5\n          }\n        }\n      });\n      // End createIndex example 2\n    }\n  });","file":"integration/node-specific/examples/create_index.test.js","skipped":false,"dir":"test"},{"name":"returns the databases","suites":["AWS Lambda Examples","#handler","when using standard authentication"],"updatePoint":{"line":18,"column":31,"index":442},"line":18,"code":"      it('returns the databases', async function () {\n        expect(response.databases).to.exist;\n      });","file":"integration/node-specific/examples/handler.test.js","skipped":false,"dir":"test"},{"name":"returns the status code","suites":["AWS Lambda Examples","#handler","when using standard authentication"],"updatePoint":{"line":21,"column":33,"index":553},"line":21,"code":"      it('returns the status code', async function () {\n        expect(response.statusCode).to.equal(200);\n      });","file":"integration/node-specific/examples/handler.test.js","skipped":false,"dir":"test"},{"name":"Insert a Single Document","suites":["examples(insert):"],"updatePoint":{"line":21,"column":30,"index":598},"line":21,"code":"  it('Insert a Single Document', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 1\n      await db.collection('inventory').insertOne({\n        item: 'canvas',\n        qty: 100,\n        tags: ['cotton'],\n        size: {\n          h: 28,\n          w: 35.5,\n          uom: 'cm'\n        }\n      });\n      // End Example 1\n\n      // Start Example 2\n      const cursor = db.collection('inventory').find({\n        item: 'canvas'\n      });\n      // End Example 2\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/insert.test.js","skipped":false,"dir":"test"},{"name":"Insert Multiple Documents","suites":["examples(insert):"],"updatePoint":{"line":51,"column":31,"index":1228},"line":51,"code":"  it('Insert Multiple Documents', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 3\n      await db.collection('inventory').insertMany([{\n        item: 'journal',\n        qty: 25,\n        tags: ['blank', 'red'],\n        size: {\n          h: 14,\n          w: 21,\n          uom: 'cm'\n        }\n      }, {\n        item: 'mat',\n        qty: 85,\n        tags: ['gray'],\n        size: {\n          h: 27.9,\n          w: 35.5,\n          uom: 'cm'\n        }\n      }, {\n        item: 'mousepad',\n        qty: 25,\n        tags: ['gel', 'blue'],\n        size: {\n          h: 19,\n          w: 22.85,\n          uom: 'cm'\n        }\n      }]);\n      // End Example 3\n\n      expect(await db.collection('inventory').count({})).to.equal(3);\n    }\n  });","file":"integration/node-specific/examples/insert.test.js","skipped":false,"dir":"test"},{"name":"Return All Fields in Matching Documents","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":88,"column":45,"index":1732},"line":88,"code":"  it('Return All Fields in Matching Documents', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 43\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      });\n      // End Example 43\n\n      expect(await cursor.count()).to.equal(3);\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Return the Specified Fields and the ``_id`` Field Only","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":105,"column":60,"index":2130},"line":105,"code":"  it('Return the Specified Fields and the ``_id`` Field Only', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 44\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      }).project({\n        item: 1,\n        status: 1\n      });\n      // End Example 44\n\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.all.keys(['_id', 'item', 'status']);\n        expect(doc).to.not.have.all.keys(['size', 'instock']);\n      });\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Suppress ``_id`` Field","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":129,"column":28,"index":2719},"line":129,"code":"  it('Suppress ``_id`` Field', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 45\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      }).project({\n        item: 1,\n        status: 1,\n        _id: 0\n      });\n      // End Example 45\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.all.keys(['item', 'status']);\n        expect(doc).to.not.have.all.keys(['_id', 'size', 'instock']);\n      });\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Return All But the Excluded Fields","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":153,"column":40,"index":3335},"line":153,"code":"  it('Return All But the Excluded Fields', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 46\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      }).project({\n        status: 0,\n        instock: 0\n      });\n      // End Example 46\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.all.keys(['_id', 'item', 'size']);\n        expect(doc).to.not.have.all.keys(['status', 'instock']);\n      });\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Return Specific Fields in Embedded Documents","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":176,"column":50,"index":3948},"line":176,"code":"  it('Return Specific Fields in Embedded Documents', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 47\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      }).project({\n        item: 1,\n        status: 1,\n        'size.uom': 1\n      });\n      // End Example 47\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.all.keys(['_id', 'item', 'status', 'size']);\n        expect(doc).to.not.have.property('instock');\n        const size = doc.size;\n        expect(size).to.have.property('uom');\n        expect(size).to.not.have.all.keys(['h', 'w']);\n      });\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Suppress Specific Fields in Embedded Documents","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":203,"column":52,"index":4713},"line":203,"code":"  it('Suppress Specific Fields in Embedded Documents', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 48\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      }).project({\n        'size.uom': 0\n      });\n      // End Example 48\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.all.keys(['_id', 'item', 'status', 'size', 'instock']);\n        const size = doc.size;\n        expect(size).to.have.all.keys(['h', 'w']);\n        expect(size).to.not.have.property('uom');\n      });\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Projection on Embedded Documents in an Array","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":227,"column":50,"index":5398},"line":227,"code":"  it('Projection on Embedded Documents in an Array', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 49\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      }).project({\n        item: 1,\n        status: 1,\n        'instock.qty': 1\n      });\n      // End Example 49\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.all.keys(['_id', 'item', 'status', 'instock']);\n        expect(doc).to.not.have.property('size');\n        doc.instock.forEach(function (subdoc) {\n          expect(subdoc).to.have.property('qty');\n          expect(subdoc).to.not.have.property('warehouse');\n        });\n      });\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Project Specific Array Elements in the Returned Array","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":255,"column":59,"index":6211},"line":255,"code":"  it('Project Specific Array Elements in the Returned Array', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 50\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      }).project({\n        item: 1,\n        status: 1,\n        instock: {\n          $slice: -1\n        }\n      });\n      // End Example 50\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.all.keys(['_id', 'item', 'status', 'instock']);\n        expect(doc).to.not.have.property('size');\n        expect(doc).to.have.property('instock').with.a.lengthOf(1);\n      });\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Query for a Document Nested in an Array","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":67,"column":45,"index":1425},"line":67,"code":"  it('Query for a Document Nested in an Array', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 30\n      const cursor = db.collection('inventory').find({\n        instock: {\n          warehouse: 'A',\n          qty: 5\n        }\n      });\n      // End Example 30\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"Query for a Document Nested in an Array - document order","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":87,"column":62,"index":1877},"line":87,"code":"  it('Query for a Document Nested in an Array - document order', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 31\n      const cursor = db.collection('inventory').find({\n        instock: {\n          qty: 5,\n          warehouse: 'A'\n        }\n      });\n      // End Example 31\n\n      expect(await cursor.count()).to.equal(0);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"Use the Array Index to Query for a Field in the Embedded Document","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":107,"column":71,"index":2338},"line":107,"code":"  it('Use the Array Index to Query for a Field in the Embedded Document', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 32\n      const cursor = db.collection('inventory').find({\n        'instock.0.qty': {\n          $lte: 20\n        }\n      });\n      // End Example 32\n\n      expect(await cursor.count()).to.equal(3);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"Specify a Query Condition on a Field Embedded in an Array of Documents","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":126,"column":76,"index":2788},"line":126,"code":"  it('Specify a Query Condition on a Field Embedded in an Array of Documents', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 33\n      const cursor = db.collection('inventory').find({\n        'instock.qty': {\n          $lte: 20\n        }\n      });\n      // End Example 33\n\n      expect(await cursor.count()).to.equal(5);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"A Single Nested Document Meets Multiple Query Conditions on Nested Fields","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":145,"column":79,"index":3239},"line":145,"code":"  it('A Single Nested Document Meets Multiple Query Conditions on Nested Fields', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 34\n      const cursor = db.collection('inventory').find({\n        instock: {\n          $elemMatch: {\n            qty: 5,\n            warehouse: 'A'\n          }\n        }\n      });\n      // End Example 34\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"A Single Nested Document Meets Multiple Query Conditions on Nested Fields: operators","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":167,"column":90,"index":3759},"line":167,"code":"  it('A Single Nested Document Meets Multiple Query Conditions on Nested Fields: operators', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 35\n      const cursor = db.collection('inventory').find({\n        instock: {\n          $elemMatch: {\n            qty: {\n              $gt: 10,\n              $lte: 20\n            }\n          }\n        }\n      });\n      // End Example 35\n\n      expect(await cursor.count()).to.equal(3);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"Combination of Elements Satisfies the Criteria","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":191,"column":52,"index":4273},"line":191,"code":"  it('Combination of Elements Satisfies the Criteria', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 36\n      const cursor = db.collection('inventory').find({\n        'instock.qty': {\n          $gt: 10,\n          $lte: 20\n        }\n      });\n      // End Example 36\n\n      expect(await cursor.count()).to.equal(4);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"Combination of Elements Satisfies the Criteria 2","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":211,"column":54,"index":4718},"line":211,"code":"  it('Combination of Elements Satisfies the Criteria 2', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 37\n      const cursor = db.collection('inventory').find({\n        'instock.qty': 5,\n        'instock.warehouse': 'A'\n      });\n      // End Example 37\n\n      expect(await cursor.count()).to.equal(2);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"Match an Array","suites":["examples(query-arrays):"],"updatePoint":{"line":50,"column":20,"index":1200},"line":50,"code":"  it('Match an Array', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 21\n      const cursor = db.collection('inventory').find({\n        tags: ['red', 'blank']\n      });\n      // End Example 21\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Match an Array: $all","suites":["examples(query-arrays):"],"updatePoint":{"line":67,"column":26,"index":1575},"line":67,"code":"  it('Match an Array: $all', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 22\n      const cursor = db.collection('inventory').find({\n        tags: {\n          $all: ['red', 'blank']\n        }\n      });\n      // End Example 22\n\n      expect(await cursor.count()).to.equal(4);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Query an Array for an Element","suites":["examples(query-arrays):"],"updatePoint":{"line":86,"column":35,"index":1987},"line":86,"code":"  it('Query an Array for an Element', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 23\n      const cursor = db.collection('inventory').find({\n        tags: 'red'\n      });\n      // End Example 23\n\n      expect(await cursor.count()).to.equal(4);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Query an Array for an Element w/ operators","suites":["examples(query-arrays):"],"updatePoint":{"line":103,"column":48,"index":2373},"line":103,"code":"  it('Query an Array for an Element w/ operators', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 24\n      const cursor = db.collection('inventory').find({\n        dim_cm: {\n          $gt: 25\n        }\n      });\n      // End Example 24\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Query an Array with Compound Filter Conditions on the Array Elements","suites":["examples(query-arrays):"],"updatePoint":{"line":122,"column":74,"index":2811},"line":122,"code":"  it('Query an Array with Compound Filter Conditions on the Array Elements', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 25\n      const cursor = db.collection('inventory').find({\n        dim_cm: {\n          $gt: 15,\n          $lt: 20\n        }\n      });\n      // End Example 25\n\n      expect(await cursor.count()).to.equal(4);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Query for an Array Element that Meets Multiple Criteria","suites":["examples(query-arrays):"],"updatePoint":{"line":142,"column":61,"index":3255},"line":142,"code":"  it('Query for an Array Element that Meets Multiple Criteria', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 26\n      const cursor = db.collection('inventory').find({\n        dim_cm: {\n          $elemMatch: {\n            $gt: 22,\n            $lt: 30\n          }\n        }\n      });\n      // End Example 26\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Query for an Element by the Array Index Position","suites":["examples(query-arrays):"],"updatePoint":{"line":164,"column":54,"index":3732},"line":164,"code":"  it('Query for an Element by the Array Index Position', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 27\n      const cursor = db.collection('inventory').find({\n        'dim_cm.1': {\n          $gt: 25\n        }\n      });\n      // End Example 27\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Query an Array by Array Length","suites":["examples(query-arrays):"],"updatePoint":{"line":183,"column":36,"index":4136},"line":183,"code":"  it('Query an Array by Array Length', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 28\n      const cursor = db.collection('inventory').find({\n        tags: {\n          $size: 3\n        }\n      });\n      // End Example 28\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Match an Embedded/Nested Document","suites":["examples(query-embedded-documents):"],"updatePoint":{"line":70,"column":39,"index":1412},"line":70,"code":"  it('Match an Embedded/Nested Document', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 15\n      const cursor = db.collection('inventory').find({\n        size: {\n          h: 14,\n          w: 21,\n          uom: 'cm'\n        }\n      });\n      // End Example 15\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_embedded_documents.test.js","skipped":false,"dir":"test"},{"name":"Match an Embedded/Nested Document - document order","suites":["examples(query-embedded-documents):"],"updatePoint":{"line":91,"column":56,"index":1866},"line":91,"code":"  it('Match an Embedded/Nested Document - document order', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 16\n      const cursor = db.collection('inventory').find({\n        size: {\n          w: 21,\n          h: 14,\n          uom: 'cm'\n        }\n      });\n      // End Example 16\n\n      expect(await cursor.count()).to.equal(0);\n    }\n  });","file":"integration/node-specific/examples/query_embedded_documents.test.js","skipped":false,"dir":"test"},{"name":"Specify Equality Match on a Nested Field","suites":["examples(query-embedded-documents):"],"updatePoint":{"line":112,"column":46,"index":2310},"line":112,"code":"  it('Specify Equality Match on a Nested Field', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 17\n      const cursor = db.collection('inventory').find({\n        'size.uom': 'in'\n      });\n      // End Example 17\n\n      expect(await cursor.count()).to.equal(2);\n    }\n  });","file":"integration/node-specific/examples/query_embedded_documents.test.js","skipped":false,"dir":"test"},{"name":"Specify Match using Query Operator","suites":["examples(query-embedded-documents):"],"updatePoint":{"line":129,"column":40,"index":2693},"line":129,"code":"  it('Specify Match using Query Operator', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 18\n      const cursor = db.collection('inventory').find({\n        'size.h': {\n          $lt: 15\n        }\n      });\n      // End Example 18\n\n      expect(await cursor.count()).to.equal(4);\n    }\n  });","file":"integration/node-specific/examples/query_embedded_documents.test.js","skipped":false,"dir":"test"},{"name":"Specify ``AND`` Condition","suites":["examples(query-embedded-documents):"],"updatePoint":{"line":148,"column":31,"index":3090},"line":148,"code":"  it('Specify ``AND`` Condition', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 19\n      const cursor = db.collection('inventory').find({\n        'size.h': {\n          $lt: 15\n        },\n        'size.uom': 'in',\n        status: 'D'\n      });\n      // End Example 19\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_embedded_documents.test.js","skipped":false,"dir":"test"},{"name":"Equality Filter","suites":["examples(query-for-null-fields):"],"updatePoint":{"line":30,"column":21,"index":764},"line":30,"code":"  it('Equality Filter', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 39\n      const cursor = db.collection('inventory').find({\n        item: null\n      });\n      // End Example 39\n\n      expect(await cursor.count()).to.equal(2);\n    }\n  });","file":"integration/node-specific/examples/query_for_null_fields.test.js","skipped":false,"dir":"test"},{"name":"Type Check","suites":["examples(query-for-null-fields):"],"updatePoint":{"line":47,"column":16,"index":1117},"line":47,"code":"  it('Type Check', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 40\n      const cursor = db.collection('inventory').find({\n        item: {\n          $type: 10\n        }\n      });\n      // End Example 40\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_for_null_fields.test.js","skipped":false,"dir":"test"},{"name":"Existence Check","suites":["examples(query-for-null-fields):"],"updatePoint":{"line":66,"column":21,"index":1502},"line":66,"code":"  it('Existence Check', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 41\n      const cursor = db.collection('inventory').find({\n        item: {\n          $exists: false\n        }\n      });\n      // End Example 41\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_for_null_fields.test.js","skipped":false,"dir":"test"},{"name":"select all documents in a collection","suites":["examples(query):"],"updatePoint":{"line":70,"column":42,"index":1394},"line":70,"code":"  it('select all documents in a collection', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 7\n      const cursor = db.collection('inventory').find({});\n      // End Example 7\n\n      expect(await cursor.count()).to.equal(5);\n    }\n  });","file":"integration/node-specific/examples/query.test.js","skipped":false,"dir":"test"},{"name":"Specify Equality Condition","suites":["examples(query):"],"updatePoint":{"line":85,"column":32,"index":1735},"line":85,"code":"  it('Specify Equality Condition', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 9\n      const cursor = db.collection('inventory').find({\n        status: 'D'\n      });\n      // End Example 9\n\n      expect(await cursor.count()).to.equal(2);\n    }\n  });","file":"integration/node-specific/examples/query.test.js","skipped":false,"dir":"test"},{"name":"Specify Conditions Using Query Operators","suites":["examples(query):"],"updatePoint":{"line":102,"column":46,"index":2117},"line":102,"code":"  it('Specify Conditions Using Query Operators', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 10\n      const cursor = db.collection('inventory').find({\n        status: {\n          $in: ['A', 'D']\n        }\n      });\n      // End Example 10\n      expect(await cursor.count()).to.equal(5);\n    }\n  });","file":"integration/node-specific/examples/query.test.js","skipped":false,"dir":"test"},{"name":"Specify ``AND`` Condition","suites":["examples(query):"],"updatePoint":{"line":120,"column":31,"index":2519},"line":120,"code":"  it('Specify ``AND`` Condition', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 11\n      const cursor = db.collection('inventory').find({\n        status: 'A',\n        qty: {\n          $lt: 30\n        }\n      });\n      // End Example 11\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query.test.js","skipped":false,"dir":"test"},{"name":"Specify ``OR`` Condition","suites":["examples(query):"],"updatePoint":{"line":139,"column":30,"index":2930},"line":139,"code":"  it('Specify ``OR`` Condition', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 12\n      const cursor = db.collection('inventory').find({\n        $or: [{\n          status: 'A'\n        }, {\n          qty: {\n            $lt: 30\n          }\n        }]\n      });\n      // End Example 12\n      expect(await cursor.count()).to.equal(3);\n    }\n  });","file":"integration/node-specific/examples/query.test.js","skipped":false,"dir":"test"},{"name":"Specify ``AND`` as well as ``OR`` Conditions","suites":["examples(query):"],"updatePoint":{"line":161,"column":50,"index":3408},"line":161,"code":"  it('Specify ``AND`` as well as ``OR`` Conditions', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 13\n      const cursor = db.collection('inventory').find({\n        status: 'A',\n        $or: [{\n          qty: {\n            $lt: 30\n          }\n        }, {\n          item: {\n            $regex: '^p'\n          }\n        }]\n      });\n      // End Example 13\n      expect(await cursor.count()).to.equal(2);\n    }\n  });","file":"integration/node-specific/examples/query.test.js","skipped":false,"dir":"test"},{"name":"Delete All Documents","suites":["examples(remove-documents):"],"updatePoint":{"line":70,"column":26,"index":1391},"line":70,"code":"  it('Delete All Documents', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 56\n      await db.collection('inventory').deleteMany({});\n      // End Example 56\n      const cursor = db.collection('inventory').find({});\n      expect(await cursor.count()).to.equal(0);\n    }\n  });","file":"integration/node-specific/examples/remove_documents.test.js","skipped":false,"dir":"test"},{"name":"Delete All Documents that Match a Condition","suites":["examples(remove-documents):"],"updatePoint":{"line":85,"column":49,"index":1805},"line":85,"code":"  it('Delete All Documents that Match a Condition', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 57\n      await db.collection('inventory').deleteMany({\n        status: 'A'\n      });\n      // End Example 57\n      const cursor = db.collection('inventory').find({});\n      expect(await cursor.count()).to.equal(3);\n    }\n  });","file":"integration/node-specific/examples/remove_documents.test.js","skipped":false,"dir":"test"},{"name":"Delete Only One Document that Matches a Condition","suites":["examples(remove-documents):"],"updatePoint":{"line":102,"column":55,"index":2252},"line":102,"code":"  it('Delete Only One Document that Matches a Condition', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 58\n      await db.collection('inventory').deleteOne({\n        status: 'D'\n      });\n      // End Example 58\n      const cursor = db.collection('inventory').find({});\n      expect(await cursor.count()).to.equal(4);\n    }\n  });","file":"integration/node-specific/examples/remove_documents.test.js","skipped":false,"dir":"test"},{"name":"supports runCommand 1","suites":["examples.runCommand:"],"updatePoint":{"line":22,"column":27,"index":607},"line":22,"code":"  it('supports runCommand 1', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // Start runCommand example 1\n      await db.command({\n        buildInfo: 1\n      });\n      // End runCommand example 1\n    }\n  });","file":"integration/node-specific/examples/run_command.test.js","skipped":false,"dir":"test"},{"name":"supports runCommand 2","suites":["examples.runCommand:"],"updatePoint":{"line":37,"column":27,"index":886},"line":37,"code":"  it('supports runCommand 2', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // Start runCommand example 2\n      await db.command({\n        collStats: 'restaurants'\n      });\n      // End runCommand example 2\n    }\n  });","file":"integration/node-specific/examples/run_command.test.js","skipped":false,"dir":"test"},{"name":"Transactions Retry Example 1","suites":["examples(transactions):"],"updatePoint":{"line":25,"column":34,"index":777},"line":25,"code":"  it('Transactions Retry Example 1', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.8.0'\n      }\n    },\n    test: async function () {\n      // Start Transactions Retry Example 1\n      async function runTransactionWithRetry(txnFunc, client, session) {\n        try {\n          await txnFunc(client, session);\n        } catch (error) {\n          console.log('Transaction aborted. Caught exception during transaction.');\n\n          // If transient error, retry the whole transaction\n          if (error.hasErrorLabel('TransientTransactionError')) {\n            console.log('TransientTransactionError, retrying transaction ...');\n            await runTransactionWithRetry(txnFunc, client, session);\n          } else {\n            throw error;\n          }\n        }\n      }\n      // End Transactions Retry Example 1\n\n      async function updateEmployeeInfo(client, session) {\n        session.startTransaction({\n          readConcern: {\n            level: 'snapshot'\n          },\n          writeConcern: {\n            w: 'majority'\n          },\n          readPreference: 'primary'\n        });\n        const employeesCollection = client.db('hr').collection('employees');\n        const eventsCollection = client.db('reporting').collection('events');\n        await employeesCollection.updateOne({\n          employee: 3\n        }, {\n          $set: {\n            status: 'Inactive'\n          }\n        }, {\n          session\n        });\n        await eventsCollection.insertOne({\n          employee: 3,\n          status: {\n            new: 'Inactive',\n            old: 'Active'\n          }\n        }, {\n          session\n        });\n        try {\n          await session.commitTransaction();\n        } catch (error) {\n          await session.abortTransaction();\n          throw error;\n        }\n      }\n      return client.withSession(session => runTransactionWithRetry(updateEmployeeInfo, client, session));\n    }\n  });","file":"integration/node-specific/examples/transactions.test.js","skipped":false,"dir":"test"},{"name":"Transactions Retry Example 2","suites":["examples(transactions):"],"updatePoint":{"line":91,"column":34,"index":2732},"line":91,"code":"  it('Transactions Retry Example 2', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.8.0'\n      }\n    },\n    test: async function () {\n      // Start Transactions Retry Example 2\n      async function commitWithRetry(session) {\n        try {\n          await session.commitTransaction();\n          console.log('Transaction committed.');\n        } catch (error) {\n          if (error.hasErrorLabel('UnknownTransactionCommitResult')) {\n            console.log('UnknownTransactionCommitResult, retrying commit operation ...');\n            await commitWithRetry(session);\n          } else {\n            console.log('Error during commit ...');\n            throw error;\n          }\n        }\n      }\n      // End Transactions Retry Example 2\n\n      async function updateEmployeeInfo(client, session) {\n        session.startTransaction({\n          readConcern: {\n            level: 'snapshot'\n          },\n          writeConcern: {\n            w: 'majority'\n          },\n          readPreference: 'primary'\n        });\n        const employeesCollection = client.db('hr').collection('employees');\n        const eventsCollection = client.db('reporting').collection('events');\n        await employeesCollection.updateOne({\n          employee: 3\n        }, {\n          $set: {\n            status: 'Inactive'\n          }\n        }, {\n          session\n        });\n        await eventsCollection.insertOne({\n          employee: 3,\n          status: {\n            new: 'Inactive',\n            old: 'Active'\n          }\n        }, {\n          session\n        });\n        try {\n          await commitWithRetry(session);\n        } catch (error) {\n          await session.abortTransaction();\n          throw error;\n        }\n      }\n      return client.withSession(session => updateEmployeeInfo(client, session));\n    }\n  });","file":"integration/node-specific/examples/transactions.test.js","skipped":false,"dir":"test"},{"name":"Transaction Retry Example 3","suites":["examples(transactions):"],"updatePoint":{"line":156,"column":33,"index":4581},"line":156,"code":"  it('Transaction Retry Example 3', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.8.0'\n      }\n    },\n    test: async function () {\n      // Start Transactions Retry Example 3\n      async function commitWithRetry(session) {\n        try {\n          await session.commitTransaction();\n          console.log('Transaction committed.');\n        } catch (error) {\n          if (error.hasErrorLabel('UnknownTransactionCommitResult')) {\n            console.log('UnknownTransactionCommitResult, retrying commit operation ...');\n            await commitWithRetry(session);\n          } else {\n            console.log('Error during commit ...');\n            throw error;\n          }\n        }\n      }\n      async function runTransactionWithRetry(txnFunc, client, session) {\n        try {\n          await txnFunc(client, session);\n        } catch (error) {\n          console.log('Transaction aborted. Caught exception during transaction.');\n\n          // If transient error, retry the whole transaction\n          if (error.hasErrorLabel('TransientTransactionError')) {\n            console.log('TransientTransactionError, retrying transaction ...');\n            await runTransactionWithRetry(txnFunc, client, session);\n          } else {\n            throw error;\n          }\n        }\n      }\n      async function updateEmployeeInfo(client, session) {\n        session.startTransaction({\n          readConcern: {\n            level: 'snapshot'\n          },\n          writeConcern: {\n            w: 'majority'\n          },\n          readPreference: 'primary'\n        });\n        const employeesCollection = client.db('hr').collection('employees');\n        const eventsCollection = client.db('reporting').collection('events');\n        await employeesCollection.updateOne({\n          employee: 3\n        }, {\n          $set: {\n            status: 'Inactive'\n          }\n        }, {\n          session\n        });\n        await eventsCollection.insertOne({\n          employee: 3,\n          status: {\n            new: 'Inactive',\n            old: 'Active'\n          }\n        }, {\n          session\n        });\n        try {\n          await commitWithRetry(session);\n        } catch (error) {\n          await session.abortTransaction();\n          throw error;\n        }\n      }\n      return client.withSession(session => runTransactionWithRetry(updateEmployeeInfo, client, session));\n      // End Transactions Retry Example 3\n    }\n  });","file":"integration/node-specific/examples/transactions.test.js","skipped":false,"dir":"test"},{"name":"Transactions withTransaction API Example 1","suites":["examples(transactions):"],"updatePoint":{"line":236,"column":48,"index":7060},"line":236,"code":"  it('Transactions withTransaction API Example 1', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.8.0'\n      }\n    },\n    test: async function () {\n      const uri = this.configuration.url();\n\n      // Start Transactions withTxn API Example 1\n\n      // For a replica set, include the replica set name and a seedlist of the members in the URI string; e.g.\n      // const uri = 'mongodb://mongodb0.example.com:27017,mongodb1.example.com:27017/?replicaSet=myRepl'\n      // For a sharded cluster, connect to the mongos instances; e.g.\n      // const uri = 'mongodb://mongos0.example.com:27017,mongos1.example.com:27017/'\n\n      const client = new MongoClient(uri);\n      await client.connect();\n\n      // Prereq: Create collections.\n\n      await client.db('mydb1').collection('foo').insertOne({\n        abc: 0\n      }, {\n        writeConcern: {\n          w: 'majority'\n        }\n      });\n      await client.db('mydb2').collection('bar').insertOne({\n        xyz: 0\n      }, {\n        writeConcern: {\n          w: 'majority'\n        }\n      });\n\n      // Step 1: Start a Client Session\n      const session = client.startSession();\n\n      // Step 2: Optional. Define options to use for the transaction\n      const transactionOptions = {\n        readPreference: 'primary',\n        readConcern: {\n          level: 'local'\n        },\n        writeConcern: {\n          w: 'majority'\n        }\n      };\n\n      // Step 3: Use withTransaction to start a transaction, execute the callback, and commit (or abort on error)\n      // Note: The callback for withTransaction MUST be async and/or return a Promise.\n      try {\n        await session.withTransaction(async () => {\n          const coll1 = client.db('mydb1').collection('foo');\n          const coll2 = client.db('mydb2').collection('bar');\n\n          // Important:: You must pass the session to the operations\n\n          await coll1.insertOne({\n            abc: 1\n          }, {\n            session\n          });\n          await coll2.insertOne({\n            xyz: 999\n          }, {\n            session\n          });\n        }, transactionOptions);\n      } finally {\n        await session.endSession();\n        await client.close();\n      }\n      // End Transactions withTxn API Example 1\n    }\n  });","file":"integration/node-specific/examples/transactions.test.js","skipped":false,"dir":"test"},{"name":"Update a Single Document","suites":["examples(update-documents):"],"updatePoint":{"line":115,"column":30,"index":2092},"line":115,"code":"  it('Update a Single Document', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 52\n      await db.collection('inventory').updateOne({\n        item: 'paper'\n      }, {\n        $set: {\n          'size.uom': 'cm',\n          status: 'P'\n        },\n        $currentDate: {\n          lastModified: true\n        }\n      });\n      // End Example 52\n      const cursor = db.collection('inventory').find({\n        item: 'paper'\n      });\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.nested.property('size.uom').that.equals('cm');\n        expect(doc).to.have.property('status').that.equals('P');\n        expect(doc).to.have.property('lastModified');\n      });\n    }\n  });","file":"integration/node-specific/examples/update_documents.test.js","skipped":false,"dir":"test"},{"name":"Update Multiple Documents","suites":["examples(update-documents):"],"updatePoint":{"line":147,"column":31,"index":2931},"line":147,"code":"  it('Update Multiple Documents', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 53\n      await db.collection('inventory').updateMany({\n        qty: {\n          $lt: 50\n        }\n      }, {\n        $set: {\n          'size.uom': 'in',\n          status: 'P'\n        },\n        $currentDate: {\n          lastModified: true\n        }\n      });\n      // End Example 53\n\n      const cursor = db.collection('inventory').find({\n        qty: {\n          $lt: 50\n        }\n      });\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.nested.property('size.uom').that.equals('in');\n        expect(doc).to.have.property('status').that.equals('P');\n        expect(doc).to.have.property('lastModified');\n      });\n    }\n  });","file":"integration/node-specific/examples/update_documents.test.js","skipped":false,"dir":"test"},{"name":"Replace a Document","suites":["examples(update-documents):"],"updatePoint":{"line":184,"column":24,"index":3807},"line":184,"code":"  it('Replace a Document', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 54\n      await db.collection('inventory').replaceOne({\n        item: 'paper'\n      }, {\n        item: 'paper',\n        instock: [{\n          warehouse: 'A',\n          qty: 60\n        }, {\n          warehouse: 'B',\n          qty: 40\n        }]\n      });\n      // End Example 54\n\n      const cursor = db.collection('inventory').find({\n        item: 'paper'\n      }).project({\n        _id: 0\n      });\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(Object.keys(doc)).to.have.a.lengthOf(2);\n        expect(doc).to.have.property('item');\n        expect(doc).to.have.property('instock').that.has.a.lengthOf(2);\n      });\n    }\n  });","file":"integration/node-specific/examples/update_documents.test.js","skipped":false,"dir":"test"},{"name":"enables logging for the specified component","suites":["Feature Flags","@@mdb.enableMongoLogger","when enabled","when logging is enabled for any component"],"updatePoint":{"line":70,"column":55,"index":2242},"line":70,"code":"        it('enables logging for the specified component', () => {\n          const client = new MongoClient('mongodb://localhost:27017', {\n            [loggerFeatureFlag]: true\n          });\n          expect(client.mongoLogger.componentSeverities).to.have.property('command', SeverityLevel.EMERGENCY);\n        });","file":"integration/node-specific/feature_flags.test.ts","skipped":false,"dir":"test"},{"name":"does not enable logging for any component","suites":["Feature Flags","@@mdb.enableMongoLogger","when enabled","when logging is not enabled for any component"],"updatePoint":{"line":81,"column":53,"index":2697},"line":81,"code":"        it('does not enable logging for any component', () => {\n          const client = new MongoClient('mongodb://localhost:27017', {\n            [loggerFeatureFlag]: true\n          });\n          for (const component of components) {\n            expect(client.mongoLogger.componentSeverities).to.have.property(component, SeverityLevel.OFF);\n          }\n        });","file":"integration/node-specific/feature_flags.test.ts","skipped":false,"dir":"test"},{"name":"does not enable logging","suites":["Feature Flags","@@mdb.enableMongoLogger","when set to ","when logging is enabled for a component"],"updatePoint":{"line":97,"column":37,"index":3360},"line":97,"code":"          it('does not enable logging', () => {\n            const client = new MongoClient('mongodb://localhost:27017', {\n              [loggerFeatureFlag]: featureFlagValue\n            });\n            for (const component of components) {\n              expect(client.mongoLogger.componentSeverities).to.have.property(component, SeverityLevel.OFF);\n            }\n          });","file":"integration/node-specific/feature_flags.test.ts","skipped":false,"dir":"test"},{"name":"does not enable logging","suites":["Feature Flags","@@mdb.enableMongoLogger","when set to ","when logging is not enabled for any component"],"updatePoint":{"line":110,"column":37,"index":3891},"line":110,"code":"          it('does not enable logging', () => {\n            const client = new MongoClient('mongodb://localhost:27017', {\n              [loggerFeatureFlag]: featureFlagValue\n            });\n            for (const component of components) {\n              expect(client.mongoLogger.componentSeverities).to.have.property(component, SeverityLevel.OFF);\n            }\n          });","file":"integration/node-specific/feature_flags.test.ts","skipped":false,"dir":"test"},{"name":"falls back to environment options","suites":["Feature Flags","@@mdb.internalLoggerConfig","when undefined"],"updatePoint":{"line":134,"column":43,"index":4633},"line":134,"code":"      it('falls back to environment options', function () {\n        const client = new MongoClient('mongodb://localhost:27017', {\n          [Symbol.for('@@mdb.enableMongoLogger')]: true,\n          [Symbol.for('@@mdb.internalLoggerConfig')]: undefined\n        });\n        expect(client.mongoLogger.componentSeverities).to.have.property('command', SeverityLevel.EMERGENCY);\n      });","file":"integration/node-specific/feature_flags.test.ts","skipped":false,"dir":"test"},{"name":"overrides environment options","suites":["Feature Flags","@@mdb.internalLoggerConfig","when defined"],"updatePoint":{"line":143,"column":39,"index":5061},"line":143,"code":"      it('overrides environment options', function () {\n        const client = new MongoClient('mongodb://localhost:27017', {\n          [Symbol.for('@@mdb.enableMongoLogger')]: true,\n          [Symbol.for('@@mdb.internalLoggerConfig')]: {\n            MONGODB_LOG_COMMAND: SeverityLevel.ALERT\n          }\n        });\n        expect(client.mongoLogger.componentSeverities).to.have.property('command', SeverityLevel.ALERT);\n      });","file":"integration/node-specific/feature_flags.test.ts","skipped":false,"dir":"test"},{"name":"aggregationExample2WithPromises","suites":["Operations"],"updatePoint":{"line":34,"column":37,"index":1283},"line":34,"code":"  it('aggregationExample2WithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Some docs for insertion\n        const docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }];\n\n        // Create a collection\n        const collection = db.collection('aggregationExample2_with_promise');\n\n        // Insert the docs\n        return collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          expect(result).to.exist;\n\n          // Execute aggregate, notice the pipeline is expressed as an Array\n          const cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }], {\n            cursor: {\n              batchSize: 1\n            }\n          });\n\n          // Get all the aggregation results\n          return cursor.toArray();\n        }).then(function (docs) {\n          expect(docs.length).to.equal(2);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"Aggregation Cursor next Test With Promises","suites":["Operations"],"updatePoint":{"line":128,"column":48,"index":3930},"line":128,"code":"  it('Aggregation Cursor next Test With Promises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Some docs for insertion\n        const docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }];\n\n        // Create a collection\n        const collection = db.collection('aggregation_next_example_with_promise');\n        let cursor;\n        // Insert the docs\n        return collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          expect(result).to.exist;\n\n          // Execute aggregate, notice the pipeline is expressed as an Array\n          cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }], {\n            cursor: {\n              batchSize: 1\n            }\n          });\n\n          // Get all the aggregation results\n          return cursor.next();\n        }).then(function (docs) {\n          expect(docs).to.exist;\n\n          // Need to close cursor to close implicit session,\n          // since cursor is not exhausted\n          return cursor.close();\n        }).then(() => client.close());\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDoSimpleCountExamplesWithPromises","suites":["Operations"],"updatePoint":{"line":224,"column":54,"index":6697},"line":224,"code":"  it('shouldCorrectlyDoSimpleCountExamplesWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient({\n        w: 0\n      }, {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Crete the collection for the distinct example\n        const collection = db.collection('countExample1_with_promise');\n\n        // Insert documents to perform distinct against\n        return collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }, {\n          a: 4,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (ids) {\n          expect(ids).to.exist;\n\n          // Perform a total count command\n          return collection.count();\n        }).then(function (count) {\n          expect(count).to.equal(4);\n\n          // Perform a partial account where b=1\n          return collection.count({\n            b: 1\n          });\n        }).then(function (count) {\n          expect(count).to.equal(1);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCreateComplexIndexOnTwoFieldsWithPromises","suites":["Operations"],"updatePoint":{"line":291,"column":53,"index":8610},"line":291,"code":"  it('shouldCreateComplexIndexOnTwoFieldsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection we want to drop later\n        const collection = db.collection('createIndexExample1_with_promise');\n\n        // Insert a bunch of documents for the index\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax()).then(function (result) {\n          expect(result).to.exist;\n\n          // Create an index on the a field\n          return collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          expect(indexName).to.exist;\n\n          // Show that duplicate records got dropped\n          return collection.find({}).toArray();\n        }).then(function (items) {\n          expect(items.length).to.equal(4);\n\n          // Perform a query, with explain to show we hit the query\n          return collection.find({\n            a: 2\n          }).explain();\n        }).then(function (explanation) {\n          expect(explanation != null).to.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleDistinctIndexesWithSubQueryFilterWithPromises","suites":["Operations"],"updatePoint":{"line":369,"column":72,"index":10938},"line":369,"code":"  it('shouldCorrectlyHandleDistinctIndexesWithSubQueryFilterWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Crete the collection for the distinct example\n        const collection = db.collection('distinctExample1_with_promise');\n\n        // Insert documents to perform distinct against\n        return collection.insertMany([{\n          a: 0,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'b'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'c'\n          }\n        }, {\n          a: 2,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 3\n        }, {\n          a: 3\n        }], configuration.writeConcernMax()).then(function (ids) {\n          expect(ids).to.exist;\n\n          // Perform a distinct query against the a field\n          return collection.distinct('a');\n        }).then(function (docs) {\n          expect(docs.sort()).to.deep.equal([0, 1, 2, 3]);\n\n          // Perform a distinct query against the sub-field b.c\n          return collection.distinct('b.c');\n        }).then(function (docs) {\n          expect(docs.sort()).to.deep.equal(['a', 'b', 'c']);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleDistinctIndexesWithPromises","suites":["Operations"],"updatePoint":{"line":440,"column":54,"index":13023},"line":440,"code":"  it('shouldCorrectlyHandleDistinctIndexesWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Crete the collection for the distinct example\n        const collection = db.collection('distinctExample2_with_promise');\n\n        // Insert documents to perform distinct against\n        return collection.insertMany([{\n          a: 0,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'b'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'c'\n          }\n        }, {\n          a: 2,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 3\n        }, {\n          a: 3\n        }, {\n          a: 5,\n          c: 1\n        }], configuration.writeConcernMax()).then(function (ids) {\n          expect(ids).to.exist;\n\n          // Perform a distinct query with a filter against the documents\n          return collection.distinct('a', {\n            c: 1\n          });\n        }).then(function (docs) {\n          expect(docs.sort()).to.deep.equal([5]);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDropCollectionWithDropFunctionWithPromises","suites":["Operations"],"updatePoint":{"line":515,"column":63,"index":15011},"line":515,"code":"  it('shouldCorrectlyDropCollectionWithDropFunctionWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection we want to drop later\n        return db.createCollection('test_other_drop_with_promise').then(function (collection) {\n          // Drop the collection\n          return collection.drop();\n        }).then(function (reply) {\n          expect(reply).to.exist;\n\n          // Ensure we don't have the collection in the set of names\n          return db.listCollections().toArray();\n        }).then(function (replies) {\n          let found = false;\n          // For each collection in the list of collection names in this db look for the\n          // dropped collection\n          replies.forEach(function (document) {\n            if (document.name === 'test_other_drop_with_promise') {\n              found = true;\n              return;\n            }\n          });\n\n          // Ensure the collection is not found\n          expect(found).to.equal(false);\n\n          // Let's close the db\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"dropIndexesExample1WithPromises","suites":["Operations"],"updatePoint":{"line":574,"column":37,"index":16978},"line":574,"code":"  it('dropIndexesExample1WithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        return db.createCollection('dropExample1_with_promise').then(function (r) {\n          expect(r).to.exist;\n\n          // Drop the collection\n          return db.collection('dropExample1_with_promise').dropIndexes();\n        }).then(function (reply) {\n          expect(reply).to.exist;\n\n          // Let's close the db\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateAndDropIndexWithPromises","suites":["Operations"],"updatePoint":{"line":617,"column":51,"index":18355},"line":617,"code":"  it('shouldCorrectlyCreateAndDropIndexWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient({\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        const collection = db.collection('dropIndexExample1_with_promise');\n\n        // Insert a bunch of documents for the index\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          expect(result).to.exist;\n\n          // Create an index on the a field\n          return collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          expect(indexName).to.exist;\n\n          // Drop the index\n          return collection.dropIndex('a_1_b_1');\n        }).then(function (result) {\n          expect(result).to.exist;\n          // Verify that the index is gone\n          return collection.indexInformation();\n        }).then(function (indexInformation) {\n          expect(indexInformation._id_).to.deep.equal([['_id', 1]]);\n          expect(indexInformation.a_1_b_1).to.not.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCreateComplexEnsureIndexWithPromises","suites":["Operations"],"updatePoint":{"line":696,"column":48,"index":20656},"line":696,"code":"  it('shouldCreateComplexEnsureIndexWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        const collection = db.collection('ensureIndexExample1_with_promise');\n\n        // Insert a bunch of documents for the index\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax()).then(function (result) {\n          expect(result).to.exist;\n\n          // Create an index on the a field\n          return db.createIndex('ensureIndexExample1_with_promise', {\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          expect(indexName).to.exist;\n\n          // Show that duplicate records got dropped\n          return collection.find({}).toArray();\n        }).then(function (items) {\n          expect(items.length).to.equal(4);\n\n          // Perform a query, with explain to show we hit the query\n          return collection.find({\n            a: 2\n          }).explain();\n        }).then(function (explanation) {\n          expect(explanation != null).to.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"ensureIndexExampleWithCompountIndexWithPromises","suites":["Operations"],"updatePoint":{"line":773,"column":53,"index":22958},"line":773,"code":"  it('ensureIndexExampleWithCompountIndexWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient({\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        const collection = db.collection('ensureIndexExample2_with_promise');\n\n        // Insert a bunch of documents for the index\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          expect(result).to.exist;\n\n          // Create an index on the a field\n          return collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          expect(indexName).to.exist;\n\n          // Show that duplicate records got dropped\n          return collection.find({}).toArray();\n        }).then(function (items) {\n          expect(items.length).to.equal(4);\n\n          // Perform a query, with explain to show we hit the query\n          return collection.find({\n            a: 2\n          }).explain();\n        }).then(function (explanation) {\n          expect(explanation != null).to.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleQueryWithPromises","suites":["Operations"],"updatePoint":{"line":854,"column":43,"index":25197},"line":854,"code":"  it('shouldPerformASimpleQueryWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection we want to drop later\n        const collection = db.collection('simple_query_with_promise');\n\n        // Insert a bunch of documents for the testing\n        return collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax()).then(function (result) {\n          expect(result).to.exist;\n\n          // Perform a simple find and return all the documents\n          return collection.find().toArray();\n        }).then(function (docs) {\n          expect(docs.length).to.equal(3);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleExplainQueryWithPromises","suites":["Operations"],"updatePoint":{"line":906,"column":50,"index":26818},"line":906,"code":"  it('shouldPerformASimpleExplainQueryWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection we want to drop later\n        const collection = db.collection('simple_explain_query_with_promise');\n\n        // Insert a bunch of documents for the testing\n        return collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax()).then(function (result) {\n          expect(result).to.exist;\n\n          // Perform a simple find and return all the documents\n          return collection.find({}).explain();\n        }).then(function (docs) {\n          expect(docs != null).to.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleLimitSkipQueryWithPromises","suites":["Operations"],"updatePoint":{"line":958,"column":52,"index":28440},"line":958,"code":"  it('shouldPerformASimpleLimitSkipQueryWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection we want to drop later\n        const collection = db.collection('simple_limit_skip_query_with_promise');\n\n        // Insert a bunch of documents for the testing\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }], configuration.writeConcernMax()).then(function (result) {\n          expect(result).to.exist;\n\n          // Perform a simple find and return all the documents\n          return collection.find({}).skip(1).limit(1).project({\n            b: 1\n          }).toArray();\n        }).then(function (docs) {\n          expect(docs.length).to.equal(1);\n          expect(docs[0].a).to.not.exist;\n          expect(docs[0].b).to.equal(2);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldPerformSimpleFindAndModifyOperationsWithPromises","suites":["Operations"],"updatePoint":{"line":1021,"column":60,"index":30546},"line":1021,"code":"  it('shouldPerformSimpleFindAndModifyOperationsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection we want to drop later\n        const collection = db.collection('simple_find_and_modify_operations_with_promise');\n\n        // Insert some test documentations\n        return collection.insertMany([{\n          a: 1\n        }, {\n          b: 1\n        }, {\n          c: 1\n        }], configuration.writeConcernMax()).then(function (result) {\n          expect(result).to.exist;\n\n          // Simple findAndModify command returning the new document\n          return collection.findOneAndUpdate({\n            a: 1\n          }, {\n            $set: {\n              b1: 1\n            }\n          }, {\n            returnDocument: ReturnDocument.AFTER\n          });\n        }).then(function (doc) {\n          expect(doc.value.a).to.equal(1);\n          expect(doc.value.b1).to.equal(1);\n\n          // Simple findAndModify command returning the new document and\n          // removing it at the same time\n          return collection.findOneAndUpdate({\n            b: 1\n          }, {\n            $set: {\n              b: 2\n            }\n          }, {\n            remove: true\n          });\n        }).then(function (doc) {\n          expect(doc).to.exist;\n\n          // Verify that the document is gone\n          return collection.findOne({\n            b: 1\n          });\n        }).then(function (item) {\n          expect(item).to.not.exist;\n\n          // Simple findAndModify command performing an upsert and returning the new document\n          // executing the command safely\n          return collection.findOneAndUpdate({\n            d: 1\n          }, {\n            $set: {\n              d: 1,\n              f: 1\n            }\n          }, {\n            returnDocument: ReturnDocument.AFTER,\n            upsert: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (doc) {\n          expect(doc.value.d).to.equal(1);\n          expect(doc.value.f).to.equal(1);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldPerformSimplefindOneAndDeleteWithPromises","suites":["Operations"],"updatePoint":{"line":1122,"column":53,"index":33521},"line":1122,"code":"  it('shouldPerformSimplefindOneAndDeleteWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection we want to drop later\n        const collection = db.collection('simple_find_and_modify_operations_2_with_promise');\n\n        // Insert some test documentations\n        return collection.insertMany([{\n          a: 1\n        }, {\n          b: 1,\n          d: 1\n        }, {\n          c: 1\n        }], configuration.writeConcernMax()).then(function (result) {\n          expect(result).to.exist;\n\n          // Simple findAndModify command returning the old document and\n          // removing it at the same time\n          return collection.findOneAndDelete({\n            b: 1\n          }, [['b', 1]]);\n        }).then(function (doc) {\n          expect(doc.value.b).to.equal(1);\n          expect(doc.value.d).to.equal(1);\n\n          // Verify that the document is gone\n          return collection.findOne({\n            b: 1\n          });\n        }).then(function (item) {\n          expect(item).to.not.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleLimitSkipFindOneQueryWithPromises","suites":["Operations"],"updatePoint":{"line":1186,"column":59,"index":35486},"line":1186,"code":"  it('shouldPerformASimpleLimitSkipFindOneQueryWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection we want to drop later\n        const collection = db.collection('simple_limit_skip_find_one_query_with_promise');\n\n        // Insert a bunch of documents for the testing\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }], configuration.writeConcernMax()).then(function (result) {\n          expect(result).to.exist;\n\n          // Perform a simple find and return all the documents\n          return collection.findOne({\n            a: 2\n          }, {\n            projection: {\n              b: 1\n            }\n          });\n        }).then(function (doc) {\n          expect(doc.a).to.not.exist;\n          expect(doc.b).to.equal(2);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveACollectionsIndexesWithPromises","suites":["Operations"],"updatePoint":{"line":1248,"column":60,"index":37313},"line":1248,"code":"  it('shouldCorrectlyRetrieveACollectionsIndexesWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Crete the collection for the distinct example\n        const collection = db.collection('simple_key_based_distinct_with_promise');\n\n        // Create a geo 2d index\n        return collection.createIndex({\n          loc: '2d'\n        }, configuration.writeConcernMax()).then(function (result) {\n          expect(result).to.exist;\n\n          // Create a simple single field index\n          return collection.createIndex({\n            a: 1\n          }, configuration.writeConcernMax());\n        }).then(function (result) {\n          expect(result).to.exist;\n          return delay(1000);\n        }).then(function () {\n          // List all of the indexes on the collection\n          return collection.indexes();\n        }).then(function (indexes) {\n          expect(indexes.length).to.equal(3);\n          return client.close();\n        });\n      });\n    }\n    // END\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteIndexExistsWithPromises","suites":["Operations"],"updatePoint":{"line":1303,"column":51,"index":39215},"line":1303,"code":"  it('shouldCorrectlyExecuteIndexExistsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a test collection that we are getting the options back from\n        const collection = db.collection('test_collection_index_exists_with_promise', configuration.writeConcernMax());\n\n        // Create an index on the collection\n        return collection.createIndex('a', configuration.writeConcernMax()).then(function (indexName) {\n          expect(indexName).to.exist;\n\n          // Let's test to check if a single index exists\n          return collection.indexExists('a_1');\n        }).then(function (result) {\n          expect(result).to.equal(true);\n\n          // Let's test to check if multiple indexes are available\n          return collection.indexExists(['a_1', '_id_']);\n        }).then(function (result) {\n          expect(result).to.equal(true);\n\n          // Check if a non existing index exists\n          return collection.indexExists('c_1');\n        }).then(function (result) {\n          expect(result).to.equal(false);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyShowTheResultsFromIndexInformationWithPromises","suites":["Operations"],"updatePoint":{"line":1358,"column":67,"index":41247},"line":1358,"code":"  it('shouldCorrectlyShowTheResultsFromIndexInformationWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient({\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection we want to drop later\n        const collection = db.collection('more_index_information_test_2_with_promise');\n\n        // Insert a bunch of documents for the index\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax()).then(function (result) {\n          expect(result).to.exist;\n\n          // Create an index on the a field\n          return collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          expect(indexName).to.exist;\n\n          // Fetch basic indexInformation for collection\n          return db.indexInformation('more_index_information_test_2_with_promise');\n        }).then(function (indexInformation) {\n          expect(indexInformation._id_).to.deep.equal([['_id', 1]]);\n          expect(indexInformation.a_1_b_1).to.deep.equal([['a', 1], ['b', 1]]);\n\n          // Fetch full index information\n          return collection.indexInformation({\n            full: true\n          });\n        }).then(function (indexInformation) {\n          expect(indexInformation[0].key).to.deep.equal({\n            _id: 1\n          });\n          expect(indexInformation[1].key).to.deep.equal({\n            a: 1,\n            b: 1\n          });\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyShowAllTheResultsFromIndexInformationWithPromises","suites":["Operations"],"updatePoint":{"line":1444,"column":70,"index":43871},"line":1444,"code":"  it('shouldCorrectlyShowAllTheResultsFromIndexInformationWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient({\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection we want to drop later\n        const collection = db.collection('more_index_information_test_3_with_promise');\n\n        // Insert a bunch of documents for the index\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          expect(result).to.exist;\n\n          // Create an index on the a field\n          return collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          expect(indexName).to.exist;\n\n          // Fetch basic indexInformation for collection\n          return collection.indexInformation();\n        }).then(function (indexInformation) {\n          expect(indexInformation._id_).to.deep.equal([['_id', 1]]);\n          expect(indexInformation.a_1_b_1).to.deep.equal([['a', 1], ['b', 1]]);\n\n          // Fetch full index information\n          return collection.indexInformation({\n            full: true\n          });\n        }).then(function (indexInformation) {\n          expect(indexInformation[0].key).to.deep.equal({\n            _id: 1\n          });\n          expect(indexInformation[1].key).to.deep.equal({\n            a: 1,\n            b: 1\n          });\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformASimpleSingleDocumentInsertNoCallbackNoSafeWithPromises","suites":["Operations"],"updatePoint":{"line":1534,"column":83,"index":46513},"line":1534,"code":"  it('shouldCorrectlyPerformASimpleSingleDocumentInsertNoCallbackNoSafeWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        const collection = db.collection('simple_document_insert_collection_no_safe_with_promise');\n\n        // Insert a single document\n        return collection.insertOne({\n          hello: 'world_no_safe'\n        }).then(function () {\n          // Fetch the document\n          return collection.findOne({\n            hello: 'world_no_safe'\n          });\n        }).then(function (item) {\n          expect(item.hello).to.equal('world_no_safe');\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformABatchDocumentInsertSafeWithPromises","suites":["Operations"],"updatePoint":{"line":1582,"column":64,"index":48186},"line":1582,"code":"  it('shouldCorrectlyPerformABatchDocumentInsertSafeWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Fetch a collection to insert document into\n        const collection = db.collection('batch_document_insert_collection_safe_with_promise');\n\n        // Insert a single document\n        return collection.insertMany([{\n          hello: 'world_safe1'\n        }, {\n          hello: 'world_safe2'\n        }], configuration.writeConcernMax()).then(function (result) {\n          expect(result).to.exist;\n\n          // Fetch the document\n          return collection.findOne({\n            hello: 'world_safe2'\n          });\n        }).then(function (item) {\n          expect(item.hello).to.equal('world_safe2');\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformASimpleDocumentInsertWithFunctionSafeWithPromises","suites":["Operations"],"updatePoint":{"line":1635,"column":77,"index":50001},"line":1635,"code":"  it('shouldCorrectlyPerformASimpleDocumentInsertWithFunctionSafeWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Fetch a collection to insert document into\n        const collection = db.collection('simple_document_insert_with_function_safe_with_promise');\n        const o = configuration.writeConcernMax();\n        o.serializeFunctions = true;\n\n        // Insert a single document\n        return collection.insertOne({\n          hello: 'world',\n          func: new Code('function () {}')\n        }, o).then(function (result) {\n          expect(result).to.exist;\n\n          // Fetch the document\n          return collection.findOne({\n            hello: 'world'\n          });\n        }).then(function (item) {\n          expect('function() {}', item.code).to.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteIsCappedWithPromises","suites":["Operations"],"updatePoint":{"line":1689,"column":48,"index":51848},"line":1689,"code":"  it('shouldCorrectlyExecuteIsCappedWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a test collection that we are getting the options back from\n        return db.createCollection('test_collection_is_capped_with_promise', {\n          capped: true,\n          size: 1024\n        }).then(function (collection) {\n          expect(collection.collectionName).to.equal('test_collection_is_capped_with_promise');\n\n          // Let's fetch the collection options\n          return collection.isCapped();\n        }).then(function (capped) {\n          expect(capped).to.equal(true);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveCollectionOptionsWithPromises","suites":["Operations"],"updatePoint":{"line":1735,"column":58,"index":53403},"line":1735,"code":"  it('shouldCorrectlyRetrieveCollectionOptionsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a test collection that we are getting the options back from\n        return db.createCollection('test_collection_options_with_promise', {\n          capped: true,\n          size: 1024\n        }).then(function (collection) {\n          expect(collection.collectionName).to.equal('test_collection_options_with_promise');\n\n          // Let's fetch the collection options\n          return collection.options();\n        }).then(function (options) {\n          expect(options.capped).to.equal(true);\n          expect(options.size >= 1024).to.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"deleteMany() deletes all documents in collection","suites":["Operations"],"updatePoint":{"line":1782,"column":54,"index":55026},"line":1782,"code":"  it('deleteMany() deletes all documents in collection', async function () {\n    const db = client.db();\n    // Fetch a collection to insert document into\n    const collection = db.collection('remove_all_documents_no_safe_with_promise');\n\n    // Insert a bunch of documents\n    const result = await collection.insertMany([{\n      a: 1\n    }, {\n      b: 2\n    }], {\n      writeConcern: {\n        w: 1\n      }\n    });\n    expect(result).to.exist;\n    await collection.deleteMany();\n    const items = await collection.find().toArray();\n    expect(items).to.have.lengthOf(0);\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldRemoveSubsetOfDocumentsSafeModeWithPromises","suites":["Operations"],"updatePoint":{"line":1809,"column":55,"index":55791},"line":1809,"code":"  it('shouldRemoveSubsetOfDocumentsSafeModeWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient({\n        w: 0\n      }, {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Fetch a collection to insert document into\n        const collection = db.collection('remove_subset_of_documents_safe_with_promise');\n\n        // Insert a bunch of documents\n        return collection.insertMany([{\n          a: 1\n        }, {\n          b: 2\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          expect(result).to.exist;\n\n          // Remove all the document\n          return collection.deleteOne({\n            a: 1\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (r) {\n          expect(r).property('deletedCount').to.equal(1);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRenameCollectionWithPromises","suites":["Operations"],"updatePoint":{"line":1871,"column":49,"index":57511},"line":1871,"code":"  it('shouldCorrectlyRenameCollectionWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n\n      /* eslint-disable */\n\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Open a couple of collections\n\n        var collection1, collection2;\n        return Promise.all([db.createCollection('test_rename_collection_with_promise'), db.createCollection('test_rename_collection2_with_promise')]).then(function (collections) {\n          collection1 = collections[0];\n          collection2 = collections[1];\n          expect(collection2).to.exist;\n\n          // Attemp to rename a collection to a number\n          try {\n            collection1.rename(5, function (err, collection) {});\n          } catch (err) {\n            expect(err instanceof Error).to.exist;\n            expect(err.message).to.equal('Collection name must be a String');\n          }\n\n          // Attemp to rename a collection to an empty string\n          try {\n            collection1.rename('', function (err, collection) {});\n          } catch (err) {\n            expect(err instanceof Error).to.exist;\n            expect(err.message).to.equal('Collection names cannot be empty');\n          }\n\n          // Attemp to rename a collection to an illegal name including the character $\n          try {\n            collection1.rename('te$t', function (err, collection) {});\n          } catch (err) {\n            expect(err instanceof Error).to.exist;\n            expect(err.message).to.equal(\"Collection names must not contain '$'\");\n          }\n\n          // Attemp to rename a collection to an illegal name starting with the character .\n          try {\n            collection1.rename('.test', function (err, collection) {});\n          } catch (err) {\n            expect(err instanceof Error).to.exist;\n            expect(err.message).to.equal(\"Collection names must not start or end with '.'\");\n          }\n\n          // Attemp to rename a collection to an illegal name ending with the character .\n          try {\n            collection1.rename('test.', function (err, collection) {});\n          } catch (err) {\n            expect(err instanceof Error).to.exist;\n            expect(err.message).to.equal(\"Collection names must not start or end with '.'\");\n          }\n\n          // Attemp to rename a collection to an illegal name with an empty middle name\n          try {\n            collection1.rename('tes..t', function (err, collection) {});\n          } catch (err) {\n            expect(err.message).to.equal('Collection names cannot be empty');\n          }\n\n          // Insert a couple of documents\n          return collection1.insertMany([{\n            x: 1\n          }, {\n            x: 2\n          }], configuration.writeConcernMax());\n        }).then(function (docs) {\n          expect(docs).to.exist;\n\n          // Attemp to rename the first collection to the second one, this will fail\n          return collection1.rename('test_rename_collection2_with_promise');\n        }).catch(function (err) {\n          expect(err instanceof Error).to.exist;\n          expect(err.message.length > 0).to.exist;\n\n          // Attemp to rename the first collection to a name that does not exist\n          // this will be successful\n          return collection1.rename('test_rename_collection3_with_promise');\n        }).then(function (collection2) {\n          expect(collection2.collectionName).to.equal('test_rename_collection3_with_promise');\n\n          // Ensure that the collection is pointing to the new one\n          return collection2.count();\n        }).then(function (count) {\n          expect(count).to.equal(2);\n        }).then(() => client.close(), e => {\n          client.close();\n          throw e;\n        });\n      });\n      // END\n      /* eslint-enable */\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUpdateASimpleDocumentWithPromises","suites":["Operations"],"updatePoint":{"line":1991,"column":54,"index":62119},"line":1991,"code":"  it('shouldCorrectlyUpdateASimpleDocumentWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient({\n        w: 0\n      }, {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Get a collection\n        const collection = db.collection('update_a_simple_document_with_promise');\n\n        // Insert a document, then update it\n        return collection.insertOne({\n          a: 1\n        }, configuration.writeConcernMax()).then(function (doc) {\n          expect(doc).to.exist;\n          // Update the document with an atomic operator\n          return collection.updateOne({\n            a: 1\n          }, {\n            $set: {\n              b: 2\n            }\n          });\n        }).then(function () {\n          // Fetch the document that we modified\n          return collection.findOne({\n            a: 1\n          });\n        }).then(function (item) {\n          expect(item.a).to.equal(1);\n          expect(item.b).to.equal(2);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUpsertASimpleDocumentWithPromises","suites":["Operations"],"updatePoint":{"line":2052,"column":54,"index":63970},"line":2052,"code":"  it('shouldCorrectlyUpsertASimpleDocumentWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Get a collection\n        const collection = db.collection('update_a_simple_document_upsert_with_promise');\n\n        // Update the document using an upsert operation, ensuring creation if it does not exist\n        return collection.updateOne({\n          a: 1\n        }, {\n          $set: {\n            b: 2,\n            a: 1\n          }\n        }, {\n          upsert: true,\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          expect(result).property('upsertedCount').to.equal(1);\n\n          // Fetch the document that we modified and check if it got inserted correctly\n          return collection.findOne({\n            a: 1\n          });\n        }).then(function (item) {\n          expect(item.a).to.equal(1);\n          expect(item.b).to.equal(2);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUpdateMultipleDocumentsWithPromises","suites":["Operations"],"updatePoint":{"line":2113,"column":56,"index":65849},"line":2113,"code":"  it('shouldCorrectlyUpdateMultipleDocumentsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Get a collection\n        const collection = db.collection('update_a_simple_document_multi_with_promise');\n\n        // Insert a couple of documentations\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 1,\n          b: 2\n        }], configuration.writeConcernMax()).then(function (result) {\n          expect(result).to.exist;\n          const o = configuration.writeConcernMax();\n          return collection.updateMany({\n            a: 1\n          }, {\n            $set: {\n              b: 0\n            }\n          }, o);\n        }).then(function (r) {\n          expect(r).property('matchedCount').to.equal(2);\n\n          // Fetch all the documents and verify that we have changed the b value\n          return collection.find().toArray();\n        }).then(function (items) {\n          expect(items[0].a).to.equal(1);\n          expect(items[0].b).to.equal(0);\n          expect(items[1].a).to.equal(1);\n          expect(items[1].b).to.equal(0);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyReturnACollectionsStatsWithPromises","suites":["Operations"],"updatePoint":{"line":2178,"column":56,"index":67887},"line":2178,"code":"  it('shouldCorrectlyReturnACollectionsStatsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Crete the collection for the distinct example\n        const collection = db.collection('collection_stats_test_with_promise');\n\n        // Insert some documents\n        return collection.insertMany([{\n          a: 1\n        }, {\n          hello: 'world'\n        }], configuration.writeConcernMax()).then(function (result) {\n          expect(result).to.exist;\n          // Retrieve the statistics for the collection\n          return collection.stats();\n        }).then(function (stats) {\n          expect(stats.count).to.equal(2);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateAndDropAllIndexWithPromises","suites":["Operations"],"updatePoint":{"line":2227,"column":54,"index":69485},"line":2227,"code":"  it('shouldCorrectlyCreateAndDropAllIndexWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient({\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection we want to drop later\n        const collection = db.collection('shouldCorrectlyCreateAndDropAllIndex_with_promise');\n        // Insert a bunch of documents for the index\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4,\n          c: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          expect(result).to.exist;\n\n          // Create an index on the a field\n          return collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          expect(indexName).to.exist;\n          // Create an additional index\n          return collection.createIndex({\n            c: 1\n          }, {\n            unique: true,\n            background: true,\n            sparse: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          expect(indexName).to.exist;\n          // Drop the index\n          return collection.dropIndexes();\n        }).then(function (result) {\n          expect(result).to.exist;\n          // Verify that the index is gone\n          return collection.indexInformation();\n        }).then(function (indexInformation) {\n          expect(indexInformation._id_).to.deep.equal([['_id', 1]]);\n          expect(indexInformation.a_1_b_1).to.not.exist;\n          expect(indexInformation.c_1).to.not.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyOpenASimpleDbSingleServerConnectionAndCloseWithCallbackWithPromises","suites":["Operations"],"updatePoint":{"line":2327,"column":88,"index":72435},"line":2327,"code":"  it('shouldCorrectlyOpenASimpleDbSingleServerConnectionAndCloseWithCallbackWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Close the connection with a callback that is optional\n        return client.close();\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrievelistCollectionsWithPromises","suites":["Operations"],"updatePoint":{"line":2361,"column":56,"index":73498},"line":2361,"code":"  it('shouldCorrectlyRetrievelistCollectionsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get an empty db\n        const db1 = client.db('listCollectionTestDb2');\n\n        // Create a collection\n        const collection = db1.collection('shouldCorrectlyRetrievelistCollections_with_promise');\n\n        // Ensure the collection was created\n        return collection.insertOne({\n          a: 1\n        }).then(function () {\n          // Return the information of a single collection name\n          return db1.listCollections({\n            name: 'shouldCorrectlyRetrievelistCollections_with_promise'\n          }).toArray();\n        }).then(function (items) {\n          expect(items.length).to.equal(1);\n\n          // Return the information of a all collections, using the callback format\n          return db1.listCollections().toArray();\n        }).then(function (items) {\n          expect(items.length >= 1).to.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrievelistCollectionsWiredTigerWithPromises","suites":["Operations"],"updatePoint":{"line":2409,"column":66,"index":75237},"line":2409,"code":"  it('shouldCorrectlyRetrievelistCollectionsWiredTigerWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['wiredtiger']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        // Get an empty db\n        const db1 = client.db('listCollectionTestDb2');\n\n        // Create a collection\n        const collection = db1.collection('shouldCorrectlyRetrievelistCollections_with_promise');\n\n        // Ensure the collection was created\n        return collection.insertOne({\n          a: 1\n        }).then(function () {\n          // Return the information of a single collection name\n          return db1.listCollections({\n            name: 'shouldCorrectlyRetrievelistCollections_with_promise'\n          }).toArray();\n        }).then(function (items) {\n          expect(items.length).to.equal(1);\n\n          // Return the information of a all collections, using the callback format\n          return db1.listCollections().toArray();\n        }).then(function (items) {\n          expect(items.length).to.equal(1);\n          return client.close();\n        });\n      });\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveAllCollectionsWithPromises","suites":["Operations"],"updatePoint":{"line":2454,"column":55,"index":76686},"line":2454,"code":"  it('shouldCorrectlyRetrieveAllCollectionsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Retry to get the collection, should work as it's now created\n        return db.collections().then(function (collections) {\n          expect(collections.length > 0).to.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyAddUserToDbWithPromises","suites":["Operations"],"updatePoint":{"line":2491,"column":44,"index":77893},"line":2491,"code":"  it('shouldCorrectlyAddUserToDbWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Add a user to the database\n        return db.addUser('user', 'name').then(function (result) {\n          expect(result).to.exist;\n          // Remove the user from the db\n          return db.removeUser('user');\n        }).then(function (result) {\n          expect(result).to.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyAddAndRemoveUserWithPromises","suites":["Operations"],"line":2533,"code":"  it.skip('shouldCorrectlyAddAndRemoveUserWithPromises', {","file":"integration/node-specific/operation_examples.test.ts","skipped":true,"dir":"test"},{"name":"shouldCorrectlyCreateACollectionWithPromises","suites":["Operations"],"updatePoint":{"line":2593,"column":50,"index":81293},"line":2593,"code":"  it('shouldCorrectlyCreateACollectionWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a capped collection with a maximum of 1000 documents\n        return db.createCollection('a_simple_collection_with_promise', {\n          capped: true,\n          size: 10000,\n          max: 1000,\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (collection) {\n          // Insert a document in the capped collection\n          return collection.insertOne({\n            a: 1\n          }, configuration.writeConcernMax());\n        }).then(function (result) {\n          expect(result).to.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteACommandAgainstTheServerWithPromises","suites":["Operations"],"updatePoint":{"line":2642,"column":64,"index":82932},"line":2642,"code":"  it('shouldCorrectlyExecuteACommandAgainstTheServerWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Execute ping against the server\n        return db.command({\n          ping: 1\n        }).then(function (result) {\n          expect(result).to.exist;\n          // Create a capped collection with a maximum of 1000 documents\n          return db.createCollection('a_simple_create_drop_collection_with_promise', {\n            capped: true,\n            size: 10000,\n            max: 1000,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (collection) {\n          // Insert a document in the capped collection\n          return collection.insertOne({\n            a: 1\n          }, configuration.writeConcernMax());\n        }).then(function (result) {\n          expect(result).to.exist;\n          // Drop the collection from this world\n          return db.dropCollection('a_simple_create_drop_collection_with_promise');\n        }).then(function (result) {\n          expect(result).to.exist;\n          // Verify that the collection is gone\n          return db.listCollections({\n            name: 'a_simple_create_drop_collection_with_promise'\n          }).toArray();\n        }).then(function (names) {\n          expect(names.length).to.equal(0);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateDropAndVerifyThatCollectionIsGoneWithPromises","suites":["Operations"],"updatePoint":{"line":2707,"column":72,"index":85192},"line":2707,"code":"  it('shouldCorrectlyCreateDropAndVerifyThatCollectionIsGoneWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Execute ping against the server\n        return db.command({\n          ping: 1\n        }).then(function (result) {\n          expect(result).to.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRenameACollectionWithPromises","suites":["Operations"],"updatePoint":{"line":2746,"column":50,"index":86425},"line":2746,"code":"  it('shouldCorrectlyRenameACollectionWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection\n\n        return db.createCollection('simple_rename_collection_with_promise', configuration.writeConcernMax()).then(function (collection) {\n          // Insert a document in the collection\n          return collection.insertOne({\n            a: 1\n          }, configuration.writeConcernMax()).then(function () {\n            return collection;\n          });\n        }).then(function (collection) {\n          // Retrieve the number of documents from the collection\n          return collection.count();\n        }).then(function (count) {\n          expect(count).to.equal(1);\n\n          // Rename the collection\n          return db.renameCollection('simple_rename_collection_with_promise', 'simple_rename_collection_2_with_promise');\n        }).then(function (collection2) {\n          // Retrieve the number of documents from the collection\n          return collection2.count();\n        }).then(function (count) {\n          expect(count).to.equal(1);\n\n          // Verify that the collection is gone\n          return db.listCollections({\n            name: 'simple_rename_collection_with_promise'\n          }).toArray();\n        }).then(function (names) {\n          expect(names.length).to.equal(0);\n\n          // Verify that the new collection exists\n          return db.listCollections({\n            name: 'simple_rename_collection_2_with_promise'\n          }).toArray();\n        }).then(function (names) {\n          expect(names.length).to.equal(1);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCreateOnDbComplexIndexOnTwoFieldsWithPromises","suites":["Operations"],"updatePoint":{"line":2816,"column":57,"index":89006},"line":2816,"code":"  it('shouldCreateOnDbComplexIndexOnTwoFieldsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection we want to drop later\n        const collection = db.collection('more_complex_index_test_with_promise');\n\n        // Insert a bunch of documents for the index\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax()).then(function (result) {\n          expect(result).to.exist;\n          // Create an index on the a field\n          return db.createIndex('more_complex_index_test_with_promise', {\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          expect(indexName).to.exist;\n          // Show that duplicate records got dropped\n          return collection.find({}).toArray();\n        }).then(function (items) {\n          expect(items.length).to.equal(4);\n\n          // Perform a query, with explain to show we hit the query\n          return collection.find({\n            a: 2\n          }).explain();\n        }).then(function (explanation) {\n          expect(explanation != null).to.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCreateComplexEnsureIndexDbWithPromises","suites":["Operations"],"updatePoint":{"line":2893,"column":50,"index":91391},"line":2893,"code":"  it('shouldCreateComplexEnsureIndexDbWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection we want to drop later\n        const collection = db.collection('more_complex_ensure_index_db_test_with_promise');\n\n        // Insert a bunch of documents for the index\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax()).then(function (result) {\n          expect(result).to.exist;\n          // Create an index on the a field\n          return db.createIndex('more_complex_ensure_index_db_test_with_promise', {\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          expect(indexName).to.exist;\n          // Show that duplicate records got dropped\n          return collection.find({}).toArray();\n        }).then(function (items) {\n          expect(items.length).to.equal(4);\n\n          // Perform a query, with explain to show we hit the query\n          return collection.find({\n            a: 2\n          }).explain();\n        }).then(function (explanation) {\n          expect(explanation != null).to.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDropTheDatabaseWithPromises","suites":["Operations"],"updatePoint":{"line":2970,"column":48,"index":93733},"line":2970,"code":"  it('shouldCorrectlyDropTheDatabaseWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection\n        const collection = db.collection('more_index_information_test_1_with_promise');\n\n        // Insert a bunch of documents for the index\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax()).then(function (result) {\n          expect(result).to.exist;\n\n          // Let's drop the database\n          return db.dropDatabase();\n        }).then(function (result) {\n          expect(result).to.exist;\n\n          // Get the admin database\n          return db.admin().listDatabases();\n        }).then(function (dbs) {\n          // Grab the databases\n          dbs = dbs.databases;\n          // Did we find the db\n          let found = false;\n\n          // Check if we have the db in the list\n          for (let i = 0; i < dbs.length; i++) {\n            if (dbs[i].name === 'integration_tests_to_drop') found = true;\n          }\n\n          // We should not find the databases\n          if (process.env['JENKINS'] == null) expect(found).to.equal(false);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveDbStatsWithPromisesWithPromises","suites":["Operations"],"updatePoint":{"line":3047,"column":60,"index":95998},"line":3047,"code":"  it('shouldCorrectlyRetrieveDbStatsWithPromisesWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        return db.stats().then(function (stats) {\n          expect(stats != null).to.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyShareConnectionPoolsAcrossMultipleDbInstancesWithPromises","suites":["Operations"],"updatePoint":{"line":3083,"column":78,"index":97187},"line":3083,"code":"  it('shouldCorrectlyShareConnectionPoolsAcrossMultipleDbInstancesWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Reference a different database sharing the same connections\n        // for the data transfer\n        const secondDb = client.db('integration_tests_2');\n\n        // Fetch the collections\n        const multipleColl1 = db.collection('multiple_db_instances_with_promise');\n        const multipleColl2 = secondDb.collection('multiple_db_instances_with_promise');\n\n        // Write a record into each and then count the records stored\n        return multipleColl1.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          expect(result).to.exist;\n          return multipleColl2.insertOne({\n            a: 1\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (result) {\n          expect(result).to.exist;\n          // Count over the results ensuring only on record in each collection\n          return multipleColl1.count();\n        }).then(function (count) {\n          expect(count).to.equal(1);\n          return multipleColl2.count();\n        }).then(function (count) {\n          expect(count).to.equal(1);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveBuildInfoWithPromises","suites":["Operations"],"updatePoint":{"line":3156,"column":50,"index":99575},"line":3156,"code":"  it('shouldCorrectlyRetrieveBuildInfoWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Use the admin database for the operation\n        const adminDb = db.admin();\n\n        // Retrieve the build information for the MongoDB instance\n        return adminDb.buildInfo().then(function (info) {\n          expect(info).to.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveBuildInfoUsingCommandWithPromises","suites":["Operations"],"updatePoint":{"line":3198,"column":62,"index":100908},"line":3198,"code":"  it('shouldCorrectlyRetrieveBuildInfoUsingCommandWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Use the admin database for the operation\n        const adminDb = db.admin();\n\n        // Retrieve the build information using the admin command\n        return adminDb.command({\n          buildInfo: 1\n        }).then(function (info) {\n          expect(info).to.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlySetDefaultProfilingLevelWithPromises","suites":["Operations"],"updatePoint":{"line":3242,"column":57,"index":102287},"line":3242,"code":"  it('shouldCorrectlySetDefaultProfilingLevelWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Grab a collection object\n        const collection = db.collection('test_with_promise');\n\n        // Force the creation of the collection by inserting a document\n        // Collections are not created until the first document is inserted\n        return collection.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (doc) {\n          expect(doc).to.exist;\n          // Use the admin database for the operation\n          const adminDb = client.db('admin');\n\n          // Retrieve the profiling level\n          return adminDb.profilingLevel();\n        }).then(function (level) {\n          expect(level).to.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"setProfilingLevel changes profiling level","suites":["Operations"],"updatePoint":{"line":3299,"column":47,"index":104121},"line":3299,"code":"  it('setProfilingLevel changes profiling level', {\n    requires: {\n      topology: 'single'\n    }\n  }, async function () {\n    const configuration = this.configuration;\n    const db = client.db(configuration.db);\n    // LINE var MongoClient = require('mongodb').MongoClient,\n    // LINE   test = require('assert');\n    // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n    // LINE client.connect().then(() => {\n    // LINE   var db = client.db('test);\n    // REPLACE configuration.writeConcernMax() WITH {w:1}\n    // REMOVE-LINE restartAndDone\n    // REMOVE-LINE done();\n    // BEGIN\n\n    // Grab a collection object\n    const collection = db.collection('test_with_promise');\n    const adminDb = client.db('admin');\n\n    // Force the creation of the collection by inserting a document\n    // Collections are not created until the first document is inserted\n    await collection.insertOne({\n      a: 1\n    }, {\n      writeConcern: {\n        w: 1\n      }\n    }).then(function (doc) {\n      expect(doc).to.exist;\n      // Set the profiling level to only profile slow queries\n      return adminDb.setProfilingLevel('slow_only');\n    }).then(function (level) {\n      expect(level).to.exist;\n      // Retrieve the profiling level and verify that it's set to slow_only\n      return adminDb.profilingLevel();\n    }).then(function (level) {\n      expect(level).to.equal('slow_only');\n\n      // Turn profiling off\n      return adminDb.setProfilingLevel('off');\n    }).then(function (level) {\n      expect(level).to.exist;\n      // Retrieve the profiling level and verify that it's set to off\n      return adminDb.profilingLevel();\n    }).then(function (level) {\n      expect(level).to.equal('off');\n\n      // Set the profiling level to log all queries\n      return adminDb.setProfilingLevel('all');\n    }).then(function (level) {\n      expect(level).to.exist;\n      // Retrieve the profiling level and verify that it's set to all\n      return adminDb.profilingLevel();\n    }).then(function (level) {\n      expect(level).to.equal('all');\n\n      // Attempt to set an illegal profiling level\n      return adminDb.setProfilingLevel('medium');\n    }).catch(function (err) {\n      expect(err).to.be.instanceOf(Error);\n      expect(`Profiling level must be one of \"${enumToString(ProfilingLevel)}\"`).to.equal(err.message);\n    });\n    // END\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCallValidateCollectionWithPromises","suites":["Operations"],"updatePoint":{"line":3373,"column":55,"index":106748},"line":3373,"code":"  it('shouldCorrectlyCallValidateCollectionWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Grab a collection object\n        const collection = db.collection('test_with_promise');\n\n        // Force the creation of the collection by inserting a document\n        // Collections are not created until the first document is inserted\n        return collection.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (doc) {\n          expect(doc).to.exist;\n          // Use the admin database for the operation\n          const adminDb = db.admin();\n\n          // Validate the 'test' collection\n          return adminDb.validateCollection('test_with_promise');\n        }).then(function (doc) {\n          expect(doc).to.exist;\n          return client.close();\n        });\n      });\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPingTheMongoDbInstanceWithPromises","suites":["Operations"],"updatePoint":{"line":3428,"column":55,"index":108517},"line":3428,"code":"  it('shouldCorrectlyPingTheMongoDbInstanceWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Use the admin database for the operation\n        const adminDb = db.admin();\n\n        // Ping the server\n        return adminDb.ping().then(function (pingResult) {\n          expect(pingResult).to.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyAddAUserToAdminDbWithPromises","suites":["Operations"],"updatePoint":{"line":3470,"column":50,"index":109809},"line":3470,"code":"  it('shouldCorrectlyAddAUserToAdminDbWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Use the admin database for the operation\n        const adminDb = db.admin();\n\n        // Add the new user to the admin database\n        return adminDb.addUser('admin11', 'admin11').then(function (result) {\n          expect(result).to.exist;\n          return adminDb.removeUser('admin11');\n        }).then(function (result) {\n          expect(result).to.exist;\n          return client.close();\n        });\n      });\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyAddAUserAndRemoveItFromAdminDbWithPromises","suites":["Operations"],"updatePoint":{"line":3514,"column":63,"index":111266},"line":3514,"code":"  it('shouldCorrectlyAddAUserAndRemoveItFromAdminDbWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Use the admin database for the operation\n        const adminDb = db.admin();\n\n        // Add the new user to the admin database\n        return adminDb.addUser('admin12', 'admin12').then(function (result) {\n          expect(result).to.exist;\n\n          // Remove the user\n          return adminDb.removeUser('admin12');\n        }).then(function (result) {\n          expect(result).to.equal(true);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyListAllAvailableDatabasesWithPromises","suites":["Operations"],"updatePoint":{"line":3561,"column":58,"index":112758},"line":3561,"code":"  it('shouldCorrectlyListAllAvailableDatabasesWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Use the admin database for the operation\n        const adminDb = db.admin();\n\n        // List all the available databases\n        return adminDb.listDatabases().then(function (dbs) {\n          expect(dbs.databases.length > 0).to.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveServerInfoWithPromises","suites":["Operations"],"updatePoint":{"line":3603,"column":51,"index":114070},"line":3603,"code":"  it('shouldCorrectlyRetrieveServerInfoWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Grab a collection object\n        const collection = db.collection('test_with_promise');\n\n        // Use the admin database for the operation\n        const adminDb = db.admin();\n\n        // Force the creation of the collection by inserting a document\n        // Collections are not created until the first document is inserted\n        return collection.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (doc) {\n          expect(doc).to.exist;\n          // Add the new user to the admin database\n          return adminDb.addUser('admin13', 'admin13');\n        }).then(function (result) {\n          expect(result).to.exist;\n          // Retrieve the server Info\n          return adminDb.serverStatus();\n        }).then(function (info) {\n          expect(info != null).to.exist;\n          return adminDb.removeUser('admin13');\n        }).then(function (result) {\n          expect(result).to.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteToArrayWithPromises","suites":["Operations"],"updatePoint":{"line":3672,"column":47,"index":116316},"line":3672,"code":"  it('shouldCorrectlyExecuteToArrayWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection to hold our documents\n        const collection = db.collection('test_array_with_promise');\n\n        // Insert a test document\n        return collection.insertOne({\n          b: [1, 2, 3]\n        }, configuration.writeConcernMax()).then(function (ids) {\n          expect(ids).to.exist;\n          // Retrieve all the documents in the collection\n          return collection.find().toArray();\n        }).then(function (documents) {\n          expect(documents.length).to.equal(1);\n          expect(documents[0].b).to.deep.equal([1, 2, 3]);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUseCursorCountFunctionWithPromises","suites":["Operations"],"updatePoint":{"line":3723,"column":55,"index":118101},"line":3723,"code":"  it('shouldCorrectlyUseCursorCountFunctionWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Creat collection\n        const collection = db.collection('cursor_count_collection_with_promise');\n\n        // Insert some docs\n        return collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }], configuration.writeConcernMax()).then(function (docs) {\n          expect(docs).to.exist;\n          // Do a find and get the cursor count\n          return collection.find().count();\n        }).then(function (count) {\n          expect(count).to.equal(2);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformNextOnCursorWithPromises","suites":["Operations"],"updatePoint":{"line":3775,"column":52,"index":119786},"line":3775,"code":"  it('shouldCorrectlyPerformNextOnCursorWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection\n        const collection = db.collection('simple_next_object_collection_with_promise');\n\n        // Insert some documents we can sort on\n        return collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax()).then(function (docs) {\n          expect(docs).to.exist;\n          // Do normal ascending sort\n          return collection.find().next();\n        }).then(function (item) {\n          expect(item.a).to.equal(1);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformSimpleExplainCursorWithPromises","suites":["Operations"],"updatePoint":{"line":3829,"column":59,"index":121550},"line":3829,"code":"  it('shouldCorrectlyPerformSimpleExplainCursorWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a collection\n        const collection = db.collection('simple_explain_collection_with_promise');\n\n        // Insert some documents we can sort on\n        return collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax()).then(function (docs) {\n          expect(docs).to.exist;\n          // Do normal ascending sort\n          return collection.find().explain();\n        }).then(function (explanation) {\n          expect(explanation).to.exist;\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"shouldStreamDocumentsUsingTheCloseFunctionWithPromises","suites":["Operations"],"updatePoint":{"line":3883,"column":60,"index":123319},"line":3883,"code":"  it('shouldStreamDocumentsUsingTheCloseFunctionWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        // Create a lot of documents to insert\n        const docs = [];\n        for (let i = 0; i < 100; i++) {\n          docs.push({\n            a: i\n          });\n        }\n\n        // Create a collection\n        const collection = db.collection('test_close_function_on_cursor_with_promise');\n\n        // Perform a find to get a cursor\n        const cursor = collection.find();\n\n        // Insert documents into collection\n        return collection.insertMany(docs, configuration.writeConcernMax()).then(function (ids) {\n          expect(ids).to.exist;\n          // Fetch the first object\n          return cursor.next();\n        }).then(function (object) {\n          expect(object).to.exist;\n          // Close the cursor, this is the same as reseting the query\n          return cursor.close();\n        }).then(function () {\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly connect to a replicaset With Promises","suites":["Operations"],"updatePoint":{"line":3950,"column":60,"index":125571},"line":3950,"code":"  it('Should correctly connect to a replicaset With Promises', {\n    metadata: {\n      requires: {\n        topology: 'replicaset'\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const url = f('mongodb://%s,%s/%s?replicaSet=%s&readPreference=%s', f('%s:%s', configuration.host, configuration.port), f('%s:%s', configuration.host, configuration.port + 1), 'integration_test_', configuration.replicasetName, 'primary');\n      const client = configuration.newClient(url);\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n        expect(db != null).to.exist;\n        return db.collection('replicaset_mongo_client_collection_with_promise').updateOne({\n          a: 1\n        }, {\n          $set: {\n            b: 1\n          }\n        }, {\n          upsert: true\n        }).then(function (result) {\n          expect(result).property('upsertedCount').to.equal(1);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"Should connect to mongos proxies using connectiong string With Promises","suites":["Operations"],"updatePoint":{"line":3994,"column":77,"index":127211},"line":3994,"code":"  it('Should connect to mongos proxies using connectiong string With Promises', {\n    metadata: {\n      requires: {\n        topology: 'sharded'\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const url = f('mongodb://%s:%s,%s:%s/sharded_test_db?w=1', configuration.host, configuration.port, configuration.host, configuration.port + 1);\n      const client = configuration.newClient(url);\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n        expect(db != null).to.exist;\n        return db.collection('replicaset_mongo_client_collection_with_promise').updateOne({\n          a: 1\n        }, {\n          $set: {\n            b: 1\n          }\n        }, {\n          upsert: true\n        }).then(function (result) {\n          expect(result.upsertedCount).to.equal(1);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly connect using MongoClient to a single server using connect With Promises","suites":["Operations"],"updatePoint":{"line":4038,"column":95,"index":128730},"line":4038,"code":"  it('Should correctly connect using MongoClient to a single server using connect With Promises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient();\n\n      // DOC_START\n      // Connect using the connection string\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n        return db.collection('mongoclient_test_with_promise').updateOne({\n          a: 1\n        }, {\n          $set: {\n            b: 1\n          }\n        }, {\n          upsert: true\n        }).then(function (result) {\n          expect(result).property('upsertedCount').to.equal(1);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly execute ordered batch with no errors using write commands With Promises","suites":["Operations"],"updatePoint":{"line":4092,"column":94,"index":130492},"line":4092,"code":"  it('Should correctly execute ordered batch with no errors using write commands With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        const col = db.collection('batch_write_ordered_ops_0_with_promise');\n        // Initialize the Ordered Batch\n        const batch = col.initializeOrderedBulkOp();\n        // Add some operations to be executed in order\n        batch.insert({\n          a: 1\n        });\n        batch.find({\n          a: 1\n        }).updateOne({\n          $set: {\n            b: 1\n          }\n        });\n        batch.find({\n          a: 2\n        }).upsert().updateOne({\n          $set: {\n            b: 2\n          }\n        });\n        batch.insert({\n          a: 3\n        });\n        batch.find({\n          a: 3\n        }).delete({\n          a: 3\n        });\n\n        // Execute the operations\n        return batch.execute().then(function (result) {\n          // Check state of result\n          expect(result.insertedCount).to.equal(2);\n          expect(result.upsertedCount).to.equal(1);\n          expect(result.matchedCount).to.equal(1);\n          expect(1 === result.modifiedCount || result.modifiedCount === 0 || result.modifiedCount == null).to.exist;\n          expect(result.deletedCount).to.equal(1);\n          const upserts = result.result.upserted;\n          expect(upserts.length).to.equal(1);\n          expect(upserts[0].index).to.equal(2);\n          expect(upserts[0]._id != null).to.exist;\n          const upsert = result.getUpsertedIdAt(0);\n          expect(upsert.index).to.equal(2);\n          expect(upsert._id != null).to.exist;\n\n          // Finish up test\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly execute unordered batch with no errors With Promises","suites":["Operations"],"updatePoint":{"line":4175,"column":75,"index":133106},"line":4175,"code":"  it('Should correctly execute unordered batch with no errors With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        const col = db.collection('batch_write_unordered_ops_legacy_0_with_promise');\n        // Initialize the unordered Batch\n        const batch = col.initializeUnorderedBulkOp();\n\n        // Add some operations to be executed in order\n        batch.insert({\n          a: 1\n        });\n        batch.find({\n          a: 1\n        }).updateOne({\n          $set: {\n            b: 1\n          }\n        });\n        batch.find({\n          a: 2\n        }).upsert().updateOne({\n          $set: {\n            b: 2\n          }\n        });\n        batch.insert({\n          a: 3\n        });\n        batch.find({\n          a: 3\n        }).delete({\n          a: 3\n        });\n\n        // Execute the operations\n        return batch.execute().then(function (result) {\n          // Check state of result\n          expect(result.insertedCount).to.equal(2);\n          expect(result.upsertedCount).to.equal(1);\n          expect(result.matchedCount).to.equal(1);\n          expect(1 === result.modifiedCount || result.modifiedCount === 0 || result.modifiedCount == null).to.exist;\n          expect(result.deletedCount).to.equal(1);\n          const upserts = result.result.upserted;\n          expect(upserts.length).to.equal(1);\n          expect(upserts[0].index).to.equal(2);\n          expect(upserts[0]._id != null).to.exist;\n          const upsert = result.getUpsertedIdAt(0);\n          expect(upsert.index).to.equal(2);\n          expect(upsert._id != null).to.exist;\n\n          // Finish up test\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly execute insertOne operation With Promises","suites":["Operations"],"updatePoint":{"line":4264,"column":64,"index":135850},"line":4264,"code":"  it('Should correctly execute insertOne operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        const col = db.collection('insert_one_with_promise');\n        return col.insertOne({\n          a: 1\n        }).then(function (r) {\n          expect(r).property('insertedId').to.exist;\n          // Finish up test\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly execute insertMany operation With Promises","suites":["Operations"],"updatePoint":{"line":4305,"column":65,"index":137151},"line":4305,"code":"  it('Should correctly execute insertMany operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        const col = db.collection('insert_many_with_promise');\n        return col.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }]).then(function (r) {\n          expect(r.insertedCount).to.equal(2);\n          // Finish up test\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly execute updateOne operation With Promises","suites":["Operations"],"updatePoint":{"line":4348,"column":64,"index":138475},"line":4348,"code":"  it('Should correctly execute updateOne operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        const col = db.collection('update_one_with_promise');\n        return col.updateOne({\n          a: 1\n        }, {\n          $set: {\n            a: 2\n          }\n        }, {\n          upsert: true\n        }).then(function (r) {\n          expect(r.matchedCount).to.equal(0);\n          expect(r.upsertedCount).to.equal(1);\n          // Finish up test\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly execute updateMany operation With Promises","suites":["Operations"],"updatePoint":{"line":4396,"column":65,"index":139912},"line":4396,"code":"  it('Should correctly execute updateMany operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        const col = db.collection('update_many_with_promise');\n        return col.insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }]).then(function (r) {\n          expect(r.insertedCount).to.equal(2);\n\n          // Update all documents\n          return col.updateMany({\n            a: 1\n          }, {\n            $set: {\n              b: 1\n            }\n          });\n        }).then(function (r) {\n          if (r.n) {\n            expect(r.n).to.equal(2);\n          } else {\n            expect(r.matchedCount).to.equal(2);\n            expect(r.modifiedCount).to.equal(2);\n          }\n\n          // Finish up test\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly execute deleteOne operation With Promises","suites":["Operations"],"updatePoint":{"line":4456,"column":64,"index":141622},"line":4456,"code":"  it('Should correctly execute deleteOne operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        const col = db.collection('remove_one_with_promise');\n        return col.insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }]).then(function (r) {\n          expect(r.insertedCount).to.equal(2);\n          return col.deleteOne({\n            a: 1\n          });\n        }).then(function (r) {\n          expect(r.deletedCount).to.equal(1);\n          // Finish up test\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly execute deleteMany operation With Promises","suites":["Operations"],"updatePoint":{"line":4504,"column":65,"index":143089},"line":4504,"code":"  it('Should correctly execute deleteMany operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        const col = db.collection('remove_many_with_promise');\n        return col.insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }]).then(function (r) {\n          expect(r.insertedCount).to.equal(2);\n\n          // Update all documents\n          return col.deleteMany({\n            a: 1\n          });\n        }).then(function (r) {\n          expect(r.deletedCount).to.equal(2);\n\n          // Finish up test\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly execute bulkWrite operation With Promises","suites":["Operations"],"updatePoint":{"line":4555,"column":64,"index":144591},"line":4555,"code":"  it('Should correctly execute bulkWrite operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        const col = db.collection('bulk_write_with_promise');\n        return col.bulkWrite([{\n          insertOne: {\n            document: {\n              a: 1\n            }\n          }\n        }, {\n          updateOne: {\n            filter: {\n              a: 2\n            },\n            update: {\n              $set: {\n                a: 2\n              }\n            },\n            upsert: true\n          }\n        }, {\n          updateMany: {\n            filter: {\n              a: 2\n            },\n            update: {\n              $set: {\n                a: 2\n              }\n            },\n            upsert: true\n          }\n        }, {\n          deleteOne: {\n            filter: {\n              c: 1\n            }\n          }\n        }, {\n          deleteMany: {\n            filter: {\n              c: 1\n            }\n          }\n        }, {\n          replaceOne: {\n            filter: {\n              c: 3\n            },\n            replacement: {\n              c: 4\n            },\n            upsert: true\n          }\n        }], {\n          ordered: true,\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (r) {\n          expect(r.insertedCount).to.equal(1);\n          expect(r.upsertedCount).to.equal(2);\n          expect(r.deletedCount).to.equal(0);\n          // Crud fields\n          expect(r.insertedCount).to.equal(1);\n          expect(Object.keys(r.insertedIds).length).to.equal(1);\n          expect(r.matchedCount).to.equal(1);\n          expect(r.modifiedCount === 0 || r.modifiedCount === 1).to.exist;\n          expect(r.deletedCount).to.equal(0);\n          expect(r.upsertedCount).to.equal(2);\n          expect(Object.keys(r.upsertedIds).length).to.equal(2);\n\n          // Ordered bulk operation\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly handle duplicate key error with bulkWrite","suites":["Operations"],"updatePoint":{"line":4659,"column":64,"index":147320},"line":4659,"code":"  it('Should correctly handle duplicate key error with bulkWrite', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // Get the collection\n        const col = db.collection('bulk_write_with_promise_write_error');\n        return col.bulkWrite([{\n          insertOne: {\n            document: {\n              _id: 1\n            }\n          }\n        }, {\n          insertOne: {\n            document: {\n              _id: 1\n            }\n          }\n        }], {\n          ordered: true,\n          writeConcern: {\n            w: 1\n          }\n        }).catch(function (err) {\n          expect(err.result.hasWriteErrors()).to.equal(true);\n          // Ordered bulk operation\n          return client.close();\n        });\n      });\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndDelete operation With Promises","suites":["Operations"],"updatePoint":{"line":4706,"column":71,"index":148546},"line":4706,"code":"  it('Should correctly execute findOneAndDelete operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        const col = db.collection('find_one_and_delete_with_promise');\n        return col.insertMany([{\n          a: 1,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (r) {\n          expect(r).property('insertedCount').to.equal(1);\n          return col.findOneAndDelete({\n            a: 1\n          }, {\n            projection: {\n              b: 1\n            },\n            sort: {\n              a: 1\n            }\n          });\n        }).then(function (r) {\n          expect(r.lastErrorObject.n).to.equal(1);\n          expect(r.value.b).to.equal(1);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndReplace operation With Promises","suites":["Operations"],"updatePoint":{"line":4764,"column":72,"index":150264},"line":4764,"code":"  it('Should correctly execute findOneAndReplace operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        const col = db.collection('find_one_and_replace_with_promise');\n        return col.insertMany([{\n          a: 1,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (r) {\n          expect(r).property('insertedCount').to.equal(1);\n          return col.findOneAndReplace({\n            a: 1\n          }, {\n            c: 1,\n            b: 1\n          }, {\n            projection: {\n              b: 1,\n              c: 1\n            },\n            sort: {\n              a: 1\n            },\n            returnDocument: ReturnDocument.AFTER,\n            upsert: true\n          }).then(function (r) {\n            expect(r.lastErrorObject.n).to.equal(1);\n            expect(r.value.b).to.equal(1);\n            expect(r.value.c).to.equal(1);\n            return client.close();\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndUpdate operation With Promises","suites":["Operations"],"updatePoint":{"line":4829,"column":71,"index":152178},"line":4829,"code":"  it('Should correctly execute findOneAndUpdate operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n        const col = db.collection('find_one_and_update_with_promise');\n        return col.insertMany([{\n          a: 1,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (r) {\n          expect(r).property('insertedCount').to.equal(1);\n          return col.findOneAndUpdate({\n            a: 1\n          }, {\n            $set: {\n              d: 1\n            }\n          }, {\n            projection: {\n              b: 1,\n              d: 1\n            },\n            sort: {\n              a: 1\n            },\n            returnDocument: ReturnDocument.AFTER,\n            upsert: true\n          });\n        }).then(function (r) {\n          expect(r.lastErrorObject.n).to.equal(1);\n          expect(r.value.b).to.equal(1);\n          expect(r.value.d).to.equal(1);\n          return client.close();\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly add capped collection options to cursor With Promises","suites":["Operations"],"updatePoint":{"line":4895,"column":76,"index":154110},"line":4895,"code":"  it('Should correctly add capped collection options to cursor With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a capped collection with a maximum of 1000 documents\n        let collection;\n        db.createCollection('a_simple_collection_2_with_promise', {\n          capped: true,\n          size: 100000,\n          max: 1000,\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (_collection) {\n          collection = _collection;\n          const docs = [];\n          for (let i = 0; i < 1000; i++) docs.push({\n            a: i\n          });\n\n          // Insert a document in the capped collection\n          return collection.insertMany(docs, configuration.writeConcernMax());\n        }).then(function (result) {\n          expect(result).to.exist;\n          let total = 0;\n\n          // Get the cursor\n          const cursor = collection.find({\n            a: {\n              $gte: 0\n            }\n          }).addCursorFlag('tailable', true).addCursorFlag('awaitData', true);\n          const stream = cursor.stream();\n          stream.on('data', function (d) {\n            expect(d).to.exist;\n            total = total + 1;\n            if (total === 1000) {\n              cursor.close();\n            }\n          });\n          cursor.on('close', function () {\n            // TODO: forced because the cursor is still open/active\n            client.close(true, done);\n          });\n        });\n      });\n      // END\n    }\n  });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"should be able to run transactions example 1","suites":["Operations","Transaction Examples"],"updatePoint":{"line":4970,"column":52,"index":156715},"line":4970,"code":"    it('should be able to run transactions example 1', {\n      metadata: {\n        requires: {\n          topology: ['replicaset'],\n          mongodb: '>=3.8.0'\n        }\n      },\n      test: function () {\n        const configuration = this.configuration;\n        const client = configuration.newClient(configuration.writeConcernMax());\n\n        // BEGIN\n        function updateEmployeeInfo(client) {\n          return client.withSession(session => {\n            function commit() {\n              return session.commitTransaction().catch(e => {\n                if (e.hasErrorLabel('UnknownTransactionCommitResult')) {\n                  // LINE console.log('Transaction aborted. Caught exception during transaction.');\n                  return commit();\n                }\n\n                // LINE console.log('Error during commit ...');\n                throw e;\n              });\n            }\n            const employeesCollection = client.db('hr').collection('employees');\n            const eventsCollection = client.db('reporting').collection('events');\n            session.startTransaction({\n              readConcern: {\n                level: 'snapshot'\n              },\n              writeConcern: {\n                w: 'majority'\n              }\n            });\n            return employeesCollection.updateOne({\n              employee: 3\n            }, {\n              $set: {\n                status: 'Inactive'\n              }\n            }, {\n              session\n            }).then(() => {\n              return eventsCollection.insertOne({\n                employee: 3,\n                status: {\n                  new: 'Inactive',\n                  old: 'Active'\n                }\n              }, {\n                session\n              });\n            }).catch(e => {\n              // LINE console.log('caugh exception during transaction, aborting')\n              return session.abortTransaction().then(() => Promise.reject(e));\n            }).then(() => commit()).then(() => {\n              // LINE console.log('Transaction committed');\n            });\n          });\n          // END\n        }\n\n        return client.connect().then(() => updateEmployeeInfo(client)).then(() => client.close());\n      }\n    });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"should be able to run transactions retry example 1","suites":["Operations","Transaction Examples"],"updatePoint":{"line":5039,"column":58,"index":159025},"line":5039,"code":"    it('should be able to run transactions retry example 1', {\n      metadata: {\n        requires: {\n          topology: ['replicaset'],\n          mongodb: '>=3.8.0'\n        }\n      },\n      test: function () {\n        // BEGIN\n        function runTransactionWithRetry(txnFunc, client, session) {\n          return txnFunc(client, session).catch(error => {\n            // LINE console.log('Transaction aborted. Caught exception during transaction.');\n\n            // If transient error, retry the whole transaction\n            if (error.hasErrorLabel('TransientTransactionError')) {\n              // LINE console.log('TransientTransactionError, retrying transaction ...');\n              return runTransactionWithRetry(txnFunc, client, session);\n            }\n            throw error;\n          });\n        }\n        // END\n\n        function updateEmployeeInfo(client, session) {\n          session.startTransaction({\n            readConcern: {\n              level: 'snapshot'\n            },\n            writeConcern: {\n              w: 'majority'\n            }\n          });\n          const employeesCollection = client.db('hr').collection('employees');\n          const eventsCollection = client.db('reporting').collection('events');\n          return employeesCollection.updateOne({\n            employee: 3\n          }, {\n            $set: {\n              status: 'Inactive'\n            }\n          }, {\n            session\n          }).then(() => {\n            return eventsCollection.insertOne({\n              employee: 3,\n              status: {\n                new: 'Inactive',\n                old: 'Active'\n              }\n            }, {\n              session\n            });\n          }).then(() => session.commitTransaction()).catch(e => {\n            return session.abortTransaction().then(() => Promise.reject(e));\n          });\n        }\n        const configuration = this.configuration;\n        const client = configuration.newClient(configuration.writeConcernMax());\n        return client.connect().then(() => client.withSession(session => runTransactionWithRetry(updateEmployeeInfo, client, session))).then(() => client.close());\n      }\n    });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"should be able to run transactions retry example 2","suites":["Operations","Transaction Examples"],"updatePoint":{"line":5104,"column":58,"index":161268},"line":5104,"code":"    it('should be able to run transactions retry example 2', {\n      metadata: {\n        requires: {\n          topology: ['replicaset'],\n          mongodb: '>=3.8.0'\n        }\n      },\n      test: function () {\n        // BEGIN\n        function commitWithRetry(session) {\n          return session.commitTransaction()\n          // LINE .then(() => console.log('Transaction committed.'))\n          .catch(error => {\n            if (error.hasErrorLabel('UnknownTransactionCommitResult')) {\n              // LINE console.log('UnknownTransactionCommitResult, retrying commit operation ...');\n              return commitWithRetry(session);\n            }\n            // LINE console.log('Error during commit ...');\n            throw error;\n          });\n        }\n        // END\n\n        function updateEmployeeInfo(client, session) {\n          session.startTransaction({\n            readConcern: {\n              level: 'snapshot'\n            },\n            writeConcern: {\n              w: 'majority'\n            }\n          });\n          const employeesCollection = client.db('hr').collection('employees');\n          const eventsCollection = client.db('reporting').collection('events');\n          return employeesCollection.updateOne({\n            employee: 3\n          }, {\n            $set: {\n              status: 'Inactive'\n            }\n          }, {\n            session\n          }).then(() => {\n            return eventsCollection.insertOne({\n              employee: 3,\n              status: {\n                new: 'Inactive',\n                old: 'Active'\n              }\n            }, {\n              session\n            });\n          }).then(() => commitWithRetry(session)).catch(e => {\n            return session.abortTransaction().then(() => Promise.reject(e));\n          });\n        }\n        const configuration = this.configuration;\n        const client = configuration.newClient(configuration.writeConcernMax());\n        return client.connect().then(() => client.withSession(session => updateEmployeeInfo(client, session))).then(() => client.close());\n      }\n    });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"should be able to run transactions retry example 3","suites":["Operations","Transaction Examples"],"updatePoint":{"line":5168,"column":58,"index":163432},"line":5168,"code":"    it('should be able to run transactions retry example 3', {\n      metadata: {\n        requires: {\n          topology: ['replicaset'],\n          mongodb: '>=3.8.0'\n        }\n      },\n      test: function () {\n        const configuration = this.configuration;\n        const client = configuration.newClient(configuration.writeConcernMax());\n\n        // BEGIN\n        function commitWithRetry(session) {\n          return session.commitTransaction()\n          // LINE .then(() => console.log('Transaction committed.'))\n          .catch(error => {\n            if (error.hasErrorLabel('UnknownTransactionCommitResult')) {\n              // LINE console.log('UnknownTransactionCommitResult, retrying commit operation ...');\n              return commitWithRetry(session);\n            }\n            // LINE console.log('Error during commit ...');\n            throw error;\n          });\n        }\n        function runTransactionWithRetry(txnFunc, client, session) {\n          return txnFunc(client, session).catch(error => {\n            // LINE console.log('Transaction aborted. Caught exception during transaction.');\n\n            // If transient error, retry the whole transaction\n            if (error.hasErrorLabel('TransientTransactionError')) {\n              // LINE console.log('TransientTransactionError, retrying transaction ...');\n              return runTransactionWithRetry(txnFunc, client, session);\n            }\n            throw error;\n          });\n        }\n        function updateEmployeeInfo(client, session) {\n          const employeesCollection = client.db('hr').collection('employees');\n          const eventsCollection = client.db('reporting').collection('events');\n          session.startTransaction({\n            readConcern: {\n              level: 'snapshot'\n            },\n            writeConcern: {\n              w: 'majority'\n            }\n          });\n          return employeesCollection.updateOne({\n            employee: 3\n          }, {\n            $set: {\n              status: 'Inactive'\n            }\n          }, {\n            session\n          }).then(() => {\n            return eventsCollection.insertOne({\n              employee: 3,\n              status: {\n                new: 'Inactive',\n                old: 'Active'\n              }\n            }, {\n              session\n            });\n          }).catch(e => {\n            // LINE console.log('caugh exception during transaction, aborting')\n            return session.abortTransaction().then(() => Promise.reject(e));\n          }).then(() => commitWithRetry(session));\n        }\n\n        // LINE const { MongoClient } = require('mongodb'),\n        // LINE const client = new MongoClient('myRepl/mongodb0.example.net:27017,mongodb1.example.net:27017,mongodb2.example.net:27017');\n        return client.connect().then(() => client.withSession(session => runTransactionWithRetry(updateEmployeeInfo, client, session))).then(() => client.close());\n        // END\n      }\n    });","file":"integration/node-specific/operation_examples.test.ts","skipped":false,"dir":"test"},{"name":"is within MB of starting amount","suites":["Driver Resources","on MongoClient.close()","ending memory usage"],"updatePoint":{"line":63,"column":63,"index":2598},"line":63,"code":"      it(`is within ${MB_PERMITTED_OFFSET}MB of starting amount`, async () => {\n        // Why check the lower bound? No reason, but it would be very surprising if we managed to free MB_PERMITTED_OFFSET MB of memory\n        // I expect us to **never** be below the lower bound, but I'd want to know if it happened\n        expect(endingMemoryUsed, `script started with ${startingMemoryUsed}MB heap but ended with ${endingMemoryUsed}MB heap used`).to.be.within(startingMemoryUsed - MB_PERMITTED_OFFSET, startingMemoryUsed + MB_PERMITTED_OFFSET);\n      });","file":"integration/node-specific/resource_clean_up.test.ts","skipped":false,"dir":"test"},{"name":"has 0 MongoClients in memory","suites":["Driver Resources","on MongoClient.close()","ending heap snapshot"],"updatePoint":{"line":70,"column":38,"index":3180},"line":70,"code":"      it('has 0 MongoClients in memory', async () => {\n        const clients = heap.nodes.filter(n => n.name === 'MongoClient' && n.type === 'object');\n        // lengthOf crashes chai b/c it tries to print out a gigantic diff\n        expect(clients.length, `expected no MongoClients in the heapsnapshot, found ${clients.length}`).to.equal(0);\n      });","file":"integration/node-specific/resource_clean_up.test.ts","skipped":false,"dir":"test"},{"name":"generated objectId returns inserted document when cloned via hex string","suites":["ObjectId"],"updatePoint":{"line":25,"column":77,"index":971},"line":25,"code":"  it('generated objectId returns inserted document when cloned via hex string', async function () {\n    const {\n      insertedId\n    } = await collection.insertOne({\n      name: 'toph'\n    });\n    expect(insertedId).to.have.property('_bsontype', 'ObjectId');\n    const found = await collection.findOne({\n      _id: new ObjectId(insertedId.toHexString())\n    });\n    expect(found).to.have.property('name', 'toph');\n    expect(found).to.have.property('_id');\n    expect(found?._id.toHexString()).to.equal(insertedId.toHexString());\n  });","file":"integration/objectid.test.ts","skipped":false,"dir":"test"},{"name":"ObjectId toString returns 24 character string","suites":["ObjectId"],"updatePoint":{"line":39,"column":51,"index":1481},"line":39,"code":"  it('ObjectId toString returns 24 character string', () => {\n    const objectId = new ObjectId();\n    expect(objectId.toString()).to.have.lengthOf(24);\n  });","file":"integration/objectid.test.ts","skipped":false,"dir":"test"},{"name":"ObjectId toJSON returns 24 character string","suites":["ObjectId"],"updatePoint":{"line":43,"column":49,"index":1638},"line":43,"code":"  it('ObjectId toJSON returns 24 character string', function () {\n    const objectId = new ObjectId();\n    expect(objectId.toJSON()).to.have.lengthOf(24);\n  });","file":"integration/objectid.test.ts","skipped":false,"dir":"test"},{"name":"Date can be used as a primary key _id","suites":["ObjectId"],"updatePoint":{"line":47,"column":43,"index":1793},"line":47,"code":"  it('Date can be used as a primary key _id', async function () {\n    // This has nothing to do with ObjectId\n    const configuration = this.configuration;\n    const client = configuration.newClient(configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    const db = client.db(configuration.db);\n    const collection = db.collection < {\n      _id: Date\n    } > 'test_non_oid_id';\n    const date = new Date();\n    date.setUTCDate(12);\n    date.setUTCFullYear(2009);\n    date.setUTCMonth(11 - 1);\n    date.setUTCHours(12);\n    date.setUTCMinutes(0);\n    date.setUTCSeconds(30);\n    await collection.insertOne({\n      _id: date\n    }, {\n      writeConcern: {\n        w: 1\n      }\n    });\n    const items = await collection.find({\n      _id: date\n    }).toArray();\n    expect('' + date).to.equal('' + items[0]._id);\n\n    // Let's close the db\n    await client.close();\n  });","file":"integration/objectid.test.ts","skipped":false,"dir":"test"},{"name":"getTimestamp should return date equal to input Date","suites":["ObjectId"],"updatePoint":{"line":79,"column":57,"index":2689},"line":79,"code":"  it('getTimestamp should return date equal to input Date', function () {\n    const date = new Date();\n    // ObjectId timestamp is only in seconds\n    date.setMilliseconds(0);\n    const epochSeconds = date.getTime() / 1000;\n    const oid = new ObjectId(epochSeconds);\n    const time = oid.getTimestamp();\n    expect(time).to.deep.equal(date);\n    expect(time.getTime() / 1000).to.deep.equal(epochSeconds);\n  });","file":"integration/objectid.test.ts","skipped":false,"dir":"test"},{"name":"range query based on objectId timestamp","suites":["ObjectId"],"updatePoint":{"line":89,"column":45,"index":3090},"line":89,"code":"  it('range query based on objectId timestamp', async () => {\n    const oid1 = new ObjectId();\n    await sleep(1000);\n    const oid2 = new ObjectId();\n    await sleep(1000);\n    const oid3 = new ObjectId();\n    const collection = client.db().collection < {\n      _id: ObjectId\n    } > 'oid_range';\n    await collection.drop().catch(() => null);\n\n    // Insertion intentionally out of order, we want to filter out 3 with a range query\n    await collection.insertMany([{\n      _id: oid1\n    }, {\n      _id: oid3\n    }, {\n      _id: oid2\n    }]);\n\n    // Greater than or equal to the time in oid1\n    const $gte = ObjectId.createFromTime(oid1.getTimestamp().getTime() / 1000);\n    // Strictly less than the time in oid3\n    const $lt = ObjectId.createFromTime(oid3.getTimestamp().getTime() / 1000);\n    const found = await collection.find({\n      _id: {\n        $gte,\n        $lt\n      }\n    }).toArray();\n    expect(found).to.have.lengthOf(2);\n    expect(found).to.have.deep.nested.property('[0]._id', oid1);\n    expect(found).to.have.deep.nested.property('[1]._id', oid2);\n  });","file":"integration/objectid.test.ts","skipped":false,"dir":"test"},{"name":"timestamp section of ObjectId should translate to Date","suites":["ObjectId"],"updatePoint":{"line":123,"column":60,"index":4183},"line":123,"code":"  it('timestamp section of ObjectId should translate to Date', async function () {\n    const client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    const db = client.db(this.configuration.db);\n    const collection = db.collection('shouldCorrectlyInsertWithObjectId');\n    await collection.insertMany([{}], {\n      writeConcern: {\n        w: 1\n      }\n    });\n    const firstCompareDate = new Date();\n    await sleep(200);\n    await collection.insertMany([{}], {\n      writeConcern: {\n        w: 1\n      }\n    });\n    const secondCompareDate = new Date();\n    const items = await collection.find().toArray();\n    // Date 1\n    const date1 = items[0]._id.getTimestamp();\n    // Date 2\n    const date2 = items[1]._id.getTimestamp();\n\n    // Compare\n    expect(firstCompareDate.getFullYear()).to.equal(date1.getFullYear());\n    expect(firstCompareDate.getDate()).to.equal(date1.getDate());\n    expect(firstCompareDate.getMonth()).to.equal(date1.getMonth());\n    expect(firstCompareDate.getHours()).to.equal(date1.getHours());\n    expect(secondCompareDate.getFullYear()).to.equal(date2.getFullYear());\n    expect(secondCompareDate.getDate()).to.equal(date2.getDate());\n    expect(secondCompareDate.getMonth()).to.equal(date2.getMonth());\n    expect(secondCompareDate.getHours()).to.equal(date2.getHours());\n\n    // Let's close the db\n    await client.close();\n  });","file":"integration/objectid.test.ts","skipped":false,"dir":"test"},{"name":"Should set majority readConcern aggregate command but ignore due to out","suites":["ReadConcern","client-url specific ReadConcern"],"updatePoint":{"line":276,"column":77,"index":8547},"line":276,"code":"  it('Should set majority readConcern aggregate command but ignore due to out', {\n    metadata: {\n      requires: {\n        topology: 'replicaset',\n        mongodb: '>= 3.2 < 4.1'\n      }\n    },\n    test: function (done) {\n      const started = [];\n      const succeeded = [];\n      // Get a new instance\n      const configuration = this.configuration;\n      client = configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1,\n        readConcern: {\n          level: 'majority'\n        },\n        monitorCommands: true\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        const db = client.db(configuration.db);\n        expect(db.readConcern).to.deep.equal({\n          level: 'majority'\n        });\n\n        // Get a collection\n        const collection = db.collection('readConcernCollectionAggregate1');\n        // Validate readConcern\n        expect(collection.readConcern).to.deep.equal({\n          level: 'majority'\n        });\n\n        // Listen to apm events\n        client.on('commandStarted', filterForCommands('aggregate', started));\n        client.on('commandSucceeded', filterForCommands('aggregate', succeeded));\n\n        // Execute find\n        collection.aggregate([{\n          $match: {}\n        }, {\n          $out: 'readConcernCollectionAggregate1Output'\n        }]).toArray(err => {\n          expect(err).to.not.exist;\n          validateTestResults(started, succeeded, 'aggregate');\n\n          // Execute find\n          collection.aggregate([{\n            $match: {}\n          }], {\n            out: 'readConcernCollectionAggregate2Output'\n          }).toArray(err => {\n            expect(err).to.not.exist;\n            validateTestResults(started, succeeded, 'aggregate');\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/read-write-concern/readconcern.test.js","skipped":false,"dir":"test"},{"name":"Should set majority readConcern aggregate command against server >= 4.1","suites":["ReadConcern","client-url specific ReadConcern"],"updatePoint":{"line":338,"column":77,"index":10361},"line":338,"code":"  it('Should set majority readConcern aggregate command against server >= 4.1', {\n    metadata: {\n      requires: {\n        topology: 'replicaset',\n        mongodb: '>= 4.1'\n      }\n    },\n    test: function (done) {\n      const started = [];\n      const succeeded = [];\n      // Get a new instance\n      const configuration = this.configuration;\n      client = configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1,\n        readConcern: {\n          level: 'majority'\n        },\n        monitorCommands: true\n      });\n      client.connect().then(() => {\n        // Get a collection\n        const collection = client.db(configuration.db).collection('readConcernCollectionAggregate1');\n\n        // Listen to apm events\n        client.on('commandStarted', filterForCommands('aggregate', started));\n        client.on('commandSucceeded', filterForCommands('aggregate', succeeded));\n\n        // Execute find\n        return collection.aggregate([{\n          $match: {}\n        }, {\n          $out: 'readConcernCollectionAggregate1Output'\n        }]).toArray().then(() => {\n          validateTestResults(started, succeeded, 'aggregate', 'majority');\n\n          // Execute find\n          return collection.aggregate([{\n            $match: {}\n          }], {\n            out: 'readConcernCollectionAggregate2Output'\n          }).toArray().then(() => {\n            validateTestResults(started, succeeded, 'aggregate', 'majority');\n          });\n        });\n      }).then(() => client.close(done), e => client.close(() => done(e)));\n    }\n  });","file":"integration/read-write-concern/readconcern.test.js","skipped":false,"dir":"test"},{"name":"Should set local readConcern on db level when using createCollection method","suites":["ReadConcern","client-url specific ReadConcern"],"updatePoint":{"line":387,"column":81,"index":11918},"line":387,"code":"  it('Should set local readConcern on db level when using createCollection method', {\n    metadata: {\n      requires: {\n        topology: 'replicaset',\n        mongodb: '>= 3.2'\n      }\n    },\n    test: function (done) {\n      // Get a new instance\n      const configuration = this.configuration;\n      client = configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1,\n        readConcern: {\n          level: 'local'\n        }\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        const db = client.db(configuration.db);\n        expect(db.readConcern).to.deep.equal({\n          level: 'local'\n        });\n\n        // Get a collection using createCollection\n        db.createCollection('readConcernCollection_createCollection', (err, collection) => {\n          expect(err).to.not.exist;\n\n          // Validate readConcern\n          expect(collection.readConcern).to.deep.equal({\n            level: 'local'\n          });\n          done();\n        });\n      });\n    }\n  });","file":"integration/read-write-concern/readconcern.test.js","skipped":false,"dir":"test"},{"name":"respects the writeConcern from uri","suites":["Write Concern","when the WriteConcern is set in the uri"],"updatePoint":{"line":15,"column":42,"index":711},"line":15,"code":"    it('respects the writeConcern from uri', async function () {\n      expect(client.writeConcern).to.deep.equal({\n        w: 0\n      });\n      const result = await client.db('test').collection('test').insertOne({\n        a: 1\n      });\n      expect(result).to.exist;\n      expect(events).to.be.an('array').with.lengthOf(1);\n      expect(events[0]).to.containSubset({\n        commandName: 'insert',\n        command: {\n          writeConcern: {\n            w: 0\n          }\n        }\n      });\n    });","file":"integration/read-write-concern/write_concern.test.ts","skipped":false,"dir":"test"},{"name":"should pipe writeConcern from client down to API call","suites":["Write Concern","mock server write concern test"],"updatePoint":{"line":42,"column":61,"index":1441},"line":42,"code":"    it('should pipe writeConcern from client down to API call', function () {\n      server.setMessageHandler(request => {\n        if (request.document && request.document[LEGACY_HELLO_COMMAND]) {\n          return request.reply(mock.HELLO);\n        }\n        if (request.document && request.document.endSessions) {\n          return request.reply({\n            ok: 1\n          });\n        }\n        expect(request.document.writeConcern).to.exist;\n        expect(request.document.writeConcern.w).to.equal('majority');\n        return request.reply({\n          ok: 1\n        });\n      });\n      const uri = `mongodb://${server.uri()}`;\n      const client = new MongoClient(uri, {\n        writeConcern: {\n          w: 'majority'\n        }\n      });\n      return client.connect().then(() => {\n        const db = client.db('wc_test');\n        const collection = db.collection('wc');\n        return collection.insertMany([{\n          a: 2\n        }]);\n      }).then(() => {\n        return client.close();\n      });\n    });","file":"integration/read-write-concern/write_concern.test.ts","skipped":false,"dir":"test"},{"name":"succeeds on find","suites":["Write Concern","when performing read operations","when writeConcern = 0","cursor creating operations with a getMore"],"updatePoint":{"line":102,"column":28,"index":3267},"line":102,"code":"        it('succeeds on find', async function () {\n          const findResult = col.find({}, {\n            batchSize: 2\n          });\n          const err = await findResult.toArray().catch(e => e);\n          expect(err).to.not.be.instanceOf(Error);\n        });","file":"integration/read-write-concern/write_concern.test.ts","skipped":false,"dir":"test"},{"name":"succeeds on listCollections","suites":["Write Concern","when performing read operations","when writeConcern = 0","cursor creating operations with a getMore"],"updatePoint":{"line":109,"column":39,"index":3539},"line":109,"code":"        it('succeeds on listCollections', async function () {\n          const collections = Array.from({\n            length: 10\n          }, (_, i) => `writeConcernTestCol${i + 1}`);\n          await Promise.allSettled(collections.map(colName => db.createCollection(colName).catch(() => null)));\n          const cols = db.listCollections({}, {\n            batchSize: 2\n          });\n          const err = await cols.toArray().catch(e => e);\n          expect(err).to.not.be.instanceOf(Error);\n        });","file":"integration/read-write-concern/write_concern.test.ts","skipped":false,"dir":"test"},{"name":"succeeds on aggregate","suites":["Write Concern","when performing read operations","when writeConcern = 0","cursor creating operations with a getMore"],"updatePoint":{"line":120,"column":33,"index":4036},"line":120,"code":"        it('succeeds on aggregate', async function () {\n          const aggResult = col.aggregate([{\n            $match: {\n              a: {\n                $gte: 0\n              }\n            }\n          }], {\n            batchSize: 2\n          });\n          const err = await aggResult.toArray().catch(e => e);\n          expect(err).to.not.be.instanceOf(Error);\n        });","file":"integration/read-write-concern/write_concern.test.ts","skipped":false,"dir":"test"},{"name":"succeeds on listIndexes","suites":["Write Concern","when performing read operations","when writeConcern = 0","cursor creating operations with a getMore"],"updatePoint":{"line":133,"column":35,"index":4415},"line":133,"code":"        it('succeeds on listIndexes', async function () {\n          await col.createIndex({\n            a: 1\n          });\n          await col.createIndex({\n            b: -1\n          });\n          await col.createIndex({\n            a: 1,\n            b: -1\n          });\n          const listIndexesResult = col.listIndexes({\n            batchSize: 2\n          });\n          const err = await listIndexesResult.toArray().catch(e => e);\n          expect(err).to.not.be.instanceOf(Error);\n        });","file":"integration/read-write-concern/write_concern.test.ts","skipped":false,"dir":"test"},{"name":"succeeds on changeStream","suites":["Write Concern","when performing read operations","when writeConcern = 0","cursor creating operations with a getMore"],"updatePoint":{"line":150,"column":36,"index":4916},"line":150,"code":"        it('succeeds on changeStream', {\n          metadata: {\n            requires: {\n              topology: 'replicaset'\n            }\n          },\n          async test() {\n            const changeStream = col.watch(undefined, {\n              batchSize: 2\n            });\n            const changes = on(changeStream, 'change');\n            await once(changeStream.cursor, 'init');\n            await col.insertMany([{\n              a: 10\n            }, {\n              a: 10\n            }, {\n              a: 10\n            }, {\n              a: 10\n            }, {\n              a: 10\n            }, {\n              a: 10\n            }, {\n              a: 10\n            }, {\n              a: 10\n            }, {\n              a: 10\n            }, {\n              a: 10\n            }, {\n              a: 10\n            }, {\n              a: 10\n            }], {\n              writeConcern: {\n                w: 'majority'\n              }\n            });\n            const err = await changes.next().catch(e => e);\n            expect(err).to.not.be.instanceOf(Error);\n          }\n        });","file":"integration/read-write-concern/write_concern.test.ts","skipped":false,"dir":"test"},{"name":"does not modify user input","suites":["RunCommand API"],"updatePoint":{"line":25,"column":32,"index":729},"line":25,"code":"  it('does not modify user input', {\n    requires: {\n      mongodb: '>=5.0'\n    }\n  }, async () => {\n    const command = Object.freeze({\n      ping: 1\n    });\n    // will throw if it tries to modify command\n    await db.command(command, {\n      readPreference: ReadPreference.nearest\n    });\n  });","file":"integration/run-command/run_command.test.ts","skipped":false,"dir":"test"},{"name":"does not support writeConcern in options","suites":["RunCommand API"],"updatePoint":{"line":38,"column":46,"index":1041},"line":38,"code":"  it('does not support writeConcern in options', {\n    requires: {\n      mongodb: '>=5.0'\n    }\n  }, async () => {\n    const command = Object.freeze({\n      insert: 'test',\n      documents: [{\n        x: 1\n      }]\n    });\n    await db.command(command, {\n      writeConcern: new WriteConcern('majority')\n    });\n    expect(commandsStarted).to.not.have.nested.property('[0].command.writeConcern');\n    expect(command).to.not.have.property('writeConcern');\n  });","file":"integration/run-command/run_command.test.ts","skipped":false,"dir":"test"},{"name":"does not support readConcern in options","suites":["RunCommand API"],"line":57,"code":"  it.skip('does not support readConcern in options', {","file":"integration/run-command/run_command.test.ts","skipped":true,"dir":"test"},{"name":"ensure monitors sleep for an appropriate amount of time between pings","suites":["Server Discovery and Monitoring Prose Tests","Monitors sleep at least minHeartbeatFrequencyMS between checks"],"updatePoint":{"line":67,"column":77,"index":2386},"line":67,"code":"    it('ensure monitors sleep for an appropriate amount of time between pings', {\n      metadata: {\n        requires: {\n          mongodb: '>=4.9.0',\n          topology: '!load-balanced'\n        }\n      },\n      test: async function () {\n        // 3.\n        const startTime = Date.now();\n        // 4.\n        await client.db().command({\n          ping: 1\n        });\n        // 5.\n        const timeTaken = Date.now() - startTime;\n        const secondsTaken = timeTaken / 1000;\n        expect(secondsTaken).to.be.within(2, 3.5);\n      }\n    });","file":"integration/server-discovery-and-monitoring/server_discovery_and_monitoring.prose.test.ts","skipped":false,"dir":"test"},{"name":"ensure monitors properly create and unpause connection pools when they discover servers","suites":["Server Discovery and Monitoring Prose Tests","Connection Pool Management"],"updatePoint":{"line":137,"column":95,"index":4939},"line":137,"code":"    it('ensure monitors properly create and unpause connection pools when they discover servers', {\n      metadata: {\n        requires: {\n          mongodb: '>=4.2.9',\n          topology: '!load-balanced'\n        }\n      },\n      test: async function () {\n        await client.connect();\n        expect(events.shift()).to.equal(SERVER_HEARTBEAT_SUCCEEDED);\n        expect(events.shift()).to.equal(CONNECTION_POOL_READY);\n        expect(events).to.be.empty;\n        const heartBeatFailedEvent = once(client, SERVER_HEARTBEAT_FAILED);\n        await client.db('admin').command({\n          configureFailPoint: 'failCommand',\n          mode: {\n            times: 2\n          },\n          data: {\n            failCommands: ['hello'],\n            errorCode: 1234,\n            appName: 'SDAMPoolManagementTest'\n          }\n        });\n        await heartBeatFailedEvent;\n        expect(events.shift()).to.equal(SERVER_HEARTBEAT_FAILED);\n        expect(events.shift()).to.equal(CONNECTION_POOL_CLEARED);\n        expect(events).to.be.empty;\n        await once(client, SERVER_HEARTBEAT_SUCCEEDED);\n        expect(events.shift()).to.equal(SERVER_HEARTBEAT_SUCCEEDED);\n        expect(events.shift()).to.equal(CONNECTION_POOL_READY);\n        expect(events).to.be.empty;\n      }\n    });","file":"integration/server-discovery-and-monitoring/server_discovery_and_monitoring.prose.test.ts","skipped":false,"dir":"test"},{"name":"is zero after a successful command","suites":["Server Operation Count Tests","load balanced mode with pinnable operations"],"updatePoint":{"line":58,"column":42,"index":1590},"line":58,"code":"    it('is zero after a successful command', loadBalancedTestMetadata, async function () {\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      const commandSpy = sinon.spy(server, 'command');\n      await collection.findOne({\n        count: 1\n      });\n      expect(commandSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"is zero after a command fails","suites":["Server Operation Count Tests","load balanced mode with pinnable operations"],"updatePoint":{"line":68,"column":37,"index":2017},"line":68,"code":"    it('is zero after a command fails', loadBalancedTestMetadata, async function () {\n      await client.db('admin').command(enableFailPointCommand);\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      const commandSpy = sinon.spy(server, 'command');\n      const error = await collection.findOne({\n        count: 1\n      }).catch(e => e);\n      expect(error).to.exist;\n      expect(commandSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"is zero after failing to check out a connection for a command","suites":["Server Operation Count Tests","load balanced mode with pinnable operations"],"updatePoint":{"line":80,"column":69,"index":2598},"line":80,"code":"    it('is zero after failing to check out a connection for a command', loadBalancedTestMetadata, async function () {\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      sinon.stub(ConnectionPool.prototype, 'checkOut').callsFake(function (cb) {\n        cb(new Error('unable to checkout connection'), undefined);\n      });\n      const commandSpy = sinon.spy(server, 'command');\n      const error = await collection.findOne({\n        count: 1\n      }).catch(e => e);\n      expect(error).to.exist;\n      expect(error).to.match(/unable to checkout connection/i);\n      expect(commandSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"is zero after a successful command","suites":["Server Operation Count Tests","operationCount is adjusted properly on successful operation"],"updatePoint":{"line":97,"column":42,"index":3403},"line":97,"code":"    it('is zero after a successful command', testMetadata, async function () {\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      const commandSpy = sinon.spy(server, 'command');\n      const operationPromises = Array.from({\n        length: 10\n      }, () => collection.insertOne({\n        count: 1\n      }));\n\n      // operation count is incremented after connection checkout, which happens asynchronously (even though there are plenty of connections in the pool).\n      // we sleep to give the event loop a turn so that all the commands check out a connection before asserting the operation count\n      await sleep(1);\n      expect(server.s.operationCount).to.equal(10);\n      await Promise.all(operationPromises);\n      expect(commandSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"is zero after a command fails","suites":["Server Operation Count Tests","operationCount is adjusted properly when operations fail"],"updatePoint":{"line":117,"column":37,"index":4385},"line":117,"code":"    it('is zero after a command fails', testMetadata, async function () {\n      await client.db('admin').command(enableFailPointCommand);\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      const commandSpy = sinon.spy(server, 'command');\n      const error = await collection.insertOne({\n        count: 1\n      }).catch(e => e);\n      expect(error).to.exist;\n      expect(commandSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"is zero after failing to check out a connection for a command","suites":["Server Operation Count Tests","operationCount is decremented when the server fails to checkout a connection"],"updatePoint":{"line":131,"column":69,"index":5066},"line":131,"code":"    it('is zero after failing to check out a connection for a command', testMetadata, async function () {\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      sinon.stub(ConnectionPool.prototype, 'checkOut').callsFake(function (cb) {\n        cb(new Error('unable to checkout connection'), undefined);\n      });\n      const commandSpy = sinon.spy(server, 'command');\n      const error = await collection.insertOne({\n        count: 1\n      }).catch(e => e);\n      expect(error).to.exist;\n      expect(error).to.match(/unable to checkout connection/i);\n      expect(commandSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly apply collection level read Preference to count","suites":["ReadPreference"],"updatePoint":{"line":29,"column":70,"index":661},"line":29,"code":"  it('Should correctly apply collection level read Preference to count', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        // Set read preference\n        var collection = db.collection('read_pref_1', {\n          readPreference: ReadPreference.SECONDARY_PREFERRED\n        });\n        // Save checkout function\n        var command = client.topology.command;\n        // Set up our checker method\n        client.topology.command = function () {\n          var args = Array.prototype.slice.call(arguments, 0);\n          if (args[0] === 'integration_tests.$cmd') {\n            test.equal(ReadPreference.SECONDARY_PREFERRED, args[2].readPreference.mode);\n          }\n          return command.apply(db.s.topology, args);\n        };\n\n        // Execute count\n        collection.count(function (err) {\n          expect(err).to.not.exist;\n          client.topology.command = command;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply collection level read Preference to aggregate","suites":["ReadPreference"],"updatePoint":{"line":68,"column":74,"index":1985},"line":68,"code":"  it('Should correctly apply collection level read Preference to aggregate', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        // Set read preference\n        var collection = db.collection('read_pref_1', {\n          readPreference: ReadPreference.SECONDARY_PREFERRED\n        });\n        // Save checkout function\n        var command = client.topology.command;\n        // Set up our checker method\n        client.topology.command = function () {\n          var args = Array.prototype.slice.call(arguments, 0);\n          if (args[0] === 'integration_tests.$cmd') {\n            test.equal(ReadPreference.SECONDARY_PREFERRED, args[2].readPreference.mode);\n          }\n          return command.apply(db.s.topology, args);\n        };\n        const cursor = collection.aggregate([{\n          $project: {\n            author: 1,\n            tags: 1\n          }\n        }, {\n          $unwind: '$tags'\n        }, {\n          $group: {\n            _id: {\n              tags: '$tags'\n            },\n            authors: {\n              $addToSet: '$author'\n            }\n          }\n        }]);\n        cursor.toArray(function (err) {\n          expect(err).to.not.exist;\n          client.topology.command = command;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply collection level read Preference to stats","suites":["ReadPreference"],"updatePoint":{"line":122,"column":70,"index":3633},"line":122,"code":"  it('Should correctly apply collection level read Preference to stats', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        // Set read preference\n        var collection = db.collection('read_pref_1', {\n          readPreference: ReadPreference.SECONDARY_PREFERRED\n        });\n        // Save checkout function\n        var command = client.topology.command;\n        // Set up our checker method\n        client.topology.command = function () {\n          var args = Array.prototype.slice.call(arguments, 0);\n          if (args[0] === 'integration_tests.$cmd') {\n            test.equal(ReadPreference.SECONDARY_PREFERRED, args[2].readPreference.mode);\n          }\n          return command.apply(db.s.topology, args);\n        };\n\n        // Perform the map reduce\n        collection.stats(function /* err */\n        () {\n          // expect(err).to.not.exist;\n          client.topology.command = command;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly honor the readPreferences at DB and individual command level","suites":["ReadPreference"],"updatePoint":{"line":162,"column":83,"index":4993},"line":162,"code":"  it('Should correctly honor the readPreferences at DB and individual command level', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        w: 1,\n        readPreference: 'secondary'\n      }, {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        // Save checkout function\n        var command = client.topology.command;\n        // Set up our checker method\n        client.topology.command = function () {\n          var args = Array.prototype.slice.call(arguments, 0);\n          if (args[0] === 'integration_tests.$cmd') {\n            test.equal(ReadPreference.SECONDARY, args[2].readPreference.mode);\n          }\n          return command.apply(db.s.topology, args);\n        };\n        db.command({\n          dbStats: true\n        }, function (err) {\n          expect(err).to.not.exist;\n          client.topology.command = function () {\n            var args = Array.prototype.slice.call(arguments, 0);\n            if (args[0] === 'integration_tests.$cmd') {\n              test.equal(ReadPreference.SECONDARY_PREFERRED, args[2].readPreference.mode);\n            }\n            return command.apply(db.s.topology, args);\n          };\n          db.command({\n            dbStats: true\n          }, {\n            readPreference: 'secondaryPreferred'\n          }, function (err) {\n            expect(err).to.not.exist;\n            client.topology.command = command;\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply readPreferences specified as objects","suites":["ReadPreference"],"updatePoint":{"line":213,"column":65,"index":6680},"line":213,"code":"  it('Should correctly apply readPreferences specified as objects', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        // Create read preference object.\n        var mySecondaryPreferred = {\n          mode: 'secondaryPreferred',\n          tags: []\n        };\n        db.command({\n          dbStats: true\n        }, {\n          readPreference: mySecondaryPreferred\n        }, function (err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly pass readPreferences specified as objects to cursors","suites":["ReadPreference"],"updatePoint":{"line":244,"column":75,"index":7564},"line":244,"code":"  it('Should correctly pass readPreferences specified as objects to cursors', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        // Create read preference object.\n        var mySecondaryPreferred = {\n          mode: 'secondaryPreferred',\n          tags: []\n        };\n        db.listCollections({}, {\n          readPreference: mySecondaryPreferred\n        }).toArray(function (err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly pass readPreferences specified as objects to collection methods","suites":["ReadPreference"],"updatePoint":{"line":273,"column":86,"index":8442},"line":273,"code":"  it('Should correctly pass readPreferences specified as objects to collection methods', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        // Create read preference object.\n        var mySecondaryPreferred = {\n          mode: 'secondaryPreferred',\n          tags: []\n        };\n        var cursor = db.collection('test').find({}, {\n          readPreference: mySecondaryPreferred\n        });\n        cursor.toArray(function (err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly pass readPreferences on the Collection to listIndexes","suites":["ReadPreference"],"updatePoint":{"line":303,"column":76,"index":9347},"line":303,"code":"  it('Should correctly pass readPreferences on the Collection to listIndexes', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        var cursor = db.collection('test', {\n          readPreference: ReadPreference.SECONDARY_PREFERRED\n        }).listIndexes();\n        test.equal(cursor.readPreference.mode, 'secondaryPreferred');\n        client.close(done);\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should throw an error on an invalid readPreference","suites":["ReadPreference"],"updatePoint":{"line":326,"column":56,"index":10084},"line":326,"code":"  it('Should throw an error on an invalid readPreference', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient();\n    client.connect((err, client) => {\n      const db = client.db(configuration.db);\n      expect(db.collection.bind(db, 'test', {\n        readPreference: 'invalid'\n      })).to.throw('Invalid read preference mode \"invalid\"');\n      client.close(done);\n    });\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"should set hedge using [find option & empty hedge]","suites":["ReadPreference","hedge"],"updatePoint":{"line":338,"column":58,"index":10554},"line":338,"code":"    it('should set hedge using [find option & empty hedge]', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.6.0'\n        }\n      },\n      test: function (done) {\n        const events = [];\n        client.on('commandStarted', event => {\n          if (event.commandName === 'find') {\n            events.push(event);\n          }\n        });\n        const rp = new ReadPreference(ReadPreference.SECONDARY, null, {\n          hedge: {}\n        });\n        client.db(this.configuration.db).collection('test').find({}, {\n          readPreference: rp\n        }).toArray(err => {\n          expect(err).to.not.exist;\n          const expected = {\n            mode: ReadPreference.SECONDARY,\n            hedge: {}\n          };\n          expect(events[0]).nested.property('command.$readPreference').to.deep.equal(expected);\n          done();\n        });\n      }\n    });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"should set hedge using [.withReadPreference & empty hedge] ","suites":["ReadPreference","hedge"],"updatePoint":{"line":367,"column":67,"index":11436},"line":367,"code":"    it('should set hedge using [.withReadPreference & empty hedge] ', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.6.0'\n        }\n      },\n      test: function (done) {\n        const events = [];\n        client.on('commandStarted', event => {\n          if (event.commandName === 'find') {\n            events.push(event);\n          }\n        });\n        const rp = new ReadPreference(ReadPreference.SECONDARY, null, {\n          hedge: {}\n        });\n        client.db(this.configuration.db).collection('test').find({}).withReadPreference(rp).toArray(err => {\n          expect(err).to.not.exist;\n          const expected = {\n            mode: ReadPreference.SECONDARY,\n            hedge: {}\n          };\n          expect(events[0]).nested.property('command.$readPreference').to.deep.equal(expected);\n          done();\n        });\n      }\n    });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"should set hedge using [.withReadPreference & enabled hedge] ","suites":["ReadPreference","hedge"],"updatePoint":{"line":394,"column":69,"index":12301},"line":394,"code":"    it('should set hedge using [.withReadPreference & enabled hedge] ', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.6.0'\n        }\n      },\n      test: function (done) {\n        const events = [];\n        client.on('commandStarted', event => {\n          if (event.commandName === 'find') {\n            events.push(event);\n          }\n        });\n        const rp = new ReadPreference(ReadPreference.SECONDARY, null, {\n          hedge: {\n            enabled: true\n          }\n        });\n        client.db(this.configuration.db).collection('test').find({}).withReadPreference(rp).toArray(err => {\n          expect(err).to.not.exist;\n          const expected = {\n            mode: ReadPreference.SECONDARY,\n            hedge: {\n              enabled: true\n            }\n          };\n          expect(events[0]).nested.property('command.$readPreference').to.deep.equal(expected);\n          done();\n        });\n      }\n    });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"should set hedge using [.withReadPreference & disabled hedge] ","suites":["ReadPreference","hedge"],"updatePoint":{"line":425,"column":70,"index":13245},"line":425,"code":"    it('should set hedge using [.withReadPreference & disabled hedge] ', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.6.0'\n        }\n      },\n      test: function (done) {\n        const events = [];\n        client.on('commandStarted', event => {\n          if (event.commandName === 'find') {\n            events.push(event);\n          }\n        });\n        const rp = new ReadPreference(ReadPreference.SECONDARY, null, {\n          hedge: {\n            enabled: false\n          }\n        });\n        client.db(this.configuration.db).collection('test').find({}).withReadPreference(rp).toArray(err => {\n          expect(err).to.not.exist;\n          const expected = {\n            mode: ReadPreference.SECONDARY,\n            hedge: {\n              enabled: false\n            }\n          };\n          expect(events[0]).nested.property('command.$readPreference').to.deep.equal(expected);\n          done();\n        });\n      }\n    });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"should set hedge using [.withReadPreference & undefined hedge] ","suites":["ReadPreference","hedge"],"updatePoint":{"line":456,"column":71,"index":14192},"line":456,"code":"    it('should set hedge using [.withReadPreference & undefined hedge] ', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.6.0'\n        }\n      },\n      test: function (done) {\n        const events = [];\n        client.on('commandStarted', event => {\n          if (event.commandName === 'find') {\n            events.push(event);\n          }\n        });\n        const rp = new ReadPreference(ReadPreference.SECONDARY, null);\n        client.db(this.configuration.db).collection('test').find({}).withReadPreference(rp).toArray(err => {\n          expect(err).to.not.exist;\n          const expected = {\n            mode: ReadPreference.SECONDARY\n          };\n          expect(events[0]).nested.property('command.$readPreference').to.deep.equal(expected);\n          done();\n        });\n      }\n    });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"","suites":["ReadPreference","should enforce fixed primary read preference"],"updatePoint":{"line":521,"column":22,"index":16379},"line":521,"code":"      it(`${operation}`, {\n        metadata: {\n          requires: {\n            topology: ['replicaset', 'sharded']\n          }\n        },\n        test: async function () {\n          const configuration = this.configuration;\n          const db = client.db(configuration.db);\n          const args = methods[operation];\n          const [parentId, method] = operation.split('#');\n          const collection = db.collection(collectionName);\n          const parent = parentId === 'Collection' ? collection : parentId === 'Db' ? db : null;\n          const selectServerSpy = this.sinon.spy(Topology.prototype, 'selectServer');\n          expect(parent).to.have.property(method).that.is.a('function');\n          await parent[method](...args);\n          expect(selectServerSpy.called).to.equal(true);\n          const selectionCall = selectServerSpy.getCall(0);\n          expect(selectionCall.args[0]).to.not.be.a('function');\n          expect(selectionCall).nested.property('args[0].mode').to.equal(ReadPreference.PRIMARY);\n        }\n      });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"should respect readPreference from uri","suites":["ReadPreference","should enforce fixed primary read preference"],"updatePoint":{"line":545,"column":44,"index":17448},"line":545,"code":"  it('should respect readPreference from uri', {\n    metadata: {\n      requires: {\n        topology: 'replicaset',\n        mongodb: '>=3.6'\n      }\n    },\n    test: async function () {\n      const client = this.configuration.newClient({\n        readPreference: 'secondary',\n        monitorCommands: true\n      });\n      const events = [];\n      client.on('commandStarted', event => {\n        if (event.commandName === 'find') {\n          events.push(event);\n        }\n      });\n      expect(client.readPreference.mode).to.equal('secondary');\n      await client.db('test').collection('test').findOne({\n        a: 1\n      });\n      expect(events).to.be.an('array').with.lengthOf(1);\n      expect(events[0]).to.containSubset({\n        commandName: 'find',\n        command: {\n          $readPreference: {\n            mode: 'secondary'\n          }\n        }\n      });\n      await client.close();\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"released server sessions are correctly reused","suites":["Sessions Prose Tests","14. Implicit sessions only allocate their server session after a successful connection checkout"],"updatePoint":{"line":32,"column":53,"index":1639},"line":32,"code":"    it('released server sessions are correctly reused', async () => {\n      const events = [];\n      client.on('commandStarted', ev => events.push(ev));\n      const operations = [testCollection.insertOne({\n        _id: 1\n      }), testCollection.deleteOne({\n        _id: 2\n      }), testCollection.updateOne({\n        _id: 3\n      }, {\n        $set: {\n          a: 1\n        }\n      }), testCollection.bulkWrite([{\n        updateOne: {\n          filter: {\n            _id: 4\n          },\n          update: {\n            $set: {\n              a: 1\n            }\n          }\n        }\n      }]), testCollection.findOneAndDelete({\n        _id: 5\n      }), testCollection.findOneAndUpdate({\n        _id: 6\n      }, {\n        $set: {\n          a: 1\n        }\n      }), testCollection.findOneAndReplace({\n        _id: 7\n      }, {\n        a: 8\n      }), testCollection.find().toArray()];\n      const allResults = await Promise.all(operations);\n      expect(allResults).to.have.lengthOf(operations.length);\n      expect(events).to.have.lengthOf(operations.length);\n\n      // This is a guarantee in node, unless you are performing a transaction (which is not being done in this test)\n      expect(new Set(events.map(ev => ev.command.lsid.id.toString('hex')))).to.have.lengthOf(2);\n    });","file":"integration/sessions/sessions.prose.test.ts","skipped":false,"dir":"test"},{"name":"18. Implicit session is ignored if connection does not support sessions","suites":["Sessions Prose Tests","When sessions are not supported"],"updatePoint":{"line":115,"column":79,"index":4401},"line":115,"code":"    it('18. Implicit session is ignored if connection does not support sessions', {\n      requires: {\n        clientSideEncryption: true,\n        mongodb: '>=4.2.0'\n      }\n    }, async function () {\n      /**\n       * 1. Send a read command to the server (e.g., `findOne`), ignoring any errors from the server response\n       * 2. Check the corresponding `commandStarted` event: verify that `lsid` is not set\n       */\n      const readCommandEventPromise = once(client, 'commandStarted').then(res => res[0]);\n      await client.db().collection('test').findOne({}).catch(() => null);\n      const readCommandEvent = await Promise.race([readCommandEventPromise, sleep(500)]);\n      expect(readCommandEvent).to.have.property('commandName', 'find');\n      expect(readCommandEvent).to.not.have.property('lsid');\n\n      /**\n       * 3. Send a write command to the server (e.g., `insertOne`), ignoring any errors from the server response\n       * 4. Check the corresponding `commandStarted` event: verify that `lsid` is not set\n       */\n      const writeCommandEventPromise = once(client, 'commandStarted').then(res => res[0]);\n      await client.db().collection('test').insertOne({}).catch(() => null);\n      const writeCommandEvent = await Promise.race([writeCommandEventPromise, sleep(500)]);\n      expect(writeCommandEvent).to.have.property('commandName', 'insert');\n      expect(writeCommandEvent).to.not.have.property('lsid');\n    });","file":"integration/sessions/sessions.prose.test.ts","skipped":false,"dir":"test"},{"name":"19. Explicit session raises an error if connection does not support sessions","suites":["Sessions Prose Tests","When sessions are not supported"],"updatePoint":{"line":141,"column":84,"index":5841},"line":141,"code":"    it('19. Explicit session raises an error if connection does not support sessions', {\n      requires: {\n        clientSideEncryption: true,\n        mongodb: '>=4.2.0'\n      }\n    }, async function () {\n      /**\n       * 1. Create a new explicit session by calling `startSession` (this MUST NOT error)\n       */\n      const session = client.startSession();\n\n      /**\n       * 2. Attempt to send a read command to the server (e.g., `findOne`) with the explicit session passed in\n       * 3. Assert that a client-side error is generated indicating that sessions are not supported\n       */\n      const readOutcome = await client.db().collection('test').findOne({}, {\n        session\n      }).catch(err => err);\n      expect(readOutcome).to.be.instanceOf(MongoDriverError);\n      expect(readOutcome.message).to.match(/does not support sessions/);\n\n      /**\n       * 4. Attempt to send a write command to the server (e.g., `insertOne`) with the explicit session passed in\n       * 5. Assert that a client-side error is generated indicating that sessions are not supported\n       */\n      const writeOutcome = await client.db().collection('test').insertOne({}, {\n        session\n      }).catch(err => err);\n      expect(writeOutcome).to.be.instanceOf(MongoDriverError);\n      expect(writeOutcome.message).to.match(/does not support sessions/);\n    });","file":"integration/sessions/sessions.prose.test.ts","skipped":false,"dir":"test"},{"name":"should send endSessions for multiple sessions","suites":["Sessions Spec","Sessions - functional - old format","endSessions"],"updatePoint":{"line":64,"column":55,"index":2012},"line":64,"code":"      it('should send endSessions for multiple sessions', function (done) {\n        const client = test.client;\n        const sessions = [client.startSession(), client.startSession()].map(s => s.id);\n        client.close(err => {\n          expect(err).to.not.exist;\n          expect(test.commands.started).to.have.length(1);\n          expect(test.commands.started[0].commandName).to.equal('endSessions');\n          expect(test.commands.started[0].command.endSessions).to.include.deep.members(sessions);\n          expect(client.s.activeSessions.size).to.equal(0);\n          done();\n        });\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"supports passing options to ClientSession","suites":["Sessions Spec","Sessions - functional - old format","withSession"],"updatePoint":{"line":153,"column":51,"index":5547},"line":153,"code":"      it('supports passing options to ClientSession', async function () {\n        let sessionWasEnded = false;\n        await client.withSession({\n          causalConsistency: false\n        }, async session => {\n          session.on('ended', () => {\n            sessionWasEnded = true;\n          });\n          expect(session.supports.causalConsistency).to.be.false;\n          await client.db('test').collection('foo').find({}, {\n            session\n          }).toArray();\n        });\n        expect(client.s.sessionPool.sessions).to.have.length(1);\n        expect(sessionWasEnded).to.be.true;\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should not include session for unacknowledged writes","suites":["Sessions Spec","Sessions - functional - old format","unacknowledged writes"],"updatePoint":{"line":171,"column":62,"index":6214},"line":171,"code":"      it('should not include session for unacknowledged writes', async function () {\n        const events = [];\n        client.on('commandStarted', event => {\n          if (event.commandName === 'insert') {\n            events.push(event);\n          }\n        });\n        await client.db('test').collection('foo').insertOne({\n          foo: 'bar'\n        }, {\n          writeConcern: {\n            w: 0\n          }\n        });\n        const event = events[0];\n        expect(event).nested.property('command.writeConcern.w').to.equal(0);\n        expect(event).to.not.have.nested.property('command.lsid');\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should throw error with explicit session","suites":["Sessions Spec","Sessions - functional - old format","unacknowledged writes"],"updatePoint":{"line":189,"column":50,"index":6815},"line":189,"code":"      it('should throw error with explicit session', {\n        metadata: {\n          requires: {\n            topology: 'replicaset',\n            mongodb: '>=3.6.0'\n          }\n        },\n        test: async function () {\n          const events = [];\n          client.on('commandStarted', event => {\n            if (event.commandName === 'insert') {\n              events.push(event);\n            }\n          });\n          const session = client.startSession({\n            causalConsistency: true\n          });\n          const error = await client.db('test').collection('foo').insertOne({\n            foo: 'bar'\n          }, {\n            writeConcern: {\n              w: 0\n            },\n            session\n          }).catch(error => error);\n          expect(error.message).to.equal('Cannot have explicit session with unacknowledged writes');\n          await session.endSession();\n        }\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should result in a usable session when called with a valid cluster time and should not affect any other sessions","suites":["Sessions Spec","Sessions - functional - new format","advanceClusterTime()"],"updatePoint":{"line":269,"column":122,"index":9686},"line":269,"code":"      it('should result in a usable session when called with a valid cluster time and should not affect any other sessions', {\n        metadata: {\n          requires: {\n            mongodb: '>= 3.6.0',\n            topology: ['replicaset']\n          }\n        },\n        async test() {\n          // advance cluster time to a new valid value\n          testSession.advanceClusterTime(otherSession.clusterTime);\n          expect(testSession.clusterTime).to.deep.equal(otherSession.clusterTime);\n\n          // check control session\n          expect(controlSession.clusterTime).to.not.deep.equal(testSession.clusterTime);\n\n          // check that the session still works\n          expect(await collection.findOne({}, {\n            session: testSession\n          })).property('apple').to.equal('green');\n        }\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should not let an invalid cluster time impact existing sessions","suites":["Sessions Spec","Sessions - functional - new format","advanceClusterTime()"],"updatePoint":{"line":290,"column":73,"index":10454},"line":290,"code":"      it('should not let an invalid cluster time impact existing sessions', {\n        metadata: {\n          requires: {\n            mongodb: '>= 3.6.0',\n            topology: ['replicaset']\n          }\n        },\n        async test() {\n          // note, because of our validation, we can't use advanceClusterTime to set an invalid clusterTime\n          // so for testing, we have to set it directly\n          testSession.clusterTime = {\n            clusterTime: {\n              greaterThan: () => true\n            }\n          };\n          try {\n            await collection.findOne({}, {\n              session: testSession\n            });\n            expect.fail('expected findOne to fail, but it passed');\n          } catch (err) {\n            expect(err).to.be.instanceOf(MongoServerError);\n          }\n          expect(await collection.findOne({}, {\n            session: controlSession\n          })).property('apple').to.equal('green');\n        }\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should not let an invalid cluster time impact new sessions","suites":["Sessions Spec","Sessions - functional - new format","advanceClusterTime()"],"updatePoint":{"line":318,"column":68,"index":11410},"line":318,"code":"      it('should not let an invalid cluster time impact new sessions', {\n        metadata: {\n          requires: {\n            mongodb: '>= 3.6.0',\n            topology: ['replicaset']\n          }\n        },\n        async test() {\n          // note, because of our validation, we can't use advanceClusterTime to set an invalid clusterTime\n          // so for testing, we have to set it directly\n          testSession.clusterTime = {\n            clusterTime: {\n              greaterThan: () => true\n            }\n          };\n          try {\n            await collection.findOne({}, {\n              session: testSession\n            });\n            expect.fail('expected findOne to fail, but it passed');\n          } catch (err) {\n            expect(err).to.be.instanceOf(MongoServerError);\n          }\n          await otherSession.endSession();\n          otherSession = client.startSession();\n          expect(await collection.findOne({}, {\n            session: otherSession\n          })).property('apple').to.equal('green');\n        }\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should not let an invalid cluster time impact other uses of the client","suites":["Sessions Spec","Sessions - functional - new format","advanceClusterTime()"],"updatePoint":{"line":348,"column":80,"index":12467},"line":348,"code":"      it('should not let an invalid cluster time impact other uses of the client', {\n        metadata: {\n          requires: {\n            mongodb: '>= 3.6.0',\n            topology: ['replicaset']\n          }\n        },\n        async test() {\n          // note, because of our validation, we can't use advanceClusterTime to set an invalid clusterTime\n          // so for testing, we have to set it directly\n          testSession.clusterTime = {\n            clusterTime: {\n              greaterThan: () => true\n            }\n          };\n          try {\n            await collection.findOne({}, {\n              session: testSession\n            });\n            expect.fail('expected findOne to fail, but it passed');\n          } catch (err) {\n            expect(err).to.be.instanceOf(MongoServerError);\n          }\n          expect(await collection.findOne({})).property('apple').to.equal('green');\n        }\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should only use two sessions for many operations when maxPoolSize is 1","suites":["Sessions Spec","Session allocation"],"updatePoint":{"line":402,"column":78,"index":14251},"line":402,"code":"    it('should only use two sessions for many operations when maxPoolSize is 1', async () => {\n      const documents = Array.from({\n        length: 50\n      }).map((_, idx) => ({\n        _id: idx\n      }));\n      const events = [];\n      client.on('commandStarted', ev => events.push(ev));\n      const allResults = await Promise.all(documents.map(doc => testCollection.insertOne(doc)));\n      expect(allResults).to.have.lengthOf(documents.length);\n      expect(events).to.have.lengthOf(documents.length);\n      expect(new Set(events.map(ev => ev.command.lsid.id.toString('hex'))).size).to.equal(2);\n    });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should provide a useful error if a Promise is not returned","suites":["Transactions","withTransaction"],"updatePoint":{"line":16,"column":66,"index":628},"line":16,"code":"    it('should provide a useful error if a Promise is not returned', {\n      requires: {\n        topology: ['replicaset', 'sharded'],\n        mongodb: '>=4.1.5',\n        serverless: 'forbid'\n      }\n    }, async function () {\n      function fnThatDoesNotReturnPromise() {\n        return false;\n      }\n      const result = await session\n      // @ts-expect-error: testing a function that does not return a promise\n      .withTransaction(fnThatDoesNotReturnPromise).catch(error => error);\n      expect(result).to.be.instanceOf(MongoInvalidArgumentError);\n      expect(result.message).to.match(/must return a Promise/);\n      await session.endSession();\n    });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should return readable error if promise rejected with no reason","suites":["Transactions","withTransaction"],"updatePoint":{"line":33,"column":71,"index":1293},"line":33,"code":"    it('should return readable error if promise rejected with no reason', {\n      metadata: {\n        requires: {\n          topology: ['replicaset', 'sharded'],\n          mongodb: '>=4.2.0',\n          serverless: 'forbid'\n        }\n      },\n      test: function (done) {\n        function fnThatReturnsBadPromise() {\n          return Promise.reject();\n        }\n        session.withTransaction(fnThatReturnsBadPromise).then(() => done(Error('Expected error'))).catch(err => {\n          expect(err).to.equal(undefined);\n          session.endSession(done);\n        });\n      }\n    });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should return undefined when transaction is aborted explicitly","suites":["Transactions","withTransaction","return value semantics"],"updatePoint":{"line":68,"column":72,"index":2404},"line":68,"code":"      it('should return undefined when transaction is aborted explicitly', async () => {\n        const session = client.startSession();\n        const withTransactionResult = await session.withTransaction(async session => {\n          await collection.insertOne({\n            a: 1\n          }, {\n            session\n          });\n          await collection.findOne({\n            a: 1\n          }, {\n            session\n          });\n          await session.abortTransaction();\n        }).finally(async () => await session.endSession());\n        expect(withTransactionResult).to.be.undefined;\n      });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should return raw command when transaction is successfully committed","suites":["Transactions","withTransaction","return value semantics"],"updatePoint":{"line":85,"column":78,"index":3010},"line":85,"code":"      it('should return raw command when transaction is successfully committed', async () => {\n        const session = client.startSession();\n        const withTransactionResult = await session.withTransaction(async session => {\n          await collection.insertOne({\n            a: 1\n          }, {\n            session\n          });\n          await collection.findOne({\n            a: 1\n          }, {\n            session\n          });\n        }).finally(async () => await session.endSession());\n        expect(withTransactionResult).to.exist;\n        expect(withTransactionResult).to.be.an('object');\n        expect(withTransactionResult).to.have.property('ok', 1);\n      });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should throw when transaction is aborted due to an error","suites":["Transactions","withTransaction","return value semantics"],"updatePoint":{"line":103,"column":66,"index":3676},"line":103,"code":"      it('should throw when transaction is aborted due to an error', async () => {\n        const session = client.startSession();\n        const withTransactionResult = await session.withTransaction(async session => {\n          await collection.insertOne({\n            a: 1\n          }, {\n            session\n          });\n          await collection.findOne({\n            a: 1\n          }, {\n            session\n          });\n          throw new Error(\"I don't wanna transact anymore!\");\n        }).catch(error => error).finally(async () => await session.endSession());\n        expect(withTransactionResult).to.be.instanceOf(Error);\n        expect(withTransactionResult.message).to.equal(\"I don't wanna transact anymore!\");\n      });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should error if transactions are not supported","suites":["Transactions","startTransaction"],"updatePoint":{"line":124,"column":54,"index":4456},"line":124,"code":"    it('should error if transactions are not supported', {\n      metadata: {\n        requires: {\n          topology: ['sharded'],\n          mongodb: '4.0.x'\n        }\n      },\n      test: function (done) {\n        const configuration = this.configuration;\n        const client = configuration.newClient(configuration.url());\n        client.connect((err, client) => {\n          const session = client.startSession();\n          const db = client.db(configuration.db);\n          const coll = db.collection('transaction_error_test');\n          coll.insertOne({\n            a: 1\n          }, err => {\n            expect(err).to.not.exist;\n            expect(() => session.startTransaction()).to.throw('Transactions are not supported on sharded clusters in MongoDB < 4.2.');\n            session.endSession(() => {\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should not error if transactions are supported","suites":["Transactions","startTransaction"],"updatePoint":{"line":150,"column":54,"index":5356},"line":150,"code":"    it('should not error if transactions are supported', {\n      metadata: {\n        requires: {\n          topology: ['sharded'],\n          mongodb: '>=4.1.0'\n        }\n      },\n      test: function (done) {\n        const configuration = this.configuration;\n        const client = configuration.newClient(configuration.url());\n        client.connect(err => {\n          expect(err).to.not.exist;\n          const session = client.startSession();\n          const db = client.db(configuration.db);\n          const coll = db.collection('transaction_error_test');\n          coll.insertOne({\n            a: 1\n          }, err => {\n            expect(err).to.not.exist;\n            expect(() => session.startTransaction()).to.not.throw();\n            session.abortTransaction(() => session.endSession(() => client.close(done)));\n          });\n        });\n      }\n    });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should have a TransientTransactionError label inside of a transaction","suites":["Transactions","TransientTransactionError"],"updatePoint":{"line":177,"column":77,"index":6302},"line":177,"code":"    it('should have a TransientTransactionError label inside of a transaction', {\n      metadata: {\n        requires: {\n          topology: 'replicaset',\n          mongodb: '>=4.0.0'\n        }\n      },\n      test: function (done) {\n        const configuration = this.configuration;\n        const client = configuration.newClient({\n          w: 1\n        });\n        client.connect(err => {\n          expect(err).to.not.exist;\n          const session = client.startSession();\n          const db = client.db(configuration.db);\n          db.collection('transaction_error_test_2').drop(() => {\n            db.createCollection('transaction_error_test_2', (err, coll) => {\n              expect(err).to.not.exist;\n              session.startTransaction();\n              coll.insertOne({\n                a: 1\n              }, {\n                session\n              }, err => {\n                expect(err).to.not.exist;\n                expect(session.inTransaction()).to.be.true;\n                client.db('admin').command({\n                  configureFailPoint: 'failCommand',\n                  mode: {\n                    times: 1\n                  },\n                  data: {\n                    failCommands: ['insert'],\n                    closeConnection: true\n                  }\n                }, err => {\n                  expect(err).to.not.exist;\n                  expect(session.inTransaction()).to.be.true;\n                  coll.insertOne({\n                    b: 2\n                  }, {\n                    session\n                  }, err => {\n                    expect(err).to.exist.and.to.be.an.instanceof(MongoNetworkError);\n                    if (err instanceof MongoNetworkError) {\n                      expect(err.hasErrorLabel('TransientTransactionError')).to.be.true;\n                    }\n                    session.abortTransaction(() => session.endSession(() => client.close(done)));\n                  });\n                });\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should not have a TransientTransactionError label outside of a transaction","suites":["Transactions","TransientTransactionError"],"updatePoint":{"line":234,"column":82,"index":8334},"line":234,"code":"    it('should not have a TransientTransactionError label outside of a transaction', {\n      metadata: {\n        requires: {\n          topology: 'replicaset',\n          mongodb: '>=4.0.0'\n        }\n      },\n      test: function (done) {\n        const configuration = this.configuration;\n        const client = configuration.newClient({\n          w: 1\n        });\n        client.connect(err => {\n          expect(err).to.not.exist;\n          const db = client.db(configuration.db);\n          const coll = db.collection('transaction_error_test1');\n          client.db('admin').command({\n            configureFailPoint: 'failCommand',\n            mode: {\n              times: 2\n            },\n            data: {\n              failCommands: ['insert'],\n              closeConnection: true\n            }\n          }, err => {\n            expect(err).to.not.exist;\n            coll.insertOne({\n              a: 1\n            }, err => {\n              expect(err).to.exist.and.to.be.an.instanceOf(MongoNetworkError);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should correctly allow for w:0 overriding on the connect url","suites":["URI"],"updatePoint":{"line":11,"column":66,"index":231},"line":11,"code":"  it('should correctly allow for w:0 overriding on the connect url', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      const authInformation = process.env.AUTH === 'auth' ? 'bob:pwd123@' : '';\n      // Connect using the connection string\n      const client = this.configuration.newClient(`mongodb://${authInformation}localhost:27017/?w=0`);\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(self.configuration.db);\n        db.collection('mongoclient_test').update({\n          a: 1\n        }, {\n          $set: {\n            b: 1\n          }\n        }, {\n          upsert: true\n        }, function (err, result) {\n          expect(err).to.not.exist;\n          expect(result).to.exist;\n          expect(result).property('acknowledged').to.be.false;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/uri-options/uri.test.js","skipped":false,"dir":"test"},{"name":"should correctly connect via domain socket","suites":["URI"],"updatePoint":{"line":44,"column":48,"index":1297},"line":44,"code":"  it('should correctly connect via domain socket', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      if (process.platform === 'win32') {\n        return done();\n      }\n      const client = this.configuration.newClient('mongodb://%2Ftmp%2Fmongodb-27017.sock');\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        client.close(done);\n      });\n    }\n  });","file":"integration/uri-options/uri.test.js","skipped":false,"dir":"test"},{"name":"should correctly connect via normal url using ip","suites":["URI"],"updatePoint":{"line":63,"column":54,"index":1886},"line":63,"code":"  it('should correctly connect via normal url using ip', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      const client = this.configuration.newClient('mongodb://127.0.0.1:27017/?fsync=true');\n      client.connect((err, client) => {\n        var db = client.db(this.configuration.db);\n        expect(db.writeConcern.fsync).to.be.true;\n        client.close(done);\n      });\n    }\n  });","file":"integration/uri-options/uri.test.js","skipped":false,"dir":"test"},{"name":"should correctly connect using uri encoded username and password","suites":["URI"],"updatePoint":{"line":80,"column":70,"index":2479},"line":80,"code":"  it('should correctly connect using uri encoded username and password', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      const configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var user = 'u$ser',\n          pass = '$specialch@rs';\n        var db = client.db(self.configuration.db);\n        db.addUser(user, pass, function (err) {\n          expect(err).to.not.exist;\n          var uri = 'mongodb://' + encodeURIComponent(user) + ':' + encodeURIComponent(pass) + '@localhost:27017/integration_tests';\n          configuration.newClient(uri).connect(function (err, c) {\n            expect(err).to.not.exist;\n            c.close(() => client.close(done));\n          });\n        });\n      });\n    }\n  });","file":"integration/uri-options/uri.test.js","skipped":false,"dir":"test"},{"name":"should correctly translate uri options","suites":["URI"],"updatePoint":{"line":108,"column":44,"index":3492},"line":108,"code":"  it('should correctly translate uri options', {\n    metadata: {\n      requires: {\n        topology: 'replicaset'\n      }\n    },\n    test: function (done) {\n      const config = this.configuration;\n      const uri = `mongodb://${config.host}:${config.port}/${config.db}?replicaSet=${config.replicasetName}`;\n      const client = this.configuration.newClient(uri);\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        expect(client).to.exist;\n        expect(client.options.replicaSet).to.exist.and.equal(config.replicasetName);\n        client.close(done);\n      });\n    }\n  });","file":"integration/uri-options/uri.test.js","skipped":false,"dir":"test"},{"name":"should generate valid credentials with X509","suites":["URI"],"updatePoint":{"line":126,"column":49,"index":4103},"line":126,"code":"  it('should generate valid credentials with X509', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      function validateConnect(options) {\n        expect(options).to.have.property('credentials');\n        expect(options.credentials.mechanism).to.eql('MONGODB-X509');\n        connectStub.restore();\n        done();\n      }\n      const topologyPrototype = Topology.prototype;\n      const connectStub = sinon.stub(topologyPrototype, 'connect').callsFake(validateConnect);\n      const uri = 'mongodb://some-hostname/test?ssl=true&authMechanism=MONGODB-X509&replicaSet=rs0';\n      const client = this.configuration.newClient(uri);\n      client.connect();\n    }\n  });","file":"integration/uri-options/uri.test.js","skipped":false,"dir":"test"},{"name":"","suites":["Atlas Connectivity"],"updatePoint":{"line":34,"column":19,"index":1134},"line":34,"code":"        it(`${name}`, makeConnectionTest(connectionString));","file":"manual/atlas_connectivity.test.js","skipped":false,"dir":"test"},{"name":"should authenticate with original uri","suites":["Kerberos"],"updatePoint":{"line":46,"column":43,"index":1602},"line":46,"code":"  it('should authenticate with original uri', async function () {\n    client = new MongoClient(krb5Uri);\n    await client.connect();\n    await verifyKerberosAuthentication(client);\n  });","file":"manual/kerberos.test.ts","skipped":false,"dir":"test"},{"name":"authenticates with a forward cname lookup","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is forward"],"updatePoint":{"line":59,"column":51,"index":2133},"line":59,"code":"      it('authenticates with a forward cname lookup', async function () {\n        client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:mongodb,CANONICALIZE_HOST_NAME:forward&maxPoolSize=1`);\n        await client.connect();\n        expect(dns.resolveCname).to.be.calledOnceWith(host);\n        await verifyKerberosAuthentication(client);\n      });","file":"manual/kerberos.test.ts","skipped":false,"dir":"test"},{"name":"authenticates with no dns lookups","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is "],"updatePoint":{"line":68,"column":45,"index":2605},"line":68,"code":"        it('authenticates with no dns lookups', async function () {\n          client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:mongodb,CANONICALIZE_HOST_NAME:${option}&maxPoolSize=1`);\n          await client.connect();\n          expect(dns.resolveCname).to.not.be.called;\n          // There are 2 calls to establish connection, however they use the callback form of dns.lookup\n          expect(dns.lookup).to.not.be.called;\n          await verifyKerberosAuthentication(client);\n        });","file":"manual/kerberos.test.ts","skipped":false,"dir":"test"},{"name":"authenticates with a forward dns lookup and a reverse ptr lookup","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is ","when the reverse lookup succeeds"],"updatePoint":{"line":85,"column":78,"index":3496},"line":85,"code":"          it('authenticates with a forward dns lookup and a reverse ptr lookup', async function () {\n            client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:mongodb,CANONICALIZE_HOST_NAME:${option}&maxPoolSize=1`);\n            await client.connect();\n            // There are 2 calls to establish connection, however they use the callback form of dns.lookup\n            // 1 dns.promises.lookup call in canonicalization.\n            expect(dns.lookup).to.be.calledOnce;\n            expect(dns.resolvePtr).to.be.calledOnce;\n            await verifyKerberosAuthentication(client);\n          });","file":"manual/kerberos.test.ts","skipped":false,"dir":"test"},{"name":"authenticates with a fallback cname lookup","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is ","when the reverse lookup is empty"],"updatePoint":{"line":100,"column":56,"index":4317},"line":100,"code":"          it('authenticates with a fallback cname lookup', async function () {\n            client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:mongodb,CANONICALIZE_HOST_NAME:${option}&maxPoolSize=1`);\n            await client.connect();\n            // There are 2 calls to establish connection, however they use the callback form of dns.lookup\n            // 1 dns.promises.lookup call in canonicalization.\n            expect(dns.lookup).to.be.calledOnce;\n            // This fails.\n            expect(dns.resolvePtr).to.be.calledOnce;\n            // Expect the fallback to the host name.\n            expect(dns.resolveCname).to.not.be.called;\n            await verifyKerberosAuthentication(client);\n          });","file":"manual/kerberos.test.ts","skipped":false,"dir":"test"},{"name":"authenticates with a fallback cname lookup","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is ","when the reverse lookup fails"],"updatePoint":{"line":118,"column":56,"index":5289},"line":118,"code":"          it('authenticates with a fallback cname lookup', async function () {\n            client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:mongodb,CANONICALIZE_HOST_NAME:${option}&maxPoolSize=1`);\n            await client.connect();\n            // There are 2 calls to establish connection, however they use the callback form of dns.lookup\n            // 1 dns.promises.lookup call in canonicalization.\n            expect(dns.lookup).to.be.calledOnce;\n            // This fails.\n            expect(dns.resolvePtr).to.be.calledOnce;\n            // Expect the fallback to be called.\n            expect(dns.resolveCname).to.be.calledOnceWith(host);\n            await verifyKerberosAuthentication(client);\n          });","file":"manual/kerberos.test.ts","skipped":false,"dir":"test"},{"name":"authenticates with a fallback host name","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is ","when the cname lookup fails"],"updatePoint":{"line":136,"column":53,"index":6266},"line":136,"code":"          it('authenticates with a fallback host name', async function () {\n            client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:mongodb,CANONICALIZE_HOST_NAME:${option}&maxPoolSize=1`);\n            await client.connect();\n            // There are 2 calls to establish connection, however they use the callback form of dns.lookup\n            // 1 dns.promises.lookup call in canonicalization.\n            expect(dns.lookup).to.be.calledOnce;\n            // This fails.\n            expect(dns.resolvePtr).to.be.calledOnce;\n            // Expect the fallback to be called.\n            expect(dns.resolveCname).to.be.calledOnceWith(host);\n            await verifyKerberosAuthentication(client);\n          });","file":"manual/kerberos.test.ts","skipped":false,"dir":"test"},{"name":"authenticates with a fallback host name","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is ","when the cname lookup is empty"],"updatePoint":{"line":154,"column":53,"index":7227},"line":154,"code":"          it('authenticates with a fallback host name', async function () {\n            client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:mongodb,CANONICALIZE_HOST_NAME:${option}&maxPoolSize=1`);\n            await client.connect();\n            // There are 2 calls to establish connection, however they use the callback form of dns.lookup\n            // 1 dns.promises.lookup call in canonicalization.\n            expect(dns.lookup).to.be.calledOnce;\n            // This fails.\n            expect(dns.resolvePtr).to.be.calledOnce;\n            // Expect the fallback to be called.\n            expect(dns.resolveCname).to.be.calledOnceWith(host);\n            await verifyKerberosAuthentication(client);\n          });","file":"manual/kerberos.test.ts","skipped":false,"dir":"test"},{"name":"validate that SERVICE_REALM and CANONICALIZE_HOST_NAME can be passed in","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is ","when the cname lookup is empty"],"line":170,"code":"  it.skip('validate that SERVICE_REALM and CANONICALIZE_HOST_NAME can be passed in', async function () {","file":"manual/kerberos.test.ts","skipped":true,"dir":"test"},{"name":"fails to authenticate","suites":["Kerberos","when passing SERVICE_HOST as an auth mech option","when the SERVICE_HOST is invalid"],"updatePoint":{"line":177,"column":31,"index":8539},"line":177,"code":"      it('fails to authenticate', async function () {\n        client = new MongoClient(`${krb5Uri}&maxPoolSize=1`, {\n          authMechanismProperties: {\n            SERVICE_HOST: 'example.com'\n          }\n        });\n        const expectedError = await client.connect().catch(e => e);\n        if (!expectedError) {\n          expect.fail('Expected connect with invalid SERVICE_HOST to fail');\n        }\n        expect(expectedError.message).to.match(/GSS failure|UNKNOWN_SERVER/);\n      });","file":"manual/kerberos.test.ts","skipped":false,"dir":"test"},{"name":"authenticates","suites":["Kerberos","when passing SERVICE_HOST as an auth mech option","when the SERVICE_HOST is valid"],"updatePoint":{"line":191,"column":23,"index":9090},"line":191,"code":"      it('authenticates', async function () {\n        client = new MongoClient(`${krb5Uri}&maxPoolSize=1`, {\n          authMechanismProperties: {\n            SERVICE_HOST: 'ldaptest.10gen.cc'\n          }\n        });\n        await client.connect();\n        await verifyKerberosAuthentication(client);\n      });","file":"manual/kerberos.test.ts","skipped":false,"dir":"test"},{"name":"as an option handed to the MongoClient","suites":["Kerberos","should use the SERVICE_NAME property"],"updatePoint":{"line":203,"column":46,"index":9502},"line":203,"code":"    it('as an option handed to the MongoClient', async function () {\n      client = new MongoClient(`${krb5Uri}&maxPoolSize=1`, {\n        authMechanismProperties: {\n          SERVICE_NAME: 'alternate'\n        }\n      });\n      const err = await client.connect().catch(e => e);\n      expect(err.message).to.match(/(Error from KDC: LOOKING_UP_SERVER)|(not found in Kerberos database)|(UNKNOWN_SERVER)/);\n    });","file":"manual/kerberos.test.ts","skipped":false,"dir":"test"},{"name":"as part of the query string parameters","suites":["Kerberos","should use the SERVICE_NAME property"],"updatePoint":{"line":212,"column":46,"index":9912},"line":212,"code":"    it('as part of the query string parameters', async function () {\n      client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:alternate&maxPoolSize=1`);\n      const err = await client.connect().catch(e => e);\n      expect(err.message).to.match(/(Error from KDC: LOOKING_UP_SERVER)|(not found in Kerberos database)|(UNKNOWN_SERVER)/);\n    });","file":"manual/kerberos.test.ts","skipped":false,"dir":"test"},{"name":"should fail to authenticate with bad credentials","suites":["Kerberos","should use the SERVICE_NAME property"],"updatePoint":{"line":218,"column":54,"index":10291},"line":218,"code":"  it('should fail to authenticate with bad credentials', async function () {\n    client = new MongoClient(krb5Uri.replace(encodeURIComponent(process.env.KRB5_PRINCIPAL), 'bad%40creds.cc'));\n    const err = await client.connect().catch(e => e);\n    expect(err.message).to.match(/Authentication failed/);\n  });","file":"manual/kerberos.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly authenticate against ldap","suites":["LDAP"],"updatePoint":{"line":13,"column":48,"index":319},"line":13,"code":"  it('Should correctly authenticate against ldap', function (done) {\n    const client = new MongoClient(process.env.MONGODB_URI);\n    client.connect(function (err, client) {\n      expect(err).to.not.exist;\n      client.db('ldap').collection('test').findOne(function (err, doc) {\n        expect(err).to.not.exist;\n        expect(doc).property('ldap').to.equal(true);\n        client.close(done);\n      });\n    });\n  });","file":"manual/ldap.test.js","skipped":false,"dir":"test"},{"name":"contains AWS_WEB_IDENTITY_TOKEN_FILE","suites":["MONGODB-OIDC","when running in the environment"],"updatePoint":{"line":9,"column":44,"index":571},"line":9,"code":"    it('contains AWS_WEB_IDENTITY_TOKEN_FILE', function () {\n      expect(process.env).to.have.property('AWS_WEB_IDENTITY_TOKEN_FILE');\n    });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"successfully authenticates","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","1. Callback-Driven Auth","1.1 Single Principal Implicit Username"],"updatePoint":{"line":88,"column":38,"index":3529},"line":88,"code":"        it('successfully authenticates', async function () {\n          const result = await collection.findOne();\n          expect(result).to.be.null;\n        });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"successfully authenticates","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","1. Callback-Driven Auth","1.2 Single Principal Explicit Username"],"updatePoint":{"line":108,"column":38,"index":4417},"line":108,"code":"        it('successfully authenticates', async function () {\n          const result = await collection.findOne();\n          expect(result).to.be.null;\n        });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"successfully authenticates","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","1. Callback-Driven Auth","1.3 Multiple Principal User 1"],"updatePoint":{"line":128,"column":38,"index":5424},"line":128,"code":"        it('successfully authenticates', async function () {\n          const result = await collection.findOne();\n          expect(result).to.be.null;\n        });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"successfully authenticates","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","1. Callback-Driven Auth","1.4 Multiple Principal User 2"],"updatePoint":{"line":148,"column":38,"index":6466},"line":148,"code":"        it('successfully authenticates', async function () {\n          const result = await collection.findOne();\n          expect(result).to.be.null;\n        });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"fails authentication","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","1. Callback-Driven Auth","1.5  Multiple Principal No User"],"updatePoint":{"line":167,"column":32,"index":7378},"line":167,"code":"        it('fails authentication', async function () {\n          try {\n            await collection.findOne();\n            expect.fail('Expected OIDC auth to fail with no user provided');\n          } catch (e) {\n            expect(e).to.be.instanceOf(MongoServerError);\n            expect(e.message).to.include('Authentication failed');\n          }\n        });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"fails validation","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","1. Callback-Driven Auth","1.6 Allowed Hosts Blocked","when ALLOWED_HOSTS is empty"],"updatePoint":{"line":197,"column":30,"index":8586},"line":197,"code":"          it('fails validation', async function () {\n            const error = await collection.findOne().catch(error => error);\n            expect(error).to.be.instanceOf(MongoInvalidArgumentError);\n            expect(error.message).to.include('is not valid for OIDC authentication with ALLOWED_HOSTS');\n          });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"fails validation","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","1. Callback-Driven Auth","1.6 Allowed Hosts Blocked","when ALLOWED_HOSTS does not match"],"updatePoint":{"line":224,"column":30,"index":9926},"line":224,"code":"          it('fails validation', async function () {\n            // try {\n            //   await collection.findOne();\n            // } catch (error) {\n            //   expect(error).to.be.instanceOf(MongoInvalidArgumentError);\n            //   expect(error.message).to.include('Host does not match provided ALLOWED_HOSTS values');\n            // }\n          });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"fails validation","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","1. Callback-Driven Auth","1.6 Allowed Hosts Blocked","when ALLOWED_HOSTS is invalid"],"updatePoint":{"line":248,"column":30,"index":11040},"line":248,"code":"          it('fails validation', async function () {\n            const error = await collection.findOne().catch(error => error);\n            expect(error).to.be.instanceOf(MongoInvalidArgumentError);\n            expect(error.message).to.include('is not valid for OIDC authentication with ALLOWED_HOSTS');\n          });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"does not simultaneously enter a callback","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","1. Callback-Driven Auth","1.7 Lock Avoids Extra Callback Calls"],"updatePoint":{"line":307,"column":52,"index":13542},"line":307,"code":"        it('does not simultaneously enter a callback', async function () {\n          await Promise.all([testPromise(), testPromise()]);\n          // The request callback will get called twice, but will not be entered\n          // simultaneously. If it does, the function will throw and we'll have\n          // and exception here.\n          expect(requestSpy).to.have.been.calledTwice;\n          expect(refreshSpy).to.have.been.calledTwice;\n        });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"successfully authenticates","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","2. AWS Automatic Auth","2.1 Single Principal"],"updatePoint":{"line":332,"column":38,"index":14673},"line":332,"code":"        it('successfully authenticates', async function () {\n          const result = await collection.findOne();\n          expect(result).to.be.null;\n        });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"successfully authenticates","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","2. AWS Automatic Auth","2.2 Multiple Principal User 1"],"updatePoint":{"line":346,"column":38,"index":15485},"line":346,"code":"        it('successfully authenticates', async function () {\n          const result = await collection.findOne();\n          expect(result).to.be.null;\n        });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"successfully authenticates","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","2. AWS Automatic Auth","2.3 Multiple Principal User 2"],"updatePoint":{"line":368,"column":38,"index":16829},"line":368,"code":"        it('successfully authenticates', async function () {\n          const result = await collection.findOne();\n          expect(result).to.be.null;\n        });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"successfully authenticates","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","2. AWS Automatic Auth","2.4 Allowed Hosts Ignored"],"updatePoint":{"line":386,"column":38,"index":17656},"line":386,"code":"        it('successfully authenticates', async function () {\n          const result = await collection.findOne();\n          expect(result).to.be.null;\n        });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"successfully authenticates with the request and refresh callbacks","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","3. Callback Validation","3.1 Valid Callbacks"],"updatePoint":{"line":422,"column":77,"index":19477},"line":422,"code":"        it('successfully authenticates with the request and refresh callbacks', async function () {\n          client = new MongoClient('mongodb://localhost/?authMechanism=MONGODB-OIDC', {\n            authMechanismProperties: authMechanismProperties\n          });\n          collection = client.db('test').collection('test');\n          await collection.findOne();\n          expect(refreshSpy).to.have.been.calledOnce;\n        });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"fails authentication","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","3. Callback Validation","3.2 Request Callback Returns Null"],"updatePoint":{"line":448,"column":32,"index":20502},"line":448,"code":"        it('fails authentication', async function () {\n          try {\n            await collection.findOne();\n            expect.fail('Expected OIDC auth to fail with null return from request callback');\n          } catch (e) {\n            expect(e).to.be.instanceOf(MongoMissingCredentialsError);\n            expect(e.message).to.include('User provided OIDC callbacks must return a valid object with an accessToken');\n          }\n        });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"fails authentication on refresh","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","3. Callback Validation","3.3 Refresh Callback Returns Null"],"updatePoint":{"line":480,"column":43,"index":21914},"line":480,"code":"        it('fails authentication on refresh', async function () {\n          client = new MongoClient('mongodb://localhost/?authMechanism=MONGODB-OIDC', {\n            authMechanismProperties: authMechanismProperties\n          });\n          try {\n            await client.db('test').collection('test').findOne();\n            expect.fail('Expected OIDC auth to fail with invlid return from refresh callback');\n          } catch (e) {\n            expect(e).to.be.instanceOf(MongoMissingCredentialsError);\n            expect(e.message).to.include('User provided OIDC callbacks must return a valid object with an accessToken');\n          }\n        });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"fails authentication","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","3. Callback Validation","3.4 Request Callback Returns Invalid Data","when the request callback has missing fields"],"updatePoint":{"line":511,"column":34,"index":23374},"line":511,"code":"          it('fails authentication', async function () {\n            try {\n              await collection.findOne();\n              expect.fail('Expected OIDC auth to fail with invlid return from request callback');\n            } catch (e) {\n              expect(e).to.be.instanceOf(MongoMissingCredentialsError);\n              expect(e.message).to.include('User provided OIDC callbacks must return a valid object with an accessToken');\n            }\n          });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"fails authentication","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","3. Callback Validation","3.4 Request Callback Returns Invalid Data","when the request callback has extra fields"],"updatePoint":{"line":537,"column":34,"index":24573},"line":537,"code":"          it('fails authentication', async function () {\n            try {\n              await collection.findOne();\n              expect.fail('Expected OIDC auth to fail with extra fields from request callback');\n            } catch (e) {\n              expect(e).to.be.instanceOf(MongoMissingCredentialsError);\n              expect(e.message).to.include('User provided OIDC callbacks must return a valid object with an accessToken');\n            }\n          });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"fails authentication on the refresh","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","3. Callback Validation","3.5 Refresh Callback Returns Missing Data"],"updatePoint":{"line":572,"column":47,"index":26188},"line":572,"code":"        it('fails authentication on the refresh', async function () {\n          client = new MongoClient('mongodb://localhost/?authMechanism=MONGODB-OIDC', {\n            authMechanismProperties: authMechanismProperties\n          });\n          try {\n            await client.db('test').collection('test').findOne();\n            expect.fail('Expected OIDC auth to fail with missing data from refresh callback');\n          } catch (e) {\n            expect(e).to.be.instanceOf(MongoMissingCredentialsError);\n            expect(e.message).to.include('User provided OIDC callbacks must return a valid object with an accessToken');\n          }\n        });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"fails authentication on the refresh","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","3. Callback Validation","3.6 Refresh Callback Returns Extra Data"],"updatePoint":{"line":609,"column":47,"index":27978},"line":609,"code":"        it('fails authentication on the refresh', async function () {\n          client = new MongoClient('mongodb://localhost/?authMechanism=MONGODB-OIDC', {\n            authMechanismProperties: authMechanismProperties\n          });\n          try {\n            await client.db('test').collection('test').findOne();\n            expect.fail('Expected OIDC auth to fail with extra fields from refresh callback');\n          } catch (e) {\n            expect(e).to.be.instanceOf(MongoMissingCredentialsError);\n            expect(e.message).to.include('User provided OIDC callbacks must return a valid object with an accessToken');\n          }\n        });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"successfully authenticates and calls the refresh callback","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","4. Cached Credentials","4.1 Cache with refresh"],"updatePoint":{"line":651,"column":69,"index":29953},"line":651,"code":"        it('successfully authenticates and calls the refresh callback', async function () {\n          // Ensure credentials added to the cache.\n          client = new MongoClient('mongodb://localhost/?authMechanism=MONGODB-OIDC', {\n            authMechanismProperties: authMechanismProperties\n          });\n          await client.db('test').collection('test').findOne();\n          expect(refreshSpy).to.have.been.calledOnce;\n        });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"successfully authenticates and calls only the request callback","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","4. Cached Credentials","4.2 Cache with no refresh"],"updatePoint":{"line":680,"column":74,"index":31344},"line":680,"code":"        it('successfully authenticates and calls only the request callback', async function () {\n          expect(cache.entries.size).to.equal(1);\n          client = new MongoClient('mongodb://localhost/?authMechanism=MONGODB-OIDC', {\n            authMechanismProperties: {\n              REQUEST_TOKEN_CALLBACK: requestSpy\n            }\n          });\n          await client.db('test').collection('test').findOne();\n          expect(requestSpy).to.have.been.calledTwice;\n        });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"replaces expired entries in the cache","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","4. Cached Credentials","4.3 Cache key includes callback"],"updatePoint":{"line":712,"column":49,"index":32832},"line":712,"code":"        it('replaces expired entries in the cache', async function () {\n          expect(cache.entries.size).to.equal(1);\n          const initialKey = cache.entries.keys().next().value;\n          client = new MongoClient('mongodb://localhost/?authMechanism=MONGODB-OIDC', {\n            authMechanismProperties: {\n              REQUEST_TOKEN_CALLBACK: secondRequestCallback\n            }\n          });\n          await client.db('test').collection('test').findOne();\n          expect(cache.entries.size).to.equal(1);\n          const newKey = cache.entries.keys().next().value;\n          expect(newKey).to.not.equal(initialKey);\n        });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"clears the cache on authentication error","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","4. Cached Credentials","4.4 Error clears cache"],"updatePoint":{"line":749,"column":52,"index":34569},"line":749,"code":"        it('clears the cache on authentication error', async function () {\n          client = new MongoClient('mongodb://localhost/?authMechanism=MONGODB-OIDC', {\n            authMechanismProperties: authMechanismProperties\n          });\n          try {\n            await client.db('test').collection('test').findOne();\n            expect.fail('Expected OIDC auth to fail with invalid fields from refresh callback');\n          } catch (error) {\n            expect(error).to.be.instanceOf(MongoMissingCredentialsError);\n            expect(error.message).to.include('');\n            expect(cache.entries.size).to.equal(0);\n          }\n        });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"authenticates with no cache usage","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","4. Cached Credentials","4.5 AWS Automatic workflow does not use cache"],"updatePoint":{"line":774,"column":45,"index":35757},"line":774,"code":"        it('authenticates with no cache usage', async function () {\n          await collection.findOne();\n          expect(cache.entries.size).to.equal(0);\n        });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"successfully speculative authenticates","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","5. Speculative Authentication"],"updatePoint":{"line":849,"column":48,"index":38144},"line":849,"code":"      it('successfully speculative authenticates', async function () {\n        client = new MongoClient('mongodb://localhost/?authMechanism=MONGODB-OIDC', {\n          authMechanismProperties: authMechanismProperties\n        });\n        await setupFailPoint();\n        const result = await client.db('test').collection('test').findOne();\n        expect(result).to.be.null;\n      });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"successfully reauthenticates","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","6. Reauthentication","6.1 Succeeds"],"updatePoint":{"line":957,"column":40,"index":42478},"line":957,"code":"        it('successfully reauthenticates', async function () {\n          client = new MongoClient('mongodb://localhost/?authMechanism=MONGODB-OIDC', {\n            authMechanismProperties: authMechanismProperties,\n            monitorCommands: true\n          });\n          addListeners();\n          await setupFailPoint();\n          await client.db('test').collection('test').findOne();\n          expect(refreshSpy).to.have.been.calledOnce;\n          expect(commandStartedEvents.map(event => event.commandName)).to.deep.equal(['find', 'find']);\n          expect(commandSucceededEvents.map(event => event.commandName)).to.deep.equal(['find']);\n          expect(commandFailedEvents.map(event => event.commandName)).to.deep.equal(['find']);\n        });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"successfully authenticates","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","6. Reauthentication","6.2 Retries and Succeeds with Cache"],"updatePoint":{"line":1024,"column":38,"index":45116},"line":1024,"code":"        it('successfully authenticates', async function () {\n          const result = await client.db('test').collection('test').findOne();\n          expect(result).to.be.null;\n        });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"fails authentication","suites":["MONGODB-OIDC","OIDC Auth Spec Prose Tests","6. Reauthentication","6.3 Retries and Fails with no Cache"],"updatePoint":{"line":1084,"column":32,"index":47271},"line":1084,"code":"        it('fails authentication', async function () {\n          try {\n            await client.db('test').collection('test').findOne();\n            expect.fail('Reauthentication must fail on the saslStart error');\n          } catch (error) {\n            // This is the saslStart failCommand bubbled up.\n            expect(error).to.be.instanceOf(MongoServerError);\n          }\n        });","file":"manual/mongodb_oidc.prose.test.ts","skipped":false,"dir":"test"},{"name":"there are no new mongosh scopes","suites":["mongosh scopes"],"updatePoint":{"line":13,"column":37,"index":1052},"line":13,"code":"  it('there are no new mongosh scopes', function () {\n    expect(expectedMongoshScopes).to.deep.equal(scopes);\n  });","file":"manual/mongosh_scopes.test.ts","skipped":false,"dir":"test"},{"name":"should support OCSP with tlsInsecure","suites":["OCSP Support"],"updatePoint":{"line":29,"column":42,"index":915},"line":29,"code":"  it('should support OCSP with tlsInsecure', function (done) {\n    // should always succeed\n    connect('tls=true&tlsInsecure=true', done);\n  });","file":"manual/ocsp_support.test.js","skipped":false,"dir":"test"},{"name":"should support OCSP with tlsAllowInvalidCertificates","suites":["OCSP Support"],"updatePoint":{"line":33,"column":58,"index":1077},"line":33,"code":"  it('should support OCSP with tlsAllowInvalidCertificates', function (done) {\n    // should always succeed\n    connect('tls=true&tlsAllowInvalidCertificates=true', done);\n  });","file":"manual/ocsp_support.test.js","skipped":false,"dir":"test"},{"name":"should support OCSP with `tls=true`","suites":["OCSP Support"],"updatePoint":{"line":37,"column":41,"index":1238},"line":37,"code":"  it('should support OCSP with `tls=true`', function (done) {\n    connect('tls=true', err => {\n      if (OCSP_TLS_SHOULD_SUCCEED) {\n        expect(err).to.not.exist;\n        return done();\n      }\n      expect(err).to.exist;\n      expect(err).to.match(/invalid status response/);\n      done();\n    });\n  });","file":"manual/ocsp_support.test.js","skipped":false,"dir":"test"},{"name":"fails to connect to a single host (connection string)","suites":["Socks5 Connectivity","with missing required Socks5 auth configuration"],"updatePoint":{"line":37,"column":63,"index":1807},"line":37,"code":"      it('fails to connect to a single host (connection string)', async function () {\n        const cs = singleConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n        cs.searchParams.set('directConnection', 'true');\n        try {\n          await testConnection(cs.toString(), {});\n        } catch (err) {\n          expect(err.name).to.equal('MongoServerSelectionError');\n          expect(err.message).to.match(/Received invalid Socks5 initial handshake/);\n          return;\n        }\n        expect.fail('missed exception');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"fails to connect to a single host (config options)","suites":["Socks5 Connectivity","with missing required Socks5 auth configuration"],"updatePoint":{"line":51,"column":60,"index":2431},"line":51,"code":"      it('fails to connect to a single host (config options)', async function () {\n        try {\n          await testConnection(singleConnectionString.toString(), {\n            proxyHost,\n            proxyPort,\n            directConnection: true\n          });\n        } catch (err) {\n          expect(err.name).to.equal('MongoServerSelectionError');\n          expect(err.message).to.match(/Received invalid Socks5 initial handshake/);\n          return;\n        }\n        expect.fail('missed exception');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"fails to connect to a replica set (connection string)","suites":["Socks5 Connectivity","with missing required Socks5 auth configuration"],"updatePoint":{"line":65,"column":63,"index":2948},"line":65,"code":"      it('fails to connect to a replica set (connection string)', async function () {\n        const cs = rsConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n        try {\n          await testConnection(cs.toString(), {});\n        } catch (err) {\n          expect(err.name).to.equal('MongoServerSelectionError');\n          expect(err.message).to.match(/Received invalid Socks5 initial handshake/);\n          return;\n        }\n        expect.fail('missed exception');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"fails to connect to a replica set (config options)","suites":["Socks5 Connectivity","with missing required Socks5 auth configuration"],"updatePoint":{"line":78,"column":60,"index":3511},"line":78,"code":"      it('fails to connect to a replica set (config options)', async function () {\n        try {\n          await testConnection(rsConnectionString.toString(), {\n            proxyHost,\n            proxyPort\n          });\n        } catch (err) {\n          expect(err.name).to.equal('MongoServerSelectionError');\n          expect(err.message).to.match(/Received invalid Socks5 initial handshake/);\n          return;\n        }\n        expect.fail('missed exception');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"fails to connect to a single host (connection string) if auth is present but wrong","suites":["Socks5 Connectivity","with missing required Socks5 auth configuration"],"updatePoint":{"line":91,"column":92,"index":4017},"line":91,"code":"      it('fails to connect to a single host (connection string) if auth is present but wrong', async function () {\n        const cs = singleConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n        cs.searchParams.set('proxyUsername', 'nonexistentuser');\n        cs.searchParams.set('proxyPassword', 'badauth');\n        cs.searchParams.set('directConnection', 'true');\n        try {\n          await testConnection(cs.toString(), {});\n        } catch (err) {\n          expect(err.name).to.equal('MongoServerSelectionError');\n          expect(err.message).to.match(/Socket closed/);\n          return;\n        }\n        expect.fail('missed exception');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a single host (connection string)","suites":["Socks5 Connectivity","with extraneous Socks5 auth configuration"],"updatePoint":{"line":114,"column":58,"index":4915},"line":114,"code":"      it('can connect to a single host (connection string)', async function () {\n        const cs = singleConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n        cs.searchParams.set('proxyUsername', 'nonexistentuser');\n        cs.searchParams.set('proxyPassword', 'badauth');\n        cs.searchParams.set('directConnection', 'true');\n        await testConnection(cs.toString(), {});\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a single host (config options)","suites":["Socks5 Connectivity","with extraneous Socks5 auth configuration"],"updatePoint":{"line":123,"column":55,"index":5396},"line":123,"code":"      it('can connect to a single host (config options)', async function () {\n        await testConnection(singleConnectionString.toString(), {\n          proxyHost,\n          proxyPort,\n          ...(proxyUsername ? {} : {\n            proxyUsername: 'nonexistentuser',\n            proxyPassword: 'badauth'\n          }),\n          directConnection: true\n        });\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a replica set (connection string)","suites":["Socks5 Connectivity","with extraneous Socks5 auth configuration"],"updatePoint":{"line":134,"column":58,"index":5774},"line":134,"code":"      it('can connect to a replica set (connection string)', async function () {\n        const cs = rsConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n        cs.searchParams.set('proxyUsername', 'nonexistentuser');\n        cs.searchParams.set('proxyPassword', 'badauth');\n        await testConnection(cs.toString(), {});\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a replica set (config options)","suites":["Socks5 Connectivity","with extraneous Socks5 auth configuration"],"updatePoint":{"line":142,"column":55,"index":6194},"line":142,"code":"      it('can connect to a replica set (config options)', async function () {\n        await testConnection(rsConnectionString.toString(), {\n          proxyHost,\n          proxyPort,\n          ...(proxyUsername ? {} : {\n            proxyUsername: 'nonexistentuser',\n            proxyPassword: 'badauth'\n          })\n        });\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a single host (connection string, with directConnection)","suites":["Socks5 Connectivity","with matching socks5 authentication"],"updatePoint":{"line":154,"column":81,"index":6624},"line":154,"code":"      it('can connect to a single host (connection string, with directConnection)', async function () {\n        const cs = singleConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n        if (proxyUsername) {\n          cs.searchParams.set('proxyUsername', proxyUsername);\n          cs.searchParams.set('proxyPassword', proxyPassword);\n        }\n        cs.searchParams.set('directConnection', 'true');\n        expect(await testConnection(cs.toString(), {})).to.equal('Single');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a single host (config options, with directConnection)","suites":["Socks5 Connectivity","with matching socks5 authentication"],"updatePoint":{"line":165,"column":78,"index":7198},"line":165,"code":"      it('can connect to a single host (config options, with directConnection)', async function () {\n        expect(await testConnection(singleConnectionString.toString(), {\n          proxyHost,\n          proxyPort,\n          ...(proxyUsername ? {\n            proxyUsername,\n            proxyPassword\n          } : {}),\n          directConnection: true\n        })).to.equal('Single');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a single host (connection string, without directConnection)","suites":["Socks5 Connectivity","with matching socks5 authentication"],"updatePoint":{"line":176,"column":84,"index":7599},"line":176,"code":"      it('can connect to a single host (connection string, without directConnection)', async function () {\n        const cs = singleConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n        if (proxyUsername) {\n          cs.searchParams.set('proxyUsername', proxyUsername);\n          cs.searchParams.set('proxyPassword', proxyPassword);\n        }\n        cs.searchParams.set('directConnection', 'false');\n        expect(await testConnection(cs.toString(), {})).to.equal('ReplicaSetWithPrimary');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a single host (config options, without directConnection)","suites":["Socks5 Connectivity","with matching socks5 authentication"],"updatePoint":{"line":187,"column":81,"index":8192},"line":187,"code":"      it('can connect to a single host (config options, without directConnection)', async function () {\n        expect(await testConnection(singleConnectionString.toString(), {\n          proxyHost,\n          proxyPort,\n          ...(proxyUsername ? {\n            proxyUsername,\n            proxyPassword\n          } : {}),\n          directConnection: false\n        })).to.equal('ReplicaSetWithPrimary');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a replica set (connection string)","suites":["Socks5 Connectivity","with matching socks5 authentication"],"updatePoint":{"line":198,"column":58,"index":8583},"line":198,"code":"      it('can connect to a replica set (connection string)', async function () {\n        const cs = rsConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n        if (proxyUsername) {\n          cs.searchParams.set('proxyUsername', proxyUsername);\n          cs.searchParams.set('proxyPassword', proxyPassword);\n        }\n        expect(await testConnection(cs.toString(), {})).to.equal('ReplicaSetWithPrimary');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a replica set (config options)","suites":["Socks5 Connectivity","with matching socks5 authentication"],"updatePoint":{"line":208,"column":55,"index":9088},"line":208,"code":"      it('can connect to a replica set (config options)', async function () {\n        expect(await testConnection(rsConnectionString.toString(), {\n          proxyHost,\n          proxyPort,\n          ...(proxyUsername ? {\n            proxyUsername,\n            proxyPassword\n          } : {})\n        })).to.equal('ReplicaSetWithPrimary');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"does not mention the proxy in command monitoring events","suites":["Socks5 Connectivity","with matching socks5 authentication"],"updatePoint":{"line":218,"column":65,"index":9447},"line":218,"code":"      it('does not mention the proxy in command monitoring events', async function () {\n        const client = new MongoClient(singleConnectionString.toString(), {\n          proxyHost,\n          proxyPort,\n          ...(proxyUsername ? {\n            proxyUsername,\n            proxyPassword\n          } : {}),\n          directConnection: true,\n          monitorCommands: true\n        });\n        const seenCommandAddresses = new Set();\n        client.on('commandSucceeded', ev => seenCommandAddresses.add(ev.address));\n        await client.connect();\n        await client.db('admin').command({\n          [LEGACY_HELLO_COMMAND]: 1\n        });\n        await client.close();\n        expect([...seenCommandAddresses]).to.deep.equal(singleConnectionString.hosts);\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"rejects invalid MongoClient options ","suites":["Socks5 Connectivity","MongoClient option validation"],"updatePoint":{"line":258,"column":77,"index":10650},"line":258,"code":"      it(`rejects invalid MongoClient options ${JSON.stringify(proxyOptions)}`, () => {\n        expect(() => new MongoClient('mongodb://localhost', proxyOptions)).to.throw(MongoParseError);\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"should connect with tls via client options","suites":["TLS Support"],"updatePoint":{"line":24,"column":48,"index":687},"line":24,"code":"  it('should connect with tls via client options', makeConnectionTest(connectionString, tlsSettings));","file":"manual/tls_support.test.js","skipped":false,"dir":"test"},{"name":"should connect with tls via url options","suites":["TLS Support"],"updatePoint":{"line":25,"column":45,"index":787},"line":25,"code":"  it('should connect with tls via url options', makeConnectionTest(`${connectionString}?${Object.keys(tlsSettings).map(key => `${key}=${tlsSettings[key]}`).join('&')}`));","file":"manual/tls_support.test.js","skipped":false,"dir":"test"},{"name":"","suites":["Auth option spec tests (legacy)"],"updatePoint":{"line":8,"column":31,"index":367},"line":8,"code":"        it(`${test.description}`, function () {\n          executeUriValidationTest(test);\n        });","file":"unit/assorted/auth.spec.test.ts","skipped":false,"dir":"test"},{"name":"should let wrapping libraries amend the client metadata","suites":["Client (unit)"],"updatePoint":{"line":23,"column":61,"index":582},"line":23,"code":"  it('should let wrapping libraries amend the client metadata', function () {\n    let handshake;\n    server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        handshake = doc;\n        request.reply(Object.assign({}, mock.HELLO));\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    client = new MongoClient(`mongodb://${server.uri()}/`, {\n      driverInfo: {\n        name: 'mongoose',\n        version: '5.7.10',\n        platform: 'llama edition'\n      }\n    });\n    return client.connect().then(() => {\n      expect(handshake).to.have.nested.property('client.driver');\n      expect(handshake).nested.property('client.driver.name')\n      // Currently the tests import either MongoClient or LegacyMongoClient, the latter of which overrides the client metadata\n      // We still are confirming here that a third party wrapper can set the metadata but it will change depending on the\n      // MongoClient constructor that is imported\n      .to.equal(isLegacyMongoClient ? 'nodejs|mongodb-legacy|mongoose' : 'nodejs|mongoose');\n      expect(handshake).nested.property('client.driver.version').to.match(/|5.7.10/);\n      expect(handshake).nested.property('client.platform').to.match(/llama edition/);\n    });\n  });","file":"unit/assorted/client.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to count command","suites":["Collation"],"updatePoint":{"line":22,"column":58,"index":519},"line":22,"code":"  it('Successfully pass through collation to count command', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.count) {\n        commandResult = doc;\n        request.reply({\n          ok: 1,\n          result: {\n            n: 1\n          }\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_test');\n      return db.collection('test').estimatedDocumentCount({\n        collation: {\n          caseLevel: true\n        }\n      }).then(() => {\n        expect(commandResult).to.have.property('collation');\n        expect(commandResult.collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to aggregation command","suites":["Collation"],"updatePoint":{"line":59,"column":64,"index":1597},"line":59,"code":"  it('Successfully pass through collation to aggregation command', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.aggregate) {\n        commandResult = doc;\n        request.reply({\n          ok: 1,\n          cursor: {\n            id: 0,\n            firstBatch: [],\n            ns: 'collation_test'\n          }\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_test');\n      return db.collection('test').aggregate([{\n        $match: {}\n      }, {\n        $out: 'readConcernCollectionAggregate1Output'\n      }], {\n        collation: {\n          caseLevel: true\n        }\n      }).toArray().then(() => {\n        expect(commandResult).to.have.property('collation');\n        expect(commandResult.collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to distinct command","suites":["Collation"],"updatePoint":{"line":102,"column":61,"index":2833},"line":102,"code":"  it('Successfully pass through collation to distinct command', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      var doc = request.document;\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.distinct) {\n        commandResult = doc;\n        request.reply({\n          ok: 1\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').distinct('a', {}, {\n        collation: {\n          caseLevel: true\n        }\n      }).then(() => {\n        expect(commandResult).to.have.property('collation');\n        expect(commandResult.collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to remove command","suites":["Collation"],"updatePoint":{"line":136,"column":59,"index":3850},"line":136,"code":"  it('Successfully pass through collation to remove command', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      var doc = request.document;\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.delete) {\n        commandResult = doc;\n        request.reply({\n          ok: 1\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').deleteMany({}, {\n        collation: {\n          caseLevel: true\n        }\n      }).then(() => {\n        expect(commandResult.deletes).to.have.length.at.least(1);\n        expect(commandResult.deletes[0]).to.have.property('collation');\n        expect(commandResult.deletes[0].collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to update command","suites":["Collation"],"updatePoint":{"line":171,"column":59,"index":4950},"line":171,"code":"  it('Successfully pass through collation to update command', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.update) {\n        commandResult = doc;\n        request.reply({\n          ok: 1\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').updateOne({\n        a: 1\n      }, {\n        $set: {\n          b: 1\n        }\n      }, {\n        collation: {\n          caseLevel: true\n        }\n      }).then(() => {\n        expect(commandResult.updates).to.have.length.at.least(1);\n        expect(commandResult.updates[0]).to.have.property('collation');\n        expect(commandResult.updates[0].collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to find command via options","suites":["Collation"],"updatePoint":{"line":212,"column":69,"index":6133},"line":212,"code":"  it('Successfully pass through collation to find command via options', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.find) {\n        commandResult = doc;\n        request.reply({\n          ok: 1,\n          cursor: {\n            id: 0,\n            firstBatch: []\n          }\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').find({\n        a: 1\n      }, {\n        collation: {\n          caseLevel: true\n        }\n      }).toArray().then(() => {\n        expect(commandResult).to.have.property('collation');\n        expect(commandResult.collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to find command via cursor","suites":["Collation"],"updatePoint":{"line":252,"column":68,"index":7257},"line":252,"code":"  it('Successfully pass through collation to find command via cursor', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.find) {\n        commandResult = doc;\n        request.reply({\n          ok: 1,\n          cursor: {\n            id: 0,\n            firstBatch: []\n          }\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').find({\n        a: 1\n      }).collation({\n        caseLevel: true\n      }).toArray().then(() => {\n        expect(commandResult).to.have.property('collation');\n        expect(commandResult.collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to findOne","suites":["Collation"],"updatePoint":{"line":290,"column":52,"index":8342},"line":290,"code":"  it('Successfully pass through collation to findOne', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.find) {\n        commandResult = doc;\n        request.reply({\n          ok: 1,\n          cursor: {\n            id: 0,\n            firstBatch: []\n          }\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').findOne({\n        a: 1\n      }, {\n        collation: {\n          caseLevel: true\n        }\n      }).then(() => {\n        expect(commandResult).to.have.property('collation');\n        expect(commandResult.collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to createCollection","suites":["Collation"],"updatePoint":{"line":330,"column":61,"index":9452},"line":330,"code":"  it('Successfully pass through collation to createCollection', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.listCollections) {\n        request.reply({\n          ok: 1,\n          cursor: {\n            id: Long.fromNumber(0),\n            ns: 'test.cmd$.listCollections',\n            firstBatch: []\n          }\n        });\n      } else if (doc.create) {\n        commandResult = doc;\n        request.reply({\n          ok: 1\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.createCollection('test', {\n        collation: {\n          caseLevel: true\n        }\n      }).then(() => {\n        expect(commandResult).to.have.property('collation');\n        expect(commandResult.collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to bulkWrite command","suites":["Collation"],"updatePoint":{"line":373,"column":62,"index":10693},"line":373,"code":"  it('Successfully pass through collation to bulkWrite command', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.update) {\n        commandResult = doc;\n        request.reply({\n          ok: 1\n        });\n      } else if (doc.delete) {\n        request.reply({\n          ok: 1\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').bulkWrite([{\n        updateOne: {\n          filter: {\n            a: 2\n          },\n          update: {\n            $set: {\n              a: 2\n            }\n          },\n          upsert: true,\n          collation: {\n            caseLevel: true\n          }\n        }\n      }, {\n        deleteOne: {\n          filter: {\n            c: 1\n          }\n        }\n      }], {\n        ordered: true\n      }).then(() => {\n        expect(commandResult).to.exist;\n        expect(commandResult).to.have.property('updates');\n        expect(commandResult.updates).to.have.length.at.least(1);\n        expect(commandResult.updates[0]).to.have.property('collation');\n        expect(commandResult.updates[0].collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully create index with collation","suites":["Collation"],"updatePoint":{"line":433,"column":46,"index":12282},"line":433,"code":"  it('Successfully create index with collation', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.createIndexes) {\n        commandResult = doc;\n        request.reply({\n          ok: 1\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').createIndex({\n        a: 1\n      }, {\n        collation: {\n          caseLevel: true\n        }\n      }).then(() => {\n        expect(commandResult).to.containSubset({\n          createIndexes: 'test',\n          indexes: [{\n            name: 'a_1',\n            key: {\n              a: 1\n            },\n            collation: {\n              caseLevel: true\n            }\n          }]\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"should import  directly without issue","suites":["importing mongodb driver"],"updatePoint":{"line":23,"column":75,"index":772},"line":23,"code":"    it(`should import ${sourceFile.slice(sliceFrom)} directly without issue`, () => {\n      execSync(`./node_modules/.bin/ts-node -e \"require('${sourceFile}')\"`);\n    });","file":"unit/assorted/imports.test.ts","skipped":false,"dir":"test"},{"name":"should error if not installed","suites":["optionalRequire","Snappy"],"updatePoint":{"line":32,"column":37,"index":619},"line":32,"code":"    it('should error if not installed', function () {\n      const moduleName = 'snappy';\n      if (moduleExistsSync(moduleName)) {\n        return this.skip();\n      }\n      compress({\n        options: {\n          agreedCompressor: 'snappy'\n        }\n      }, Buffer.alloc(1), error => {\n        expect(error).to.exist;\n        expect(error.message).includes('not found');\n      });\n    });","file":"unit/assorted/optional_require.test.js","skipped":false,"dir":"test"},{"name":"should error if not installed","suites":["optionalRequire","Kerberos"],"updatePoint":{"line":48,"column":37,"index":1051},"line":48,"code":"    it('should error if not installed', function () {\n      const moduleName = 'kerberos';\n      if (moduleExistsSync(moduleName)) {\n        return this.skip();\n      }\n      const gssapi = new GSSAPI();\n      gssapi.auth(new AuthContext(null, true, {\n        hostAddress: new HostAddress('a'),\n        credentials: true\n      }), error => {\n        expect(error).to.exist;\n        expect(error.message).includes('not found');\n      });\n    });","file":"unit/assorted/optional_require.test.js","skipped":false,"dir":"test"},{"name":"should error if not installed","suites":["optionalRequire","aws4"],"updatePoint":{"line":64,"column":37,"index":1534},"line":64,"code":"    it('should error if not installed', function () {\n      const moduleName = 'aws4';\n      if (moduleExistsSync(moduleName)) {\n        return this.skip();\n      }\n      const mdbAWS = new MongoDBAWS();\n      mdbAWS.auth(new AuthContext({\n        hello: {\n          maxWireVersion: 9\n        }\n      }, true, null), error => {\n        expect(error).to.exist;\n        expect(error.message).includes('not found');\n      });\n    });","file":"unit/assorted/optional_require.test.js","skipped":false,"dir":"test"},{"name":"should error if iteration count is less than 4096","suites":["SCRAM Iterations Tests"],"updatePoint":{"line":15,"column":55,"index":540},"line":15,"code":"  it('should error if iteration count is less than 4096', async function () {\n    const scramResponse = 'r=IE+xNFeOcslsupAA+zkDVzHd5HfwoRuP7Wi8S4py+erf8PcNm7XIdXQyT52Nj3+M,s=AzomrlMs99A7oFxDLpgFvVb+CSvdyXuNagoWVw==,i=4000';\n    const credentials = new MongoCredentials({\n      mechanism: 'DEFAULT',\n      source: 'db',\n      username: 'user',\n      password: 'pencil',\n      mechanismProperties: {}\n    });\n    client.s.options.credentials = credentials;\n    server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        return request.reply(Object.assign({}, mock.HELLO));\n      } else if (doc.saslStart) {\n        return request.reply({\n          ok: 1,\n          done: false,\n          payload: Buffer.from(scramResponse)\n        });\n      } else if (doc.saslContinue) {\n        throw new Error('should not be here');\n      }\n    });\n    const thrownError = await client.connect().catch(error => error);\n    expect(thrownError).to.be.instanceOf(MongoRuntimeError);\n    expect(thrownError).to.have.property('message').that.matches(/Server returned an invalid iteration count/);\n  });","file":"unit/assorted/scram_iterations.test.ts","skipped":false,"dir":"test"},{"name":"should error if server digest is invalid","suites":["SCRAM Iterations Tests"],"updatePoint":{"line":43,"column":46,"index":1663},"line":43,"code":"  it('should error if server digest is invalid', async function () {\n    const credentials = new MongoCredentials({\n      mechanism: 'DEFAULT',\n      source: 'db',\n      username: 'user',\n      password: 'pencil',\n      mechanismProperties: {}\n    });\n    client.s.options.credentials = credentials;\n    server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        return request.reply(Object.assign({}, mock.HELLO));\n      } else if (doc.saslStart) {\n        return request.reply({\n          ok: 1,\n          done: false,\n          payload: Buffer.from('r=VNnXkRqKflB5+rmfnFiisCWzgDLzez02iRpbvE5mQjMvizb+VkSPRZZ/pDmFzLxq,s=dZTyOb+KZqoeTFdsULiqow==,i=10000')\n        });\n      } else if (doc.saslContinue) {\n        return request.reply({\n          ok: 1,\n          done: false,\n          payload: Buffer.from('v=bWFsaWNpb3VzbWFsaWNpb3VzVzV')\n        });\n      }\n    });\n    const thrownError = await client.connect().catch(error => error);\n    expect(thrownError).to.be.instanceOf(MongoRuntimeError);\n    expect(thrownError).to.have.property('message').that.matches(/Server returned an invalid signature/);\n  });","file":"unit/assorted/scram_iterations.test.ts","skipped":false,"dir":"test"},{"name":"should properly handle network errors on `saslContinue`","suites":["SCRAM Iterations Tests"],"updatePoint":{"line":74,"column":61,"index":2839},"line":74,"code":"  it('should properly handle network errors on `saslContinue`', async function () {\n    const credentials = new MongoCredentials({\n      mechanism: 'DEFAULT',\n      source: 'db',\n      username: 'user',\n      password: 'pencil',\n      mechanismProperties: {}\n    });\n    client.s.options.credentials = credentials;\n    server.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        return request.reply(Object.assign({}, mock.HELLO));\n      } else if (doc.saslStart) {\n        return request.reply({\n          ok: 1,\n          done: false,\n          payload: Buffer.from('r=VNnXkRqKflB5+rmfnFiisCWzgDLzez02iRpbvE5mQjMvizb+VkSPRZZ/pDmFzLxq,s=dZTyOb+KZqoeTFdsULiqow==,i=10000')\n        });\n      } else if (doc.saslContinue) {\n        request.connection.destroy();\n      }\n    });\n    const thrownError = await client.connect().catch(error => error);\n    expect(thrownError).to.be.instanceOf(MongoNetworkError);\n    expect(thrownError).to.have.property('message').that.matches(/connection(.+)closed/);\n  });","file":"unit/assorted/scram_iterations.test.ts","skipped":false,"dir":"test"},{"name":"should not throw a synchronous exception if sessions are not supported","suites":["Sessions - client/unit","Client"],"updatePoint":{"line":23,"column":78,"index":608},"line":23,"code":"    it('should not throw a synchronous exception if sessions are not supported', function () {\n      test.server.setMessageHandler(request => {\n        var doc = request.document;\n        if (isHello(doc)) {\n          request.reply(Object.assign({}, mock.HELLO));\n        } else if (doc.endSessions) {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      const client = new MongoClient(`mongodb://${test.server.uri()}/test`);\n      return client.connect().then(() => {\n        expect(() => client.startSession()).to.not.throw('Current topology does not support sessions');\n        return client.close();\n      });\n    });","file":"unit/assorted/sessions_client.test.js","skipped":false,"dir":"test"},{"name":"should throw an exception if sessions are not supported on some servers","suites":["Sessions - client/unit","Client"],"updatePoint":{"line":40,"column":79,"index":1262},"line":40,"code":"    it('should throw an exception if sessions are not supported on some servers', function () {\n      const replicaSetMock = new ReplSetFixture();\n      let testClient;\n      return replicaSetMock.setup({\n        doNotInitHandlers: true\n      }).then(() => {\n        replicaSetMock.firstSecondaryServer.setMessageHandler(request => {\n          var doc = request.document;\n          if (isHello(doc)) {\n            const hello = replicaSetMock.firstSecondaryStates[0];\n            hello.logicalSessionTimeoutMinutes = 20;\n            request.reply(hello);\n          } else if (doc.endSessions) {\n            request.reply({\n              ok: 1\n            });\n          }\n        });\n        replicaSetMock.secondSecondaryServer.setMessageHandler(request => {\n          var doc = request.document;\n          if (isHello(doc)) {\n            const hello = replicaSetMock.secondSecondaryStates[0];\n            hello.logicalSessionTimeoutMinutes = 10;\n            request.reply(hello);\n          } else if (doc.endSessions) {\n            request.reply({\n              ok: 1\n            });\n          }\n        });\n        replicaSetMock.arbiterServer.setMessageHandler(request => {\n          var doc = request.document;\n          if (isHello(doc)) {\n            const hello = replicaSetMock.arbiterStates[0];\n            hello.logicalSessionTimeoutMinutes = 30;\n            request.reply(hello);\n          } else if (doc.endSessions) {\n            request.reply({\n              ok: 1\n            });\n          }\n        });\n        replicaSetMock.primaryServer.setMessageHandler(request => {\n          var doc = request.document;\n          if (isHello(doc)) {\n            const hello = replicaSetMock.primaryStates[0];\n            hello.logicalSessionTimeoutMinutes = null;\n            request.reply(hello);\n          } else if (doc.endSessions) {\n            request.reply({\n              ok: 1\n            });\n          }\n        });\n        return replicaSetMock.uri();\n      }).then(uri => {\n        testClient = new MongoClient(uri);\n        return testClient.connect();\n      }).then(client => {\n        const session = client.startSession();\n        return client.db().collection('t').insertOne({\n          a: 1\n        }, {\n          session\n        });\n      }).then(() => {\n        expect.fail('Expected an error to be thrown about not supporting sessions');\n      }).catch(error => {\n        expect(error.message).to.equal('Current topology does not support sessions');\n      }).finally(() => testClient ? testClient.close() : null);\n    });","file":"unit/assorted/sessions_client.test.js","skipped":false,"dir":"test"},{"name":"should return a client session when requested if the topology supports it","suites":["Sessions - client/unit","Client"],"updatePoint":{"line":111,"column":81,"index":3812},"line":111,"code":"    it('should return a client session when requested if the topology supports it', function (done) {\n      test.server.setMessageHandler(request => {\n        var doc = request.document;\n        if (isHello(doc)) {\n          request.reply(Object.assign({}, mock.HELLO, {\n            logicalSessionTimeoutMinutes: 10\n          }));\n        } else if (doc.endSessions) {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      const client = new MongoClient(`mongodb://${test.server.uri()}/test`);\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        let session = client.startSession();\n        expect(session).to.exist;\n        session.endSession({\n          skipCommand: true\n        });\n        client.close(done);\n      });\n    });","file":"unit/assorted/sessions_client.test.js","skipped":false,"dir":"test"},{"name":"should include `afterClusterTime` in read command with causal consistency","suites":["Sessions - unit/sessions","Collection"],"updatePoint":{"line":25,"column":81,"index":597},"line":25,"code":"    it('should include `afterClusterTime` in read command with causal consistency', function () {\n      let findCommand;\n      let insertOperationTime = Timestamp.fromNumber(Date.now());\n      test.server.setMessageHandler(request => {\n        const doc = request.document;\n        if (isHello(doc)) {\n          request.reply(Object.assign({\n            logicalSessionTimeoutMinutes: 15\n          }, mock.HELLO));\n        } else if (doc.insert) {\n          request.reply({\n            ok: 1,\n            operationTime: insertOperationTime\n          });\n        } else if (doc.find) {\n          findCommand = doc;\n          request.reply({\n            ok: 1,\n            cursor: {\n              id: 0,\n              firstBatch: []\n            }\n          });\n        } else if (doc.endSessions) {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      const client = new MongoClient(`mongodb://${test.server.uri()}/test`);\n      const session = client.startSession({\n        causalConsistency: true\n      });\n      const coll = client.db('foo').collection('bar');\n      return coll.insertOne({\n        a: 42\n      }, {\n        session: session\n      }).then(() => coll.findOne({}, {\n        session: session,\n        readConcern: {\n          level: 'majority'\n        }\n      })).then(() => {\n        expect(findCommand.readConcern).to.have.keys(['level', 'afterClusterTime']);\n        expect(findCommand.readConcern.afterClusterTime).to.eql(insertOperationTime);\n        session.endSession({\n          skipCommand: true\n        });\n        return client.close();\n      });\n    });","file":"unit/assorted/sessions_collection.test.js","skipped":false,"dir":"test"},{"name":"does not mutate command options","suites":["Sessions - unit/sessions","Collection"],"updatePoint":{"line":77,"column":39,"index":2165},"line":77,"code":"    it('does not mutate command options', function () {\n      const options = Object.freeze({});\n      test.server.setMessageHandler(request => {\n        const doc = request.document;\n        if (isHello(doc)) {\n          request.reply(mock.HELLO);\n        } else if (doc.count || doc.aggregate || doc.endSessions) {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      const client = new MongoClient(`mongodb://${test.server.uri()}/test`);\n      return client.connect().then(client => {\n        const coll = client.db('foo').collection('bar');\n        return coll.countDocuments({}, options).then(() => {\n          expect(options).to.deep.equal({});\n          return client.close();\n        });\n      });\n    });","file":"unit/assorted/sessions_collection.test.js","skipped":false,"dir":"test"},{"name":"","suites":["URI option spec tests"],"updatePoint":{"line":31,"column":31,"index":1595},"line":31,"code":"        it(`${test.description}`, function () {\n          if (skipTests.includes(test.description)) {\n            return this.skip();\n          }\n          executeUriValidationTest(test, testsThatDoNotThrowOnWarn.some(t => t === test.description));\n        });","file":"unit/assorted/uri_options.spec.test.ts","skipped":false,"dir":"test"},{"name":"should raise a compatibility error","suites":["Wire Protocol Version","minimum is greater than max supported"],"updatePoint":{"line":40,"column":42,"index":1175},"line":40,"code":"    it('should raise a compatibility error', async function () {\n      setWireProtocolMessageHandler(Number.MAX_SAFE_INTEGER - 1, Number.MAX_SAFE_INTEGER);\n\n      /** @type {MongoClient} */\n      client = new MongoClient(`mongodb://${server.uri()}/wireVersionTest?serverSelectionTimeoutMS=200`);\n      try {\n        await client.connect();\n        expect.fail('should fail to select server!');\n      } catch (error) {\n        expect(error).to.be.instanceOf(MongoServerSelectionError);\n        expect(error).to.have.property('message').that.includes(minCompatErrMsg);\n      }\n    });","file":"unit/assorted/wire_version.test.js","skipped":false,"dir":"test"},{"name":"should raise a compatibility error","suites":["Wire Protocol Version","maximum is less than min supported"],"updatePoint":{"line":55,"column":42,"index":1821},"line":55,"code":"    it('should raise a compatibility error', async function () {\n      setWireProtocolMessageHandler(1, 1);\n\n      /** @type {MongoClient} */\n      client = new MongoClient(`mongodb://${server.uri()}/wireVersionTest?serverSelectionTimeoutMS=200`);\n      try {\n        await client.connect();\n        expect.fail('should fail to select server!');\n      } catch (error) {\n        expect(error).to.be.instanceOf(MongoServerSelectionError);\n        expect(error).to.have.property('message').that.includes(maxCompatErrMsg);\n      }\n    });","file":"unit/assorted/wire_version.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to aggregate command","suites":["Command Write Concern"],"updatePoint":{"line":128,"column":65,"index":3651},"line":128,"code":"  it('successfully pass through writeConcern to aggregate command', () => writeConcernTest('aggregate', (db, writeConcernTestOptions) => db.collection('test').aggregate([{\n    $match: {}\n  }, {\n    $out: 'readConcernCollectionAggregate1Output'\n  }], writeConcernTestOptions).toArray()));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to create command","suites":["Command Write Concern"],"updatePoint":{"line":133,"column":62,"index":3936},"line":133,"code":"  it('successfully pass through writeConcern to create command', () => writeConcernTest('create', (db, writeConcernTestOptions) => db.createCollection('test_collection_methods', writeConcernTestOptions)));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to createIndexes command","suites":["Command Write Concern"],"updatePoint":{"line":134,"column":69,"index":4149},"line":134,"code":"  it('successfully pass through writeConcern to createIndexes command', () => writeConcernTest('createIndexes', (db, writeConcernTestOptions) => db.collection('indexOptionDefault').createIndex({\n    a: 1\n  }, Object.assign({\n    indexOptionDefaults: true\n  }, writeConcernTestOptions))));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to drop command","suites":["Command Write Concern"],"updatePoint":{"line":139,"column":60,"index":4429},"line":139,"code":"  it('successfully pass through writeConcern to drop command', () => writeConcernTest('drop', (db, writeConcernTestOptions) => db.collection('indexOptionDefault').drop(writeConcernTestOptions)));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to dropDatabase command","suites":["Command Write Concern"],"updatePoint":{"line":140,"column":68,"index":4633},"line":140,"code":"  it('successfully pass through writeConcern to dropDatabase command', () => writeConcernTest('dropDatabase', (db, writeConcernTestOptions) => db.dropDatabase(writeConcernTestOptions)));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to dropIndexes command","suites":["Command Write Concern"],"updatePoint":{"line":141,"column":67,"index":4819},"line":141,"code":"  it('successfully pass through writeConcern to dropIndexes command', () => writeConcernTest('dropIndexes', (db, writeConcernTestOptions) => db.collection('test').dropIndexes(writeConcernTestOptions)));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to createUser command","suites":["Command Write Concern"],"updatePoint":{"line":142,"column":66,"index":5021},"line":142,"code":"  it('successfully pass through writeConcern to createUser command', () => writeConcernTest('createUser', (db, writeConcernTestOptions) => db.admin().addUser('kay:kay', 'abc123', writeConcernTestOptions)));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to dropUser command","suites":["Command Write Concern"],"updatePoint":{"line":143,"column":64,"index":5226},"line":143,"code":"  it('successfully pass through writeConcern to dropUser command', () => writeConcernTest('dropUser', (db, writeConcernTestOptions) => db.admin().removeUser('kay:kay', writeConcernTestOptions)));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"copies all non-resume related options from the original cursor","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken"],"updatePoint":{"line":11,"column":72,"index":466},"line":11,"code":"      it('copies all non-resume related options from the original cursor', function () {\n        const cursor = new ChangeStreamCursor(new MongoClient('mongodb://localhost:27027'), new MongoDBNamespace('db', 'collection'), [], {\n          promoteBuffers: true,\n          promoteLongs: false,\n          maxAwaitTimeMS: 5000\n        });\n        cursor.resumeToken = 'resume token';\n        const options = cursor.resumeOptions;\n        expect(options).to.haveOwnProperty('promoteBuffers', true);\n        expect(options).to.haveOwnProperty('promoteLongs', false);\n        expect(options).to.haveOwnProperty('maxAwaitTimeMS', 5000);\n      });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"sets the startAfter option to the cached resumeToken","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was started with startAfter","when the cursor has not yet returned a document"],"updatePoint":{"line":35,"column":66,"index":1644},"line":35,"code":"          it('sets the startAfter option to the cached resumeToken', function () {\n            expect(cursor.resumeOptions).to.haveOwnProperty('startAfter', 'resume token');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the resumeAfter option","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was started with startAfter","when the cursor has not yet returned a document"],"updatePoint":{"line":38,"column":49,"index":1815},"line":38,"code":"          it('does NOT set the resumeAfter option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('resumeAfter');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAtOperationTime option","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was started with startAfter","when the cursor has not yet returned a document","when the startAtOperationTime option is NOT set"],"updatePoint":{"line":42,"column":60,"index":2069},"line":42,"code":"            it('does NOT set the startAtOperationTime option', function () {\n              expect(cursor.resumeOptions).not.to.haveOwnProperty('startAtOperationTime');\n            });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAtOperationTime option","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was started with startAfter","when the cursor has not yet returned a document","when the startAtOperationTime option is set"],"updatePoint":{"line":47,"column":60,"index":2346},"line":47,"code":"            it('does NOT set the startAtOperationTime option', function () {\n              cursor.startAtOperationTime = new Timestamp(Long.ZERO);\n              expect(cursor.resumeOptions).not.to.haveOwnProperty('startAtOperationTime');\n            });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAfter option","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was started with startAfter","when the cursor has returned a document"],"updatePoint":{"line":57,"column":48,"index":2775},"line":57,"code":"          it('does NOT set the startAfter option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('startAfter');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"sets the resumeAFter option to the cached resumeToken","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was started with startAfter","when the cursor has returned a document"],"updatePoint":{"line":60,"column":67,"index":2952},"line":60,"code":"          it('sets the resumeAFter option to the cached resumeToken', function () {\n            expect(cursor.resumeOptions).to.haveOwnProperty('resumeAfter', 'resume token');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAtOperationTime option","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was started with startAfter","when the cursor has returned a document","when the startAtOperationTime option is NOT set"],"updatePoint":{"line":64,"column":60,"index":3218},"line":64,"code":"            it('does NOT set the startAtOperationTime option', function () {\n              expect(cursor.resumeOptions).not.to.haveOwnProperty('startAtOperationTime');\n            });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAtOperationTime option","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was started with startAfter","when the cursor has returned a document","when the startAtOperationTime option is set"],"updatePoint":{"line":69,"column":60,"index":3495},"line":69,"code":"            it('does NOT set the startAtOperationTime option', function () {\n              cursor.startAtOperationTime = new Timestamp(Long.ZERO);\n              expect(cursor.resumeOptions).not.to.haveOwnProperty('startAtOperationTime');\n            });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"sets the resumeAfter option to the cached resumeToken","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was not initialized with startAfter set"],"updatePoint":{"line":82,"column":65,"index":4128},"line":82,"code":"        it('sets the resumeAfter option to the cached resumeToken', function () {\n          expect(cursor.resumeOptions).to.haveOwnProperty('resumeAfter', 'resume token');\n        });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAfter option","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was not initialized with startAfter set"],"updatePoint":{"line":85,"column":46,"index":4293},"line":85,"code":"        it('does NOT set the startAfter option', function () {\n          expect(cursor.resumeOptions).not.to.haveOwnProperty('startAfter');\n        });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAtOperationTime option","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was not initialized with startAfter set","when the startAtOperationTime option is NOT set"],"updatePoint":{"line":89,"column":58,"index":4538},"line":89,"code":"          it('does NOT set the startAtOperationTime option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('startAtOperationTime');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAtOperationTime option","suites":["ChangeStreamCursor","get resumeOptions()","when there is a cached resumeToken","when the cursor was not initialized with startAfter set","when the startAtOperationTime option is set"],"updatePoint":{"line":94,"column":58,"index":4805},"line":94,"code":"          it('does NOT set the startAtOperationTime option', function () {\n            cursor.startAtOperationTime = new Timestamp(Long.ZERO);\n            cursor.resumeToken = 'resume token';\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('startAtOperationTime');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"copies all non-resume related options from the original cursor","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor has a saved operation time"],"updatePoint":{"line":104,"column":74,"index":5285},"line":104,"code":"        it('copies all non-resume related options from the original cursor', function () {\n          const cursor = new ChangeStreamCursor(new MongoClient('mongodb://localhost:27027'), new MongoDBNamespace('db', 'collection'), [], {\n            startAfter: 'start after',\n            resumeAfter: 'resume after',\n            startAtOperationTime: new Timestamp(Long.ZERO),\n            promoteBuffers: true,\n            promoteLongs: false,\n            maxAwaitTimeMS: 5000\n          });\n          cursor.resumeToken = null;\n          const options = cursor.resumeOptions;\n          expect(options).to.haveOwnProperty('promoteBuffers', true);\n          expect(options).to.haveOwnProperty('promoteLongs', false);\n          expect(options).to.haveOwnProperty('maxAwaitTimeMS', 5000);\n        });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the resumeAfter option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor has a saved operation time","when the maxWireVersion >= 7"],"updatePoint":{"line":134,"column":49,"index":6668},"line":134,"code":"          it('does NOT set the resumeAfter option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('resumeAfter');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAfter option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor has a saved operation time","when the maxWireVersion >= 7"],"updatePoint":{"line":137,"column":48,"index":6827},"line":137,"code":"          it('does NOT set the startAfter option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('startAfter');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does set the startAtOperationTime option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor has a saved operation time","when the maxWireVersion >= 7"],"updatePoint":{"line":140,"column":54,"index":6991},"line":140,"code":"          it('does set the startAtOperationTime option', function () {\n            expect(cursor.resumeOptions).to.haveOwnProperty('startAtOperationTime');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the resumeAfter option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor has a saved operation time","when the maxWireVersion < 7"],"updatePoint":{"line":159,"column":49,"index":7782},"line":159,"code":"          it('does NOT set the resumeAfter option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('resumeAfter');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAfter option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor has a saved operation time","when the maxWireVersion < 7"],"updatePoint":{"line":162,"column":48,"index":7941},"line":162,"code":"          it('does NOT set the startAfter option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('startAfter');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAtOperationTime option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor has a saved operation time","when the maxWireVersion < 7"],"updatePoint":{"line":165,"column":58,"index":8109},"line":165,"code":"          it('does NOT set the startAtOperationTime option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('startAtOperationTime');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"copies all non-resume related options from the original cursor","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor does NOT have a saved operation time"],"updatePoint":{"line":171,"column":74,"index":8409},"line":171,"code":"        it('copies all non-resume related options from the original cursor', function () {\n          const cursor = new ChangeStreamCursor(new MongoClient('mongodb://localhost:27027'), new MongoDBNamespace('db', 'collection'), [], {\n            startAfter: 'start after',\n            resumeAfter: 'resume after',\n            promoteBuffers: true,\n            promoteLongs: false,\n            maxAwaitTimeMS: 5000\n          });\n          cursor.resumeToken = null;\n          const options = cursor.resumeOptions;\n          expect(options).to.haveOwnProperty('promoteBuffers', true);\n          expect(options).to.haveOwnProperty('promoteLongs', false);\n          expect(options).to.haveOwnProperty('maxAwaitTimeMS', 5000);\n        });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the resumeAfter option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor does NOT have a saved operation time","when the maxWireVersion >= 7"],"updatePoint":{"line":199,"column":49,"index":9670},"line":199,"code":"          it('does NOT set the resumeAfter option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('resumeAfter');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAfter option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor does NOT have a saved operation time","when the maxWireVersion >= 7"],"updatePoint":{"line":202,"column":48,"index":9829},"line":202,"code":"          it('does NOT set the startAfter option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('startAfter');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAtOperationTime option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor does NOT have a saved operation time","when the maxWireVersion >= 7"],"updatePoint":{"line":205,"column":58,"index":9997},"line":205,"code":"          it('does NOT set the startAtOperationTime option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('startAtOperationTime');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the resumeAfter option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor does NOT have a saved operation time","when the maxWireVersion < 7"],"updatePoint":{"line":224,"column":49,"index":10792},"line":224,"code":"          it('does NOT set the resumeAfter option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('resumeAfter');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAfter option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor does NOT have a saved operation time","when the maxWireVersion < 7"],"updatePoint":{"line":227,"column":48,"index":10951},"line":227,"code":"          it('does NOT set the startAfter option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('startAfter');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"does NOT set the startAtOperationTime option","suites":["ChangeStreamCursor","get resumeOptions()","when there is no cached resumeToken","when the cursor does NOT have a saved operation time","when the maxWireVersion < 7"],"updatePoint":{"line":230,"column":58,"index":11119},"line":230,"code":"          it('does NOT set the startAtOperationTime option', function () {\n            expect(cursor.resumeOptions).not.to.haveOwnProperty('startAtOperationTime');\n          });","file":"unit/change_stream.test.ts","skipped":false,"dir":"test"},{"name":"returns an error","suites":["AuthProvider","#reauth","when the provider is already reauthenticating"],"updatePoint":{"line":10,"column":26,"index":383},"line":10,"code":"      it('returns an error', function () {\n        provider.reauth(context, error => {\n          expect(error).to.exist;\n          expect(error).to.be.instanceOf(MongoRuntimeError);\n          expect(error?.message).to.equal('Reauthentication already in progress.');\n        });\n      });","file":"unit/cmap/auth/auth_provider.test.ts","skipped":false,"dir":"test"},{"name":"performs no dns lookups","suites":["GSSAPI",".performGSSAPICanonicalizeHostName","when the mode is "],"updatePoint":{"line":21,"column":35,"index":796},"line":21,"code":"        it('performs no dns lookups', async () => {\n          const host = await performGSSAPICanonicalizeHostName(hostName, {\n            CANONICALIZE_HOST_NAME: mode\n          });\n          expect(host).to.equal(hostName);\n          expect(dns.lookup).to.not.be.called;\n          expect(dns.resolvePtr).to.not.be.called;\n          expect(dns.resolveCname).to.not.be.called;\n        });","file":"unit/cmap/auth/gssapi.test.ts","skipped":false,"dir":"test"},{"name":"performs a cname lookup","suites":["GSSAPI",".performGSSAPICanonicalizeHostName","when the mode is forward"],"updatePoint":{"line":38,"column":33,"index":1413},"line":38,"code":"      it('performs a cname lookup', async () => {\n        const host = await performGSSAPICanonicalizeHostName(hostName, {\n          CANONICALIZE_HOST_NAME: GSSAPICanonicalizationValue.forward\n        });\n        expect(host).to.equal(resolved);\n        expect(dns.lookup).to.not.be.called;\n        expect(dns.resolvePtr).to.not.be.called;\n        expect(dns.resolveCname).to.be.calledOnceWith(hostName);\n      });","file":"unit/cmap/auth/gssapi.test.ts","skipped":false,"dir":"test"},{"name":"uses the reverse lookup host","suites":["GSSAPI",".performGSSAPICanonicalizeHostName","when the mode is ","when the forward lookup succeeds","when the reverse lookup succeeds","when there is 1 result"],"updatePoint":{"line":64,"column":46,"index":2579},"line":64,"code":"              it('uses the reverse lookup host', async () => {\n                const host = await performGSSAPICanonicalizeHostName(hostName, {\n                  CANONICALIZE_HOST_NAME: mode\n                });\n                expect(host).to.equal(resolved);\n                expect(dns.lookup).to.be.calledOnceWith(hostName);\n                expect(dns.resolvePtr).to.be.calledOnceWith(lookedUp.address);\n                expect(dns.resolveCname).to.not.be.called;\n              });","file":"unit/cmap/auth/gssapi.test.ts","skipped":false,"dir":"test"},{"name":"uses the first found reverse lookup host","suites":["GSSAPI",".performGSSAPICanonicalizeHostName","when the mode is ","when the forward lookup succeeds","when the reverse lookup succeeds","when there is more than 1 result"],"updatePoint":{"line":82,"column":58,"index":3471},"line":82,"code":"              it('uses the first found reverse lookup host', async () => {\n                const host = await performGSSAPICanonicalizeHostName(hostName, {\n                  CANONICALIZE_HOST_NAME: mode\n                });\n                expect(host).to.equal(resolved);\n                expect(dns.lookup).to.be.calledOnceWith(hostName);\n                expect(dns.resolvePtr).to.be.calledOnceWith(lookedUp.address);\n                expect(dns.resolveCname).to.not.be.called;\n              });","file":"unit/cmap/auth/gssapi.test.ts","skipped":false,"dir":"test"},{"name":"falls back to a cname lookup","suites":["GSSAPI",".performGSSAPICanonicalizeHostName","when the mode is ","when the forward lookup succeeds","when the reverse lookup fails"],"updatePoint":{"line":103,"column":44,"index":4440},"line":103,"code":"            it('falls back to a cname lookup', async () => {\n              const host = await performGSSAPICanonicalizeHostName(hostName, {\n                CANONICALIZE_HOST_NAME: mode\n              });\n              expect(host).to.equal(cname);\n              expect(dns.lookup).to.be.calledOnceWith(hostName);\n              expect(dns.resolvePtr).to.be.calledOnceWith(lookedUp.address);\n              expect(dns.resolveCname).to.be.calledWith(hostName);\n            });","file":"unit/cmap/auth/gssapi.test.ts","skipped":false,"dir":"test"},{"name":"uses the provided host","suites":["GSSAPI",".performGSSAPICanonicalizeHostName","when the mode is ","when the forward lookup succeeds","when the reverse lookup is empty"],"updatePoint":{"line":120,"column":38,"index":5221},"line":120,"code":"            it('uses the provided host', async () => {\n              const host = await performGSSAPICanonicalizeHostName(hostName, {\n                CANONICALIZE_HOST_NAME: mode\n              });\n              expect(host).to.equal(hostName);\n              expect(dns.lookup).to.be.calledOnceWith(hostName);\n              expect(dns.resolvePtr).to.be.calledOnceWith(lookedUp.address);\n              expect(dns.resolveCname).to.not.be.called;\n            });","file":"unit/cmap/auth/gssapi.test.ts","skipped":false,"dir":"test"},{"name":"fails with the error","suites":["GSSAPI",".performGSSAPICanonicalizeHostName","when the mode is ","when the forward lookup fails"],"updatePoint":{"line":136,"column":34,"index":5903},"line":136,"code":"          it('fails with the error', async () => {\n            const error = await performGSSAPICanonicalizeHostName(hostName, {\n              CANONICALIZE_HOST_NAME: mode\n            }).catch(error => error);\n            expect(error.message).to.equal('failed');\n            expect(dns.lookup).to.be.calledOnceWith(hostName);\n            expect(dns.resolvePtr).to.not.be.called;\n            expect(dns.resolveCname).to.not.be.called;\n          });","file":"unit/cmap/auth/gssapi.test.ts","skipped":false,"dir":"test"},{"name":"falls back to the provided host name","suites":["GSSAPI",".resolveCname","when the cname call errors"],"updatePoint":{"line":156,"column":46,"index":6662},"line":156,"code":"      it('falls back to the provided host name', async () => {\n        const host = await resolveCname(hostName);\n        expect(host).to.equal(hostName);\n        expect(dns.resolveCname).to.be.calledOnceWith(hostName);\n      });","file":"unit/cmap/auth/gssapi.test.ts","skipped":false,"dir":"test"},{"name":"uses the result","suites":["GSSAPI",".resolveCname","when the cname call returns results","when there is one result"],"updatePoint":{"line":170,"column":27,"index":7207},"line":170,"code":"        it('uses the result', async () => {\n          const host = await resolveCname(hostName);\n          expect(host).to.equal(resolved);\n          expect(dns.resolveCname).to.be.calledOnceWith(hostName);\n        });","file":"unit/cmap/auth/gssapi.test.ts","skipped":false,"dir":"test"},{"name":"uses the first result","suites":["GSSAPI",".resolveCname","when the cname call returns results","when there is more than one result"],"updatePoint":{"line":183,"column":33,"index":7729},"line":183,"code":"        it('uses the first result', async () => {\n          const host = await resolveCname(hostName);\n          expect(host).to.equal(resolved);\n          expect(dns.resolveCname).to.be.calledOnceWith(hostName);\n        });","file":"unit/cmap/auth/gssapi.test.ts","skipped":false,"dir":"test"},{"name":"falls back to using the provided host","suites":["GSSAPI",".resolveCname","when the cname call returns no results"],"updatePoint":{"line":196,"column":47,"index":8210},"line":196,"code":"      it('falls back to using the provided host', async () => {\n        const host = await resolveCname(hostName);\n        expect(host).to.equal(hostName);\n        expect(dns.resolveCname).to.be.calledOnceWith(hostName);\n      });","file":"unit/cmap/auth/gssapi.test.ts","skipped":false,"dir":"test"},{"name":"prepare rejects with MongoInvalidArgumentError","suites":["class MongoDBOIDC","when an unknown OIDC provider name is set"],"updatePoint":{"line":5,"column":54,"index":293},"line":5,"code":"    it('prepare rejects with MongoInvalidArgumentError', async () => {\n      const oidc = new MongoDBOIDC();\n      const error = await oidc.prepare({}, new AuthContext({}, new MongoCredentials({\n        mechanism: 'MONGODB-OIDC',\n        mechanismProperties: {\n          PROVIDER_NAME: 'iLoveJavaScript'\n        }\n      }), {})).catch(error => error);\n      expect(error).to.be.instanceOf(MongoInvalidArgumentError);\n      expect(error).to.match(/workflow for provider/);\n    });","file":"unit/cmap/auth/mongodb_oidc.test.ts","skipped":false,"dir":"test"},{"name":"auth rejects with MongoInvalidArgumentError","suites":["class MongoDBOIDC","when an unknown OIDC provider name is set"],"updatePoint":{"line":16,"column":51,"index":770},"line":16,"code":"    it('auth rejects with MongoInvalidArgumentError', async () => {\n      const oidc = new MongoDBOIDC();\n      const error = await oidc.auth(new AuthContext({}, new MongoCredentials({\n        mechanism: 'MONGODB-OIDC',\n        mechanismProperties: {\n          PROVIDER_NAME: 'iLoveJavaScript'\n        }\n      }), {})).catch(error => error);\n      expect(error).to.be.instanceOf(MongoInvalidArgumentError);\n      expect(error).to.match(/workflow for provider/);\n    });","file":"unit/cmap/auth/mongodb_oidc.test.ts","skipped":false,"dir":"test"},{"name":"throws an error","suites":["AwsDeviceWorkFlow","#execute","when AWS_WEB_IDENTITY_TOKEN_FILE is not in the env"],"updatePoint":{"line":18,"column":25,"index":775},"line":18,"code":"      it('throws an error', async function () {\n        try {\n          await workflow.execute(connection, credentials);\n          expect.fail('workflow must fail without AWS_WEB_IDENTITY_TOKEN_FILE');\n        } catch (error) {\n          expect(error.message).to.include('AWS_WEB_IDENTITY_TOKEN_FILE');\n        }\n      });","file":"unit/cmap/auth/mongodb_oidc/aws_service_workflow.test.ts","skipped":false,"dir":"test"},{"name":"raises an error","suites":["CallbackLockCache","#getCallbacks","when a request callback does not exist"],"updatePoint":{"line":17,"column":25,"index":732},"line":17,"code":"      it('raises an error', function () {\n        try {\n          cache.getCallbacks(connection, credentials);\n          expect.fail('Must raise error when no request callback exists.');\n        } catch (error) {\n          expect(error).to.be.instanceOf(MongoInvalidArgumentError);\n          expect(error.message).to.include('Auth mechanism property REQUEST_TOKEN_CALLBACK is required');\n        }\n      });","file":"unit/cmap/auth/mongodb_oidc/callback_lock_cache.test.ts","skipped":false,"dir":"test"},{"name":"puts a new entry in the cache","suites":["CallbackLockCache","#getCallbacks","when no entry exists in the cache","when a refresh callback exists"],"updatePoint":{"line":70,"column":41,"index":2565},"line":70,"code":"        it('puts a new entry in the cache', function () {\n          expect(cache.entries).to.have.lengthOf(1);\n        });","file":"unit/cmap/auth/mongodb_oidc/callback_lock_cache.test.ts","skipped":false,"dir":"test"},{"name":"returns the new entry","suites":["CallbackLockCache","#getCallbacks","when no entry exists in the cache","when a refresh callback exists"],"updatePoint":{"line":73,"column":33,"index":2680},"line":73,"code":"        it('returns the new entry', function () {\n          expect(requestCallback).to.exist;\n          expect(refreshCallback).to.exist;\n          expect(callbackHash).to.exist;\n        });","file":"unit/cmap/auth/mongodb_oidc/callback_lock_cache.test.ts","skipped":false,"dir":"test"},{"name":"locks the callbacks","suites":["CallbackLockCache","#getCallbacks","when no entry exists in the cache","when a refresh callback exists"],"updatePoint":{"line":78,"column":31,"index":2869},"line":78,"code":"        it('locks the callbacks', async function () {\n          await Promise.allSettled([requestCallback(), requestCallback(), refreshCallback(), refreshCallback()]);\n          expect(requestSpy).to.have.been.calledTwice;\n          expect(refreshSpy).to.have.been.calledTwice;\n        });","file":"unit/cmap/auth/mongodb_oidc/callback_lock_cache.test.ts","skipped":false,"dir":"test"},{"name":"puts a new entry in the cache","suites":["CallbackLockCache","#getCallbacks","when no entry exists in the cache","when a refresh function does not exist"],"updatePoint":{"line":112,"column":41,"index":4093},"line":112,"code":"        it('puts a new entry in the cache', function () {\n          expect(cache.entries).to.have.lengthOf(1);\n        });","file":"unit/cmap/auth/mongodb_oidc/callback_lock_cache.test.ts","skipped":false,"dir":"test"},{"name":"returns the new entry","suites":["CallbackLockCache","#getCallbacks","when no entry exists in the cache","when a refresh function does not exist"],"updatePoint":{"line":115,"column":33,"index":4208},"line":115,"code":"        it('returns the new entry', function () {\n          expect(requestCallback).to.exist;\n          expect(refreshCallback).to.not.exist;\n          expect(callbackHash).to.exist;\n        });","file":"unit/cmap/auth/mongodb_oidc/callback_lock_cache.test.ts","skipped":false,"dir":"test"},{"name":"locks the callbacks","suites":["CallbackLockCache","#getCallbacks","when no entry exists in the cache","when a refresh function does not exist"],"updatePoint":{"line":120,"column":31,"index":4401},"line":120,"code":"        it('locks the callbacks', async function () {\n          await Promise.allSettled([requestCallback(), requestCallback()]);\n          expect(requestSpy).to.have.been.calledTwice;\n        });","file":"unit/cmap/auth/mongodb_oidc/callback_lock_cache.test.ts","skipped":false,"dir":"test"},{"name":"adds the token result","suites":["TokenEntryCache","#addEntry","when expiresInSeconds is provided"],"updatePoint":{"line":21,"column":31,"index":757},"line":21,"code":"      it('adds the token result', function () {\n        expect(entry.tokenResult).to.deep.equal(tokenResultWithExpiration);\n      });","file":"unit/cmap/auth/mongodb_oidc/token_entry_cache.test.ts","skipped":false,"dir":"test"},{"name":"adds the server result","suites":["TokenEntryCache","#addEntry","when expiresInSeconds is provided"],"updatePoint":{"line":24,"column":32,"index":892},"line":24,"code":"      it('adds the server result', function () {\n        expect(entry.serverInfo).to.deep.equal(serverResult);\n      });","file":"unit/cmap/auth/mongodb_oidc/token_entry_cache.test.ts","skipped":false,"dir":"test"},{"name":"creates an expiration","suites":["TokenEntryCache","#addEntry","when expiresInSeconds is provided"],"updatePoint":{"line":27,"column":31,"index":1012},"line":27,"code":"      it('creates an expiration', function () {\n        expect(entry.expiration).to.be.within(Date.now(), Date.now() + 100 * 1000);\n      });","file":"unit/cmap/auth/mongodb_oidc/token_entry_cache.test.ts","skipped":false,"dir":"test"},{"name":"sets an immediate expiration","suites":["TokenEntryCache","#addEntry","when expiresInSeconds is not provided"],"updatePoint":{"line":41,"column":38,"index":1570},"line":41,"code":"      it('sets an immediate expiration', function () {\n        expect(entry.expiration).to.be.at.most(Date.now());\n      });","file":"unit/cmap/auth/mongodb_oidc/token_entry_cache.test.ts","skipped":false,"dir":"test"},{"name":"sets an immediate expiration","suites":["TokenEntryCache","#addEntry","when expiresInSeconds is null"],"updatePoint":{"line":56,"column":38,"index":2128},"line":56,"code":"      it('sets an immediate expiration', function () {\n        expect(entry.expiration).to.be.at.most(Date.now());\n      });","file":"unit/cmap/auth/mongodb_oidc/token_entry_cache.test.ts","skipped":false,"dir":"test"},{"name":"clears the cache","suites":["TokenEntryCache","#clear"],"updatePoint":{"line":67,"column":24,"index":2481},"line":67,"code":"    it('clears the cache', function () {\n      expect(cache.entries.size).to.equal(0);\n    });","file":"unit/cmap/auth/mongodb_oidc/token_entry_cache.test.ts","skipped":false,"dir":"test"},{"name":"deletes all expired tokens from the cache 5 minutes before expiredInSeconds","suites":["TokenEntryCache","#deleteExpiredEntries"],"updatePoint":{"line":82,"column":83,"index":3097},"line":82,"code":"    it('deletes all expired tokens from the cache 5 minutes before expiredInSeconds', function () {\n      expect(cache.entries.size).to.equal(1);\n      expect(cache.getEntry('localhost', 'user', callbackHash)).to.not.exist;\n      expect(cache.getEntry('localhost', 'user2', callbackHash)).to.exist;\n    });","file":"unit/cmap/auth/mongodb_oidc/token_entry_cache.test.ts","skipped":false,"dir":"test"},{"name":"deletes the entry","suites":["TokenEntryCache","#deleteEntry"],"updatePoint":{"line":94,"column":25,"index":3625},"line":94,"code":"    it('deletes the entry', function () {\n      expect(cache.getEntry('localhost', 'user', callbackHash)).to.not.exist;\n    });","file":"unit/cmap/auth/mongodb_oidc/token_entry_cache.test.ts","skipped":false,"dir":"test"},{"name":"returns the entry","suites":["TokenEntryCache","#getEntry","when there is a matching entry"],"updatePoint":{"line":105,"column":27,"index":4130},"line":105,"code":"      it('returns the entry', function () {\n        expect(cache.getEntry('localhost', 'user', callbackHash)?.tokenResult).to.equal(tokenResultWithExpiration);\n      });","file":"unit/cmap/auth/mongodb_oidc/token_entry_cache.test.ts","skipped":false,"dir":"test"},{"name":"returns undefined","suites":["TokenEntryCache","#getEntry","when there is no matching entry"],"updatePoint":{"line":110,"column":27,"index":4369},"line":110,"code":"      it('returns undefined', function () {\n        expect(cache.getEntry('localhost', 'user1', callbackHash)).to.equal(undefined);\n      });","file":"unit/cmap/auth/mongodb_oidc/token_entry_cache.test.ts","skipped":false,"dir":"test"},{"name":"should make a deep copy of object of type: ","suites":["Command Monitoring Events - unit/cmap"],"updatePoint":{"line":56,"column":78,"index":902},"line":56,"code":"    it(`should make a deep copy of object of type: ${command.constructor.name}`, () => {\n      const ev = new CommandStartedEvent({\n        id: 'someId',\n        address: 'someHost'\n      }, command);\n      if (command instanceof Query) {\n        if (command.ns === 'admin.$cmd') {\n          expect(ev.command !== command.query.$query).to.equal(true);\n          for (const k in command.query.$query) {\n            expect(ev.command[k]).to.deep.equal(command.query.$query[k]);\n          }\n        } else {\n          expect(ev.command.filter !== command.query.$query).to.equal(true);\n          for (const k in command.query.$query) {\n            expect(ev.command.filter[k]).to.deep.equal(command.query.$query[k]);\n          }\n        }\n      } else if (command instanceof Msg) {\n        expect(ev.command !== command.command).to.equal(true);\n        expect(ev.command).to.deep.equal(command.command);\n      } else if (typeof command === 'object') {\n        if (command.ns === 'admin.$cmd') {\n          expect(ev.command !== command.query.$query).to.equal(true);\n          for (const k in command.query.$query) {\n            expect(ev.command[k]).to.deep.equal(command.query.$query[k]);\n          }\n        }\n      }\n    });","file":"unit/cmap/command_monitoring_events.test.js","skipped":false,"dir":"test"},{"name":"should wrap a basic query option","suites":["Command Monitoring Events - unit/cmap","CommandStartedEvent"],"updatePoint":{"line":91,"column":40,"index":2220},"line":91,"code":"    it('should wrap a basic query option', function () {\n      const db = 'test1';\n      const coll = 'testingQuery';\n      const query = new Query(`${db}.${coll}`, {\n        testCmd: 1,\n        fizz: 'buzz',\n        star: 'trek'\n      }, {});\n      const startEvent = new CommandStartedEvent(conn, query);\n      expect(startEvent).to.have.property('commandName', 'testCmd');\n      expect(startEvent).to.have.property('databaseName', db);\n      expect(startEvent).to.have.property('requestId', query.requestId);\n      expect(startEvent).to.have.property('connectionId').that.is.a('string');\n      expect(startEvent).to.have.property('command').that.deep.equals(query.query);\n    });","file":"unit/cmap/command_monitoring_events.test.js","skipped":false,"dir":"test"},{"name":"should upconvert a Query wrapping a command into the corresponding command","suites":["Command Monitoring Events - unit/cmap","CommandStartedEvent"],"updatePoint":{"line":106,"column":82,"index":2945},"line":106,"code":"    it('should upconvert a Query wrapping a command into the corresponding command', function () {\n      const db = 'admin';\n      const coll = '$cmd';\n      const query = new Query(`${db}.${coll}`, {\n        $query: {\n          testCmd: 1,\n          fizz: 'buzz',\n          star: 'trek',\n          batchSize: 0,\n          skip: 0\n        }\n      }, {});\n      const startEvent = new CommandStartedEvent(conn, query);\n      expect(startEvent).to.have.property('commandName', 'testCmd');\n      expect(startEvent).to.have.property('databaseName', db);\n      expect(startEvent).to.have.property('requestId', query.requestId);\n      expect(startEvent).to.have.property('connectionId').that.is.a('string');\n      expect(startEvent).to.have.property('command').that.deep.equals(query.query.$query);\n    });","file":"unit/cmap/command_monitoring_events.test.js","skipped":false,"dir":"test"},{"name":"should upconvert a Query wrapping a query into a find command","suites":["Command Monitoring Events - unit/cmap","CommandStartedEvent"],"updatePoint":{"line":125,"column":69,"index":3733},"line":125,"code":"    it('should upconvert a Query wrapping a query into a find command', function () {\n      const db = 'test5';\n      const coll = 'testingFindCommand';\n      const query = new Query(`${db}.${coll}`, {\n        $query: {\n          testCmd: 1,\n          fizz: 'buzz',\n          star: 'trek'\n        }\n      }, {});\n      const startEvent = new CommandStartedEvent(conn, query);\n      expect(startEvent).to.have.property('commandName', 'find');\n      expect(startEvent).to.have.property('databaseName', db);\n      expect(startEvent).to.have.property('requestId', query.requestId);\n      expect(startEvent).to.have.property('connectionId').that.is.a('string');\n      expect(startEvent).to.have.property('command').that.deep.equals({\n        find: coll,\n        filter: query.query.$query,\n        batchSize: 0,\n        skip: 0\n      });\n    });","file":"unit/cmap/command_monitoring_events.test.js","skipped":false,"dir":"test"},{"name":"throws an exception","suites":["commands","Response","#parse","when the message body is invalid","when the buffer is empty"],"updatePoint":{"line":20,"column":33,"index":573},"line":20,"code":"          it('throws an exception', function () {\n            const response = new Response(message, header, body);\n            expect(() => response.parse()).to.throw(RangeError, /outside buffer bounds/);\n          });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"throws an exception","suites":["commands","Response","#parse","when the message body is invalid","when numReturned is invalid"],"updatePoint":{"line":35,"column":33,"index":1128},"line":35,"code":"          it('throws an exception', function () {\n            const response = new Response(message, header, body);\n            expect(() => response.parse()).to.throw(RangeError, /Invalid array length/);\n          });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not throw an exception","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":52,"column":39,"index":1695},"line":52,"code":"        it('does not throw an exception', function () {\n          let error;\n          try {\n            new Response(message, header, body);\n          } catch (err) {\n            error = err;\n          }\n          expect(error).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"initializes the documents to an empty array","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":61,"column":55,"index":1969},"line":61,"code":"        it('initializes the documents to an empty array', function () {\n          const response = new Response(message, header, body);\n          expect(response.documents).to.be.empty;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set the responseFlags","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":65,"column":42,"index":2154},"line":65,"code":"        it('does not set the responseFlags', function () {\n          const response = new Response(message, header, body);\n          expect(response.responseFlags).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set the cursorNotFound flag","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":69,"column":48,"index":2353},"line":69,"code":"        it('does not set the cursorNotFound flag', function () {\n          const response = new Response(message, header, body);\n          expect(response.cursorNotFound).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set the cursorId","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":73,"column":37,"index":2542},"line":73,"code":"        it('does not set the cursorId', function () {\n          const response = new Response(message, header, body);\n          expect(response.cursorId).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set startingFrom","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":77,"column":37,"index":2725},"line":77,"code":"        it('does not set startingFrom', function () {\n          const response = new Response(message, header, body);\n          expect(response.startingFrom).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set numberReturned","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":81,"column":39,"index":2914},"line":81,"code":"        it('does not set numberReturned', function () {\n          const response = new Response(message, header, body);\n          expect(response.numberReturned).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set queryFailure","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":85,"column":37,"index":3103},"line":85,"code":"        it('does not set queryFailure', function () {\n          const response = new Response(message, header, body);\n          expect(response.queryFailure).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set shardConfigStale","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":89,"column":41,"index":3294},"line":89,"code":"        it('does not set shardConfigStale', function () {\n          const response = new Response(message, header, body);\n          expect(response.shardConfigStale).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set awaitCapable","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":93,"column":37,"index":3485},"line":93,"code":"        it('does not set awaitCapable', function () {\n          const response = new Response(message, header, body);\n          expect(response.awaitCapable).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"should destroy connections which have been closed","suites":["Connection Pool"],"updatePoint":{"line":48,"column":55,"index":993},"line":48,"code":"  it('should destroy connections which have been closed', function (done) {\n    mockMongod.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(mock.HELLO);\n      } else {\n        // destroy on any other command\n        request.connection.destroy();\n      }\n    });\n    const pool = new ConnectionPool(stubServer, {\n      maxPoolSize: 1,\n      hostAddress: mockMongod.hostAddress()\n    });\n    pool.ready();\n    const events = [];\n    pool.on('connectionClosed', event => events.push(event));\n    pool.checkOut((err, conn) => {\n      expect(err).to.not.exist;\n      conn.command(ns('admin.$cmd'), {\n        ping: 1\n      }, undefined, (err, result) => {\n        expect(err).to.exist;\n        expect(result).to.not.exist;\n        pool.checkIn(conn);\n        expect(events).to.have.length(1);\n        const closeEvent = events[0];\n        expect(closeEvent).have.property('reason').equal('error');\n      });\n    });\n    pool.withConnection(undefined, (err, conn, cb) => {\n      expect(err).to.not.exist;\n      cb();\n    }, () => {\n      pool.close(done);\n    });\n  });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"should propagate socket timeouts to connections","suites":["Connection Pool"],"updatePoint":{"line":85,"column":53,"index":2120},"line":85,"code":"  it('should propagate socket timeouts to connections', function (done) {\n    mockMongod.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(mock.HELLO);\n      } else {\n        // blackhole other requests\n      }\n    });\n    const pool = new ConnectionPool(stubServer, {\n      maxPoolSize: 1,\n      socketTimeoutMS: 200,\n      hostAddress: mockMongod.hostAddress()\n    });\n    pool.ready();\n    pool.withConnection((err, conn, cb) => {\n      expect(err).to.not.exist;\n      conn.command(ns('admin.$cmd'), {\n        ping: 1\n      }, undefined, (err, result) => {\n        expect(err).to.exist;\n        expect(result).to.not.exist;\n        expect(err).to.match(/timed out/);\n        cb();\n      });\n    }, () => pool.close(done));\n  });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"should clear timed out wait queue members if no connections are available","suites":["Connection Pool"],"updatePoint":{"line":112,"column":79,"index":2943},"line":112,"code":"  it('should clear timed out wait queue members if no connections are available', function (done) {\n    mockMongod.setMessageHandler(request => {\n      const doc = request.document;\n      if (isHello(doc)) {\n        request.reply(mock.HELLO);\n      }\n    });\n    const pool = new ConnectionPool(stubServer, {\n      maxPoolSize: 1,\n      waitQueueTimeoutMS: 200,\n      hostAddress: mockMongod.hostAddress()\n    });\n    pool.ready();\n    pool.checkOut((err, conn) => {\n      expect(err).to.not.exist;\n      expect(conn).to.exist;\n      pool.checkOut(err => {\n        expect(err).to.exist.and.be.instanceOf(WaitQueueTimeoutError);\n\n        // We can only process the wait queue with `checkIn` and `checkOut`, so we\n        // force the pool here to think there are no available connections, even though\n        // we are checking the connection back in. This simulates a slow leak where\n        // incoming requests outpace the ability of the queue to fully process cancelled\n        // wait queue members\n        sinon.stub(pool, 'availableConnectionCount').get(() => 0);\n        pool.checkIn(conn);\n        setImmediate(() => expect(pool).property('waitQueueSize').to.equal(0));\n        done();\n      });\n    });\n  });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"should respect the minPoolSizeCheckFrequencyMS option","suites":["Connection Pool","minPoolSize population"],"updatePoint":{"line":156,"column":61,"index":4475},"line":156,"code":"    it('should respect the minPoolSizeCheckFrequencyMS option', function () {\n      const pool = new ConnectionPool(stubServer, {\n        minPoolSize: 2,\n        minPoolSizeCheckFrequencyMS: 42,\n        hostAddress: mockMongod.hostAddress()\n      });\n      const ensureSpy = sinon.spy(pool, 'ensureMinPoolSize');\n\n      // return a fake connection that won't get identified as perished\n      const createConnStub = sinon.stub(pool, 'createConnection').yields(null, {\n        destroy: () => null,\n        generation: 0\n      });\n      pool.ready();\n\n      // expect ensureMinPoolSize to execute immediately\n      expect(ensureSpy).to.have.been.calledOnce;\n      expect(createConnStub).to.have.been.calledOnce;\n\n      // check that the successful connection return schedules another run\n      clock.tick(42);\n      expect(ensureSpy).to.have.been.calledTwice;\n      expect(createConnStub).to.have.been.calledTwice;\n\n      // check that the 2nd successful connection return schedules another run\n      // but don't expect to get a new connection since we are at minPoolSize\n      clock.tick(42);\n      expect(ensureSpy).to.have.been.calledThrice;\n      expect(createConnStub).to.have.been.calledTwice;\n\n      // check that the next scheduled check runs even after we're at minPoolSize\n      clock.tick(42);\n      expect(ensureSpy).to.have.callCount(4);\n      expect(createConnStub).to.have.been.calledTwice;\n    });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"should default minPoolSizeCheckFrequencyMS to 100ms","suites":["Connection Pool","minPoolSize population"],"updatePoint":{"line":191,"column":59,"index":5885},"line":191,"code":"    it('should default minPoolSizeCheckFrequencyMS to 100ms', function () {\n      const pool = new ConnectionPool(stubServer, {\n        minPoolSize: 2,\n        hostAddress: mockMongod.hostAddress()\n      });\n      const ensureSpy = sinon.spy(pool, 'ensureMinPoolSize');\n\n      // return a fake connection that won't get identified as perished\n      const createConnStub = sinon.stub(pool, 'createConnection').yields(null, {\n        destroy: () => null,\n        generation: 0\n      });\n      pool.ready();\n\n      // expect ensureMinPoolSize to execute immediately\n      expect(ensureSpy).to.have.been.calledOnce;\n      expect(createConnStub).to.have.been.calledOnce;\n\n      // check that the successful connection return schedules another run\n      clock.tick(100);\n      expect(ensureSpy).to.have.been.calledTwice;\n      expect(createConnStub).to.have.been.calledTwice;\n\n      // check that the 2nd successful connection return schedules another run\n      // but don't expect to get a new connection since we are at minPoolSize\n      clock.tick(100);\n      expect(ensureSpy).to.have.been.calledThrice;\n      expect(createConnStub).to.have.been.calledTwice;\n\n      // check that the next scheduled check runs even after we're at minPoolSize\n      clock.tick(100);\n      expect(ensureSpy).to.have.callCount(4);\n      expect(createConnStub).to.have.been.calledTwice;\n    });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"should manage a connection for a successful operation","suites":["Connection Pool","withConnection"],"updatePoint":{"line":227,"column":61,"index":7308},"line":227,"code":"    it('should manage a connection for a successful operation', function (done) {\n      mockMongod.setMessageHandler(request => {\n        const doc = request.document;\n        if (isHello(doc)) {\n          request.reply(mock.HELLO);\n        }\n      });\n      const pool = new ConnectionPool(stubServer, {\n        hostAddress: mockMongod.hostAddress()\n      });\n      pool.ready();\n      const callback = (err, result) => {\n        expect(err).to.not.exist;\n        expect(result).to.exist;\n        pool.close(done);\n      };\n      pool.withConnection((err, conn, cb) => {\n        expect(err).to.not.exist;\n        conn.command(ns('$admin.cmd'), {\n          [LEGACY_HELLO_COMMAND]: 1\n        }, undefined, (cmdErr, hello) => {\n          expect(cmdErr).to.not.exist;\n          cb(undefined, hello);\n        });\n      }, callback);\n    });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"should allow user interaction with an error","suites":["Connection Pool","withConnection"],"updatePoint":{"line":253,"column":51,"index":8135},"line":253,"code":"    it('should allow user interaction with an error', function (done) {\n      mockMongod.setMessageHandler(request => {\n        const doc = request.document;\n        if (isHello(doc)) {\n          request.connection.destroy();\n        }\n      });\n      const pool = new ConnectionPool(stubServer, {\n        waitQueueTimeoutMS: 200,\n        hostAddress: mockMongod.hostAddress()\n      });\n      pool.ready();\n      const callback = err => {\n        expect(err).to.exist;\n        expect(err).to.match(/closed/);\n        pool.close(done);\n      };\n      pool.withConnection(undefined, (err, conn, cb) => {\n        expect(err).to.exist;\n        expect(err).to.match(/closed/);\n        cb(err);\n      }, callback);\n    });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"should return an error to the original callback","suites":["Connection Pool","withConnection"],"updatePoint":{"line":276,"column":55,"index":8856},"line":276,"code":"    it('should return an error to the original callback', function (done) {\n      mockMongod.setMessageHandler(request => {\n        const doc = request.document;\n        if (isHello(doc)) {\n          request.reply(mock.HELLO);\n        }\n      });\n      const pool = new ConnectionPool(stubServer, {\n        hostAddress: mockMongod.hostAddress()\n      });\n      pool.ready();\n      const callback = (err, result) => {\n        expect(err).to.exist;\n        expect(result).to.not.exist;\n        expect(err).to.match(/my great error/);\n        pool.close(done);\n      };\n      pool.withConnection(undefined, (err, conn, cb) => {\n        expect(err).to.not.exist;\n        cb(new Error('my great error'));\n      }, callback);\n    });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"only reads the last message in the buffer","suites":["MessageStream","when the stream is for a monitoring connection"],"updatePoint":{"line":25,"column":49,"index":867},"line":25,"code":"    it('only reads the last message in the buffer', async function () {\n      const inputStream = bufferToStream(Buffer.concat([firstHello, secondHello, thirdHello]));\n      const messageStream = new MessageStream();\n      messageStream.isMonitoringConnection = true;\n      inputStream.pipe(messageStream);\n      const messages = await once(messageStream, 'message');\n      const msg = messages[0];\n      msg.parse();\n      expect(msg).to.have.property('documents').that.deep.equals([lastResponse]);\n      // Make sure there is nothing left in the buffer.\n      expect(messageStream.buffer.length).to.equal(0);\n    });","file":"unit/cmap/message_stream.test.ts","skipped":false,"dir":"test"},{"name":"does not read partial messages","suites":["MessageStream","when the stream is for a monitoring connection"],"updatePoint":{"line":37,"column":38,"index":1475},"line":37,"code":"    it('does not read partial messages', async function () {\n      const inputStream = bufferToStream(Buffer.concat([firstHello, secondHello, thirdHello, partial]));\n      const messageStream = new MessageStream();\n      messageStream.isMonitoringConnection = true;\n      inputStream.pipe(messageStream);\n      const messages = await once(messageStream, 'message');\n      const msg = messages[0];\n      msg.parse();\n      expect(msg).to.have.property('documents').that.deep.equals([lastResponse]);\n      // Make sure the buffer wasn't read to the end.\n      expect(messageStream.buffer.length).to.equal(5);\n    });","file":"unit/cmap/message_stream.test.ts","skipped":false,"dir":"test"},{"name":"reads all messages in the buffer","suites":["MessageStream","when the stream is not for a monitoring connection","when the messages are valid"],"updatePoint":{"line":64,"column":42,"index":2594},"line":64,"code":"      it('reads all messages in the buffer', async function () {\n        const inputStream = bufferToStream(Buffer.concat([firstHello, secondHello, thirdHello]));\n        const messageStream = new MessageStream();\n        inputStream.pipe(messageStream);\n        for await (const messages of on(messageStream, 'message')) {\n          messageCount++;\n          const msg = messages[0];\n          msg.parse();\n          expect(msg).to.have.property('documents').that.deep.equals([response]);\n          // Test will not complete until 3 messages processed.\n          if (messageCount === 3) {\n            return;\n          }\n        }\n      });","file":"unit/cmap/message_stream.test.ts","skipped":false,"dir":"test"},{"name":"emits an error","suites":["MessageStream","when the stream is not for a monitoring connection","when the messages are invalid","when the message size is negative"],"updatePoint":{"line":82,"column":26,"index":3352},"line":82,"code":"        it('emits an error', async function () {\n          const inputStream = bufferToStream(Buffer.from('ffffffff', 'hex'));\n          const messageStream = new MessageStream();\n          inputStream.pipe(messageStream);\n          const errors = await once(messageStream, 'error');\n          const err = errors[0];\n          expect(err).to.have.property('message').that.equals('Invalid message size: -1');\n        });","file":"unit/cmap/message_stream.test.ts","skipped":false,"dir":"test"},{"name":"emits an error","suites":["MessageStream","when the stream is not for a monitoring connection","when the messages are invalid","when the message size exceeds the bson maximum"],"updatePoint":{"line":92,"column":26,"index":3860},"line":92,"code":"        it('emits an error', async function () {\n          const inputStream = bufferToStream(Buffer.from('01000004', 'hex'));\n          const messageStream = new MessageStream();\n          inputStream.pipe(messageStream);\n          const errors = await once(messageStream, 'error');\n          const err = errors[0];\n          expect(err).to.have.property('message').that.equals('Invalid message size: 67108865, max allowed: 67108864');\n        });","file":"unit/cmap/message_stream.test.ts","skipped":false,"dir":"test"},{"name":"pushes the message","suites":["MessageStream","when writing to the message stream"],"updatePoint":{"line":104,"column":26,"index":4395},"line":104,"code":"    it('pushes the message', function (done) {\n      const readableStream = new Readable({\n        read() {\n          // ignore\n        }\n      });\n      const writeableStream = new Writable({\n        write: (chunk, _, callback) => {\n          readableStream.push(chunk);\n          callback();\n        }\n      });\n      readableStream.on('data', data => {\n        expect(data.toString('hex')).to.eql('370000000300000000000000dd0700000000000000220000001069736d6173746572000100000002246462000600000061646d696e0000');\n        done();\n      });\n      const messageStream = new MessageStream();\n      messageStream.pipe(writeableStream);\n      const command = new Msg('admin.$cmd', {\n        [LEGACY_HELLO_COMMAND]: 1\n      }, {\n        requestId: 3\n      });\n      messageStream.writeCommand(command, {\n        started: 0,\n        command: true,\n        noResponse: false,\n        raw: false,\n        requestId: command.requestId,\n        cb: err => {\n          done(err);\n        }\n      });\n    });","file":"unit/cmap/message_stream.test.ts","skipped":false,"dir":"test"},{"name":"defaults txnConnections to zero","suites":["ConnectionPoolMetrics","#constructor"],"updatePoint":{"line":12,"column":39,"index":293},"line":12,"code":"    it('defaults txnConnections to zero', function () {\n      expect(metrics).property('txnConnections').to.equal(0);\n    });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"defaults cursorConnections to zero","suites":["ConnectionPoolMetrics","#constructor"],"updatePoint":{"line":15,"column":42,"index":422},"line":15,"code":"    it('defaults cursorConnections to zero', function () {\n      expect(metrics).property('cursorConnections').to.equal(0);\n    });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"defaults otherConnections to zero","suites":["ConnectionPoolMetrics","#constructor"],"updatePoint":{"line":18,"column":41,"index":553},"line":18,"code":"    it('defaults otherConnections to zero', function () {\n      expect(metrics).property('otherConnections').to.equal(0);\n    });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"returns the metrics information","suites":["ConnectionPoolMetrics","#info"],"updatePoint":{"line":24,"column":39,"index":770},"line":24,"code":"    it('returns the metrics information', function () {\n      expect(metrics.info(5)).to.equal('Timed out while checking out a connection from connection pool: ' + 'maxPoolSize: 5, ' + 'connections in use by cursors: 0, ' + 'connections in use by transactions: 0, ' + 'connections in use by other operations: 0');\n    });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"increments the txnConnections count","suites":["ConnectionPoolMetrics","#markPinned","when the type is TXN"],"updatePoint":{"line":35,"column":45,"index":1360},"line":35,"code":"      it('increments the txnConnections count', function () {\n        expect(metrics).to.deep.equal({\n          txnConnections: 1,\n          cursorConnections: 0,\n          otherConnections: 0\n        });\n      });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"increments the cursorConnections count","suites":["ConnectionPoolMetrics","#markPinned","when the type is CURSOR"],"updatePoint":{"line":48,"column":48,"index":1759},"line":48,"code":"      it('increments the cursorConnections count', function () {\n        expect(metrics).to.deep.equal({\n          txnConnections: 0,\n          cursorConnections: 1,\n          otherConnections: 0\n        });\n      });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"increments the otherConnections count","suites":["ConnectionPoolMetrics","#markPinned","when the type is OTHER"],"updatePoint":{"line":61,"column":47,"index":2155},"line":61,"code":"      it('increments the otherConnections count', function () {\n        expect(metrics).to.deep.equal({\n          txnConnections: 0,\n          cursorConnections: 0,\n          otherConnections: 1\n        });\n      });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"decrements the txnConnections count","suites":["ConnectionPoolMetrics","#markUnpinned","when the type is TXN"],"updatePoint":{"line":77,"column":45,"index":2644},"line":77,"code":"      it('decrements the txnConnections count', function () {\n        expect(metrics).to.deep.equal({\n          txnConnections: -1,\n          cursorConnections: 0,\n          otherConnections: 0\n        });\n      });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"decrements the cursorConnections count","suites":["ConnectionPoolMetrics","#markUnpinned","when the type is CURSOR"],"updatePoint":{"line":90,"column":48,"index":3046},"line":90,"code":"      it('decrements the cursorConnections count', function () {\n        expect(metrics).to.deep.equal({\n          txnConnections: 0,\n          cursorConnections: -1,\n          otherConnections: 0\n        });\n      });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"decrements the otherConnections count","suites":["ConnectionPoolMetrics","#markUnpinned","when the type is OTHER"],"updatePoint":{"line":103,"column":47,"index":3445},"line":103,"code":"      it('decrements the otherConnections count', function () {\n        expect(metrics).to.deep.equal({\n          txnConnections: 0,\n          cursorConnections: 0,\n          otherConnections: -1\n        });\n      });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"sets the property","suites":["StreamDescription - unit/cmap",".new","when options are provided","when logicalSessionTimeoutMinutes is in the options"],"updatePoint":{"line":17,"column":29,"index":518},"line":17,"code":"        it('sets the property', function () {\n          expect(description.logicalSessionTimeoutMinutes).to.eq(5);\n        });","file":"unit/cmap/stream_description.test.js","skipped":false,"dir":"test"},{"name":"sets logicalSessionTimeoutMinutes to undefined","suites":["StreamDescription - unit/cmap",".new","when options are provided","when logicalSessionTimeoutMinutes is not in the options"],"updatePoint":{"line":23,"column":58,"index":837},"line":23,"code":"        it('sets logicalSessionTimeoutMinutes to undefined', function () {\n          expect(description).to.have.property('logicalSessionTimeoutMinutes', undefined);\n        });","file":"unit/cmap/stream_description.test.js","skipped":false,"dir":"test"},{"name":"sets the property to true","suites":["StreamDescription - unit/cmap",".new","when options are provided","when loadBalanced is in the options","when the value is true"],"updatePoint":{"line":33,"column":39,"index":1274},"line":33,"code":"          it('sets the property to true', function () {\n            expect(description.loadBalanced).to.be.true;\n          });","file":"unit/cmap/stream_description.test.js","skipped":false,"dir":"test"},{"name":"sets the property to false","suites":["StreamDescription - unit/cmap",".new","when options are provided","when loadBalanced is in the options","when the value is false"],"updatePoint":{"line":42,"column":40,"index":1617},"line":42,"code":"          it('sets the property to false', function () {\n            expect(description.loadBalanced).to.be.false;\n          });","file":"unit/cmap/stream_description.test.js","skipped":false,"dir":"test"},{"name":"sets loadBalanced to false","suites":["StreamDescription - unit/cmap",".new","when options are provided","when loadBalanced is not in the options"],"updatePoint":{"line":49,"column":38,"index":1903},"line":49,"code":"        it('sets loadBalanced to false', function () {\n          expect(description.loadBalanced).to.be.false;\n        });","file":"unit/cmap/stream_description.test.js","skipped":false,"dir":"test"},{"name":"defaults logicalSessionTimeoutMinutes to undefined","suites":["StreamDescription - unit/cmap",".new","when options are not provided"],"updatePoint":{"line":56,"column":60,"index":2185},"line":56,"code":"      it('defaults logicalSessionTimeoutMinutes to undefined', function () {\n        expect(description).to.have.property('logicalSessionTimeoutMinutes', undefined);\n      });","file":"unit/cmap/stream_description.test.js","skipped":false,"dir":"test"},{"name":"defaults loadBalanced to false","suites":["StreamDescription - unit/cmap",".new","when options are not provided"],"updatePoint":{"line":59,"column":40,"index":2341},"line":59,"code":"      it('defaults loadBalanced to false', function () {\n        expect(description.loadBalanced).to.be.false;\n      });","file":"unit/cmap/stream_description.test.js","skipped":false,"dir":"test"},{"name":"returns 3.6","suites":["Wire Protocol Constants","MIN_SUPPORTED_SERVER_VERSION"],"updatePoint":{"line":12,"column":19,"index":329},"line":12,"code":"    it('returns 3.6', function () {\n      expect(MIN_SUPPORTED_SERVER_VERSION).to.equal('3.6');\n    });","file":"unit/cmap/wire_protocol/constants.test.js","skipped":false,"dir":"test"},{"name":"returns 7.0","suites":["Wire Protocol Constants","MAX_SUPPORTED_SERVER_VERSION"],"updatePoint":{"line":17,"column":19,"index":496},"line":17,"code":"    it('returns 7.0', function () {\n      expect(MAX_SUPPORTED_SERVER_VERSION).to.equal('7.0');\n    });","file":"unit/cmap/wire_protocol/constants.test.js","skipped":false,"dir":"test"},{"name":"returns 6","suites":["Wire Protocol Constants","MIN_SUPPORTED_WIRE_VERSION"],"updatePoint":{"line":22,"column":17,"index":659},"line":22,"code":"    it('returns 6', function () {\n      expect(MIN_SUPPORTED_WIRE_VERSION).to.equal(6);\n    });","file":"unit/cmap/wire_protocol/constants.test.js","skipped":false,"dir":"test"},{"name":"returns 21","suites":["Wire Protocol Constants","MAX_SUPPORTED_WIRE_VERSION"],"updatePoint":{"line":27,"column":18,"index":817},"line":27,"code":"    it('returns 21', function () {\n      expect(MAX_SUPPORTED_WIRE_VERSION).to.equal(21);\n    });","file":"unit/cmap/wire_protocol/constants.test.js","skipped":false,"dir":"test"},{"name":"should error when createIndex fails","suites":["Collection","#createIndex"],"updatePoint":{"line":13,"column":43,"index":409},"line":13,"code":"    it('should error when createIndex fails', function (done) {\n      const ERROR_RESPONSE = {\n        ok: 0,\n        errmsg: 'WiredTigerIndex::insert: key too large to index, failing  1470 { : \"56f37cb8e4b089e98d52ab0e\", : \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa...\" }',\n        code: 17280\n      };\n      server.setMessageHandler(request => {\n        const doc = request.document;\n        if (isHello(doc)) {\n          return request.reply(Object.assign({}, HELLO));\n        }\n        if (doc.createIndexes) {\n          return request.reply(ERROR_RESPONSE);\n        }\n        if (doc.insert === 'system.indexes') {\n          return request.reply(ERROR_RESPONSE);\n        }\n      });\n      const client = new MongoClient(`mongodb://${server.uri()}`);\n      const close = e => client.close().then(() => done(e));\n      client.connect().then(() => client.db('foo').collection('bar')).then(coll => coll.createIndex({\n        a: 1\n      })).then(() => close('Expected createIndex to fail, but it succeeded'), e => {\n        try {\n          expect(e).to.have.property('ok', ERROR_RESPONSE.ok);\n          expect(e).to.have.property('errmsg', ERROR_RESPONSE.errmsg);\n          expect(e).to.have.property('code', ERROR_RESPONSE.code);\n          close(null);\n        } catch (err) {\n          close(err);\n        }\n      });\n    });","file":"unit/collection.test.ts","skipped":false,"dir":"test"},{"name":"should only set bypass document validation if strictly true in aggregate","suites":["Collection","#aggregate","bypass document validation"],"updatePoint":{"line":94,"column":82,"index":3190},"line":94,"code":"      it('should only set bypass document validation if strictly true in aggregate', function (done) {\n        testAggregate({\n          expected: true,\n          actual: true\n        }, done);\n      });","file":"unit/collection.test.ts","skipped":false,"dir":"test"},{"name":"should not set bypass document validation if not strictly true in aggregate","suites":["Collection","#aggregate","bypass document validation"],"updatePoint":{"line":100,"column":85,"index":3397},"line":100,"code":"      it('should not set bypass document validation if not strictly true in aggregate', function (done) {\n        testAggregate({\n          expected: undefined,\n          actual: false\n        }, done);\n      });","file":"unit/collection.test.ts","skipped":false,"dir":"test"},{"name":"should only set bypass document validation if strictly true in findOneAndUpdate","suites":["Collection","#findOneAndModify"],"updatePoint":{"line":153,"column":87,"index":4874},"line":153,"code":"    it('should only set bypass document validation if strictly true in findOneAndUpdate', function (done) {\n      testFindOneAndUpdate({\n        expected: true,\n        actual: true\n      }, done);\n    });","file":"unit/collection.test.ts","skipped":false,"dir":"test"},{"name":"should not set bypass document validation if not strictly true in findOneAndUpdate","suites":["Collection","#findOneAndModify"],"updatePoint":{"line":159,"column":90,"index":5083},"line":159,"code":"    it('should not set bypass document validation if not strictly true in findOneAndUpdate', function (done) {\n      testFindOneAndUpdate({\n        expected: undefined,\n        actual: false\n      }, done);\n    });","file":"unit/collection.test.ts","skipped":false,"dir":"test"},{"name":"should only set bypass document validation if strictly true in ordered bulkWrite","suites":["Collection","#bulkWrite"],"updatePoint":{"line":211,"column":88,"index":6601},"line":211,"code":"    it('should only set bypass document validation if strictly true in ordered bulkWrite', function (done) {\n      testBulkWrite({\n        expected: true,\n        actual: true,\n        ordered: true\n      }, done);\n    });","file":"unit/collection.test.ts","skipped":false,"dir":"test"},{"name":"should not set bypass document validation if not strictly true in ordered bulkWrite","suites":["Collection","#bulkWrite"],"updatePoint":{"line":218,"column":91,"index":6827},"line":218,"code":"    it('should not set bypass document validation if not strictly true in ordered bulkWrite', function (done) {\n      testBulkWrite({\n        expected: undefined,\n        actual: false,\n        ordered: true\n      }, done);\n    });","file":"unit/collection.test.ts","skipped":false,"dir":"test"},{"name":"should only set bypass document validation if strictly true in unordered bulkWrite","suites":["Collection","#bulkWrite"],"updatePoint":{"line":227,"column":90,"index":7117},"line":227,"code":"    it('should only set bypass document validation if strictly true in unordered bulkWrite', function (done) {\n      testBulkWrite({\n        expected: true,\n        actual: true,\n        ordered: false\n      }, done);\n    });","file":"unit/collection.test.ts","skipped":false,"dir":"test"},{"name":"should not set bypass document validation if not strictly true in unordered bulkWrite","suites":["Collection","#bulkWrite"],"updatePoint":{"line":234,"column":93,"index":7346},"line":234,"code":"    it('should not set bypass document validation if not strictly true in unordered bulkWrite', function (done) {\n      testBulkWrite({\n        expected: undefined,\n        actual: false,\n        ordered: false\n      }, done);\n    });","file":"unit/collection.test.ts","skipped":false,"dir":"test"},{"name":"","suites":["Connection String spec tests"],"updatePoint":{"line":15,"column":31,"index":759},"line":15,"code":"        it(`${test.description}`, function () {\n          if (skipTests.includes(test.description)) {\n            return this.skip();\n          }\n          executeUriValidationTest(test, testsThatDoNotThrowOnWarn.some(t => t === test.description));\n        });","file":"unit/connection_string.spec.test.ts","skipped":false,"dir":"test"},{"name":"should be false when readPreference is Primary","suites":["class Db","secondaryOk"],"updatePoint":{"line":7,"column":54,"index":339},"line":7,"code":"    it('should be false when readPreference is Primary', function () {\n      const options = {\n        readPreference: ReadPreference.PRIMARY\n      };\n      const mydb = new Db(client, 'mydb', options);\n      expect(mydb).property(secondary_ok).to.be.false;\n    });","file":"unit/db.test.ts","skipped":false,"dir":"test"},{"name":"should be true when readPreference is Primary Preferred","suites":["class Db","secondaryOk"],"updatePoint":{"line":14,"column":63,"index":614},"line":14,"code":"    it('should be true when readPreference is Primary Preferred', function () {\n      const options = {\n        readPreference: ReadPreference.PRIMARY_PREFERRED\n      };\n      const mydb = new Db(client, 'mydb', options);\n      expect(mydb).property(secondary_ok).to.be.true;\n    });","file":"unit/db.test.ts","skipped":false,"dir":"test"},{"name":"should be true when readPreference is Secondary","suites":["class Db","secondaryOk"],"updatePoint":{"line":21,"column":55,"index":890},"line":21,"code":"    it('should be true when readPreference is Secondary', function () {\n      const options = {\n        readPreference: ReadPreference.SECONDARY\n      };\n      const mydb = new Db(client, 'mydb', options);\n      expect(mydb).property(secondary_ok).to.be.true;\n    });","file":"unit/db.test.ts","skipped":false,"dir":"test"},{"name":"should be true when readPreference is Secondary Preferred","suites":["class Db","secondaryOk"],"updatePoint":{"line":28,"column":65,"index":1168},"line":28,"code":"    it('should be true when readPreference is Secondary Preferred', function () {\n      const options = {\n        readPreference: ReadPreference.SECONDARY_PREFERRED\n      };\n      const mydb = new Db(client, 'mydb', options);\n      expect(mydb).property(secondary_ok).to.be.true;\n    });","file":"unit/db.test.ts","skipped":false,"dir":"test"},{"name":"should be true when readPreference is Nearest","suites":["class Db","secondaryOk"],"updatePoint":{"line":35,"column":53,"index":1444},"line":35,"code":"    it('should be true when readPreference is Nearest', function () {\n      const options = {\n        readPreference: ReadPreference.NEAREST\n      };\n      const mydb = new Db(client, 'mydb', options);\n      expect(mydb).property(secondary_ok).to.be.true;\n    });","file":"unit/db.test.ts","skipped":false,"dir":"test"},{"name":"should export all and only the expected keys in expected_exports","suites":["mongodb entrypoint"],"updatePoint":{"line":15,"column":70,"index":3049},"line":15,"code":"  it('should export all and only the expected keys in expected_exports', () => {\n    expect(sorted(Object.keys(mongodb), byStrings)).to.deep.equal(sorted(EXPECTED_EXPORTS, byStrings));\n  });","file":"unit/index.test.ts","skipped":false,"dir":"test"},{"name":"should export keys added by ts-node as undefined","suites":["mongodb entrypoint"],"updatePoint":{"line":18,"column":54,"index":3224},"line":18,"code":"  it('should export keys added by ts-node as undefined', () => {\n    // If the array is empty, this test would be a no-op so we should remove it\n    expect(TS_NODE_EXPORTS).to.have.length.greaterThan(0);\n    for (const tsNodeExportKey of TS_NODE_EXPORTS) {\n      expect(mongodb).to.have.property(tsNodeExportKey, undefined);\n    }\n  });","file":"unit/index.test.ts","skipped":false,"dir":"test"},{"name":"MongoClient should always freeze public options","suites":["MongoOptions"],"updatePoint":{"line":40,"column":53,"index":739},"line":40,"code":"  it('MongoClient should always freeze public options', function () {\n    const client = new MongoClient('mongodb://localhost:27017');\n    expect(client.options).to.be.frozen;\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"programmatic options should override URI options","suites":["MongoOptions"],"updatePoint":{"line":44,"column":54,"index":922},"line":44,"code":"  it('programmatic options should override URI options', function () {\n    const options = parseOptions('mongodb://localhost:27017/test?directConnection=true', {\n      directConnection: false\n    });\n    expect(options.directConnection).to.be.false;\n    expect(options.hosts).has.length(1);\n    expect(options.dbName).to.equal('test');\n    expect(options.prototype).to.not.exist;\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should rename tls options correctly","suites":["MongoOptions"],"updatePoint":{"line":53,"column":41,"index":1295},"line":53,"code":"  it('should rename tls options correctly', function () {\n    const filename = `${os.tmpdir()}/tmp.pem`;\n    fs.closeSync(fs.openSync(filename, 'w'));\n    const options = parseOptions('mongodb://localhost:27017/?ssl=true', {\n      tlsCertificateKeyFile: filename,\n      tlsCertificateFile: filename,\n      tlsCAFile: filename,\n      sslCRL: filename,\n      tlsCertificateKeyFilePassword: 'tlsCertificateKeyFilePassword',\n      sslValidate: false\n    });\n    fs.unlinkSync(filename);\n\n    /*\n     * If set TLS enabled, equivalent to setting the ssl option.\n     *\n     * ### Additional options:\n     *\n     * |    nodejs option     | MongoDB equivalent                                 | type                                   |\n     * |:---------------------|----------------------------------------------------|:---------------------------------------|\n     * | `ca`                 | sslCA, tlsCAFile                                   | `string \\| Buffer \\| Buffer[]`         |\n     * | `crl`                | sslCRL                                             | `string \\| Buffer \\| Buffer[]`         |\n     * | `cert`               | sslCert, tlsCertificateFile                        | `string \\| Buffer \\| Buffer[]`         |\n     * | `key`                | sslKey, tlsCertificateKeyFile                      | `string \\| Buffer \\| KeyObject[]`      |\n     * | `passphrase`         | sslPass, tlsCertificateKeyFilePassword             | `string`                               |\n     * | `rejectUnauthorized` | sslValidate                                        | `boolean`                              |\n     *\n     */\n    expect(options).to.not.have.property('tlsCertificateKeyFile');\n    expect(options).to.not.have.property('tlsCAFile');\n    expect(options).to.not.have.property('sslCRL');\n    expect(options).to.not.have.property('tlsCertificateKeyFilePassword');\n    expect(options).has.property('ca', '');\n    expect(options).has.property('crl', '');\n    expect(options).has.property('cert', '');\n    expect(options).has.property('key');\n    expect(options.key).has.length(0);\n    expect(options).has.property('passphrase', 'tlsCertificateKeyFilePassword');\n    expect(options).has.property('rejectUnauthorized', false);\n    expect(options).has.property('tls', true);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should parse all options from the options object","suites":["MongoOptions"],"updatePoint":{"line":178,"column":54,"index":5577},"line":178,"code":"  it('should parse all options from the options object', function () {\n    const options = parseOptions('mongodb://localhost:27017/', ALL_OPTIONS);\n    // Check consolidated options\n    expect(options).has.property('writeConcern');\n    expect(options.writeConcern).has.property('w', 2);\n    expect(options.writeConcern).has.property('j', true);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should parse all options from the URI string","suites":["MongoOptions"],"updatePoint":{"line":186,"column":50,"index":6757},"line":186,"code":"  it('should parse all options from the URI string', function () {\n    const options = parseOptions(allURIOptions);\n    expect(options).has.property('zlibCompressionLevel', 2);\n    expect(options).has.property('writeConcern');\n    expect(options.writeConcern).has.property('w', 'majority');\n    expect(options.writeConcern).has.property('wtimeout', 2);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should ignore undefined and null values in the options object","suites":["MongoOptions"],"updatePoint":{"line":193,"column":67,"index":7133},"line":193,"code":"  it('should ignore undefined and null values in the options object', function () {\n    const options = parseOptions('mongodb://localhost:27017/', {\n      maxPoolSize: null,\n      servername: undefined,\n      randomopt: null,\n      otherrandomopt: undefined\n    });\n\n    // test valid option key with default value\n    expect(options).to.have.property('maxPoolSize', 100);\n\n    // test valid option key without default value\n    expect(options).not.to.have.property('servername');\n\n    // test invalid option keys that are null/undefined\n    expect(options).not.to.have.property('randomopt');\n    expect(options).not.to.have.property('otherrandomopt');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should throw an error on unrecognized keys in the options object if they are defined","suites":["MongoOptions"],"updatePoint":{"line":211,"column":90,"index":7815},"line":211,"code":"  it('should throw an error on unrecognized keys in the options object if they are defined', function () {\n    expect(() => parseOptions('mongodb://localhost:27017/', {\n      randomopt: 'test'\n    })).to.throw(MongoParseError, 'option randomopt is not supported');\n    expect(() => parseOptions('mongodb://localhost:27017/', {\n      randomopt: 'test',\n      randomopt2: 'test'\n    })).to.throw(MongoParseError, 'options randomopt, randomopt2 are not supported');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"srvHost saved to options for later resolution","suites":["MongoOptions"],"updatePoint":{"line":220,"column":51,"index":8245},"line":220,"code":"  it('srvHost saved to options for later resolution', function () {\n    const options = parseOptions('mongodb+srv://server.example.com/');\n    expect(options).has.property('srvHost', 'server.example.com');\n    expect(options).has.property('tls', true);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"ssl= can be used to set tls=false","suites":["MongoOptions"],"updatePoint":{"line":225,"column":39,"index":8492},"line":225,"code":"  it('ssl= can be used to set tls=false', function () {\n    const options = parseOptions('mongodb+srv://server.example.com/?ssl=false');\n    expect(options).has.property('srvHost', 'server.example.com');\n    expect(options).has.property('tls', false);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"tls= can be used to set tls=false","suites":["MongoOptions"],"updatePoint":{"line":230,"column":39,"index":8750},"line":230,"code":"  it('tls= can be used to set tls=false', function () {\n    const options = parseOptions('mongodb+srv://server.example.com/?tls=false');\n    expect(options).has.property('srvHost', 'server.example.com');\n    expect(options).has.property('tls', false);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"ssl= can be used to set tls=true","suites":["MongoOptions"],"updatePoint":{"line":235,"column":38,"index":9007},"line":235,"code":"  it('ssl= can be used to set tls=true', function () {\n    const options = parseOptions('mongodb+srv://server.example.com/?ssl=true');\n    expect(options).has.property('srvHost', 'server.example.com');\n    expect(options).has.property('tls', true);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"tls= can be used to set tls=true","suites":["MongoOptions"],"updatePoint":{"line":240,"column":38,"index":9262},"line":240,"code":"  it('tls= can be used to set tls=true', function () {\n    const options = parseOptions('mongodb+srv://server.example.com/?tls=true');\n    expect(options).has.property('srvHost', 'server.example.com');\n    expect(options).has.property('tls', true);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports ReadPreference option in url","suites":["MongoOptions"],"updatePoint":{"line":245,"column":43,"index":9522},"line":245,"code":"  it('supports ReadPreference option in url', function () {\n    const options = parseOptions('mongodb://localhost/?readPreference=nearest');\n    expect(options.readPreference).to.be.an.instanceof(ReadPreference);\n    expect(options.readPreference.mode).to.equal('nearest');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports ReadPreference option in object plain","suites":["MongoOptions"],"updatePoint":{"line":250,"column":52,"index":9811},"line":250,"code":"  it('supports ReadPreference option in object plain', function () {\n    const options = parseOptions('mongodb://localhost', {\n      readPreference: {\n        mode: 'nearest',\n        hedge: {\n          enabled: true\n        }\n      }\n    });\n    expect(options.readPreference).to.be.an.instanceof(ReadPreference);\n    expect(options.readPreference.mode).to.equal('nearest');\n    expect(options.readPreference.hedge).to.include({\n      enabled: true\n    });\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports ReadPreference option in object proper class","suites":["MongoOptions"],"updatePoint":{"line":265,"column":59,"index":10282},"line":265,"code":"  it('supports ReadPreference option in object proper class', function () {\n    const tag = {\n      rack: 1\n    };\n    const options = parseOptions('mongodb://localhost', {\n      readPreference: new ReadPreference('nearest', [tag], {\n        maxStalenessSeconds: 20\n      })\n    });\n    expect(options.readPreference).to.be.an.instanceof(ReadPreference);\n    expect(options.readPreference.mode).to.equal('nearest');\n    expect(options.readPreference.tags).to.be.an('array').that.includes(tag);\n    expect(options.readPreference.maxStalenessSeconds).to.equal(20);\n    // maxStalenessSeconds sets the minWireVersion\n    expect(options.readPreference.minWireVersion).to.be.at.least(5);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should throw when given a readpreference options with an unsupported type","suites":["MongoOptions"],"updatePoint":{"line":281,"column":79,"index":10991},"line":281,"code":"  it('should throw when given a readpreference options with an unsupported type', () => {\n    expect(() => new MongoClient('mongodb://blah', {\n      readPreference: 34\n    })).to.throw(MongoParseError, /Unknown ReadPreference value/);\n    // Passing readPreference in URI will always be string\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports WriteConcern option in url","suites":["MongoOptions"],"updatePoint":{"line":288,"column":41,"index":11254},"line":288,"code":"  it('supports WriteConcern option in url', function () {\n    const options = parseOptions('mongodb://localhost/?w=3');\n    expect(options.writeConcern).to.be.an.instanceof(WriteConcern);\n    expect(options.writeConcern.w).to.equal(3);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports WriteConcern option in object plain","suites":["MongoOptions"],"updatePoint":{"line":293,"column":50,"index":11505},"line":293,"code":"  it('supports WriteConcern option in object plain', function () {\n    const options = parseOptions('mongodb://localhost', {\n      writeConcern: {\n        w: 'majority',\n        wtimeoutMS: 300\n      }\n    });\n    expect(options.writeConcern).to.be.an.instanceof(WriteConcern);\n    expect(options.writeConcern.w).to.equal('majority');\n    expect(options.writeConcern.wtimeout).to.equal(300);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports WriteConcern option in object proper class","suites":["MongoOptions"],"updatePoint":{"line":304,"column":57,"index":11910},"line":304,"code":"  it('supports WriteConcern option in object proper class', function () {\n    const options = parseOptions('mongodb://localhost', {\n      writeConcern: new WriteConcern(5, 200, true)\n    });\n    expect(options.writeConcern).to.be.an.instanceof(WriteConcern);\n    expect(options.writeConcern.w).to.equal(5);\n    expect(options.writeConcern.wtimeout).to.equal(200);\n    expect(options.writeConcern.j).to.equal(true);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports ReadConcern option in url","suites":["MongoOptions"],"updatePoint":{"line":313,"column":40,"index":12314},"line":313,"code":"  it('supports ReadConcern option in url', function () {\n    const options = parseOptions('mongodb://localhost/?readConcernLevel=available');\n    expect(options.readConcern).to.be.an.instanceof(ReadConcern);\n    expect(options.readConcern.level).to.equal('available');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports ReadConcern option in object plain","suites":["MongoOptions"],"updatePoint":{"line":318,"column":49,"index":12598},"line":318,"code":"  it('supports ReadConcern option in object plain', function () {\n    const options = parseOptions('mongodb://localhost', {\n      readConcern: {\n        level: 'linearizable'\n      }\n    });\n    expect(options.readConcern).to.be.an.instanceof(ReadConcern);\n    expect(options.readConcern.level).to.equal('linearizable');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports ReadConcern option in object proper class","suites":["MongoOptions"],"updatePoint":{"line":327,"column":56,"index":12932},"line":327,"code":"  it('supports ReadConcern option in object proper class', function () {\n    const options = parseOptions('mongodb://localhost', {\n      readConcern: new ReadConcern('snapshot')\n    });\n    expect(options.readConcern).to.be.an.instanceof(ReadConcern);\n    expect(options.readConcern.level).to.equal('snapshot');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports Credentials option in url","suites":["MongoOptions"],"updatePoint":{"line":334,"column":40,"index":13234},"line":334,"code":"  it('supports Credentials option in url', function () {\n    const options = parseOptions('mongodb://USERNAME:PASSWORD@localhost/');\n    expect(options.credentials).to.be.an.instanceof(MongoCredentials);\n    expect(options.credentials.username).to.equal('USERNAME');\n    expect(options.credentials.password).to.equal('PASSWORD');\n    expect(options.credentials.source).to.equal('admin');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports Credentials option in url with db","suites":["MongoOptions"],"updatePoint":{"line":341,"column":48,"index":13636},"line":341,"code":"  it('supports Credentials option in url with db', function () {\n    const options = parseOptions('mongodb://USERNAME:PASSWORD@localhost/foo');\n    expect(options.credentials).to.be.an.instanceof(MongoCredentials);\n    expect(options.credentials.username).to.equal('USERNAME');\n    expect(options.credentials.password).to.equal('PASSWORD');\n    expect(options.credentials.source).to.equal('foo');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports Credentials option in auth object plain","suites":["MongoOptions"],"updatePoint":{"line":348,"column":54,"index":14045},"line":348,"code":"  it('supports Credentials option in auth object plain', function () {\n    const options = parseOptions('mongodb://localhost/', {\n      auth: {\n        username: 'USERNAME',\n        password: 'PASSWORD'\n      }\n    });\n    expect(options.credentials).to.be.an.instanceof(MongoCredentials);\n    expect(options.credentials.username).to.equal('USERNAME');\n    expect(options.credentials.password).to.equal('PASSWORD');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"transforms tlsAllowInvalidCertificates and tlsAllowInvalidHostnames correctly","suites":["MongoOptions"],"updatePoint":{"line":359,"column":83,"index":14496},"line":359,"code":"  it('transforms tlsAllowInvalidCertificates and tlsAllowInvalidHostnames correctly', function () {\n    const optionsTrue = parseOptions('mongodb://localhost/', {\n      tlsAllowInvalidCertificates: true,\n      tlsAllowInvalidHostnames: true\n    });\n    expect(optionsTrue.rejectUnauthorized).to.equal(false);\n    expect(optionsTrue.checkServerIdentity).to.be.a('function');\n    expect(optionsTrue.checkServerIdentity()).to.equal(undefined);\n    const optionsFalse = parseOptions('mongodb://localhost/', {\n      tlsAllowInvalidCertificates: false,\n      tlsAllowInvalidHostnames: false\n    });\n    expect(optionsFalse.rejectUnauthorized).to.equal(true);\n    expect(optionsFalse.checkServerIdentity).to.equal(undefined);\n    const optionsUndefined = parseOptions('mongodb://localhost/');\n    expect(optionsUndefined.rejectUnauthorized).to.equal(undefined);\n    expect(optionsUndefined.checkServerIdentity).to.equal(undefined);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"correctly sets the cert and key if only tlsCertificateKeyFile is provided","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":388,"column":81,"index":15799},"line":388,"code":"    it('correctly sets the cert and key if only tlsCertificateKeyFile is provided', function () {\n      const optsFromObject = parseOptions('mongodb://localhost/', {\n        tlsCertificateKeyFile: 'testCertKey.pem'\n      });\n      expect(optsFromObject).to.have.property('cert', 'cert key');\n      expect(optsFromObject).to.have.property('key', 'cert key');\n      const optsFromUri = parseOptions('mongodb://localhost?tlsCertificateKeyFile=testCertKey.pem');\n      expect(optsFromUri).to.have.property('cert', 'cert key');\n      expect(optsFromUri).to.have.property('key', 'cert key');\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"correctly sets the cert and key if both tlsCertificateKeyFile and tlsCertificateFile is provided","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":398,"column":104,"index":16416},"line":398,"code":"    it('correctly sets the cert and key if both tlsCertificateKeyFile and tlsCertificateFile is provided', function () {\n      const optsFromObject = parseOptions('mongodb://localhost/', {\n        tlsCertificateKeyFile: 'testKey.pem',\n        tlsCertificateFile: 'testCert.pem'\n      });\n      expect(optsFromObject).to.have.property('cert', 'test cert');\n      expect(optsFromObject).to.have.property('key', 'test key');\n      const optsFromUri = parseOptions('mongodb://localhost?tlsCertificateKeyFile=testKey.pem&tlsCertificateFile=testCert.pem');\n      expect(optsFromUri).to.have.property('cert', 'test cert');\n      expect(optsFromUri).to.have.property('key', 'test key');\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"throws an error if multiple tls parameters are not all set to the same value","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":410,"column":82,"index":17087},"line":410,"code":"  it('throws an error if multiple tls parameters are not all set to the same value', () => {\n    expect(() => parseOptions('mongodb://localhost?tls=true&tls=false')).to.throw('All values of tls/ssl must be the same.');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"throws an error if multiple ssl parameters are not all set to the same value","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":413,"column":82,"index":17312},"line":413,"code":"  it('throws an error if multiple ssl parameters are not all set to the same value', () => {\n    expect(() => parseOptions('mongodb://localhost?ssl=true&ssl=false')).to.throw('All values of tls/ssl must be the same.');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"throws an error if tls and ssl parameters are not all set to the same value","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":416,"column":81,"index":17536},"line":416,"code":"  it('throws an error if tls and ssl parameters are not all set to the same value', () => {\n    expect(() => parseOptions('mongodb://localhost?tls=true&ssl=false')).to.throw('All values of tls/ssl must be the same.');\n    expect(() => parseOptions('mongodb://localhost?tls=false&ssl=true')).to.throw('All values of tls/ssl must be the same.');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"correctly sets tls if multiple tls parameters are all set to the same value","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":420,"column":81,"index":17886},"line":420,"code":"  it('correctly sets tls if multiple tls parameters are all set to the same value', () => {\n    expect(parseOptions('mongodb://localhost?tls=true&tls=true')).to.have.property('tls', true);\n    expect(parseOptions('mongodb://localhost?tls=false&tls=false')).to.have.property('tls', false);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"correctly sets tls if multiple ssl parameters are all set to the same value","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":424,"column":81,"index":18181},"line":424,"code":"  it('correctly sets tls if multiple ssl parameters are all set to the same value', () => {\n    expect(parseOptions('mongodb://localhost?ssl=true&ssl=true')).to.have.property('tls', true);\n    expect(parseOptions('mongodb://localhost?ssl=false&ssl=false')).to.have.property('tls', false);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"correctly sets tls if tls and ssl parameters are all set to the same value","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":428,"column":80,"index":18475},"line":428,"code":"  it('correctly sets tls if tls and ssl parameters are all set to the same value', () => {\n    expect(parseOptions('mongodb://localhost?ssl=true&tls=true')).to.have.property('tls', true);\n    expect(parseOptions('mongodb://localhost?ssl=false&tls=false')).to.have.property('tls', false);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"transforms tlsInsecure correctly","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":432,"column":38,"index":18727},"line":432,"code":"  it('transforms tlsInsecure correctly', function () {\n    const optionsTrue = parseOptions('mongodb://localhost/', {\n      tlsInsecure: true\n    });\n    expect(optionsTrue.rejectUnauthorized).to.equal(false);\n    expect(optionsTrue.checkServerIdentity).to.be.a('function');\n    expect(optionsTrue.checkServerIdentity()).to.equal(undefined);\n    const optionsFalse = parseOptions('mongodb://localhost/', {\n      tlsInsecure: false\n    });\n    expect(optionsFalse.rejectUnauthorized).to.equal(true);\n    expect(optionsFalse.checkServerIdentity).to.equal(undefined);\n    const optionsUndefined = parseOptions('mongodb://localhost/');\n    expect(optionsUndefined.rejectUnauthorized).to.equal(undefined);\n    expect(optionsUndefined.checkServerIdentity).to.equal(undefined);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"can be set when passed in as an array in the options object","suites":["MongoOptions","compressors"],"updatePoint":{"line":449,"column":67,"index":19573},"line":449,"code":"    it('can be set when passed in as an array in the options object', function () {\n      const clientViaOpt = new MongoClient('mongodb://localhost', {\n        compressors: ['zlib', 'snappy']\n      });\n      expect(clientViaOpt.options).to.have.property('compressors').deep.equal(['zlib', 'snappy']);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"can be set when passed in as a comma-delimited string in the options object or URI","suites":["MongoOptions","compressors"],"updatePoint":{"line":455,"column":90,"index":19905},"line":455,"code":"    it('can be set when passed in as a comma-delimited string in the options object or URI', function () {\n      const clientViaOpt = new MongoClient('mongodb://localhost', {\n        compressors: 'zlib,snappy'\n      });\n      const clientViaUri = new MongoClient('mongodb://localhost?compressors=zlib,snappy');\n      expect(clientViaOpt.options).to.have.property('compressors').deep.equal(['zlib', 'snappy']);\n      expect(clientViaUri.options).to.have.property('compressors').deep.equal(['zlib', 'snappy']);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should validate that a string or an array of strings is provided as input","suites":["MongoOptions","compressors"],"updatePoint":{"line":463,"column":81,"index":20413},"line":463,"code":"    it('should validate that a string or an array of strings is provided as input', function () {\n      expect(() => new MongoClient('mongodb://localhost', {\n        compressors: {\n          zlib: true\n        }\n      })).to.throw(/^compressors must be an array or a comma-delimited list of strings/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if an unrecognized compressor is specified","suites":["MongoOptions","compressors"],"updatePoint":{"line":470,"column":72,"index":20714},"line":470,"code":"    it('should throw an error if an unrecognized compressor is specified', function () {\n      const expectedErrRegex = /not a valid compression mechanism/;\n      expect(() => new MongoClient('mongodb://localhost', {\n        compressors: ['invalid']\n      })).to.throw(expectedErrRegex);\n      expect(() => new MongoClient('mongodb://localhost', {\n        compressors: 'invalid'\n      })).to.throw(expectedErrRegex);\n      expect(() => new MongoClient('mongodb://localhost?compressors=invalid')).to.throw(expectedErrRegex);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"is supported as a client option when it is a valid ServerApiVersion string","suites":["MongoOptions","serverApi"],"updatePoint":{"line":482,"column":82,"index":21300},"line":482,"code":"    it('is supported as a client option when it is a valid ServerApiVersion string', function () {\n      const validVersions = Object.values(ServerApiVersion);\n      expect(validVersions.length).to.be.at.least(1);\n      for (const version of validVersions) {\n        const result = parseOptions('mongodb://localhost/', {\n          serverApi: version\n        });\n        expect(result).to.have.property('serverApi').deep.equal({\n          version\n        });\n      }\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"is supported as a client option when it is an object with a valid version property","suites":["MongoOptions","serverApi"],"updatePoint":{"line":494,"column":90,"index":21782},"line":494,"code":"    it('is supported as a client option when it is an object with a valid version property', function () {\n      const validVersions = Object.values(ServerApiVersion);\n      expect(validVersions.length).to.be.at.least(1);\n      for (const version of validVersions) {\n        const result = parseOptions('mongodb://localhost/', {\n          serverApi: {\n            version\n          }\n        });\n        expect(result).to.have.property('serverApi').deep.equal({\n          version\n        });\n      }\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"is not supported as a client option when it is an invalid string","suites":["MongoOptions","serverApi"],"updatePoint":{"line":508,"column":72,"index":22272},"line":508,"code":"    it('is not supported as a client option when it is an invalid string', function () {\n      expect(() => parseOptions('mongodb://localhost/', {\n        serverApi: 'bad'\n      })).to.throw(/^Invalid server API version=bad;/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"is not supported as a client option when it is a number","suites":["MongoOptions","serverApi"],"updatePoint":{"line":513,"column":63,"index":22499},"line":513,"code":"    it('is not supported as a client option when it is a number', function () {\n      expect(() => parseOptions('mongodb://localhost/', {\n        serverApi: 1\n      })).to.throw(/^Invalid `serverApi` property;/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"is not supported as a client option when it is an object without a specified version","suites":["MongoOptions","serverApi"],"updatePoint":{"line":518,"column":92,"index":22749},"line":518,"code":"    it('is not supported as a client option when it is an object without a specified version', function () {\n      expect(() => parseOptions('mongodb://localhost/', {\n        serverApi: {}\n      })).to.throw(/^Invalid `serverApi` property;/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"is not supported as a client option when it is an object with an invalid specified version","suites":["MongoOptions","serverApi"],"updatePoint":{"line":523,"column":98,"index":23006},"line":523,"code":"    it('is not supported as a client option when it is an object with an invalid specified version', function () {\n      expect(() => parseOptions('mongodb://localhost/', {\n        serverApi: {\n          version: 1\n        }\n      })).to.throw(/^Invalid server API version=1;/);\n      expect(() => parseOptions('mongodb://localhost/', {\n        serverApi: {\n          version: 'bad'\n        }\n      })).to.throw(/^Invalid server API version=bad;/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"is not supported as a URI option even when it is a valid ServerApiVersion string","suites":["MongoOptions","serverApi"],"updatePoint":{"line":535,"column":88,"index":23453},"line":535,"code":"    it('is not supported as a URI option even when it is a valid ServerApiVersion string', function () {\n      expect(() => parseOptions('mongodb://localhost/?serverApi=1')).to.throw('URI cannot contain `serverApi`, it can only be passed to the client');\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should define known defaults in client.options","suites":["MongoOptions","default options"],"updatePoint":{"line":551,"column":54,"index":24684},"line":551,"code":"    it(`should define known defaults in client.options`, () => {\n      const client = new MongoClient('mongodb://localhost');\n      const clientOptions = client.options;\n      for (const [optionName, value] of KNOWN_DEFAULTS) {\n        const camelCaseName = findMatchingKey(clientOptions, optionName);\n        expect(camelCaseName, `did not find a camelcase match for ${optionName}`).to.be.a('string');\n        expect(clientOptions).to.have.property(camelCaseName);\n        if (value !== doNotCheckEq) {\n          expect(clientOptions).to.have.property(camelCaseName).that.deep.equals(value);\n        }\n      }\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"set monitorCommands to false (NODE-3513)","suites":["MongoOptions","default options"],"updatePoint":{"line":563,"column":48,"index":25297},"line":563,"code":"    it('set monitorCommands to false (NODE-3513)', function () {\n      const client = new MongoClient('mongodb://localhost');\n      const clientOptions = client.options;\n      expect(clientOptions).to.have.property('monitorCommands', false);\n      expect(client.s.options).to.have.property('monitorCommands', false);\n      expect(client).to.have.property('monitorCommands', false);\n      const optionsSym = getSymbolFrom(client, 'options');\n      expect(client[optionsSym]).to.have.property('monitorCommands', false);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"respects monitorCommands option passed in","suites":["MongoOptions","default options"],"updatePoint":{"line":572,"column":49,"index":25824},"line":572,"code":"    it('respects monitorCommands option passed in', function () {\n      const clientViaOpt = new MongoClient('mongodb://localhost', {\n        monitorCommands: true\n      });\n      const clientViaUri = new MongoClient('mongodb://localhost?monitorCommands=true');\n      const testTable = [[clientViaOpt, clientViaOpt.options], [clientViaUri, clientViaUri.options]];\n      for (const [client, clientOptions] of testTable) {\n        expect(clientOptions).to.have.property('monitorCommands', true);\n        expect(client.s.options).to.have.property('monitorCommands', true);\n        expect(client).to.have.property('monitorCommands', true);\n        const optionsSym = getSymbolFrom(client, 'options');\n        expect(client[optionsSym]).to.have.property('monitorCommands', true);\n      }\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"sets the option","suites":["MongoOptions","when loadBalanced=true is in the URI"],"updatePoint":{"line":588,"column":23,"index":26659},"line":588,"code":"    it('sets the option', function () {\n      const options = parseOptions('mongodb://a/?loadBalanced=true');\n      expect(options.loadBalanced).to.be.true;\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"errors with multiple hosts","suites":["MongoOptions","when loadBalanced=true is in the URI"],"updatePoint":{"line":592,"column":34,"index":26835},"line":592,"code":"    it('errors with multiple hosts', function () {\n      const parse = () => {\n        parseOptions('mongodb://a,b/?loadBalanced=true');\n      };\n      expect(parse).to.throw(/single host/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"errors with a replicaSet option","suites":["MongoOptions","when loadBalanced=true is in the URI"],"updatePoint":{"line":598,"column":39,"index":27039},"line":598,"code":"    it('errors with a replicaSet option', function () {\n      const parse = () => {\n        parseOptions('mongodb://a/?loadBalanced=true&replicaSet=test');\n      };\n      expect(parse).to.throw(/replicaSet/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"errors with a directConnection option","suites":["MongoOptions","when loadBalanced=true is in the URI"],"updatePoint":{"line":604,"column":45,"index":27262},"line":604,"code":"    it('errors with a directConnection option', function () {\n      const parse = () => {\n        parseOptions('mongodb://a/?loadBalanced=true&directConnection=true');\n      };\n      expect(parse).to.throw(/directConnection/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"errors when the option is true","suites":["MongoOptions","when loadBalanced is in the options object"],"updatePoint":{"line":612,"column":38,"index":27566},"line":612,"code":"    it('errors when the option is true', function () {\n      const parse = () => {\n        parseOptions('mongodb://a/', {\n          loadBalanced: true\n        });\n      };\n      expect(parse).to.throw(/URI/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"errors when the option is false","suites":["MongoOptions","when loadBalanced is in the options object"],"updatePoint":{"line":620,"column":39,"index":27784},"line":620,"code":"    it('errors when the option is false', function () {\n      const parse = () => {\n        parseOptions('mongodb://a/', {\n          loadBalanced: false\n        });\n      };\n      expect(parse).to.throw(/URI/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"srvMaxHosts > 0 cannot be combined with LB or ReplicaSet","suites":["MongoOptions","when loadBalanced is in the options object"],"updatePoint":{"line":629,"column":62,"index":28032},"line":629,"code":"  it('srvMaxHosts > 0 cannot be combined with LB or ReplicaSet', () => {\n    expect(() => {\n      new MongoClient('mongodb+srv://localhost?srvMaxHosts=2&replicaSet=repl');\n    }).to.throw(MongoParseError, 'Cannot use srvMaxHosts option with replicaSet');\n    expect(() => {\n      new MongoClient('mongodb+srv://localhost?srvMaxHosts=2&loadBalanced=true');\n    }).to.throw(MongoParseError, 'Cannot limit srv hosts with loadBalanced enabled');\n    expect(() => {\n      new MongoClient('mongodb+srv://localhost', {\n        srvMaxHosts: 2,\n        replicaSet: 'blah'\n      });\n    }).to.throw(MongoParseError, 'Cannot use srvMaxHosts option with replicaSet');\n    expect(() => {\n      new MongoClient('mongodb+srv://localhost?loadBalanced=true', {\n        srvMaxHosts: 2\n      });\n    }).to.throw(MongoParseError, 'Cannot limit srv hosts with loadBalanced enabled');\n\n    // These should not throw.\n    new MongoClient('mongodb+srv://localhost?srvMaxHosts=0&replicaSet=repl');\n    new MongoClient('mongodb+srv://localhost', {\n      srvMaxHosts: 0,\n      replicaSet: 'blah'\n    });\n    new MongoClient('mongodb+srv://localhost?srvMaxHosts=0&loadBalanced=true');\n    new MongoClient('mongodb+srv://localhost?loadBalanced=true', {\n      srvMaxHosts: 0\n    });\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"srvServiceName and srvMaxHosts cannot be used on a non-srv connection string","suites":["MongoOptions","when loadBalanced is in the options object"],"updatePoint":{"line":659,"column":82,"index":29311},"line":659,"code":"  it('srvServiceName and srvMaxHosts cannot be used on a non-srv connection string', () => {\n    expect(() => {\n      new MongoClient('mongodb://localhost?srvMaxHosts=2');\n    }).to.throw(MongoParseError);\n    expect(() => {\n      new MongoClient('mongodb://localhost?srvMaxHosts=0');\n    }).to.throw(MongoParseError);\n    expect(() => {\n      new MongoClient('mongodb://localhost', {\n        srvMaxHosts: 0\n      });\n    }).to.throw(MongoParseError);\n    expect(() => {\n      new MongoClient('mongodb://localhost?srvServiceName=abc');\n    }).to.throw(MongoParseError);\n    expect(() => {\n      new MongoClient('mongodb://localhost', {\n        srvMaxHosts: 2\n      });\n    }).to.throw(MongoParseError);\n    expect(() => {\n      new MongoClient('mongodb://localhost', {\n        srvServiceName: 'abc'\n      });\n    }).to.throw(MongoParseError);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"srvServiceName should error if it is too long","suites":["MongoOptions","when loadBalanced is in the options object"],"updatePoint":{"line":685,"column":51,"index":30129},"line":685,"code":"  it('srvServiceName should error if it is too long', async () => {\n    const options = parseOptions('mongodb+srv://localhost.a.com', {\n      srvServiceName: 'a'.repeat(255)\n    });\n    const error = await resolveSRVRecord(options).catch(error => error);\n    expect(error).to.have.property('code', 'EBADNAME');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"srvServiceName should not error if it is greater than 15 characters as long as the DNS query limit is not surpassed","suites":["MongoOptions","when loadBalanced is in the options object"],"updatePoint":{"line":692,"column":121,"index":30516},"line":692,"code":"  it('srvServiceName should not error if it is greater than 15 characters as long as the DNS query limit is not surpassed', async () => {\n    const options = parseOptions('mongodb+srv://localhost.a.com', {\n      srvServiceName: 'a'.repeat(16)\n    });\n    const error = await resolveSRVRecord(options).catch(error => error);\n\n    // Nothing wrong with the name, just DNE\n    expect(error).to.have.property('code', 'ENOTFOUND');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should set the database name to the dbName in the uri","suites":["MongoOptions","dbName and authSource","in the URI"],"updatePoint":{"line":703,"column":63,"index":30970},"line":703,"code":"      it('should set the database name to the dbName in the uri', () => {\n        const client = new MongoClient('mongodb://u:p@host/myDb');\n        const db = client.db();\n        expect(db).to.have.property('databaseName', 'myDb');\n        expect(client).to.have.nested.property('options.credentials.source', 'myDb');\n      });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should set the database name to the uri pathname and respect the authSource option","suites":["MongoOptions","dbName and authSource","in the URI"],"updatePoint":{"line":709,"column":92,"index":31329},"line":709,"code":"      it('should set the database name to the uri pathname and respect the authSource option', () => {\n        const client = new MongoClient('mongodb://u:p@host/myDb?authSource=myAuthDb');\n        const db = client.db();\n        expect(db).to.have.property('databaseName', 'myDb');\n        expect(client).to.have.nested.property('options.credentials.source', 'myAuthDb');\n      });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should set the database name to the uri pathname and respect the authSource option in options object","suites":["MongoOptions","dbName and authSource","in the URI"],"updatePoint":{"line":715,"column":110,"index":31730},"line":715,"code":"      it('should set the database name to the uri pathname and respect the authSource option in options object', () => {\n        const client = new MongoClient('mongodb://u:p@host/myDb', {\n          authSource: 'myAuthDb'\n        });\n        const db = client.db();\n        expect(db).to.have.property('databaseName', 'myDb');\n        expect(client).to.have.nested.property('options.credentials.source', 'myAuthDb');\n      });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should set the database name to the dbName in the options object","suites":["MongoOptions","dbName and authSource","in the options object"],"updatePoint":{"line":725,"column":74,"index":32175},"line":725,"code":"      it('should set the database name to the dbName in the options object', () => {\n        const client = new MongoClient('mongodb://u:p@host', {\n          dbName: 'myDb'\n        });\n        const db = client.db();\n        expect(db).to.have.property('databaseName', 'myDb');\n        expect(client).to.have.nested.property('options.credentials.source', 'myDb');\n      });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should set the database name to dbName and respect the authSource option","suites":["MongoOptions","dbName and authSource","in the options object"],"updatePoint":{"line":733,"column":82,"index":32557},"line":733,"code":"      it('should set the database name to dbName and respect the authSource option', () => {\n        const client = new MongoClient('mongodb://u:p@host?authSource=myAuthDb', {\n          dbName: 'myDb'\n        });\n        const db = client.db();\n        expect(db).to.have.property('databaseName', 'myDb');\n        expect(client).to.have.nested.property('options.credentials.source', 'myAuthDb');\n      });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should set the database name to dbName and respect the authSource option in options object","suites":["MongoOptions","dbName and authSource","in the options object"],"updatePoint":{"line":741,"column":100,"index":32981},"line":741,"code":"      it('should set the database name to dbName and respect the authSource option in options object', () => {\n        const client = new MongoClient('mongodb://u:p@host', {\n          dbName: 'myDb',\n          authSource: 'myAuthDb'\n        });\n        const db = client.db();\n        expect(db).to.have.property('databaseName', 'myDb');\n        expect(client).to.have.nested.property('options.credentials.source', 'myAuthDb');\n      });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should set the database name to dbName in options object and respect the authSource option in options object","suites":["MongoOptions","dbName and authSource","in the options object"],"updatePoint":{"line":750,"column":118,"index":33437},"line":750,"code":"      it('should set the database name to dbName in options object and respect the authSource option in options object', () => {\n        const client = new MongoClient('mongodb://u:p@host/myIgnoredDb', {\n          dbName: 'myDb',\n          authSource: 'myAuthDb'\n        });\n        const db = client.db();\n        expect(db).to.have.property('databaseName', 'myDb');\n        expect(client).to.have.nested.property('options.credentials.source', 'myAuthDb');\n      });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"assigns the parsed options to the mongoLoggerOptions option","suites":["MongoOptions","loggingOptions"],"updatePoint":{"line":774,"column":67,"index":34209},"line":774,"code":"    it('assigns the parsed options to the mongoLoggerOptions option', function () {\n      const client = new MongoClient('mongodb://localhost:27017');\n      expect(client.options).to.have.property('mongoLoggerOptions').to.equal(expectedLoggingObject);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"sets trySecondaryWrite to true","suites":["AggregateOperation","#constructor","when out is in the options"],"updatePoint":{"line":17,"column":40,"index":423},"line":17,"code":"      it('sets trySecondaryWrite to true', function () {\n        expect(operation.trySecondaryWrite).to.be.true;\n      });","file":"unit/operations/aggregate.test.js","skipped":false,"dir":"test"},{"name":"sets trySecondaryWrite to true","suites":["AggregateOperation","#constructor","when $out is the last stage"],"updatePoint":{"line":27,"column":40,"index":727},"line":27,"code":"      it('sets trySecondaryWrite to true', function () {\n        expect(operation.trySecondaryWrite).to.be.true;\n      });","file":"unit/operations/aggregate.test.js","skipped":false,"dir":"test"},{"name":"sets trySecondaryWrite to false","suites":["AggregateOperation","#constructor","when $out is not the last stage"],"updatePoint":{"line":41,"column":41,"index":1095},"line":41,"code":"      it('sets trySecondaryWrite to false', function () {\n        expect(operation.trySecondaryWrite).to.be.false;\n      });","file":"unit/operations/aggregate.test.js","skipped":false,"dir":"test"},{"name":"sets trySecondaryWrite to true","suites":["AggregateOperation","#constructor","when $merge is the last stage"],"updatePoint":{"line":53,"column":40,"index":1432},"line":53,"code":"      it('sets trySecondaryWrite to true', function () {\n        expect(operation.trySecondaryWrite).to.be.true;\n      });","file":"unit/operations/aggregate.test.js","skipped":false,"dir":"test"},{"name":"sets trySecondaryWrite to false","suites":["AggregateOperation","#constructor","when $merge is not the last stage"],"updatePoint":{"line":69,"column":41,"index":1832},"line":69,"code":"      it('sets trySecondaryWrite to false', function () {\n        expect(operation.trySecondaryWrite).to.be.false;\n      });","file":"unit/operations/aggregate.test.js","skipped":false,"dir":"test"},{"name":"sets trySecondaryWrite to false","suites":["AggregateOperation","#constructor","when no writable stages in empty pipeline"],"updatePoint":{"line":77,"column":41,"index":2122},"line":77,"code":"      it('sets trySecondaryWrite to false', function () {\n        expect(operation.trySecondaryWrite).to.be.false;\n      });","file":"unit/operations/aggregate.test.js","skipped":false,"dir":"test"},{"name":"sets trySecondaryWrite to false","suites":["AggregateOperation","#constructor","when no writable stages"],"updatePoint":{"line":89,"column":41,"index":2451},"line":89,"code":"      it('sets trySecondaryWrite to false', function () {\n        expect(operation.trySecondaryWrite).to.be.false;\n      });","file":"unit/operations/aggregate.test.js","skipped":false,"dir":"test"},{"name":"sets nameOnly to true","suites":["ListCollectionsOperation","#constructor","when nameOnly is provided","when nameOnly is true"],"updatePoint":{"line":18,"column":33,"index":497},"line":18,"code":"        it('sets nameOnly to true', function () {\n          expect(operation).to.have.property('nameOnly', true);\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets nameOnly to false","suites":["ListCollectionsOperation","#constructor","when nameOnly is provided","when nameOnly is false"],"updatePoint":{"line":27,"column":34,"index":813},"line":27,"code":"        it('sets nameOnly to false', function () {\n          expect(operation).to.have.property('nameOnly', false);\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets authorizedCollections to true","suites":["ListCollectionsOperation","#constructor","when authorizedCollections is provided","when authorizedCollections is true"],"updatePoint":{"line":38,"column":46,"index":1242},"line":38,"code":"        it('sets authorizedCollections to true', function () {\n          expect(operation).to.have.property('authorizedCollections', true);\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets authorizedCollections to false","suites":["ListCollectionsOperation","#constructor","when authorizedCollections is provided","when authorizedCollections is false"],"updatePoint":{"line":47,"column":47,"index":1610},"line":47,"code":"        it('sets authorizedCollections to false', function () {\n          expect(operation).to.have.property('authorizedCollections', false);\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets nameOnly to false","suites":["ListCollectionsOperation","#constructor","when no options are provided"],"updatePoint":{"line":56,"column":32,"index":1917},"line":56,"code":"      it('sets nameOnly to false', function () {\n        expect(operation).to.have.property('nameOnly', false);\n      });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets authorizedCollections to false","suites":["ListCollectionsOperation","#constructor","when no options are provided"],"updatePoint":{"line":59,"column":45,"index":2052},"line":59,"code":"      it('sets authorizedCollections to false', function () {\n        expect(operation).to.have.property('authorizedCollections', false);\n      });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"does not set a comment on the command","suites":["ListCollectionsOperation","#generateCommand","when comment is provided","when the wireVersion < 9"],"updatePoint":{"line":67,"column":49,"index":2373},"line":67,"code":"        it('does not set a comment on the command', function () {\n          const operation = new ListCollectionsOperation(db, {}, {\n            dbName: db,\n            comment: 'test comment'\n          });\n          const command = operation.generateCommand(8);\n          expect(command).not.to.haveOwnProperty('comment');\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets a comment on the command","suites":["ListCollectionsOperation","#generateCommand","when comment is provided","when the wireVersion >= 9"],"updatePoint":{"line":77,"column":41,"index":2768},"line":77,"code":"        it('sets a comment on the command', function () {\n          const operation = new ListCollectionsOperation(db, {}, {\n            dbName: db,\n            comment: 'test comment'\n          });\n          const command = operation.generateCommand(9);\n          expect(command).to.have.property('comment').that.equals('test comment');\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets nameOnly to true","suites":["ListCollectionsOperation","#generateCommand","when nameOnly is provided","when nameOnly is true"],"updatePoint":{"line":93,"column":33,"index":3360},"line":93,"code":"        it('sets nameOnly to true', function () {\n          expect(operation.generateCommand(8)).to.deep.equal({\n            listCollections: 1,\n            cursor: {},\n            filter: {},\n            nameOnly: true,\n            authorizedCollections: false\n          });\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets nameOnly to false","suites":["ListCollectionsOperation","#generateCommand","when nameOnly is provided","when nameOnly is false"],"updatePoint":{"line":108,"column":34,"index":3838},"line":108,"code":"        it('sets nameOnly to false', function () {\n          expect(operation.generateCommand(8)).to.deep.equal({\n            listCollections: 1,\n            cursor: {},\n            filter: {},\n            nameOnly: false,\n            authorizedCollections: false\n          });\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets authorizedCollections to true","suites":["ListCollectionsOperation","#generateCommand","when authorizedCollections is provided","when authorizedCollections is true"],"updatePoint":{"line":125,"column":46,"index":4429},"line":125,"code":"        it('sets authorizedCollections to true', function () {\n          expect(operation.generateCommand(8)).to.deep.equal({\n            listCollections: 1,\n            cursor: {},\n            filter: {},\n            nameOnly: false,\n            authorizedCollections: true\n          });\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets authorizedCollections to false","suites":["ListCollectionsOperation","#generateCommand","when authorizedCollections is provided","when authorizedCollections is false"],"updatePoint":{"line":140,"column":47,"index":4946},"line":140,"code":"        it('sets authorizedCollections to false', function () {\n          expect(operation.generateCommand(8)).to.deep.equal({\n            listCollections: 1,\n            cursor: {},\n            filter: {},\n            nameOnly: false,\n            authorizedCollections: false\n          });\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets nameOnly and authorizedCollections properties to false","suites":["ListCollectionsOperation","#generateCommand","when no options are provided"],"updatePoint":{"line":155,"column":69,"index":5439},"line":155,"code":"      it('sets nameOnly and authorizedCollections properties to false', function () {\n        expect(operation.generateCommand(8)).to.deep.equal({\n          listCollections: 1,\n          cursor: {},\n          filter: {},\n          nameOnly: false,\n          authorizedCollections: false\n        });\n      });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"should throw if given a null address","suites":["ServerDescription","constructor()"],"updatePoint":{"line":5,"column":44,"index":283},"line":5,"code":"    it('should throw if given a null address', () => {\n      // @ts-expect-error: Passing nullish value to prove error will be thrown\n      expect(() => new ServerDescription(null)).to.throw(MongoRuntimeError);\n      // @ts-expect-error: Passing nullish value to prove error will be thrown\n      expect(() => new ServerDescription()).to.throw(MongoRuntimeError);\n    });","file":"unit/sdam/server_description.test.ts","skipped":false,"dir":"test"},{"name":"should throw if given an empty string for an address","suites":["ServerDescription","constructor()"],"updatePoint":{"line":11,"column":60,"index":670},"line":11,"code":"    it('should throw if given an empty string for an address', () => {\n      expect(() => new ServerDescription('')).to.throw(MongoRuntimeError);\n    });","file":"unit/sdam/server_description.test.ts","skipped":false,"dir":"test"},{"name":"should normalize an IPv6 address with brackets and toLowered characters","suites":["ServerDescription","error equality"],"updatePoint":{"line":68,"column":77,"index":2538},"line":68,"code":"  it('should normalize an IPv6 address with brackets and toLowered characters', function () {\n    const description = new ServerDescription('[ABCD:f::abcd:abcd:abcd:abcd]:1234');\n    expect(description.host).to.equal('[abcd:f::abcd:abcd:abcd:abcd]'); // IPv6 Addresses must always be bracketed if there is a port\n    expect(description.port).to.equal(1234);\n  });","file":"unit/sdam/server_description.test.ts","skipped":false,"dir":"test"},{"name":"should normalize an IPv6 address with brackets and toLowered characters even when the port is omitted","suites":["ServerDescription","error equality"],"updatePoint":{"line":73,"column":107,"index":2932},"line":73,"code":"  it('should normalize an IPv6 address with brackets and toLowered characters even when the port is omitted', function () {\n    const description = new ServerDescription('[ABCD:f::abcd:abcd:abcd:abcd]');\n    expect(description.host).to.equal('[abcd:f::abcd:abcd:abcd:abcd]');\n    expect(description.port).to.equal(27017);\n  });","file":"unit/sdam/server_description.test.ts","skipped":false,"dir":"test"},{"name":"returns an empty array","suites":["server selection","#sameServerSelector","when the server is unknown"],"updatePoint":{"line":68,"column":32,"index":1750},"line":68,"code":"      it('returns an empty array', function () {\n        expect(servers).to.be.empty;\n      });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"returns the server","suites":["server selection","#sameServerSelector","when the server is not unknown"],"updatePoint":{"line":76,"column":28,"index":1995},"line":76,"code":"      it('returns the server', function () {\n        expect(servers).to.deep.equal([primary]);\n      });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"returns an empty array","suites":["server selection","#sameServerSelector","when no server description provided"],"updatePoint":{"line":84,"column":32,"index":2255},"line":84,"code":"      it('returns an empty array', function () {\n        expect(servers).to.be.empty;\n      });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"returns an empty array","suites":["server selection","#sameServerSelector","when the server is not the same"],"updatePoint":{"line":92,"column":32,"index":2507},"line":92,"code":"      it('returns an empty array', function () {\n        expect(servers).to.be.empty;\n      });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"uses the provided read preference","suites":["server selection","#secondaryWritableServerSelector","when the topology is a replica set","when the common server version is >= 5.0","when a read preference is provided"],"updatePoint":{"line":107,"column":47,"index":3484},"line":107,"code":"          it('uses the provided read preference', function () {\n            expect(servers).to.deep.equal([secondary]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a primary","suites":["server selection","#secondaryWritableServerSelector","when the topology is a replica set","when the common server version is >= 5.0","when a read preference is not provided"],"updatePoint":{"line":114,"column":31,"index":3878},"line":114,"code":"          it('selects a primary', function () {\n            expect(servers).to.deep.equal([primary]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a primary","suites":["server selection","#secondaryWritableServerSelector","when the topology is a replica set","when the common server version is < 5.0","when a read preference is provided"],"updatePoint":{"line":124,"column":31,"index":4590},"line":124,"code":"          it('selects a primary', function () {\n            expect(servers).to.deep.equal([primary]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a primary","suites":["server selection","#secondaryWritableServerSelector","when the topology is a replica set","when the common server version is < 5.0","when read preference is not provided"],"updatePoint":{"line":131,"column":31,"index":4984},"line":131,"code":"          it('selects a primary', function () {\n            expect(servers).to.deep.equal([primary]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a primary","suites":["server selection","#secondaryWritableServerSelector","when the topology is a replica set","when a common wire version is not provided"],"updatePoint":{"line":140,"column":29,"index":5594},"line":140,"code":"        it('selects a primary', function () {\n          expect(servers).to.deep.equal([primary]);\n        });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a mongos","suites":["server selection","#secondaryWritableServerSelector","when the topology is sharded","when the common server version is >= 5.0","when a read preference is provided"],"updatePoint":{"line":153,"column":30,"index":6432},"line":153,"code":"          it('selects a mongos', function () {\n            expect(servers).to.deep.equal([mongos]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a mongos","suites":["server selection","#secondaryWritableServerSelector","when the topology is sharded","when the common server version is >= 5.0","when a read preference is not provided"],"updatePoint":{"line":160,"column":30,"index":6822},"line":160,"code":"          it('selects a mongos', function () {\n            expect(servers).to.deep.equal([mongos]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a mongos","suites":["server selection","#secondaryWritableServerSelector","when the topology is sharded","when the common server version is < 5.0","when a read preference is provided"],"updatePoint":{"line":170,"column":30,"index":7518},"line":170,"code":"          it('selects a mongos', function () {\n            expect(servers).to.deep.equal([mongos]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a mongos","suites":["server selection","#secondaryWritableServerSelector","when the topology is sharded","when the common server version is < 5.0","when read preference is not provided"],"updatePoint":{"line":177,"column":30,"index":7910},"line":177,"code":"          it('selects a mongos', function () {\n            expect(servers).to.deep.equal([mongos]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a mongos","suites":["server selection","#secondaryWritableServerSelector","when the topology is sharded","when a common wire version is not provided"],"updatePoint":{"line":186,"column":28,"index":8469},"line":186,"code":"        it('selects a mongos', function () {\n          expect(servers).to.deep.equal([mongos]);\n        });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a load balancer","suites":["server selection","#secondaryWritableServerSelector","when the topology is load balanced","when the common server version is >= 5.0","when a read preference is provided"],"updatePoint":{"line":199,"column":37,"index":9336},"line":199,"code":"          it('selects a load balancer', function () {\n            expect(servers).to.deep.equal([loadBalancer]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a load balancer","suites":["server selection","#secondaryWritableServerSelector","when the topology is load balanced","when the common server version is >= 5.0","when a read preference is not provided"],"updatePoint":{"line":206,"column":37,"index":9739},"line":206,"code":"          it('selects a load balancer', function () {\n            expect(servers).to.deep.equal([loadBalancer]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a load balancer","suites":["server selection","#secondaryWritableServerSelector","when the topology is load balanced","when the common server version is < 5.0","when a read preference is provided"],"updatePoint":{"line":216,"column":37,"index":10453},"line":216,"code":"          it('selects a load balancer', function () {\n            expect(servers).to.deep.equal([loadBalancer]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a load balancer","suites":["server selection","#secondaryWritableServerSelector","when the topology is load balanced","when the common server version is < 5.0","when read preference is not provided"],"updatePoint":{"line":223,"column":37,"index":10858},"line":223,"code":"          it('selects a load balancer', function () {\n            expect(servers).to.deep.equal([loadBalancer]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a load balancer","suites":["server selection","#secondaryWritableServerSelector","when the topology is load balanced","when a common wire version is not provided"],"updatePoint":{"line":232,"column":35,"index":11435},"line":232,"code":"        it('selects a load balancer', function () {\n          expect(servers).to.deep.equal([loadBalancer]);\n        });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a standalone","suites":["server selection","#secondaryWritableServerSelector","when the topology is single","when the common server version is >= 5.0","when a read preference is provided"],"updatePoint":{"line":245,"column":34,"index":12280},"line":245,"code":"          it('selects a standalone', function () {\n            expect(servers).to.deep.equal([single]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a standalone","suites":["server selection","#secondaryWritableServerSelector","when the topology is single","when the common server version is >= 5.0","when a read preference is not provided"],"updatePoint":{"line":252,"column":34,"index":12674},"line":252,"code":"          it('selects a standalone', function () {\n            expect(servers).to.deep.equal([single]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a standalone","suites":["server selection","#secondaryWritableServerSelector","when the topology is single","when the common server version is < 5.0","when a read preference is provided"],"updatePoint":{"line":262,"column":34,"index":13373},"line":262,"code":"          it('selects a standalone', function () {\n            expect(servers).to.deep.equal([single]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a standalone","suites":["server selection","#secondaryWritableServerSelector","when the topology is single","when the common server version is < 5.0","when read preference is not provided"],"updatePoint":{"line":269,"column":34,"index":13769},"line":269,"code":"          it('selects a standalone', function () {\n            expect(servers).to.deep.equal([single]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a standalone","suites":["server selection","#secondaryWritableServerSelector","when the topology is single","when a common wire version is not provided"],"updatePoint":{"line":278,"column":32,"index":14331},"line":278,"code":"        it('selects a standalone', function () {\n          expect(servers).to.deep.equal([single]);\n        });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"includes servers inside the latency window with default localThresholdMS","suites":["server selection","#secondaryWritableServerSelector","localThresholdMS is respected as an option"],"updatePoint":{"line":312,"column":82,"index":15581},"line":312,"code":"      it('includes servers inside the latency window with default localThresholdMS', function () {\n        const topologyDescription = new TopologyDescription(TopologyType.Single, serverDescriptions, 'test', MIN_SECONDARY_WRITE_WIRE_VERSION, new ObjectId(), MIN_SECONDARY_WRITE_WIRE_VERSION);\n        const selector = secondaryWritableServerSelector();\n        const servers = selector(topologyDescription, Array.from(serverDescriptions.values()));\n        expect(servers).to.have.lengthOf(2);\n        const selectedAddresses = new Set(servers.map(({\n          address\n        }) => address));\n        expect(selectedAddresses.has(serverDescription1.address)).to.be.true;\n        expect(selectedAddresses.has(serverDescription2.address)).to.be.true;\n        expect(selectedAddresses.has(serverDescription3.address)).to.be.false;\n      });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"includes servers inside the latency window with custom localThresholdMS","suites":["server selection","#secondaryWritableServerSelector","localThresholdMS is respected as an option"],"updatePoint":{"line":324,"column":81,"index":16419},"line":324,"code":"      it('includes servers inside the latency window with custom localThresholdMS', function () {\n        const topologyDescription = new TopologyDescription(TopologyType.Single, serverDescriptions, 'test', MIN_SECONDARY_WRITE_WIRE_VERSION, new ObjectId(), MIN_SECONDARY_WRITE_WIRE_VERSION, {\n          localThresholdMS: 5\n        });\n        const selector = secondaryWritableServerSelector();\n        const servers = selector(topologyDescription, Array.from(serverDescriptions.values()));\n        expect(servers).to.have.lengthOf(1);\n        const selectedAddresses = new Set(servers.map(({\n          address\n        }) => address));\n        expect(selectedAddresses.has(serverDescription1.address)).to.be.true;\n        expect(selectedAddresses.has(serverDescription2.address)).to.be.false;\n        expect(selectedAddresses.has(serverDescription3.address)).to.be.false;\n      });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"should always return a valid value for `intervalMS`","suites":["Mongos SRV Polling","SrvPoller"],"updatePoint":{"line":40,"column":59,"index":1222},"line":40,"code":"    it('should always return a valid value for `intervalMS`', function () {\n      const poller = new SrvPoller({\n        srvHost: SRV_HOST\n      });\n      expect(poller).property('intervalMS').to.equal(60000);\n    });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should emit event, disable haMode, and schedule another poll","suites":["Mongos SRV Polling","SrvPoller","success"],"updatePoint":{"line":47,"column":70,"index":1489},"line":47,"code":"      it('should emit event, disable haMode, and schedule another poll', async function () {\n        const records = [srvRecord('jalad.tanagra.com'), srvRecord('thebeast.tanagra.com')];\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST,\n          heartbeatFrequencyMS: 100\n        });\n        const willBeDiscovery = once(poller, 'srvRecordDiscovery');\n        sinon.stub(poller, 'schedule');\n        poller.haMode = true;\n        expect(poller).to.have.property('haMode', true);\n        poller.success(records);\n        const [e] = await willBeDiscovery;\n        expect(e).to.be.an.instanceOf(SrvPollingEvent).and.to.have.property('srvRecords').that.deep.equals(records);\n        expect(poller.schedule).to.have.been.calledOnce;\n        expect(poller).to.have.property('haMode', false);\n      });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should enable haMode and schedule","suites":["Mongos SRV Polling","SrvPoller","failure"],"updatePoint":{"line":65,"column":43,"index":2323},"line":65,"code":"      it('should enable haMode and schedule', async () => {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        sinon.stub(poller, 'schedule');\n        poller.failure('Some kind of failure');\n        expect(poller.schedule).to.have.been.calledOnce;\n        expect(poller).to.have.property('haMode', true);\n      });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should throw if srvHost is not passed in","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":76,"column":50,"index":2724},"line":76,"code":"      it('should throw if srvHost is not passed in', function () {\n        expect(() => new SrvPoller()).to.throw(MongoDriverError);\n        expect(() => new SrvPoller({})).to.throw(MongoDriverError);\n      });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should poll dns srv records","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":80,"column":37,"index":2922},"line":80,"code":"      it('should poll dns srv records', async function () {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        sinon.stub(dns.promises, 'resolveSrv').resolves([srvRecord('iLoveJavascript.lots')]);\n        await poller._poll();\n        clearTimeout(poller._timeout);\n        expect(dns.promises.resolveSrv).to.have.been.calledOnce.and.to.have.been.calledWith(`_mongodb._tcp.${SRV_HOST}`);\n      });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should not succeed or fail if poller was stopped","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":89,"column":58,"index":3377},"line":89,"code":"      it('should not succeed or fail if poller was stopped', async function () {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        stubDns(null, []);\n        stubPoller(poller);\n        const pollerPromise = poller._poll();\n        poller.generation += 1;\n        await pollerPromise;\n        expect(poller.success).to.not.have.been.called;\n        expect(poller.failure).to.not.have.been.called;\n      });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should fail if dns returns error","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":101,"column":42,"index":3805},"line":101,"code":"      it('should fail if dns returns error', async () => {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        stubDns(new Error('Some Error'));\n        stubPoller(poller);\n        await poller._poll();\n        expect(poller.success).to.not.have.been.called;\n        expect(poller.failure).to.have.been.calledOnce;\n      });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should fail if dns returns no records","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":111,"column":47,"index":4170},"line":111,"code":"      it('should fail if dns returns no records', async () => {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        stubDns(null, []);\n        stubPoller(poller);\n        await poller._poll();\n        expect(poller.success).to.not.have.been.called;\n        expect(poller.failure).to.have.been.calledOnce;\n      });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should fail if dns returns no records that match parent domain","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":121,"column":72,"index":4545},"line":121,"code":"      it('should fail if dns returns no records that match parent domain', async () => {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        const records = [srvRecord('jalad.tanagra.org'), srvRecord('shaka.walls.com')];\n        stubDns(null, records);\n        stubPoller(poller);\n        await poller._poll();\n        expect(poller.success).to.not.have.been.called;\n        expect(poller.failure).to.have.been.calledOnce;\n      });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should succeed when valid records are returned by dns","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":132,"column":63,"index":5004},"line":132,"code":"      it('should succeed when valid records are returned by dns', async () => {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        const records = [srvRecord('jalad.tanagra.com'), srvRecord('thebeast.tanagra.com')];\n        stubDns(null, records);\n        stubPoller(poller);\n        await poller._poll();\n        expect(poller.success).to.have.been.calledOnce.and.calledWithMatch(records);\n        expect(poller.failure).to.not.have.been.called;\n      });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should succeed when some valid records are returned and some do not match parent domain","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":143,"column":97,"index":5531},"line":143,"code":"      it('should succeed when some valid records are returned and some do not match parent domain', async () => {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        const records = [srvRecord('jalad.tanagra.com'), srvRecord('thebeast.walls.com')];\n        stubDns(null, records);\n        stubPoller(poller);\n        await poller._poll();\n        expect(poller.success).to.have.been.calledOnce.and.calledWithMatch([records[0]]);\n        expect(poller.failure).to.not.have.been.called;\n      });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should not make an srv poller if there is no srv host","suites":["Mongos SRV Polling","topology"],"updatePoint":{"line":168,"column":61,"index":6322},"line":168,"code":"    it('should not make an srv poller if there is no srv host', function () {\n      const srvPoller = new FakeSrvPoller({\n        srvHost: SRV_HOST\n      });\n      const topology = topologyWithPlaceholderClient(['localhost:27017', 'localhost:27018'], {\n        srvPoller\n      });\n      expect(topology).to.not.have.property('srvPoller');\n    });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should make an srvPoller if there is an srvHost","suites":["Mongos SRV Polling","topology"],"updatePoint":{"line":177,"column":55,"index":6663},"line":177,"code":"    it('should make an srvPoller if there is an srvHost', function () {\n      const srvPoller = new FakeSrvPoller({\n        srvHost: SRV_HOST\n      });\n      const topology = topologyWithPlaceholderClient(['localhost:27017', 'localhost:27018'], {\n        srvHost: SRV_HOST,\n        srvPoller\n      });\n      expect(topology.s).to.have.property('srvPoller').that.equals(srvPoller);\n    });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should only start polling if topology description changes to sharded","suites":["Mongos SRV Polling","topology"],"updatePoint":{"line":187,"column":76,"index":7073},"line":187,"code":"    it('should only start polling if topology description changes to sharded', function () {\n      const srvPoller = new FakeSrvPoller({\n        srvHost: SRV_HOST\n      });\n      sinon.stub(srvPoller, 'start');\n      const topology = topologyWithPlaceholderClient(['localhost:27017', 'localhost:27018'], {\n        srvHost: SRV_HOST,\n        srvPoller\n      });\n      const topologyDescriptions = [new TopologyDescription(TopologyType.Unknown), new TopologyDescription(TopologyType.Unknown), new TopologyDescription(TopologyType.Sharded), new TopologyDescription(TopologyType.Sharded)];\n      function emit(prev, current) {\n        topology.emit('topologyDescriptionChanged', new sdamEvents.TopologyDescriptionChangedEvent(topology.s.id, prev, current));\n      }\n      expect(srvPoller.start).to.not.have.been.called;\n      emit(topologyDescriptions[0], topologyDescriptions[1]);\n      expect(srvPoller.start).to.not.have.been.called;\n      emit(topologyDescriptions[1], topologyDescriptions[2]);\n      expect(srvPoller.start).to.have.been.calledOnce;\n      emit(topologyDescriptions[2], topologyDescriptions[3]);\n      expect(srvPoller.start).to.have.been.calledOnce;\n    });","file":"unit/sdam/srv_polling.test.ts","skipped":false,"dir":"test"},{"name":"should correctly pass appname","suites":["Topology (unit)","client metadata"],"updatePoint":{"line":62,"column":37,"index":1325},"line":62,"code":"    it('should correctly pass appname', function (done) {\n      const server = topologyWithPlaceholderClient([`localhost:27017`], {\n        metadata: makeClientMetadata({\n          appName: 'My application name',\n          driverInfo: {}\n        })\n      });\n      expect(server.clientMetadata.application.name).to.equal('My application name');\n      done();\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should report the correct platform in client metadata","suites":["Topology (unit)","client metadata"],"updatePoint":{"line":72,"column":61,"index":1716},"line":72,"code":"    it('should report the correct platform in client metadata', async function () {\n      const helloRequests = [];\n      mockServer.setMessageHandler(request => {\n        const doc = request.document;\n        if (isHello(doc)) {\n          helloRequests.push(doc);\n          request.reply(mock.HELLO);\n        } else {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      client = new MongoClient(`mongodb://${mockServer.uri()}/`);\n      await client.connect();\n      await client.db().command({\n        ping: 1\n      });\n      expect(helloRequests).to.have.length.greaterThan(1);\n      for (const request of helloRequests) {\n        expect(request).nested.property('client.platform').to.match(/Node.js /);\n      }\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should time out operations against servers that have been blackholed","suites":["Topology (unit)","black holes"],"updatePoint":{"line":100,"column":76,"index":2667},"line":100,"code":"    it('should time out operations against servers that have been blackholed', function (done) {\n      mockServer.setMessageHandler(request => {\n        const doc = request.document;\n        let initialHelloSent = false;\n        if (isHello(doc) && !initialHelloSent) {\n          request.reply(mock.HELLO);\n          initialHelloSent = true;\n        } else {\n          // black hole all other operations\n        }\n      });\n      const topology = topologyWithPlaceholderClient(mockServer.hostAddress());\n      topology.connect(err => {\n        expect(err).to.not.exist;\n        topology.selectServer('primary', {}, (err, server) => {\n          expect(err).to.not.exist;\n          server.command(ns('admin.$cmd'), {\n            ping: 1\n          }, {\n            socketTimeoutMS: 250\n          }, (err, result) => {\n            expect(result).to.not.exist;\n            expect(err).to.exist;\n            expect(err).to.match(/timed out/);\n            topology.close({}, done);\n          });\n        });\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"returns a MongoServerSelectionError","suites":["Topology (unit)","error handling","when server selection returns a server description but the description is not in the topology","when the topology originally only contained one server"],"updatePoint":{"line":169,"column":47,"index":4938},"line":169,"code":"        it('returns a MongoServerSelectionError', function (done) {\n          topology = topologyWithPlaceholderClient([mockServer.hostAddress(), secondMockServer.hostAddress()]);\n          topology.connect(err => {\n            expect(err).to.not.exist;\n            sinon.stub(topology.s.servers, 'get').callsFake(() => {\n              return undefined;\n            });\n            topology.selectServer('primary', {}, (err, server) => {\n              expect(err).to.be.instanceOf(MongoServerSelectionError);\n              expect(server).not.to.exist;\n              done();\n            });\n          });\n        });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"returns a MongoServerSelectionError","suites":["Topology (unit)","error handling","when server selection returns a server description but the description is not in the topology","when the topology originally contained more than one server"],"updatePoint":{"line":185,"column":47,"index":5655},"line":185,"code":"        it('returns a MongoServerSelectionError', function (done) {\n          topology = topologyWithPlaceholderClient([mockServer.hostAddress(), secondMockServer.hostAddress()]);\n          topology.connect(err => {\n            expect(err).to.not.exist;\n            sinon.stub(topology.s.servers, 'get').callsFake(() => {\n              return undefined;\n            });\n            topology.selectServer('primary', {}, (err, server) => {\n              expect(err).to.be.instanceOf(MongoServerSelectionError);\n              expect(server).not.to.exist;\n              done();\n            });\n          });\n        });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should set server to unknown and reset pool on `node is recovering` error","suites":["Topology (unit)","error handling","when server selection returns a server description but the description is not in the topology","when the topology originally contained more than one server"],"updatePoint":{"line":201,"column":81,"index":6323},"line":201,"code":"    it('should set server to unknown and reset pool on `node is recovering` error', function (done) {\n      mockServer.setMessageHandler(request => {\n        const doc = request.document;\n        if (isHello(doc)) {\n          request.reply(Object.assign({}, mock.HELLO, {\n            maxWireVersion: 9\n          }));\n        } else if (doc.insert) {\n          request.reply({\n            ok: 0,\n            message: 'node is recovering',\n            code: 11600\n          });\n        } else {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      topology = topologyWithPlaceholderClient(mockServer.hostAddress());\n      topology.connect(err => {\n        expect(err).to.not.exist;\n        topology.selectServer('primary', {}, (err, server) => {\n          expect(err).to.not.exist;\n          let serverDescription;\n          server.on('descriptionReceived', sd => serverDescription = sd);\n          let poolCleared = false;\n          topology.on('connectionPoolCleared', () => poolCleared = true);\n          server.command(ns('test.test'), {\n            insert: {\n              a: 42\n            }\n          }, {}, (err, result) => {\n            expect(result).to.not.exist;\n            expect(err).to.exist;\n            expect(err).to.eql(serverDescription.error);\n            expect(poolCleared).to.be.true;\n            done();\n          });\n        });\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should set server to unknown and NOT reset pool on stepdown errors","suites":["Topology (unit)","error handling","when server selection returns a server description but the description is not in the topology","when the topology originally contained more than one server"],"updatePoint":{"line":243,"column":74,"index":7719},"line":243,"code":"    it('should set server to unknown and NOT reset pool on stepdown errors', function (done) {\n      mockServer.setMessageHandler(request => {\n        const doc = request.document;\n        if (isHello(doc)) {\n          request.reply(Object.assign({}, mock.HELLO, {\n            maxWireVersion: 9\n          }));\n        } else if (doc.insert) {\n          request.reply({\n            ok: 0,\n            message: LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE.source\n          });\n        } else {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      const topology = topologyWithPlaceholderClient(mockServer.hostAddress());\n      topology.connect(err => {\n        expect(err).to.not.exist;\n        topology.selectServer('primary', {}, (err, server) => {\n          expect(err).to.not.exist;\n          let serverDescription;\n          server.on('descriptionReceived', sd => serverDescription = sd);\n          let poolCleared = false;\n          topology.on('connectionPoolCleared', () => poolCleared = true);\n          server.command(ns('test.test'), {\n            insert: {\n              a: 42\n            }\n          }, {}, (err, result) => {\n            expect(result).to.not.exist;\n            expect(err).to.exist;\n            expect(err).to.eql(serverDescription.error);\n            expect(poolCleared).to.be.false;\n            topology.close({}, done);\n          });\n        });\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should set server to unknown on non-timeout network error","suites":["Topology (unit)","error handling","when server selection returns a server description but the description is not in the topology","when the topology originally contained more than one server"],"updatePoint":{"line":284,"column":65,"index":9134},"line":284,"code":"    it('should set server to unknown on non-timeout network error', function (done) {\n      mockServer.setMessageHandler(request => {\n        const doc = request.document;\n        if (isHello(doc)) {\n          request.reply(Object.assign({}, mock.HELLO, {\n            maxWireVersion: 9\n          }));\n        } else if (doc.insert) {\n          request.connection.destroy();\n        } else {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      topology = topologyWithPlaceholderClient(mockServer.hostAddress());\n      topology.connect(err => {\n        expect(err).to.not.exist;\n        topology.selectServer('primary', {}, (err, server) => {\n          expect(err).to.not.exist;\n          let serverDescription;\n          server.on('descriptionReceived', sd => serverDescription = sd);\n          server.command(ns('test.test'), {\n            insert: {\n              a: 42\n            }\n          }, {}, (err, result) => {\n            expect(result).to.not.exist;\n            expect(err).to.exist;\n            expect(err).to.eql(serverDescription.error);\n            expect(server.description.type).to.equal('Unknown');\n            done();\n          });\n        });\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should encounter a server selection timeout on garbled server responses","suites":["Topology (unit)","error handling","when server selection returns a server description but the description is not in the topology","when the topology originally contained more than one server"],"updatePoint":{"line":320,"column":79,"index":10361},"line":320,"code":"    it('should encounter a server selection timeout on garbled server responses', function (done) {\n      const server = net.createServer();\n      const p = Promise.resolve();\n      let unexpectedError, expectedError;\n      server.listen(0, 'localhost', 2, () => {\n        server.on('connection', c => c.on('data', () => c.write('garbage_data')));\n        const {\n          address,\n          port\n        } = server.address();\n        const client = new MongoClient(`mongodb://${address}:${port}`, {\n          serverSelectionTimeoutMS: 1000\n        });\n        p.then(() => client.connect().then(() => {\n          unexpectedError = new Error('Expected a server selection error but got none');\n        }).catch(error => {\n          expectedError = error;\n        }).then(() => {\n          server.close();\n          return client.close(err => {\n            if (!unexpectedError) {\n              unexpectedError = err;\n            }\n          });\n        }).finally(() => {\n          if (unexpectedError) {\n            return done(unexpectedError);\n          }\n          if (expectedError) {\n            return done();\n          }\n        }));\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should emit topologyDescriptionChange event","suites":["Topology (unit)","error handling","srv event listeners","srvRecordDiscovery event listener"],"updatePoint":{"line":389,"column":55,"index":13337},"line":389,"code":"        it('should emit topologyDescriptionChange event', function () {\n          topology.once(Topology.TOPOLOGY_DESCRIPTION_CHANGED, ev => {\n            // The first event we get here is caused by the srv record discovery event below\n            expect(ev).to.have.nested.property('newDescription.servers');\n            expect(ev.newDescription.servers.get('fake:2')).to.be.a('object').with.property('address', 'fake:2');\n          });\n          topology.s.srvPoller.emit(SrvPoller.SRV_RECORD_DISCOVERY, new SrvPollingEvent([{\n            priority: 1,\n            weight: 1,\n            port: 2,\n            name: 'fake'\n          }]));\n        });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should clean up listeners on close","suites":["Topology (unit)","error handling","srv event listeners","srvRecordDiscovery event listener"],"updatePoint":{"line":402,"column":46,"index":13979},"line":402,"code":"        it('should clean up listeners on close', function (done) {\n          topology.s.state = 'connected'; // fake state to test clean up logic\n          topology.close({}, e => {\n            const srvPollerListeners = topology.s.srvPoller.listeners(SrvPoller.SRV_RECORD_DISCOVERY);\n            expect(srvPollerListeners).to.have.lengthOf(0);\n            const topologyChangeListeners = topology.listeners(Topology.TOPOLOGY_DESCRIPTION_CHANGED);\n            expect(topologyChangeListeners).to.have.lengthOf(0);\n            done(e);\n          });\n        });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should not add more than one srvRecordDiscovery listener","suites":["Topology (unit)","error handling","srv event listeners","topologyDescriptionChange event listener"],"updatePoint":{"line":414,"column":68,"index":14644},"line":414,"code":"        it('should not add more than one srvRecordDiscovery listener', function () {\n          // fake a transition to Sharded\n          transitionTopology(topology, TopologyType.Unknown, TopologyType.Sharded); // Transition 1\n\n          const srvListenersFirstTransition = topology.s.srvPoller.listeners(SrvPoller.SRV_RECORD_DISCOVERY);\n          expect(srvListenersFirstTransition).to.have.lengthOf(1);\n          transitionTopology(topology, TopologyType.Unknown, TopologyType.Sharded); // Transition 2\n\n          const srvListenersSecondTransition = topology.s.srvPoller.listeners(SrvPoller.SRV_RECORD_DISCOVERY);\n          expect(srvListenersSecondTransition).to.have.lengthOf(1);\n        });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should not add srvRecordDiscovery listener if transition is not to Sharded topology","suites":["Topology (unit)","error handling","srv event listeners","topologyDescriptionChange event listener"],"updatePoint":{"line":425,"column":95,"index":15368},"line":425,"code":"        it('should not add srvRecordDiscovery listener if transition is not to Sharded topology', function () {\n          // fake a transition to **NOT** Sharded\n          transitionTopology(topology, TopologyType.Unknown, TopologyType.ReplicaSetWithPrimary);\n          const srvListeners = topology.s.srvPoller.listeners(SrvPoller.SRV_RECORD_DISCOVERY);\n          expect(srvListeners).to.have.lengthOf(0);\n        });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should schedule monitoring if no suitable server is found","suites":["Topology (unit)","selectServer()"],"updatePoint":{"line":441,"column":65,"index":15967},"line":441,"code":"    it('should schedule monitoring if no suitable server is found', function (done) {\n      const topology = topologyWithPlaceholderClient('someserver:27019');\n      const requestCheck = this.sinon.stub(Server.prototype, 'requestCheck');\n\n      // satisfy the initial connect, then restore the original method\n      const selectServer = this.sinon.stub(Topology.prototype, 'selectServer').callsFake(function (selector, options, callback) {\n        const server = Array.from(this.s.servers.values())[0];\n        selectServer.restore();\n        callback(null, server);\n      });\n      this.sinon.stub(Server.prototype, 'connect').callsFake(function () {\n        this.s.state = 'connected';\n        this.emit('connect');\n      });\n      topology.connect(() => {\n        topology.selectServer(ReadPreference.secondary, {\n          serverSelectionTimeoutMS: 1000\n        }, err => {\n          expect(err).to.exist;\n          expect(err).to.match(/Server selection timed out/);\n          expect(err).to.have.property('reason');\n\n          // When server is created `connect` is called on the monitor. When server selection\n          // occurs `requestCheck` will be called for an immediate check.\n          expect(requestCheck).property('callCount').to.equal(1);\n          topology.close({}, done);\n        });\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should disallow selection when the topology is explicitly closed","suites":["Topology (unit)","selectServer()"],"updatePoint":{"line":470,"column":72,"index":17297},"line":470,"code":"    it('should disallow selection when the topology is explicitly closed', function (done) {\n      const topology = topologyWithPlaceholderClient('someserver:27019');\n      this.sinon.stub(Server.prototype, 'connect').callsFake(function () {\n        this.s.state = 'connected';\n        this.emit('connect');\n      });\n      topology.close({}, () => {\n        topology.selectServer(ReadPreference.primary, {\n          serverSelectionTimeoutMS: 2000\n        }, err => {\n          expect(err).to.exist;\n          expect(err).to.match(/Topology is closed/);\n          done();\n        });\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should process all wait queue members, including selection with errors","suites":["Topology (unit)","selectServer()","waitQueue"],"updatePoint":{"line":487,"column":80,"index":17947},"line":487,"code":"      it('should process all wait queue members, including selection with errors', function (done) {\n        const topology = topologyWithPlaceholderClient('someserver:27019');\n        const selectServer = this.sinon.stub(Topology.prototype, 'selectServer').callsFake(function (selector, options, callback) {\n          const server = Array.from(this.s.servers.values())[0];\n          selectServer.restore();\n          callback(null, server);\n        });\n        this.sinon.stub(Server.prototype, 'connect').callsFake(function () {\n          this.s.state = 'connected';\n          this.emit('connect');\n        });\n        const toSelect = 10;\n        let completed = 0;\n        function finish() {\n          completed++;\n          if (completed === toSelect) done();\n        }\n\n        // methodology:\n        //   - perform 9 server selections, a few with a selector that throws an error\n        //   - ensure each selection immediately returns an empty result (gated by a boolean)\n        //     guaranteeing tha the queue will be full before the last selection\n        //   - make one last selection, but ensure that all selections are no longer blocked from\n        //     returning their value\n        //   - verify that 10 callbacks were called\n\n        topology.connect(err => {\n          expect(err).to.not.exist;\n          let preventSelection = true;\n          const anySelector = td => {\n            if (preventSelection) return [];\n            const server = Array.from(td.servers.values())[0];\n            return [server];\n          };\n          const failingSelector = () => {\n            if (preventSelection) return [];\n            throw new TypeError('bad news!');\n          };\n          preventSelection = true;\n          for (let i = 0; i < toSelect - 1; ++i) {\n            topology.selectServer(i % 5 === 0 ? failingSelector : anySelector, {}, finish);\n          }\n          preventSelection = false;\n          topology.selectServer(anySelector, {}, finish);\n        });\n      });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if the session is snapshot enabled","suites":["Sessions - unit","class ClientSession","startTransaction()"],"updatePoint":{"line":45,"column":66,"index":996},"line":45,"code":"      it('should throw an error if the session is snapshot enabled', function () {\n        session = new ClientSession(client, serverSessionPool, {\n          snapshot: true\n        });\n        expect(session.snapshotEnabled).to.equal(true);\n        expect(() => session.startTransaction()).to.throw('Transactions are not supported in snapshot sessions');\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if the input cluster time is not an object","suites":["Sessions - unit","class ClientSession","advanceClusterTime()"],"updatePoint":{"line":54,"column":74,"index":1422},"line":54,"code":"      it('should throw an error if the input cluster time is not an object', function () {\n        const invalidInputs = [undefined, null, 3, 'a'];\n        for (const input of invalidInputs) {\n          expect(() => session.advanceClusterTime(input)).to.throw('input cluster time must be an object');\n        }\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if the input cluster time is missing a valid clusterTime property","suites":["Sessions - unit","class ClientSession","advanceClusterTime()"],"updatePoint":{"line":60,"column":97,"index":1766},"line":60,"code":"      it('should throw an error if the input cluster time is missing a valid clusterTime property', function () {\n        const invalidInputs = Array(5).fill(1).map(time => genClusterTime(time));\n        delete invalidInputs[0].clusterTime;\n        invalidInputs[1].clusterTime = null;\n        invalidInputs[2].clusterTime = 5;\n        invalidInputs[3].clusterTime = 'not a timestamp';\n        invalidInputs[4].clusterTime = new Date('1');\n        for (const input of invalidInputs) {\n          expect(() => session.advanceClusterTime(input), `expected to fail on input: ${JSON.stringify(input)}`).to.throw('input cluster time \"clusterTime\" property must be a valid BSON Timestamp');\n        }\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if the input cluster time is missing a valid signature property","suites":["Sessions - unit","class ClientSession","advanceClusterTime()"],"updatePoint":{"line":71,"column":95,"index":2468},"line":71,"code":"      it('should throw an error if the input cluster time is missing a valid signature property', function () {\n        const invalidInputs = Array(9).fill(1).map(time => genClusterTime(time));\n\n        // null types\n        delete invalidInputs[0].signature;\n        delete invalidInputs[1].signature.hash;\n        delete invalidInputs[2].signature.keyId;\n        invalidInputs[3].signature.hash = null;\n        invalidInputs[4].signature.keyId = null;\n        // invalid non-null types\n        // keyId must be number or BSON long\n        // hash must be BSON binary\n        invalidInputs[5].signature.keyId = {};\n        invalidInputs[6].signature.keyId = 'not BSON Long';\n        invalidInputs[7].signature.hash = 123;\n        invalidInputs[8].signature.hash = 'not BSON Binary';\n        for (const input of invalidInputs) {\n          expect(() => session.advanceClusterTime(input), `expected to fail on input: ${JSON.stringify(input)}`).to.throw('input cluster time must have a valid \"signature\" property with BSON Binary hash and BSON Long keyId');\n        }\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should set the session clusterTime to the one provided if the existing session clusterTime is null","suites":["Sessions - unit","class ClientSession","advanceClusterTime()"],"updatePoint":{"line":91,"column":108,"index":3556},"line":91,"code":"      it('should set the session clusterTime to the one provided if the existing session clusterTime is null', () => {\n        expect(session).property('clusterTime').to.be.undefined;\n        const validTime = genClusterTime(100);\n        session.advanceClusterTime(validTime);\n        expect(session).property('clusterTime').to.equal(validTime);\n        session.clusterTime = null;\n        expect(session).property('clusterTime').to.be.null;\n        session.advanceClusterTime(validTime);\n        expect(session).property('clusterTime').to.equal(validTime);\n\n        // extra test case for valid alternative keyId type in signature\n        const alsoValidTime = genClusterTime(200);\n        alsoValidTime.signature.keyId = 10;\n        session.clusterTime = null;\n        expect(session).property('clusterTime').to.be.null;\n        session.advanceClusterTime(alsoValidTime);\n        expect(session).property('clusterTime').to.equal(alsoValidTime);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"sets clusterTime to the one provided when the signature.keyId is a bigint","suites":["Sessions - unit","class ClientSession","advanceClusterTime()"],"updatePoint":{"line":109,"column":83,"index":4489},"line":109,"code":"      it('sets clusterTime to the one provided when the signature.keyId is a bigint', () => {\n        const validClusterTime = {\n          clusterTime: new BSON.Timestamp(BSON.Long.fromNumber(1, true)),\n          signature: {\n            hash: new BSON.Binary('test'),\n            keyId: 100n\n          }\n        };\n        session.advanceClusterTime(validClusterTime);\n        expect(session.clusterTime.signature.keyId).to.equal(100n);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should set the session clusterTime to the one provided if it is greater than the the existing session clusterTime","suites":["Sessions - unit","class ClientSession","advanceClusterTime()"],"updatePoint":{"line":120,"column":123,"index":4977},"line":120,"code":"      it('should set the session clusterTime to the one provided if it is greater than the the existing session clusterTime', () => {\n        const validInitialTime = genClusterTime(100);\n        const validGreaterTime = genClusterTime(200);\n        session.advanceClusterTime(validInitialTime);\n        expect(session).property('clusterTime').to.equal(validInitialTime);\n        session.advanceClusterTime(validGreaterTime);\n        expect(session).property('clusterTime').to.equal(validGreaterTime);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should leave the session clusterTime unchanged if it is less than or equal to the the existing session clusterTime","suites":["Sessions - unit","class ClientSession","advanceClusterTime()"],"updatePoint":{"line":128,"column":124,"index":5490},"line":128,"code":"      it('should leave the session clusterTime unchanged if it is less than or equal to the the existing session clusterTime', () => {\n        const validInitialTime = genClusterTime(100);\n        const validEqualTime = genClusterTime(100);\n        const validLesserTime = genClusterTime(50);\n        session.advanceClusterTime(validInitialTime);\n        expect(session).property('clusterTime').to.equal(validInitialTime);\n        session.advanceClusterTime(validEqualTime);\n        expect(session).property('clusterTime').to.equal(validInitialTime); // the reference check ensures no update happened\n\n        session.advanceClusterTime(validLesserTime);\n        expect(session).property('clusterTime').to.equal(validInitialTime);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw errors with invalid parameters","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":142,"column":53,"index":6212},"line":142,"code":"      it('should throw errors with invalid parameters', function () {\n        expect(() => {\n          new ClientSession();\n        }).to.throw(/ClientSession requires a MongoClient/);\n        expect(() => {\n          new ClientSession({});\n        }).to.throw(/ClientSession requires a ServerSessionPool/);\n        expect(() => {\n          new ClientSession({}, {});\n        }).to.throw(/ClientSession requires a ServerSessionPool/);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if snapshot and causalConsistency options are both set to true","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":153,"column":94,"index":6698},"line":153,"code":"      it('should throw an error if snapshot and causalConsistency options are both set to true', function () {\n        expect(() => new ClientSession(client, serverSessionPool, {\n          causalConsistency: true,\n          snapshot: true\n        })).to.throw('Properties \"causalConsistency\" and \"snapshot\" are mutually exclusive');\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should default `causalConsistency` to `true` for explicit non-snapshot sessions","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":159,"column":89,"index":7036},"line":159,"code":"      it('should default `causalConsistency` to `true` for explicit non-snapshot sessions', function () {\n        const session = new ClientSession(client, serverSessionPool, {\n          explicit: true\n        });\n        expect(session.supports).property('causalConsistency', true);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should default `causalConsistency` to `false` for explicit snapshot sessions","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":165,"column":86,"index":7327},"line":165,"code":"      it('should default `causalConsistency` to `false` for explicit snapshot sessions', function () {\n        const session = new ClientSession(client, serverSessionPool, {\n          explicit: true,\n          snapshot: true\n        });\n        expect(session.supports).property('causalConsistency', false);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should allow `causalConsistency=false` option in explicit snapshot sessions","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":172,"column":85,"index":7644},"line":172,"code":"      it('should allow `causalConsistency=false` option in explicit snapshot sessions', function () {\n        const session = new ClientSession(client, serverSessionPool, {\n          explicit: true,\n          causalConsistency: false,\n          snapshot: true\n        });\n        expect(session.supports).property('causalConsistency', false);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should respect `causalConsistency=false` option in explicit sessions","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":180,"column":78,"index":7990},"line":180,"code":"      it('should respect `causalConsistency=false` option in explicit sessions', function () {\n        const session = new ClientSession(client, serverSessionPool, {\n          explicit: true,\n          causalConsistency: false\n        });\n        expect(session.supports).property('causalConsistency', false);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should respect `causalConsistency=true` option in explicit non-snapshot sessions","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":187,"column":90,"index":8322},"line":187,"code":"      it('should respect `causalConsistency=true` option in explicit non-snapshot sessions', function () {\n        const session = new ClientSession(client, serverSessionPool, {\n          explicit: true,\n          causalConsistency: true\n        });\n        expect(session.supports).property('causalConsistency', true);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should default `causalConsistency` to `false` for implicit sessions","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":194,"column":77,"index":8639},"line":194,"code":"      it('should default `causalConsistency` to `false` for implicit sessions', function () {\n        const session = new ClientSession(client, serverSessionPool, {\n          explicit: false\n        });\n        expect(session.supports).property('causalConsistency', false);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should respect `causalConsistency=false` option in implicit sessions","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":200,"column":78,"index":8924},"line":200,"code":"      it('should respect `causalConsistency=false` option in implicit sessions', function () {\n        const session = new ClientSession(client, serverSessionPool, {\n          explicit: false,\n          causalConsistency: false\n        });\n        expect(session.supports).property('causalConsistency', false);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should respect `causalConsistency=true` option in implicit sessions","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":207,"column":77,"index":9244},"line":207,"code":"      it('should respect `causalConsistency=true` option in implicit sessions', function () {\n        const session = new ClientSession(client, serverSessionPool, {\n          explicit: false,\n          causalConsistency: true\n        });\n        expect(session.supports).property('causalConsistency', true);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should default to `null` for `clusterTime`","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":214,"column":52,"index":9537},"line":214,"code":"      it('should default to `null` for `clusterTime`', function () {\n        const session = new ClientSession(client, serverSessionPool);\n        expect(session.clusterTime).to.not.exist;\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should set the internal clusterTime to `initialClusterTime` if provided","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":218,"column":81,"index":9765},"line":218,"code":"      it('should set the internal clusterTime to `initialClusterTime` if provided', function () {\n        const clusterTime = genClusterTime(Date.now());\n        const session = new ClientSession(client, serverSessionPool, {\n          initialClusterTime: clusterTime\n        });\n        expect(session.clusterTime).to.eql(clusterTime);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should acquire a serverSession in the constructor if the session is explicit","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":225,"column":86,"index":10116},"line":225,"code":"      it('should acquire a serverSession in the constructor if the session is explicit', () => {\n        const session = new ClientSession(client, serverSessionPool, {\n          explicit: true\n        });\n        const serverSessionSymbol = getSymbolFrom(session, 'serverSession');\n        expect(session).to.have.property(serverSessionSymbol).that.is.an.instanceOf(ServerSession);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should leave serverSession null if the session is implicit","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":232,"column":68,"index":10490},"line":232,"code":"      it('should leave serverSession null if the session is implicit', () => {\n        // implicit via false (this should not be allowed...)\n        let session = new ClientSession(client, serverSessionPool, {\n          explicit: false\n        });\n        const serverSessionSymbol = getSymbolFrom(session, 'serverSession');\n        expect(session).to.have.property(serverSessionSymbol, null);\n        // implicit via omission\n        session = new ClientSession(client, serverSessionPool, {});\n        expect(session).to.have.property(serverSessionSymbol, null);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should start the txnNumberIncrement at zero","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":243,"column":53,"index":11049},"line":243,"code":"      it('should start the txnNumberIncrement at zero', () => {\n        const session = new ClientSession(client, serverSessionPool);\n        const txnNumberIncrementSymbol = getSymbolFrom(session, 'txnNumberIncrement');\n        expect(session).to.have.property(txnNumberIncrementSymbol, 0);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should always have a non-null serverSession after construction","suites":["Sessions - unit","class ClientSession","get serverSession()","from an explicit session"],"updatePoint":{"line":255,"column":74,"index":11645},"line":255,"code":"        it('should always have a non-null serverSession after construction', () => {\n          const session = new ClientSession(client, serverSessionPool, {\n            explicit: true\n          });\n          expect(session).to.have.a.property(serverSessionSymbol).be.an.instanceOf(ServerSession);\n          expect(session.serverSession).be.an.instanceOf(ServerSession);\n        });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should always have non-null serverSession even if it is ended before getter called","suites":["Sessions - unit","class ClientSession","get serverSession()","from an explicit session"],"updatePoint":{"line":262,"column":94,"index":12048},"line":262,"code":"        it('should always have non-null serverSession even if it is ended before getter called', () => {\n          const session = new ClientSession(client, serverSessionPool, {\n            explicit: true\n          });\n          session.hasEnded = true;\n          expect(session).to.have.a.property(serverSessionSymbol).be.an.instanceOf(ServerSession);\n          expect(session.serverSession).be.an.instanceOf(ServerSession);\n        });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw if the serverSession at the symbol property goes missing","suites":["Sessions - unit","class ClientSession","get serverSession()","from an explicit session"],"updatePoint":{"line":270,"column":81,"index":12473},"line":270,"code":"        it('should throw if the serverSession at the symbol property goes missing', () => {\n          const session = new ClientSession(client, serverSessionPool, {\n            explicit: true\n          });\n          // We really want to make sure a ClientSession is not separated from its serverSession\n          session[serverSessionSymbol] = null;\n          expect(session).to.have.a.property(serverSessionSymbol).be.null;\n          expect(() => session.serverSession).throw(MongoRuntimeError);\n        });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw if the session ended before serverSession was acquired","suites":["Sessions - unit","class ClientSession","get serverSession()","from an implicit session"],"updatePoint":{"line":281,"column":79,"index":13041},"line":281,"code":"        it('should throw if the session ended before serverSession was acquired', () => {\n          const session = new ClientSession(client, serverSessionPool, {\n            explicit: false\n          }); // make an implicit session\n          expect(session).to.have.property(serverSessionSymbol, null);\n          session.hasEnded = true;\n          expect(() => session.serverSession).to.throw(MongoRuntimeError);\n        });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should acquire a serverSession if clientSession.hasEnded is false and serverSession is not set","suites":["Sessions - unit","class ClientSession","get serverSession()","from an implicit session"],"updatePoint":{"line":289,"column":106,"index":13494},"line":289,"code":"        it('should acquire a serverSession if clientSession.hasEnded is false and serverSession is not set', () => {\n          const session = new ClientSession(client, serverSessionPool, {\n            explicit: false\n          }); // make an implicit session\n          expect(session).to.have.property(serverSessionSymbol, null);\n          session.hasEnded = false;\n          const acquireSpy = sinon.spy(serverSessionPool, 'acquire');\n          expect(session.serverSession).to.be.instanceOf(ServerSession);\n          expect(acquireSpy.calledOnce).to.be.true;\n          acquireSpy.restore();\n        });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should return the existing serverSession and not acquire a new one if one is already set","suites":["Sessions - unit","class ClientSession","get serverSession()","from an implicit session"],"updatePoint":{"line":300,"column":100,"index":14094},"line":300,"code":"        it('should return the existing serverSession and not acquire a new one if one is already set', () => {\n          const session = new ClientSession(client, serverSessionPool, {\n            explicit: false\n          }); // make an implicit session\n          expect(session).to.have.property(serverSessionSymbol, null);\n          const acquireSpy = sinon.spy(serverSessionPool, 'acquire');\n          const firstServerSessionGetResult = session.serverSession;\n          expect(firstServerSessionGetResult).to.be.instanceOf(ServerSession);\n          expect(acquireSpy.calledOnce).to.be.true;\n\n          // call the getter a bunch more times\n          expect(session.serverSession).to.be.instanceOf(ServerSession);\n          expect(session.serverSession).to.be.instanceOf(ServerSession);\n          expect(session.serverSession).to.be.instanceOf(ServerSession);\n          expect(session.serverSession.id.id.buffer.toString('hex')).to.equal(firstServerSessionGetResult.id.id.buffer.toString('hex'));\n\n          // acquire never called again\n          expect(acquireSpy.calledOnce).to.be.true;\n          acquireSpy.restore();\n        });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should return the existing serverSession and not acquire a new one if one is already set and session is ended","suites":["Sessions - unit","class ClientSession","get serverSession()","from an implicit session"],"updatePoint":{"line":320,"column":121,"index":15252},"line":320,"code":"        it('should return the existing serverSession and not acquire a new one if one is already set and session is ended', () => {\n          const session = new ClientSession(client, serverSessionPool, {\n            explicit: false\n          }); // make an implicit session\n          expect(session).to.have.property(serverSessionSymbol, null);\n          const acquireSpy = sinon.spy(serverSessionPool, 'acquire');\n          const firstServerSessionGetResult = session.serverSession;\n          expect(firstServerSessionGetResult).to.be.instanceOf(ServerSession);\n          expect(acquireSpy.calledOnce).to.be.true;\n          session.hasEnded = true;\n\n          // call the getter a bunch more times\n          expect(session.serverSession).to.be.instanceOf(ServerSession);\n          expect(session.serverSession).to.be.instanceOf(ServerSession);\n          expect(session.serverSession).to.be.instanceOf(ServerSession);\n          expect(session.serverSession.id.id.buffer.toString('hex')).to.equal(firstServerSessionGetResult.id.id.buffer.toString('hex'));\n\n          // acquire never called again\n          expect(acquireSpy.calledOnce).to.be.true;\n          acquireSpy.restore();\n        });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should not allocate serverSession","suites":["Sessions - unit","class ClientSession","incrementTransactionNumber()"],"updatePoint":{"line":344,"column":43,"index":16438},"line":344,"code":"      it('should not allocate serverSession', () => {\n        const session = new ClientSession(client, serverSessionPool);\n        const txnNumberIncrementSymbol = getSymbolFrom(session, 'txnNumberIncrement');\n        session.incrementTransactionNumber();\n        expect(session).to.have.property(txnNumberIncrementSymbol, 1);\n        const serverSessionSymbol = getSymbolFrom(session, 'serverSession');\n        expect(session).to.have.property(serverSessionSymbol, null);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should save increments to txnNumberIncrement symbol","suites":["Sessions - unit","class ClientSession","incrementTransactionNumber()"],"updatePoint":{"line":352,"column":61,"index":16940},"line":352,"code":"      it('should save increments to txnNumberIncrement symbol', () => {\n        const session = new ClientSession(client, serverSessionPool);\n        const txnNumberIncrementSymbol = getSymbolFrom(session, 'txnNumberIncrement');\n        session.incrementTransactionNumber();\n        session.incrementTransactionNumber();\n        session.incrementTransactionNumber();\n        expect(session).to.have.property(txnNumberIncrementSymbol, 3);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should allocate serverSession","suites":["Sessions - unit","class ClientSession","applySession()"],"updatePoint":{"line":362,"column":39,"index":17413},"line":362,"code":"      it('should allocate serverSession', () => {\n        const session = new ClientSession(client, serverSessionPool);\n        const serverSessionSymbol = getSymbolFrom(session, 'serverSession');\n        const command = {\n          magic: 1\n        };\n        const result = applySession(session, command, {});\n        expect(result).to.not.exist;\n        expect(command).to.have.property('lsid');\n        expect(session).to.have.property(serverSessionSymbol).that.is.instanceOf(ServerSession);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should apply saved txnNumberIncrements","suites":["Sessions - unit","class ClientSession","applySession()"],"updatePoint":{"line":373,"column":48,"index":17928},"line":373,"code":"      it('should apply saved txnNumberIncrements', () => {\n        const session = new ClientSession(client, serverSessionPool);\n        const serverSessionSymbol = getSymbolFrom(session, 'serverSession');\n        session.incrementTransactionNumber();\n        session.incrementTransactionNumber();\n        session.incrementTransactionNumber();\n        const command = {\n          magic: 1\n        };\n        const result = applySession(session, command, {\n          // txnNumber will be applied for retryable write command\n          willRetryWrite: true\n        });\n        expect(result).to.not.exist;\n        expect(command).to.have.property('lsid');\n        expect(command).to.have.property('txnNumber').instanceOf(Long);\n        expect(command.txnNumber.toNumber()).to.equal(3);\n        expect(session).to.have.property(serverSessionSymbol).that.is.instanceOf(ServerSession);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw errors with invalid parameters","suites":["Sessions - unit","class ServerSessionPool"],"updatePoint":{"line":414,"column":51,"index":19445},"line":414,"code":"    it('should throw errors with invalid parameters', function () {\n      expect(() => new ServerSessionPool()).to.throw(MongoRuntimeError);\n    });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should create a new session if the pool is empty","suites":["Sessions - unit","class ServerSessionPool"],"updatePoint":{"line":417,"column":56,"index":19599},"line":417,"code":"    it('should create a new session if the pool is empty', function (done) {\n      const pool = new ServerSessionPool(client);\n      expect(pool.sessions).to.have.length(0);\n      const session = pool.acquire();\n      expect(session).to.exist;\n      expect(pool.sessions).to.have.length(0);\n      pool.release(session);\n      done();\n    });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should reuse sessions which have not timed out yet on acquire","suites":["Sessions - unit","class ServerSessionPool"],"updatePoint":{"line":426,"column":69,"index":19954},"line":426,"code":"    it('should reuse sessions which have not timed out yet on acquire', function (done) {\n      const oldSession = new ServerSession();\n      const pool = new ServerSessionPool(client);\n      pool.sessions.push(oldSession);\n      const session = pool.acquire();\n      expect(session).to.exist;\n      expect(session).to.eql(oldSession);\n      pool.release(session);\n      done();\n    });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should remove sessions which have timed out on acquire, and return a fresh session","suites":["Sessions - unit","class ServerSessionPool"],"updatePoint":{"line":436,"column":90,"index":20362},"line":436,"code":"    it('should remove sessions which have timed out on acquire, and return a fresh session', function (done) {\n      const oldSession = new ServerSession();\n      oldSession.lastUse = now() - 30 * 60 * 1000; // add 30min\n\n      const pool = new ServerSessionPool(client);\n      pool.sessions.push(oldSession);\n      const session = pool.acquire();\n      expect(session).to.exist;\n      expect(session).to.not.eql(oldSession);\n      pool.release(session);\n      done();\n    });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should remove old sessions if they are at the start of the pool","suites":["Sessions - unit","class ServerSessionPool","release()"],"updatePoint":{"line":454,"column":73,"index":21043},"line":454,"code":"      it('should remove old sessions if they are at the start of the pool', () => {\n        const pool = new ServerSessionPool(client);\n        // old sessions at the start\n        pool.sessions.pushMany(Array.from({\n          length: 3\n        }, () => makeOldSession()));\n        pool.sessions.pushMany([new ServerSession(), new ServerSession()]);\n        pool.release(new ServerSession());\n        expect(pool.sessions).to.have.lengthOf(3);\n        const anyTimedOutSessions = pool.sessions.toArray().some(s => s.hasTimedOut(30 * 60 * 1000));\n        expect(anyTimedOutSessions, 'Unexpected timed out sessions found in pool after release').to.be.false;\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should remove old sessions if they are in the middle of the pool","suites":["Sessions - unit","class ServerSessionPool","release()"],"updatePoint":{"line":466,"column":74,"index":21710},"line":466,"code":"      it('should remove old sessions if they are in the middle of the pool', () => {\n        const pool = new ServerSessionPool(client);\n        pool.sessions.push(new ServerSession()); // one fresh before\n        pool.sessions.pushMany(Array.from({\n          length: 3\n        }, () => makeOldSession()));\n        pool.sessions.push(new ServerSession()); // one fresh after\n\n        pool.release(new ServerSession());\n        expect(pool.sessions).to.have.lengthOf(3);\n        const anyTimedOutSessions = pool.sessions.toArray().some(s => s.hasTimedOut(30 * 60 * 1000));\n        expect(anyTimedOutSessions, 'Unexpected timed out sessions found in pool after release').to.be.false;\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should remove old sessions if they are at the end of the pool","suites":["Sessions - unit","class ServerSessionPool","release()"],"updatePoint":{"line":479,"column":71,"index":22399},"line":479,"code":"      it('should remove old sessions if they are at the end of the pool', () => {\n        const pool = new ServerSessionPool(client);\n        pool.sessions.pushMany([new ServerSession(), new ServerSession()]);\n        const oldSession = makeOldSession();\n        pool.sessions.push(oldSession);\n        pool.release(new ServerSession());\n        expect(pool.sessions).to.have.lengthOf(3);\n        const anyTimedOutSessions = pool.sessions.toArray().some(s => s.hasTimedOut(30 * 60 * 1000));\n        expect(anyTimedOutSessions, 'Unexpected timed out sessions found in pool after release').to.be.false;\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should remove old sessions that are not contiguous in the pool","suites":["Sessions - unit","class ServerSessionPool","release()"],"updatePoint":{"line":489,"column":72,"index":23011},"line":489,"code":"      it('should remove old sessions that are not contiguous in the pool', () => {\n        const pool = new ServerSessionPool(client);\n        pool.sessions.pushMany([makeOldSession(), new ServerSession(), makeOldSession(), new ServerSession(), makeOldSession()]);\n        pool.release(new ServerSession());\n        expect(pool.sessions).to.have.lengthOf(3);\n        const anyTimedOutSessions = pool.sessions.toArray().some(s => s.hasTimedOut(30 * 60 * 1000));\n        expect(anyTimedOutSessions, 'Unexpected timed out sessions found in pool after release').to.be.false;\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should not reintroduce a soon-to-expire session to the pool on release","suites":["Sessions - unit","class ServerSessionPool","release()"],"updatePoint":{"line":498,"column":78,"index":23606},"line":498,"code":"    it('should not reintroduce a soon-to-expire session to the pool on release', function (done) {\n      const session = new ServerSession();\n      session.lastUse = now() - 9.5 * 60 * 1000; // add 9.5min\n\n      const pool = new ServerSessionPool(client);\n      pool.release(session);\n      expect(pool.sessions).to.have.length(0);\n      done();\n    });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should maintain a LIFO queue of sessions","suites":["Sessions - unit","class ServerSessionPool","release()"],"updatePoint":{"line":507,"column":48,"index":23930},"line":507,"code":"    it('should maintain a LIFO queue of sessions', function (done) {\n      const pool = new ServerSessionPool(client);\n      const sessionA = new ServerSession();\n      const sessionB = new ServerSession();\n      pool.release(sessionA);\n      pool.release(sessionB);\n      const sessionC = pool.acquire();\n      const sessionD = pool.acquire();\n      expect(sessionC.id).to.eql(sessionB.id);\n      expect(sessionD.id).to.eql(sessionA.id);\n      pool.release(sessionC);\n      pool.release(sessionD);\n      done();\n    });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"does not configure the provider if none is given","suites":["parseOptions","aws providers"],"updatePoint":{"line":5,"column":56,"index":251},"line":5,"code":"    it('does not configure the provider if none is given', function () {\n      const parsedProviders = mergeKMSProviders({}, {});\n      expect(parsedProviders).not.to.have.property('aws');\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"configures the provider without credentials if an empty object is supplied","suites":["parseOptions","aws providers"],"updatePoint":{"line":9,"column":82,"index":474},"line":9,"code":"    it('configures the provider without credentials if an empty object is supplied', function () {\n      const parsedProviders = mergeKMSProviders({\n        aws: {}\n      }, {});\n      expect(parsedProviders.aws).deep.equal({});\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"replaces a $$placeholder value with the value from the environment","suites":["parseOptions","aws providers"],"updatePoint":{"line":15,"column":74,"index":703},"line":15,"code":"    it('replaces a $$placeholder value with the value from the environment', function () {\n      const parsedProviders = mergeKMSProviders({\n        aws: {\n          accessKeyId: {\n            $$placeholder: 1\n          },\n          secretAccessKey: 'secretAccessKey'\n        }\n      }, {\n        aws: {\n          accessKeyId: 'accessKeyId'\n        }\n      });\n      expect(parsedProviders.aws).deep.equal({\n        accessKeyId: 'accessKeyId',\n        secretAccessKey: 'secretAccessKey'\n      });\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"omits required fields if the field is not present in the kmsProviders","suites":["parseOptions","aws providers"],"updatePoint":{"line":33,"column":77,"index":1211},"line":33,"code":"    it('omits required fields if the field is not present in the kmsProviders', function () {\n      const parsedProviders = mergeKMSProviders({\n        aws: {\n          accessKeyId: {\n            $$placeholder: 1\n          }\n        }\n      }, {\n        aws: {\n          accessKeyId: 'accessKeyId'\n        }\n      });\n      expect(parsedProviders.aws).not.to.have.property('secretAccessKey');\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"configures the provider with the exact credentials from the test","suites":["parseOptions","aws providers"],"updatePoint":{"line":47,"column":72,"index":1607},"line":47,"code":"    it('configures the provider with the exact credentials from the test', function () {\n      const parsedProviders = mergeKMSProviders({\n        aws: {\n          accessKeyId: 'accessKeyId',\n          secretAccessKey: 'secretAccessKey',\n          sessionToken: 'sessionToken'\n        }\n      }, {\n        aws: {\n          accessKeyId: 'accessKeyIdFromEnvironment',\n          secretAccessKey: 'secretAccessKeyFromEnvironment',\n          sessionToken: 'sessionTokenFromEnvironment'\n        }\n      });\n      expect(parsedProviders.aws).deep.equal({\n        accessKeyId: 'accessKeyId',\n        secretAccessKey: 'secretAccessKey',\n        sessionToken: 'sessionToken'\n      });\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"does not configure the provider if none is given","suites":["parseOptions","local providers"],"updatePoint":{"line":69,"column":56,"index":2323},"line":69,"code":"    it('does not configure the provider if none is given', function () {\n      const parsedProviders = mergeKMSProviders({}, {});\n      expect(parsedProviders).not.to.have.property('local');\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"configures the provider without credentials if an empty object is supplied","suites":["parseOptions","local providers"],"updatePoint":{"line":73,"column":82,"index":2548},"line":73,"code":"    it('configures the provider without credentials if an empty object is supplied', function () {\n      const parsedProviders = mergeKMSProviders({\n        local: {}\n      }, {});\n      expect(parsedProviders.local).deep.equal({});\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"replaces a $$placeholder value with the value from the environment","suites":["parseOptions","local providers"],"updatePoint":{"line":79,"column":74,"index":2781},"line":79,"code":"    it('replaces a $$placeholder value with the value from the environment', function () {\n      const parsedProviders = mergeKMSProviders({\n        local: {\n          key: {\n            $$placeholder: 1\n          }\n        }\n      }, {\n        local: {\n          key: 'key'\n        }\n      });\n      expect(parsedProviders.local).deep.equal({\n        key: 'key'\n      });\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"configures the provider with the exact credentials from the test","suites":["parseOptions","local providers"],"updatePoint":{"line":95,"column":72,"index":3160},"line":95,"code":"    it('configures the provider with the exact credentials from the test', function () {\n      const parsedProviders = mergeKMSProviders({\n        local: {\n          key: 'key'\n        }\n      }, {\n        local: {\n          key: 'keyFromEnvironment'\n        }\n      });\n      expect(parsedProviders.local).deep.equal({\n        key: 'key'\n      });\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"does not configure the provider if none is given","suites":["parseOptions","azure"],"updatePoint":{"line":111,"column":56,"index":3540},"line":111,"code":"    it('does not configure the provider if none is given', function () {\n      const parsedProviders = mergeKMSProviders({}, {});\n      expect(parsedProviders).not.to.have.property('azure');\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"configures the provider without credentials if an empty object is supplied","suites":["parseOptions","azure"],"updatePoint":{"line":115,"column":82,"index":3765},"line":115,"code":"    it('configures the provider without credentials if an empty object is supplied', function () {\n      const parsedProviders = mergeKMSProviders({\n        azure: {}\n      }, {});\n      expect(parsedProviders.azure).deep.equal({});\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"replaces a $$placeholder value with the value from the environment","suites":["parseOptions","azure"],"updatePoint":{"line":121,"column":74,"index":3998},"line":121,"code":"    it('replaces a $$placeholder value with the value from the environment', function () {\n      const parsedProviders = mergeKMSProviders({\n        azure: {\n          tenantId: 'tenantId',\n          clientId: {\n            $$placeholder: 1\n          },\n          clientSecret: 'clientSecret',\n          identityPlatformEndpoint: 'identifyPlatformEndpoint'\n        }\n      }, {\n        azure: {\n          clientId: 'clientId'\n        }\n      });\n      expect(parsedProviders.azure).deep.equal({\n        tenantId: 'tenantId',\n        clientId: 'clientId',\n        clientSecret: 'clientSecret',\n        identityPlatformEndpoint: 'identifyPlatformEndpoint'\n      });\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"omits required fields if the field is not present in the kmsProviders","suites":["parseOptions","azure"],"updatePoint":{"line":143,"column":77,"index":4673},"line":143,"code":"    it('omits required fields if the field is not present in the kmsProviders', function () {\n      const parsedProviders = mergeKMSProviders({\n        azure: {\n          tenantId: 'tenantId',\n          clientSecret: 'clientSecret',\n          identityPlatformEndpoint: 'identifyPlatformEndpoint'\n        }\n      }, {});\n      expect(parsedProviders.azure).not.to.have.property('clientId');\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"configures the provider with the exact credentials from the test otherwise","suites":["parseOptions","azure"],"updatePoint":{"line":153,"column":82,"index":5076},"line":153,"code":"    it('configures the provider with the exact credentials from the test otherwise', function () {\n      const parsedProviders = mergeKMSProviders({\n        azure: {\n          tenantId: 'tenantId',\n          clientId: 'clientId',\n          clientSecret: 'clientSecret',\n          identityPlatformEndpoint: 'identifyPlatformEndpoint'\n        }\n      }, {\n        azure: {\n          tenantId: 'tenantIdFromEnvironment',\n          clientId: 'clientIdFromEnvironment',\n          clientSecret: 'clientSecretFromEnvironment',\n          identityPlatformEndpoint: 'identifyPlatformEndpointFromEnvironment'\n        }\n      });\n      expect(parsedProviders.azure).deep.equal({\n        tenantId: 'tenantId',\n        clientId: 'clientId',\n        clientSecret: 'clientSecret',\n        identityPlatformEndpoint: 'identifyPlatformEndpoint'\n      });\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"does not configure the provider if none is given","suites":["parseOptions","gcp"],"updatePoint":{"line":178,"column":56,"index":5931},"line":178,"code":"    it('does not configure the provider if none is given', function () {\n      const parsedProviders = mergeKMSProviders({}, {});\n      expect(parsedProviders).not.to.have.property('gcp');\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"configures the provider without credentials if an empty object is supplied","suites":["parseOptions","gcp"],"updatePoint":{"line":182,"column":82,"index":6154},"line":182,"code":"    it('configures the provider without credentials if an empty object is supplied', function () {\n      const parsedProviders = mergeKMSProviders({\n        gcp: {}\n      }, {});\n      expect(parsedProviders.gcp).deep.equal({});\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"replaces a $$placeholder value with the value from the environment","suites":["parseOptions","gcp"],"updatePoint":{"line":188,"column":74,"index":6383},"line":188,"code":"    it('replaces a $$placeholder value with the value from the environment', function () {\n      const parsedProviders = mergeKMSProviders({\n        gcp: {\n          email: 'email',\n          privateKey: {\n            $$placeholder: 1\n          },\n          endPoint: 'endPoint'\n        }\n      }, {\n        gcp: {\n          privateKey: 'privateKeyFromEnvironment'\n        }\n      });\n      expect(parsedProviders.gcp).deep.equal({\n        email: 'email',\n        privateKey: 'privateKeyFromEnvironment',\n        endPoint: 'endPoint'\n      });\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"omits required fields if the field is not present in the kmsProviders","suites":["parseOptions","gcp"],"updatePoint":{"line":208,"column":77,"index":6938},"line":208,"code":"    it('omits required fields if the field is not present in the kmsProviders', function () {\n      const parsedProviders = mergeKMSProviders({\n        gcp: {\n          email: 'email',\n          endPoint: 'endPoint'\n        }\n      }, {});\n      expect(parsedProviders.gcp).not.to.have.property('privateKey');\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"configures the provider with the exact credentials from the test otherwise","suites":["parseOptions","gcp"],"updatePoint":{"line":217,"column":82,"index":7261},"line":217,"code":"    it('configures the provider with the exact credentials from the test otherwise', function () {\n      const parsedProviders = mergeKMSProviders({\n        gcp: {\n          email: 'email',\n          privateKey: 'privateKey',\n          endPoint: 'endPoint'\n        }\n      }, {\n        gcp: {\n          email: 'emailFromEnvironment',\n          privateKey: 'privateKeyFromEnvironment',\n          endPoint: 'endPointFromEnvironment'\n        }\n      });\n      expect(parsedProviders.gcp).deep.equal({\n        email: 'email',\n        privateKey: 'privateKey',\n        endPoint: 'endPoint'\n      });\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"does not configure the provider if none is given","suites":["parseOptions","kmip"],"updatePoint":{"line":239,"column":56,"index":7876},"line":239,"code":"    it('does not configure the provider if none is given', function () {\n      const parsedProviders = mergeKMSProviders({}, {});\n      expect(parsedProviders).not.to.have.property('kmip');\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"configures the provider without credentials if an empty object is supplied","suites":["parseOptions","kmip"],"updatePoint":{"line":243,"column":82,"index":8100},"line":243,"code":"    it('configures the provider without credentials if an empty object is supplied', function () {\n      const parsedProviders = mergeKMSProviders({\n        kmip: {}\n      }, {});\n      expect(parsedProviders.kmip).deep.equal({});\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"replaces a $$placeholder value with the value from the environment","suites":["parseOptions","kmip"],"updatePoint":{"line":249,"column":74,"index":8331},"line":249,"code":"    it('replaces a $$placeholder value with the value from the environment', function () {\n      const parsedProviders = mergeKMSProviders({\n        kmip: {\n          endpoint: {\n            $$placeholder: 1\n          }\n        }\n      }, {\n        kmip: {\n          endpoint: 'endpointFromEnvironment'\n        }\n      });\n      expect(parsedProviders.kmip).deep.equal({\n        endpoint: 'endpointFromEnvironment'\n      });\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"configures the provider with the exact credentials from the test otherwise","suites":["parseOptions","kmip"],"updatePoint":{"line":265,"column":82,"index":8772},"line":265,"code":"    it('configures the provider with the exact credentials from the test otherwise', function () {\n      const parsedProviders = mergeKMSProviders({\n        kmip: {\n          endpoint: 'endpoint'\n        }\n      }, {\n        kmip: {\n          endpoint: 'endpointFromEnvironment'\n        }\n      });\n      expect(parsedProviders.kmip).deep.equal({\n        endpoint: 'endpoint'\n      });\n    });","file":"unit/tools/unifed-utils.test.ts","skipped":false,"dir":"test"},{"name":"throws AssertionError when it finds extra keys","suites":["Unified Spec Runner","Matching","resultCheck","$$matchAsDocument","when actual value is EJSON string"],"updatePoint":{"line":35,"column":60,"index":1226},"line":35,"code":"          it('throws AssertionError when it finds extra keys', function () {\n            actual = '{\"data\": {\"$numberLong\": \"100\"}, \"a\": {\"$numberInt\": \"10\"}, \"b\": {\"$numberInt\": \"100\"}}';\n            expect(() => resultCheckSpy(actual, expected, entitiesMap, [])).to.throw(AssertionError, /object has more keys than expected/);\n          });","file":"unit/tools/unified_spec_runner.test.ts","skipped":false,"dir":"test"},{"name":"passes when all keys match","suites":["Unified Spec Runner","Matching","resultCheck","$$matchAsDocument","when actual value is EJSON string"],"updatePoint":{"line":39,"column":40,"index":1549},"line":39,"code":"          it('passes when all keys match', function () {\n            actual = '{\"data\": {\"$numberLong\": \"100\"}, \"a\": {\"$numberInt\": \"10\"}}';\n            resultCheckSpy(actual, expected, entitiesMap, []);\n          });","file":"unit/tools/unified_spec_runner.test.ts","skipped":false,"dir":"test"},{"name":"throws AssertionError","suites":["Unified Spec Runner","Matching","resultCheck","$$matchAsDocument","when actual value is not EJSON string"],"updatePoint":{"line":45,"column":35,"index":1845},"line":45,"code":"          it('throws AssertionError', function () {\n            actual = {\n              data: {\n                $numberLong: '100'\n              },\n              a: {\n                $numberInt: 10\n              }\n            };\n            expect(() => resultCheckSpy(actual, expected, entitiesMap, [])).to.throw(AssertionError, /Expected .* to be string/);\n          });","file":"unit/tools/unified_spec_runner.test.ts","skipped":false,"dir":"test"},{"name":"passes when all expected keys match and there are extra keys","suites":["Unified Spec Runner","Matching","resultCheck","$$matchAsRoot","when expected and actual values are documents"],"updatePoint":{"line":74,"column":74,"index":2743},"line":74,"code":"          it('passes when all expected keys match and there are extra keys', function () {\n            actual = {\n              data: {\n                data: new BSON.Long(100),\n                a: 10,\n                b: 100\n              }\n            };\n            resultCheckSpy(actual, expected, entitiesMap, []);\n          });","file":"unit/tools/unified_spec_runner.test.ts","skipped":false,"dir":"test"},{"name":"throws AssertionError when some expected keys differ","suites":["Unified Spec Runner","Matching","resultCheck","$$matchAsRoot","when expected and actual values are documents"],"updatePoint":{"line":84,"column":66,"index":3067},"line":84,"code":"          it('throws AssertionError when some expected keys differ', function () {\n            actual = {\n              data: {\n                data: new BSON.Long(100),\n                a: 'string'\n              }\n            };\n            expect(() => resultCheckSpy(actual, expected, entitiesMap, [])).to.throw(AssertionError, /Expected \\[string\\] to be one of \\[int\\]/);\n          });","file":"unit/tools/unified_spec_runner.test.ts","skipped":false,"dir":"test"},{"name":"throws AssertionError","suites":["Unified Spec Runner","Matching","resultCheck","$$matchAsRoot","when the expected value is not a document"],"updatePoint":{"line":100,"column":35,"index":3666},"line":100,"code":"          it('throws AssertionError', function () {\n            actual = {\n              data: {\n                data: 10,\n                a: 11\n              }\n            };\n            expect(() => resultCheckSpy(actual, expected, entitiesMap, [])).to.throw(AssertionError, /Value of \\$\\$matchAsRoot must be an object/);\n          });","file":"unit/tools/unified_spec_runner.test.ts","skipped":false,"dir":"test"},{"name":"throws AssertionError","suites":["Unified Spec Runner","Matching","resultCheck","$$matchAsRoot","when the actual value is not a document"],"updatePoint":{"line":119,"column":35,"index":4264},"line":119,"code":"          it('throws AssertionError', function () {\n            actual = '{\"data\": { \"data\": 10, \"a\": 11 }}';\n            expect(() => resultCheckSpy(actual, expected, entitiesMap, [])).to.throw(AssertionError, /Expected actual value to be an object/);\n          });","file":"unit/tools/unified_spec_runner.test.ts","skipped":false,"dir":"test"},{"name":"passes when failure is present and redacted","suites":["Unified Spec Runner","Matching","compareLogs","when failureIsRedacted is present","when failureIsRedacted=true"],"updatePoint":{"line":150,"column":57,"index":5334},"line":150,"code":"          it('passes when failure is present and redacted', function () {\n            actual = {\n              level: 'debug',\n              component: 'command',\n              data: {\n                failure: {}\n              }\n            };\n            compareLogsSpy([expected], [actual], entitiesMap);\n          });","file":"unit/tools/unified_spec_runner.test.ts","skipped":false,"dir":"test"},{"name":"throws AssertionError when failure is absent","suites":["Unified Spec Runner","Matching","compareLogs","when failureIsRedacted is present","when failureIsRedacted=true"],"updatePoint":{"line":160,"column":58,"index":5656},"line":160,"code":"          it('throws AssertionError when failure is absent', function () {\n            actual = {\n              level: 'debug',\n              component: 'command',\n              data: {\n                message: 'some message'\n              }\n            };\n            expect(() => compareLogsSpy([expected], [actual], entitiesMap)).to.throw(AssertionError, /Expected failure to exist/);\n          });","file":"unit/tools/unified_spec_runner.test.ts","skipped":false,"dir":"test"},{"name":"throws AssertionError when failure is present and not redacted","suites":["Unified Spec Runner","Matching","compareLogs","when failureIsRedacted is present","when failureIsRedacted=true"],"updatePoint":{"line":170,"column":76,"index":6076},"line":170,"code":"          it('throws AssertionError when failure is present and not redacted', function () {\n            actual = {\n              level: 'debug',\n              component: 'command',\n              data: {\n                failure: {\n                  message: 'some failure'\n                }\n              }\n            };\n            expect(() => compareLogsSpy([expected], [actual], entitiesMap)).to.throw(AssertionError, /Expected failure to have been redacted/);\n          });","file":"unit/tools/unified_spec_runner.test.ts","skipped":false,"dir":"test"},{"name":"passes when failure is present and not redacted","suites":["Unified Spec Runner","Matching","compareLogs","when failureIsRedacted is present","when failureIsRedacted=false"],"updatePoint":{"line":194,"column":61,"index":6879},"line":194,"code":"          it('passes when failure is present and not redacted', function () {\n            actual = {\n              level: 'debug',\n              component: 'command',\n              data: {\n                failure: {\n                  message: 'some failure'\n                }\n              }\n            };\n            compareLogsSpy([expected], [actual], entitiesMap);\n          });","file":"unit/tools/unified_spec_runner.test.ts","skipped":false,"dir":"test"},{"name":"throws AssertionError when failure is absent","suites":["Unified Spec Runner","Matching","compareLogs","when failureIsRedacted is present","when failureIsRedacted=false"],"updatePoint":{"line":206,"column":58,"index":7260},"line":206,"code":"          it('throws AssertionError when failure is absent', function () {\n            actual = {\n              level: 'debug',\n              component: 'command',\n              data: {\n                message: 'some message'\n              }\n            };\n            expect(() => compareLogsSpy([expected], [actual], entitiesMap)).to.throw(AssertionError, /Expected failure to exist/);\n          });","file":"unit/tools/unified_spec_runner.test.ts","skipped":false,"dir":"test"},{"name":"throws AssertionError when failure is present and redacted","suites":["Unified Spec Runner","Matching","compareLogs","when failureIsRedacted is present","when failureIsRedacted=false"],"updatePoint":{"line":216,"column":72,"index":7676},"line":216,"code":"          it('throws AssertionError when failure is present and redacted', function () {\n            actual = {\n              level: 'debug',\n              component: 'command',\n              data: {\n                failure: {}\n              }\n            };\n            expect(() => compareLogsSpy([expected], [actual], entitiesMap)).to.throw(AssertionError, /Expected failure to have not been redacted/);\n          });","file":"unit/tools/unified_spec_runner.test.ts","skipped":false,"dir":"test"},{"name":"passes when failure is not present","suites":["Unified Spec Runner","Matching","compareLogs","when failureIsRedacted is undefined"],"updatePoint":{"line":238,"column":46,"index":8366},"line":238,"code":"        it('passes when failure is not present', function () {\n          actual = {\n            level: 'debug',\n            component: 'command',\n            data: {\n              message: 'some message'\n            }\n          };\n          compareLogsSpy([expected], [actual], entitiesMap);\n        });","file":"unit/tools/unified_spec_runner.test.ts","skipped":false,"dir":"test"},{"name":"passes when actual.data field has additional fields not specified by expected.data","suites":["Unified Spec Runner","Matching","compareLogs","matches data field as root documents"],"updatePoint":{"line":261,"column":94,"index":9032},"line":261,"code":"        it('passes when actual.data field has additional fields not specified by expected.data', function () {\n          actual = {\n            level: 'debug',\n            component: 'command',\n            data: {\n              a: 1,\n              b: 2,\n              c: 3,\n              d: 4,\n              e: 5\n            }\n          };\n          compareLogsSpy([expected], [actual], entitiesMap);\n        });","file":"unit/tools/unified_spec_runner.test.ts","skipped":false,"dir":"test"},{"name":"throws an Assertion error when expected.data has fields not specified by actual.data","suites":["Unified Spec Runner","Matching","compareLogs","matches data field as root documents"],"updatePoint":{"line":275,"column":96,"index":9447},"line":275,"code":"        it('throws an Assertion error when expected.data has fields not specified by actual.data', function () {\n          actual = {\n            level: 'debug',\n            component: 'command',\n            data: {\n              a: 1,\n              b: 2\n            }\n          };\n          expect(() => compareLogsSpy([expected], [actual], entitiesMap)).to.throw(AssertionError, /expected undefined to equal 3/);\n        });","file":"unit/tools/unified_spec_runner.test.ts","skipped":false,"dir":"test"},{"name":"uses ReadPreference instance","suites":["class Transaction","constructor()"],"updatePoint":{"line":5,"column":36,"index":200},"line":5,"code":"    it('uses ReadPreference instance', () => {\n      const transaction = new Transaction({\n        readPreference: ReadPreference.nearest\n      });\n      expect(transaction.options).to.have.property('readPreference').that.is.instanceOf(ReadPreference).that.has.property('mode', 'nearest');\n    });","file":"unit/transactions.test.ts","skipped":false,"dir":"test"},{"name":"transforms ReadPreferenceLike string","suites":["class Transaction","constructor()"],"updatePoint":{"line":11,"column":44,"index":506},"line":11,"code":"    it('transforms ReadPreferenceLike string', () => {\n      const transaction = new Transaction({\n        readPreference: 'nearest'\n      });\n      expect(transaction.options).to.have.property('readPreference').that.is.instanceOf(ReadPreference).that.has.property('mode', 'nearest');\n    });","file":"unit/transactions.test.ts","skipped":false,"dir":"test"}]}