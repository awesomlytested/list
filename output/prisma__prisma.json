{"repo":"prisma/prisma","url":"https://github.com/prisma/prisma","branch":"main","configs":[{"package":"prisma","lang":"ts","dir":"packages/cli/src/__tests__","framework":"jest","pattern":"**/*[._-]{test,spec,unittest,unit}.{ts,js}"},{"package":"@prisma/client","lang":"ts","dir":"packages/client/src/__tests__","framework":"jest","pattern":"**/*[._-]{test,spec,unittest,unit}.{ts,js}"},{"package":"@prisma/debug","lang":"ts","dir":"packages/debug/src/__tests__","framework":"jest","pattern":"**/*[._-]{test,spec,unittest,unit}.{ts,js}"},{"package":"@prisma/engine-core","lang":"ts","dir":"packages/engine-core/src/__tests__","framework":"jest","pattern":"**/*[._-]{test,spec,unittest,unit}.{ts,js}"},{"package":"@prisma/generator-helper","lang":"ts","dir":"packages/generator-helper/src/__tests__","framework":"jest","pattern":"**/*[._-]{test,spec,unittest,unit}.{ts,js}"},{"package":"@prisma/integration-tests","lang":"js","dir":"packages/integration-tests/src/__tests__","framework":"jest","pattern":"**/*[._-]{test,spec,unittest,unit}.{ts,js}"},{"package":"@prisma/migrate","lang":"ts","dir":"packages/migrate/src/__tests__","framework":"jest","pattern":"**/*[._-]{test,spec,unittest,unit}.{ts,js}"},{"package":"@prisma/sdk","lang":"ts","dir":"packages/sdk/src/__tests__","framework":"jest","pattern":"**/*[._-]{test,spec,unittest,unit}.{ts,js}"}],"tests":[{"name":"no params should return help","suites":[],"updatePoint":{"line":65,"column":32},"line":65,"code":"it('no params should return help', async () => {\n  const spy = jest\n    .spyOn(cliInstance, 'help')\n    .mockImplementation(() => 'Help Me')\n\n  await cliInstance.parse([])\n  expect(spy).toHaveBeenCalledTimes(1)\n  spy.mockRestore()\n})","file":"commands/CLI.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"wrong flag","suites":[],"updatePoint":{"line":75,"column":14},"line":75,"code":"it('wrong flag', async () => {\n  const spy = jest\n    .spyOn(cliInstance, 'help')\n    .mockImplementation(() => 'Help Me')\n\n  await cliInstance.parse(['--something'])\n  expect(spy).toHaveBeenCalledTimes(1)\n  spy.mockRestore()\n})","file":"commands/CLI.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"help flag","suites":[],"updatePoint":{"line":85,"column":13},"line":85,"code":"it('help flag', async () => {\n  const spy = jest\n    .spyOn(cliInstance, 'help')\n    .mockImplementation(() => 'Help Me')\n\n  await cliInstance.parse(['--help'])\n  expect(spy).toHaveBeenCalledTimes(1)\n  spy.mockRestore()\n})","file":"commands/CLI.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"unknown command","suites":[],"updatePoint":{"line":95,"column":19},"line":95,"code":"it('unknown command', async () => {\n  await expect(cliInstance.parse(['doesnotexist'])).resolves.toThrowError()\n})","file":"commands/CLI.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"introspect should include deprecation warning","suites":[],"updatePoint":{"line":99,"column":49},"line":99,"code":"it('introspect should include deprecation warning', async () => {\n  const result = cliInstance.parse(['introspect'])\n\n  await expect(result).rejects.toMatchInlineSnapshot(`\n          Could not find a schema.prisma file that is required for this command.\n          You can either provide it with --schema, set it as \\`prisma.schema\\` in your package.json or put it into the default location ./prisma/schema.prisma https://pris.ly/d/prisma-schema-location\n        `)\n  expect(ctx.mocked['console.log'].mock.calls).toHaveLength(0)\n  expect(ctx.mocked['console.info'].mock.calls).toHaveLength(0)\n  expect(ctx.mocked['console.warn'].mock.calls.join('\\n'))\n    .toMatchInlineSnapshot(`\n    prisma:warn \n    prisma:warn The prisma introspect command is deprecated. Please use prisma db pull instead.\n    prisma:warn \n  `)\n  expect(ctx.mocked['console.error'].mock.calls).toHaveLength(0)\n})","file":"commands/CLI.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"doctor should succeed when schema and db do match","suites":[],"line":6,"code":"it.skip('doctor should succeed when schema and db do match', async () => {","file":"commands/Doctor.test.ts","skipped":true,"dir":"packages/cli/src/__tests__"},{"name":"should fail when db is missing","suites":[],"updatePoint":{"line":15,"column":34},"line":15,"code":"it('should fail when db is missing', async () => {\n  ctx.fixture('schema-db-out-of-sync')\n  ctx.fs.remove('dev.db')\n  const result = Doctor.new().parse([])\n  await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(\n    `P1003: SQLite database file doesn't exist`,\n  )\n})","file":"commands/Doctor.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"should fail when Prisma schema is missing","suites":[],"updatePoint":{"line":24,"column":45},"line":24,"code":"it('should fail when Prisma schema is missing', async () => {\n  const result = Doctor.new().parse([])\n  await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n          Could not find a schema.prisma file that is required for this command.\n          You can either provide it with --schema, set it as \\`prisma.schema\\` in your package.json or put it into the default location ./prisma/schema.prisma https://pris.ly/d/prisma-schema-location\n        `)\n})","file":"commands/Doctor.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"should fail when db is empty","suites":[],"updatePoint":{"line":32,"column":32},"line":32,"code":"it('should fail when db is empty', async () => {\n  ctx.fixture('schema-db-out-of-sync')\n  ctx.fs.write('dev.db', '')\n  const result = Doctor.new().parse([])\n  await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n          P4001\n\n          The introspected database was empty: file:dev.db\n\n        `)\n})","file":"commands/Doctor.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"should fail when schema and db do not match","suites":[],"updatePoint":{"line":44,"column":47},"line":44,"code":"it('should fail when schema and db do not match', async () => {\n  ctx.fixture('schema-db-out-of-sync')\n  const result = Doctor.new().parse([])\n  await expect(result).rejects.toThrowErrorMatchingSnapshot(`\n\n\n                    NewPost\n                    ↪ Model is missing in database\n\n\n                    User\n                    ↪ Field newName is missing in database\n                    ↪ Field newPosts is missing in database\n\n                `)\n})","file":"commands/Doctor.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"format should add a trailing EOL","suites":[],"updatePoint":{"line":7,"column":36},"line":7,"code":"it('format should add a trailing EOL', async () => {\n  ctx.fixture('example-project/prisma')\n  await Format.new().parse([])\n  expect(fs.read('schema.prisma')).toMatchSnapshot()\n})","file":"commands/Format.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"format should add missing backrelation","suites":[],"updatePoint":{"line":13,"column":42},"line":13,"code":"it('format should add missing backrelation', async () => {\n  ctx.fixture('example-project/prisma')\n  await Format.new().parse(['--schema=missing-backrelation.prisma'])\n  expect(fs.read('missing-backrelation.prisma')).toMatchSnapshot()\n})","file":"commands/Format.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"format should throw if schema is broken","suites":[],"updatePoint":{"line":19,"column":43},"line":19,"code":"it('format should throw if schema is broken', async () => {\n  ctx.fixture('example-project/prisma')\n  await expect(\n    Format.new().parse(['--schema=broken.prisma']),\n  ).rejects.toThrowError()\n})","file":"commands/Format.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"should work with a custom output dir","suites":["using cli"],"updatePoint":{"line":9,"column":42},"line":9,"code":"  it('should work with a custom output dir', async () => {\n    ctx.fixture('example-project')\n    const data = await ctx.cli('generate')\n\n    if (typeof data.signal === 'number' && data.signal !== 0) {\n      throw new Error(data.stderr + data.stdout)\n    }\n\n    const { main } = await import(ctx.fs.path('main.ts'))\n    expect(cleanSnapshot(data.stdout)).toMatchSnapshot()\n    await expect(main()).resolves.toMatchSnapshot()\n  }, 60000) // timeout","file":"commands/Generate.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"should error with exit code 1 with incorrect schema","suites":["using cli"],"updatePoint":{"line":22,"column":57},"line":22,"code":"  it('should error with exit code 1 with incorrect schema', async () => {\n    ctx.fixture('broken-example-project')\n    await expect(ctx.cli('generate').catch((e) => e.exitCode)).resolves.toEqual(1)\n  })","file":"commands/Generate.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"should work with a custom generator","suites":["using cli"],"updatePoint":{"line":27,"column":41},"line":27,"code":"  it('should work with a custom generator', async () => {\n    ctx.fixture('custom-generator')\n    const data = await ctx.cli('generate')\n\n    if (typeof data.signal === 'number' && data.signal !== 0) {\n      throw new Error(data.stderr + data.stdout)\n    }\n\n    expect(cleanSnapshot(data.stdout)).toContain(`I am a minimal generator`)\n  }, 30000) // timeout","file":"commands/Generate.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"--schema relative path: should work","suites":["--schema from project directory"],"updatePoint":{"line":40,"column":41},"line":40,"code":"  it('--schema relative path: should work', async () => {\n    ctx.fixture('generate-from-project-dir')\n    const result = await Generate.new().parse(['--schema=./schema.prisma'])\n    expect(replaceEngineType(result)).toMatchInlineSnapshot(`\n\n✔ Generated Prisma Client (0.0.0 | TEST_ENGINE_TYPE) to ./@prisma/client in XXms\nYou can now start using Prisma Client in your code. Reference: https://pris.ly/d/client\n\\`\\`\\`\nimport { PrismaClient } from './@prisma/client'\nconst prisma = new PrismaClient()\n\\`\\`\\`\n`)\n  })","file":"commands/Generate.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"--schema relative path: should fail - invalid path","suites":["--schema from project directory"],"updatePoint":{"line":54,"column":56},"line":54,"code":"  it('--schema relative path: should fail - invalid path', async () => {\n    ctx.fixture('generate-from-project-dir')\n    const result = Generate.new().parse(['--schema=./doesnotexists.prisma'])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(\n      `Provided --schema at ./doesnotexists.prisma doesn't exist.`,\n    )\n  })","file":"commands/Generate.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"--schema absolute path: should work","suites":["--schema from project directory"],"updatePoint":{"line":62,"column":41},"line":62,"code":"  it('--schema absolute path: should work', async () => {\n    ctx.fixture('generate-from-project-dir')\n    const absoluteSchemaPath = path.resolve('./schema.prisma')\n    const result = await Generate.new().parse([`--schema=${absoluteSchemaPath}`])\n    expect(replaceEngineType(result)).toMatchInlineSnapshot(`\n\n✔ Generated Prisma Client (0.0.0 | TEST_ENGINE_TYPE) to ./@prisma/client in XXms\nYou can now start using Prisma Client in your code. Reference: https://pris.ly/d/client\n\\`\\`\\`\nimport { PrismaClient } from './@prisma/client'\nconst prisma = new PrismaClient()\n\\`\\`\\`\n`)\n  })","file":"commands/Generate.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"--schema absolute path: should fail - invalid path","suites":["--schema from project directory"],"updatePoint":{"line":77,"column":56},"line":77,"code":"  it('--schema absolute path: should fail - invalid path', async () => {\n    ctx.fixture('generate-from-project-dir')\n    const absoluteSchemaPath = path.resolve('./doesnotexists.prisma')\n    const result = Generate.new().parse([`--schema=${absoluteSchemaPath}`])\n    await expect(result).rejects.toThrowError(`Provided --schema at ${absoluteSchemaPath} doesn't exist.`)\n  })","file":"commands/Generate.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"--schema relative path: should work","suites":["--schema from parent directory"],"updatePoint":{"line":86,"column":41},"line":86,"code":"  it('--schema relative path: should work', async () => {\n    ctx.fixture('generate-from-parent-dir')\n    const result = await Generate.new().parse(['--schema=./subdirectory/schema.prisma'])\n    expect(replaceEngineType(result)).toMatchInlineSnapshot(`\n\n✔ Generated Prisma Client (0.0.0 | TEST_ENGINE_TYPE) to ./subdirectory/@prisma/client in XXms\nYou can now start using Prisma Client in your code. Reference: https://pris.ly/d/client\n\\`\\`\\`\nimport { PrismaClient } from './subdirectory/@prisma/client'\nconst prisma = new PrismaClient()\n\\`\\`\\`\n`)\n  })","file":"commands/Generate.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"--schema relative path: should fail - invalid path","suites":["--schema from parent directory"],"updatePoint":{"line":100,"column":56},"line":100,"code":"  it('--schema relative path: should fail - invalid path', async () => {\n    ctx.fixture('generate-from-parent-dir')\n\n    const result = Generate.new().parse(['--schema=./subdirectory/doesnotexists.prisma'])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(\n      `Provided --schema at ./subdirectory/doesnotexists.prisma doesn't exist.`,\n    )\n  })","file":"commands/Generate.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"--schema absolute path: should work","suites":["--schema from parent directory"],"updatePoint":{"line":109,"column":41},"line":109,"code":"  it('--schema absolute path: should work', async () => {\n    ctx.fixture('generate-from-parent-dir')\n\n    const absoluteSchemaPath = path.resolve('./subdirectory/schema.prisma')\n    const result = await Generate.new().parse([`--schema=${absoluteSchemaPath}`])\n    expect(replaceEngineType(result)).toMatchInlineSnapshot(`\n\n✔ Generated Prisma Client (0.0.0 | TEST_ENGINE_TYPE) to ./subdirectory/@prisma/client in XXms\nYou can now start using Prisma Client in your code. Reference: https://pris.ly/d/client\n\\`\\`\\`\nimport { PrismaClient } from './subdirectory/@prisma/client'\nconst prisma = new PrismaClient()\n\\`\\`\\`\n`)\n  })","file":"commands/Generate.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"--schema absolute path: should fail - invalid path","suites":["--schema from parent directory"],"updatePoint":{"line":125,"column":56},"line":125,"code":"  it('--schema absolute path: should fail - invalid path', async () => {\n    ctx.fixture('generate-from-parent-dir')\n\n    const absoluteSchemaPath = path.resolve('./subdirectory/doesnotexists.prisma')\n    const result = Generate.new().parse([`--schema=${absoluteSchemaPath}`])\n    await expect(result).rejects.toThrowError(`Provided --schema at ${absoluteSchemaPath} doesn't exist.`)\n  })","file":"commands/Generate.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"is schema and env written on disk replace","suites":[],"updatePoint":{"line":9,"column":47},"line":9,"code":"test('is schema and env written on disk replace', async () => {\n  const result = await ctx.cli('init')\n  expect(stripAnsi(result.stdout)).toMatchSnapshot()\n\n  const schema = fs.readFileSync(\n    join(ctx.tmpDir, 'prisma', 'schema.prisma'),\n    'utf-8',\n  )\n  expect(schema).toMatch(defaultSchema())\n\n  const env = fs.readFileSync(join(ctx.tmpDir, '.env'), 'utf-8')\n  expect(env).toMatch(defaultEnv())\n})","file":"commands/Init.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"works with url param","suites":[],"updatePoint":{"line":23,"column":26},"line":23,"code":"test('works with url param', async () => {\n  ctx.fixture('init')\n  const result = await ctx.cli('init', '--url', 'file:dev.db')\n  expect(stripAnsi(result.stdout)).toMatchSnapshot()\n\n  const schema = fs.readFileSync(\n    join(ctx.tmpDir, 'prisma', 'schema.prisma'),\n    'utf-8',\n  )\n  expect(schema).toMatch(defaultSchema('sqlite'))\n\n  const env = fs.readFileSync(join(ctx.tmpDir, '.env'), 'utf-8')\n  expect(env).toMatchInlineSnapshot(`\n# Environment variables declared in this file are automatically made available to Prisma.\n# See the documentation for more detail: https://pris.ly/d/prisma-schema#using-environment-variables\n\n# Prisma supports the native connection string format for PostgreSQL, MySQL, SQLite, SQL Server and MongoDB (Preview).\n# See the documentation for all the connection string options: https://pris.ly/d/connection-strings\n\nDATABASE_URL=\"file:dev.db\"\n`)\n})","file":"commands/Init.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"works with provider param - postgresql","suites":[],"updatePoint":{"line":46,"column":44},"line":46,"code":"test('works with provider param - postgresql', async () => {\n  ctx.fixture('init')\n  const result = await ctx.cli('init', '--datasource-provider', 'postgresql')\n  expect(stripAnsi(result.stdout)).toMatchSnapshot()\n\n  const schema = fs.readFileSync(\n    join(ctx.tmpDir, 'prisma', 'schema.prisma'),\n    'utf-8',\n  )\n  expect(schema).toMatch(defaultSchema('postgresql'))\n\n  const env = fs.readFileSync(join(ctx.tmpDir, '.env'), 'utf-8')\n  expect(env).toMatchInlineSnapshot(`\n# Environment variables declared in this file are automatically made available to Prisma.\n# See the documentation for more detail: https://pris.ly/d/prisma-schema#using-environment-variables\n\n# Prisma supports the native connection string format for PostgreSQL, MySQL, SQLite, SQL Server and MongoDB (Preview).\n# See the documentation for all the connection string options: https://pris.ly/d/connection-strings\n\nDATABASE_URL=\"postgresql://johndoe:randompassword@localhost:5432/mydb?schema=public\"\n`)\n})","file":"commands/Init.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"works with provider param - mysql","suites":[],"updatePoint":{"line":69,"column":39},"line":69,"code":"test('works with provider param - mysql', async () => {\n  ctx.fixture('init')\n  const result = await ctx.cli('init', '--datasource-provider', 'mysql')\n  expect(stripAnsi(result.stdout)).toMatchSnapshot()\n\n  const schema = fs.readFileSync(\n    join(ctx.tmpDir, 'prisma', 'schema.prisma'),\n    'utf-8',\n  )\n  expect(schema).toMatch(defaultSchema('mysql'))\n\n  const env = fs.readFileSync(join(ctx.tmpDir, '.env'), 'utf-8')\n  expect(env).toMatchInlineSnapshot(`\n# Environment variables declared in this file are automatically made available to Prisma.\n# See the documentation for more detail: https://pris.ly/d/prisma-schema#using-environment-variables\n\n# Prisma supports the native connection string format for PostgreSQL, MySQL, SQLite, SQL Server and MongoDB (Preview).\n# See the documentation for all the connection string options: https://pris.ly/d/connection-strings\n\nDATABASE_URL=\"mysql://johndoe:randompassword@localhost:3306/mydb\"\n`)\n})","file":"commands/Init.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"works with provider param - SQLITE","suites":[],"updatePoint":{"line":92,"column":40},"line":92,"code":"test('works with provider param - SQLITE', async () => {\n  ctx.fixture('init')\n  const result = await ctx.cli('init', '--datasource-provider', 'SQLITE')\n  expect(stripAnsi(result.stdout)).toMatchSnapshot()\n\n  const schema = fs.readFileSync(\n    join(ctx.tmpDir, 'prisma', 'schema.prisma'),\n    'utf-8',\n  )\n  expect(schema).toMatch(defaultSchema('sqlite'))\n\n  const env = fs.readFileSync(join(ctx.tmpDir, '.env'), 'utf-8')\n  expect(env).toMatchInlineSnapshot(`\n# Environment variables declared in this file are automatically made available to Prisma.\n# See the documentation for more detail: https://pris.ly/d/prisma-schema#using-environment-variables\n\n# Prisma supports the native connection string format for PostgreSQL, MySQL, SQLite, SQL Server and MongoDB (Preview).\n# See the documentation for all the connection string options: https://pris.ly/d/connection-strings\n\nDATABASE_URL=\"file:./dev.db\"\n`)\n})","file":"commands/Init.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"works with provider param - SqlServer","suites":[],"updatePoint":{"line":115,"column":43},"line":115,"code":"test('works with provider param - SqlServer', async () => {\n  ctx.fixture('init')\n  const result = await ctx.cli('init', '--datasource-provider', 'SqlServer')\n  expect(stripAnsi(result.stdout)).toMatchSnapshot()\n\n  const schema = fs.readFileSync(\n    join(ctx.tmpDir, 'prisma', 'schema.prisma'),\n    'utf-8',\n  )\n  expect(schema).toMatch(defaultSchema('sqlserver'))\n\n  const env = fs.readFileSync(join(ctx.tmpDir, '.env'), 'utf-8')\n  expect(env).toMatchInlineSnapshot(`\n# Environment variables declared in this file are automatically made available to Prisma.\n# See the documentation for more detail: https://pris.ly/d/prisma-schema#using-environment-variables\n\n# Prisma supports the native connection string format for PostgreSQL, MySQL, SQLite, SQL Server and MongoDB (Preview).\n# See the documentation for all the connection string options: https://pris.ly/d/connection-strings\n\nDATABASE_URL=\"sqlserver://localhost:1433;database=mydb;user=SA;password=randompassword;\"\n`)\n})","file":"commands/Init.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"works with provider param - MongoDB","suites":[],"updatePoint":{"line":138,"column":41},"line":138,"code":"test('works with provider param - MongoDB', async () => {\n  ctx.fixture('init')\n  const result = await ctx.cli('init', '--datasource-provider', 'MongoDB')\n  expect(stripAnsi(result.stdout)).toMatchSnapshot()\n\n  const schema = fs.readFileSync(\n    join(ctx.tmpDir, 'prisma', 'schema.prisma'),\n    'utf-8',\n  )\n  expect(schema).toMatch(defaultSchema('mongodb'))\n\n  const env = fs.readFileSync(join(ctx.tmpDir, '.env'), 'utf-8')\n  expect(env).toMatchInlineSnapshot(`\n# Environment variables declared in this file are automatically made available to Prisma.\n# See the documentation for more detail: https://pris.ly/d/prisma-schema#using-environment-variables\n\n# Prisma supports the native connection string format for PostgreSQL, MySQL, SQLite, SQL Server and MongoDB (Preview).\n# See the documentation for all the connection string options: https://pris.ly/d/connection-strings\n\nDATABASE_URL=\"mongodb+srv://root:randompassword@cluster0.ab1cd.mongodb.net/mydb?retryWrites=true&w=majority\"\n`)\n})","file":"commands/Init.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"errors with invalid provider param","suites":[],"updatePoint":{"line":161,"column":40},"line":161,"code":"test('errors with invalid provider param', async () => {\n  ctx.fixture('init')\n  const result = ctx.cli('init', '--datasource-provider', 'INVALID')\n  await expect(result).rejects.toThrowError()\n})","file":"commands/Init.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"warns when DATABASE_URL present in .env ","suites":[],"updatePoint":{"line":167,"column":46},"line":167,"code":"test('warns when DATABASE_URL present in .env ', async () => {\n  fs.writeFileSync(\n    join(ctx.tmpDir, '.env'),\n    `DATABASE_URL=\"postgres://dont:overwrite@me:5432/tests\"`,\n  )\n  const result = await ctx.cli('init')\n  expect(stripAnsi(result.all!)).toMatchSnapshot()\n\n  const schema = fs.readFileSync(\n    join(ctx.tmpDir, 'prisma', 'schema.prisma'),\n    'utf-8',\n  )\n  expect(schema).toMatch(defaultSchema())\n\n  const env = fs.readFileSync(join(ctx.tmpDir, '.env'), 'utf-8')\n  expect(env).toMatch(`DATABASE_URL=\"postgres://dont:overwrite@me:5432/tests\"`)\n})","file":"commands/Init.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"appends when .env present","suites":[],"updatePoint":{"line":185,"column":31},"line":185,"code":"test('appends when .env present', async () => {\n  fs.writeFileSync(join(ctx.tmpDir, '.env'), `SOMTHING=\"is here\"`)\n  const result = await ctx.cli('init')\n  expect(stripAnsi(result.stdout)).toMatchSnapshot()\n\n  const schema = fs.readFileSync(\n    join(ctx.tmpDir, 'prisma', 'schema.prisma'),\n    'utf-8',\n  )\n  expect(schema).toMatch(defaultSchema())\n\n  const env = fs.readFileSync(join(ctx.tmpDir, '.env'), 'utf-8')\n  expect(env).toMatchSnapshot()\n})","file":"commands/Init.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"writes a minimal .gitignore file","suites":[],"updatePoint":{"line":200,"column":38},"line":200,"code":"test('writes a minimal .gitignore file', async () => {\n  ctx.fixture('init')\n  await ctx.cli('init')\n  const gitignore = fs.readFileSync(join(ctx.tmpDir, '.gitignore'), 'utf-8')\n  expect(gitignore).toMatch(defaultGitIgnore())\n\n  expect(gitignore).toMatchSnapshot()\n})","file":"commands/Init.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"ignore .gitignore file if already present (do not override)","suites":[],"updatePoint":{"line":209,"column":65},"line":209,"code":"test('ignore .gitignore file if already present (do not override)', async () => {\n  ctx.fixture('init')\n  const gitignorePath = join(ctx.tmpDir, '.gitignore')\n  fs.writeFileSync(gitignorePath, `# This should not be overriden`)\n  const gitignoreBefore = fs.readFileSync(gitignorePath, 'utf-8')\n  await ctx.cli('init')\n  const gitignoreAfter = fs.readFileSync(gitignorePath, 'utf-8')\n  expect(gitignoreAfter).toEqual(gitignoreBefore)\n})","file":"commands/Init.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"can start up correctly","suites":["studio"],"updatePoint":{"line":54,"column":30},"line":54,"code":"  test('can start up correctly', async () => {\n    const res = await fetch(`http://localhost:${STUDIO_TEST_PORT}`)\n    expect(res.status).toEqual(200)\n  })","file":"commands/Studio.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"can respond to `findMany` queries","suites":["studio"],"updatePoint":{"line":59,"column":41},"line":59,"code":"  test('can respond to `findMany` queries', async () => {\n    const res = await sendRequest({\n      requestId: 1,\n      channel: 'prisma',\n      action: 'clientRequest',\n      payload: {\n        data: {\n          modelName: 'with_all_field_types',\n          operation: 'findMany',\n          args: {\n            select: {\n              id: true,\n              string: true,\n              int: true,\n              float: true,\n              datetime: true,\n              relation: true,\n              relation_list: true,\n            },\n          },\n        },\n      },\n    })\n\n    expect(res).toMatchSnapshot()\n  })","file":"commands/Studio.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"can respond to `create` queries","suites":["studio"],"updatePoint":{"line":86,"column":39},"line":86,"code":"  test('can respond to `create` queries', async () => {\n    const res = await sendRequest({\n      requestId: 2,\n      channel: 'prisma',\n      action: 'clientRequest',\n      payload: {\n        data: {\n          modelName: 'with_all_field_types',\n          operation: 'create',\n          args: {\n            data: {\n              id: 3,\n              string: '',\n              int: 0,\n              float: 0.0,\n              datetime: '2020-08-03T00:00:00.000Z',\n              relation: {\n                connect: {\n                  id: 3,\n                },\n              },\n              relation_list: {\n                connect: {\n                  id: 3,\n                },\n              },\n            },\n            select: {\n              id: true,\n              string: true,\n              int: true,\n              float: true,\n              datetime: true,\n              relation: true,\n              relation_list: true,\n            },\n          },\n        },\n      },\n    })\n\n    expect(res).toMatchSnapshot()\n  })","file":"commands/Studio.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"can respond to `update` queries","suites":["studio"],"updatePoint":{"line":130,"column":39},"line":130,"code":"  test('can respond to `update` queries', async () => {\n    const res = await sendRequest({\n      requestId: 3,\n      channel: 'prisma',\n      action: 'clientRequest',\n      payload: {\n        data: {\n          modelName: 'with_all_field_types',\n          operation: 'update',\n          args: {\n            where: {\n              id: 1,\n            },\n            data: {\n              string: 'Changed String',\n              int: 100,\n              float: 100.5,\n              datetime: '2025-08-03T00:00:00.000Z',\n              relation: {\n                connect: {\n                  id: 3,\n                },\n              },\n              relation_list: {\n                connect: {\n                  id: 3,\n                },\n              },\n            },\n            select: {\n              id: true,\n              string: true,\n              int: true,\n              float: true,\n              datetime: true,\n              relation: true,\n              relation_list: true,\n            },\n          },\n        },\n      },\n    })\n\n    expect(res).toMatchSnapshot()\n  })","file":"commands/Studio.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"can respond to `delete` queries","suites":["studio"],"updatePoint":{"line":176,"column":39},"line":176,"code":"  test('can respond to `delete` queries', async () => {\n    const res = await sendRequest({\n      requestId: 4,\n      channel: 'prisma',\n      action: 'clientRequest',\n      payload: {\n        data: {\n          modelName: 'with_all_field_types',\n          operation: 'delete',\n          args: {\n            where: { id: 2 },\n            select: {\n              id: true,\n              string: true,\n              int: true,\n              float: true,\n              datetime: true,\n              relation: true,\n              relation_list: true,\n            },\n          },\n        },\n      },\n    })\n\n    expect(res).toMatchSnapshot()\n  })","file":"commands/Studio.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"should error when dependent generator is missing","suites":[],"updatePoint":{"line":7,"column":52},"line":7,"code":"it('should error when dependent generator is missing', async () => {\n  expect.assertions(1)\n\n  try {\n    await execa.node(\n      path.join(__dirname, '../../build/index.js'),\n      ['generate'],\n      {\n        cwd: path.join(__dirname, './fixtures/dependent-generator'),\n        stdio: 'pipe',\n      },\n    )\n  } catch (e) {\n    expect(e.stderr).toMatchSnapshot()\n  }\n})","file":"dependent-generator.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"should read .env file in root folder and custom-path","suites":[],"updatePoint":{"line":5,"column":56},"line":5,"code":"it('should read .env file in root folder and custom-path', async () => {\n  process.argv.push('--version')\n  process.argv.push('--schema=./custom-path/schema.prisma')\n  ctx.fixture('dotenv-1-custom-schema-path')\n  await import('../bin')\n  expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchSnapshot()\n\n  expect(process.env.DOTENV_PRISMA_WHEN_CUSTOM_SCHEMA_PATH_SHOULD_WORK).toEqual(\n    'file:dev.db',\n  )\n  expect(process.env.DOTENV_ROOT).toEqual('shouldbebread')\n  expect(\n    process.env.DOTENV_PRISMA_WHEN_CUSTOM_SCHEMA_PATH_SHOULD_BE_UNDEFINED,\n  ).toEqual(undefined)\n})","file":"dotenv-1-custom-schema-path.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"should read .env file in prisma folder","suites":[],"updatePoint":{"line":5,"column":42},"line":5,"code":"it('should read .env file in prisma folder', async () => {\n  process.argv.push('--version')\n  ctx.fixture('dotenv-2-prisma-folder')\n  await import('../bin')\n  expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchSnapshot()\n  expect(process.env.DOTENV_PRISMA_SHOULD_WORK).toEqual('file:dev.db')\n  expect(process.env.DOTENV_ROOT_SHOULD_BE_UNDEFINED).toEqual(undefined)\n})","file":"dotenv-2-prisma-folder.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"should throw error","suites":[],"updatePoint":{"line":5,"column":22},"line":5,"code":"it('should throw error', async () => {\n  ctx.fixture('dotenv-3-conflict')\n  expect.assertions(1)\n\n  await expect(\n    ctx.cli('version').catch((e) => {\n      const message = e.message.split('\\n').slice(1).join('\\n')\n      throw new Error(message)\n    }),\n  ).rejects.toThrowErrorMatchingInlineSnapshot(`\n          Error: There is a conflict between env var in .env and prisma/.env\n          Conflicting env vars:\n            SHOULD_THROW\n\n          We suggest to move the contents of prisma/.env to .env to consolidate your env vars.\n\n        `)\n})","file":"dotenv-3-conflict.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"should read .env file in prisma folder when there is no schema","suites":[],"updatePoint":{"line":5,"column":66},"line":5,"code":"it('should read .env file in prisma folder when there is no schema', async () => {\n  process.argv.push('--version')\n  ctx.fixture('dotenv-4-prisma-no-schema')\n  await import('../bin')\n  expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchSnapshot()\n  expect(process.env.DOTENV_PRISMA_NO_SCHEMA_SHOULD_WORK).toEqual('file:dev.db')\n  expect(process.env.DOTENV_ROOT_SHOULD_BE_UNDEFINED).toEqual(undefined)\n})","file":"dotenv-4-prisma-when-no-schema.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"should not load root .env file","suites":[],"updatePoint":{"line":5,"column":34},"line":5,"code":"it('should not load root .env file', async () => {\n  process.argv.push('--version')\n  ctx.fixture('dotenv-5-only-root')\n  await import('../bin')\n  expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchSnapshot()\n  expect(process.env.DOTENV_ROOT_SHOULD_BE_UNDEFINED).toEqual(undefined)\n})","file":"dotenv-5-only-root.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"should read expanded env vars","suites":[],"updatePoint":{"line":5,"column":33},"line":5,"code":"it('should read expanded env vars', async () => {\n  ctx.fixture('dotenv-6-expand')\n  process.argv.push('--version')\n  process.argv.push('--schema=./expand/schema.prisma')\n  await import('../bin')\n  expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchSnapshot()\n  expect(process.env.DOTENV_PRISMA_EXPAND_DATABASE_URL_WITH_SCHEMA).toEqual(\n    'postgres://user:password@server.host:5432/database?ssl=1&schema=schema1234',\n  )\n})","file":"dotenv-6-expand.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"dev tag - minor","suites":["update available message"],"updatePoint":{"line":8,"column":21},"line":8,"code":"  it('dev tag - minor', () => {\n    printUpdateMessage({\n      status: 'ok',\n      // @ts-ignore\n      data: {\n        previous_version: '2.6.1-dev.18',\n        current_version: '2.16.0-dev.8',\n        package: 'prisma',\n        release_tag: 'dev',\n      },\n    })\n    const message = ctx.mocked['console.error'].mock.calls[0][0]\n    expect(message).toContain('npm i --save-dev prisma@dev')\n    expect(message).toContain('npm i @prisma/client@dev')\n    expect(message).toMatchSnapshot()\n  })","file":"update-message.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"dev tag - major","suites":["update available message"],"updatePoint":{"line":25,"column":21},"line":25,"code":"  it('dev tag - major', () => {\n    printUpdateMessage({\n      status: 'ok',\n      // @ts-ignore\n      data: {\n        previous_version: '2.6.1-dev.18',\n        current_version: '3.0.1-dev.8',\n        package: 'prisma',\n        release_tag: 'dev',\n      },\n    })\n    const message = ctx.mocked['console.error'].mock.calls[0][0]\n    expect(message).toContain('This is a major update')\n    expect(message).toContain('npm i --save-dev prisma@dev')\n    expect(message).toContain('npm i @prisma/client@dev')\n    expect(message).toMatchSnapshot()\n  })","file":"update-message.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"latest tag - minor","suites":["update available message"],"updatePoint":{"line":43,"column":24},"line":43,"code":"  it('latest tag - minor', () => {\n    printUpdateMessage({\n      status: 'ok',\n      // @ts-ignore\n      data: {\n        previous_version: '2.6.1',\n        current_version: '2.16.0',\n        package: 'prisma',\n        release_tag: 'latest',\n      },\n    })\n    const message = ctx.mocked['console.error'].mock.calls[0][0]\n    expect(message).toContain('npm i --save-dev prisma@latest')\n    expect(message).toContain('npm i @prisma/client@latest')\n    expect(message).toMatchSnapshot()\n  })","file":"update-message.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"latest tag - major","suites":["update available message"],"updatePoint":{"line":60,"column":24},"line":60,"code":"  it('latest tag - major', () => {\n    printUpdateMessage({\n      status: 'ok',\n      // @ts-ignore\n      data: {\n        previous_version: '2.6.1',\n        current_version: '3.0.0',\n        package: 'prisma',\n        release_tag: 'latest',\n      },\n    })\n    const message = ctx.mocked['console.error'].mock.calls[0][0]\n    expect(message).toContain('This is a major update')\n    expect(message).toContain('npm i --save-dev prisma@latest')\n    expect(message).toContain('npm i @prisma/client@latest')\n    expect(message).toMatchSnapshot()\n  })","file":"update-message.test.ts","skipped":false,"dir":"packages/cli/src/__tests__"},{"name":"count happy path","suites":["aggregate"],"updatePoint":{"line":55,"column":24},"line":55,"code":"  test('count happy path', () => {\n    const document = makeDocument({\n      dmmf,\n      select: {\n        take: 10,\n        select: {\n          _count: {\n            select: {\n              _all: true,\n            },\n          },\n        },\n      },\n      rootTypeName: 'query',\n      rootField: 'aggregateUser',\n    })\n    document.validate(undefined, false, 'user', 'colorless')\n    expect(String(document)).toMatchInlineSnapshot(`\n      query {\n        aggregateUser(take: 10) {\n          _count {\n            _all\n          }\n        }\n      }\n    `)\n  })","file":"aggregate.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"combined happy path","suites":["aggregate"],"updatePoint":{"line":83,"column":27},"line":83,"code":"  test('combined happy path', () => {\n    const document = makeDocument({\n      dmmf,\n      select: {\n        take: 10,\n        cursor: {\n          email: 'a@a.de',\n        },\n        orderBy: {\n          age: 'asc',\n        },\n        skip: 12,\n        where: {\n          age: { gt: 500 },\n        },\n        select: {\n          _count: true,\n          _avg: {\n            select: {\n              age: true,\n            },\n          },\n          _min: {\n            select: {\n              age: true,\n            },\n          },\n          _max: {\n            select: {\n              age: true,\n            },\n          },\n          _sum: {\n            select: {\n              age: true,\n            },\n          },\n        },\n      },\n      rootTypeName: 'query',\n      rootField: 'aggregateUser',\n    })\n    document.validate(undefined, false, 'user', 'colorless')\n    expect(String(document)).toMatchSnapshot()\n  })","file":"aggregate.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"unhappy path - incorrect arg","suites":["aggregate"],"updatePoint":{"line":129,"column":36},"line":129,"code":"  test('unhappy path - incorrect arg', () => {\n    const select = { mount: true }\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'query',\n      rootField: 'aggregateUser',\n    })\n    expect(() => document.validate(select, false, 'user', 'colorless')).toThrowErrorMatchingSnapshot()\n  })","file":"aggregate.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"unhappy path - incorrect field","suites":["aggregate"],"updatePoint":{"line":140,"column":38},"line":140,"code":"  test('unhappy path - incorrect field', () => {\n    const select = {\n      select: {\n        _avg: {\n          select: {\n            blub: true,\n          },\n        },\n      },\n    }\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'query',\n      rootField: 'aggregateUser',\n    })\n    expect(() => document.validate(select, false, 'user', 'colorless')).toThrowErrorMatchingSnapshot()\n  })","file":"aggregate.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"invalid query","suites":["at least one validation"],"updatePoint":{"line":12,"column":21},"line":12,"code":"  test('invalid query', () => {\n    const select = {\n      where: {\n        email: {},\n      },\n    }\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'query',\n      rootField: 'findManyUser',\n    })\n    expect(String(document)).toMatchInlineSnapshot(`\n      query {\n        findManyUser(where: {\n          email: {\n\n          }\n        }) {\n          id\n          name\n          email\n          status\n          nicknames\n          permissions\n          favoriteTree\n          locationId\n          someFloats\n        }\n      }\n    `)\n    try {\n      document.validate(select, false, 'users')\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchInlineSnapshot(`\n        \"\n        Invalid \\`prisma.users()\\` invocation:\n\n        {\n          where: {\n            email: {\n        ?     equals?: String,\n        ?     not?: String | StringFilter,\n        ?     in?: String,\n        ?     notIn?: String,\n        ?     lt?: String,\n        ?     lte?: String,\n        ?     gt?: String,\n        ?     gte?: String,\n        ?     contains?: String,\n        ?     startsWith?: String,\n        ?     endsWith?: String\n            }\n          }\n        }\n\n        Argument where.email of type StringFilter needs at least one argument. Available args are listed in green.\n\n        Note: Lines with ? are optional.\n        \"\n      `)\n    }\n  })","file":"atLeastOne.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"valid query","suites":["at least one validation"],"updatePoint":{"line":76,"column":19},"line":76,"code":"  test('valid query', () => {\n    const select = {\n      where: {\n        email: '',\n      },\n    }\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'query',\n      rootField: 'findManyUser',\n    })\n    expect(String(document)).toMatchSnapshot()\n    expect(() => document.validate(select, false, 'users')).not.toThrow()\n  })","file":"atLeastOne.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"atomic set operation without object wrapping","suites":["minimal atomic update transformation"],"updatePoint":{"line":29,"column":52},"line":29,"code":"  test('atomic set operation without object wrapping', () => {\n    const transformedDocument = getTransformedDocument({\n      data: {\n        countFloat: 3.1415926,\n        countInt1: 3,\n      },\n    })\n\n    expect(transformedDocument).toMatchInlineSnapshot(`\n      mutation {\n        updateOneUser(\n          data: {\n            countFloat: 3.1415926\n            countInt1: 3\n          }\n        ) {\n          id\n          email\n          name\n          json\n          countFloat\n          countInt1\n          countInt2\n          countInt3\n          countInt4\n          countInt5\n          countInt6\n          lastLoginAt\n          coinflips\n        }\n      }\n    `)\n  })","file":"atomicOperationsUpdate.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"atomic operations with object wrapping","suites":["minimal atomic update transformation"],"updatePoint":{"line":63,"column":46},"line":63,"code":"  test('atomic operations with object wrapping', () => {\n    const select = {\n      data: {\n        countFloat: {\n          set: null,\n        },\n        countInt1: {\n          set: null,\n        },\n        countInt2: {\n          set: 123,\n        },\n        countInt3: {\n          increment: 1,\n        },\n        countInt4: {\n          decrement: 1,\n        },\n        countInt5: {\n          multiply: 2,\n        },\n        countInt6: {\n          divide: 4,\n        },\n      },\n      where: {\n        email: 'a@a.de',\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'mutation',\n      rootField: 'updateOneUser',\n    })\n\n    expect(String(document)).toMatchInlineSnapshot(`\n      mutation {\n        updateOneUser(\n          data: {\n            countFloat: {\n              set: null\n            }\n            countInt1: {\n              set: null\n            }\n            countInt2: {\n              set: 123\n            }\n            countInt3: {\n              increment: 1\n            }\n            countInt4: {\n              decrement: 1\n            }\n            countInt5: {\n              multiply: 2\n            }\n            countInt6: {\n              divide: 4\n            }\n          }\n          where: {\n            email: \"a@a.de\"\n          }\n        ) {\n          id\n          email\n          name\n          json\n          countFloat\n          countInt1\n          countInt2\n          countInt3\n          countInt4\n          countInt5\n          countInt6\n          lastLoginAt\n          coinflips\n        }\n      }\n    `)\n\n    expect(() => document.validate(select, false)).not.toThrowError()\n  })","file":"atomicOperationsUpdate.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"basic batching","suites":["batching"],"updatePoint":{"line":7,"column":22},"line":7,"code":"  test('basic batching', async () => {\n    const dmmf = new DMMFClass(await getDMMF({ datamodel: blog }))\n    const batches: any[] = []\n    const requests: any[] = []\n\n    const fetcher = new PrismaClientFetcher({\n      $connect: () => Promise.resolve(),\n      _engine: {\n        requestBatch: (batch) => {\n          batches.push(batch)\n          return Promise.resolve(batch.map(() => ({ data: { data: null }, elapsed: 0.2 })))\n        },\n        request: (request) => {\n          requests.push(request)\n          return Promise.resolve({ data: { data: null }, elapsed: 0.3 })\n        },\n      },\n    })\n\n    await Promise.all([\n      fetcher.request({\n        clientMethod: 'findUnique',\n        dataPath: [],\n        document: makeDocument({\n          dmmf,\n          select: {\n            where: {\n              id: '1',\n            },\n          },\n          rootTypeName: 'query',\n          rootField: 'findUniqueUser',\n        }),\n        isList: false,\n        rootField: 'query',\n        typeName: 'User',\n        args: {\n          where: {\n            id: '1',\n          },\n        },\n      }),\n      fetcher.request({\n        clientMethod: 'findUnique',\n        dataPath: [],\n        document: makeDocument({\n          dmmf,\n          select: {\n            where: {\n              id: '2',\n            },\n          },\n          rootTypeName: 'query',\n          rootField: 'findUniqueUser',\n        }),\n        isList: false,\n        rootField: 'query',\n        typeName: 'User',\n        args: {\n          where: {\n            id: '2',\n          },\n        },\n      }),\n    ])\n\n    expect(batches).toMatchInlineSnapshot(`\n      Array [\n        Array [\n          query {\n        findUniqueUser(where: {\n          id: \"1\"\n        }) {\n          id\n          email\n          name\n          json\n          countFloat\n          countInt1\n          countInt2\n          countInt3\n          countInt4\n          countInt5\n          countInt6\n          lastLoginAt\n          coinflips\n        }\n      },\n          query {\n        findUniqueUser(where: {\n          id: \"2\"\n        }) {\n          id\n          email\n          name\n          json\n          countFloat\n          countInt1\n          countInt2\n          countInt3\n          countInt4\n          countInt5\n          countInt6\n          lastLoginAt\n          coinflips\n        }\n      },\n        ],\n      ]\n    `)\n    expect(requests).toMatchInlineSnapshot(`Array []`)\n  })","file":"batching.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"dont batch different models","suites":["batching"],"updatePoint":{"line":120,"column":35},"line":120,"code":"  test('dont batch different models', async () => {\n    const dmmf = new DMMFClass(await getDMMF({ datamodel: blog }))\n    const batches: any[] = []\n    const requests: any[] = []\n\n    const fetcher = new PrismaClientFetcher({\n      $connect: () => Promise.resolve(),\n      _engine: {\n        requestBatch: (batch) => {\n          batches.push(batch)\n          return Promise.resolve(batch.map(() => ({ data: { data: null }, elapsed: 0.2 })))\n        },\n        request: (request) => {\n          requests.push(request)\n          return Promise.resolve({ data: { data: null }, elapsed: 0.3 })\n        },\n      },\n    })\n\n    await Promise.all([\n      fetcher.request({\n        clientMethod: 'findUnique',\n        dataPath: [],\n        document: makeDocument({\n          dmmf,\n          select: {\n            where: {\n              id: '1',\n            },\n          },\n          rootTypeName: 'query',\n          rootField: 'findUniquePost',\n        }),\n        isList: false,\n        rootField: 'query',\n        typeName: 'User',\n        args: {\n          where: { id: '1' },\n        },\n      }),\n      fetcher.request({\n        clientMethod: 'findUnique',\n        dataPath: [],\n        document: makeDocument({\n          dmmf,\n          select: {\n            where: {\n              id: '2',\n            },\n          },\n          rootTypeName: 'query',\n          rootField: 'findUniqueUser',\n        }),\n        isList: false,\n        rootField: 'query',\n        typeName: 'User',\n        args: {\n          where: { id: '2' },\n        },\n      }),\n    ])\n\n    expect(batches).toMatchInlineSnapshot(`Array []`)\n    expect(requests).toMatchInlineSnapshot(`\n      Array [\n        query {\n        findUniquePost(where: {\n          id: \"1\"\n        }) {\n          id\n          createdAt\n          updatedAt\n          published\n          title\n          content\n          authorId\n          optionnal\n        }\n      },\n        query {\n        findUniqueUser(where: {\n          id: \"2\"\n        }) {\n          id\n          email\n          name\n          json\n          countFloat\n          countInt1\n          countInt2\n          countInt3\n          countInt4\n          countInt5\n          countInt6\n          lastLoginAt\n          coinflips\n        }\n      },\n      ]\n    `)\n  })","file":"batching.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"dont batch different wheres","suites":["batching"],"updatePoint":{"line":222,"column":35},"line":222,"code":"  test('dont batch different wheres', async () => {\n    const dmmf = new DMMFClass(await getDMMF({ datamodel: blog }))\n    const batches: any[] = []\n    const requests: any[] = []\n\n    const fetcher = new PrismaClientFetcher({\n      $connect: () => Promise.resolve(),\n      _engine: {\n        requestBatch: (batch) => {\n          batches.push(batch)\n          return Promise.resolve(batch.map(() => ({ data: { data: null }, elapsed: 0.2 })))\n        },\n        request: (request) => {\n          requests.push(request)\n          return Promise.resolve({ data: { data: null }, elapsed: 0.3 })\n        },\n      },\n    })\n\n    await Promise.all([\n      fetcher.request({\n        clientMethod: 'findUnique',\n        dataPath: [],\n        document: makeDocument({\n          dmmf,\n          select: {\n            where: {\n              email: 'a@a.de',\n            },\n          },\n          rootTypeName: 'query',\n          rootField: 'findUniqueUser',\n        }),\n        isList: false,\n        rootField: 'query',\n        typeName: 'User',\n        args: { where: { email: 'a@a.de' } },\n      }),\n      fetcher.request({\n        clientMethod: 'findUnique',\n        dataPath: [],\n        document: makeDocument({\n          dmmf,\n          select: {\n            where: {\n              id: '2',\n            },\n          },\n          rootTypeName: 'query',\n          rootField: 'findUniqueUser',\n        }),\n        isList: false,\n        rootField: 'query',\n        typeName: 'User',\n        args: { where: { id: '2' } },\n      }),\n    ])\n\n    expect(batches).toMatchInlineSnapshot(`Array []`)\n    expect(requests).toMatchInlineSnapshot(`\n      Array [\n        query {\n        findUniqueUser(where: {\n          email: \"a@a.de\"\n        }) {\n          id\n          email\n          name\n          json\n          countFloat\n          countInt1\n          countInt2\n          countInt3\n          countInt4\n          countInt5\n          countInt6\n          lastLoginAt\n          coinflips\n        }\n      },\n        query {\n        findUniqueUser(where: {\n          id: \"2\"\n        }) {\n          id\n          email\n          name\n          json\n          countFloat\n          countInt1\n          countInt2\n          countInt3\n          countInt4\n          countInt5\n          countInt6\n          lastLoginAt\n          coinflips\n        }\n      },\n      ]\n    `)\n  })","file":"batching.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"should error correctly with invalid flags","suites":["BinaryEngine"],"updatePoint":{"line":6,"column":49},"line":6,"code":"  test('should error correctly with invalid flags', async () => {\n    // Skip for Node-API library\n    // TODO Better scoping when to run this test so this conditional is not necessary\n    if (getClientEngineType() === ClientEngineType.Library) {\n      return\n    }\n\n    try {\n      const engine = new BinaryEngine({\n        flags: ['--flag-that-does-not-exist'],\n        datamodelPath: path.join(__dirname, './runtime-tests/blog/schema.prisma'),\n      })\n      await engine.start()\n    } catch (e) {\n      expect(e.message).toMatch(` Found argument '--flag-that-does-not-exist' which wasn't expected`)\n    }\n  })","file":"binaryEngine.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"generate correct query","suites":["date where filter"],"updatePoint":{"line":38,"column":30},"line":38,"code":"  test('generate correct query', () => {\n    const select = {\n      where: {\n        AND: [\n          { employeeId: { in: [''] } },\n          { status: 'uploaded' },\n          { paymentDate: new Date('2010-11-13T10:36:43.261Z') },\n          { publishedAt: null },\n        ],\n      },\n      data: {\n        status: 'published',\n        publishedAt: new Date('2020-11-13T10:36:43.261Z'),\n        // tests RFC 3339\n        updatedAt: '2021-01-13T12:40:47+01:00',\n      },\n    }\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'mutation',\n      rootField: 'updateManyPayslip',\n    })\n    document.validate(select, false)\n    expect(String(document)).toMatchInlineSnapshot(`\n      mutation {\n        updateManyPayslip(\n          where: {\n            AND: [\n              {\n                employeeId: {\n                  in: [\"\"]\n                }\n              },\n              {\n                status: \"uploaded\"\n              },\n              {\n                paymentDate: \"2010-11-13T10:36:43.261Z\"\n              },\n              {\n                publishedAt: null\n              }\n            ]\n          }\n          data: {\n            status: \"published\"\n            publishedAt: \"2020-11-13T10:36:43.261Z\"\n            updatedAt: \"2021-01-13T12:40:47+01:00\"\n          }\n        ) {\n          count\n        }\n      }\n    `)\n    expect(String(transformDocument(document))).toMatchInlineSnapshot(`\n      mutation {\n        updateManyPayslip(\n          where: {\n            AND: [\n              {\n                employeeId: {\n                  in: [\"\"]\n                }\n              },\n              {\n                status: \"uploaded\"\n              },\n              {\n                paymentDate: \"2010-11-13T10:36:43.261Z\"\n              },\n              {\n                publishedAt: null\n              }\n            ]\n          }\n          data: {\n            status: \"published\"\n            publishedAt: \"2020-11-13T10:36:43.261Z\"\n            updatedAt: \"2021-01-13T12:40:47+01:00\"\n          }\n        ) {\n          count\n        }\n      }\n    `)\n  })","file":"dateWhere.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"OR posts some id in","suites":["minimal where transformation"],"updatePoint":{"line":13,"column":27},"line":13,"code":"  test('OR posts some id in', () => {\n    const transformedDocument = getTransformedDocument({\n      where: {\n        OR: [\n          {\n            posts: {\n              some: {\n                OR: [\n                  {\n                    author: {\n                      OR: [\n                        {\n                          AND: [\n                            {\n                              OR: [\n                                {\n                                  id: '10',\n                                },\n                              ],\n                            },\n                          ],\n                        },\n                      ],\n                    },\n                  },\n                ],\n              },\n            },\n          },\n        ],\n      },\n    })\n\n    expect(transformedDocument).toMatchInlineSnapshot(`\n      query {\n        findManyUser(where: {\n          OR: [\n            {\n              posts: {\n                some: {\n                  OR: [\n                    {\n                      author: {\n                        OR: [\n                          {\n                            AND: [\n                              {\n                                OR: [\n                                  {\n                                    id: \"10\"\n                                  }\n                                ]\n                              }\n                            ]\n                          }\n                        ]\n                      }\n                    }\n                  ]\n                }\n              }\n            }\n          ]\n        }) {\n          id\n          email\n          name\n          json\n          countFloat\n          countInt1\n          countInt2\n          countInt3\n          countInt4\n          countInt5\n          countInt6\n          lastLoginAt\n          coinflips\n        }\n      }\n    `)\n  })","file":"deepAndOr.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"work with 0","suites":["deepGet"],"updatePoint":{"line":4,"column":19},"line":4,"code":"  test('work with 0', () => {\n    const obj = {\n      aggregateUser: {\n        count: 0,\n      },\n    }\n    const path = ['aggregateUser', 'count']\n    const result = deepGet(obj, path)\n    expect(result).toMatchInlineSnapshot(`0`)\n  })","file":"deepGet.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"work with false","suites":["deepGet"],"updatePoint":{"line":15,"column":23},"line":15,"code":"  test('work with false', () => {\n    const obj = {\n      aggregateUser: {\n        count: false,\n      },\n    }\n    const path = ['aggregateUser', 'count']\n    expect(deepGet(obj, path)).toMatchInlineSnapshot(`false`)\n  })","file":"deepGet.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"work with deep object","suites":["deepGet"],"updatePoint":{"line":25,"column":29},"line":25,"code":"  test('work with deep object', () => {\n    const obj = {\n      very: {\n        deep: {\n          obj: {\n            with: {\n              deep: 'stuff',\n            },\n          },\n        },\n      },\n    }\n    const path = ['very', 'deep', 'obj']\n    expect(deepGet(obj, path)).toMatchInlineSnapshot(`\n      Object {\n        with: Object {\n          deep: stuff,\n        },\n      }\n    `)\n  })","file":"deepGet.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"return undefined for invalid path","suites":["deepGet"],"updatePoint":{"line":47,"column":41},"line":47,"code":"  test('return undefined for invalid path', () => {\n    const obj = {\n      very: {\n        deep: {\n          obj: {\n            with: {\n              deep: 'stuff',\n            },\n          },\n        },\n      },\n    }\n    const path = ['very', 'deep', 'obj2']\n    expect(deepGet(obj, path)).toMatchInlineSnapshot(`undefined`)\n  })","file":"deepGet.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"work with array","suites":["deepGet"],"updatePoint":{"line":63,"column":23},"line":63,"code":"  test('work with array', () => {\n    const obj = [\n      {\n        id: 1,\n      },\n    ]\n\n    const path = ['0', 'id']\n    expect(deepGet(obj, path)).toMatchInlineSnapshot(`1`)\n  })","file":"deepGet.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"OR posts some id in","suites":["minimal where transformation"],"updatePoint":{"line":13,"column":27},"line":13,"code":"  test('OR posts some id in', () => {\n    const transformedDocument = getTransformedDocument({\n      where: {\n        likedArticles: {\n          some: {\n            likedBy: {\n              some: {\n                AND: {\n                  likedArticles: {\n                    some: {\n                      likedBy: {\n                        some: {\n                          likedArticles: {\n                            some: {\n                              title: {\n                                contains: 'A string',\n                              },\n                            },\n                          },\n                        },\n                      },\n                    },\n                  },\n                },\n              },\n            },\n          },\n        },\n      },\n    })\n\n    expect(transformedDocument).toMatchInlineSnapshot(`\n      query {\n        findManyUser(where: {\n          likedArticles: {\n            some: {\n              likedBy: {\n                some: {\n                  AND: {\n                    likedArticles: {\n                      some: {\n                        likedBy: {\n                          some: {\n                            likedArticles: {\n                              some: {\n                                title: {\n                                  contains: \"A string\"\n                                }\n                              }\n                            }\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }) {\n          id\n          name\n          email\n          personaId\n        }\n      }\n    `)\n  })","file":"deepQuery.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"OR posts some id in","suites":["minimal where transformation"],"updatePoint":{"line":14,"column":27},"line":14,"code":"  test('OR posts some id in', () => {\n    const transformedDocument = getTransformedDocument({\n      where: {\n        posts: {\n          some: {\n            author: {\n              posts: {\n                some: {\n                  author: {\n                    posts: {\n                      some: {\n                        id: '5',\n                      },\n                    },\n                  },\n                },\n              },\n            },\n          },\n        },\n      },\n    })\n\n    expect(transformedDocument).toMatchInlineSnapshot(`\n      query {\n        findManyUser(where: {\n          posts: {\n            some: {\n              author: {\n                posts: {\n                  some: {\n                    author: {\n                      posts: {\n                        some: {\n                          id: \"5\"\n                        }\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }) {\n          id\n          email\n          name\n          json\n          countFloat\n          countInt1\n          countInt2\n          countInt3\n          countInt4\n          countInt5\n          countInt6\n          lastLoginAt\n          coinflips\n        }\n      }\n    `)\n  })","file":"deepSome.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"dmmf enum filter mysql","suites":["dmmf"],"updatePoint":{"line":5,"column":30},"line":5,"code":"  test('dmmf enum filter mysql', async () => {\n    const datamodel = `\n      datasource db {\n        provider = \"mysql\"\n        url      = env(\"MY_MYSQL_DB\")\n      }\n      \n      model User {\n        id Int @id @default(autoincrement())\n        name String\n        email String @unique\n        kind PostKind\n      }\n      \n      enum PostKind {\n        NICE\n        AWESOME\n      }`\n\n    const dmmf = await getDMMF({ datamodel })\n    expect(dmmf.schema.inputObjectTypes.prisma.find((i) => i.name === 'NestedEnumPostKindFilter'))\n      .toMatchInlineSnapshot(`\n      Object {\n        constraints: Object {\n          maxNumFields: null,\n          minNumFields: null,\n        },\n        fields: Array [\n          Object {\n            inputTypes: Array [\n              Object {\n                isList: false,\n                location: enumTypes,\n                namespace: model,\n                type: PostKind,\n              },\n            ],\n            isNullable: false,\n            isRequired: false,\n            name: equals,\n          },\n          Object {\n            inputTypes: Array [\n              Object {\n                isList: true,\n                location: enumTypes,\n                namespace: model,\n                type: PostKind,\n              },\n            ],\n            isNullable: false,\n            isRequired: false,\n            name: in,\n          },\n          Object {\n            inputTypes: Array [\n              Object {\n                isList: true,\n                location: enumTypes,\n                namespace: model,\n                type: PostKind,\n              },\n            ],\n            isNullable: false,\n            isRequired: false,\n            name: notIn,\n          },\n          Object {\n            inputTypes: Array [\n              Object {\n                isList: false,\n                location: enumTypes,\n                namespace: model,\n                type: PostKind,\n              },\n              Object {\n                isList: false,\n                location: inputObjectTypes,\n                namespace: prisma,\n                type: NestedEnumPostKindFilter,\n              },\n            ],\n            isNullable: false,\n            isRequired: false,\n            name: not,\n          },\n        ],\n        name: NestedEnumPostKindFilter,\n      }\n    `)\n    expect(dmmf.schema.inputObjectTypes.prisma.find((i) => i.name === 'EnumPostKindFilter')).toMatchInlineSnapshot(`\n      Object {\n        constraints: Object {\n          maxNumFields: null,\n          minNumFields: null,\n        },\n        fields: Array [\n          Object {\n            inputTypes: Array [\n              Object {\n                isList: false,\n                location: enumTypes,\n                namespace: model,\n                type: PostKind,\n              },\n            ],\n            isNullable: false,\n            isRequired: false,\n            name: equals,\n          },\n          Object {\n            inputTypes: Array [\n              Object {\n                isList: true,\n                location: enumTypes,\n                namespace: model,\n                type: PostKind,\n              },\n            ],\n            isNullable: false,\n            isRequired: false,\n            name: in,\n          },\n          Object {\n            inputTypes: Array [\n              Object {\n                isList: true,\n                location: enumTypes,\n                namespace: model,\n                type: PostKind,\n              },\n            ],\n            isNullable: false,\n            isRequired: false,\n            name: notIn,\n          },\n          Object {\n            inputTypes: Array [\n              Object {\n                isList: false,\n                location: enumTypes,\n                namespace: model,\n                type: PostKind,\n              },\n              Object {\n                isList: false,\n                location: inputObjectTypes,\n                namespace: prisma,\n                type: NestedEnumPostKindFilter,\n              },\n            ],\n            isNullable: false,\n            isRequired: false,\n            name: not,\n          },\n        ],\n        name: EnumPostKindFilter,\n      }\n    `)\n  })","file":"dmmf.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"dmmf enum filter postgresql","suites":["dmmf"],"updatePoint":{"line":166,"column":35},"line":166,"code":"  test('dmmf enum filter postgresql', async () => {\n    const datamodel = `\n      datasource db {\n        provider = \"postgresql\"\n        url      = env(\"MY_POSTGRES_DB\")\n      }\n      \n      model User {\n        id Int @id @default(autoincrement())\n        name String\n        email String @unique\n        kind PostKind\n      }\n      \n      enum PostKind {\n        NICE\n        AWESOME\n      }`\n\n    const dmmf = await getDMMF({ datamodel })\n    expect(dmmf.schema.inputObjectTypes.prisma.find((i) => i.name === 'NestedEnumPostKindFilter'))\n      .toMatchInlineSnapshot(`\n      Object {\n        constraints: Object {\n          maxNumFields: null,\n          minNumFields: null,\n        },\n        fields: Array [\n          Object {\n            inputTypes: Array [\n              Object {\n                isList: false,\n                location: enumTypes,\n                namespace: model,\n                type: PostKind,\n              },\n            ],\n            isNullable: false,\n            isRequired: false,\n            name: equals,\n          },\n          Object {\n            inputTypes: Array [\n              Object {\n                isList: true,\n                location: enumTypes,\n                namespace: model,\n                type: PostKind,\n              },\n            ],\n            isNullable: false,\n            isRequired: false,\n            name: in,\n          },\n          Object {\n            inputTypes: Array [\n              Object {\n                isList: true,\n                location: enumTypes,\n                namespace: model,\n                type: PostKind,\n              },\n            ],\n            isNullable: false,\n            isRequired: false,\n            name: notIn,\n          },\n          Object {\n            inputTypes: Array [\n              Object {\n                isList: false,\n                location: enumTypes,\n                namespace: model,\n                type: PostKind,\n              },\n              Object {\n                isList: false,\n                location: inputObjectTypes,\n                namespace: prisma,\n                type: NestedEnumPostKindFilter,\n              },\n            ],\n            isNullable: false,\n            isRequired: false,\n            name: not,\n          },\n        ],\n        name: NestedEnumPostKindFilter,\n      }\n    `)\n    expect(dmmf.schema.inputObjectTypes.prisma.find((i) => i.name === 'EnumPostKindFilter')).toMatchInlineSnapshot(`\n      Object {\n        constraints: Object {\n          maxNumFields: null,\n          minNumFields: null,\n        },\n        fields: Array [\n          Object {\n            inputTypes: Array [\n              Object {\n                isList: false,\n                location: enumTypes,\n                namespace: model,\n                type: PostKind,\n              },\n            ],\n            isNullable: false,\n            isRequired: false,\n            name: equals,\n          },\n          Object {\n            inputTypes: Array [\n              Object {\n                isList: true,\n                location: enumTypes,\n                namespace: model,\n                type: PostKind,\n              },\n            ],\n            isNullable: false,\n            isRequired: false,\n            name: in,\n          },\n          Object {\n            inputTypes: Array [\n              Object {\n                isList: true,\n                location: enumTypes,\n                namespace: model,\n                type: PostKind,\n              },\n            ],\n            isNullable: false,\n            isRequired: false,\n            name: notIn,\n          },\n          Object {\n            inputTypes: Array [\n              Object {\n                isList: false,\n                location: enumTypes,\n                namespace: model,\n                type: PostKind,\n              },\n              Object {\n                isList: false,\n                location: inputObjectTypes,\n                namespace: prisma,\n                type: NestedEnumPostKindFilter,\n              },\n            ],\n            isNullable: false,\n            isRequired: false,\n            name: not,\n          },\n        ],\n        name: EnumPostKindFilter,\n      }\n    `)\n  })","file":"dmmf.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"dmmf enum should fail on sqlite","suites":["dmmf"],"updatePoint":{"line":327,"column":39},"line":327,"code":"  test('dmmf enum should fail on sqlite', async () => {\n    const datamodel = `\n      datasource db {\n        provider = \"sqlite\"\n        url      = \"file:./dev.db\"\n      }\n\n      model User {\n        id Int @id @default(autoincrement())\n        name String\n        email String @unique\n        kind PostKind\n      }\n\n      enum PostKind {\n        NICE\n        AWESOME\n      }`\n\n    try {\n      await getDMMF({ datamodel })\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchInlineSnapshot(`\n        Schema parsing\n        error: Error validating: You defined the enum \\`PostKind\\`. But the current connector does not support enums.\n          -->  schema.prisma:14\n           | \n        13 | \n        14 |       enum PostKind {\n        15 |         NICE\n        16 |         AWESOME\n        17 |       }\n           | \n\n        Validation Error Count: 1\n      `)\n    }\n  })","file":"dmmf.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"dmmf types","suites":[],"updatePoint":{"line":25,"column":16},"line":25,"code":"test('dmmf types', async () => {\n  const dmmf = await getDMMF({ datamodel: blog })\n  const file = `import { DMMF } from '@prisma/generator-helper'\n\nconst dmmf: DMMF.Document = ${JSON.stringify(sortKeys(dmmf, { deep: true }), null, 2)}\n`\n  const target = path.join(__dirname, '__helpers__/dmmf-types.ts')\n  fs.writeFileSync(target, file)\n\n  try {\n    await import('./__helpers__/dmmf-types')\n  } catch (e) {\n    // we need to do this, as jest can't print the errors\n    // resulting from the dynamic import\n    console.error(e)\n    throw e\n  }\n  expect(1).toBe(1)\n})","file":"dmmfTypes.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"document stringify","suites":[],"updatePoint":{"line":3,"column":24},"line":3,"code":"test('document stringify', () => {\n  const document = new Document('query', [\n    new Field({\n      name: 'users',\n      args: new Args([\n        new Arg({\n          key: 'mirst',\n          value: 100,\n          error: {\n            didYouMeanArg: 'first',\n            providedName: 'mirst',\n            providedValue: '',\n            type: 'invalidName',\n            originalType: 'String',\n          },\n        }),\n        new Arg({\n          key: 'skip',\n          value: '200',\n          error: {\n            type: 'invalidType',\n            providedValue: '200',\n            argName: 'skip',\n            requiredType: {\n              inputType: [\n                {\n                  isList: false,\n                  location: 'scalar',\n                  type: 'number',\n                },\n              ],\n              bestFittingType: {\n                isList: false,\n                location: 'scalar',\n                type: 'number',\n              },\n            },\n          },\n        }),\n        new Arg({\n          key: 'where',\n          value: new Args([\n            new Arg({ key: 'age_gt', value: 10 }),\n            new Arg({ key: 'age_in', value: [1, 2, 3] }),\n            new Arg({ key: 'name_in', value: ['hans', 'peter', 'schmidt'] }),\n            new Arg({\n              key: 'OR',\n              value: [\n                new Args([\n                  new Arg({ key: 'age_gt', value: 10123123123 }),\n                  new Arg({\n                    key: 'email_endsWith',\n                    value: 'veryLongNameGoIntoaNewLineNow@gmail.com',\n                  }),\n                ]),\n                new Args([\n                  new Arg({ key: 'age_gt', value: 10123123123 }),\n                  new Arg({\n                    key: 'email_endsWith',\n                    value: 'veryLongNameGoIntoaNewLineNow@gmail.com',\n                  }),\n                  new Arg({\n                    key: 'OR',\n                    value: [\n                      new Args([\n                        new Arg({ key: 'age_gt', value: 10123123123 }),\n                        new Arg({\n                          key: 'email_endsWith',\n                          value: 'veryLongNameGoIntoaNewLineNow@gmail.com',\n                        }),\n                      ]),\n                    ],\n                  }),\n                ]),\n              ],\n            }),\n          ]),\n        }),\n      ]),\n      children: [\n        new Field({ name: 'id' }),\n        new Field({\n          name: 'name2',\n          error: {\n            modelName: 'User',\n            didYouMean: 'name',\n            providedName: 'name2',\n            type: 'invalidFieldName',\n            outputType: {\n              fields: [],\n              name: 'User',\n              fieldMap: {},\n            },\n          },\n        }),\n        new Field({\n          name: 'friends',\n          args: new Args(),\n          children: [new Field({ name: 'id' }), new Field({ name: 'name' })],\n        }),\n        new Field({\n          name: 'posts',\n          args: new Args([new Arg({ key: 'first', value: 200 })]),\n          children: [new Field({ name: 'id' }), new Field({ name: 'name' })],\n        }),\n      ],\n    }),\n  ])\n\n  expect(String(document)).toMatchInlineSnapshot(`\n    query {\n      users(\n        mirst: 100\n        skip: \"200\"\n        where: {\n          age_gt: 10\n          age_in: [1, 2, 3]\n          name_in: [\"hans\", \"peter\", \"schmidt\"]\n          OR: [\n            {\n              age_gt: 10123123123\n              email_endsWith: \"veryLongNameGoIntoaNewLineNow@gmail.com\"\n            },\n            {\n              age_gt: 10123123123\n              email_endsWith: \"veryLongNameGoIntoaNewLineNow@gmail.com\"\n              OR: [\n                {\n                  age_gt: 10123123123\n                  email_endsWith: \"veryLongNameGoIntoaNewLineNow@gmail.com\"\n                }\n              ]\n            }\n          ]\n        }\n      ) {\n        id\n        name2 # INVALID_FIELD\n        friends {\n          id\n          name\n        }\n        posts(first: 200) {\n          id\n          name\n        }\n      }\n    }\n  `)\n})","file":"document.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"ignore comments","suites":[],"updatePoint":{"line":4,"column":21},"line":4,"code":"test('ignore comments', () => {\n  const datamodel = `datasource db {\n    provider = \"sqlite\"\n    // url = \"file:another/wrong/folder/dev.db\"\n    url      = \"file:my/folder/dev.db\"\n  }\n\n  generator client {\n    provider  = \"prisma-client-js\"\n    output    = \"@prisma/client\"\n    transpile = false\n  }\n\n  model User {\n    id    String  @id @default(uuid())\n    email String  @unique\n    name  String?\n    posts Post[]\n  }\n\n  model Post {\n    id         String   @id @default(uuid())\n    createdAt  DateTime @default(now())\n    updatedAt  DateTime @updatedAt\n    randomDate DateTime\n    published  Boolean\n    title      String\n    content    String?\n    author     User?\n  }\n\n  /// Role num comment\n  enum Role {\n    USER\n    ADMIN\n  }`\n\n  const result = extractSqliteSources(datamodel, '/cwd', '/outputdir')\n\n  expect(result).toMatchInlineSnapshot(`\n    Array [\n      Object {\n        name: db,\n        url: ../cwd/my/folder/dev.db,\n      },\n    ]\n  `)\n\n  let serializedResult = serializeDatasources(result)\n\n  // TODO: Windows: fixup to work around a bug in jestSnapshotSerializer\n  if (process.platform === 'win32') {\n    serializedResult = serializedResult.replace(/\\\\\\\\/g, '/')\n  }\n\n  expect(serializedResult).toMatchInlineSnapshot(`\n    [\n      {\n        \"name\": \"db\",\n        \"url\": \"../cwd/my/folder/dev.db\"\n      }\n    ]\n  `)\n})","file":"extractSqliteSources.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"basic happy path","suites":[],"updatePoint":{"line":69,"column":22},"line":69,"code":"test('basic happy path', () => {\n  const datamodel = `datasource db {\n    provider = \"sqlite\"\n    url      = \"file:my/folder/dev.db\"\n    \n  }\n\n  generator client {\n    provider  = \"prisma-client-js\"\n    output    = \"@prisma/client\"\n    transpile = false\n  }\n\n  model User {\n    id    String  @id @default(uuid())\n    email String  @unique\n    name  String?\n    posts Post[]\n  }\n\n  model Post {\n    id         String   @id @default(uuid())\n    createdAt  DateTime @default(now())\n    updatedAt  DateTime @updatedAt\n    randomDate DateTime\n    published  Boolean\n    title      String\n    content    String?\n    author     User?\n  }\n\n  /// Role num comment\n  enum Role {\n    USER\n    ADMIN\n  }`\n\n  const result = extractSqliteSources(datamodel, '/cwd', '/outputdir')\n\n  expect(result).toMatchInlineSnapshot(`\n    Array [\n      Object {\n        name: db,\n        url: ../cwd/my/folder/dev.db,\n      },\n    ]\n  `)\n\n  let serializedResult = serializeDatasources(result)\n\n  // TODO: Windows: fixup to work around a bug in jestSnapshotSerializer\n  if (process.platform === 'win32') {\n    serializedResult = serializedResult.replace(/\\\\\\\\/g, '/')\n  }\n\n  expect(serializedResult).toMatchInlineSnapshot(`\n    [\n      {\n        \"name\": \"db\",\n        \"url\": \"../cwd/my/folder/dev.db\"\n      }\n    ]\n  `)\n})","file":"extractSqliteSources.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"minimal","suites":["generator"],"updatePoint":{"line":13,"column":15},"line":13,"code":"  test('minimal', async () => {\n    const prismaClientTarget = path.join(__dirname, './node_modules/@prisma/client')\n    // Make sure, that nothing is cached.\n    try {\n      await del(prismaClientTarget)\n    } catch (e) {\n      //\n    }\n    await getPackedPackage('@prisma/client', prismaClientTarget)\n\n    if (!fs.existsSync(prismaClientTarget)) {\n      throw new Error(`Prisma Client didn't get packed properly 🤔`)\n    }\n\n    const generator = await getGenerator({\n      schemaPath: path.join(__dirname, 'schema.prisma'),\n      baseDir: __dirname,\n      printDownloadProgress: false,\n      skipDownload: true,\n    })\n\n    const manifest = omit<any, any>(generator.manifest, ['version']) as any\n\n    if (manifest.requiresEngineVersion.length !== 40) {\n      throw new Error(`Generator manifest should have \"requiresEngineVersion\" with length 40`)\n    }\n    manifest.requiresEngineVersion = 'ENGINE_VERSION_TEST'\n\n    if (getClientEngineType() === ClientEngineType.Library) {\n      expect(manifest).toMatchInlineSnapshot(`\n        Object {\n          defaultOutput: .prisma/client,\n          prettyName: Prisma Client,\n          requiresEngineVersion: ENGINE_VERSION_TEST,\n          requiresEngines: Array [\n            libqueryEngine,\n          ],\n        }\n      `)\n    } else {\n      expect(manifest).toMatchInlineSnapshot(`\n        Object {\n          defaultOutput: .prisma/client,\n          prettyName: Prisma Client,\n          requiresEngineVersion: ENGINE_VERSION_TEST,\n          requiresEngines: Array [\n            queryEngine,\n          ],\n        }\n      `)\n    }\n\n    expect(omit(generator.options!.generator, ['output'])).toMatchInlineSnapshot(`\n      Object {\n        binaryTargets: Array [],\n        config: Object {},\n        name: client,\n        previewFeatures: Array [],\n        provider: Object {\n          fromEnvVar: null,\n          value: prisma-client-js,\n        },\n      }\n    `)\n\n    expect(path.relative(__dirname, parseEnvValue(generator.options!.generator.output!))).toMatchInlineSnapshot(\n      `node_modules/@prisma/client`,\n    )\n\n    await generator.generate()\n    const photonDir = path.join(__dirname, 'node_modules/@prisma/client')\n    expect(fs.existsSync(photonDir)).toBe(true)\n    expect(fs.existsSync(path.join(photonDir, 'index.js'))).toBe(true)\n    expect(fs.existsSync(path.join(photonDir, 'index-browser.js'))).toBe(true)\n    expect(fs.existsSync(path.join(photonDir, 'index.d.ts'))).toBe(true)\n    expect(fs.existsSync(path.join(photonDir, 'runtime'))).toBe(true)\n    generator.stop()\n  })","file":"generation/generator.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"denylist from engine validation","suites":["generator"],"updatePoint":{"line":92,"column":39},"line":92,"code":"  test('denylist from engine validation', async () => {\n    const prismaClientTarget = path.join(__dirname, './node_modules/@prisma/client')\n    // Make sure, that nothing is cached.\n    try {\n      await del(prismaClientTarget)\n    } catch (e) {\n      //\n    }\n    await getPackedPackage('@prisma/client', prismaClientTarget)\n\n    if (!fs.existsSync(prismaClientTarget)) {\n      throw new Error(`Prisma Client didn't get packed properly 🤔`)\n    }\n\n    try {\n      await getGenerator({\n        schemaPath: path.join(__dirname, 'denylist.prisma'),\n        baseDir: __dirname,\n        printDownloadProgress: false,\n        skipDownload: true,\n      })\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchInlineSnapshot(`\n        Schema parsing\n        error: Error validating model \"public\": The model name \\`public\\` is invalid. It is a reserved name. Please change it. Read more at https://pris.ly/d/naming-models\n          -->  schema.prisma:10\n           | \n         9 | \n        10 | model public {\n        11 |   id Int @id\n        12 | }\n           | \n        error: Error validating model \"return\": The model name \\`return\\` is invalid. It is a reserved name. Please change it. Read more at https://pris.ly/d/naming-models\n          -->  schema.prisma:14\n           | \n        13 | \n        14 | model return {\n        15 |   id Int @id\n        16 | }\n           | \n\n        Validation Error Count: 2\n      `)\n    }\n  })","file":"generation/generator.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"schema path does not exist","suites":["generator"],"updatePoint":{"line":138,"column":34},"line":138,"code":"  test('schema path does not exist', async () => {\n    const prismaClientTarget = path.join(__dirname, './node_modules/@prisma/client')\n    // Make sure, that nothing is cached.\n    try {\n      await del(prismaClientTarget)\n    } catch (e) {\n      //\n    }\n    await getPackedPackage('@prisma/client', prismaClientTarget)\n\n    if (!fs.existsSync(prismaClientTarget)) {\n      throw new Error(`Prisma Client didn't get packed properly 🤔`)\n    }\n\n    let doesnNotExistError\n    try {\n      await getGenerator({\n        schemaPath: path.join(__dirname, 'doesnotexist.prisma'),\n        baseDir: __dirname,\n        printDownloadProgress: false,\n        skipDownload: true,\n      })\n    } catch (e) {\n      doesnNotExistError = e\n    } finally {\n      expect(stripAnsi(doesnNotExistError.message).split('generation' + path.sep)[1]).toMatchInlineSnapshot(\n        `doesnotexist.prisma does not exist`,\n      )\n    }\n  })","file":"generation/generator.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"mongo","suites":["generator"],"updatePoint":{"line":169,"column":13},"line":169,"code":"  test('mongo', async () => {\n    const prismaClientTarget = path.join(__dirname, './node_modules/@prisma/client')\n    // Make sure, that nothing is cached.\n    try {\n      await del(prismaClientTarget)\n    } catch (e) {\n      //\n    }\n    await getPackedPackage('@prisma/client', prismaClientTarget)\n\n    if (!fs.existsSync(prismaClientTarget)) {\n      throw new Error(`Prisma Client didn't get packed properly 🤔`)\n    }\n\n    const generator = await getGenerator({\n      schemaPath: path.join(__dirname, 'mongo.prisma'),\n      baseDir: __dirname,\n      printDownloadProgress: false,\n      skipDownload: true,\n    })\n\n    const manifest = omit<any, any>(generator.manifest, ['version']) as any\n\n    if (manifest.requiresEngineVersion.length !== 40) {\n      throw new Error(`Generator manifest should have \"requiresEngineVersion\" with length 40`)\n    }\n    manifest.requiresEngineVersion = 'ENGINE_VERSION_TEST'\n\n    if (getClientEngineType(generator.config) === ClientEngineType.Library) {\n      expect(manifest).toMatchInlineSnapshot(`\n        Object {\n          defaultOutput: .prisma/client,\n          prettyName: Prisma Client,\n          requiresEngineVersion: ENGINE_VERSION_TEST,\n          requiresEngines: Array [\n            libqueryEngine,\n          ],\n        }\n      `)\n    } else {\n      expect(manifest).toMatchInlineSnapshot(`\n        Object {\n          defaultOutput: .prisma/client,\n          prettyName: Prisma Client,\n          requiresEngineVersion: ENGINE_VERSION_TEST,\n          requiresEngines: Array [\n            queryEngine,\n          ],\n        }\n      `)\n    }\n\n    expect(omit(generator.options!.generator, ['output'])).toMatchInlineSnapshot(`\n      Object {\n        binaryTargets: Array [],\n        config: Object {},\n        name: client,\n        previewFeatures: Array [\n          mongoDb,\n        ],\n        provider: Object {\n          fromEnvVar: null,\n          value: prisma-client-js,\n        },\n      }\n    `)\n\n    expect(path.relative(__dirname, parseEnvValue(generator.options!.generator.output!))).toMatchInlineSnapshot(\n      `node_modules/@prisma/client`,\n    )\n\n    await generator.generate()\n    const photonDir = path.join(__dirname, 'node_modules/@prisma/client')\n    expect(fs.existsSync(photonDir)).toBe(true)\n    expect(fs.existsSync(path.join(photonDir, 'index.js'))).toBe(true)\n    expect(fs.existsSync(path.join(photonDir, 'index-browser.js'))).toBe(true)\n    expect(fs.existsSync(path.join(photonDir, 'index.d.ts'))).toBe(true)\n    expect(fs.existsSync(path.join(photonDir, 'runtime'))).toBe(true)\n    generator.stop()\n  })","file":"generation/generator.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"info and warn","suites":[],"updatePoint":{"line":3,"column":19},"line":3,"code":"test('info and warn', () => {\n  const level = getLogLevel([\n    {\n      emit: 'event',\n      level: 'info',\n    },\n    {\n      emit: 'event',\n      level: 'warn',\n    },\n  ])\n\n  expect(level).toMatchInlineSnapshot(`info`)\n})","file":"getLogLevel.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"query","suites":[],"updatePoint":{"line":18,"column":11},"line":18,"code":"test('query', () => {\n  const level = getLogLevel([\n    {\n      emit: 'event',\n      level: 'query',\n    },\n  ])\n\n  expect(level).toMatchInlineSnapshot(`undefined`)\n})","file":"getLogLevel.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"strings and objects","suites":[],"updatePoint":{"line":29,"column":25},"line":29,"code":"test('strings and objects', () => {\n  const level = getLogLevel([\n    {\n      emit: 'event',\n      level: 'query',\n    },\n    'warn',\n  ])\n\n  expect(level).toMatchInlineSnapshot(`warn`)\n})","file":"getLogLevel.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"strings","suites":[],"updatePoint":{"line":40,"column":13},"line":40,"code":"test('strings', () => {\n  const level = getLogLevel('warn')\n\n  expect(level).toMatchInlineSnapshot(`warn`)\n})","file":"getLogLevel.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"strings array","suites":[],"updatePoint":{"line":46,"column":19},"line":46,"code":"test('strings array', () => {\n  const level = getLogLevel(['warn', 'error'])\n\n  expect(level).toMatchInlineSnapshot(`error`)\n})","file":"getLogLevel.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"deep include query","suites":["include validation"],"updatePoint":{"line":14,"column":26},"line":14,"code":"  test('deep include query', () => {\n    const ast = {\n      include: {\n        author: {\n          include: {\n            posts: true,\n          },\n        },\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'query',\n      rootField: 'findManyPost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    expect(() => document.validate(ast)).not.toThrow()\n  })","file":"include.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"dont allow empty include statements","suites":["include validation"],"updatePoint":{"line":36,"column":43},"line":36,"code":"  test('dont allow empty include statements', () => {\n    const ast = {\n      include: {},\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'query',\n      rootField: 'findManyPost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    try {\n      document.validate(ast, false)\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchInlineSnapshot(`\n\nInvalid \\`prisma.findManyPost()\\` invocation:\n\n{\n  include: {\n?   author?: true,\n?   categories?: true,\n?   _count?: true\n  }\n}\n\n\nThe \\`include\\` statement for type Post must not be empty. Available options are listed in green.\n\n`)\n    }\n  })","file":"include.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"allow normal findMany without include for empty model","suites":["include validation"],"updatePoint":{"line":71,"column":61},"line":71,"code":"  test('allow normal findMany without include for empty model', () => {\n    const ast = {}\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'query',\n      rootField: 'findManyNoRelations',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    document.validate(ast, false)\n  })","file":"include.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"enforce no include, if no relation","suites":["include validation"],"updatePoint":{"line":85,"column":42},"line":85,"code":"  test('enforce no include, if no relation', () => {\n    const ast = {\n      include: {},\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'query',\n      rootField: 'findManyNoRelations',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    try {\n      document.validate(ast, false)\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchInlineSnapshot(`\n\n        Invalid \\`prisma.findManyNoRelations()\\` invocation:\n\n        {\n          include: {}\n        }\n\n\n        NoRelations does not have any relation and therefore can't have an \\`include\\` statement.\n\n      `)\n    }\n  })","file":"include.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"enforce empty include, if no relation","suites":["include validation"],"updatePoint":{"line":116,"column":45},"line":116,"code":"  test('enforce empty include, if no relation', () => {\n    const ast = {\n      include: {\n        asd: true,\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'query',\n      rootField: 'findManyNoRelations',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    try {\n      document.validate(ast, false)\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchInlineSnapshot(`\n\n        Invalid \\`prisma.asd()\\` invocation:\n\n        {\n          include: {\n            asd: true\n            ~~~\n          }\n        }\n\n\n        Unknown field \\`asd\\` for include statement on model NoRelations.\n        This model has no relations, so you can't use include with it.\n\n      `)\n    }\n  })","file":"include.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"allow include statement with only false properties","suites":["include validation"],"updatePoint":{"line":157,"column":58},"line":157,"code":"  test('allow include statement with only false properties', () => {\n    const ast = {\n      include: {\n        author: true,\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'query',\n      rootField: 'findManyPost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    expect(() => document.validate(ast)).not.toThrow()\n  })","file":"include.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"allow deep include with empty object","suites":["include validation"],"updatePoint":{"line":175,"column":44},"line":175,"code":"  test('allow deep include with empty object', () => {\n    const ast = {\n      include: {\n        posts: {},\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'query',\n      rootField: 'findManyUser',\n    })\n\n    expect(String(document)).toMatchInlineSnapshot(`\n      query {\n        findManyUser {\n          id\n          email\n          name\n          json\n          countFloat\n          countInt1\n          countInt2\n          countInt3\n          countInt4\n          countInt5\n          countInt6\n          lastLoginAt\n          coinflips\n          posts {\n            id\n            createdAt\n            updatedAt\n            published\n            title\n            content\n            authorId\n            optionnal\n          }\n        }\n      }\n    `)\n    expect(() => document.validate(ast)).not.toThrow()\n  })","file":"include.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"allow deep include without another include","suites":["include validation"],"updatePoint":{"line":221,"column":50},"line":221,"code":"  test('allow deep include without another include', () => {\n    const ast = {\n      include: {\n        posts: { take: 20 },\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'query',\n      rootField: 'findManyUser',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    expect(() => document.validate(ast)).not.toThrow()\n  })","file":"include.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"handle scalar fields special","suites":["include validation"],"updatePoint":{"line":239,"column":36},"line":239,"code":"  test('handle scalar fields special', () => {\n    const ast = {\n      include: {\n        id: true,\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'query',\n      rootField: 'findManyPost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    try {\n      document.validate(ast, false)\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchInlineSnapshot(`\n\nInvalid \\`prisma.id()\\` invocation:\n\n{\n  include: {\n    id: true,\n    ~~\n?   author?: true,\n?   categories?: true,\n?   _count?: true\n  }\n}\n\n\nInvalid scalar field \\`id\\` for include statement on model Post. Available options are listed in green.\nNote, that include statements only accept relation fields.\n\n`)\n    }\n  })","file":"include.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"catch unknown field name","suites":["include validation"],"updatePoint":{"line":279,"column":32},"line":279,"code":"  test('catch unknown field name', () => {\n    const ast = {\n      include: {\n        mauthor: true,\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'query',\n      rootField: 'findManyPost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    try {\n      document.validate(ast, false)\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchInlineSnapshot(`\n\nInvalid \\`prisma.mauthor()\\` invocation:\n\n{\n  include: {\n    mauthor: true,\n    ~~~~~~~\n?   author?: true,\n?   categories?: true,\n?   _count?: true\n  }\n}\n\n\nUnknown field \\`mauthor\\` for include statement on model Post. Available options are listed in green. Did you mean \\`author\\`?\n\n`)\n    }\n  })","file":"include.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"allow include with a select","suites":["include validation"],"updatePoint":{"line":318,"column":35},"line":318,"code":"  test('allow include with a select', () => {\n    const ast = {\n      include: {\n        posts: {\n          take: 20,\n          select: {\n            id: true,\n          },\n        },\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'query',\n      rootField: 'findManyUser',\n    })\n\n    expect(String(document)).toMatchInlineSnapshot(`\n      query {\n        findManyUser {\n          id\n          email\n          name\n          json\n          countFloat\n          countInt1\n          countInt2\n          countInt3\n          countInt4\n          countInt5\n          countInt6\n          lastLoginAt\n          coinflips\n          posts(take: 20) {\n            id\n          }\n        }\n      }\n    `)\n    expect(() => document.validate(ast)).not.toThrow()\n  })","file":"include.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"allow include with a select with an include","suites":["include validation"],"updatePoint":{"line":362,"column":51},"line":362,"code":"  test('allow include with a select with an include', () => {\n    const ast = {\n      include: {\n        posts: {\n          take: 20,\n          select: {\n            id: true,\n            author: {\n              include: { posts: true },\n            },\n          },\n        },\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'query',\n      rootField: 'findManyUser',\n    })\n\n    expect(String(document)).toMatchInlineSnapshot(`\n      query {\n        findManyUser {\n          id\n          email\n          name\n          json\n          countFloat\n          countInt1\n          countInt2\n          countInt3\n          countInt4\n          countInt5\n          countInt6\n          lastLoginAt\n          coinflips\n          posts(take: 20) {\n            id\n            author {\n              id\n              email\n              name\n              json\n              countFloat\n              countInt1\n              countInt2\n              countInt3\n              countInt4\n              countInt5\n              countInt6\n              lastLoginAt\n              coinflips\n              posts {\n                id\n                createdAt\n                updatedAt\n                published\n                title\n                content\n                authorId\n                optionnal\n              }\n            }\n          }\n        }\n      }\n    `)\n    expect(() => document.validate(ast)).not.toThrow()\n  })","file":"include.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"missing-engine-native-binaryTarget: binary","suites":[],"updatePoint":{"line":7,"column":48},"line":7,"code":"test('missing-engine-native-binaryTarget: binary', async () => {\n  if (getClientEngineType() !== ClientEngineType.Binary) {\n    return\n  }\n\n  expect.assertions(1)\n  await generateTestClient()\n\n  const { PrismaClient } = require('./node_modules/@prisma/client')\n\n  const platform = await getPlatform()\n  let binaryPath =\n    getClientEngineType() === ClientEngineType.Library\n      ? path.join(__dirname, 'node_modules/.prisma/client', getNodeAPIName(platform, 'fs'))\n      : path.join(__dirname, 'node_modules/.prisma/client', `query-engine-${platform}`)\n\n  if (process.platform === 'win32') {\n    binaryPath += '.exe'\n  }\n\n  fs.unlinkSync(binaryPath)\n  const prisma = new PrismaClient({\n    log: [\n      {\n        emit: 'event',\n        level: 'query',\n      },\n    ],\n  })\n\n  await expect(async () => {\n    await prisma.user.findMany()\n  }).rejects.toThrowErrorMatchingInlineSnapshot(`\n\n          Invalid \\`prisma.user.findMany()\\` invocation in\n          /client/src/__tests__/integration/errors/missing-engine-native-binaryTarget/binary.test.ts:0:0\n\n            35 })\n            36 \n            37 await expect(async () => {\n          → 38   await prisma.user.findMany(\n            Query engine binary for current platform \"TEST_PLATFORM\" could not be found.\n          This probably happens, because you built Prisma Client on a different platform.\n          (Prisma Client looked in \"/client/src/__tests__/integration/errors/missing-engine-native-binaryTarget/node_modules/@prisma/client/runtime/query-engine-TEST_PLATFORM\")\n\n          Searched Locations:\n\n            /client/src/__tests__/integration/errors/missing-engine-native-binaryTarget/node_modules/.prisma/client\n            /client/src/__tests__/integration/errors/missing-engine-native-binaryTarget/node_modules/@prisma/client/runtime\n            /client/src/__tests__/integration/errors/missing-engine-native-binaryTarget/node_modules/@prisma/client\n            /client/src/__tests__/integration/errors/missing-engine-native-binaryTarget/node_modules/.prisma/client\n            /client/src/__tests__/integration/errors/missing-engine-native-binaryTarget\n            /tmp/prisma-engines\n            /client/src/__tests__/integration/errors/missing-engine-native-binaryTarget/node_modules/.prisma/client\n\n          You already added the platform \"native\" to the \"generator\" block\n          in the \"schema.prisma\" file as described in https://pris.ly/d/client-generator,\n          but something went wrong. That's suboptimal.\n\n          Please create an issue at TEST_GITHUB_LINK\n        `)\n})","file":"integration/errors/missing-engine-native-binaryTarget/binary.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"missing-engine-native-binaryTarget: library","suites":[],"updatePoint":{"line":7,"column":49},"line":7,"code":"test('missing-engine-native-binaryTarget: library', async () => {\n  if (getClientEngineType() !== ClientEngineType.Library) {\n    return\n  }\n\n  expect.assertions(1)\n  await generateTestClient()\n\n  const { PrismaClient } = require('./node_modules/@prisma/client')\n\n  const platform = await getPlatform()\n  const binaryPath =\n    getClientEngineType() === ClientEngineType.Library\n      ? path.join(__dirname, 'node_modules/.prisma/client', getNodeAPIName(platform, 'fs'))\n      : path.join(__dirname, 'node_modules/.prisma/client', `query-engine-${platform}`)\n  fs.unlinkSync(binaryPath)\n  const prisma = new PrismaClient({\n    log: [\n      {\n        emit: 'event',\n        level: 'query',\n      },\n    ],\n  })\n\n  await expect(async () => {\n    await prisma.user.findMany()\n  }).rejects.toThrowErrorMatchingInlineSnapshot(`\n\n          Invalid \\`prisma.user.findMany()\\` invocation in\n          /client/src/__tests__/integration/errors/missing-engine-native-binaryTarget/library.test.ts:0:0\n\n            30 })\n            31 \n            32 await expect(async () => {\n          → 33   await prisma.user.findMany(\n            Query engine library for current platform \"TEST_PLATFORM\" could not be found.\n          You incorrectly pinned it to TEST_PLATFORM\n\n          This probably happens, because you built Prisma Client on a different platform.\n          (Prisma Client looked in \"/client/src/__tests__/integration/errors/missing-engine-native-binaryTarget/node_modules/@prisma/client/runtime/libquery_engine-TEST_PLATFORM.LIBRARY_TYPE.node\")\n\n          Searched Locations:\n\n            /client/src/__tests__/integration/errors/missing-engine-native-binaryTarget/node_modules/.prisma/client\n            /client/src/__tests__/integration/errors/missing-engine-native-binaryTarget/node_modules/@prisma/client/runtime\n            /client/src/__tests__/integration/errors/missing-engine-native-binaryTarget/node_modules/@prisma/client\n            /client/src/__tests__/integration/errors/missing-engine-native-binaryTarget/node_modules/.prisma/client\n            /client/src/__tests__/integration/errors/missing-engine-native-binaryTarget\n            /tmp/prisma-engines\n            /client/src/__tests__/integration/errors/missing-engine-native-binaryTarget/node_modules/.prisma/client\n\n          You already added the platform \"native\" to the \"generator\" block\n          in the \"schema.prisma\" file as described in https://pris.ly/d/client-generator,\n          but something went wrong. That's suboptimal.\n\n          Please create an issue at TEST_GITHUB_LINK\n        `)\n})","file":"integration/errors/missing-engine-native-binaryTarget/library.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"missing-engine: binary","suites":[],"updatePoint":{"line":7,"column":28},"line":7,"code":"test('missing-engine: binary', async () => {\n  if (getClientEngineType() !== ClientEngineType.Binary) {\n    return\n  }\n\n  expect.assertions(1)\n  await generateTestClient()\n\n  const { PrismaClient } = require('./node_modules/@prisma/client')\n\n  const platform = await getPlatform()\n  let binaryPath =\n    getClientEngineType() === ClientEngineType.Library\n      ? path.join(__dirname, 'node_modules/.prisma/client', getNodeAPIName(platform, 'fs'))\n      : path.join(__dirname, 'node_modules/.prisma/client', `query-engine-${platform}`)\n\n  if (process.platform === 'win32') {\n    binaryPath += '.exe'\n  }\n\n  fs.unlinkSync(binaryPath)\n  const prisma = new PrismaClient({\n    log: [\n      {\n        emit: 'event',\n        level: 'query',\n      },\n    ],\n  })\n\n  await expect(async () => {\n    await prisma.user.findMany()\n  }).rejects.toThrowErrorMatchingInlineSnapshot(`\n\n          Invalid \\`prisma.user.findMany()\\` invocation in\n          /client/src/__tests__/integration/errors/missing-engine/binary.test.ts:0:0\n\n            35 })\n            36 \n            37 await expect(async () => {\n          → 38   await prisma.user.findMany(\n            Query engine binary for current platform \"TEST_PLATFORM\" could not be found.\n          This probably happens, because you built Prisma Client on a different platform.\n          (Prisma Client looked in \"/client/src/__tests__/integration/errors/missing-engine/node_modules/@prisma/client/runtime/query-engine-TEST_PLATFORM\")\n\n          Searched Locations:\n\n            /client/src/__tests__/integration/errors/missing-engine/node_modules/.prisma/client\n            /client/src/__tests__/integration/errors/missing-engine/node_modules/@prisma/client/runtime\n            /client/src/__tests__/integration/errors/missing-engine/node_modules/@prisma/client\n            /client/src/__tests__/integration/errors/missing-engine/node_modules/.prisma/client\n            /client/src/__tests__/integration/errors/missing-engine\n            /tmp/prisma-engines\n            /client/src/__tests__/integration/errors/missing-engine/node_modules/.prisma/client\n\n\n          To solve this problem, add the platform \"TEST_PLATFORM\" to the \"binaryTargets\" attribute in the \"generator\" block in the \"schema.prisma\" file:\n          generator client {\n            provider      = \"prisma-client-js\"\n            binaryTargets = [\"native\"]\n          }\n\n          Then run \"prisma generate\" for your changes to take effect.\n          Read more about deploying Prisma Client: https://pris.ly/d/client-generator\n        `)\n})","file":"integration/errors/missing-engine/binary.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"missing-engine: library","suites":[],"updatePoint":{"line":7,"column":29},"line":7,"code":"test('missing-engine: library', async () => {\n  if (getClientEngineType() !== ClientEngineType.Library) {\n    return\n  }\n\n  expect.assertions(1)\n  await generateTestClient()\n\n  const { PrismaClient } = require('./node_modules/@prisma/client')\n\n  const platform = await getPlatform()\n  const binaryPath =\n    getClientEngineType() === ClientEngineType.Library\n      ? path.join(__dirname, 'node_modules/.prisma/client', getNodeAPIName(platform, 'fs'))\n      : path.join(__dirname, 'node_modules/.prisma/client', `query-engine-${platform}`)\n  fs.unlinkSync(binaryPath)\n  const prisma = new PrismaClient({\n    log: [\n      {\n        emit: 'event',\n        level: 'query',\n      },\n    ],\n  })\n\n  await expect(async () => {\n    await prisma.user.findMany()\n  }).rejects.toThrowErrorMatchingInlineSnapshot(`\n\n          Invalid \\`prisma.user.findMany()\\` invocation in\n          /client/src/__tests__/integration/errors/missing-engine/library.test.ts:0:0\n\n            30 })\n            31 \n            32 await expect(async () => {\n          → 33   await prisma.user.findMany(\n            Query engine library for current platform \"TEST_PLATFORM\" could not be found.\n          You incorrectly pinned it to TEST_PLATFORM\n\n          This probably happens, because you built Prisma Client on a different platform.\n          (Prisma Client looked in \"/client/src/__tests__/integration/errors/missing-engine/node_modules/@prisma/client/runtime/libquery_engine-TEST_PLATFORM.LIBRARY_TYPE.node\")\n\n          Searched Locations:\n\n            /client/src/__tests__/integration/errors/missing-engine/node_modules/.prisma/client\n            /client/src/__tests__/integration/errors/missing-engine/node_modules/@prisma/client/runtime\n            /client/src/__tests__/integration/errors/missing-engine/node_modules/@prisma/client\n            /client/src/__tests__/integration/errors/missing-engine/node_modules/.prisma/client\n            /client/src/__tests__/integration/errors/missing-engine\n            /tmp/prisma-engines\n            /client/src/__tests__/integration/errors/missing-engine/node_modules/.prisma/client\n\n\n          To solve this problem, add the platform \"TEST_PLATFORM\" to the \"binaryTargets\" attribute in the \"generator\" block in the \"schema.prisma\" file:\n          generator client {\n            provider      = \"prisma-client-js\"\n            binaryTargets = [\"native\"]\n          }\n\n          Then run \"prisma generate\" for your changes to take effect.\n          Read more about deploying Prisma Client: https://pris.ly/d/client-generator\n        `)\n})","file":"integration/errors/missing-engine/library.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"dmmf-types","suites":[],"updatePoint":{"line":9,"column":16},"line":9,"code":"test('dmmf-types', async () => {\n  const datamodel = fs.readFileSync(path.join(__dirname, 'schema.prisma'), 'utf-8')\n  const dmmf = await getDMMF({\n    datamodel,\n  })\n  const dmmfFile = path.join(__dirname, 'generated-dmmf.ts')\n\n  fs.writeFileSync(\n    dmmfFile,\n    `import { DMMF } from '@prisma/generator-helper'\n\n  const dmmf: DMMF.Document = ${JSON.stringify(dmmf, null, 2)}`,\n  )\n\n  await expect(compileFile(dmmfFile)).resolves.not.toThrow()\n})","file":"integration/happy/exhaustive-schema/dmmf-types.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"should be able to create json","suites":[],"updatePoint":{"line":51,"column":37},"line":51,"code":"  test('should be able to create json', () => {\n    const document = makeDocument({\n      dmmf,\n      select: {\n        data: {\n          email: 'a@a.de',\n          json: {\n            hello: 'world',\n          },\n          jsonList: [{ hello: 'world' }],\n          name: 'Bob',\n        },\n      },\n      rootTypeName: 'mutation',\n      rootField: 'createOneUser',\n    })\n    document.validate(undefined, false, 'user', 'colorless')\n    expect(String(document)).toMatchSnapshot()\n  })","file":"json.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"should be able filter json","suites":[],"updatePoint":{"line":71,"column":34},"line":71,"code":"  test('should be able filter json', () => {\n    const document = makeDocument({\n      dmmf,\n      select: {\n        where: {\n          json: {\n            equals: {\n              hello: 'world',\n            },\n          },\n        },\n      },\n      rootTypeName: 'query',\n      rootField: 'findManyUser',\n    })\n    document.validate(undefined, false, 'user', 'colorless')\n    expect(String(document)).toMatchSnapshot()\n  })","file":"json.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"should be able filter json null","suites":[],"updatePoint":{"line":90,"column":39},"line":90,"code":"  test('should be able filter json null', () => {\n    const document = makeDocument({\n      dmmf,\n      select: {\n        where: {\n          json: {\n            equals: 'JsonNull',\n          },\n        },\n      },\n      rootTypeName: 'query',\n      rootField: 'findManyOptionalUser',\n    })\n    document.validate(undefined, false, 'user', 'colorless')\n    expect(String(document)).toMatchSnapshot()\n  })","file":"json.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"should be able filter json \"null\"","suites":[],"updatePoint":{"line":107,"column":41},"line":107,"code":"  test('should be able filter json \"null\"', () => {\n    const document = makeDocument({\n      dmmf,\n      select: {\n        where: {\n          json: {\n            equals: 'null',\n          },\n        },\n      },\n      rootTypeName: 'query',\n      rootField: 'findManyOptionalUser',\n    })\n    document.validate(undefined, false, 'user', 'colorless')\n    expect(String(document)).toMatchSnapshot()\n  })","file":"json.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"should error if equals is missing","suites":[],"updatePoint":{"line":124,"column":41},"line":124,"code":"  test('should error if equals is missing', () => {\n    const document = makeDocument({\n      dmmf,\n      select: {\n        where: {\n          json: {\n            hello: 'world',\n          },\n        },\n      },\n      rootTypeName: 'query',\n      rootField: 'findManyUser',\n    })\n    expect(() => document.validate(undefined, false, 'user', 'colorless')).toThrowErrorMatchingSnapshot()\n  })","file":"json.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"should be able to update json","suites":[],"updatePoint":{"line":140,"column":37},"line":140,"code":"  test('should be able to update json', () => {\n    function getTransformedDocument(select) {\n      const document = makeDocument({\n        dmmf,\n        select,\n        rootTypeName: 'mutation',\n        rootField: 'updateOneUser',\n      })\n      return String(transformDocument(document))\n    }\n\n    const transformedDocument = getTransformedDocument({\n      data: {\n        json: ['value1', 'value2'],\n        jsonList: ['value1', 'value2'],\n      },\n      where: {\n        id: 5,\n      },\n    })\n\n    expect(transformedDocument).toMatchInlineSnapshot(`\n      mutation {\n        updateOneUser(\n          data: {\n            json: \"[\\\\\"value1\\\\\",\\\\\"value2\\\\\"]\"\n            jsonList: [\"\\\\\"value1\\\\\"\",\"\\\\\"value2\\\\\"\"]\n          }\n          where: {\n            id: 5\n          }\n        ) {\n          id\n          name\n          email\n          json\n          jsonList\n        }\n      }\n    `)\n  })","file":"json.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"basic mergeBy","suites":[],"updatePoint":{"line":3,"column":19},"line":3,"code":"test('basic mergeBy', () => {\n  const arr1 = [\n    {\n      name: 'db',\n      url: 'file:old-url.db',\n    },\n  ]\n  const arr2 = [\n    {\n      name: 'db',\n      url: 'file:new-url.db',\n    },\n  ]\n  expect(mergeBy(arr1, arr2, (a) => a.name)).toMatchInlineSnapshot(`\n    Array [\n      Object {\n        name: db,\n        url: file:new-url.db,\n      },\n    ]\n  `)\n})","file":"mergeBy.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"mergeBy should merge last item","suites":[],"updatePoint":{"line":26,"column":36},"line":26,"code":"test('mergeBy should merge last item', () => {\n  const arr1 = [\n    {\n      name: 'db',\n      url: 'file:old-url.db',\n    },\n  ]\n  const arr2 = [\n    {\n      name: 'db',\n      url: 'file:new-url.db',\n    },\n    {\n      name: 'db',\n      url: 'file:new-url2.db',\n    },\n  ]\n  expect(mergeBy(arr1, arr2, (a) => a.name)).toMatchInlineSnapshot(`\n    Array [\n      Object {\n        name: db,\n        url: file:new-url2.db,\n      },\n    ]\n  `)\n})","file":"mergeBy.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"OR posts some id in","suites":["minimal where transformation"],"updatePoint":{"line":13,"column":27},"line":13,"code":"  test('OR posts some id in', () => {\n    const transformedDocument = getTransformedDocument({\n      where: {\n        OR: [\n          {\n            posts: {\n              some: {\n                id: {\n                  in: ['test'],\n                },\n              },\n            },\n          },\n        ],\n      },\n    })\n\n    expect(transformedDocument).toMatchInlineSnapshot(`\n      query {\n        findManyUser(where: {\n          OR: [\n            {\n              posts: {\n                some: {\n                  id: {\n                    in: [\"test\"]\n                  }\n                }\n              }\n            }\n          ]\n        }) {\n          id\n          email\n          name\n          json\n          countFloat\n          countInt1\n          countInt2\n          countInt3\n          countInt4\n          countInt5\n          countInt6\n          lastLoginAt\n          coinflips\n        }\n      }\n    `)\n  })","file":"minimalWhereTransformation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"OR name startsWith","suites":["minimal where transformation"],"updatePoint":{"line":63,"column":26},"line":63,"code":"  test('OR name startsWith', () => {\n    const transformedDocument = getTransformedDocument({\n      where: {\n        OR: [\n          {\n            name: {\n              startsWith: 'x',\n            },\n          },\n        ],\n      },\n    })\n\n    expect(transformedDocument).toMatchInlineSnapshot(`\n      query {\n        findManyUser(where: {\n          OR: [\n            {\n              name: {\n                startsWith: \"x\"\n              }\n            }\n          ]\n        }) {\n          id\n          email\n          name\n          json\n          countFloat\n          countInt1\n          countInt2\n          countInt3\n          countInt4\n          countInt5\n          countInt6\n          lastLoginAt\n          coinflips\n        }\n      }\n    `)\n  })","file":"minimalWhereTransformation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"OR name endsWith","suites":["minimal where transformation"],"updatePoint":{"line":105,"column":24},"line":105,"code":"  test('OR name endsWith', () => {\n    const transformedDocument = getTransformedDocument({\n      where: {\n        OR: [\n          {\n            name: {\n              endsWith: 'x',\n            },\n          },\n        ],\n      },\n    })\n\n    expect(transformedDocument).toMatchInlineSnapshot(`\n      query {\n        findManyUser(where: {\n          OR: [\n            {\n              name: {\n                endsWith: \"x\"\n              }\n            }\n          ]\n        }) {\n          id\n          email\n          name\n          json\n          countFloat\n          countInt1\n          countInt2\n          countInt3\n          countInt4\n          countInt5\n          countInt6\n          lastLoginAt\n          coinflips\n        }\n      }\n    `)\n  })","file":"minimalWhereTransformation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"implicit many-to-many relation: contains","suites":["minimal where transformation"],"updatePoint":{"line":147,"column":48},"line":147,"code":"  test('implicit many-to-many relation: contains', () => {\n    const transformedDocument = getTransformedDocument({\n      where: {\n        posts: {\n          some: {\n            title: {\n              contains: 'mytitle',\n            },\n          },\n        },\n      },\n    })\n\n    expect(transformedDocument).toMatchInlineSnapshot(`\n      query {\n        findManyUser(where: {\n          posts: {\n            some: {\n              title: {\n                contains: \"mytitle\"\n              }\n            }\n          }\n        }) {\n          id\n          email\n          name\n          json\n          countFloat\n          countInt1\n          countInt2\n          countInt3\n          countInt4\n          countInt5\n          countInt6\n          lastLoginAt\n          coinflips\n        }\n      }\n    `)\n  })","file":"minimalWhereTransformation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"implicit many-to-many relation: select date equals (implicit)","suites":["minimal where transformation"],"updatePoint":{"line":189,"column":69},"line":189,"code":"  test('implicit many-to-many relation: select date equals (implicit)', () => {\n    const transformedDocument = getTransformedDocument({\n      select: {\n        posts: {\n          where: {\n            OR: [\n              {\n                createdAt: '2020-08-19T10:02:43.353Z',\n              },\n            ],\n          },\n        },\n      },\n    })\n\n    expect(transformedDocument).toMatchInlineSnapshot(`\n      query {\n        findManyUser {\n          posts(where: {\n            OR: [\n              {\n                createdAt: \"2020-08-19T10:02:43.353Z\"\n              }\n            ]\n          }) {\n            id\n            createdAt\n            updatedAt\n            published\n            title\n            content\n            authorId\n            optionnal\n          }\n        }\n      }\n    `)\n  })","file":"minimalWhereTransformation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"implicit many-to-many relation: select date equals (explicit)","suites":["minimal where transformation"],"updatePoint":{"line":228,"column":69},"line":228,"code":"  test('implicit many-to-many relation: select date equals (explicit)', () => {\n    const transformedDocument = getTransformedDocument({\n      select: {\n        posts: {\n          where: {\n            OR: [\n              {\n                createdAt: { equals: '2020-08-19T10:02:43.353Z' },\n              },\n            ],\n          },\n        },\n      },\n    })\n\n    expect(transformedDocument).toMatchInlineSnapshot(`\n      query {\n        findManyUser {\n          posts(where: {\n            OR: [\n              {\n                createdAt: {\n                  equals: \"2020-08-19T10:02:43.353Z\"\n                }\n              }\n            ]\n          }) {\n            id\n            createdAt\n            updatedAt\n            published\n            title\n            content\n            authorId\n            optionnal\n          }\n        }\n      }\n    `)\n  })","file":"minimalWhereTransformation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"implicit many-to-many relation: where null","suites":["minimal where transformation"],"updatePoint":{"line":269,"column":50},"line":269,"code":"  test('implicit many-to-many relation: where null', () => {\n    const transformedDocument = getTransformedDocument({\n      select: {\n        posts: {\n          where: {\n            content: null,\n          },\n        },\n      },\n    })\n\n    expect(transformedDocument).toMatchInlineSnapshot(`\n      query {\n        findManyUser {\n          posts(where: {\n            content: null\n          }) {\n            id\n            createdAt\n            updatedAt\n            published\n            title\n            content\n            authorId\n            optionnal\n          }\n        }\n      }\n    `)\n  })","file":"minimalWhereTransformation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"where null","suites":["minimal where transformation"],"updatePoint":{"line":300,"column":18},"line":300,"code":"  test('where null', () => {\n    const transformedDocument = getTransformedDocument({\n      where: {\n        name: null,\n      },\n    })\n\n    expect(transformedDocument).toMatchInlineSnapshot(`\n      query {\n        findManyUser(where: {\n          name: null\n        }) {\n          id\n          email\n          name\n          json\n          countFloat\n          countInt1\n          countInt2\n          countInt3\n          countInt4\n          countInt5\n          countInt6\n          lastLoginAt\n          coinflips\n        }\n      }\n    `)\n  })","file":"minimalWhereTransformation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"one-to-one realtion where null","suites":["minimal where transformation"],"updatePoint":{"line":330,"column":38},"line":330,"code":"  test('one-to-one realtion where null', () => {\n    const transformedDocument = getTransformedDocument({\n      where: {\n        profile: {\n          bio: { not: null },\n        },\n      },\n    })\n\n    expect(transformedDocument).toMatchInlineSnapshot(`\n      query {\n        findManyUser(where: {\n          profile: {\n            bio: {\n              not: null\n            }\n          }\n        }) {\n          id\n          email\n          name\n          json\n          countFloat\n          countInt1\n          countInt2\n          countInt3\n          countInt4\n          countInt5\n          countInt6\n          lastLoginAt\n          coinflips\n        }\n      }\n    `)\n  })","file":"minimalWhereTransformation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"findUnique","suites":["no args"],"updatePoint":{"line":11,"column":18},"line":11,"code":"  test('findUnique', () => {\n    const document = makeDocument({\n      dmmf,\n      select: undefined,\n      rootTypeName: 'query',\n      rootField: 'findUniqueUser',\n    })\n    expect(() => document.validate(undefined, false, 'user', 'colorless')).toThrowErrorMatchingSnapshot()\n  })","file":"noArgs.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"findMany","suites":["no args"],"updatePoint":{"line":21,"column":16},"line":21,"code":"  test('findMany', () => {\n    const document = makeDocument({\n      dmmf,\n      select: undefined,\n      rootTypeName: 'query',\n      rootField: 'findManyUser',\n    })\n    document.validate(undefined, false, 'user', 'colorless')\n    expect(String(document)).toMatchInlineSnapshot(`\n      query {\n        findManyUser {\n          id\n          name\n          email\n          personaId\n        }\n      }\n    `)\n  })","file":"noArgs.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"findMany with filter","suites":["no args"],"updatePoint":{"line":40,"column":28},"line":40,"code":"  test('findMany with filter', () => {\n    const select = {\n      where: {\n        likedArticles: null,\n      },\n    }\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'query',\n      rootField: 'findManyUser',\n    })\n    expect(() => document.validate(select, false, 'user', 'colorless')).toThrowErrorMatchingSnapshot()\n    expect(String(document)).toMatchInlineSnapshot(`\n      query {\n        findManyUser(where: {\n          likedArticles: null\n        }) {\n          id\n          name\n          email\n          personaId\n        }\n      }\n    `)\n  })","file":"noArgs.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"createOne","suites":["no args"],"updatePoint":{"line":66,"column":17},"line":66,"code":"  test('createOne', () => {\n    const document = makeDocument({\n      dmmf,\n      select: undefined,\n      rootTypeName: 'mutation',\n      rootField: 'createOneUser',\n    })\n    expect(() => document.validate(undefined, false, 'user', 'colorless')).toThrowErrorMatchingSnapshot()\n  })","file":"noArgs.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"deleteMany","suites":["no args"],"updatePoint":{"line":75,"column":18},"line":75,"code":"  test('deleteMany', () => {\n    const document = makeDocument({\n      dmmf,\n      select: undefined,\n      rootTypeName: 'mutation',\n      rootField: 'deleteManyUser',\n    })\n    document.validate(undefined, false, 'user', 'colorless')\n    expect(String(document)).toMatchInlineSnapshot(`\n      mutation {\n        deleteManyUser {\n          count\n        }\n      }\n    `)\n  })","file":"noArgs.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"deleteOne","suites":["no args"],"updatePoint":{"line":91,"column":17},"line":91,"code":"  test('deleteOne', () => {\n    const document = makeDocument({\n      dmmf,\n      select: undefined,\n      rootTypeName: 'mutation',\n      rootField: 'deleteOneUser',\n    })\n    expect(() => document.validate(undefined, false, 'user', 'colorless')).toThrowErrorMatchingSnapshot()\n  })","file":"noArgs.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"updateMany","suites":["no args"],"updatePoint":{"line":100,"column":18},"line":100,"code":"  test('updateMany', () => {\n    const document = makeDocument({\n      dmmf,\n      select: undefined,\n      rootTypeName: 'mutation',\n      rootField: 'updateManyUser',\n    })\n    expect(() => document.validate(undefined, false, 'user', 'colorless')).toThrowErrorMatchingSnapshot()\n  })","file":"noArgs.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"upsertOne","suites":["no args"],"updatePoint":{"line":109,"column":17},"line":109,"code":"  test('upsertOne', () => {\n    const document = makeDocument({\n      dmmf,\n      select: undefined,\n      rootTypeName: 'mutation',\n      rootField: 'upsertOneUser',\n    })\n    expect(() => document.validate(undefined, false, 'user', 'colorless')).toThrowErrorMatchingSnapshot()\n  })","file":"noArgs.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"nested create","suites":["no args"],"updatePoint":{"line":118,"column":21},"line":118,"code":"  test('nested create', () => {\n    const document = makeDocument({\n      dmmf,\n      select: {\n        data: {\n          id: 5,\n          name: 'Harshit',\n          email: 'a@a.de',\n          likedArticles: {\n            connect: null,\n          },\n          persona: {\n            create: {\n              id: 123,\n              isDeveloper: true,\n            },\n          },\n        },\n      },\n      rootTypeName: 'mutation',\n      rootField: 'createOneUser',\n    })\n    expect(() => document.validate(undefined, false, 'user', 'colorless')).toThrowErrorMatchingSnapshot()\n  })","file":"noArgs.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"null query","suites":["optional to one relation"],"updatePoint":{"line":13,"column":18},"line":13,"code":"  test('null query', () => {\n    const select = {\n      where: {\n        author: null,\n      },\n    }\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'query',\n      rootField: 'findManyPost',\n    })\n\n    expect(String(transformDocument(document))).toMatchInlineSnapshot(`\n      query {\n        findManyPost(where: {\n          author: null\n        }) {\n          id\n          createdAt\n          updatedAt\n          published\n          title\n          content\n          authorId\n          optionnal\n        }\n      }\n    `)\n  })","file":"optionalRelation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"invalid or query","suites":["at least one validation"],"updatePoint":{"line":12,"column":24},"line":12,"code":"  test('invalid or query', () => {\n    const select = {\n      where: {\n        OR: {\n          email: {},\n        },\n      },\n    }\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'query',\n      rootField: 'findManyUser',\n    })\n    expect(String(document)).toMatchInlineSnapshot(`\n      query {\n        findManyUser(where: {\n          OR: [\n            {\n              email: {\n\n              }\n            }\n          ]\n        }) {\n          id\n          name\n          email\n          status\n          nicknames\n          permissions\n          favoriteTree\n          locationId\n          someFloats\n        }\n      }\n    `)\n    try {\n      document.validate(select, false, 'users')\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchInlineSnapshot(`\n\n                                        Invalid \\`prisma.users()\\` invocation:\n\n                                        {\n                                          where: {\n                                            OR: {\n                                              email: {}\n                                            }\n                                            ~~~~~~~~~~~\n                                          }\n                                        }\n\n                                        Argument OR: Got invalid value \n                                        {\n                                          email: {}\n                                        }\n                                        on prisma.findManyUser. Provided Json, expected List<UserWhereInput>:\n                                        type UserWhereInput {\n                                          AND?: UserWhereInput\n                                          OR?: UserWhereInput\n                                          NOT?: UserWhereInput\n                                          id?: StringFilter | String\n                                          name?: StringFilter | String\n                                          email?: StringFilter | String\n                                          status?: StringFilter | String\n                                          nicknames?: StringNullableListFilter\n                                          permissions?: EnumPermissionNullableListFilter\n                                          favoriteTree?: EnumTreeFilter | Tree\n                                          locationId?: IntFilter | Int\n                                          location?: LocationRelationFilter | LocationWhereInput\n                                          posts?: PostListRelationFilter\n                                          someFloats?: FloatNullableListFilter\n                                        }\n\n\n                              `)\n    }\n  })","file":"or.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"valid or query","suites":["at least one validation"],"updatePoint":{"line":91,"column":22},"line":91,"code":"  test('valid or query', () => {\n    const select = {\n      where: {\n        OR: [\n          {\n            email: '',\n          },\n        ],\n      },\n    }\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'query',\n      rootField: 'findManyUser',\n    })\n    expect(String(document)).toMatchSnapshot()\n    expect(() => document.validate(select, false, 'users')).not.toThrow()\n  })","file":"or.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"transform correctly","suites":["where transformation"],"updatePoint":{"line":12,"column":27},"line":12,"code":"  test('transform correctly', () => {\n    const select = {\n      orderBy: {\n        email: 'asc',\n      },\n    }\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'query',\n      rootField: 'findManyUser',\n    })\n    document.validate(select, false)\n    expect(String(document)).toMatchInlineSnapshot(`\n      query {\n        findManyUser(orderBy: [\n          {\n            email: asc\n          }\n        ]) {\n          id\n          name\n          email\n          status\n          nicknames\n          permissions\n          favoriteTree\n          locationId\n          someFloats\n        }\n      }\n    `)\n    expect(String(transformDocument(document))).toMatchInlineSnapshot(`\n      query {\n        findManyUser(orderBy: [\n          {\n            email: asc\n          }\n        ]) {\n          id\n          name\n          email\n          status\n          nicknames\n          permissions\n          favoriteTree\n          locationId\n          someFloats\n        }\n      }\n    `)\n  })","file":"orderTransformation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"throw when 2 order by args provided","suites":["where transformation"],"updatePoint":{"line":65,"column":43},"line":65,"code":"  test('throw when 2 order by args provided', () => {\n    const select = {\n      orderBy: {\n        email: 'asc',\n        id: 'asc',\n      },\n    }\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'query',\n      rootField: 'findManyUser',\n    })\n    expect(String(document)).toMatchInlineSnapshot(`\n      query {\n        findManyUser(orderBy: [\n          {\n            email: asc\n            id: asc\n          }\n        ]) {\n          id\n          name\n          email\n          status\n          nicknames\n          permissions\n          favoriteTree\n          locationId\n          someFloats\n        }\n      }\n    `)\n    expect(String(transformDocument(document))).toMatchInlineSnapshot(`\n      query {\n        findManyUser(orderBy: [\n          {\n            email: asc\n            id: asc\n          }\n        ]) {\n          id\n          name\n          email\n          status\n          nicknames\n          permissions\n          favoriteTree\n          locationId\n          someFloats\n        }\n      }\n    `)\n    try {\n      document.validate(select, false, 'users')\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchInlineSnapshot(`\n\nInvalid \\`prisma.users()\\` invocation:\n\n{\n  orderBy: {\n    email: 'asc',\n    id: 'asc'\n  }\n  ~~~~~~~~~~~~~~~\n}\n\nArgument orderBy of type UserOrderByWithRelationInput needs exactly one argument, but you provided email and id. Please choose one. Available args: \ntype UserOrderByWithRelationInput {\n  id?: SortOrder\n  name?: SortOrder\n  email?: SortOrder\n  status?: SortOrder\n  nicknames?: SortOrder\n  permissions?: SortOrder\n  favoriteTree?: SortOrder\n  locationId?: SortOrder\n  location?: LocationOrderByWithRelationInput\n  posts?: PostOrderByRelationAggregateInput\n  someFloats?: SortOrder\n}\n\n\n`)\n    }\n  })","file":"orderTransformation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"DO NOT ignore order null","suites":["where transformation"],"updatePoint":{"line":164,"column":32},"line":164,"code":"  test('DO NOT ignore order null', () => {\n    const select = {\n      orderBy: null,\n    }\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'query',\n      rootField: 'findManyUser',\n    })\n    expect(String(transformDocument(document))).toMatchInlineSnapshot(`\n      query {\n        findManyUser(orderBy: null) {\n          id\n          name\n          email\n          status\n          nicknames\n          permissions\n          favoriteTree\n          locationId\n          someFloats\n        }\n      }\n    `)\n  })","file":"orderTransformation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"ignore order by id null","suites":["where transformation"],"updatePoint":{"line":191,"column":31},"line":191,"code":"  test('ignore order by id null', () => {\n    const select = {\n      orderBy: { id: null },\n    }\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'query',\n      rootField: 'findManyUser',\n    })\n    expect(String(transformDocument(document))).toMatchInlineSnapshot(`\n      query {\n        findManyUser(orderBy: {\n          id: null\n        }) {\n          id\n          name\n          email\n          status\n          nicknames\n          permissions\n          favoriteTree\n          locationId\n          someFloats\n        }\n      }\n    `)\n  })","file":"orderTransformation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"where OR not null","suites":["minimal where transformation"],"updatePoint":{"line":13,"column":25},"line":13,"code":"  test('where OR not null', () => {\n    const transformedDocument = getDocument({\n      where: {\n        OR: [\n          {\n            date: { not: null },\n          },\n        ],\n      },\n    })\n\n    expect(transformedDocument).toMatchInlineSnapshot(`\n      query {\n        findManySale(where: {\n          OR: [\n            {\n              date: {\n                not: null\n              }\n            }\n          ]\n        }) {\n          id\n          date\n        }\n      }\n    `)\n  })","file":"relationWhereORNotNullTransformation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"transform correctly","suites":["relation where transformation"],"updatePoint":{"line":13,"column":27},"line":13,"code":"  test('transform correctly', () => {\n    const select = {\n      where: {\n        Albums: {\n          some: {\n            Tracks: {\n              some: {\n                AND: {\n                  UnitPrice: 5,\n                  Playlists: {\n                    some: {\n                      Tracks: {\n                        some: {\n                          Name: '',\n                          Genre: {\n                            id: 5,\n                          },\n                        },\n                      },\n                    },\n                  },\n                },\n              },\n            },\n          },\n        },\n      },\n    }\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'query',\n      rootField: 'findManyArtist',\n    })\n\n    expect(() => document.validate(select, false, 'users')).toThrowErrorMatchingSnapshot()\n  })","file":"relationWhereTransformation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"throw correctly for incorrect deep scalar","suites":["relation where transformation"],"updatePoint":{"line":51,"column":49},"line":51,"code":"  test('throw correctly for incorrect deep scalar', () => {\n    const select = {\n      where: {\n        Albums: {\n          some: {\n            Tracks: {\n              some: {\n                AND: {\n                  UnitPrice: 5,\n                  Playlists: {\n                    some: {\n                      Tracks: {\n                        some: {\n                          Name: '',\n                          Genre: {\n                            id: '5',\n                          },\n                        },\n                      },\n                    },\n                  },\n                },\n              },\n            },\n          },\n        },\n      },\n    }\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'query',\n      rootField: 'findManyArtist',\n    })\n    expect(() => document.validate(select, false, 'users')).toThrowErrorMatchingSnapshot()\n  })","file":"relationWhereTransformation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"throw correctly for deep at least one error","suites":["relation where transformation"],"updatePoint":{"line":87,"column":51},"line":87,"code":"  test('throw correctly for deep at least one error', () => {\n    const select = {\n      where: {\n        Albums: {\n          some: {\n            Tracks: {\n              some: {\n                AND: {\n                  UnitPrice: 5,\n                  Playlists: {\n                    some: {\n                      Tracks: {\n                        some: {\n                          Name: '',\n                          Genre: {},\n                        },\n                      },\n                    },\n                  },\n                },\n              },\n            },\n          },\n        },\n      },\n    }\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'query',\n      rootField: 'findManyArtist',\n    })\n    expect(() => document.validate(select, false, 'artists')).toThrowErrorMatchingSnapshot()\n  })","file":"relationWhereTransformation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"absolutizeRelativePath","suites":[],"updatePoint":{"line":8,"column":28},"line":8,"code":"test('absolutizeRelativePath', () => {\n  expect(absolutizeRelativePath('file:db.db', cwd, outputDir)).toMatchInlineSnapshot(`../../../../prisma/db.db`)\n  expect(absolutizeRelativePath('file:/db.db', cwd, outputDir)).toMatchInlineSnapshot(`../../../../../../../db.db`)\n  expect(absolutizeRelativePath('file:../db.db', cwd, outputDir)).toMatchInlineSnapshot(`../../../../db.db`)\n  expect(absolutizeRelativePath('file:./db.db', cwd, outputDir)).toMatchInlineSnapshot(`../../../../prisma/db.db`)\n\n  expect(absolutizeRelativePath('file:asd/another/dir/db.db', cwd, outputDir)).toMatchInlineSnapshot(\n    `../../../../prisma/asd/another/dir/db.db`,\n  )\n  expect(absolutizeRelativePath('file:/some/random/dir/db.db', cwd, outputDir)).toMatchInlineSnapshot(\n    `../../../../../../../some/random/dir/db.db`,\n  )\n  expect(\n    absolutizeRelativePath('file:/Users/tim/project/node_modules/@prisma/client/runtime', cwd, outputDir),\n  ).toMatchInlineSnapshot(``)\n  expect(absolutizeRelativePath('file:../another-dir/db.db', cwd, outputDir)).toMatchInlineSnapshot(\n    `../../../../another-dir/db.db`,\n  )\n  expect(absolutizeRelativePath('file:./some/dir/db.db', cwd, outputDir)).toMatchInlineSnapshot(\n    `../../../../prisma/some/dir/db.db`,\n  )\n})","file":"resolveDatasources.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"serializeDatasources","suites":[],"updatePoint":{"line":74,"column":26},"line":74,"code":"test('serializeDatasources', () => {\n  expect(serializeDatasources(datasources.map(datasourceToDatasourceOverwrite))).toMatchInlineSnapshot(`\n    [\n      {\n        \"name\": \"db\",\n        \"url\": \"file:db.db\"\n      },\n      {\n        \"name\": \"db2\",\n        \"url\": \"file:./some-dir/db.db\"\n      },\n      {\n        \"name\": \"db3\",\n        \"url\": \"mysql:localhost\"\n      },\n      {\n        \"name\": \"db4\",\n        \"url\": \"postgresql://\"\n      }\n    ]\n  `)\n})","file":"resolveDatasources.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"allow providing Int and Float scalar list in set","suites":["scalar where transformation"],"updatePoint":{"line":13,"column":56},"line":13,"code":"  test('allow providing Int and Float scalar list in set', () => {\n    const select = {\n      data: {\n        name: 'Name',\n        email: 'hans@hans.de',\n        status: '',\n        favoriteTree: 'OAK',\n        location: {\n          create: {\n            city: 'Berlin',\n            id: 5,\n          },\n        },\n        someFloats: {\n          set: [1, 1.2],\n        },\n      },\n    }\n\n    const document = transformDocument(\n      makeDocument({\n        dmmf,\n        select,\n        rootTypeName: 'mutation',\n        rootField: 'createOneUser',\n      }),\n    )\n\n    expect(String(document)).toMatchInlineSnapshot(`\n      mutation {\n        createOneUser(data: {\n          name: \"Name\"\n          email: \"hans@hans.de\"\n          status: \"\"\n          favoriteTree: OAK\n          location: {\n            create: {\n              city: \"Berlin\"\n              id: 5\n            }\n          }\n          someFloats: {\n            set: [1, 1.2]\n          }\n        }) {\n          id\n          name\n          email\n          status\n          nicknames\n          permissions\n          favoriteTree\n          locationId\n          someFloats\n        }\n      }\n    `)\n\n    expect(() => document.validate(select, false, 'tests')).not.toThrow()\n  })","file":"scalarListCreate.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"allow providing Int and Float scalar list without set","suites":["scalar where transformation"],"updatePoint":{"line":74,"column":61},"line":74,"code":"  test('allow providing Int and Float scalar list without set', () => {\n    const select = {\n      data: {\n        name: 'Name',\n        email: 'hans@hans.de',\n        status: '',\n        favoriteTree: 'OAK',\n        location: {\n          create: {\n            city: 'Berlin',\n            id: 5,\n          },\n        },\n        someFloats: [1, 1.2],\n      },\n    }\n\n    const document = transformDocument(\n      makeDocument({\n        dmmf,\n        select,\n        rootTypeName: 'mutation',\n        rootField: 'createOneUser',\n      }),\n    )\n\n    expect(String(document)).toMatchInlineSnapshot(`\n      mutation {\n        createOneUser(data: {\n          name: \"Name\"\n          email: \"hans@hans.de\"\n          status: \"\"\n          favoriteTree: OAK\n          location: {\n            create: {\n              city: \"Berlin\"\n              id: 5\n            }\n          }\n          someFloats: [1, 1.2]\n        }) {\n          id\n          name\n          email\n          status\n          nicknames\n          permissions\n          favoriteTree\n          locationId\n          someFloats\n        }\n      }\n    `)\n\n    expect(() => document.validate(select, false, 'tests')).not.toThrow()\n  })","file":"scalarListCreate.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"transform correctly","suites":["scalar where transformation"],"updatePoint":{"line":14,"column":27},"line":14,"code":"  test('transform correctly', () => {\n    const select = {\n      where: {\n        AND: [\n          {\n            email: {\n              equals: 'a@a.de',\n              gt: '0',\n            },\n            AND: [\n              {\n                name: {\n                  equals: '5',\n                  not: '7',\n                },\n                OR: [\n                  {\n                    id: {\n                      not: '8',\n                      notIn: ['7'],\n                    },\n                  },\n                  {\n                    id: {\n                      not: '9',\n                    },\n                  },\n                ],\n              },\n            ],\n          },\n          {\n            id: {\n              equals: '1',\n              gt: '0',\n            },\n          },\n        ],\n      },\n    }\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'query',\n      rootField: 'findManyUser',\n    })\n    expect(String(document)).toMatchInlineSnapshot(`\n      query {\n        findManyUser(where: {\n          AND: [\n            {\n              email: {\n                equals: \"a@a.de\"\n                gt: \"0\"\n              }\n              AND: [\n                {\n                  name: {\n                    equals: \"5\"\n                    not: \"7\"\n                  }\n                  OR: [\n                    {\n                      id: {\n                        not: \"8\"\n                        notIn: [\"7\"]\n                      }\n                    },\n                    {\n                      id: {\n                        not: \"9\"\n                      }\n                    }\n                  ]\n                }\n              ]\n            },\n            {\n              id: {\n                equals: \"1\"\n                gt: \"0\"\n              }\n            }\n          ]\n        }) {\n          id\n          name\n          email\n          status\n          nicknames\n          permissions\n          favoriteTree\n          locationId\n          someFloats\n        }\n      }\n    `)\n    expect(String(transformDocument(document))).toMatchInlineSnapshot(`\n      query {\n        findManyUser(where: {\n          AND: [\n            {\n              email: {\n                equals: \"a@a.de\"\n                gt: \"0\"\n              }\n              AND: [\n                {\n                  name: {\n                    equals: \"5\"\n                    not: \"7\"\n                  }\n                  OR: [\n                    {\n                      id: {\n                        not: \"8\"\n                        notIn: [\"7\"]\n                      }\n                    },\n                    {\n                      id: {\n                        not: \"9\"\n                      }\n                    }\n                  ]\n                }\n              ]\n            },\n            {\n              id: {\n                equals: \"1\"\n                gt: \"0\"\n              }\n            }\n          ]\n        }) {\n          id\n          name\n          email\n          status\n          nicknames\n          permissions\n          favoriteTree\n          locationId\n          someFloats\n        }\n      }\n    `)\n  })","file":"scalarWhereTransformation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"MODELScalarWhereInput","suites":["scalar where transformation"],"updatePoint":{"line":164,"column":29},"line":164,"code":"  test('MODELScalarWhereInput', () => {\n    const select = {\n      where: {\n        AND: [\n          {\n            title: {\n              equals: 'a@a.de',\n              gt: '0',\n            },\n            AND: [\n              {\n                title: {\n                  equals: '5',\n                  not: '7',\n                },\n                OR: [\n                  {\n                    id: {\n                      not: '8',\n                    },\n                  },\n                  {\n                    id: {\n                      not: '9',\n                    },\n                  },\n                ],\n              },\n            ],\n          },\n          {\n            id: {\n              equals: '1',\n              gt: '0',\n            },\n          },\n        ],\n      },\n      data: {},\n    }\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'mutation',\n      rootField: 'updateManyPost',\n    })\n\n    expect(() => document.validate(select)).toThrowErrorMatchingInlineSnapshot(`\n\n      Invalid \\`prisma.updateManyPost()\\` invocation:\n\n      {\n        where: {\n          AND: [\n            {\n              title: {\n              ~~~~~\n                equals: 'a@a.de',\n                gt: '0'\n              },\n              AND: [\n                {\n                  title: {\n                  ~~~~~\n                    equals: '5',\n                    not: '7'\n                  },\n                  OR: [\n                    {\n                      id: {\n                        not: '8'\n                      }\n                    },\n                    {\n                      id: {\n                        not: '9'\n                      }\n                    }\n                  ]\n                }\n              ]\n            },\n            {\n              id: {\n                equals: '1',\n                gt: '0'\n              }\n            }\n          ]\n        },\n        data: {}\n      }\n\n      Unknown arg \\`title\\` in where.AND.0.title for type PostWhereInput. Did you mean \\`id\\`? Available args:\n      type PostWhereInput {\n        AND?: PostWhereInput | List<PostWhereInput>\n        OR?: List<PostWhereInput>\n        NOT?: PostWhereInput | List<PostWhereInput>\n        id?: StringFilter | String\n        name?: StringFilter | String\n        email?: StringFilter | String\n        createdAt?: DateTimeFilter | DateTime\n        updatedAt?: DateTimeFilter | DateTime\n        userId?: StringFilter | String\n        user?: UserRelationFilter | UserWhereInput\n      }\n      Unknown arg \\`title\\` in where.AND.0.AND.0.title for type PostWhereInput. Did you mean \\`id\\`? Available args:\n      type PostWhereInput {\n        AND?: PostWhereInput | List<PostWhereInput>\n        OR?: List<PostWhereInput>\n        NOT?: PostWhereInput | List<PostWhereInput>\n        id?: StringFilter | String\n        name?: StringFilter | String\n        email?: StringFilter | String\n        createdAt?: DateTimeFilter | DateTime\n        updatedAt?: DateTimeFilter | DateTime\n        userId?: StringFilter | String\n        user?: UserRelationFilter | UserWhereInput\n      }\n\n\n    `)\n\n    expect(String(transformDocument(document))).toMatchInlineSnapshot(`\n      mutation {\n        updateManyPost(\n          where: {\n            AND: [\n              {\n                title: {\n                  \"equals\": \"a@a.de\",\n                  \"gt\": \"0\"\n                }\n                AND: [\n                  {\n                    title: {\n                      \"equals\": \"5\",\n                      \"not\": \"7\"\n                    }\n                    OR: [\n                      {\n                        id: {\n                          not: \"8\"\n                        }\n                      },\n                      {\n                        id: {\n                          not: \"9\"\n                        }\n                      }\n                    ]\n                  }\n                ]\n              },\n              {\n                id: {\n                  equals: \"1\"\n                  gt: \"0\"\n                }\n              }\n            ]\n          }\n          data: {\n\n          }\n        ) {\n          count\n        }\n      }\n    `)\n  })","file":"scalarWhereTransformation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"validate uuid scalar filter correctly","suites":["scalar where transformation"],"updatePoint":{"line":336,"column":45},"line":336,"code":"  test('validate uuid scalar filter correctly', () => {\n    const select = {\n      where: {\n        id: '806c902c-eab3-4e6e-ba4a-99c135389118',\n      },\n    }\n    const document = transformDocument(\n      makeDocument({\n        dmmf,\n        select,\n        rootTypeName: 'query',\n        rootField: 'findManyTest',\n      }),\n    )\n\n    expect(String(document)).toMatchInlineSnapshot(`\n      query {\n        findManyTest(where: {\n          id: \"806c902c-eab3-4e6e-ba4a-99c135389118\"\n        }) {\n          id\n          name\n        }\n      }\n    `)\n\n    expect(document.validate(select, false, 'tests')).toMatchInlineSnapshot(`undefined`)\n  })","file":"scalarWhereTransformation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"validate uuid scalar filter should error when invalid input","suites":["scalar where transformation"],"updatePoint":{"line":365,"column":67},"line":365,"code":"  test('validate uuid scalar filter should error when invalid input', () => {\n    const select = {\n      where: {\n        id: 'asd',\n      },\n    }\n\n    const document = transformDocument(\n      makeDocument({\n        dmmf,\n        select,\n        rootTypeName: 'query',\n        rootField: 'findManyTest',\n      }),\n    )\n\n    expect(String(document)).toMatchInlineSnapshot(`\n      query {\n        findManyTest(where: {\n          id: \"asd\"\n        }) {\n          id\n          name\n        }\n      }\n    `)\n\n    try {\n      expect(document.validate(select, false, 'tests')).toMatchInlineSnapshot(`undefined`)\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchInlineSnapshot(`\n        \"\n        Invalid \\`prisma.tests()\\` invocation:\n\n        {\n          where: {\n            id: 'asd'\n                ~~~~~\n          }\n        }\n\n        Argument id: Got invalid value 'asd' on prisma.findManyTest. Provided String, expected UUID or UUIDFilter.\n        type UUIDFilter {\n          equals?: UUID\n          not?: UUID | UUIDFilter\n          in?: List<UUID>\n          notIn?: List<UUID>\n          lt?: UUID\n          lte?: UUID\n          gt?: UUID\n          gte?: UUID\n          contains?: UUID\n          startsWith?: UUID\n          endsWith?: UUID\n        }\n\n        \"\n      `)\n    }\n  })","file":"scalarWhereTransformation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"filter by enum","suites":["scalar where transformation"],"updatePoint":{"line":426,"column":22},"line":426,"code":"  test('filter by enum', () => {\n    const select = {\n      where: {\n        favoriteTree: {\n          in: ['OAK', 'BLACKASH'],\n        },\n      },\n    }\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'query',\n      rootField: 'findManyUser',\n    })\n\n    expect(String(transformDocument(document))).toMatchInlineSnapshot(`\n      query {\n        findManyUser(where: {\n          favoriteTree: {\n            in: [OAK, BLACKASH]\n          }\n        }) {\n          id\n          name\n          email\n          status\n          nicknames\n          permissions\n          favoriteTree\n          locationId\n          someFloats\n        }\n      }\n    `)\n\n    document.validate(select, false, 'user')\n  })","file":"scalarWhereTransformation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"joins the argv array of strings input into one single string","suites":[],"updatePoint":{"line":16,"column":66},"line":16,"code":"test('joins the argv array of strings input into one single string', () => {\n  expect(getPostInstallTrigger()).toEqual('npm foo bar')\n})","file":"scripts/postinstall.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"empty original argv array results in just the package manager name as the command","suites":[],"updatePoint":{"line":20,"column":87},"line":20,"code":"test('empty original argv array results in just the package manager name as the command', () => {\n  process.env.npm_config_argv = '{\"original\":[]}'\n  expect(getPostInstallTrigger()).toEqual('npm')\n})","file":"scripts/postinstall.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"gets package manager name from npm_config_user_agent when matching userAgent pattern e.g. for %s","suites":["npm_config_user_agent"],"line":26,"code":"  test.each([['yarn'], ['npm'], ['pnpm'], ['qux']])(\n    'gets package manager name from npm_config_user_agent when matching userAgent pattern e.g. for %s',\n    (name) => {\n      process.env.npm_config_user_agent = `${name}/1.2.3`\n      expect(getPostInstallTrigger()).toEqual(`${name} foo bar`)\n    },\n  )","file":"scripts/postinstall.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"trailing whitespace on command trimmed","suites":["npm_config_user_agent"],"updatePoint":{"line":34,"column":46},"line":34,"code":"  test('trailing whitespace on command trimmed', () => {\n    process.env.npm_config_user_agent = 'npm /1.2.3'\n    expect(getPostInstallTrigger()).toEqual('npm foo bar')\n  })","file":"scripts/postinstall.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"leading whitespace on command trimmed","suites":["npm_config_user_agent"],"updatePoint":{"line":38,"column":45},"line":38,"code":"  test('leading whitespace on command trimmed', () => {\n    process.env.npm_config_user_agent = '  npm/1.2.3'\n    expect(getPostInstallTrigger()).toEqual('npm foo bar')\n  })","file":"scripts/postinstall.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"if npm_config_user_agent not available then falls back to MISSING_NPM_CONFIG_USER_AGENT","suites":["npm_config_user_agent"],"line":43,"code":"  test.each([[undefined], [''], [' ']])(\n    'if npm_config_user_agent not available then falls back to MISSING_NPM_CONFIG_USER_AGENT',\n    (value) => {\n      if (value === undefined) {\n        delete process.env.npm_config_user_agent\n      } else {\n        process.env.npm_config_user_agent = value\n      }\n      delete process.env.npm_config_user_agent\n      expect(getPostInstallTrigger()).toEqual(`MISSING_NPM_CONFIG_USER_AGENT foo bar`)\n    },\n  )","file":"scripts/postinstall.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"if npm_config_user_agent not parsable then falls back to UNKNOWN_NPM_CONFIG_USER_AGENT","suites":["npm_config_user_agent"],"line":56,"code":"  test.each([['foo@1.2.3']])(\n    'if npm_config_user_agent not parsable then falls back to UNKNOWN_NPM_CONFIG_USER_AGENT',\n    (userAgentString) => {\n      process.env.npm_config_user_agent = userAgentString\n      expect(getPostInstallTrigger()).toEqual(`UNKNOWN_NPM_CONFIG_USER_AGENT(${userAgentString}) foo bar`)\n    },\n  )","file":"scripts/postinstall.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"%s","suites":["fails gracefully with"],"line":67,"code":"  test.each([\n    ['envar missing', undefined, UNABLE_TO_FIND_POSTINSTALL_TRIGGER__ENVAR_MISSING],\n    ['envar bad json', 'bah', UNABLE_TO_FIND_POSTINSTALL_TRIGGER_JSON_PARSE_ERROR +': bah'],\n    ['envar bad json schema missing field', '{}', UNABLE_TO_FIND_POSTINSTALL_TRIGGER_JSON_SCHEMA_ERROR+': {}'],\n    ['envar bad json schema bad field type', '{\"original\":1}', UNABLE_TO_FIND_POSTINSTALL_TRIGGER_JSON_SCHEMA_ERROR+': {\"original\":1}'],\n  ])('%s', (_, envVarValue, expected) => {\n    if (envVarValue === undefined) {\n       delete process.env.npm_config_argv\n     } else  {\n       process.env.npm_config_argv = envVarValue\n     }\n    expect(getPostInstallTrigger()).toEqual(expected)\n  })","file":"scripts/postinstall.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"unknown arg, field, incorrect arg type","suites":["select validation"],"updatePoint":{"line":14,"column":46},"line":14,"code":"  test('unknown arg, field, incorrect arg type', () => {\n    expect.assertions(4)\n    const ast = {\n      skip: 200,\n      where: {\n        name_contains: undefined,\n        name_in: ['hans', 'peter', 'schmidt'],\n        AND: [\n          {\n            age_gt: 10123123123,\n            this_is_completely_arbitrary: 'veryLongNameGoIntoaNewLineNow@gmail.com',\n          },\n          {\n            age_gt: 10123123123,\n            id_endsWith: 'veryLongNameGoIntoaNewLineNow@gmail.com',\n            name_contains: 'hans',\n            name_gt: 2131203912039123,\n            name_in: ['hans'],\n            AND: [\n              {\n                age_gt: '10123123123',\n                id_endsWith: 'veryLongNameGoIntoaNewLineNow@gmail.com',\n              },\n            ],\n          },\n        ],\n      },\n      select: {\n        id: true,\n        name: 'asd',\n        name2: true,\n        posts: {\n          take: 200,\n          select: {\n            id: true,\n            title: false,\n          },\n        },\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'query',\n      rootField: 'findManyUser',\n    })\n    expect(String(document)).toMatchSnapshot()\n\n    try {\n      document.validate(ast, undefined, undefined, 'minimal')\n    } catch (e) {\n      expect(e.message).toMatchSnapshot()\n    }\n\n    try {\n      document.validate(ast, undefined, undefined, 'colorless')\n    } catch (e) {\n      expect(e.message).toMatchSnapshot()\n    }\n\n    try {\n      document.validate(ast)\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchSnapshot()\n    }\n  })","file":"select.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"missing arg object","suites":["select validation"],"updatePoint":{"line":82,"column":26},"line":82,"code":"  test('missing arg object', () => {\n    expect.assertions(2)\n    const ast = {}\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'mutation',\n      rootField: 'createOnePost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    try {\n      document.validate(ast)\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchSnapshot()\n    }\n  })","file":"select.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"missing arg object colorless","suites":["select validation"],"updatePoint":{"line":101,"column":36},"line":101,"code":"  test('missing arg object colorless', () => {\n    expect.assertions(4)\n    const ast = {}\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'mutation',\n      rootField: 'createOnePost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    try {\n      document.validate(ast)\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchSnapshot()\n    }\n\n    try {\n      document.validate(ast, undefined, undefined, 'minimal')\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchSnapshot()\n    }\n\n    try {\n      document.validate(ast, undefined, undefined, 'colorless')\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchSnapshot()\n    }\n  })","file":"select.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"missing arg scalar","suites":["select validation"],"updatePoint":{"line":132,"column":26},"line":132,"code":"  test('missing arg scalar', () => {\n    expect.assertions(2)\n    const ast = {\n      data: {\n        title: 'string',\n        author: {\n          connect: { id: '' },\n        },\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'mutation',\n      rootField: 'createOnePost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    try {\n      document.validate(ast)\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchSnapshot()\n    }\n  })","file":"select.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"missing arg scalar && object","suites":["select validation"],"updatePoint":{"line":158,"column":36},"line":158,"code":"  test('missing arg scalar && object', () => {\n    expect.assertions(2)\n    const ast = {\n      data: {\n        title: 'string',\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'mutation',\n      rootField: 'createOnePost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    try {\n      document.validate(ast)\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchSnapshot()\n    }\n  })","file":"select.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"Allow simple create mutation","suites":["select validation"],"updatePoint":{"line":181,"column":36},"line":181,"code":"  test('Allow simple create mutation', () => {\n    expect.assertions(2)\n    const ast = {\n      data: {\n        title: 'Some title',\n        content: 'Some Content',\n        published: false,\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'mutation',\n      rootField: 'createOnePost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    expect(() => document.validate(ast)).not.toThrow()\n  })","file":"select.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"Allow explicit null value","suites":["select validation"],"updatePoint":{"line":202,"column":33},"line":202,"code":"  test('Allow explicit null value', () => {\n    expect.assertions(2)\n    const ast = {\n      data: {\n        title: 'Some title',\n        content: null,\n        published: false,\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'mutation',\n      rootField: 'createOnePost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    expect(() => document.validate(ast)).not.toThrow()\n  })","file":"select.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"Allow different iso strings 1","suites":["select validation"],"updatePoint":{"line":223,"column":37},"line":223,"code":"  test('Allow different iso strings 1', () => {\n    expect.assertions(2)\n    const ast = {\n      data: {\n        title: 'Some title',\n        content: null,\n        published: false,\n        createdAt: '2020-05-05T16:28:33.983Z',\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'mutation',\n      rootField: 'createOnePost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    expect(() => document.validate(ast)).not.toThrow()\n  })","file":"select.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"Allow different iso strings 2","suites":["select validation"],"updatePoint":{"line":245,"column":37},"line":245,"code":"  test('Allow different iso strings 2', () => {\n    expect.assertions(2)\n    const ast = {\n      data: {\n        title: 'Some title',\n        content: null,\n        published: false,\n        createdAt: '2020-05-05T16:28:33.983+03:00',\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'mutation',\n      rootField: 'createOnePost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    expect(() => document.validate(ast)).not.toThrow()\n  })","file":"select.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"Allow different iso strings 3","suites":["select validation"],"updatePoint":{"line":267,"column":37},"line":267,"code":"  test('Allow different iso strings 3', () => {\n    expect.assertions(2)\n    const ast = {\n      data: {\n        title: 'Some title',\n        content: null,\n        published: false,\n        createdAt: '2020-05-05T16:28:33.983-02:00',\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'mutation',\n      rootField: 'createOnePost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    expect(() => document.validate(ast)).not.toThrow()\n  })","file":"select.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"Allow uuid for string input","suites":["select validation"],"updatePoint":{"line":289,"column":35},"line":289,"code":"  test('Allow uuid for string input', () => {\n    expect.assertions(2)\n    const ast = {\n      data: {\n        title: 'Some title',\n        content: '123e4567-e89b-12d3-a456-426655440000',\n        published: false,\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'mutation',\n      rootField: 'createOnePost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    expect(() => document.validate(ast)).not.toThrow()\n  })","file":"select.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"Allow deep select query","suites":["select validation"],"updatePoint":{"line":310,"column":31},"line":310,"code":"  test('Allow deep select query', () => {\n    expect.assertions(2)\n    const ast = {\n      select: {\n        author: {\n          select: {\n            id: true,\n          },\n        },\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'query',\n      rootField: 'findManyPost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    expect(() => document.validate(ast)).not.toThrow()\n  })","file":"select.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"Accept empty where in findMany","suites":["select validation"],"updatePoint":{"line":333,"column":38},"line":333,"code":"  test('Accept empty where in findMany', () => {\n    expect.assertions(2)\n    const ast = {\n      select: {\n        author: {\n          select: {\n            id: true,\n          },\n        },\n      },\n      where: {},\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'query',\n      rootField: 'findManyPost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    expect(() => document.validate(ast)).not.toThrow()\n  })","file":"select.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"allow where with all undefined in findMany","suites":["select validation"],"updatePoint":{"line":357,"column":50},"line":357,"code":"  test('allow where with all undefined in findMany', () => {\n    expect.assertions(2)\n    const ast = {\n      select: {\n        author: {\n          select: {\n            id: true,\n          },\n        },\n      },\n      where: {\n        id: undefined,\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'query',\n      rootField: 'findManyPost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    expect(() => document.validate(ast)).not.toThrow()\n  })","file":"select.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"reject empty where for findUnique","suites":["select validation"],"updatePoint":{"line":383,"column":41},"line":383,"code":"  test('reject empty where for findUnique', () => {\n    expect.assertions(2)\n    const ast = {\n      select: {\n        author: {\n          select: {\n            id: true,\n          },\n        },\n      },\n      where: {},\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'query',\n      rootField: 'findUniquePost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    try {\n      document.validate(ast)\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchSnapshot()\n    }\n  })","file":"select.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"reject all undefined where for findUnique","suites":["select validation"],"updatePoint":{"line":411,"column":49},"line":411,"code":"  test('reject all undefined where for findUnique', () => {\n    expect.assertions(2)\n    const ast = {\n      select: {\n        author: {\n          select: {\n            id: true,\n          },\n        },\n      },\n      where: {\n        id: undefined,\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'query',\n      rootField: 'findUniquePost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    try {\n      document.validate(ast)\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchSnapshot()\n    }\n  })","file":"select.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"Allow uuid array for string array","suites":["select validation"],"updatePoint":{"line":441,"column":41},"line":441,"code":"  test('Allow uuid array for string array', () => {\n    expect.assertions(2)\n    const ast = {\n      select: {\n        author: {\n          select: {\n            id: true,\n          },\n        },\n      },\n      where: {\n        id: {\n          in: ['d4082b42-b161-11e9-8754-6542abf52968'],\n        },\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'query',\n      rootField: 'findManyPost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    expect(() => document.validate(ast)).not.toThrow()\n  })","file":"select.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"Allow empty input array","suites":["select validation"],"updatePoint":{"line":469,"column":31},"line":469,"code":"  test('Allow empty input array', () => {\n    expect.assertions(2)\n    const ast = {\n      select: {\n        author: {\n          select: {\n            id: true,\n          },\n        },\n      },\n      where: {\n        id: {\n          in: [],\n        },\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'query',\n      rootField: 'findManyPost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    expect(() => document.validate(ast)).not.toThrow()\n  })","file":"select.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"Allow select with an include","suites":["select validation"],"updatePoint":{"line":497,"column":36},"line":497,"code":"  test('Allow select with an include', () => {\n    expect.assertions(2)\n    const ast = {\n      select: {\n        author: {\n          include: { posts: true },\n        },\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select: ast,\n      rootTypeName: 'query',\n      rootField: 'findManyPost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    expect(() => document.validate(ast)).not.toThrow()\n  })","file":"select.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"object","suites":["serializeRawParemeters"],"updatePoint":{"line":6,"column":14},"line":6,"code":"  test('object', () => {\n    const data = {\n      date: new Date('2020-06-22T17:07:16.348Z'),\n      bigInt: BigInt('321804719213721'),\n    }\n\n    expect(serializeHelper(data)).toMatchInlineSnapshot(`\n      Object {\n        bigInt: 321804719213721,\n        date: Object {\n          prisma__type: date,\n          prisma__value: 2020-06-22T17:07:16.348Z,\n        },\n      }\n    `)\n  })","file":"serializeRawParameters.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"array","suites":["serializeRawParemeters"],"updatePoint":{"line":23,"column":13},"line":23,"code":"  test('array', () => {\n    const data = {\n      date: [new Date('2020-06-22T17:07:16.348Z')],\n      bigInt: [BigInt('321804719213721')],\n    }\n\n    expect(serializeHelper(data)).toMatchInlineSnapshot(`\n      Object {\n        bigInt: Array [\n          321804719213721,\n        ],\n        date: Array [\n          Object {\n            prisma__type: date,\n            prisma__value: 2020-06-22T17:07:16.348Z,\n          },\n        ],\n      }\n    `)\n  })","file":"serializeRawParameters.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"scalar date","suites":["serializeRawParemeters"],"updatePoint":{"line":44,"column":19},"line":44,"code":"  test('scalar date', () => {\n    const data = new Date('2020-06-22T17:07:16.348Z')\n\n    expect(serializeHelper(data)).toMatchInlineSnapshot(`\n      Object {\n        prisma__type: date,\n        prisma__value: 2020-06-22T17:07:16.348Z,\n      }\n    `)\n  })","file":"serializeRawParameters.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"scalar bigInt","suites":["serializeRawParemeters"],"updatePoint":{"line":55,"column":21},"line":55,"code":"  test('scalar bigInt', () => {\n    const data = BigInt('321804719213721')\n\n    expect(serializeHelper(data)).toMatchInlineSnapshot(`321804719213721`)\n  })","file":"serializeRawParameters.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"nested","suites":["serializeRawParemeters"],"updatePoint":{"line":61,"column":14},"line":61,"code":"  test('nested', () => {\n    const data = {\n      deep: {\n        date: [new Date('2020-06-22T17:07:16.348Z'), new Date('2020-06-22T17:07:16.348Z')],\n        bigInt: [BigInt('321804719213721'), BigInt('321804719213721')],\n      },\n    }\n\n    expect(serializeHelper(data)).toMatchInlineSnapshot(`\n      Object {\n        deep: Object {\n          bigInt: Array [\n            321804719213721,\n            321804719213721,\n          ],\n          date: Array [\n            Object {\n              prisma__type: date,\n              prisma__value: 2020-06-22T17:07:16.348Z,\n            },\n            Object {\n              prisma__type: date,\n              prisma__value: 2020-06-22T17:07:16.348Z,\n            },\n          ],\n        },\n      }\n    `)\n  })","file":"serializeRawParameters.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"where null","suites":["minimal where transformation"],"updatePoint":{"line":13,"column":18},"line":13,"code":"  test('where null', () => {\n    const transformedDocument = getTransformedDocument({\n      where: {\n        company: null,\n      },\n    })\n\n    expect(transformedDocument).toMatchInlineSnapshot(`\n      query {\n        findManyLocation(where: {\n          company: null\n        }) {\n          id\n          companyId\n        }\n      }\n    `)\n  })","file":"singularRelationWhereTransformation.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"%s","suites":["valid types"],"line":21,"code":"  test.concurrent.each(subDirs)('%s', async (dir) => {\n    const testName = path.basename(dir)\n\n    const nodeModules = path.join(dir, 'node_modules')\n    if (fs.existsSync(nodeModules)) {\n      await del(nodeModules)\n    }\n    await generateInFolder({\n      projectDir: dir,\n      useLocalRuntime: false,\n      transpile: true,\n      packageSource,\n    })\n    const indexPath = path.join(dir, 'test.ts')\n    const tsdTestPath = path.join(dir, 'index.test-d.ts')\n\n    if (fs.existsSync(tsdTestPath)) {\n      await runTsd(dir)\n    }\n\n    if (testName.startsWith('unhappy')) {\n      await expect(compileFile(indexPath)).rejects.toThrow()\n    } else {\n      await expect(compileFile(indexPath)).resolves.not.toThrow()\n    }\n  })","file":"types/types.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"null when undefined is allowed","suites":["select validation"],"updatePoint":{"line":14,"column":38},"line":14,"code":"  test('null when undefined is allowed', () => {\n    const select = {\n      data: {\n        id: null,\n      },\n      where: {\n        id: 'abc',\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'mutation',\n      rootField: 'updateOnePost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    try {\n      document.validate(select)\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchInlineSnapshot(`\n\n        Invalid \\`prisma.updateOnePost()\\` invocation:\n\n        {\n          data: {\n            id: null\n                ~~~~\n          },\n          where: {\n            id: 'abc'\n          }\n        }\n\n        Argument id for data.id must not be null. Please use undefined instead.\n\n\n      `)\n    }\n  })","file":"undefined-vs-null.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"null when undefined is not allowed","suites":["select validation"],"updatePoint":{"line":55,"column":42},"line":55,"code":"  test('null when undefined is not allowed', () => {\n    const select = {\n      data: {\n        published: true,\n        title: null,\n      },\n    }\n\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'mutation',\n      rootField: 'createOnePost',\n    })\n\n    expect(String(document)).toMatchSnapshot()\n    try {\n      document.validate(select)\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchInlineSnapshot(`\n\n                                                        Invalid \\`prisma.createOnePost()\\` invocation:\n\n                                                        {\n                                                          data: {\n                                                            published: true,\n                                                            title: null\n                                                                   ~~~~\n                                                          }\n                                                        }\n\n                                                        Argument title: Got invalid value null on prisma.createOnePost. Provided null, expected String.\n\n\n                                          `)\n    }\n  })","file":"undefined-vs-null.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"blog findUniqueUser","suites":["getField"],"updatePoint":{"line":16,"column":27},"line":16,"code":"  test('blog findUniqueUser', () => {\n    const document = makeDocument({\n      dmmf,\n      select: {\n        select: {\n          id: true,\n          posts: true,\n        },\n      },\n      rootTypeName: 'query',\n      rootField: 'findUniqueUser',\n    })\n\n    expect(getField(document, ['findUniqueUser']).name).toMatchInlineSnapshot(`findUniqueUser`)\n    expect(getField(document, ['findUniqueUser', 'id']).name).toMatchInlineSnapshot(`id`)\n    expect(getField(document, ['findUniqueUser', 'posts']).name).toMatchInlineSnapshot(`posts`)\n    expect(getField(document, ['findUniqueUser', 'posts', 'title']).name).toMatchInlineSnapshot(`title`)\n  })","file":"unpack.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"findUniquePost","suites":["unpack"],"updatePoint":{"line":37,"column":22},"line":37,"code":"  test('findUniquePost', () => {\n    const document = makeDocument({\n      dmmf,\n      select: {},\n      rootTypeName: 'query',\n      rootField: 'findUniquePost',\n    })\n\n    const path = ['findUniquePost']\n\n    const data = {\n      findUniquePost: {\n        id: 'some-id',\n        createdAt: '2019-10-17T09:56:37.690Z',\n        updatedAt: '2019-10-17T09:56:37.690Z',\n        published: false,\n        title: 'Some mighty hightly title',\n      },\n    }\n\n    const result = unpack({\n      document,\n      path,\n      data,\n    })\n\n    expect(result.createdAt).toBeInstanceOf(Date)\n    expect(result.updatedAt).toBeInstanceOf(Date)\n\n    expect(result).toMatchInlineSnapshot(`\n      Object {\n        createdAt: 2019-10-17T09:56:37.690Z,\n        id: some-id,\n        published: false,\n        title: Some mighty hightly title,\n        updatedAt: 2019-10-17T09:56:37.690Z,\n      }\n    `)\n  })","file":"unpack.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"findManyPost","suites":["unpack"],"updatePoint":{"line":77,"column":20},"line":77,"code":"  test('findManyPost', () => {\n    const document = makeDocument({\n      dmmf,\n      select: {},\n      rootTypeName: 'query',\n      rootField: 'findManyPost',\n    })\n\n    const path = ['findManyPost']\n\n    const data = {\n      findManyPost: [\n        {\n          id: 'some-id',\n          createdAt: '2019-10-17T09:56:37.690Z',\n          updatedAt: '2019-10-17T09:56:37.690Z',\n          published: false,\n          title: 'Some mighty hightly title',\n        },\n        {\n          id: 'some-id2',\n          createdAt: '2019-11-17T09:56:37.690Z',\n          updatedAt: '2019-11-17T09:56:37.690Z',\n          published: true,\n          title: 'Having a title that is recital is just vital',\n        },\n        {\n          id: 'some-id3',\n          createdAt: '2019-11-17T09:56:37.690Z',\n          updatedAt: '2019-11-17T09:56:37.690Z',\n          published: true,\n          title: \"One thing for sure: If you don't read the bible, you can't belong to the tribal.\",\n        },\n      ],\n    }\n\n    const result = unpack({\n      document,\n      path,\n      data,\n    })\n\n    expect(result[0].createdAt).toBeInstanceOf(Date)\n    expect(result[0].updatedAt).toBeInstanceOf(Date)\n\n    expect(result).toMatchInlineSnapshot(`\n      Array [\n        Object {\n          createdAt: 2019-10-17T09:56:37.690Z,\n          id: some-id,\n          published: false,\n          title: Some mighty hightly title,\n          updatedAt: 2019-10-17T09:56:37.690Z,\n        },\n        Object {\n          createdAt: 2019-11-17T09:56:37.690Z,\n          id: some-id2,\n          published: true,\n          title: Having a title that is recital is just vital,\n          updatedAt: 2019-11-17T09:56:37.690Z,\n        },\n        Object {\n          createdAt: 2019-11-17T09:56:37.690Z,\n          id: some-id3,\n          published: true,\n          title: One thing for sure: If you don't read the bible, you can't belong to the tribal.,\n          updatedAt: 2019-11-17T09:56:37.690Z,\n        },\n      ]\n    `)\n  })","file":"unpack.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"findUniqueUser","suites":["unpack"],"updatePoint":{"line":149,"column":22},"line":149,"code":"  test('findUniqueUser', () => {\n    const document = makeDocument({\n      dmmf,\n      select: {\n        include: {\n          posts: true,\n        },\n      },\n      rootTypeName: 'query',\n      rootField: 'findUniqueUser',\n    })\n\n    const path = ['findUniqueUser']\n\n    const data = {\n      findUniqueUser: {\n        id: 'some-id',\n        email: 'a@a.com',\n        json: '{\"hello\": \"world\"}',\n        posts: [\n          {\n            id: 'some-id',\n            createdAt: '2019-10-17T09:56:37.690Z',\n            updatedAt: '2019-10-17T09:56:37.690Z',\n            published: false,\n            title: 'Some mighty hightly title',\n          },\n          {\n            id: 'some-id2',\n            createdAt: '2019-11-17T09:56:37.690Z',\n            updatedAt: '2019-11-17T09:56:37.690Z',\n            published: true,\n            title: 'Having a title that is recital is just vital',\n          },\n          {\n            id: 'some-id3',\n            createdAt: '2019-11-17T09:56:37.690Z',\n            updatedAt: '2019-11-17T09:56:37.690Z',\n            published: true,\n            title: 'Does the bible talk about the revival of the tribal?',\n          },\n        ],\n      },\n    }\n\n    const result = unpack({\n      document,\n      path,\n      data,\n    })\n\n    expect(result).toMatchInlineSnapshot(`\n      Object {\n        email: a@a.com,\n        id: some-id,\n        json: Object {\n          hello: world,\n        },\n        posts: Array [\n          Object {\n            createdAt: 2019-10-17T09:56:37.690Z,\n            id: some-id,\n            published: false,\n            title: Some mighty hightly title,\n            updatedAt: 2019-10-17T09:56:37.690Z,\n          },\n          Object {\n            createdAt: 2019-11-17T09:56:37.690Z,\n            id: some-id2,\n            published: true,\n            title: Having a title that is recital is just vital,\n            updatedAt: 2019-11-17T09:56:37.690Z,\n          },\n          Object {\n            createdAt: 2019-11-17T09:56:37.690Z,\n            id: some-id3,\n            published: true,\n            title: Does the bible talk about the revival of the tribal?,\n            updatedAt: 2019-11-17T09:56:37.690Z,\n          },\n        ],\n      }\n    `)\n  })","file":"unpack.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"set null values","suites":["minimal update transformation"],"updatePoint":{"line":24,"column":23},"line":24,"code":"  test('set null values', () => {\n    const transformedDocument = getTransformedDocument({\n      data: {\n        name: null,\n        profile: {\n          set: null,\n        },\n        posts: {\n          updateMany: {\n            data: {\n              optionnal: null,\n              content: {\n                set: null,\n              },\n            },\n            where: {\n              id: 'someid',\n            },\n          },\n        },\n      },\n    })\n\n    expect(transformedDocument).toMatchInlineSnapshot(`\n      mutation {\n        updateOneUser(\n          data: {\n            name: null\n            profile: {\n              set: null\n            }\n            posts: {\n              updateMany: {\n                data: {\n                  optionnal: null\n                  content: {\n                    set: null\n                  }\n                }\n                where: {\n                  id: \"someid\"\n                }\n              }\n            }\n          }\n        ) {\n          id\n          email\n          name\n          json\n          countFloat\n          countInt1\n          countInt2\n          countInt3\n          countInt4\n          countInt5\n          countInt6\n          lastLoginAt\n          coinflips\n        }\n      }\n    `)\n  })","file":"update.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"set date","suites":["minimal update transformation"],"updatePoint":{"line":88,"column":16},"line":88,"code":"  test('set date', () => {\n    const transformedDocument = getTransformedDocument({\n      data: {\n        lastLoginAt: new Date('2020-09-04T07:45:24.484Z'),\n        posts: {\n          updateMany: {\n            data: {\n              updatedAt: new Date('2020-09-04T07:45:24.484Z'),\n            },\n            where: {\n              id: 'someid',\n            },\n          },\n        },\n      },\n    })\n\n    expect(transformedDocument).toMatchInlineSnapshot(`\n      mutation {\n        updateOneUser(\n          data: {\n            lastLoginAt: \"2020-09-04T07:45:24.484Z\"\n            posts: {\n              updateMany: {\n                data: {\n                  updatedAt: \"2020-09-04T07:45:24.484Z\"\n                }\n                where: {\n                  id: \"someid\"\n                }\n              }\n            }\n          }\n        ) {\n          id\n          email\n          name\n          json\n          countFloat\n          countInt1\n          countInt2\n          countInt3\n          countInt4\n          countInt5\n          countInt6\n          lastLoginAt\n          coinflips\n        }\n      }\n    `)\n  })","file":"update.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"set date with set wrapper","suites":["minimal update transformation"],"updatePoint":{"line":140,"column":33},"line":140,"code":"  test('set date with set wrapper', () => {\n    const transformedDocument = getTransformedDocument({\n      data: {\n        lastLoginAt: {\n          set: new Date('2020-09-04T07:45:24.484Z'),\n        },\n        posts: {\n          updateMany: {\n            data: {\n              updatedAt: {\n                set: new Date('2020-09-04T07:45:24.484Z'),\n              },\n            },\n            where: {\n              id: 'someid',\n            },\n          },\n        },\n      },\n    })\n\n    expect(transformedDocument).toMatchInlineSnapshot(`\n      mutation {\n        updateOneUser(\n          data: {\n            lastLoginAt: {\n              set: \"2020-09-04T07:45:24.484Z\"\n            }\n            posts: {\n              updateMany: {\n                data: {\n                  updatedAt: {\n                    set: \"2020-09-04T07:45:24.484Z\"\n                  }\n                }\n                where: {\n                  id: \"someid\"\n                }\n              }\n            }\n          }\n        ) {\n          id\n          email\n          name\n          json\n          countFloat\n          countInt1\n          countInt2\n          countInt3\n          countInt4\n          countInt5\n          countInt6\n          lastLoginAt\n          coinflips\n        }\n      }\n    `)\n  })","file":"update.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"Boolean[] list with set","suites":["minimal update transformation"],"updatePoint":{"line":200,"column":31},"line":200,"code":"  test('Boolean[] list with set', () => {\n    const transformedDocument = getTransformedDocument({\n      data: {\n        coinflips: {\n          set: [true, true, true, false, true],\n        },\n      },\n    })\n\n    expect(transformedDocument).toMatchInlineSnapshot(`\n      mutation {\n        updateOneUser(\n          data: {\n            coinflips: {\n              set: [true, true, true, false, true]\n            }\n          }\n        ) {\n          id\n          email\n          name\n          json\n          countFloat\n          countInt1\n          countInt2\n          countInt3\n          countInt4\n          countInt5\n          countInt6\n          lastLoginAt\n          coinflips\n        }\n      }\n    `)\n  })","file":"update.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"Boolean[] list without set","suites":["minimal update transformation"],"updatePoint":{"line":236,"column":34},"line":236,"code":"  test('Boolean[] list without set', () => {\n    const transformedDocument = getTransformedDocument({\n      data: {\n        coinflips: [true, true, true, false, true],\n      },\n    })\n\n    // this is broken and needs to be fixed\n    expect(transformedDocument).toMatchInlineSnapshot(`\n      mutation {\n        updateOneUser(\n          data: {\n            coinflips: [true, true, true, false, true]\n          }\n        ) {\n          id\n          email\n          name\n          json\n          countFloat\n          countInt1\n          countInt2\n          countInt3\n          countInt4\n          countInt5\n          countInt6\n          lastLoginAt\n          coinflips\n        }\n      }\n    `)\n  })","file":"update.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"string first","suites":["at least one validation"],"updatePoint":{"line":21,"column":20},"line":21,"code":"  test('string first', () => {\n    const select = {\n      data: {\n        hobbies: {\n          set: [\n            'sample 1 string',\n            '7fb1aef9-5250-4cf6-92c7-b01f53862822',\n            'sample 3 string',\n            '575e0b28-81fa-43e0-8f05-708a98d55c14',\n            'sample 5 string',\n          ],\n        },\n        name: 'name',\n      },\n    }\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'mutation',\n      rootField: 'createOneUser',\n    })\n    expect(() => document.validate(select, false)).not.toThrow()\n  })","file":"uuid.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"uuid first","suites":["at least one validation"],"updatePoint":{"line":44,"column":18},"line":44,"code":"  test('uuid first', () => {\n    const select = {\n      data: {\n        hobbies: {\n          set: [\n            '7fb1aef9-5250-4cf6-92c7-b01f53862822',\n            'sample 3 string',\n            '575e0b28-81fa-43e0-8f05-708a98d55c14',\n            'sample 5 string',\n          ],\n        },\n        name: 'name',\n      },\n    }\n    const document = makeDocument({\n      dmmf,\n      select,\n      rootTypeName: 'mutation',\n      rootField: 'createOneUser',\n    })\n    expect(() => document.validate(select, false)).not.toThrow()\n  })","file":"uuid.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"empty","suites":["valid options"],"updatePoint":{"line":4,"column":13},"line":4,"code":"  test('empty', () => {\n    expect.assertions(0)\n    validatePrismaClientOptions({}, ['db'])\n  })","file":"validatePrismaClientOptions.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"full","suites":["valid options"],"updatePoint":{"line":8,"column":12},"line":8,"code":"  test('full', () => {\n    expect.assertions(0)\n    validatePrismaClientOptions(\n      {\n        datasources: {\n          db: {\n            url: '',\n          },\n        },\n        errorFormat: 'pretty',\n        log: ['error'],\n      },\n      ['db'],\n    )\n\n    validatePrismaClientOptions(\n      {\n        datasources: {\n          db: {\n            url: '',\n          },\n        },\n        errorFormat: 'pretty',\n        log: [\n          {\n            emit: 'event',\n            level: 'error',\n          },\n        ],\n      },\n      ['db'],\n    )\n  })","file":"validatePrismaClientOptions.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"typos","suites":["invalid options"],"updatePoint":{"line":44,"column":13},"line":44,"code":"  test('typos', () => {\n    expect(() =>\n      validatePrismaClientOptions(\n        {\n          errorrFormat: 'minimal',\n        } as any,\n        ['db'],\n      ),\n    ).toThrowErrorMatchingInlineSnapshot(`\n      Unknown property errorrFormat provided to PrismaClient constructor. Did you mean \"errorFormat\"?\n      Read more at https://pris.ly/d/client-constructor\n    `)\n    expect(() =>\n      validatePrismaClientOptions(\n        {\n          errorFormat: 'minimal',\n          datasources: {\n            asd: {},\n          },\n        },\n        ['db'],\n      ),\n    ).toThrowErrorMatchingInlineSnapshot(`\n      Unknown datasource asd provided to PrismaClient constructor.Available datasources: db\n      Read more at https://pris.ly/d/client-constructor\n    `)\n    expect(() =>\n      validatePrismaClientOptions(\n        {\n          errorFormat: 'minimal',\n          datasources: {\n            db: { murl: '' },\n          },\n        } as any,\n        ['db'],\n      ),\n    ).toThrowErrorMatchingInlineSnapshot(`\n      Invalid value {\"db\":{\"murl\":\"\"}} for datasource \"db\" provided to PrismaClient constructor.\n      It should have this form: { url: \"CONNECTION_STRING\" }\n      Read more at https://pris.ly/d/client-constructor\n    `)\n    expect(() =>\n      validatePrismaClientOptions(\n        {\n          errorFormat: 'minimal',\n          log: [{ helo: 'world' }],\n        } as any,\n        ['db'],\n      ),\n    ).toThrowErrorMatchingInlineSnapshot(`\n      Invalid property helo for \"log\" provided to PrismaClient constructor\n      Read more at https://pris.ly/d/client-constructor\n    `)\n    expect(() =>\n      validatePrismaClientOptions(\n        {\n          errorFormat: 'minimal',\n          log: ['muery'],\n        } as any,\n        ['db'],\n      ),\n    ).toThrowErrorMatchingInlineSnapshot(`\n      Invalid log level \"muery\" provided to PrismaClient constructor. Did you mean \"query\"?\n      Read more at https://pris.ly/d/client-constructor\n    `)\n  })","file":"validatePrismaClientOptions.test.ts","skipped":false,"dir":"packages/client/src/__tests__"},{"name":"shouldnt log if its not enabled","suites":["debug"],"updatePoint":{"line":6,"column":39},"line":6,"code":"  test('shouldnt log if its not enabled', () => {\n    const debug = Debug('my-namespace')\n    const logs: string[] = []\n    debug.log = (...args) => {\n      logs.push(stripAnsi(args[0]).trimStart())\n    }\n    debug('Does it even log?')\n    debug('I dont know')\n\n    expect(removeISODate(JSON.stringify(logs, null, 2))).toMatchInlineSnapshot(`\"[]\"`)\n\n    expect(sanitizeTestLogs(getLogs())).toMatchInlineSnapshot(`\n      \"my-namespace Does it even log?\n      my-namespace I dont know\"\n    `)\n  })","file":"basic.test.ts","skipped":false,"dir":"packages/debug/src/__tests__"},{"name":"should log if its enabled","suites":["debug"],"updatePoint":{"line":22,"column":33},"line":22,"code":"  test('should log if its enabled', () => {\n    const debug = Debug('a-namespace')\n    Debug.enable('a-namespace')\n    const logs: string[] = []\n    debug.log = (...args) => {\n      logs.push(stripAnsi(args[0]).trimStart())\n    }\n    debug('Does it even log?')\n    debug('I dont know')\n\n    expect(removeISODate(JSON.stringify(logs, null, 2))).toMatchInlineSnapshot(`\n      \"[\n        \\\\\" a-namespace Does it even log?\\\\\",\n        \\\\\" a-namespace I dont know\\\\\"\n      ]\"\n    `)\n\n    expect(sanitizeTestLogs(getLogs())).toMatchInlineSnapshot(`\n      \"my-namespace Does it even log?\n      my-namespace I dont know\n      a-namespace Does it even log?\n      a-namespace I dont know\"\n    `)\n  })","file":"basic.test.ts","skipped":false,"dir":"packages/debug/src/__tests__"},{"name":"* works as expected","suites":["debug"],"updatePoint":{"line":8,"column":27},"line":8,"code":"  test('* works as expected', () => {\n    const debug = Debug('my-namespace')\n    const logs: string[] = []\n    debug.log = (...args) => {\n      logs.push(stripAnsi(args[0]).trimStart())\n    }\n    debug('Does it even log?')\n    debug('I dont know')\n\n    expect(logs).toMatchInlineSnapshot(`Array []`)\n\n    expect(sanitizeTestLogs(getLogs())).toMatchInlineSnapshot(`\n      \"my-namespace Does it even log?\n      my-namespace I dont know\"\n    `)\n  })","file":"env-disabled.test.ts","skipped":false,"dir":"packages/debug/src/__tests__"},{"name":"env vars work as expected","suites":["debug"],"updatePoint":{"line":8,"column":33},"line":8,"code":"  test('env vars work as expected', () => {\n    const debug = Debug('my-namespace')\n    const logs: string[] = []\n    debug.log = (...args) => {\n      logs.push(stripAnsi(args[0]).trimStart())\n    }\n    debug('Does it even log?')\n    debug('I dont know')\n\n    expect(removeISODate(JSON.stringify(logs, null, 2))).toMatchInlineSnapshot(`\n      \"[\n        \\\\\" my-namespace Does it even log?\\\\\",\n        \\\\\" my-namespace I dont know\\\\\"\n      ]\"\n    `)\n\n    expect(sanitizeTestLogs(getLogs())).toMatchInlineSnapshot(`\n      \"my-namespace Does it even log?\n      my-namespace I dont know\"\n    `)\n  })","file":"env-enabled.test.ts","skipped":false,"dir":"packages/debug/src/__tests__"},{"name":"basic serialization","suites":["getErrorMessageWithLink"],"updatePoint":{"line":6,"column":27},"line":6,"code":"  test('basic serialization', () => {\n    const debug = Debug('test-namespace')\n    debug('hello')\n    const message = getErrorMessageWithLink({\n      platform: 'darwin',\n      title: 'This is a title',\n      version: '1.2.3',\n      description: 'This is some crazy description',\n      query: 'QUERY',\n      database: 'mongodb',\n      engineVersion: 'abcdefhg',\n    })\n    expect(\n      stripAnsi(message)\n        .replace(/v\\d{1,2}\\.\\d{1,2}\\.\\d{1,2}/, 'NODE_VERSION')\n        .replace(/[\\+-]/g, ''),\n    ).toMatchInlineSnapshot(`\n      \"This is a title\n\n      This is a nonrecoverable error which probably happens when the Prisma Query Engine has a panic.\n\n      https://github.com/prisma/prisma/issues/new?body=HiPrismaTeam%21MyPrismaClientjustcrashed.Thisisthereport%3A%0A%23%23Versions%0A%0A%7CName%7CVersion%7C%0A%7C%7C%7C%0A%7CNode%7CNODE_VERSION%7C%0A%7COS%7Cdarwin%7C%0A%7CPrismaClient%7C1.2.3%7C%0A%7CQueryEngine%7Cabcdefhg%7C%0A%7CDatabase%7Cmongodb%7C%0A%0A%23Description%0A%60%60%60%0AThisissomecrazydescription%0A%60%60%60%0A%0A%23%23Logs%0A%60%60%60%0Atestnamespacehello%0A%60%60%60%0A%0A%23%23ClientSnippet%0A%60%60%60ts%0A%2F%2FPLEASEFILLYOURCODESNIPPETHERE%0A%60%60%60%0A%0A%23%23Schema%0A%60%60%60prisma%0A%2F%2FPLEASEADDYOURSCHEMAHEREIFPOSSIBLE%0A%60%60%60%0A%0A%23%23PrismaEngineQuery%0A%60%60%60%0AQUERY%0A%60%60%60%0A&title=Thisisatitle&template=bug_report.md\n\n      If you want the Prisma team to look into it, please open the link above 🙏\n      To increase the chance of success, please post your schema and a snippet of\n      how you used Prisma Client in the issue. \n      \"\n    `)\n  })","file":"errors.test.ts","skipped":false,"dir":"packages/engine-core/src/__tests__"},{"name":"big query","suites":[],"updatePoint":{"line":3,"column":15},"line":3,"code":"test('big query', () => {\n  const query = `query {\n  users(\n    mirst: 100\n    skip: \"200\"\n    where: {\n      age_gt: -10\n      age_in: [1, 2, 3.123]\n      name_in: [\"hans\", \"peter\", \"schmidt\"]\n      OR: [\n        {\n          age_gt: 10123123123\n          email_endsWith: \"veryLongNameGoIntoaNewLineNow@gmail.com\"\n        },\n        {\n          age_gt: 10123123123\n          email_endsWith: \"veryLongNameGoIntoaNewLineNow@gmail.com\"\n          OR: [\n            {\n              age_gt: 10123123123\n              email_endsWith: \"veryLongNameGoIntoaNewLineNow@gmail.com\"\n            }\n          ]\n        }\n      ]\n    }\n  ) {\n    id\n    name2 # INVALID_FIELD\n    friends {\n      id\n      name\n    }\n    posts(first: 200) {\n      id\n      name\n    }\n  }\n}`\n\n  expect(maskQuery(query)).toMatchInlineSnapshot(`\n    \"query {\n      users(\n        mirst: 5\n        skip: \\\\\"X\\\\\"\n        where: {\n          age_gt: 5\n          age_in: [5, 5, 5]\n          name_in: [\\\\\"X\\\\\"]\n          OR: [\n            {\n              age_gt: 5\n              email_endsWith: \\\\\"X\\\\\"\n            },\n            {\n              age_gt: 5\n              email_endsWith: \\\\\"X\\\\\"\n              OR: [\n                {\n                  age_gt: 5\n                  email_endsWith: \\\\\"X\\\\\"\n                }\n              ]\n            }\n          ]\n        }\n      ) {\n        id\n        name2 # INVALID_FIELD\n        friends {\n          id\n          name\n        }\n        posts(first: 5) {\n          id\n          name\n        }\n      }\n    }\"\n  `)\n})","file":"maskQuery.test.ts","skipped":false,"dir":"packages/engine-core/src/__tests__"},{"name":"aggregate","suites":[],"updatePoint":{"line":85,"column":15},"line":85,"code":"test('aggregate', () => {\n  const query = `query {\n    aggregateUser(take: 10) {\n      count {\n        _all\n      }\n    }\n  }`\n\n  expect(maskQuery(query)).toMatchInlineSnapshot(`\n    \"query {\n        aggregateUser(take: 5) {\n          count {\n            _all\n          }\n        }\n      }\"\n  `)\n})","file":"maskQuery.test.ts","skipped":false,"dir":"packages/engine-core/src/__tests__"},{"name":"minimal-executable","suites":["generatorHandler"],"updatePoint":{"line":78,"column":26},"line":78,"code":"  test('minimal-executable', async () => {\n    const generator = new GeneratorProcess(getExecutable('minimal-executable'))\n    await generator.init()\n    const manifest = await generator.getManifest(stubOptions.generator)\n    expect(manifest).toMatchInlineSnapshot(`\n      Object {\n        \"defaultOutput\": \"default-output\",\n        \"denylists\": Object {\n          \"models\": Array [\n            \"SomeForbiddenModel\",\n          ],\n        },\n        \"prettyName\": \"This is a pretty pretty name\",\n        \"requiresEngines\": Array [\n          \"introspection-engine\",\n          \"query-engine\",\n        ],\n        \"requiresGenerators\": Array [\n          \"prisma-client-js\",\n        ],\n      }\n    `)\n    expect(() => generator.generate(stubOptions)).not.toThrow()\n\n    generator.stop()\n  })","file":"generatorHandler.test.ts","skipped":false,"dir":"packages/generator-helper/src/__tests__"},{"name":"failing-executable","suites":["generatorHandler"],"updatePoint":{"line":105,"column":26},"line":105,"code":"  test('failing-executable', async () => {\n    const generator = new GeneratorProcess(getExecutable('failing-executable'))\n    await generator.init()\n    await expect(generator.getManifest(stubOptions.generator)).rejects.toThrow()\n    await expect(generator.generate(stubOptions)).rejects.toThrow()\n    generator.stop()\n  })","file":"generatorHandler.test.ts","skipped":false,"dir":"packages/generator-helper/src/__tests__"},{"name":"non existent executable","suites":["generatorHandler"],"updatePoint":{"line":113,"column":31},"line":113,"code":"  test('non existent executable', async () => {\n    const generator = new GeneratorProcess(getExecutable('random path that doesnt exist'))\n    await expect(() => generator.init()).rejects.toThrow()\n  })","file":"generatorHandler.test.ts","skipped":false,"dir":"packages/generator-helper/src/__tests__"},{"name":"no params should return help","suites":[],"updatePoint":{"line":4,"column":32},"line":4,"code":"it('no params should return help', async () => {\n  const commandInstance = DbCommand.new({})\n  const spy = jest\n    .spyOn(commandInstance, 'help')\n    .mockImplementation(() => 'Help Me')\n\n  await commandInstance.parse([])\n  expect(spy).toHaveBeenCalledTimes(1)\n  spy.mockRestore()\n})","file":"DbCommand.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"wrong flag","suites":[],"updatePoint":{"line":15,"column":14},"line":15,"code":"it('wrong flag', async () => {\n  const commandInstance = DbCommand.new({})\n  const spy = jest\n    .spyOn(commandInstance, 'help')\n    .mockImplementation(() => 'Help Me')\n\n  await commandInstance.parse(['--something'])\n  expect(spy).toHaveBeenCalledTimes(1)\n  spy.mockRestore()\n})","file":"DbCommand.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"help flag","suites":[],"updatePoint":{"line":26,"column":13},"line":26,"code":"it('help flag', async () => {\n  const commandInstance = DbCommand.new({})\n  const spy = jest\n    .spyOn(commandInstance, 'help')\n    .mockImplementation(() => 'Help Me')\n\n  await commandInstance.parse(['--help'])\n  expect(spy).toHaveBeenCalledTimes(1)\n  spy.mockRestore()\n})","file":"DbCommand.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"unknown command","suites":[],"updatePoint":{"line":37,"column":19},"line":37,"code":"it('unknown command', async () => {\n  await expect(\n    DbCommand.new({}).parse(['doesnotexist']),\n  ).resolves.toThrowError()\n})","file":"DbCommand.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"db seed with --preview-feature flag","suites":[],"updatePoint":{"line":43,"column":39},"line":43,"code":"it('db seed with --preview-feature flag', async () => {\n  await expect(\n    DbCommand.new({\n      dev: DbSeed.new(),\n    }).parse(['dev', '--preview-feature']),\n  ).rejects.toThrowError()\n})","file":"DbCommand.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"db seed without --preview-feature flag","suites":[],"updatePoint":{"line":51,"column":42},"line":51,"code":"it('db seed without --preview-feature flag', async () => {\n  await expect(\n    DbCommand.new({\n      dev: DbSeed.new(),\n    }).parse(['dev']),\n  ).rejects.toThrowError()\n})","file":"DbCommand.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"requires --preview-feature flag","suites":[],"updatePoint":{"line":13,"column":37},"line":13,"code":"  it('requires --preview-feature flag', async () => {\n    ctx.fixture('empty')\n\n    const result = DbDrop.new().parse([])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            This feature is currently in Preview. There may be bugs and it's not recommended to use it in production environments.\n            Please provide the --preview-feature flag to use this command.\n          `)\n  })","file":"DbDrop.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if no schema file","suites":[],"updatePoint":{"line":23,"column":35},"line":23,"code":"  it('should fail if no schema file', async () => {\n    ctx.fixture('empty')\n\n    const result = DbDrop.new().parse(['--preview-feature'])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n                      Could not find a schema.prisma file that is required for this command.\n                      You can either provide it with --schema, set it as \\`prisma.schema\\` in your package.json or put it into the default location ./prisma/schema.prisma https://pris.ly/d/prisma-schema-location\n                  `)\n  })","file":"DbDrop.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"with missing db should fail (prompt)","suites":[],"updatePoint":{"line":33,"column":42},"line":33,"code":"  it('with missing db should fail (prompt)', async () => {\n    ctx.fixture('reset')\n    ctx.fs.remove('prisma/dev.db')\n\n    prompt.inject(['y']) // simulate user yes input\n\n    const result = DbDrop.new().parse(['--preview-feature'])\n    await expect(result).rejects.toMatchInlineSnapshot(`The database name entered \"y\" doesn't match \"dev.db\".`)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbDrop.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"with missing db should fail (--force)","suites":[],"updatePoint":{"line":44,"column":43},"line":44,"code":"  it('with missing db should fail (--force)', async () => {\n    ctx.fixture('reset')\n    ctx.fs.remove('prisma/dev.db')\n\n    const result = DbDrop.new().parse(['--preview-feature', '--force'])\n    await expect(result).rejects.toMatchInlineSnapshot(`\nMigration engine error:\nFailed to delete SQLite database at \\`dev.db\\`.\nNo such file or directory (os error 2)\n\n`)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbDrop.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should work (prompt)","suites":[],"updatePoint":{"line":58,"column":26},"line":58,"code":"  it('should work (prompt)', async () => {\n    ctx.fixture('reset')\n\n    prompt.inject(['dev.db']) // simulate user input\n\n    const result = DbDrop.new().parse(['--preview-feature'])\n    await expect(result).resolves.toMatchInlineSnapshot(`\n            🚀  The SQLite database \"dev.db\" from \"file:dev.db\" was successfully dropped.\n\n          `)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbDrop.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should work (--force)","suites":[],"updatePoint":{"line":77,"column":27},"line":77,"code":"  it('should work (--force)', async () => {\n    ctx.fixture('reset')\n\n    const result = DbDrop.new().parse(['--preview-feature', '--force'])\n    await expect(result).resolves.toMatchInlineSnapshot(`\n            🚀  The SQLite database \"dev.db\" from \"file:dev.db\" was successfully dropped.\n\n          `)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbDrop.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should work (-f)","suites":[],"updatePoint":{"line":93,"column":22},"line":93,"code":"  it('should work (-f)', async () => {\n    ctx.fixture('reset')\n    const result = DbDrop.new().parse(['--preview-feature', '-f'])\n    await expect(result).resolves.toMatchInlineSnapshot(`\n            🚀  The SQLite database \"dev.db\" from \"file:dev.db\" was successfully dropped.\n\n          `)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbDrop.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should be cancelled (prompt)","suites":[],"updatePoint":{"line":108,"column":34},"line":108,"code":"  it('should be cancelled (prompt)', async () => {\n    ctx.fixture('reset')\n    const mockExit = jest.spyOn(process, 'exit').mockImplementation()\n\n    prompt.inject([new Error()]) // simulate cancel\n\n    const result = DbDrop.new().parse(['--preview-feature'])\n    await expect(result).resolves.toMatchInlineSnapshot(`\n            🚀  The SQLite database \"dev.db\" from \"file:dev.db\" was successfully dropped.\n\n          `)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n\n      Drop cancelled.\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(mockExit).toBeCalledWith(0)\n  })","file":"DbDrop.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should ask for --force if not provided if CI","suites":[],"updatePoint":{"line":130,"column":50},"line":130,"code":"  it('should ask for --force if not provided if CI', async () => {\n    ctx.fixture('reset')\n    const result = DbDrop.new().parse(['--preview-feature'])\n    await expect(result).rejects.toMatchInlineSnapshot(\n      `Use the --force flag to use the drop command in an unnattended environment like prisma db drop --force --preview-feature`,\n    )\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbDrop.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"basic introspection","suites":["common/sqlite"],"updatePoint":{"line":20,"column":27},"line":20,"code":"  test('basic introspection', async () => {\n    ctx.fixture('introspection/sqlite')\n    const introspect = new DbPull()\n    await introspect.parse(['--print'])\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"introspection --force","suites":["common/sqlite"],"updatePoint":{"line":29,"column":29},"line":29,"code":"  test('introspection --force', async () => {\n    ctx.fixture('introspection/sqlite')\n    const introspect = new DbPull()\n    await introspect.parse(['--print', '--force'])\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"basic introspection with invalid --url","suites":["common/sqlite"],"updatePoint":{"line":52,"column":46},"line":52,"code":"  test('basic introspection with invalid --url', async () => {\n    ctx.fixture('introspection/sqlite')\n    const introspect = new DbPull()\n    const result = introspect.parse(['--print', '--url', 'invalidstring'])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`Unknown database type invalidstring:`)\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should succeed when schema and db do match","suites":["common/sqlite"],"updatePoint":{"line":62,"column":48},"line":62,"code":"  it('should succeed when schema and db do match', async () => {\n    ctx.fixture('introspect/prisma')\n    const result = DbPull.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n').replace(/\\d{2,3}ms/, 'XXms')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from schema.prisma\n      Datasource \"db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      Introspecting based on datasource defined in schema.prisma …\n\n      ✔ Introspected 3 models and wrote them into schema.prisma in XXXms\n            \n      Run prisma generate to generate Prisma Client.\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"basic introspection with invalid --url - empty host","suites":["common/sqlite"],"updatePoint":{"line":104,"column":59},"line":104,"code":"  test('basic introspection with invalid --url - empty host', async () => {\n    const introspect = new DbPull()\n    const result = introspect.parse(['--print', '--url', 'postgresql://root:prisma@/prisma'])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n                      Error parsing connection string: empty host in database URL\n\n                  `)\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should succeed and keep changes to valid schema and output warnings","suites":["common/sqlite"],"updatePoint":{"line":116,"column":73},"line":116,"code":"  it('should succeed and keep changes to valid schema and output warnings', async () => {\n    ctx.fixture('introspect')\n    const result = DbPull.new().parse(['--schema=./prisma/reintrospection.prisma'])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n').replace(/\\d{2,3}ms/, 'in XXms')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/reintrospection.prisma\n      Datasource \"db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      Introspecting based on datasource defined in prisma/reintrospection.prisma …\n\n      ✔ Introspected 3 models and wrote them into prisma/reintrospection.prisma in XXXms\n            \n      *** WARNING ***\n\n      These models were enriched with \\`@@map\\` information taken from the previous Prisma schema.\n      - Model \"AwesomeNewPost\"\n      - Model \"AwesomeProfile\"\n      - Model \"AwesomeUser\"\n\n      Run prisma generate to generate Prisma Client.\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n\n    expect(ctx.fs.read('prisma/reintrospection.prisma')).toMatchInlineSnapshot(`\n      generator client {\n        provider = \"prisma-client-js\"\n        output   = \"../generated/client\"\n      }\n\n      datasource db {\n        provider = \"sqlite\"\n        url      = \"file:dev.db\"\n      }\n\n      model AwesomeUser {\n        email    String           @unique(map: \"User.email\")\n        id       Int              @id @default(autoincrement())\n        name     String?\n        newPosts AwesomeNewPost[]\n        profile  AwesomeProfile?\n\n        @@map(\"User\")\n      }\n\n      model AwesomeNewPost {\n        authorId  Int\n        content   String?\n        createdAt DateTime    @default(now())\n        id        Int         @id @default(autoincrement())\n        published Boolean     @default(false)\n        title     String\n        author    AwesomeUser @relation(fields: [authorId], references: [id], onDelete: Cascade)\n\n        @@map(\"Post\")\n      }\n\n      model AwesomeProfile {\n        bio    String?\n        id     Int         @id @default(autoincrement())\n        userId Int         @unique(map: \"Profile.userId\")\n        user   AwesomeUser @relation(fields: [userId], references: [id], onDelete: Cascade)\n\n        @@map(\"Profile\")\n      }\n\n    `)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should succeed and keep changes to valid schema and output warnings when using --print","suites":["common/sqlite"],"updatePoint":{"line":186,"column":92},"line":186,"code":"  it('should succeed and keep changes to valid schema and output warnings when using --print', async () => {\n    ctx.fixture('introspect')\n    const originalSchema = ctx.fs.read('prisma/reintrospection.prisma')\n    const result = DbPull.new().parse(['--print', '--schema=./prisma/reintrospection.prisma'])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n').replace(/\\d{2,3}ms/, 'in XXms')).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n\n                                                                                                              // *** WARNING ***\n                                                                                                              // \n                                                                                                              // These models were enriched with \\`@@map\\` information taken from the previous Prisma schema.\n                                                                                                              // - Model \"AwesomeNewPost\"\n                                                                                                              // - Model \"AwesomeProfile\"\n                                                                                                              // - Model \"AwesomeUser\"\n                                                                                                              // \n                                                                        `)\n\n    expect(ctx.fs.read('prisma/reintrospection.prisma')).toStrictEqual(originalSchema)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should succeed when schema and db do not match","suites":["common/sqlite"],"updatePoint":{"line":208,"column":52},"line":208,"code":"  it('should succeed when schema and db do not match', async () => {\n    ctx.fixture('existing-db-histories-diverge')\n    const result = DbPull.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n').replace(/\\d{2,3}ms/, 'in XXms')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      Introspecting based on datasource defined in prisma/schema.prisma …\n\n      ✔ Introspected 3 models and wrote them into prisma/schema.prisma in XXXms\n            \n      Run prisma generate to generate Prisma Client.\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail when db is missing","suites":["common/sqlite"],"updatePoint":{"line":227,"column":36},"line":227,"code":"  it('should fail when db is missing', async () => {\n    ctx.fixture('schema-only-sqlite')\n    const result = DbPull.new().parse([])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n\n                        P4001 The introspected database was empty: \n\n                        prisma db pull could not create any models in your schema.prisma file and you will not be able to generate Prisma Client with the prisma generate command.\n\n                        To fix this, you have two options:\n\n                        - manually create a table in your database.\n                        - make sure the database connection URL inside the datasource block in schema.prisma points to a database that is not empty (it must contain at least one table).\n\n                        Then you can run prisma db pull again. \n\n                    `)\n\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      Introspecting based on datasource defined in prisma/schema.prisma …\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail when db is empty","suites":["common/sqlite"],"updatePoint":{"line":255,"column":34},"line":255,"code":"  it('should fail when db is empty', async () => {\n    ctx.fixture('schema-only-sqlite')\n    ctx.fs.write('prisma/dev.db', '')\n    const result = DbPull.new().parse([])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n\n                        P4001 The introspected database was empty: \n\n                        prisma db pull could not create any models in your schema.prisma file and you will not be able to generate Prisma Client with the prisma generate command.\n\n                        To fix this, you have two options:\n\n                        - manually create a table in your database.\n                        - make sure the database connection URL inside the datasource block in schema.prisma points to a database that is not empty (it must contain at least one table).\n\n                        Then you can run prisma db pull again. \n\n                    `)\n\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      Introspecting based on datasource defined in prisma/schema.prisma …\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail when Prisma schema is missing","suites":["common/sqlite"],"updatePoint":{"line":284,"column":47},"line":284,"code":"  it('should fail when Prisma schema is missing', async () => {\n    const result = DbPull.new().parse([])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n                      Could not find a schema.prisma file that is required for this command.\n                      You can either provide it with --schema, set it as \\`prisma.schema\\` in your package.json or put it into the default location ./prisma/schema.prisma https://pris.ly/d/prisma-schema-location\n                  `)\n\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail when schema is invalid","suites":["common/sqlite"],"updatePoint":{"line":296,"column":40},"line":296,"code":"  it('should fail when schema is invalid', async () => {\n    ctx.fixture('introspect')\n    const result = DbPull.new().parse(['--schema=./prisma/invalid.prisma'])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            P1012 Introspection failed as your current Prisma schema file is invalid\n\n            Please fix your current schema manually, use prisma validate to confirm it is valid and then run this command again.\n            Or run this command with the --force flag to ignore your current schema and overwrite it. All local modifications will be lost.\n\n          `)\n\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/invalid.prisma\n      Datasource \"db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      Introspecting based on datasource defined in prisma/invalid.prisma …\n\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should succeed when schema is invalid and using --force","suites":["common/sqlite"],"updatePoint":{"line":318,"column":61},"line":318,"code":"  it('should succeed when schema is invalid and using --force', async () => {\n    ctx.fixture('introspect')\n\n    const result = DbPull.new().parse(['--schema=./prisma/invalid.prisma', '--force'])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n').replace(/\\d{2,3}ms/, 'in XXms')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/invalid.prisma\n      Datasource \"db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      Introspecting based on datasource defined in prisma/invalid.prisma …\n\n      ✔ Introspected 3 models and wrote them into prisma/invalid.prisma in XXXms\n            \n      Run prisma generate to generate Prisma Client.\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n\n    expect(ctx.fs.read('prisma/invalid.prisma')).toMatchSnapshot()\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"basic introspection","suites":["postgresql"],"updatePoint":{"line":365,"column":27},"line":365,"code":"  test('basic introspection', async () => {\n    ctx.fixture('introspection/postgresql')\n    const introspect = new DbPull()\n    await introspect.parse(['--print'])\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"basic introspection --url","suites":["postgresql"],"updatePoint":{"line":374,"column":33},"line":374,"code":"  test('basic introspection --url', async () => {\n    const introspect = new DbPull()\n    const result = introspect.parse(['--print', '--url', setupParams.connectionString])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"basic introspection","suites":["mysql"],"updatePoint":{"line":408,"column":27},"line":408,"code":"  test('basic introspection', async () => {\n    ctx.fixture('introspection/mysql')\n    const introspect = new DbPull()\n    await introspect.parse(['--print'])\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"basic introspection","suites":["mysql"],"updatePoint":{"line":460,"column":27},"line":460,"code":"  test('basic introspection', async () => {\n    ctx.fixture('introspection/sqlserver')\n    const introspect = new DbPull()\n    await introspect.parse(['--print'])\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"basic introspection --url","suites":["mysql"],"updatePoint":{"line":469,"column":33},"line":469,"code":"  test('basic introspection --url', async () => {\n    const introspect = new DbPull()\n    const result = introspect.parse(['--print', '--url', JDBC_URI])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"basic introspection","suites":["mysql"],"updatePoint":{"line":485,"column":27},"line":485,"code":"  test('basic introspection', async () => {\n    ctx.fixture('schema-only-mongodb')\n    const introspect = new DbPull()\n    await introspect.parse(['--schema=./prisma/no-model.prisma'])\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/no-model.prisma\n      Datasource \"my_db\"\n\n      Introspecting based on datasource defined in prisma/no-model.prisma …\n\n      ✔ Introspected 1 model and wrote it into prisma/no-model.prisma in XXXms\n            \n      Run prisma generate to generate Prisma Client.\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"introspection --print","suites":["mysql"],"updatePoint":{"line":503,"column":29},"line":503,"code":"  test('introspection --print', async () => {\n    ctx.fixture('schema-only-mongodb')\n    const introspect = new DbPull()\n    await introspect.parse(['--print'])\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"introspection --print --composite-type-depth=0","suites":["mysql"],"updatePoint":{"line":512,"column":54},"line":512,"code":"  test('introspection --print --composite-type-depth=0', async () => {\n    ctx.fixture('schema-only-mongodb')\n    const introspect = new DbPull()\n    await introspect.parse(['--print', '--composite-type-depth=0'])\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"introspection --print --composite-type-depth=1","suites":["mysql"],"updatePoint":{"line":521,"column":54},"line":521,"code":"  test('introspection --print --composite-type-depth=1', async () => {\n    ctx.fixture('schema-only-mongodb')\n    const introspect = new DbPull()\n    await introspect.parse(['--print', '--composite-type-depth=1'])\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"introspection --print --composite-type-depth=-1","suites":["mysql"],"updatePoint":{"line":530,"column":55},"line":530,"code":"  test('introspection --print --composite-type-depth=-1', async () => {\n    ctx.fixture('schema-only-mongodb')\n    const introspect = new DbPull()\n    await introspect.parse(['--print', '--composite-type-depth=-1'])\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"basic introspection --url","suites":["mysql"],"updatePoint":{"line":539,"column":33},"line":539,"code":"  test('basic introspection --url', async () => {\n    const introspect = new DbPull()\n    const result = introspect.parse(['--print', '--url', MONGO_URI])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            Preview feature not enabled: MongoDB introspection connector (experimental feature, needs to be enabled)\n\n          `)\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"introspection with --force","suites":["mysql"],"updatePoint":{"line":551,"column":34},"line":551,"code":"  test('introspection with --force', async () => {\n    ctx.fixture('schema-only-mongodb')\n    const introspect = new DbPull()\n    const result = introspect.parse(['--force'])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\"\n\n      Introspecting based on datasource defined in prisma/schema.prisma …\n\n      ✔ Introspected 1 model and wrote it into prisma/schema.prisma in XXXms\n            \n      Run prisma generate to generate Prisma Client.\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"re-introspection should error (not supported)","suites":["mysql"],"updatePoint":{"line":570,"column":53},"line":570,"code":"  test('re-introspection should error (not supported)', async () => {\n    ctx.fixture('schema-only-mongodb')\n    const introspect = new DbPull()\n    await introspect.parse(['--schema=./prisma/no-model.prisma'])\n    // now re-introspection\n    const result = introspect.parse(['--schema=./prisma/no-model.prisma'])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            Iterating on one schema using re-introspection with db pull is currently not supported with MongoDB provider (Preview).\n            You can explicitely ignore and override your current local schema file with prisma db pull --force\n            Some information will be lost (relations, comments, mapped fields, @ignore...), follow https://github.com/prisma/prisma/issues/9585 for more info.\n          `)\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/no-model.prisma\n      Datasource \"my_db\"\n\n      Introspecting based on datasource defined in prisma/no-model.prisma …\n\n      ✔ Introspected 1 model and wrote it into prisma/no-model.prisma in XXXms\n            \n      Run prisma generate to generate Prisma Client.\n      Prisma schema loaded from prisma/no-model.prisma\n      Datasource \"my_db\"\n\n      Introspecting based on datasource defined in prisma/no-model.prisma …\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPull.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"--preview-feature flag is not required anymore","suites":[],"updatePoint":{"line":14,"column":52},"line":14,"code":"  it('--preview-feature flag is not required anymore', async () => {\n    ctx.fixture('empty')\n\n    const result = DbPush.new().parse(['--preview-feature'])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            Could not find a schema.prisma file that is required for this command.\n            You can either provide it with --schema, set it as \\`prisma.schema\\` in your package.json or put it into the default location ./prisma/schema.prisma https://pris.ly/d/prisma-schema-location\n          `)\n    expect(ctx.mocked['console.warn'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      prisma:warn Prisma \"db push\" was in Preview and is now Generally Available.\n      You can now remove the --preview-feature flag.\n    `)\n  })","file":"DbPush.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if no schema file","suites":[],"updatePoint":{"line":28,"column":35},"line":28,"code":"  it('should fail if no schema file', async () => {\n    ctx.fixture('empty')\n\n    const result = DbPush.new().parse([])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n                      Could not find a schema.prisma file that is required for this command.\n                      You can either provide it with --schema, set it as \\`prisma.schema\\` in your package.json or put it into the default location ./prisma/schema.prisma https://pris.ly/d/prisma-schema-location\n                  `)\n  })","file":"DbPush.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if nativeTypes VarChar on sqlite","suites":[],"updatePoint":{"line":38,"column":50},"line":38,"code":"  it('should fail if nativeTypes VarChar on sqlite', async () => {\n    ctx.fixture('nativeTypes-sqlite')\n    const result = DbPush.new().parse([])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            P1012\n\n            error: Native type VarChar is not supported for sqlite connector.\n              -->  schema.prisma:12\n               | \n            11 |   id   Int    @id\n            12 |   name String @db.VarChar(100)\n               | \n\n\n          `)\n  })","file":"DbPush.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"--force flag renamed","suites":[],"updatePoint":{"line":55,"column":26},"line":55,"code":"  it('--force flag renamed', async () => {\n    ctx.fixture('reset')\n    const result = DbPush.new().parse(['--force'])\n    await expect(result).rejects.toMatchInlineSnapshot(\n      `The --force flag was renamed to --accept-data-loss in 2.17.0, use prisma db push --accept-data-loss`,\n    )\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPush.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"already in sync","suites":[],"updatePoint":{"line":65,"column":21},"line":65,"code":"  it('already in sync', async () => {\n    ctx.fixture('reset')\n    const result = DbPush.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      🚀  Your database is now in sync with your schema. Done in XXXms\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPush.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"missing db","suites":[],"updatePoint":{"line":78,"column":16},"line":78,"code":"  it('missing db', async () => {\n    ctx.fixture('reset')\n    ctx.fs.remove('prisma/dev.db')\n\n    const result = DbPush.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      SQLite database dev.db created at file:dev.db\n\n      🚀  Your database is now in sync with your schema. Done in XXXms\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPush.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should ask for --accept-data-loss if not provided in CI","suites":[],"updatePoint":{"line":95,"column":61},"line":95,"code":"  it('should ask for --accept-data-loss if not provided in CI', async () => {\n    ctx.fixture('existing-db-warnings')\n    const result = DbPush.new().parse([])\n    await expect(result).rejects.toMatchInlineSnapshot(\n      `Use the --accept-data-loss flag to ignore the data loss warnings like prisma db push --accept-data-loss`,\n    )\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPush.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"dataloss warnings accepted (prompt)","suites":[],"updatePoint":{"line":105,"column":41},"line":105,"code":"  it('dataloss warnings accepted (prompt)', async () => {\n    ctx.fixture('existing-db-warnings')\n\n    prompt.inject(['y'])\n\n    const result = DbPush.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      ⚠️  There might be data loss when applying the changes:\n\n        • You are about to drop the \\`Blog\\` table, which is not empty (1 rows).\n\n\n\n      🚀  Your database is now in sync with your schema. Done in XXXms\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPush.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"dataloss warnings cancelled (prompt)","suites":[],"updatePoint":{"line":127,"column":42},"line":127,"code":"  it('dataloss warnings cancelled (prompt)', async () => {\n    ctx.fixture('existing-db-warnings')\n    const mockExit = jest.spyOn(process, 'exit').mockImplementation()\n\n    prompt.inject([new Error()]) // simulate user cancellation\n\n    const result = DbPush.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      ⚠️  There might be data loss when applying the changes:\n\n        • You are about to drop the \\`Blog\\` table, which is not empty (1 rows).\n\n\n      Push cancelled.\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(mockExit).toBeCalledWith(0)\n  })","file":"DbPush.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"--accept-data-loss flag","suites":[],"updatePoint":{"line":150,"column":29},"line":150,"code":"  it('--accept-data-loss flag', async () => {\n    ctx.fixture('existing-db-warnings')\n    const result = DbPush.new().parse(['--accept-data-loss'])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      ⚠️  There might be data loss when applying the changes:\n\n        • You are about to drop the \\`Blog\\` table, which is not empty (1 rows).\n\n\n      🚀  Your database is now in sync with your schema. Done in XXXms\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPush.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"unexecutable - drop accepted (prompt)","suites":[],"updatePoint":{"line":168,"column":43},"line":168,"code":"  it('unexecutable - drop accepted (prompt)', async () => {\n    ctx.fixture('existing-db-1-unexecutable-schema-change')\n\n    prompt.inject(['y'])\n\n    const result = DbPush.new().parse([])\n\n    const sqliteDbSizeBefore = ctx.fs.inspect('prisma/dev.db')!.size\n\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n\n    const sqliteDbSizeAfter = ctx.fs.inspect('prisma/dev.db')!.size\n\n    expect(sqliteDbSizeBefore).toBeGreaterThan(10000)\n    expect(sqliteDbSizeAfter).toBeGreaterThan(10000)\n    expect(sqliteDbSizeAfter).toBeLessThan(sqliteDbSizeBefore)\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n\n      ⚠️ We found changes that cannot be executed:\n\n        • Made the column \\`fullname\\` on table \\`Blog\\` required, but there are 1 existing NULL values.\n\n\n      The SQLite database \"dev.db\" from \"file:dev.db\" was successfully reset.\n\n      🚀  Your database is now in sync with your schema. Done in XXXms\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPush.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"unexecutable - drop cancelled (prompt)","suites":[],"updatePoint":{"line":202,"column":44},"line":202,"code":"  it('unexecutable - drop cancelled (prompt)', async () => {\n    ctx.fixture('existing-db-warnings')\n    const mockExit = jest.spyOn(process, 'exit').mockImplementation()\n\n    prompt.inject([new Error()]) // simulate user cancellation\n\n    const result = DbPush.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      ⚠️  There might be data loss when applying the changes:\n\n        • You are about to drop the \\`Blog\\` table, which is not empty (1 rows).\n\n\n      Push cancelled.\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(mockExit).toBeCalledWith(0)\n  })","file":"DbPush.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"unexecutable - --force-reset","suites":[],"updatePoint":{"line":225,"column":34},"line":225,"code":"  it('unexecutable - --force-reset', async () => {\n    ctx.fixture('existing-db-1-unexecutable-schema-change')\n    const result = DbPush.new().parse(['--force-reset'])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      The SQLite database \"dev.db\" from \"file:dev.db\" was successfully reset.\n\n      🚀  Your database is now in sync with your schema. Done in XXXms\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPush.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"unexecutable - should ask for --force-reset in CI","suites":[],"updatePoint":{"line":240,"column":55},"line":240,"code":"  it('unexecutable - should ask for --force-reset in CI', async () => {\n    ctx.fixture('existing-db-1-unexecutable-schema-change')\n    const result = DbPush.new().parse([])\n    await expect(result).rejects.toMatchInlineSnapshot(`\n\n                                                                        ⚠️ We found changes that cannot be executed:\n\n                                                                          • Made the column \\`fullname\\` on table \\`Blog\\` required, but there are 1 existing NULL values.\n\n                                                                        Use the --force-reset flag to drop the database before push like prisma db push --force-reset\n                                                                        All data will be lost.\n                                                                                \n                                                            `)\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbPush.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"seed.js","suites":[],"updatePoint":{"line":12,"column":13},"line":12,"code":"  it('seed.js', async () => {\n    ctx.fixture('seed-sqlite-js')\n\n    const result = DbSeed.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(`\n\n                                                                                                                                                                                                                                                🌱  The seed command has been executed.\n                                                                                                                                                                                                        `)\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(\n      `Running seed command \\`node prisma/seed.js\\` ...`,\n    )\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbSeed.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"one broken seed.js file","suites":[],"updatePoint":{"line":28,"column":29},"line":28,"code":"  it('one broken seed.js file', async () => {\n    const mockExit = jest.spyOn(process, 'exit').mockImplementation()\n\n    ctx.fixture('seed-sqlite-js')\n    fs.write('prisma/seed.js', 'BROKEN_CODE_SHOULD_ERROR;')\n\n    const result = DbSeed.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(\n      `Running seed command \\`node prisma/seed.js\\` ...`,\n    )\n    expect(ctx.mocked['console.error'].mock.calls.join()).toContain('An error occured while running the seed command:')\n    expect(mockExit).toBeCalledWith(1)\n  })","file":"DbSeed.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"seed.ts","suites":[],"updatePoint":{"line":43,"column":13},"line":43,"code":"  it('seed.ts', async () => {\n    ctx.fixture('seed-sqlite-ts')\n\n    const result = DbSeed.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(`\n\n                                                                                                                                                                                                                                                                        🌱  The seed command has been executed.\n                                                                                                                                                                                                                            `)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(\n      `Running seed command \\`ts-node prisma/seed.ts\\` ...`,\n    )\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbSeed.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"seed.ts - ESM","suites":[],"updatePoint":{"line":57,"column":19},"line":57,"code":"  it('seed.ts - ESM', async () => {\n    ctx.fixture('seed-sqlite-ts-esm')\n\n    // Needs ts-node to be installed\n    await execa.command('npm i')\n\n    const result = DbSeed.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(`\n\n                                                                                                                                                                                                                                                                        🌱  The seed command has been executed.\n                                                                                                                                                                                                                            `)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(\n      `Running seed command \\`node --loader ts-node/esm prisma/seed.ts\\` ...`,\n    )\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n\n    // \"high\" number since npm install can sometimes be slow\n  }, 20000)","file":"DbSeed.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"seed.sh","suites":[],"updatePoint":{"line":76,"column":13},"line":76,"code":"  it('seed.sh', async () => {\n    ctx.fixture('seed-sqlite-sh')\n\n    const result = DbSeed.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(`\n\n                                                                                                                                                                                                                                                                        🌱  The seed command has been executed.\n                                                                                                                                                                                                                            `)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(\n      `Running seed command \\`./prisma/seed.sh\\` ...`,\n    )\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbSeed.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"no seed file","suites":[],"updatePoint":{"line":92,"column":18},"line":92,"code":"  it('no seed file', async () => {\n    ctx.fixture('seed-sqlite-legacy')\n    ctx.fs.remove('prisma/seed.js')\n    ctx.fs.remove('prisma/seed.ts')\n    ctx.fs.remove('prisma/seed.sh')\n\n    try {\n      await DbSeed.new().parse([])\n    } catch (e) {\n      expect(e).toMatchInlineSnapshot(`\n        To configure seeding in your project you need to add a \"prisma.seed\" property in your package.json with the command to execute it:\n\n        1. Open the package.json of your project\n        2. Add one of the following examples to your package.json:\n\n        TypeScript:\n        \\`\\`\\`\n        \"prisma\": {\n          \"seed\": \"ts-node ./prisma/seed.ts\"\n        }\n        \\`\\`\\`\n        If you are using ESM (ECMAScript modules):\n        \\`\\`\\`\n        \"prisma\": {\n          \"seed\": \"node --loader ts-node/esm ./prisma/seed.ts\"\n        }\n        \\`\\`\\`\n\n        And install the required dependencies by running:\n        npm i -D ts-node typescript @types/node\n\n        JavaScript:\n        \\`\\`\\`\n        \"prisma\": {\n          \"seed\": \"node ./prisma/seed.js\"\n        }\n        \\`\\`\\`\n\n        Bash:\n        \\`\\`\\`\n        \"prisma\": {\n          \"seed\": \"./prisma/seed.sh\"\n        }\n        \\`\\`\\`\n        And run \\`chmod +x prisma/seed.sh\\` to make it executable.\n        More information in our documentation:\n        https://pris.ly/d/seeding\n      `)\n    }\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbSeed.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"more than one seed file","suites":[],"updatePoint":{"line":146,"column":29},"line":146,"code":"  it('more than one seed file', async () => {\n    ctx.fixture('seed-sqlite-legacy')\n\n    const result = DbSeed.new().parse([])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\nTo configure seeding in your project you need to add a \"prisma.seed\" property in your package.json with the command to execute it:\n\n1. Open the package.json of your project\n2. Add the following example to it:\n\\`\\`\\`\n\"prisma\": {\n  \"seed\": \"node prisma/seed.js\"\n}\n\\`\\`\\`\n\nMore information in our documentation:\nhttps://pris.ly/d/seeding\n`)\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbSeed.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"deprecation of --preview-feature flag","suites":[],"updatePoint":{"line":169,"column":43},"line":169,"code":"  it('deprecation of --preview-feature flag', async () => {\n    ctx.fixture('seed-sqlite-js')\n\n    const result = DbSeed.new().parse(['--preview-feature'])\n    await expect(result).resolves.toMatchInlineSnapshot(`\n\n                                                                        🌱  The seed command has been executed.\n                                                            `)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(\n      `Running seed command \\`node prisma/seed.js\\` ...`,\n    )\n    expect(ctx.mocked['console.warn'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      prisma:warn Prisma \"db seed\" was in Preview and is now Generally Available.\n      You can now remove the --preview-feature flag.\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbSeed.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"using --schema should warn","suites":[],"updatePoint":{"line":188,"column":32},"line":188,"code":"  it('using --schema should warn', async () => {\n    ctx.fixture('seed-sqlite-js')\n\n    const result = DbSeed.new().parse(['--schema=./some-folder/schema.prisma'])\n    await expect(result).resolves.toMatchInlineSnapshot(`\n\n                                                                                                                                                                                                                                                                        🌱  The seed command has been executed.\n                                                                                                                                                                                                                            `)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(\n      `Running seed command \\`node prisma/seed.js\\` ...`,\n    )\n    expect(ctx.mocked['console.warn'].mock.calls.join('\\n')).toMatchInlineSnapshot(\n      `prisma:warn The \"--schema\" parameter is not used anymore by \"prisma db seed\" since version 3.0 and can now be removed.`,\n    )\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbSeed.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"custom --schema from package.json should enrich help setup","suites":[],"updatePoint":{"line":205,"column":64},"line":205,"code":"  it('custom --schema from package.json should enrich help setup', async () => {\n    ctx.fixture('seed-sqlite-legacy-schema-from-package-json')\n\n    const result = DbSeed.new().parse([])\n    await expect(result).rejects.toMatchInlineSnapshot(`\n            To configure seeding in your project you need to add a \"prisma.seed\" property in your package.json with the command to execute it:\n\n            1. Open the package.json of your project\n            2. Add the following example to it:\n            \\`\\`\\`\n            \"prisma\": {\n              \"seed\": \"node custom-folder/seed.js\"\n            }\n            \\`\\`\\`\n\n            More information in our documentation:\n            https://pris.ly/d/seeding\n          `)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"DbSeed.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"custom ts-node should warn","suites":[],"updatePoint":{"line":227,"column":32},"line":227,"code":"  it('custom ts-node should warn', async () => {\n    ctx.fixture('seed-sqlite-legacy-custom-ts-node')\n\n    const result = DbSeed.new().parse([])\n    await expect(result).rejects.toMatchInlineSnapshot(`\n            To configure seeding in your project you need to add a \"prisma.seed\" property in your package.json with the command to execute it:\n\n            1. Open the package.json of your project\n            2. Add the following example to it:\n            \\`\\`\\`\n            \"prisma\": {\n              \"seed\": \"ts-node prisma/seed.ts\"\n            }\n            \\`\\`\\`\n            If you are using ESM (ECMAScript modules):\n            \\`\\`\\`\n            \"prisma\": {\n              \"seed\": \"node --loader ts-node/esm prisma/seed.ts\"\n            }\n            \\`\\`\\`\n\n            3. Install the required dependencies by running:\n            npm i -D ts-node typescript @types/node\n\n            More information in our documentation:\n            https://pris.ly/d/seeding\n          `)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.warn'].mock.calls.join('\\n')).toMatchInlineSnapshot(\n      `prisma:warn The \"ts-node\" script in the package.json is not used anymore since version 3.0 and can now be removed.`,\n    )\n    expect(ctx.mocked['console.error'].mock.calls.join()).toMatchInlineSnapshot(``)\n  })","file":"DbSeed.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"can create database - sqlite","suites":[],"updatePoint":{"line":7,"column":32},"line":7,"code":"it('can create database - sqlite', async () => {\n  ctx.fixture('schema-only-sqlite')\n  const schemaPath = (await getSchemaPath())!\n  const result = ensureDatabaseExists('create', true, schemaPath)\n  await expect(result).resolves.toMatchInlineSnapshot(`SQLite database dev.db created at file:dev.db`)\n})","file":"ensureDatabaseExists.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"basic serialization","suites":["getErrorMessageWithLink"],"updatePoint":{"line":5,"column":27},"line":5,"code":"  test('basic serialization', () => {\n    const message = getGithubIssueUrl({\n      title: 'This is a title',\n      body: 'This is a body',\n    })\n\n    expect(stripAnsi(message)).toMatchInlineSnapshot(\n      `https://github.com/prisma/prisma/issues/new?body=This+is+a+body&title=This+is+a+title&template=bug_report.md`,\n    )\n  })","file":"getGithubIssueUrl.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"force panic","suites":["introspection panic"],"updatePoint":{"line":5,"column":19},"line":5,"code":"  test('force panic', async () => {\n    process.env.FORCE_PANIC_INTROSPECTION_ENGINE = '1'\n    process.chdir(path.join(__dirname, 'fixtures', 'introspection', 'sqlite'))\n\n    const introspect = new DbPull()\n    try {\n      await introspect.parse(['--print'])\n    } catch (e) {\n      expect(e).toMatchInlineSnapshot(\n        `[/some/rust/path:0:0] This is the debugPanic artificial panic`,\n      )\n    }\n  })","file":"handlePanic.introspect.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"ask to submit the panic error in interactive mode","suites":["handlePanic"],"line":83,"code":"  it.skip('ask to submit the panic error in interactive mode', async () => {","file":"handlePanic.test.ts","skipped":true,"dir":"packages/migrate/src/__tests__"},{"name":"no interactive mode in CI","suites":["handlePanic"],"updatePoint":{"line":103,"column":31},"line":103,"code":"  it('no interactive mode in CI', async () => {\n    process.env.GITHUB_ACTIONS = 'maybe'\n    try {\n      await handlePanic(error, packageJsonVersion, engineVersion, command)\n    } catch (error) {\n      error.schemaPath = 'Some Schema Path'\n      expect(error).toMatchInlineSnapshot(`Some error message!`)\n      expect(JSON.stringify(error)).toMatchInlineSnapshot(\n        `{\"rustStack\":\"\",\"area\":\"LIFT_CLI\",\"schemaPath\":\"Some Schema Path\"}`,\n      )\n    }\n  })","file":"handlePanic.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"test interactive engine panic","suites":["handlePanic"],"updatePoint":{"line":116,"column":35},"line":116,"code":"  it('test interactive engine panic', async () => {\n    process.env.FORCE_PANIC_MIGRATION_ENGINE = '1'\n    const captureStdout = new CaptureStdout()\n    const files = {\n      'schema.prisma': `\n        datasource my_db {\n          provider = \"sqlite\"\n          url = \"file:./db/db_file.db\"\n          default = true\n        }\n\n        model User {\n          id Int @id\n        }\n      `,\n      'db/.keep': ``,\n    }\n    const schemaPath = join(testRootDir, Object.keys(files)[0])\n    await writeFiles(testRootDir, files)\n\n    captureStdout.startCapture()\n\n    let error\n    try {\n      const migrate = new Migrate(schemaPath)\n      await migrate.createMigration({\n        migrationsDirectoryPath: migrate.migrationsDirectoryPath,\n        migrationName: 'setup',\n        draft: false,\n        prismaSchema: migrate.getDatamodel(),\n      })\n    } catch (err) {\n      // No to send error report\n      setTimeout(() => sendKeystrokes(io).then(), 5)\n      // No to create new issue\n      setTimeout(() => sendKeystrokes(io).then(), 5)\n      // This allows this test to be run in the CI\n      try {\n        await handlePanic(err, packageJsonVersion, engineVersion, command)\n      } catch (err) {\n        error = err\n      }\n    }\n    // We use prompts.inject() for testing in our CI\n    if (isCi() && Boolean((prompt as any)._injected?.length) === false) {\n      expect(error).toMatchInlineSnapshot(`\nError in migration engine.\nReason: [/some/rust/path:0:0] This is the debugPanic artificial panic\n\nPlease create an issue with your \\`schema.prisma\\` at\nhttps://github.com/prisma/prisma/issues/new\n\n`)\n    } else {\n      const output = captureStdout.getCapturedText()\n      expect(stripAnsi(output.join('\\n'))).toMatchInlineSnapshot(`\n\n                  console.log    Oops, an unexpected error occured!    Error in migration engine.    Reason: [/some/rust/path:0:0] This is the debugPanic artificial panic        Please create an issue with your \\`schema.prisma\\` at     https://github.com/prisma/prisma/issues/new            Please help us improve Prisma by submitting an error report.    Error reports never contain personal or other sensitive information.    Learn more: https://pris.ly/d/telemetry      at panicDialog (src/utils/handlePanic.ts:25:11)\n\n                ? Submit error report › - Use arrow-keys. Return to submit.❯   Yes - Send error report once    No\n\n                ? Submit error report › - Use arrow-keys. Return to submit.    Yes❯   No - Don't send error report\n\n                ✔ Submit error report › No\n\n\n\n                ? Would you like to create a Github issue? › - Use arrow-keys. Return to submit.❯   Yes - Create a new GitHub issue    No\n\n                ? Would you like to create a Github issue? › - Use arrow-keys. Return to submit.    Yes❯   No - Don't create a new GitHub issue\n\n                ✔ Would you like to create a Github issue? › No\n\n\n            `)\n    }\n    captureStdout.stopCapture()\n  })","file":"handlePanic.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"engine panic no interactive mode in CI","suites":["handlePanic"],"updatePoint":{"line":195,"column":44},"line":195,"code":"  it('engine panic no interactive mode in CI', async () => {\n    process.env.GITHUB_ACTIONS = 'maybe'\n    process.env.FORCE_PANIC_MIGRATION_ENGINE = '1'\n\n    const files = {\n      'schema.prisma': `\n        datasource my_db {\n          provider = \"sqlite\"\n          url = \"file:./db/db_file.db\"\n          default = true\n        }\n\n        model User {\n          id Int @id\n        }\n      `,\n      'db/.keep': ``,\n    }\n    const schemaPath = join(testRootDir, Object.keys(files)[0])\n    await writeFiles(testRootDir, files)\n\n    try {\n      const migrate = new Migrate(schemaPath)\n      await migrate.createMigration({\n        migrationsDirectoryPath: migrate.migrationsDirectoryPath,\n        migrationName: 'setup',\n        draft: false,\n        prismaSchema: migrate.getDatamodel(),\n      })\n    } catch (err) {\n      expect(error).toMatchInlineSnapshot(`Some error message!`)\n      expect(JSON.stringify(error)).toMatchInlineSnapshot(\n        `{\"rustStack\":\"\",\"area\":\"LIFT_CLI\",\"schemaPath\":\"Some Schema Path\"}`,\n      )\n    }\n  })","file":"handlePanic.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"no params should return help","suites":[],"updatePoint":{"line":4,"column":32},"line":4,"code":"it('no params should return help', async () => {\n  const commandInstance = MigrateCommand.new({})\n  const spy = jest\n    .spyOn(commandInstance, 'help')\n    .mockImplementation(() => 'Help Me')\n\n  await commandInstance.parse([])\n  expect(spy).toHaveBeenCalledTimes(1)\n  spy.mockRestore()\n})","file":"MigrateCommand.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"wrong flag","suites":[],"updatePoint":{"line":15,"column":14},"line":15,"code":"it('wrong flag', async () => {\n  const commandInstance = MigrateCommand.new({})\n  const spy = jest\n    .spyOn(commandInstance, 'help')\n    .mockImplementation(() => 'Help Me')\n\n  await commandInstance.parse(['--something'])\n  expect(spy).toHaveBeenCalledTimes(1)\n  spy.mockRestore()\n})","file":"MigrateCommand.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"help flag","suites":[],"updatePoint":{"line":26,"column":13},"line":26,"code":"it('help flag', async () => {\n  const commandInstance = MigrateCommand.new({})\n  const spy = jest\n    .spyOn(commandInstance, 'help')\n    .mockImplementation(() => 'Help Me')\n\n  await commandInstance.parse(['--help'])\n  expect(spy).toHaveBeenCalledTimes(1)\n  spy.mockRestore()\n})","file":"MigrateCommand.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"unknown command","suites":[],"updatePoint":{"line":37,"column":19},"line":37,"code":"it('unknown command', async () => {\n  await expect(\n    MigrateCommand.new({}).parse(['doesnotexist']),\n  ).resolves.toThrowError()\n})","file":"MigrateCommand.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"dev with --preview-feature flag","suites":[],"updatePoint":{"line":43,"column":35},"line":43,"code":"it('dev with --preview-feature flag', async () => {\n  await expect(\n    MigrateCommand.new({\n      dev: MigrateDev.new(),\n    }).parse(['dev', '--preview-feature']),\n  ).rejects.toMatchInlineSnapshot(`\n          Could not find a schema.prisma file that is required for this command.\n          You can either provide it with --schema, set it as \\`prisma.schema\\` in your package.json or put it into the default location ./prisma/schema.prisma https://pris.ly/d/prisma-schema-location\n        `)\n})","file":"MigrateCommand.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"experimental flag","suites":["legacy"],"updatePoint":{"line":55,"column":23},"line":55,"code":"  it('experimental flag', async () => {\n    await expect(MigrateCommand.new({}).parse(['--experimental'])).rejects\n      .toMatchInlineSnapshot(`\n            Prisma Migrate was Experimental and is now Generally Available.\n            WARNING this new version has some breaking changes to use it it's recommended to read the documentation first and remove the --experimental flag.\n          `)\n  })","file":"MigrateCommand.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"up command","suites":["legacy"],"updatePoint":{"line":63,"column":16},"line":63,"code":"  it('up command', async () => {\n    await expect(MigrateCommand.new({}).parse(['up'])).rejects\n      .toMatchInlineSnapshot(`\n            The current command \"up\" doesn't exist in the new version of Prisma Migrate.\n            Read more about how to upgrade: https://pris.ly/d/migrate-upgrade\n          `)\n  })","file":"MigrateCommand.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"down command","suites":["legacy"],"updatePoint":{"line":71,"column":18},"line":71,"code":"  it('down command', async () => {\n    await expect(MigrateCommand.new({}).parse(['down'])).rejects\n      .toMatchInlineSnapshot(`\n            The current command \"down\" doesn't exist in the new version of Prisma Migrate.\n            Read more about how to upgrade: https://pris.ly/d/migrate-upgrade\n          `)\n  })","file":"MigrateCommand.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"save command","suites":["legacy"],"updatePoint":{"line":79,"column":18},"line":79,"code":"  it('save command', async () => {\n    await expect(MigrateCommand.new({}).parse(['save'])).rejects\n      .toMatchInlineSnapshot(`\n            The current command \"save\" doesn't exist in the new version of Prisma Migrate.\n            Read more about how to upgrade: https://pris.ly/d/migrate-upgrade\n          `)\n  })","file":"MigrateCommand.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if no schema file","suites":["common"],"updatePoint":{"line":10,"column":35},"line":10,"code":"  it('should fail if no schema file', async () => {\n    ctx.fixture('empty')\n    const result = MigrateDeploy.new().parse([])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            Could not find a schema.prisma file that is required for this command.\n            You can either provide it with --schema, set it as \\`prisma.schema\\` in your package.json or put it into the default location ./prisma/schema.prisma https://pris.ly/d/prisma-schema-location\n          `)\n  })","file":"MigrateDeploy.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if experimental flag","suites":["common"],"updatePoint":{"line":18,"column":38},"line":18,"code":"  it('should fail if experimental flag', async () => {\n    ctx.fixture('empty')\n    const result = MigrateDeploy.new().parse(['--experimental'])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            Prisma Migrate was Experimental and is now Generally Available.\n            WARNING this new version has some breaking changes to use it it's recommended to read the documentation first and remove the --experimental flag.\n          `)\n  })","file":"MigrateDeploy.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if early access flag","suites":["common"],"updatePoint":{"line":26,"column":38},"line":26,"code":"  it('should fail if early access flag', async () => {\n    ctx.fixture('empty')\n    const result = MigrateDeploy.new().parse(['--early-access-feature'])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            Prisma Migrate was in Early Access and is now in Preview.\n            Replace the --early-access-feature flag with --preview-feature.\n          `)\n  })","file":"MigrateDeploy.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"no unapplied migrations","suites":["sqlite"],"updatePoint":{"line":37,"column":29},"line":37,"code":"  it('no unapplied migrations', async () => {\n    ctx.fixture('schema-only-sqlite')\n    const result = MigrateDeploy.new().parse(['--schema=./prisma/empty.prisma'])\n    await expect(result).resolves.toMatchInlineSnapshot(\n      `No pending migrations to apply.`,\n    )\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n'))\n      .toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/empty.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      SQLite database dev.db created at file:dev.db\n\n      No migration found in prisma/migrations\n\n\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateDeploy.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"1 unapplied migration","suites":["sqlite"],"updatePoint":{"line":59,"column":27},"line":59,"code":"  it('1 unapplied migration', async () => {\n    ctx.fixture('existing-db-1-migration')\n    fs.remove('prisma/dev.db')\n\n    const result = MigrateDeploy.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(`\n            The following migration have been applied:\n\n            migrations/\n              └─ 20201231000000_init/\n                └─ migration.sql\n                  \n            All migrations have been successfully applied.\n          `)\n\n    // Second time should do nothing (already applied)\n    const resultBis = MigrateDeploy.new().parse([])\n    await expect(resultBis).resolves.toMatchInlineSnapshot(\n      `No pending migrations to apply.`,\n    )\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n'))\n      .toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      SQLite database dev.db created at file:dev.db\n\n      1 migration found in prisma/migrations\n\n      Applying migration \\`20201231000000_init\\`\n\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      1 migration found in prisma/migrations\n\n\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateDeploy.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should throw if database is not empty","suites":["sqlite"],"updatePoint":{"line":102,"column":43},"line":102,"code":"  it('should throw if database is not empty', async () => {\n    ctx.fixture('existing-db-1-migration-conflict')\n\n    const result = MigrateDeploy.new().parse([])\n    await expect(result).rejects.toMatchInlineSnapshot(`\n            P3005\n\n            The database schema for \\`dev.db\\` is not empty. Read more about how to baseline an existing production database: https://pris.ly/d/migrate-baseline\n\n          `)\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n'))\n      .toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      1 migration found in prisma/migrations\n\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateDeploy.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"wrong flag","suites":["common"],"updatePoint":{"line":19,"column":16},"line":19,"code":"  it('wrong flag', async () => {\n    const commandInstance = MigrateDev.new()\n    const spy = jest.spyOn(commandInstance, 'help').mockImplementation(() => 'Help Me')\n\n    await commandInstance.parse(['--something'])\n    expect(spy).toHaveBeenCalledTimes(1)\n    spy.mockRestore()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"help flag","suites":["common"],"updatePoint":{"line":27,"column":15},"line":27,"code":"  it('help flag', async () => {\n    const commandInstance = MigrateDev.new()\n    const spy = jest.spyOn(commandInstance, 'help').mockImplementation(() => 'Help Me')\n\n    await commandInstance.parse(['--help'])\n    expect(spy).toHaveBeenCalledTimes(1)\n    spy.mockRestore()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if no schema file","suites":["common"],"updatePoint":{"line":35,"column":35},"line":35,"code":"  it('should fail if no schema file', async () => {\n    ctx.fixture('empty')\n    const result = MigrateDev.new().parse([])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            Could not find a schema.prisma file that is required for this command.\n            You can either provide it with --schema, set it as \\`prisma.schema\\` in your package.json or put it into the default location ./prisma/schema.prisma https://pris.ly/d/prisma-schema-location\n          `)\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if old migrate","suites":["common"],"updatePoint":{"line":43,"column":32},"line":43,"code":"  it('should fail if old migrate', async () => {\n    ctx.fixture('old-migrate')\n    const result = MigrateDev.new().parse([])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            The migrations folder contains migration files from an older version of Prisma Migrate which is not compatible.\n\n            Read more about how to upgrade to the new version of Migrate:\n            https://pris.ly/d/migrate-upgrade\n          `)\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if experimental flag","suites":["common"],"updatePoint":{"line":53,"column":38},"line":53,"code":"  it('should fail if experimental flag', async () => {\n    ctx.fixture('empty')\n    const result = MigrateDev.new().parse(['--experimental'])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            Prisma Migrate was Experimental and is now Generally Available.\n            WARNING this new version has some breaking changes to use it it's recommended to read the documentation first and remove the --experimental flag.\n          `)\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if early access flag","suites":["common"],"updatePoint":{"line":61,"column":38},"line":61,"code":"  it('should fail if early access flag', async () => {\n    ctx.fixture('empty')\n    const result = MigrateDev.new().parse(['--early-access-feature'])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            Prisma Migrate was in Early Access and is now in Preview.\n            Replace the --early-access-feature flag with --preview-feature.\n          `)\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"dev should error in unattended environment","suites":["common"],"updatePoint":{"line":69,"column":48},"line":69,"code":"  it('dev should error in unattended environment', async () => {\n    ctx.fixture('transition-db-push-migrate')\n    const result = MigrateDev.new().parse([])\n    await expect(result).rejects.toMatchInlineSnapshot(`\n            Prisma Migrate has detected that the environment is non-interactive, which is not supported.\n\n            \\`prisma migrate dev\\` is an interactive command designed to create new migrations and evolve the database in development.\n            To apply existing migrations in deployments, use prisma migrate deploy.\n            See https://www.prisma.io/docs/reference/api-reference/command-reference#migrate-deploy\n          `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"empty schema","suites":["sqlite"],"updatePoint":{"line":84,"column":18},"line":84,"code":"  it('empty schema', async () => {\n    ctx.fixture('schema-only-sqlite')\n    const result = MigrateDev.new().parse(['--schema=./prisma/empty.prisma'])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/empty.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      SQLite database dev.db created at file:dev.db\n\n      Already in sync, no schema change or pending migration was found.\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"invalid schema","suites":["sqlite"],"updatePoint":{"line":101,"column":20},"line":101,"code":"  it('invalid schema', async () => {\n    ctx.fixture('schema-only-sqlite')\n    const result = MigrateDev.new().parse(['--schema=./prisma/invalid.prisma'])\n    await expect(result).rejects.toMatchInlineSnapshot(`\n            Get config: Schema Parsing P1012\n\n            error: Error validating: This line is invalid. It does not start with any known Prisma schema keyword.\n              -->  schema.prisma:10\n               | \n             9 | }\n            10 | model Blog {\n            11 | \n               | \n\n            Validation Error Count: 1\n\n          `)\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(\n      `Prisma schema loaded from prisma/invalid.prisma`,\n    )\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"first migration (--name)","suites":["sqlite"],"updatePoint":{"line":126,"column":30},"line":126,"code":"  it('first migration (--name)', async () => {\n    ctx.fixture('schema-only-sqlite')\n    const result = MigrateDev.new().parse(['--name=first'])\n\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(fs.exists('prisma/migrations/migration_lock.toml')).toEqual('file')\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      SQLite database dev.db created at file:dev.db\n\n      Applying migration \\`20201231000000_first\\`\n\n      The following migration(s) have been created and applied from new schema changes:\n\n      migrations/\n        └─ 20201231000000_first/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"snapshot of sql","suites":["sqlite"],"updatePoint":{"line":222,"column":21},"line":222,"code":"  it('snapshot of sql', async () => {\n    ctx.fixture('schema-only-sqlite')\n\n    const result = MigrateDev.new().parse(['--name=first'])\n\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n\n    const baseDir = path.join('prisma', 'migrations')\n    const migrationDirList = fs.list(baseDir)\n    const migrationFilePath = path.join(baseDir, migrationDirList![0], 'migration.sql')\n    const migrationFile = fs.read(migrationFilePath)\n    expect(migrationFile).toMatchInlineSnapshot(`\n      -- CreateTable\n      CREATE TABLE \"Blog\" (\n          \"id\" INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT,\n          \"viewCount20\" INTEGER NOT NULL\n      );\n\n    `)\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"draft migration and apply (prompt)","suites":["sqlite"],"updatePoint":{"line":243,"column":40},"line":243,"code":"  it('draft migration and apply (prompt)', async () => {\n    ctx.fixture('schema-only-sqlite')\n\n    prompt.inject(['some-Draft'])\n\n    const draftResult = MigrateDev.new().parse(['--create-only'])\n\n    await expect(draftResult).resolves.toMatchInlineSnapshot(`\n            Prisma Migrate created the following migration without applying it 20201231000000_some_draft\n\n            You can now edit it and apply it by running prisma migrate dev.\n          `)\n\n    const applyResult = MigrateDev.new().parse([])\n\n    await expect(applyResult).resolves.toMatchInlineSnapshot(``)\n\n    expect((fs.list('prisma/migrations')?.length || 0) > 0).toMatchInlineSnapshot(`true`)\n    expect(fs.exists('prisma/dev.db')).toEqual('file')\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      SQLite database dev.db created at file:dev.db\n\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      Applying migration \\`20201231000000_some_draft\\`\n\n      The following migration(s) have been applied:\n\n      migrations/\n        └─ 20201231000000_some_draft/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n    expect(ctx.mocked['console.log'].mock.calls.join()).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls.join()).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"draft migration with empty schema (prompt)","suites":["sqlite"],"updatePoint":{"line":285,"column":48},"line":285,"code":"  it('draft migration with empty schema (prompt)', async () => {\n    ctx.fixture('schema-only-sqlite')\n\n    prompt.inject(['some-empty-Draft'])\n\n    const draftResult = MigrateDev.new().parse(['--schema=./prisma/empty.prisma', '--create-only'])\n\n    await expect(draftResult).resolves.toMatchInlineSnapshot(`\n            Prisma Migrate created the following migration without applying it 20201231000000_some_empty_draft\n\n            You can now edit it and apply it by running prisma migrate dev.\n          `)\n\n    expect((fs.list('prisma/migrations')?.length || 0) > 0).toMatchInlineSnapshot(`true`)\n    expect(fs.exists('prisma/dev.db')).toEqual('file')\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/empty.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      SQLite database dev.db created at file:dev.db\n\n    `)\n    expect(ctx.mocked['console.log'].mock.calls.join()).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls.join()).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"draft migration and apply (--name)","suites":["sqlite"],"updatePoint":{"line":311,"column":40},"line":311,"code":"  it('draft migration and apply (--name)', async () => {\n    ctx.fixture('schema-only-sqlite')\n    const draftResult = MigrateDev.new().parse(['--create-only', '--name=first'])\n\n    await expect(draftResult).resolves.toMatchInlineSnapshot(`\n            Prisma Migrate created the following migration without applying it 20201231000000_first\n\n            You can now edit it and apply it by running prisma migrate dev.\n          `)\n\n    const applyResult = MigrateDev.new().parse([])\n\n    await expect(applyResult).resolves.toMatchInlineSnapshot(``)\n    expect((fs.list('prisma/migrations')?.length || 0) > 0).toMatchInlineSnapshot(`true`)\n    expect(fs.exists('prisma/dev.db')).toEqual('file')\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      SQLite database dev.db created at file:dev.db\n\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      Applying migration \\`20201231000000_first\\`\n\n      The following migration(s) have been applied:\n\n      migrations/\n        └─ 20201231000000_first/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n    expect(ctx.mocked['console.log'].mock.calls.join()).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls.join()).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"transition-db-push-migrate (prompt reset yes)","suites":["sqlite"],"updatePoint":{"line":349,"column":51},"line":349,"code":"  it('transition-db-push-migrate (prompt reset yes)', async () => {\n    ctx.fixture('transition-db-push-migrate')\n\n    prompt.inject(['y'])\n\n    const result = MigrateDev.new().parse([])\n\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      Drift detected: Your database schema is not in sync with your migration history.\n\n      The following is a summary of the differences between the expected database schema given your migrations files, and the actual schema of the database.\n\n      It should be understood as the set of changes to get from the expected schema to the actual schema.\n\n      If you are running this the first time on an existing database, please make sure to read this documentation page:\n      https://www.prisma.io/docs/guides/database/developing-with-prisma-migrate/troubleshooting-development\n\n      [+] Added tables\n        - Blog\n        - _Migration\n\n\n      Applying migration \\`20201231000000_\\`\n\n      The following migration(s) have been created and applied from new schema changes:\n\n      migrations/\n        └─ 20201231000000_/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n    expect(ctx.mocked['console.log'].mock.calls.join()).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls.join()).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"transition-db-push-migrate (prompt reset no)","suites":["sqlite"],"updatePoint":{"line":389,"column":50},"line":389,"code":"  it('transition-db-push-migrate (prompt reset no)', async () => {\n    ctx.fixture('transition-db-push-migrate')\n    const mockExit = jest.spyOn(process, 'exit').mockImplementation()\n\n    prompt.inject([new Error()])\n\n    const result = MigrateDev.new().parse([])\n\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      Drift detected: Your database schema is not in sync with your migration history.\n\n      The following is a summary of the differences between the expected database schema given your migrations files, and the actual schema of the database.\n\n      It should be understood as the set of changes to get from the expected schema to the actual schema.\n\n      If you are running this the first time on an existing database, please make sure to read this documentation page:\n      https://www.prisma.io/docs/guides/database/developing-with-prisma-migrate/troubleshooting-development\n\n      [+] Added tables\n        - Blog\n        - _Migration\n\n\n      Reset cancelled.\n    `)\n    expect(ctx.mocked['console.log'].mock.calls.join()).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls.join()).toMatchSnapshot()\n    expect(mockExit).toBeCalledWith(0)\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"edited migration and unapplied empty draft","suites":["sqlite"],"updatePoint":{"line":423,"column":48},"line":423,"code":"  it('edited migration and unapplied empty draft', async () => {\n    ctx.fixture('edited-and-draft')\n\n    prompt.inject(['y'])\n\n    const result = MigrateDev.new().parse([])\n\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      The migration \\`20201231000000_test\\` was modified after it was applied.\n\n      Applying migration \\`20201231000000_test\\`\n      Applying migration \\`20201231000000_draft\\`\n\n      The following migration(s) have been applied:\n\n      migrations/\n        └─ 20201231000000_test/\n          └─ migration.sql\n        └─ 20201231000000_draft/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n    expect(ctx.mocked['console.log'].mock.calls.join()).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls.join()).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"removed applied migration and unapplied empty draft","suites":["sqlite"],"updatePoint":{"line":454,"column":57},"line":454,"code":"  it('removed applied migration and unapplied empty draft', async () => {\n    ctx.fixture('edited-and-draft')\n    fs.remove('prisma/migrations/20201117144659_test')\n\n    prompt.inject(['y', 'new-change'])\n\n    const result = MigrateDev.new().parse([])\n\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      - Drift detected: Your database schema is not in sync with your migration history.\n\n      The following is a summary of the differences between the expected database schema given your migrations files, and the actual schema of the database.\n\n      It should be understood as the set of changes to get from the expected schema to the actual schema.\n\n      [+] Added tables\n        - Blog\n\n      - The migrations recorded in the database diverge from the local migrations directory.\n\n\n      Applying migration \\`20201231000000_draft\\`\n\n      The following migration(s) have been applied:\n\n      migrations/\n        └─ 20201231000000_draft/\n          └─ migration.sql\n      Applying migration \\`20201231000000_new_change\\`\n\n\n      The following migration(s) have been created and applied from new schema changes:\n\n      migrations/\n        └─ 20201231000000_new_change/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n    expect(ctx.mocked['console.log'].mock.calls.join()).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls.join()).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"broken migration should fail","suites":["sqlite"],"updatePoint":{"line":501,"column":34},"line":501,"code":"  it('broken migration should fail', async () => {\n    ctx.fixture('broken-migration')\n\n    try {\n      await MigrateDev.new().parse([])\n    } catch (e) {\n      expect(e.code).toEqual('P3006')\n      expect(e.message).toContain('near \"BROKEN\": syntax error')\n    }\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      SQLite database dev.db created at file:dev.db\n\n    `)\n    expect(ctx.mocked['console.log'].mock.calls.join()).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls.join()).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"existingdb: has a failed migration","suites":["sqlite"],"updatePoint":{"line":522,"column":40},"line":522,"code":"  it('existingdb: has a failed migration', async () => {\n    ctx.fixture('existing-db-1-failed-migration')\n\n    try {\n      await MigrateDev.new().parse([])\n    } catch (e) {\n      expect(e.code).toEqual('P3006')\n      expect(e.message).toContain('P3006')\n      expect(e.message).toContain('failed to apply cleanly to the shadow database.')\n    }\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n    `)\n    expect(ctx.mocked['console.log'].mock.calls.join()).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls.join()).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"existing-db-1-migration edit migration with broken sql","suites":["sqlite"],"updatePoint":{"line":542,"column":60},"line":542,"code":"  it('existing-db-1-migration edit migration with broken sql', async () => {\n    ctx.fixture('existing-db-1-migration')\n\n    const result = MigrateDev.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n\n    // Edit with broken SQL\n    fs.write('prisma/migrations/20201014154943_init/migration.sql', 'CREATE BROKEN')\n\n    try {\n      await MigrateDev.new().parse([])\n    } catch (e) {\n      expect(e.code).toEqual('P3006')\n      expect(e.message).toContain('P3006')\n      expect(e.message).toContain('failed to apply cleanly to the shadow database.')\n    }\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      Already in sync, no schema change or pending migration was found.\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"existingdb: 1 unapplied draft","suites":["sqlite"],"updatePoint":{"line":572,"column":35},"line":572,"code":"  it('existingdb: 1 unapplied draft', async () => {\n    ctx.fixture('existing-db-1-draft')\n    const result = MigrateDev.new().parse([])\n\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      Applying migration \\`20201231000000_draft\\`\n\n      The following migration(s) have been applied:\n\n      migrations/\n        └─ 20201231000000_draft/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"existingdb: 1 unapplied draft + 1 schema change","suites":["sqlite"],"updatePoint":{"line":595,"column":53},"line":595,"code":"  it('existingdb: 1 unapplied draft + 1 schema change', async () => {\n    ctx.fixture('existing-db-1-draft-1-change')\n    const result = MigrateDev.new().parse([])\n\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      Applying migration \\`20201231000000_draft\\`\n\n      The following migration(s) have been applied:\n\n      migrations/\n        └─ 20201231000000_draft/\n          └─ migration.sql\n      Applying migration \\`20201231000000_\\`\n\n\n      The following migration(s) have been created and applied from new schema changes:\n\n      migrations/\n        └─ 20201231000000_/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"existingdb: 1 unexecutable schema change","suites":["sqlite"],"updatePoint":{"line":626,"column":46},"line":626,"code":"  it('existingdb: 1 unexecutable schema change', async () => {\n    ctx.fixture('existing-db-1-unexecutable-schema-change')\n    const result = MigrateDev.new().parse([])\n\n    await expect(result).rejects.toMatchInlineSnapshot(`\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ⚠️ We found changes that cannot be executed:\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          • Step 0 Made the column \\`fullname\\` on table \\`Blog\\` required, but there are 1 existing NULL values.\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        You can use prisma migrate dev --create-only to create the migration file, and manually modify it to address the underlying issue(s).\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Then run prisma migrate dev to apply it and verify it works.\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            `)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"existingdb: 1 unexecutable schema change with --create-only should succeed","suites":["sqlite"],"updatePoint":{"line":650,"column":80},"line":650,"code":"  it('existingdb: 1 unexecutable schema change with --create-only should succeed', async () => {\n    ctx.fixture('existing-db-1-unexecutable-schema-change')\n    const result = MigrateDev.new().parse(['--create-only'])\n\n    await expect(result).resolves.toMatchInlineSnapshot(`\n            Prisma Migrate created the following migration without applying it 20201231000000_\n\n            You can now edit it and apply it by running prisma migrate dev.\n          `)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"existingdb: 1 warning from schema change (prompt yes)","suites":["sqlite"],"updatePoint":{"line":669,"column":59},"line":669,"code":"  it('existingdb: 1 warning from schema change (prompt yes)', async () => {\n    ctx.fixture('existing-db-1-warning')\n\n    prompt.inject(['y'])\n\n    const result = MigrateDev.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n\n      Applying migration \\`20201231000000_\\`\n\n      The following migration(s) have been created and applied from new schema changes:\n\n      migrations/\n        └─ 20201231000000_/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n\n                                                                                                                                                                                                                                          ⚠️  Warnings for the current datasource:\n\n                                                                                                                                                                                                                                            • You are about to drop the \\`Blog\\` table, which is not empty (2 rows).\n                                                                                                                                                            `)\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"existingdb: 1 warning from schema change (prompt no)","suites":["sqlite"],"updatePoint":{"line":700,"column":58},"line":700,"code":"  it('existingdb: 1 warning from schema change (prompt no)', async () => {\n    ctx.fixture('existing-db-1-warning')\n\n    prompt.inject([new Error()])\n\n    const result = MigrateDev.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(`Migration cancelled.`)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n\n    `)\n    expect(ctx.mocked['console.log'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n\n                                                                                                                                                                                                                                          ⚠️  Warnings for the current datasource:\n\n                                                                                                                                                                                                                                            • You are about to drop the \\`Blog\\` table, which is not empty (2 rows).\n                                                                                                                                                            `)\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"provider array should fail","suites":["sqlite"],"updatePoint":{"line":722,"column":32},"line":722,"code":"  it('provider array should fail', async () => {\n    ctx.fixture('schema-only-sqlite')\n    const result = MigrateDev.new().parse(['--schema=./prisma/provider-array.prisma'])\n\n    await expect(result).rejects.toMatchInlineSnapshot(`\n            Get config: Schema Parsing P1012\n\n            error: Error validating datasource \\`my_db\\`: The provider argument in a datasource must be a string literal\n              -->  schema.prisma:2\n               | \n             1 | datasource my_db {\n             2 |     provider = [\"postgresql\", \"sqlite\"]\n               | \n\n            Validation Error Count: 1\n\n          `)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(\n      `Prisma schema loaded from prisma/provider-array.prisma`,\n    )\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"one seed file --skip-seed","suites":["sqlite"],"updatePoint":{"line":780,"column":31},"line":780,"code":"  it('one seed file --skip-seed', async () => {\n    ctx.fixture('seed-sqlite-ts')\n\n    prompt.inject(['y'])\n\n    const result = MigrateDev.new().parse(['--skip-seed'])\n\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"db\": SQLite database \"dev.db\" at \"file:./dev.db\"\n\n      SQLite database dev.db created at file:./dev.db\n\n      Applying migration \\`20201231000000_y\\`\n\n      The following migration(s) have been created and applied from new schema changes:\n\n      migrations/\n        └─ 20201231000000_y/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n    expect(ctx.mocked['console.log'].mock.calls.join()).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls.join()).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"one broken seed.js file","suites":["sqlite"],"updatePoint":{"line":808,"column":29},"line":808,"code":"  it('one broken seed.js file', async () => {\n    ctx.fixture('seed-sqlite-js')\n    fs.write('prisma/seed.js', 'BROKEN_CODE_SHOULD_ERROR;')\n\n    prompt.inject(['y'])\n\n    const result = MigrateDev.new().parse([])\n\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"db\": SQLite database \"dev.db\" at \"file:./dev.db\"\n\n      SQLite database dev.db created at file:./dev.db\n\n      Applying migration \\`20201231000000_y\\`\n\n      The following migration(s) have been created and applied from new schema changes:\n\n      migrations/\n        └─ 20201231000000_y/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n\n      Running seed command \\`node prisma/seed.js\\` ...\n\n    `)\n    expect(ctx.mocked['console.log'].mock.calls.join()).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls.join()).toContain(`An error occured while running the seed command:`)\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"legacy seed (no config in package.json)","suites":["sqlite"],"updatePoint":{"line":840,"column":45},"line":840,"code":"  it('legacy seed (no config in package.json)', async () => {\n    ctx.fixture('seed-sqlite-legacy')\n    ctx.fs.remove('prisma/seed.js')\n    // ctx.fs.remove('prisma/seed.ts')\n    ctx.fs.remove('prisma/seed.sh')\n    prompt.inject(['y']) // simulate user yes input\n\n    const result = MigrateDev.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"db\": SQLite database \"dev.db\" at \"file:./dev.db\"\n\n      SQLite database dev.db created at file:./dev.db\n\n      Applying migration \\`20201231000000_y\\`\n\n      The following migration(s) have been created and applied from new schema changes:\n\n      migrations/\n        └─ 20201231000000_y/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n    expect(ctx.mocked['console.warn'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"provider switch: postgresql to sqlite","suites":["sqlite"],"updatePoint":{"line":870,"column":43},"line":870,"code":"  it('provider switch: postgresql to sqlite', async () => {\n    ctx.fixture('provider-switch-postgresql-to-sqlite')\n\n    try {\n      await MigrateDev.new().parse([])\n    } catch (e) {\n      expect(e.code).toEqual('P3019')\n      expect(e.message).toContain('P3019')\n      expect(e.message).toContain('The datasource provider')\n    }\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:./dev.db\"\n\n      SQLite database dev.db created at file:./dev.db\n\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"schema only","suites":["postgresql"],"updatePoint":{"line":928,"column":17},"line":928,"code":"  it('schema only', async () => {\n    ctx.fixture('schema-only-postgresql')\n\n    const result = MigrateDev.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": PostgreSQL database \"tests-migrate\", schema \"public\" at \"localhost:5432\"\n\n      Applying migration \\`20201231000000_\\`\n\n      The following migration(s) have been created and applied from new schema changes:\n\n      migrations/\n        └─ 20201231000000_/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"schema only with shadowdb","suites":["postgresql"],"updatePoint":{"line":951,"column":31},"line":951,"code":"  it('schema only with shadowdb', async () => {\n    ctx.fixture('schema-only-postgresql')\n\n    const result = MigrateDev.new().parse(['--schema=./prisma/shadowdb.prisma'])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/shadowdb.prisma\n      Datasource \"my_db\": PostgreSQL database \"tests-migrate\", schema \"public\" at \"localhost:5432\"\n\n      Applying migration \\`20201231000000_\\`\n\n      The following migration(s) have been created and applied from new schema changes:\n\n      migrations/\n        └─ 20201231000000_/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"create first migration","suites":["postgresql"],"updatePoint":{"line":974,"column":28},"line":974,"code":"  it('create first migration', async () => {\n    ctx.fixture('schema-only-postgresql')\n    const result = MigrateDev.new().parse([])\n\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": PostgreSQL database \"tests-migrate\", schema \"public\" at \"localhost:5432\"\n\n      Applying migration \\`20201231000000_\\`\n\n      The following migration(s) have been created and applied from new schema changes:\n\n      migrations/\n        └─ 20201231000000_/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"create first migration with nativeTypes","suites":["postgresql"],"updatePoint":{"line":997,"column":45},"line":997,"code":"  it('create first migration with nativeTypes', async () => {\n    ctx.fixture('nativeTypes-postgresql')\n\n    const result = MigrateDev.new().parse(['--name=first'])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"db\": PostgreSQL database \"tests-migrate\", schema \"public\" at \"localhost:5432\"\n\n      Applying migration \\`20201231000000_first\\`\n\n      The following migration(s) have been created and applied from new schema changes:\n\n      migrations/\n        └─ 20201231000000_first/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"draft migration and apply (--name)","suites":["postgresql"],"updatePoint":{"line":1044,"column":40},"line":1044,"code":"  it('draft migration and apply (--name)', async () => {\n    ctx.fixture('schema-only-postgresql')\n    jest.setTimeout(7000)\n\n    const draftResult = MigrateDev.new().parse(['--create-only', '--name=first'])\n\n    await expect(draftResult).resolves.toMatchInlineSnapshot(`\n            Prisma Migrate created the following migration without applying it 20201231000000_first\n\n            You can now edit it and apply it by running prisma migrate dev.\n          `)\n\n    const applyResult = MigrateDev.new().parse([])\n    await expect(applyResult).resolves.toMatchInlineSnapshot(``)\n\n    expect((fs.list('prisma/migrations')?.length || 0) > 0).toMatchInlineSnapshot(`true`)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": PostgreSQL database \"tests-migrate\", schema \"public\" at \"localhost:5432\"\n\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": PostgreSQL database \"tests-migrate\", schema \"public\" at \"localhost:5432\"\n\n      Applying migration \\`20201231000000_first\\`\n\n      The following migration(s) have been applied:\n\n      migrations/\n        └─ 20201231000000_first/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"existingdb: create first migration","suites":["postgresql"],"updatePoint":{"line":1081,"column":40},"line":1081,"code":"  it('existingdb: create first migration', async () => {\n    ctx.fixture('schema-only-postgresql')\n    const result = MigrateDev.new().parse(['--name=first'])\n\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": PostgreSQL database \"tests-migrate\", schema \"public\" at \"localhost:5432\"\n\n      Applying migration \\`20201231000000_first\\`\n\n      The following migration(s) have been created and applied from new schema changes:\n\n      migrations/\n        └─ 20201231000000_first/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"schema only","suites":["mysql"],"updatePoint":{"line":1152,"column":17},"line":1152,"code":"  it('schema only', async () => {\n    ctx.fixture('schema-only-mysql')\n\n    const result = MigrateDev.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": MySQL database \"tests-migrate\" at \"localhost:5432\"\n\n      Applying migration \\`20201231000000_\\`\n\n      The following migration(s) have been created and applied from new schema changes:\n\n      migrations/\n        └─ 20201231000000_/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"schema only with shadowdb","suites":["mysql"],"updatePoint":{"line":1175,"column":31},"line":1175,"code":"  it('schema only with shadowdb', async () => {\n    ctx.fixture('schema-only-mysql')\n\n    const result = MigrateDev.new().parse(['--schema=./prisma/shadowdb.prisma'])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/shadowdb.prisma\n      Datasource \"my_db\": MySQL database \"tests-migrate\" at \"localhost:5432\"\n\n      Applying migration \\`20201231000000_\\`\n\n      The following migration(s) have been created and applied from new schema changes:\n\n      migrations/\n        └─ 20201231000000_/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"create first migration","suites":["mysql"],"updatePoint":{"line":1198,"column":28},"line":1198,"code":"  it('create first migration', async () => {\n    ctx.fixture('schema-only-mysql')\n    const result = MigrateDev.new().parse([])\n\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": MySQL database \"tests-migrate\" at \"localhost:5432\"\n\n      Applying migration \\`20201231000000_\\`\n\n      The following migration(s) have been created and applied from new schema changes:\n\n      migrations/\n        └─ 20201231000000_/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"draft migration and apply (--name)","suites":["mysql"],"updatePoint":{"line":1269,"column":40},"line":1269,"code":"  it('draft migration and apply (--name)', async () => {\n    ctx.fixture('schema-only-mysql')\n    jest.setTimeout(7000)\n\n    const draftResult = MigrateDev.new().parse(['--create-only', '--name=first'])\n\n    await expect(draftResult).resolves.toMatchInlineSnapshot(`\n            Prisma Migrate created the following migration without applying it 20201231000000_first\n\n            You can now edit it and apply it by running prisma migrate dev.\n          `)\n\n    const applyResult = MigrateDev.new().parse([])\n    await expect(applyResult).resolves.toMatchInlineSnapshot(``)\n\n    expect((fs.list('prisma/migrations')?.length || 0) > 0).toMatchInlineSnapshot(`true`)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": MySQL database \"tests-migrate\" at \"localhost:5432\"\n\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": MySQL database \"tests-migrate\" at \"localhost:5432\"\n\n      Applying migration \\`20201231000000_first\\`\n\n      The following migration(s) have been applied:\n\n      migrations/\n        └─ 20201231000000_first/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"existingdb: create first migration","suites":["mysql"],"updatePoint":{"line":1306,"column":40},"line":1306,"code":"  it('existingdb: create first migration', async () => {\n    ctx.fixture('schema-only-mysql')\n    const result = MigrateDev.new().parse(['--name=first'])\n\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": MySQL database \"tests-migrate\" at \"localhost:5432\"\n\n      Applying migration \\`20201231000000_first\\`\n\n      The following migration(s) have been created and applied from new schema changes:\n\n      migrations/\n        └─ 20201231000000_first/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"schema only","suites":["mysql"],"updatePoint":{"line":1357,"column":17},"line":1357,"code":"  it('schema only', async () => {\n    ctx.fixture('schema-only-sqlserver')\n\n    const result = MigrateDev.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\" - SQL Server\n\n      Applying migration \\`20201231000000_\\`\n\n      The following migration(s) have been created and applied from new schema changes:\n\n      migrations/\n        └─ 20201231000000_/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"schema only with shadowdb","suites":["mysql"],"updatePoint":{"line":1380,"column":31},"line":1380,"code":"  it('schema only with shadowdb', async () => {\n    ctx.fixture('schema-only-sqlserver')\n\n    const result = MigrateDev.new().parse(['--schema=./prisma/shadowdb.prisma'])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/shadowdb.prisma\n      Datasource \"my_db\" - SQL Server\n\n      Applying migration \\`20201231000000_\\`\n\n      The following migration(s) have been created and applied from new schema changes:\n\n      migrations/\n        └─ 20201231000000_/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"create first migration","suites":["mysql"],"updatePoint":{"line":1403,"column":28},"line":1403,"code":"  it('create first migration', async () => {\n    ctx.fixture('schema-only-sqlserver')\n    const result = MigrateDev.new().parse([])\n\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\" - SQL Server\n\n      Applying migration \\`20201231000000_\\`\n\n      The following migration(s) have been created and applied from new schema changes:\n\n      migrations/\n        └─ 20201231000000_/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"draft migration and apply (--name)","suites":["mysql"],"updatePoint":{"line":1474,"column":40},"line":1474,"code":"  it('draft migration and apply (--name)', async () => {\n    ctx.fixture('schema-only-sqlserver')\n    jest.setTimeout(10000)\n\n    const draftResult = MigrateDev.new().parse(['--create-only', '--name=first'])\n\n    await expect(draftResult).resolves.toMatchInlineSnapshot(`\n            Prisma Migrate created the following migration without applying it 20201231000000_first\n\n            You can now edit it and apply it by running prisma migrate dev.\n          `)\n\n    const applyResult = MigrateDev.new().parse([])\n    await expect(applyResult).resolves.toMatchInlineSnapshot(``)\n\n    expect((fs.list('prisma/migrations')?.length || 0) > 0).toMatchInlineSnapshot(`true`)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\" - SQL Server\n\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\" - SQL Server\n\n      Applying migration \\`20201231000000_first\\`\n\n      The following migration(s) have been applied:\n\n      migrations/\n        └─ 20201231000000_first/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"existingdb: create first migration","suites":["mysql"],"updatePoint":{"line":1511,"column":40},"line":1511,"code":"  it('existingdb: create first migration', async () => {\n    ctx.fixture('schema-only-sqlserver')\n    const result = MigrateDev.new().parse(['--name=first'])\n\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\" - SQL Server\n\n      Applying migration \\`20201231000000_first\\`\n\n      The following migration(s) have been created and applied from new schema changes:\n\n      migrations/\n        └─ 20201231000000_first/\n          └─ migration.sql\n\n      Your database is now in sync with your schema.\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateDev.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"wrong flag","suites":["common"],"updatePoint":{"line":14,"column":16},"line":14,"code":"  it('wrong flag', async () => {\n    const commandInstance = MigrateReset.new()\n    const spy = jest.spyOn(commandInstance, 'help').mockImplementation(() => 'Help Me')\n\n    await commandInstance.parse(['--something'])\n    expect(spy).toHaveBeenCalledTimes(1)\n    spy.mockRestore()\n  })","file":"MigrateReset.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"help flag","suites":["common"],"updatePoint":{"line":22,"column":15},"line":22,"code":"  it('help flag', async () => {\n    const commandInstance = MigrateReset.new()\n    const spy = jest.spyOn(commandInstance, 'help').mockImplementation(() => 'Help Me')\n\n    await commandInstance.parse(['--help'])\n    expect(spy).toHaveBeenCalledTimes(1)\n    spy.mockRestore()\n  })","file":"MigrateReset.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if no schema file","suites":["common"],"updatePoint":{"line":30,"column":35},"line":30,"code":"  it('should fail if no schema file', async () => {\n    ctx.fixture('empty')\n    const result = MigrateReset.new().parse([])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            Could not find a schema.prisma file that is required for this command.\n            You can either provide it with --schema, set it as \\`prisma.schema\\` in your package.json or put it into the default location ./prisma/schema.prisma https://pris.ly/d/prisma-schema-location\n          `)\n  })","file":"MigrateReset.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if old migrate","suites":["common"],"updatePoint":{"line":38,"column":32},"line":38,"code":"  it('should fail if old migrate', async () => {\n    ctx.fixture('old-migrate')\n    const result = MigrateReset.new().parse([])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            The migrations folder contains migration files from an older version of Prisma Migrate which is not compatible.\n\n            Read more about how to upgrade to the new version of Migrate:\n            https://pris.ly/d/migrate-upgrade\n          `)\n  })","file":"MigrateReset.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if experimental flag","suites":["common"],"updatePoint":{"line":48,"column":38},"line":48,"code":"  it('should fail if experimental flag', async () => {\n    ctx.fixture('empty')\n    const result = MigrateReset.new().parse(['--experimental'])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            Prisma Migrate was Experimental and is now Generally Available.\n            WARNING this new version has some breaking changes to use it it's recommended to read the documentation first and remove the --experimental flag.\n          `)\n  })","file":"MigrateReset.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if early access flag","suites":["common"],"updatePoint":{"line":56,"column":38},"line":56,"code":"  it('should fail if early access flag', async () => {\n    ctx.fixture('empty')\n    const result = MigrateReset.new().parse(['--early-access-feature'])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            Prisma Migrate was in Early Access and is now in Preview.\n            Replace the --early-access-feature flag with --preview-feature.\n          `)\n  })","file":"MigrateReset.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should work (prompt)","suites":["reset"],"updatePoint":{"line":67,"column":26},"line":67,"code":"  it('should work (prompt)', async () => {\n    ctx.fixture('reset')\n\n    prompt.inject(['y']) // simulate user yes input\n\n    const result = MigrateReset.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n\n      Applying migration \\`20201231000000_init\\`\n\n      Database reset successful\n\n      The following migration(s) have been applied:\n\n      migrations/\n        └─ 20201231000000_init/\n          └─ migration.sql\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"MigrateReset.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should work (--force)","suites":["reset"],"updatePoint":{"line":92,"column":27},"line":92,"code":"  it('should work (--force)', async () => {\n    ctx.fixture('reset')\n\n    const result = MigrateReset.new().parse(['--force'])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      Applying migration \\`20201231000000_init\\`\n\n      Database reset successful\n\n      The following migration(s) have been applied:\n\n      migrations/\n        └─ 20201231000000_init/\n          └─ migration.sql\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"MigrateReset.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"with missing db","suites":["reset"],"updatePoint":{"line":114,"column":21},"line":114,"code":"  it('with missing db', async () => {\n    ctx.fixture('reset')\n    ctx.fs.remove('prisma/dev.db')\n\n    const result = MigrateReset.new().parse(['--force'])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n      SQLite database dev.db created at file:dev.db\n\n      Applying migration \\`20201231000000_init\\`\n\n      Database reset successful\n\n      The following migration(s) have been applied:\n\n      migrations/\n        └─ 20201231000000_init/\n          └─ migration.sql\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"MigrateReset.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"without the migrations directory should fail (prompt)","suites":["reset"],"updatePoint":{"line":139,"column":59},"line":139,"code":"  it('without the migrations directory should fail (prompt)', async () => {\n    ctx.fixture('reset')\n    ctx.fs.remove('prisma/migrations')\n\n    prompt.inject(['y']) // simulate user yes input\n\n    const result = MigrateReset.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n\n      Database reset successful\n\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"MigrateReset.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should be cancelled if user send n (prompt)","suites":["reset"],"updatePoint":{"line":158,"column":49},"line":158,"code":"  it('should be cancelled if user send n (prompt)', async () => {\n    ctx.fixture('reset')\n    const mockExit = jest.spyOn(process, 'exit').mockImplementation()\n\n    prompt.inject([new Error()]) // simulate user cancellation\n\n    const result = MigrateReset.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n\n      Reset cancelled.\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(mockExit).toBeCalledWith(0)\n  })","file":"MigrateReset.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"reset should error in unattended environment","suites":["reset"],"updatePoint":{"line":177,"column":50},"line":177,"code":"  it('reset should error in unattended environment', async () => {\n    ctx.fixture('reset')\n    const result = MigrateReset.new().parse([])\n    await expect(result).rejects.toMatchInlineSnapshot(`\n            Prisma Migrate has detected that the environment is non-interactive. It is recommended to run this command in an interactive environment.\n\n            Use --force to run this command without user interaction.\n            See https://www.prisma.io/docs/reference/api-reference/command-reference#migrate-reset\n          `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"MigrateReset.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"reset - multiple seed files","suites":["reset"],"updatePoint":{"line":189,"column":33},"line":189,"code":"  it('reset - multiple seed files', async () => {\n    ctx.fixture('seed-sqlite-legacy')\n    prompt.inject(['y']) // simulate user yes input\n\n    const result = MigrateReset.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"db\": SQLite database \"dev.db\" at \"file:./dev.db\"\n\n      SQLite database dev.db created at file:./dev.db\n\n\n      Database reset successful\n\n    `)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"MigrateReset.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"reset - multiple seed files - --skip-seed","suites":["reset"],"updatePoint":{"line":208,"column":47},"line":208,"code":"  it('reset - multiple seed files - --skip-seed', async () => {\n    ctx.fixture('seed-sqlite-legacy')\n    prompt.inject(['y']) // simulate user yes input\n\n    const result = MigrateReset.new().parse(['--skip-seed'])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"MigrateReset.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"reset - legacy seed (no config in package.json)","suites":["reset"],"updatePoint":{"line":267,"column":53},"line":267,"code":"  it('reset - legacy seed (no config in package.json)', async () => {\n    ctx.fixture('seed-sqlite-legacy')\n    ctx.fs.remove('prisma/seed.js')\n    ctx.fs.remove('prisma/seed.ts')\n    // ctx.fs.remove('prisma/seed.sh')\n    prompt.inject(['y']) // simulate user yes input\n\n    const result = MigrateReset.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(``)\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n')).toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"db\": SQLite database \"dev.db\" at \"file:./dev.db\"\n\n      SQLite database dev.db created at file:./dev.db\n\n\n      Database reset successful\n\n    `)\n    expect(ctx.mocked['console.warn'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n    expect(ctx.mocked['console.error'].mock.calls.join('\\n')).toMatchInlineSnapshot(``)\n  })","file":"MigrateReset.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if no schema file","suites":["common"],"updatePoint":{"line":12,"column":35},"line":12,"code":"  it('should fail if no schema file', async () => {\n    ctx.fixture('empty')\n    const result = MigrateResolve.new().parse([])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            Could not find a schema.prisma file that is required for this command.\n            You can either provide it with --schema, set it as \\`prisma.schema\\` in your package.json or put it into the default location ./prisma/schema.prisma https://pris.ly/d/prisma-schema-location\n          `)\n  })","file":"MigrateResolve.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if experimental flag","suites":["common"],"updatePoint":{"line":20,"column":38},"line":20,"code":"  it('should fail if experimental flag', async () => {\n    ctx.fixture('empty')\n    const result = MigrateResolve.new().parse(['--experimental'])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            Prisma Migrate was Experimental and is now Generally Available.\n            WARNING this new version has some breaking changes to use it it's recommended to read the documentation first and remove the --experimental flag.\n          `)\n  })","file":"MigrateResolve.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if early access flag","suites":["common"],"updatePoint":{"line":28,"column":38},"line":28,"code":"  it('should fail if early access flag', async () => {\n    ctx.fixture('empty')\n    const result = MigrateResolve.new().parse(['--early-access-feature'])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            Prisma Migrate was in Early Access and is now in Preview.\n            Replace the --early-access-feature flag with --preview-feature.\n          `)\n  })","file":"MigrateResolve.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if no --applied or --rolled-back","suites":["common"],"updatePoint":{"line":36,"column":50},"line":36,"code":"  it('should fail if no --applied or --rolled-back', async () => {\n    ctx.fixture('schema-only-sqlite')\n    const result = MigrateResolve.new().parse([])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            --applied or --rolled-back must be part of the command like:\n            prisma migrate resolve --applied 20201231000000_example\n            prisma migrate resolve --rolled-back 20201231000000_example\n          `)\n  })","file":"MigrateResolve.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if both --applied or --rolled-back","suites":["common"],"updatePoint":{"line":45,"column":52},"line":45,"code":"  it('should fail if both --applied or --rolled-back', async () => {\n    ctx.fixture('schema-only-sqlite')\n    const result = MigrateResolve.new().parse([\n      '--applied=something_applied',\n      '--rolled-back=something_rolledback',\n    ])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(\n      `Pass either --applied or --rolled-back, not both.`,\n    )\n  })","file":"MigrateResolve.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if no sqlite db - empty schema","suites":["sqlite"],"updatePoint":{"line":58,"column":48},"line":58,"code":"  it('should fail if no sqlite db - empty schema', async () => {\n    ctx.fixture('schema-only-sqlite')\n    const result = MigrateResolve.new().parse([\n      '--schema=./prisma/empty.prisma',\n\n      '--applied=something_applied',\n    ])\n    await expect(result).rejects.toMatchInlineSnapshot(\n      `P1003: SQLite database file doesn't exist`,\n    )\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n'))\n      .toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/empty.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateResolve.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"--applied should fail if migration doesn't exist","suites":["sqlite"],"updatePoint":{"line":82,"column":54},"line":82,"code":"  it(\"--applied should fail if migration doesn't exist\", async () => {\n    ctx.fixture('existing-db-1-failed-migration')\n    const result = MigrateResolve.new().parse(['--applied=does_not_exist'])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\nP3017\n\nThe migration does_not_exist could not be found. Please make sure that the migration exists, and that you included the whole name of the directory. (example: \"20201231000000_initial_migration\")\n\n`)\n  })","file":"MigrateResolve.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"--applied should fail if migration is already applied","suites":["sqlite"],"updatePoint":{"line":93,"column":59},"line":93,"code":"  it('--applied should fail if migration is already applied', async () => {\n    ctx.fixture('existing-db-1-migration')\n    const result = MigrateResolve.new().parse(['--applied=20201014154943_init'])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            P3008\n\n            The migration \\`20201231000000_init\\` is already recorded as applied in the database.\n\n          `)\n  })","file":"MigrateResolve.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"--applied should fail if migration is not in a failed state","suites":["sqlite"],"updatePoint":{"line":104,"column":65},"line":104,"code":"  it('--applied should fail if migration is not in a failed state', async () => {\n    ctx.fixture('existing-db-1-migration')\n    const result = MigrateResolve.new().parse([\n      '--applied',\n      '20201014154943_init',\n    ])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            P3008\n\n            The migration \\`20201231000000_init\\` is already recorded as applied in the database.\n\n          `)\n  })","file":"MigrateResolve.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"--applied should work on a failed migration","suites":["sqlite"],"updatePoint":{"line":118,"column":49},"line":118,"code":"  it('--applied should work on a failed migration', async () => {\n    ctx.fixture('existing-db-1-failed-migration')\n    const result = MigrateResolve.new().parse([\n      '--applied',\n      '20201106130852_failed',\n    ])\n    await expect(result).resolves.toMatchInlineSnapshot(\n      `Migration 20201231000000_failed marked as applied.`,\n    )\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n'))\n      .toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateResolve.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"--rolled-back should fail if migration doesn't exist","suites":["sqlite"],"updatePoint":{"line":140,"column":58},"line":140,"code":"  it(\"--rolled-back should fail if migration doesn't exist\", async () => {\n    ctx.fixture('existing-db-1-failed-migration')\n    const result = MigrateResolve.new().parse(['--rolled-back=does_not_exist'])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            P3011\n\n            Migration \\`does_not_exist\\` cannot be rolled back because it was never applied to the database. Hint: did you pass in the whole migration name? (example: \"20201231000000_initial_migration\")\n\n          `)\n  })","file":"MigrateResolve.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"--rolled-back should fail if migration is not in a failed state","suites":["sqlite"],"updatePoint":{"line":151,"column":69},"line":151,"code":"  it('--rolled-back should fail if migration is not in a failed state', async () => {\n    ctx.fixture('existing-db-1-migration')\n    const result = MigrateResolve.new().parse([\n      '--rolled-back',\n      '20201014154943_init',\n    ])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            P3012\n\n            Migration \\`20201231000000_init\\` cannot be rolled back because it is not in a failed state.\n\n          `)\n  })","file":"MigrateResolve.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"--rolled-back should work on a failed migration","suites":["sqlite"],"updatePoint":{"line":165,"column":53},"line":165,"code":"  it('--rolled-back should work on a failed migration', async () => {\n    ctx.fixture('existing-db-1-failed-migration')\n    const result = MigrateResolve.new().parse([\n      '--rolled-back',\n      '20201106130852_failed',\n    ])\n    await expect(result).resolves.toMatchInlineSnapshot(\n      `Migration 20201231000000_failed marked as rolled back.`,\n    )\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n'))\n      .toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateResolve.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"--rolled-back works if migration is already rolled back","suites":["sqlite"],"updatePoint":{"line":183,"column":61},"line":183,"code":"  it('--rolled-back works if migration is already rolled back', async () => {\n    ctx.fixture('existing-db-1-failed-migration')\n    const result = MigrateResolve.new().parse([\n      '--rolled-back',\n      '20201106130852_failed',\n    ])\n    await expect(result).resolves.toMatchInlineSnapshot(\n      `Migration 20201231000000_failed marked as rolled back.`,\n    )\n\n    // Try again\n    const result2 = MigrateResolve.new().parse([\n      '--rolled-back',\n      '20201106130852_failed',\n    ])\n    await expect(result2).resolves.toMatchInlineSnapshot(\n      `Migration 20201231000000_failed marked as rolled back.`,\n    )\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n'))\n      .toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateResolve.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if no postgres db - invalid url","suites":["postgresql"],"line":216,"code":"  it.skip('should fail if no postgres db - invalid url', async () => {","file":"MigrateResolve.test.ts","skipped":true,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if no schema file","suites":["common"],"updatePoint":{"line":17,"column":35},"line":17,"code":"  it('should fail if no schema file', async () => {\n    ctx.fixture('empty')\n    const result = MigrateStatus.new().parse([])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            Could not find a schema.prisma file that is required for this command.\n            You can either provide it with --schema, set it as \\`prisma.schema\\` in your package.json or put it into the default location ./prisma/schema.prisma https://pris.ly/d/prisma-schema-location\n          `)\n  })","file":"MigrateStatus.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if experimental flag","suites":["common"],"updatePoint":{"line":25,"column":38},"line":25,"code":"  it('should fail if experimental flag', async () => {\n    ctx.fixture('empty')\n    const result = MigrateStatus.new().parse(['--experimental'])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            Prisma Migrate was Experimental and is now Generally Available.\n            WARNING this new version has some breaking changes to use it it's recommended to read the documentation first and remove the --experimental flag.\n          `)\n  })","file":"MigrateStatus.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if early access flag","suites":["common"],"updatePoint":{"line":33,"column":38},"line":33,"code":"  it('should fail if early access flag', async () => {\n    ctx.fixture('empty')\n    const result = MigrateStatus.new().parse(['--early-access-feature'])\n    await expect(result).rejects.toThrowErrorMatchingInlineSnapshot(`\n            Prisma Migrate was in Early Access and is now in Preview.\n            Replace the --early-access-feature flag with --preview-feature.\n          `)\n  })","file":"MigrateStatus.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"should fail if no sqlite db - empty schema","suites":["sqlite"],"updatePoint":{"line":44,"column":48},"line":44,"code":"  it('should fail if no sqlite db - empty schema', async () => {\n    ctx.fixture('schema-only-sqlite')\n    const result = MigrateStatus.new().parse(['--schema=./prisma/empty.prisma'])\n    await expect(result).resolves.toMatchInlineSnapshot(`\n            Database connection error:\n\n            P1003: SQLite database file doesn't exist\n          `)\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n'))\n      .toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/empty.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateStatus.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"existing-db-1-failed-migration","suites":["sqlite"],"updatePoint":{"line":63,"column":36},"line":63,"code":"  it('existing-db-1-failed-migration', async () => {\n    ctx.fixture('existing-db-1-failed-migration')\n\n    const result = MigrateStatus.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(`\n            The failed migration(s) can be marked as rolled back or applied:\n                  \n            - If you rolled back the migration(s) manually:\n            prisma migrate resolve --rolled-back \"20201231000000_failed\"\n\n            - If you fixed the database manually (hotfix):\n            prisma migrate resolve --applied \"20201231000000_failed\"\n\n            Read more about how to resolve migration issues in a production database:\n            https://pris.ly/d/migrate-resolve\n          `)\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n'))\n      .toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n      1 migration found in prisma/migrations\n\n      Following migration have failed:\n      20201231000000_failed\n\n      During development if the failed migration(s) have not been deployed to a production database you can then fix the migration(s) and run prisma migrate dev.\n\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateStatus.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"baseline-sqlite","suites":["sqlite"],"updatePoint":{"line":96,"column":21},"line":96,"code":"  it('baseline-sqlite', async () => {\n    ctx.fixture('baseline-sqlite')\n\n    const result = MigrateStatus.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(`\n            The current database is not managed by Prisma Migrate.\n\n            If you want to keep the current database structure and data and create new migrations, baseline this database with the migration \"20201231000000_\":\n            prisma migrate resolve --applied \"20201231000000_\"\n\n            Read more about how to baseline an existing production database:\n            https://pris.ly/d/migrate-baseline\n          `)\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n'))\n      .toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n      1 migration found in prisma/migrations\n\n      Following migration have not yet been applied:\n      20201231000000_\n\n      To apply migrations in development run prisma migrate dev.\n      To apply migrations in production run prisma migrate deploy.\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateStatus.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"existing-db-1-migration","suites":["sqlite"],"updatePoint":{"line":126,"column":29},"line":126,"code":"  it('existing-db-1-migration', async () => {\n    ctx.fixture('existing-db-1-migration')\n    const result = MigrateStatus.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(\n      `Database schema is up to date!`,\n    )\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n'))\n      .toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n      1 migration found in prisma/migrations\n\n\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateStatus.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"existing-db-1-migration-conflict","suites":["sqlite"],"updatePoint":{"line":145,"column":38},"line":145,"code":"  it('existing-db-1-migration-conflict', async () => {\n    ctx.fixture('existing-db-1-migration-conflict')\n\n    const result = MigrateStatus.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(`\n            The current database is not managed by Prisma Migrate.\n\n            If you want to keep the current database structure and data and create new migrations, baseline this database with the migration \"20201231000000_init\":\n            prisma migrate resolve --applied \"20201231000000_init\"\n\n            Read more about how to baseline an existing production database:\n            https://pris.ly/d/migrate-baseline\n          `)\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n'))\n      .toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n      1 migration found in prisma/migrations\n\n      Following migration have not yet been applied:\n      20201231000000_init\n\n      To apply migrations in development run prisma migrate dev.\n      To apply migrations in production run prisma migrate deploy.\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateStatus.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"existing-db-brownfield","suites":["sqlite"],"updatePoint":{"line":175,"column":28},"line":175,"code":"  it('existing-db-brownfield', async () => {\n    ctx.fixture('existing-db-brownfield')\n    const result = MigrateStatus.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(`\n            Read more about how to baseline an existing production database:\n            https://pris.ly/d/migrate-baseline\n          `)\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n'))\n      .toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n      No migration found in prisma/migrations\n\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateStatus.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"existing-db-warnings","suites":["sqlite"],"updatePoint":{"line":194,"column":26},"line":194,"code":"  it('existing-db-warnings', async () => {\n    ctx.fixture('existing-db-warnings')\n    const result = MigrateStatus.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(`\n            Read more about how to baseline an existing production database:\n            https://pris.ly/d/migrate-baseline\n          `)\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n'))\n      .toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n      No migration found in prisma/migrations\n\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateStatus.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"old-migrate","suites":["sqlite"],"updatePoint":{"line":213,"column":17},"line":213,"code":"  it('old-migrate', async () => {\n    ctx.fixture('old-migrate')\n    const result = MigrateStatus.new().parse([])\n    await expect(result).rejects.toMatchInlineSnapshot(`\n            The migrations folder contains migration files from an older version of Prisma Migrate which is not compatible.\n\n            Read more about how to upgrade to the new version of Migrate:\n            https://pris.ly/d/migrate-upgrade\n          `)\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n'))\n      .toMatchInlineSnapshot(`\n      Prisma schema loaded from schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateStatus.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"reset","suites":["sqlite"],"updatePoint":{"line":232,"column":11},"line":232,"code":"  it('reset', async () => {\n    ctx.fixture('reset')\n    const result = MigrateStatus.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(\n      `Database schema is up to date!`,\n    )\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n'))\n      .toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n      1 migration found in prisma/migrations\n\n\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateStatus.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"existing-db-histories-diverge","suites":["sqlite"],"updatePoint":{"line":251,"column":35},"line":251,"code":"  it('existing-db-histories-diverge', async () => {\n    ctx.fixture('existing-db-histories-diverge')\n    const result = MigrateStatus.new().parse([])\n    await expect(result).resolves.toMatchInlineSnapshot(`\n            Your local migration history and the migrations table from your database are different:\n\n            The last common migration is: 20201231000000_init\n\n            The migration have not yet been applied:\n            20201231000000_catage\n\n            The migration from the database are not found locally in prisma/migrations:\n            20201231000000_dogage\n          `)\n\n    expect(ctx.mocked['console.info'].mock.calls.join('\\n'))\n      .toMatchInlineSnapshot(`\n      Prisma schema loaded from prisma/schema.prisma\n      Datasource \"my_db\": SQLite database \"dev.db\" at \"file:dev.db\"\n      2 migrations found in prisma/migrations\n\n    `)\n    expect(ctx.mocked['console.log'].mock.calls).toMatchSnapshot()\n    expect(ctx.mocked['console.error'].mock.calls).toMatchSnapshot()\n  })","file":"MigrateStatus.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"simple schema","suites":[],"updatePoint":{"line":3,"column":19},"line":3,"code":"test('simple schema', () => {\n  const schema = `\ndatasource db {\n  provider = \"sqlite\"\n  url = \"file:dev.db\"\n}\n\n\ngenerator gen {\n  provider = \"prisma-client-js\"\n}\n\nmodel User {\n  id   Int @id @default(autoincrement())\n  name String\n}\n`\n  expect(removeDatasource(schema)).toMatchInlineSnapshot(`\n    generator gen {\n      provider = \"prisma-client-js\"\n    }\n\n    model User {\n      id   Int @id @default(autoincrement())\n      name String\n    }\n  `)\n})","file":"removeDatasource.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"comments","suites":[],"updatePoint":{"line":32,"column":14},"line":32,"code":"test('comments', () => {\n  const schema = `\ndatasource db {\n// datasource db {\n  provider = \"sqlite\"\n  // provider = \"sqlite\"\n  url = \"file:dev.db\"\n}\n\n\ngenerator gen {\n  provider = \"prisma-client-js\"\n}\n\nmodel User {\n  id   Int @id @default(autoincrement())\n  name String\n}\n`\n  expect(removeDatasource(schema)).toMatchInlineSnapshot(`\n    generator gen {\n      provider = \"prisma-client-js\"\n    }\n\n    model User {\n      id   Int @id @default(autoincrement())\n      name String\n    }\n  `)\n})","file":"removeDatasource.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"schema without datasource","suites":[],"updatePoint":{"line":63,"column":31},"line":63,"code":"test('schema without datasource', () => {\n  const schema = `\n\ngenerator gen {\n  provider = \"prisma-client-js\"\n}\n\nmodel User {\n  id   Int @id @default(autoincrement())\n  name String\n}\n`\n  expect(removeDatasource(schema)).toMatchInlineSnapshot(`\n    generator gen {\n      provider = \"prisma-client-js\"\n    }\n\n    model User {\n      id   Int @id @default(autoincrement())\n      name String\n    }\n  `)\n})","file":"removeDatasource.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"schema with multiple datasources","suites":[],"updatePoint":{"line":87,"column":38},"line":87,"code":"test('schema with multiple datasources', () => {\n  const schema = `\ndatasource db {\n  provider = \"sqlite\"\n  url = \"file:dev.db\"\n}\n\ndatasource db2 {\n  provider = \"sqlite\"\n  url = \"file:dev.db\"\n}\n\n\ngenerator gen {\n  provider = \"prisma-client-js\"\n}\n\nmodel User {\n  id   Int @id @default(autoincrement())\n  name String\n}\n`\n  expect(removeDatasource(schema)).toMatchInlineSnapshot(`\n    generator gen {\n      provider = \"prisma-client-js\"\n    }\n\n    model User {\n      id   Int @id @default(autoincrement())\n      name String\n    }\n  `)\n})","file":"removeDatasource.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"getDatabaseVersion","suites":[],"updatePoint":{"line":9,"column":22},"line":9,"code":"it('getDatabaseVersion', async () => {\n  ctx.fixture('schema-only')\n  const schemaPath = (await getSchemaPath())!\n  const migrate = new Migrate(schemaPath)\n  const result = migrate.engine.getDatabaseVersion()\n  await expect(result).resolves.toContain('PostgreSQL')\n  migrate.stop()\n})","file":"rpc.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"evaluateDataLoss - schema-only-sqlite","suites":[],"updatePoint":{"line":19,"column":41},"line":19,"code":"it('evaluateDataLoss - schema-only-sqlite', async () => {\n  ctx.fixture('schema-only-sqlite')\n  const schemaPath = (await getSchemaPath())!\n  const migrate = new Migrate(schemaPath)\n  const datamodel = migrate.getDatamodel()\n  const result = migrate.engine.evaluateDataLoss({\n    migrationsDirectoryPath: migrate.migrationsDirectoryPath,\n    prismaSchema: datamodel,\n  })\n\n  await expect(result).resolves.toMatchInlineSnapshot(`\n          Object {\n            migrationSteps: 1,\n            unexecutableSteps: Array [],\n            warnings: Array [],\n          }\n        `)\n  migrate.stop()\n})","file":"rpc.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"evaluateDataLoss - existing-db-1-migration","suites":[],"updatePoint":{"line":40,"column":46},"line":40,"code":"it('evaluateDataLoss - existing-db-1-migration', async () => {\n  ctx.fixture('existing-db-1-migration')\n  const schemaPath = (await getSchemaPath())!\n  const migrate = new Migrate(schemaPath)\n  const datamodel = migrate.getDatamodel()\n  const result = migrate.engine.evaluateDataLoss({\n    migrationsDirectoryPath: migrate.migrationsDirectoryPath,\n    prismaSchema: datamodel,\n  })\n\n  await expect(result).resolves.toMatchInlineSnapshot(`\n          Object {\n            migrationSteps: 0,\n            unexecutableSteps: Array [],\n            warnings: Array [],\n          }\n        `)\n  migrate.stop()\n})","file":"rpc.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"createMigration - existing-db-1-migration","suites":[],"updatePoint":{"line":60,"column":45},"line":60,"code":"it('createMigration - existing-db-1-migration', async () => {\n  ctx.fixture('schema-only-sqlite')\n  const schemaPath = (await getSchemaPath())!\n  const migrate = new Migrate(schemaPath)\n  const datamodel = migrate.getDatamodel()\n  const result = migrate.engine.createMigration({\n    migrationsDirectoryPath: migrate.migrationsDirectoryPath,\n    migrationName: 'my_migration',\n    draft: false,\n    prismaSchema: datamodel,\n  })\n\n  await expect(result).resolves.toMatchInlineSnapshot(`\n          Object {\n            generatedMigrationName: 20201231000000_my_migration,\n          }\n        `)\n  migrate.stop()\n})","file":"rpc.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"createMigration draft - existing-db-1-migration","suites":[],"updatePoint":{"line":80,"column":51},"line":80,"code":"it('createMigration draft - existing-db-1-migration', async () => {\n  ctx.fixture('existing-db-1-migration')\n  const schemaPath = (await getSchemaPath())!\n  const migrate = new Migrate(schemaPath)\n  const datamodel = migrate.getDatamodel()\n  const result = migrate.engine.createMigration({\n    migrationsDirectoryPath: migrate.migrationsDirectoryPath,\n    migrationName: 'draft_123',\n    draft: true,\n    prismaSchema: datamodel,\n  })\n\n  await expect(result).resolves.toMatchInlineSnapshot(`\n          Object {\n            generatedMigrationName: 20201231000000_draft_123,\n          }\n        `)\n  migrate.stop()\n})","file":"rpc.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"diagnoseMigrationHistory - optInToShadowDatabase true - existing-db-1-migration","suites":[],"updatePoint":{"line":100,"column":83},"line":100,"code":"it('diagnoseMigrationHistory - optInToShadowDatabase true - existing-db-1-migration', async () => {\n  ctx.fixture('existing-db-1-migration')\n  const schemaPath = (await getSchemaPath())!\n  const migrate = new Migrate(schemaPath)\n  const result = migrate.engine.diagnoseMigrationHistory({\n    migrationsDirectoryPath: migrate.migrationsDirectoryPath,\n    optInToShadowDatabase: true,\n  })\n\n  await expect(result).resolves.toMatchInlineSnapshot(`\n          Object {\n            editedMigrationNames: Array [],\n            failedMigrationNames: Array [],\n            hasMigrationsTable: true,\n            history: null,\n          }\n        `)\n  migrate.stop()\n})","file":"rpc.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"diagnoseMigrationHistory - optInToShadowDatabase false - existing-db-1-migration","suites":[],"updatePoint":{"line":120,"column":84},"line":120,"code":"it('diagnoseMigrationHistory - optInToShadowDatabase false - existing-db-1-migration', async () => {\n  ctx.fixture('existing-db-1-migration')\n  const schemaPath = (await getSchemaPath())!\n  const migrate = new Migrate(schemaPath)\n  const result = migrate.engine.diagnoseMigrationHistory({\n    migrationsDirectoryPath: migrate.migrationsDirectoryPath,\n    optInToShadowDatabase: false,\n  })\n\n  await expect(result).resolves.toMatchInlineSnapshot(`\n          Object {\n            editedMigrationNames: Array [],\n            failedMigrationNames: Array [],\n            hasMigrationsTable: true,\n            history: null,\n          }\n        `)\n  migrate.stop()\n})","file":"rpc.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"applyMigrations","suites":[],"updatePoint":{"line":140,"column":19},"line":140,"code":"it('applyMigrations', async () => {\n  ctx.fixture('existing-db-1-migration')\n  const schemaPath = (await getSchemaPath())!\n  const migrate = new Migrate(schemaPath)\n  const result = migrate.engine.applyMigrations({\n    migrationsDirectoryPath: migrate.migrationsDirectoryPath,\n  })\n\n  await expect(result).resolves.toMatchInlineSnapshot(`\n          Object {\n            appliedMigrationNames: Array [],\n          }\n        `)\n  migrate.stop()\n})","file":"rpc.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"applyMigrations - should fail on existing brownfield db","suites":[],"updatePoint":{"line":157,"column":59},"line":157,"code":"it('applyMigrations - should fail on existing brownfield db', async () => {\n  ctx.fixture('existing-db-brownfield')\n  const schemaPath = (await getSchemaPath())!\n  const migrate = new Migrate(schemaPath)\n  const result = migrate.engine.applyMigrations({\n    migrationsDirectoryPath: migrate.migrationsDirectoryPath,\n  })\n\n  await expect(result).rejects.toMatchInlineSnapshot(`\n          P3005\n\n          The database schema for \\`dev.db\\` is not empty. Read more about how to baseline an existing production database: https://pris.ly/d/migrate-baseline\n\n        `)\n  migrate.stop()\n})","file":"rpc.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"push","suites":[],"updatePoint":{"line":174,"column":8},"line":174,"code":"it('push', async () => {\n  ctx.fixture('schema-only-sqlite')\n  const schemaPath = (await getSchemaPath())!\n  const migrate = new Migrate(schemaPath)\n  const datamodel = migrate.getDatamodel()\n  const result = migrate.engine.schemaPush({\n    force: false,\n    schema: datamodel,\n  })\n\n  await expect(result).resolves.toMatchInlineSnapshot(`\n          Object {\n            executedSteps: 1,\n            unexecutable: Array [],\n            warnings: Array [],\n          }\n        `)\n  migrate.stop()\n})","file":"rpc.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"push should return executedSteps 0 with warning if dataloss detected","suites":[],"updatePoint":{"line":194,"column":72},"line":194,"code":"it('push should return executedSteps 0 with warning if dataloss detected', async () => {\n  ctx.fixture('existing-db-brownfield')\n  const schemaPath = (await getSchemaPath())!\n  const migrate = new Migrate(schemaPath)\n  const datamodel = migrate.getDatamodel()\n\n  const result = migrate.engine.schemaPush({\n    force: false,\n    schema: datamodel.replace('Blog', 'Something'),\n  })\n\n  await expect(result).resolves.toMatchInlineSnapshot(`\n          Object {\n            executedSteps: 0,\n            unexecutable: Array [],\n            warnings: Array [\n              You are about to drop the \\`Blog\\` table, which is not empty (1 rows).,\n            ],\n          }\n        `)\n  migrate.stop()\n})","file":"rpc.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"push force should accept dataloss","suites":[],"updatePoint":{"line":217,"column":37},"line":217,"code":"it('push force should accept dataloss', async () => {\n  ctx.fixture('existing-db-brownfield')\n  const schemaPath = (await getSchemaPath())!\n  const migrate = new Migrate(schemaPath)\n  const datamodel = migrate.getDatamodel()\n\n  const result = migrate.engine.schemaPush({\n    force: true,\n    schema: datamodel.replace('Blog', 'Something'),\n  })\n\n  await expect(result).resolves.toMatchInlineSnapshot(`\n          Object {\n            executedSteps: 2,\n            unexecutable: Array [],\n            warnings: Array [\n              You are about to drop the \\`Blog\\` table, which is not empty (1 rows).,\n            ],\n          }\n        `)\n  migrate.stop()\n})","file":"rpc.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"markMigrationRolledBack - should fail - existing-db-1-migration","suites":[],"updatePoint":{"line":240,"column":67},"line":240,"code":"it('markMigrationRolledBack - should fail - existing-db-1-migration', async () => {\n  jest.setTimeout(10000)\n  ctx.fixture('existing-db-1-migration')\n\n  const schemaPath = (await getSchemaPath())!\n  const migrate = new Migrate(schemaPath)\n\n  const resultMarkRolledBacked = migrate.engine.markMigrationRolledBack({\n    migrationName: '20201014154943_init',\n  })\n\n  await expect(resultMarkRolledBacked).rejects.toMatchInlineSnapshot(`\n          P3012\n\n          Migration \\`20201231000000_init\\` cannot be rolled back because it is not in a failed state.\n\n        `)\n\n  migrate.stop()\n})","file":"rpc.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"markMigrationRolledBack - existing-db-1-migration","suites":[],"updatePoint":{"line":261,"column":53},"line":261,"code":"it('markMigrationRolledBack - existing-db-1-migration', async () => {\n  ctx.fixture('existing-db-1-migration')\n  const schemaPath = (await getSchemaPath())!\n  const migrate = new Migrate(schemaPath)\n  const datamodel = migrate.getDatamodel()\n  const result = await migrate.engine.createMigration({\n    migrationsDirectoryPath: migrate.migrationsDirectoryPath,\n    migrationName: 'draft_123',\n    draft: true,\n    prismaSchema: datamodel,\n  })\n\n  expect(result).toMatchInlineSnapshot(`\n          Object {\n            generatedMigrationName: 20201231000000_draft_123,\n          }\n        `)\n\n  fs.write(\n    path.join(migrate.migrationsDirectoryPath, result.generatedMigrationName!, 'migration.sql'),\n    'SELECT SOMETHING_THAT_DOES_NOT_WORK',\n  )\n\n  try {\n    await migrate.engine.applyMigrations({\n      migrationsDirectoryPath: migrate.migrationsDirectoryPath,\n    })\n  } catch (e) {\n    expect(e.message).toContain('no such column: SOMETHING_THAT_DOES_NOT_WORK')\n  }\n\n  const resultMarkRolledBacked = migrate.engine.markMigrationRolledBack({\n    migrationName: result.generatedMigrationName!,\n  })\n\n  await expect(resultMarkRolledBacked).resolves.toMatchSnapshot()\n\n  const resultMarkAppliedFailed = migrate.engine.markMigrationApplied({\n    migrationsDirectoryPath: migrate.migrationsDirectoryPath,\n    migrationName: result.generatedMigrationName!,\n  })\n\n  await expect(resultMarkAppliedFailed).resolves.toMatchSnapshot()\n\n  const resultMarkApplied = migrate.engine.markMigrationApplied({\n    migrationsDirectoryPath: migrate.migrationsDirectoryPath,\n    migrationName: result.generatedMigrationName!,\n  })\n\n  await expect(resultMarkApplied).rejects.toMatchInlineSnapshot(`\n          P3008\n\n          The migration \\`20201231000000_draft_123\\` is already recorded as applied in the database.\n\n        `)\n\n  migrate.stop()\n})","file":"rpc.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"markMigrationApplied - existing-db-1-migration","suites":[],"updatePoint":{"line":320,"column":50},"line":320,"code":"it('markMigrationApplied - existing-db-1-migration', async () => {\n  ctx.fixture('existing-db-1-migration')\n  const schemaPath = (await getSchemaPath())!\n  const migrate = new Migrate(schemaPath)\n  const datamodel = migrate.getDatamodel()\n  const result = await migrate.engine.createMigration({\n    migrationsDirectoryPath: migrate.migrationsDirectoryPath,\n    migrationName: 'draft_123',\n    draft: true,\n    prismaSchema: datamodel,\n  })\n\n  expect(result).toMatchInlineSnapshot(`\n          Object {\n            generatedMigrationName: 20201231000000_draft_123,\n          }\n        `)\n\n  const resultMarkApplied = migrate.engine.markMigrationApplied({\n    migrationsDirectoryPath: migrate.migrationsDirectoryPath,\n    migrationName: result.generatedMigrationName!,\n  })\n\n  await expect(resultMarkApplied).resolves.toMatchInlineSnapshot(`Object {}`)\n\n  migrate.stop()\n})","file":"rpc.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"listMigrationDirectories - existing-db-1-migration","suites":[],"updatePoint":{"line":348,"column":54},"line":348,"code":"it('listMigrationDirectories - existing-db-1-migration', async () => {\n  ctx.fixture('existing-db-1-migration')\n  const schemaPath = (await getSchemaPath())!\n  const migrate = new Migrate(schemaPath)\n  const result = migrate.engine.listMigrationDirectories({\n    migrationsDirectoryPath: migrate.migrationsDirectoryPath,\n  })\n  await expect(result).resolves.toMatchInlineSnapshot(`\n          Object {\n            migrations: Array [\n              20201231000000_init,\n            ],\n          }\n        `)\n\n  migrate.stop()\n})","file":"rpc.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"listMigrationDirectories - schema-only-sqlite","suites":[],"updatePoint":{"line":366,"column":49},"line":366,"code":"it('listMigrationDirectories - schema-only-sqlite', async () => {\n  ctx.fixture('schema-only-sqlite')\n  const schemaPath = (await getSchemaPath())!\n  const migrate = new Migrate(schemaPath)\n  const result = migrate.engine.listMigrationDirectories({\n    migrationsDirectoryPath: migrate.migrationsDirectoryPath,\n  })\n  await expect(result).resolves.toMatchInlineSnapshot(`\n          Object {\n            migrations: Array [],\n          }\n        `)\n\n  migrate.stop()\n})","file":"rpc.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"devDiagnostic - createMigration","suites":[],"updatePoint":{"line":382,"column":35},"line":382,"code":"it('devDiagnostic - createMigration', async () => {\n  ctx.fixture('schema-only-sqlite')\n  const schemaPath = (await getSchemaPath())!\n  const migrate = new Migrate(schemaPath)\n  const result = migrate.engine.devDiagnostic({\n    migrationsDirectoryPath: migrate.migrationsDirectoryPath,\n  })\n  await expect(result).resolves.toMatchInlineSnapshot(`\n          Object {\n            action: Object {\n              tag: createMigration,\n            },\n          }\n        `)\n\n  migrate.stop()\n})","file":"rpc.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"devDiagnostic - reset because drift","suites":[],"updatePoint":{"line":400,"column":39},"line":400,"code":"it('devDiagnostic - reset because drift', async () => {\n  ctx.fixture('existing-db-1-migration-conflict')\n  const schemaPath = (await getSchemaPath())!\n  const migrate = new Migrate(schemaPath)\n  const result = migrate.engine.devDiagnostic({\n    migrationsDirectoryPath: migrate.migrationsDirectoryPath,\n  })\n  await expect(result).resolves.toMatchInlineSnapshot(`\n          Object {\n            action: Object {\n              reason: Drift detected: Your database schema is not in sync with your migration history.\n\n          The following is a summary of the differences between the expected database schema given your migrations files, and the actual schema of the database.\n\n          It should be understood as the set of changes to get from the expected schema to the actual schema.\n\n          If you are running this the first time on an existing database, please make sure to read this documentation page:\n          https://www.prisma.io/docs/guides/database/developing-with-prisma-migrate/troubleshooting-development\n\n          [+] Added tables\n            - Blog\n            - _Migration\n          ,\n              tag: reset,\n            },\n          }\n        `)\n\n  migrate.stop()\n})","file":"rpc.test.ts","skipped":false,"dir":"packages/migrate/src/__tests__"},{"name":"check async signature","suites":["checkpointClient"],"updatePoint":{"line":4,"column":29},"line":4,"code":"  test('check async signature', async () => {\n    // getSignature is used in SendPanic\n    const signature = await checkpoint.getSignature()\n\n    // Check if it's a uuid\n    expect(signature).toMatch(\n      /(?:^[a-f0-9]{8}-[a-f0-9]{4}-4[a-f0-9]{3}-[a-f0-9]{4}-[a-f0-9]{12}$)|(?:^0{8}-0{4}-0{4}-0{4}-0{12}$)/u,\n    )\n  })","file":"checkpointClient.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"Convert ","suites":[],"updatePoint":{"line":29,"column":22},"line":29,"code":"  test(`Convert ${uri}`, () => {\n    const credentials = uriToCredentials(uri)\n    const uriFromCredentials = credentialsToUri(credentials)\n\n    expect(credentials).toMatchSnapshot()\n    expect(uriFromCredentials).toMatchSnapshot()\n\n    expect(uriFromCredentials).toBe(uri)\n  })","file":"convertCredentials.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"Convert ","suites":[],"updatePoint":{"line":55,"column":22},"line":55,"code":"  test(`Convert ${uri}`, () => {\n    const credentials = uriToCredentials(uri)\n    const uriFromCredentials = credentialsToUri(credentials)\n\n    expect(credentials).toMatchSnapshot()\n    expect(uriFromCredentials).toMatchSnapshot()\n  })","file":"convertCredentials.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"should not expand","suites":["dotenvExpand"],"updatePoint":{"line":6,"column":25},"line":6,"code":"  test('should not expand', () => {\n    const config = {\n      parsed: {\n        SQLITE1: 'file:dev.db',\n        SQLITE2: 'file:$dev.db',\n        SQLITE3: 'file:$dev$.db',\n        SQLITE4: 'file:$dev.db',\n        SQLITE5: 'file:dev$.db',\n        SQLITE6: 'file:dev{$.db',\n        SQLITE7: 'file:${dev.db',\n        SQLITE8: 'file:${dev$.db',\n        POSTGRES1: 'postgres://user:password@server.host:5432/database?ssl=1&schema=schema$1234',\n        POSTGRES2: 'postgres://$user:password@server.host:5432/database?ssl=1&schema=schema$1234',\n        POSTGRES3: 'postgres://u$ser:pass$word@server.host:5432/database?ssl=1&schema=schema$1234',\n        POSTGRES4: 'postgres://user:password@serv$er.host:5432/database?ssl=1&schema=schema$1234',\n        MYSQL1: 'mysql://user:password@serv$er.host:5432/$database',\n        MYSQL2: 'mysql://user:password@server.host:5432/d$atabase',\n      },\n    }\n    expect(dotenvExpand(config)).toMatchInlineSnapshot(`\n      Object {\n        \"parsed\": Object {\n          \"MYSQL1\": \"mysql://user:password@serv$er.host:5432/$database\",\n          \"MYSQL2\": \"mysql://user:password@server.host:5432/d$atabase\",\n          \"POSTGRES1\": \"postgres://user:password@server.host:5432/database?ssl=1&schema=schema$1234\",\n          \"POSTGRES2\": \"postgres://$user:password@server.host:5432/database?ssl=1&schema=schema$1234\",\n          \"POSTGRES3\": \"postgres://u$ser:pass$word@server.host:5432/database?ssl=1&schema=schema$1234\",\n          \"POSTGRES4\": \"postgres://user:password@serv$er.host:5432/database?ssl=1&schema=schema$1234\",\n          \"SQLITE1\": \"file:dev.db\",\n          \"SQLITE2\": \"file:$dev.db\",\n          \"SQLITE3\": \"file:$dev$.db\",\n          \"SQLITE4\": \"file:$dev.db\",\n          \"SQLITE5\": \"file:dev$.db\",\n          \"SQLITE6\": \"file:dev{$.db\",\n          \"SQLITE7\": \"file:\\${dev.db\",\n          \"SQLITE8\": \"file:\\${dev$.db\",\n        },\n      }\n    `)\n  })","file":"dotenvExpand.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"should expand","suites":["dotenvExpand"],"updatePoint":{"line":46,"column":21},"line":46,"code":"  test('should expand', () => {\n    const config = {\n      parsed: {\n        DOTENV_PRISMA_EXPAND_DATABASE_URL: 'postgres://user:password@server.host:5432/database',\n        DOTENV_PRISMA_EXPAND_DATABASE_URL_WITH_SCHEMA: '${DOTENV_PRISMA_EXPAND_DATABASE_URL}?ssl=1&schema=schema$1234',\n      },\n    }\n    expect(dotenvExpand(config)).toMatchInlineSnapshot(`\n      Object {\n        \"parsed\": Object {\n          \"DOTENV_PRISMA_EXPAND_DATABASE_URL\": \"postgres://user:password@server.host:5432/database\",\n          \"DOTENV_PRISMA_EXPAND_DATABASE_URL_WITH_SCHEMA\": \"postgres://user:password@server.host:5432/database?ssl=1&schema=schema$1234\",\n        },\n      }\n    `)\n  })","file":"dotenvExpand.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"returns object","suites":["dotenvExpand"],"updatePoint":{"line":68,"column":20},"line":68,"code":"  it('returns object', () => {\n    const dotenv = { parsed: {} }\n    const obj = dotenvExpand(dotenv).parsed\n\n    expect(obj).toBeInstanceOf(Object)\n  })","file":"dotenvExpand.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"expands environment variables","suites":["dotenvExpand"],"updatePoint":{"line":75,"column":35},"line":75,"code":"  it('expands environment variables', () => {\n    const dotenv = {\n      parsed: {\n        BASIC: 'basic',\n        BASIC_EXPAND: '${BASIC}',\n        BASIC_EXPAND_SIMPLE: '$BASIC',\n      },\n    }\n    const obj = dotenvExpand(dotenv).parsed\n\n    expect(obj).toMatchInlineSnapshot(`\n      Object {\n        \"BASIC\": \"basic\",\n        \"BASIC_EXPAND\": \"basic\",\n        \"BASIC_EXPAND_SIMPLE\": \"$BASIC\",\n      }\n    `)\n  })","file":"dotenvExpand.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"expands environment variables existing already on the machine","suites":["dotenvExpand"],"updatePoint":{"line":94,"column":67},"line":94,"code":"  it('expands environment variables existing already on the machine', () => {\n    process.env.MACHINE = 'machine'\n    const dotenv = {\n      parsed: {\n        MACHINE_EXPAND: '${MACHINE}',\n        MACHINE_EXPAND_SIMPLE: '$MACHINE',\n      },\n    }\n    const obj = dotenvExpand(dotenv).parsed\n\n    expect(obj).toMatchInlineSnapshot(`\n      Object {\n        \"MACHINE_EXPAND\": \"machine\",\n        \"MACHINE_EXPAND_SIMPLE\": \"$MACHINE\",\n      }\n    `)\n  })","file":"dotenvExpand.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"expands missing environment variables to an empty string","suites":["dotenvExpand"],"updatePoint":{"line":112,"column":62},"line":112,"code":"  it('expands missing environment variables to an empty string', () => {\n    const dotenv = {\n      parsed: {\n        UNDEFINED_EXPAND: '$UNDEFINED_ENV_KEY',\n      },\n    }\n    const obj = dotenvExpand(dotenv).parsed\n\n    expect(obj).toMatchInlineSnapshot(`\n      Object {\n        \"UNDEFINED_EXPAND\": \"$UNDEFINED_ENV_KEY\",\n      }\n    `)\n  })","file":"dotenvExpand.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"prioritizes machine key expansion over .env","suites":["dotenvExpand"],"updatePoint":{"line":127,"column":49},"line":127,"code":"  it('prioritizes machine key expansion over .env', () => {\n    process.env.MACHINE = 'machine'\n    const dotenv = {\n      parsed: {\n        MACHINE: 'machine_env',\n        MACHINE_EXPAND: '$MACHINE',\n      },\n    }\n    const obj = dotenvExpand(dotenv).parsed\n\n    expect(obj).toMatchInlineSnapshot(`\n      Object {\n        \"MACHINE\": \"machine\",\n        \"MACHINE_EXPAND\": \"machine\",\n      }\n    `)\n  })","file":"dotenvExpand.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"does not expand escaped variables","suites":["dotenvExpand"],"updatePoint":{"line":145,"column":39},"line":145,"code":"  it('does not expand escaped variables', () => {\n    const dotenv = {\n      parsed: {\n        ESCAPED_EXPAND: '\\\\$ESCAPED',\n      },\n    }\n    const obj = dotenvExpand(dotenv).parsed\n\n    expect(obj).toMatchInlineSnapshot(`\n      Object {\n        \"ESCAPED_EXPAND\": \"\\\\\\\\$ESCAPED\",\n      }\n    `)\n  })","file":"dotenvExpand.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"does not expand inline escaped dollar sign","suites":["dotenvExpand"],"updatePoint":{"line":160,"column":48},"line":160,"code":"  it('does not expand inline escaped dollar sign', () => {\n    const dotenv = {\n      parsed: {\n        INLINE_ESCAPED_EXPAND: 'pa\\\\$\\\\$word',\n      },\n    }\n    const obj = dotenvExpand(dotenv).parsed\n\n    expect(obj).toMatchInlineSnapshot(`\n      Object {\n        \"INLINE_ESCAPED_EXPAND\": \"pa\\\\\\\\$\\\\\\\\$word\",\n      }\n    `)\n  })","file":"dotenvExpand.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"does not overwrite preset variables","suites":["dotenvExpand"],"updatePoint":{"line":175,"column":41},"line":175,"code":"  it('does not overwrite preset variables', () => {\n    process.env.SOME_ENV = 'production'\n    const dotenv = {\n      parsed: {\n        SOME_ENV: 'development',\n      },\n    }\n    const obj = dotenvExpand(dotenv).parsed\n\n    expect(obj).toMatchInlineSnapshot(`\n      Object {\n        \"SOME_ENV\": \"production\",\n      }\n    `)\n  })","file":"dotenvExpand.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"does not expand inline escaped dollar sign 2","suites":["dotenvExpand"],"updatePoint":{"line":191,"column":50},"line":191,"code":"  it('does not expand inline escaped dollar sign 2', () => {\n    const dotenv = {\n      parsed: {\n        INLINE_ESCAPED_EXPAND_BCRYPT: '\\\\$2b\\\\$10\\\\$OMZ69gxxsmRgwAt945WHSujpr/u8ZMx.xwtxWOCMkeMW7p3XqKYca',\n      },\n    }\n    const obj = dotenvExpand(dotenv).parsed\n\n    expect(obj).toMatchInlineSnapshot(`\n      Object {\n        \"INLINE_ESCAPED_EXPAND_BCRYPT\": \"\\\\\\\\$2b\\\\\\\\$10\\\\\\\\$OMZ69gxxsmRgwAt945WHSujpr/u8ZMx.xwtxWOCMkeMW7p3XqKYca\",\n      }\n    `)\n  })","file":"dotenvExpand.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"handle mixed values","suites":["dotenvExpand"],"updatePoint":{"line":206,"column":25},"line":206,"code":"  it('handle mixed values', () => {\n    const dotenv = {\n      parsed: {\n        PARAM1: '42',\n        MIXED_VALUES: '\\\\$this$PARAM1\\\\$is${PARAM1}',\n      },\n    }\n    const obj = dotenvExpand(dotenv).parsed\n\n    expect(obj).toMatchInlineSnapshot(`\n      Object {\n        \"MIXED_VALUES\": \"\\\\\\\\$this$PARAM1\\\\\\\\$is42\",\n        \"PARAM1\": \"42\",\n      }\n    `)\n  })","file":"dotenvExpand.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"expands environment variables","suites":["integration"],"updatePoint":{"line":233,"column":35},"line":233,"code":"  it('expands environment variables', () => {\n    dotenvExpand(dotenv)\n\n    expect(process.env['BASIC_EXPAND']).toBe('basic')\n  })","file":"dotenvExpand.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"expands environment variables existing already on the machine","suites":["integration"],"updatePoint":{"line":239,"column":67},"line":239,"code":"  it('expands environment variables existing already on the machine', () => {\n    process.env.MACHINE = 'machine'\n    dotenvExpand(dotenv)\n\n    expect(process.env['MACHINE_EXPAND']).toBe('machine')\n  })","file":"dotenvExpand.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"expands missing environment variables to an empty string","suites":["integration"],"updatePoint":{"line":246,"column":62},"line":246,"code":"  it('expands missing environment variables to an empty string', () => {\n    const obj = dotenvExpand(dotenv).parsed!\n\n    expect(obj['UNDEFINED_EXPAND']).toBe('$UNDEFINED_ENV_KEY')\n  })","file":"dotenvExpand.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"prioritizes machine key expansion over .env","suites":["integration"],"updatePoint":{"line":252,"column":49},"line":252,"code":"  it('prioritizes machine key expansion over .env', () => {\n    process.env.MACHINE = 'machine'\n    const obj = dotenvExpand(dotenv).parsed!\n\n    expect(obj['MACHINE_EXPAND']).toBe('machine')\n  })","file":"dotenvExpand.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"multiple expand","suites":["integration"],"updatePoint":{"line":259,"column":21},"line":259,"code":"  it('multiple expand', () => {\n    const obj = dotenvExpand(dotenv).parsed!\n\n    expect(obj['MONGOLAB_URI']).toBe('mongodb://username:password@abcd1234.mongolab.com:12345/heroku_db')\n  })","file":"dotenvExpand.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"should expand recursively","suites":["integration"],"updatePoint":{"line":265,"column":31},"line":265,"code":"  it('should expand recursively', () => {\n    const obj = dotenvExpand(dotenv).parsed!\n\n    expect(obj['MONGOLAB_URI_RECURSIVELY']).toBe('mongodb://username:password@abcd1234.mongolab.com:12345/heroku_db')\n  })","file":"dotenvExpand.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"multiple expand without curly","suites":["integration"],"updatePoint":{"line":271,"column":35},"line":271,"code":"  it('multiple expand without curly', () => {\n    const obj = dotenvExpand(dotenv).parsed!\n\n    expect(obj['WITHOUT_CURLY_BRACES_URI']).toBe(\n      'mongodb://$MONGOLAB_USER:$MONGOLAB_PASSWORD@$MONGOLAB_DOMAIN:$MONGOLAB_PORT/$MONGOLAB_DATABASE',\n    )\n  })","file":"dotenvExpand.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"should expand recursively without curly","suites":["integration"],"updatePoint":{"line":279,"column":45},"line":279,"code":"  it('should expand recursively without curly', () => {\n    const obj = dotenvExpand(dotenv).parsed!\n\n    expect(obj['WITHOUT_CURLY_BRACES_URI_RECURSIVELY']).toBe(\n      'mongodb://$MONGOLAB_USER_RECURSIVELY@$MONGOLAB_DOMAIN:$MONGOLAB_PORT/$MONGOLAB_DATABASE',\n    )\n  })","file":"dotenvExpand.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"should not write to process.env if ignoreProcessEnv is set","suites":["integration"],"updatePoint":{"line":287,"column":64},"line":287,"code":"  it('should not write to process.env if ignoreProcessEnv is set', () => {\n    const dotenv = {\n      ignoreProcessEnv: true,\n      parsed: {\n        SHOULD_NOT_EXIST: 'testing',\n      },\n    }\n    const obj = dotenvExpand(dotenv).parsed!\n\n    expect(process.env.SHOULD_NOT_EXIST).toBe(undefined)\n    expect(obj.SHOULD_NOT_EXIST).toBe('testing')\n  })","file":"dotenvExpand.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"nothing","suites":["format"],"updatePoint":{"line":10,"column":15},"line":10,"code":"  test('nothing', async () => {\n    try {\n      // @ts-expect-error\n      await formatSchema({})\n    } catch (e) {\n      expect(e.message).toMatchSnapshot()\n    }\n  })","file":"engine-commands/formatSchema.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"valid blog schemaPath","suites":["format"],"updatePoint":{"line":19,"column":29},"line":19,"code":"  test('valid blog schemaPath', async () => {\n    const formatted = await formatSchema({\n      schemaPath: path.join(fixturesPath, 'blog.prisma'),\n    })\n\n    expect(formatted).toMatchSnapshot()\n  })","file":"engine-commands/formatSchema.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"valid blog schema","suites":["format"],"updatePoint":{"line":27,"column":25},"line":27,"code":"  test('valid blog schema', async () => {\n    const formatted = await formatSchema({\n      schema: `\n      datasource db {\n        provider = \"sqlite\"\n        url      = \"file:dev.db\"\n      }\n      \n      generator client {\n        provider      = \"prisma-client-js\"\n        binaryTargets = [\"native\"]\n      }\n      \n      model User {\n        id    String  @default(cuid()) @id\n        email String  @unique\n        name  String?\n        posts Post[]\n      }\n      \n      model Post {\n        id        String   @default(cuid()) @id\n        createdAt DateTime @default(now())\n        updatedAt DateTime @updatedAt\n        published Boolean\n        title     String\n        content   String?\n        authorId  String?\n        author    User?    @relation(fields: [authorId], references: [id])\n      }\n      \n      model Like {\n        id     String @default(cuid()) @id\n        userId String\n        user   User   @relation(fields: [userId], references: [id])\n        postId String\n        post   Post   @relation(fields: [postId], references: [id])\n      \n        @@unique([userId, postId])\n      }`,\n    })\n\n    expect(formatted).toMatchSnapshot()\n  })","file":"engine-commands/formatSchema.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"empty config","suites":["getConfig"],"updatePoint":{"line":5,"column":20},"line":5,"code":"  test('empty config', async () => {\n    const config = await getConfig({\n      datamodel: `\n      datasource db {\n        provider = \"sqlite\"\n        url      = \"file:../hello.db\"\n      }\n      \n      model A {\n        id Int @id\n        name String\n      }`,\n    })\n\n    expect(config.datasources).toHaveLength(1)\n    expect(config.datasources[0].provider).toEqual('sqlite')\n    expect(config.generators).toHaveLength(0)\n    expect(config.warnings).toHaveLength(0)\n    expect(config).toMatchSnapshot()\n  })","file":"engine-commands/getConfig.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"sqlite and createMany","suites":["getConfig"],"updatePoint":{"line":26,"column":29},"line":26,"code":"  test('sqlite and createMany', async () => {\n    expect.assertions(1)\n    try {\n      await getConfig({\n        datamodel: `\n      datasource db {\n        provider = \"sqlite\"\n        url      = \"file:../hello.db\"\n      }\n\n      generator client {\n        provider = \"prisma-client-js\"\n        previewFeatures = [\"createMany\"]\n      }\n      \n      model A {\n        id Int @id\n        name String\n      }`,\n      })\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchInlineSnapshot(`\n        \"Get config: Database provider \\\\\"sqlite\\\\\" and the preview feature \\\\\"createMany\\\\\" can't be used at the same time.\n          Please either remove the \\\\\"createMany\\\\\" feature flag or use any other database type that Prisma supports: postgres, mysql or sqlserver.\"\n      `)\n    }\n  })","file":"engine-commands/getConfig.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"with generator and datasource","suites":["getConfig"],"updatePoint":{"line":54,"column":37},"line":54,"code":"  test('with generator and datasource', async () => {\n    const config = await getConfig({\n      datamodel: `\n    datasource db {\n      url = \"file:dev.db\"\n      provider = \"sqlite\"\n    }\n\n    generator gen {\n      provider = \"fancy-provider\"\n      binaryTargets = [\"native\"]\n    }\n\n    model A {\n      id Int @id\n      name String\n    }`,\n    })\n\n    expect(config.datasources).toHaveLength(1)\n    expect(config.generators).toHaveLength(1)\n    expect(config.warnings).toHaveLength(0)\n    expect(config).toMatchSnapshot()\n  })","file":"engine-commands/getConfig.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"datasource with env var","suites":["getConfig"],"updatePoint":{"line":79,"column":31},"line":79,"code":"  test('datasource with env var', async () => {\n    process.env.TEST_POSTGRES_URI_FOR_DATASOURCE = 'postgres://user:password@something:5432/db'\n\n    const config = await getConfig({\n      datamodel: `\n      datasource db {\n        provider = \"postgresql\"\n        url      = env(\"TEST_POSTGRES_URI_FOR_DATASOURCE\")\n      }\n      `,\n    })\n\n    expect(config).toMatchSnapshot()\n  })","file":"engine-commands/getConfig.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"datasource with env var - ignoreEnvVarErrors","suites":["getConfig"],"updatePoint":{"line":94,"column":52},"line":94,"code":"  test('datasource with env var - ignoreEnvVarErrors', async () => {\n    const config = await getConfig({\n      ignoreEnvVarErrors: true,\n      datamodel: `\n      datasource db {\n        provider = \"postgresql\"\n        url      = env(\"SOMETHING-SOMETHING-1234\")\n      }\n      `,\n    })\n\n    expect(config).toMatchSnapshot()\n  })","file":"engine-commands/getConfig.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"with engineType=\"binary\"","suites":["getConfig"],"updatePoint":{"line":107,"column":32},"line":107,"code":"  test('with engineType=\"binary\"', async () => {\n    const binaryConfig = await getConfig({\n      datamodel: `\n      datasource db {\n        provider = \"sqlite\"\n        url      = \"file:../hello.db\"\n      }\n\n      generator gen {\n        provider = \"fancy-provider\"\n        engineType = \"binary\"\n      }\n\n      model A {\n        id Int @id\n        name String\n      }`,\n    })\n\n    expect(binaryConfig).toMatchInlineSnapshot(`\nObject {\n  \"datasources\": Array [\n    Object {\n      \"activeProvider\": \"sqlite\",\n      \"name\": \"db\",\n      \"provider\": \"sqlite\",\n      \"url\": Object {\n        \"fromEnvVar\": null,\n        \"value\": \"file:../hello.db\",\n      },\n    },\n  ],\n  \"generators\": Array [\n    Object {\n      \"binaryTargets\": Array [],\n      \"config\": Object {\n        \"engineType\": \"binary\",\n      },\n      \"name\": \"gen\",\n      \"output\": null,\n      \"previewFeatures\": Array [],\n      \"provider\": Object {\n        \"fromEnvVar\": null,\n        \"value\": \"fancy-provider\",\n      },\n    },\n  ],\n  \"warnings\": Array [],\n}\n`)\n  })","file":"engine-commands/getConfig.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"with engineType=\"library\"","suites":["getConfig"],"updatePoint":{"line":158,"column":33},"line":158,"code":"  test('with engineType=\"library\"', async () => {\n    const libraryConfig = await getConfig({\n      datamodel: `\n      datasource db {\n        provider = \"sqlite\"\n        url      = \"file:../hello.db\"\n      }\n\n      generator gen {\n        provider = \"fancy-provider\"\n        engineType = \"library\"\n      }\n\n      model A {\n        id Int @id\n        name String\n      }`,\n    })\n\n    expect(libraryConfig).toMatchInlineSnapshot(`\nObject {\n  \"datasources\": Array [\n    Object {\n      \"activeProvider\": \"sqlite\",\n      \"name\": \"db\",\n      \"provider\": \"sqlite\",\n      \"url\": Object {\n        \"fromEnvVar\": null,\n        \"value\": \"file:../hello.db\",\n      },\n    },\n  ],\n  \"generators\": Array [\n    Object {\n      \"binaryTargets\": Array [],\n      \"config\": Object {\n        \"engineType\": \"library\",\n      },\n      \"name\": \"gen\",\n      \"output\": null,\n      \"previewFeatures\": Array [],\n      \"provider\": Object {\n        \"fromEnvVar\": null,\n        \"value\": \"fancy-provider\",\n      },\n    },\n  ],\n  \"warnings\": Array [],\n}\n`)\n  })","file":"engine-commands/getConfig.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"simple model, no datasource","suites":["getDMMF"],"updatePoint":{"line":15,"column":35},"line":15,"code":"  test('simple model, no datasource', async () => {\n    const dmmf = await getDMMF({\n      datamodel: `model A {\n        id Int @id\n        name String\n      }`,\n    })\n\n    expect(dmmf.datamodel).toMatchSnapshot()\n    expect(dmmf).toMatchSnapshot()\n  })","file":"engine-commands/getDmmf.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"simple model, sqlite","suites":["getDMMF"],"updatePoint":{"line":27,"column":28},"line":27,"code":"  test('simple model, sqlite', async () => {\n    const dmmf = await getDMMF({\n      datamodel: `\n      datasource db {\n        provider = \"sqlite\"\n        url      = \"file:dev.db\"\n      }\n      model A {\n        id Int @id\n        name String\n      }`,\n    })\n\n    expect(dmmf.datamodel).toMatchSnapshot()\n    expect(dmmf).toMatchSnapshot()\n  })","file":"engine-commands/getDmmf.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"simple model, postgresql","suites":["getDMMF"],"updatePoint":{"line":44,"column":32},"line":44,"code":"  test('simple model, postgresql', async () => {\n    const dmmf = await getDMMF({\n      datamodel: `\n      datasource db {\n        provider = \"postgresql\"\n        url      = env(\"MY_POSTGRESQL_DB\")\n      }\n      model A {\n        id Int @id\n        name String\n      }`,\n    })\n\n    expect(dmmf.datamodel).toMatchSnapshot()\n    expect(dmmf).toMatchSnapshot()\n  })","file":"engine-commands/getDmmf.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"simple model, mysql","suites":["getDMMF"],"updatePoint":{"line":61,"column":27},"line":61,"code":"  test('simple model, mysql', async () => {\n    const dmmf = await getDMMF({\n      datamodel: `\n      datasource db {\n        provider = \"mysql\"\n        url      = env(\"MY_MYSQL_DB\")\n      }\n      model A {\n        id Int @id\n        name String\n      }`,\n    })\n\n    expect(dmmf.datamodel).toMatchSnapshot()\n    expect(dmmf).toMatchSnapshot()\n  })","file":"engine-commands/getDmmf.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"simple model, sql server","suites":["getDMMF"],"updatePoint":{"line":78,"column":32},"line":78,"code":"  test('simple model, sql server', async () => {\n    const dmmf = await getDMMF({\n      datamodel: `\n      datasource db {\n        provider = \"sqlserver\"\n        url      = env(\"MY_SQLSERVER_DB\")\n      }\n      model A {\n        id Int @id\n        name String\n      }`,\n    })\n\n    expect(dmmf.datamodel).toMatchSnapshot()\n    expect(dmmf).toMatchSnapshot()\n  })","file":"engine-commands/getDmmf.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"simple model, mongodb","suites":["getDMMF"],"updatePoint":{"line":95,"column":29},"line":95,"code":"  test('simple model, mongodb', async () => {\n    const dmmf = await getDMMF({\n      datamodel: `\n      datasource db {\n        provider = \"mongodb\"\n        url      = \"MY_MONGODB_DB\"\n      }\n      model A {\n        id Int @id @map(\"_id\")\n        name String\n      }`,\n    })\n\n    expect(dmmf.datamodel).toMatchSnapshot()\n    expect(dmmf).toMatchSnapshot()\n  })","file":"engine-commands/getDmmf.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"@@map model","suites":["getDMMF"],"updatePoint":{"line":112,"column":19},"line":112,"code":"  test('@@map model', async () => {\n    const dmmf = await getDMMF({\n      datamodel: `\n      datasource db {\n        provider = \"postgresql\"\n        url      = env(\"MY_POSTGRESQL_DB\")\n      }\n      model User {\n        id        Int      @default(autoincrement())\n        email     String   @unique\n        @@map(\"users\")\n      }`,\n    })\n    expect(dmmf.datamodel).toMatchSnapshot()\n    expect(dmmf).toMatchSnapshot()\n  })","file":"engine-commands/getDmmf.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"model with autoincrement should fail if sqlite","suites":["getDMMF"],"updatePoint":{"line":129,"column":54},"line":129,"code":"  test('model with autoincrement should fail if sqlite', async () => {\n    const datamodel = `\n      datasource db {\n        provider = \"sqlite\"\n        url      = \"file:dev.db\"\n      }\n      model User {\n        id        Int      @default(autoincrement())\n        email     String   @unique\n        @@map(\"users\")\n      }`\n\n    try {\n      await getDMMF({ datamodel })\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchSnapshot()\n    }\n  })","file":"engine-commands/getDmmf.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"model with autoincrement should fail if mysql","suites":["getDMMF"],"updatePoint":{"line":148,"column":53},"line":148,"code":"  test('model with autoincrement should fail if mysql', async () => {\n    const datamodel = `\n      datasource db {\n        provider = \"mysql\"\n        url      = env(\"MY_MYSQL_DB\")\n      }\n      model User {\n        id        Int      @default(autoincrement())\n        email     String   @unique\n        @@map(\"users\")\n      }`\n\n    try {\n      await getDMMF({ datamodel })\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchSnapshot()\n    }\n  })","file":"engine-commands/getDmmf.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"@@unique model","suites":["getDMMF"],"updatePoint":{"line":167,"column":22},"line":167,"code":"  test('@@unique model', async () => {\n    const dmmf = await getDMMF({\n      datamodel: `\n      datasource db {\n        provider = \"postgres\"\n        url      = env(\"MY_POSTGRES_DB\")\n      }\n\n      // From https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-schema/data-model#examples-3\n      // Specify a multi-field unique attribute that includes a relation field\n      model Post {\n        id        Int     @default(autoincrement())\n        author    User    @relation(fields: [authorId], references: [id])\n        authorId  Int\n        title     String\n        published Boolean @default(false)\n        \n        @@unique([authorId, title])\n      }\n      model User {\n        id    Int    @id @default(autoincrement())\n        email String @unique\n        posts Post[]\n      }\n\n      // Specify a multi-field unique attribute on two String fields\n      model User1 {\n        id        Int     @default(autoincrement())\n        firstName String\n        lastName  String\n        isAdmin   Boolean @default(false)\n        @@unique([firstName, lastName])\n      }\n      \n      // Specify a multi-field unique attribute on two String fields and one Boolean field\n      model User2 {\n        id        Int     @default(autoincrement())\n        firstName String\n        lastName  String\n        isAdmin   Boolean @default(false)\n        @@unique([firstName, lastName, isAdmin])\n      }\n  `,\n    })\n\n    expect(dmmf).toMatchSnapshot()\n  })","file":"engine-commands/getDmmf.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"@@id model","suites":["getDMMF"],"updatePoint":{"line":215,"column":18},"line":215,"code":"  test('@@id model', async () => {\n    const dmmf = await getDMMF({\n      datamodel: `\n      datasource db {\n        provider = \"postgres\"\n        url      = env(\"MY_POSTGRES_DB\")\n      }\n      generator client {\n        provider        = \"prisma-client-js\"\n      }\n      \n      model User1 {\n        id        Int     @default(autoincrement())\n        firstName String\n        lastName  String\n        isAdmin   Boolean @default(false)\n        @@id(fields: [firstName, lastName], name: \"customName\") // with name\n      }\n      \n      // Specify a multi-field id attribute on two String fields and one Boolean field\n      model User2 {\n        id        Int     @default(autoincrement())\n        firstName String\n        lastName  String\n        isAdmin   Boolean @default(false)\n        @@id([firstName, lastName, isAdmin])\n      }\n  `,\n    })\n\n    expect(dmmf).toMatchSnapshot()\n  })","file":"engine-commands/getDmmf.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"chinook introspected schema","suites":["getDMMF"],"updatePoint":{"line":248,"column":35},"line":248,"code":"  test('chinook introspected schema', async () => {\n    const file = fs.readFileSync(path.join(fixturesPath, 'chinook.prisma'), 'utf-8')\n    const dmmf = await getDMMF({\n      datamodel: file,\n    })\n    const str = JSON.stringify(dmmf)\n    expect(str.length).toMatchSnapshot()\n  })","file":"engine-commands/getDmmf.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"big schema","suites":["getDMMF"],"updatePoint":{"line":257,"column":18},"line":257,"code":"  test('big schema', async () => {\n    const file = fs.readFileSync(path.join(fixturesPath, 'bigschema.prisma'), 'utf-8')\n    const dmmf = await getDMMF({\n      datamodel: file,\n    })\n    const str = JSON.stringify(dmmf)\n    expect(str.length).toMatchSnapshot()\n  })","file":"engine-commands/getDmmf.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"with validation errors","suites":["getDMMF"],"updatePoint":{"line":266,"column":30},"line":266,"code":"  test('with validation errors', async () => {\n    const datamodel = `generator client {\n      provider = \"prisma-client-js\"\n    }\n    \n    datasource my_db {\n      provider = \"sqlite\"\n      url      = \"file:dev.db\"\n    }\n    \n    model User {\n      id           String     @id @default(cuid())\n      id           String     @id @default(cuid())\n      name         String\n      email        String     @unique\n      status       String     @default(\"\")\n      permissions  Permission @default()\n      permissions  Permission @default(\"\")\n      posts        Post[]\n      posts        Post[]\n    }\n    \n    model Post {\n      id        String   @id @default(cuid())\n      name      String\n      email     String   @unique\n      createdAt DateTime @default(now())\n      updatedAt DateTime @updatedAt\n    }\n    \n    enum Permission {\n      ADMIN\n      USER\n      OWNER\n      COLLABORATOR\n    }\n    `\n    try {\n      await getDMMF({ datamodel })\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchSnapshot()\n    }\n  })","file":"engine-commands/getDmmf.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"Introspection Engine","suites":["getVersion"],"updatePoint":{"line":8,"column":28},"line":8,"code":"  test('Introspection Engine', async () => {\n    const introspectionEngineVersion = await getVersion(undefined, BinaryType.introspectionEngine)\n    expect(introspectionEngineVersion.split(' ')[1]).toMatch(enginesVersion)\n  })","file":"engine-commands/getVersion.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"Migration Engine","suites":["getVersion"],"updatePoint":{"line":13,"column":24},"line":13,"code":"  test('Migration Engine', async () => {\n    const migrationEngineVersion = await getVersion(undefined, BinaryType.migrationEngine)\n    expect(migrationEngineVersion.split(' ')[1]).toMatch(enginesVersion)\n  })","file":"engine-commands/getVersion.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"Prisma Fmt","suites":["getVersion"],"updatePoint":{"line":18,"column":18},"line":18,"code":"  test('Prisma Fmt', async () => {\n    const prismaFmtVersion = await getVersion(undefined, BinaryType.prismaFmt)\n    expect(prismaFmtVersion.split(' ')[1]).toMatch(enginesVersion)\n  })","file":"engine-commands/getVersion.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"basic","suites":["getGenerators"],"updatePoint":{"line":25,"column":13},"line":25,"code":"  test('basic', async () => {\n    const aliases = {\n      'predefined-generator': {\n        generatorPath: generatorPath,\n        outputPath: __dirname,\n      },\n    }\n\n    const generators = await getGenerators({\n      schemaPath: path.join(__dirname, 'valid-minimal-schema.prisma'),\n      providerAliases: aliases,\n    })\n\n    expect(generators.map((g) => g.manifest)).toMatchInlineSnapshot(`\n      Array [\n        Object {\n          \"defaultOutput\": \"default-output\",\n          \"denylist\": Array [\n            \"SomeForbiddenType\",\n          ],\n          \"prettyName\": \"This is a pretty pretty name\",\n          \"requiresEngines\": Array [\n            \"queryEngine\",\n            \"migrationEngine\",\n          ],\n        },\n      ]\n    `)\n\n    expect(pick(generators[0].options!, ['datamodel', 'datasources', 'otherGenerators'])).toMatchInlineSnapshot(`\n      Object {\n        \"datamodel\": \"datasource db {\n        provider = \\\\\"sqlite\\\\\"\n        url      = \\\\\"file:./dev.db\\\\\"\n      }\n\n      generator gen {\n        provider      = \\\\\"predefined-generator\\\\\"\n        binaryTargets = [\\\\\"darwin\\\\\"]\n      }\n\n      model User {\n        id   Int    @id\n        name String\n      }\n      \",\n        \"datasources\": Array [\n          Object {\n            \"activeProvider\": \"sqlite\",\n            \"name\": \"db\",\n            \"provider\": \"sqlite\",\n            \"url\": Object {\n              \"fromEnvVar\": null,\n              \"value\": \"file:./dev.db\",\n            },\n          },\n        ],\n        \"otherGenerators\": Array [],\n      }\n    `)\n\n    expect(omit(generators[0].options!.generator, ['output'])).toMatchInlineSnapshot(`\n      Object {\n        \"binaryTargets\": Array [\n          Object {\n            \"fromEnvVar\": null,\n            \"value\": \"darwin\",\n          },\n        ],\n        \"config\": Object {},\n        \"name\": \"gen\",\n        \"previewFeatures\": Array [],\n        \"provider\": Object {\n          \"fromEnvVar\": null,\n          \"value\": \"predefined-generator\",\n        },\n      }\n    `)\n\n    generators.forEach((g) => g.stop())\n  })","file":"getGenerators/getGenerators.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"basic - binaryTargets - native string","suites":["getGenerators"],"updatePoint":{"line":107,"column":43},"line":107,"code":"  it('basic - binaryTargets - native string', async () => {\n    const aliases = {\n      'predefined-generator': {\n        generatorPath: generatorPath,\n        outputPath: __dirname,\n      },\n    }\n\n    const generators = await getGenerators({\n      schemaPath: path.join(__dirname, 'valid-minimal-schema-binaryTargets.prisma'),\n      providerAliases: aliases,\n    })\n\n    expect(generators.map((g) => g.manifest)).toMatchInlineSnapshot(`\n      Array [\n        Object {\n          \"defaultOutput\": \"default-output\",\n          \"denylist\": Array [\n            \"SomeForbiddenType\",\n          ],\n          \"prettyName\": \"This is a pretty pretty name\",\n          \"requiresEngines\": Array [\n            \"queryEngine\",\n            \"migrationEngine\",\n          ],\n        },\n      ]\n    `)\n\n    expect(pick(generators[0].options!, ['datamodel', 'datasources', 'otherGenerators'])).toMatchInlineSnapshot(`\n      Object {\n        \"datamodel\": \"datasource db {\n        provider = \\\\\"sqlite\\\\\"\n        url      = \\\\\"file:./dev.db\\\\\"\n      }\n\n      generator gen_env {\n        provider      = \\\\\"predefined-generator\\\\\"\n        binaryTargets = \\\\\"native\\\\\"\n      }\n\n      model User {\n        id   Int    @id\n        name String\n      }\n      \",\n        \"datasources\": Array [\n          Object {\n            \"activeProvider\": \"sqlite\",\n            \"name\": \"db\",\n            \"provider\": \"sqlite\",\n            \"url\": Object {\n              \"fromEnvVar\": null,\n              \"value\": \"file:./dev.db\",\n            },\n          },\n        ],\n        \"otherGenerators\": Array [],\n      }\n    `)\n\n    const generator = omit(generators[0].options!.generator, ['output'])\n    const platform = await getPlatform()\n\n    expect(generator.binaryTargets).toHaveLength(1)\n    expect(generator.binaryTargets[0].value).toEqual(platform)\n    expect(generator.binaryTargets[0].fromEnvVar).toEqual(null)\n\n    expect(omit(generator, ['binaryTargets'])).toMatchInlineSnapshot(`\n      Object {\n        \"config\": Object {},\n        \"name\": \"gen_env\",\n        \"previewFeatures\": Array [],\n        \"provider\": Object {\n          \"fromEnvVar\": null,\n          \"value\": \"predefined-generator\",\n        },\n      }\n    `)\n\n    generators.forEach((g) => g.stop())\n  })","file":"getGenerators/getGenerators.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"basic - binaryTargets as env var - native string","suites":["getGenerators"],"updatePoint":{"line":190,"column":54},"line":190,"code":"  it('basic - binaryTargets as env var - native string', async () => {\n    process.env.BINARY_TARGETS_ENV_VAR_TEST = '\"native\"'\n\n    const aliases = {\n      'predefined-generator': {\n        generatorPath: generatorPath,\n        outputPath: __dirname,\n      },\n    }\n\n    const generators = await getGenerators({\n      schemaPath: path.join(__dirname, 'valid-minimal-schema-binaryTargets-env-var.prisma'),\n      providerAliases: aliases,\n    })\n\n    expect(generators.map((g) => g.manifest)).toMatchInlineSnapshot(`\n      Array [\n        Object {\n          \"defaultOutput\": \"default-output\",\n          \"denylist\": Array [\n            \"SomeForbiddenType\",\n          ],\n          \"prettyName\": \"This is a pretty pretty name\",\n          \"requiresEngines\": Array [\n            \"queryEngine\",\n            \"migrationEngine\",\n          ],\n        },\n      ]\n    `)\n\n    expect(pick(generators[0].options!, ['datamodel', 'datasources', 'otherGenerators'])).toMatchInlineSnapshot(`\n      Object {\n        \"datamodel\": \"datasource db {\n        provider = \\\\\"sqlite\\\\\"\n        url      = \\\\\"file:./dev.db\\\\\"\n      }\n\n      generator gen_env {\n        provider      = \\\\\"predefined-generator\\\\\"\n        binaryTargets = env(\\\\\"BINARY_TARGETS_ENV_VAR_TEST\\\\\")\n      }\n\n      model User {\n        id   Int    @id\n        name String\n      }\n      \",\n        \"datasources\": Array [\n          Object {\n            \"activeProvider\": \"sqlite\",\n            \"name\": \"db\",\n            \"provider\": \"sqlite\",\n            \"url\": Object {\n              \"fromEnvVar\": null,\n              \"value\": \"file:./dev.db\",\n            },\n          },\n        ],\n        \"otherGenerators\": Array [],\n      }\n    `)\n\n    const generator = omit(generators[0].options!.generator, ['output'])\n    const platform = await getPlatform()\n\n    expect(generator.binaryTargets).toHaveLength(1)\n    expect(generator.binaryTargets[0].value).toEqual(platform)\n    expect(generator.binaryTargets[0].fromEnvVar).toEqual('BINARY_TARGETS_ENV_VAR_TEST')\n\n    expect(omit(generator, ['binaryTargets'])).toMatchInlineSnapshot(`\n      Object {\n        \"config\": Object {},\n        \"name\": \"gen_env\",\n        \"previewFeatures\": Array [],\n        \"provider\": Object {\n          \"fromEnvVar\": null,\n          \"value\": \"predefined-generator\",\n        },\n      }\n    `)\n\n    generators.forEach((g) => g.stop())\n  })","file":"getGenerators/getGenerators.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"basic - binaryTargets as env var - native (in array)","suites":["getGenerators"],"updatePoint":{"line":275,"column":58},"line":275,"code":"  it('basic - binaryTargets as env var - native (in array)', async () => {\n    process.env.BINARY_TARGETS_ENV_VAR_TEST = '[\"native\"]'\n\n    const aliases = {\n      'predefined-generator': {\n        generatorPath: generatorPath,\n        outputPath: __dirname,\n      },\n    }\n\n    const generators = await getGenerators({\n      schemaPath: path.join(__dirname, 'valid-minimal-schema-binaryTargets-env-var.prisma'),\n      providerAliases: aliases,\n    })\n\n    expect(generators.map((g) => g.manifest)).toMatchInlineSnapshot(`\n              Array [\n                Object {\n                  \"defaultOutput\": \"default-output\",\n                  \"denylist\": Array [\n                    \"SomeForbiddenType\",\n                  ],\n                  \"prettyName\": \"This is a pretty pretty name\",\n                  \"requiresEngines\": Array [\n                    \"queryEngine\",\n                    \"migrationEngine\",\n                  ],\n                },\n              ]\n          `)\n\n    expect(pick(generators[0].options!, ['datamodel', 'datasources', 'otherGenerators'])).toMatchInlineSnapshot(`\n      Object {\n        \"datamodel\": \"datasource db {\n        provider = \\\\\"sqlite\\\\\"\n        url      = \\\\\"file:./dev.db\\\\\"\n      }\n\n      generator gen_env {\n        provider      = \\\\\"predefined-generator\\\\\"\n        binaryTargets = env(\\\\\"BINARY_TARGETS_ENV_VAR_TEST\\\\\")\n      }\n\n      model User {\n        id   Int    @id\n        name String\n      }\n      \",\n        \"datasources\": Array [\n          Object {\n            \"activeProvider\": \"sqlite\",\n            \"name\": \"db\",\n            \"provider\": \"sqlite\",\n            \"url\": Object {\n              \"fromEnvVar\": null,\n              \"value\": \"file:./dev.db\",\n            },\n          },\n        ],\n        \"otherGenerators\": Array [],\n      }\n    `)\n\n    const generator = omit(generators[0].options!.generator, ['output'])\n    const platform = await getPlatform()\n\n    expect(generator.binaryTargets).toHaveLength(1)\n    expect(generator.binaryTargets[0].value).toEqual(platform)\n    expect(generator.binaryTargets[0].fromEnvVar).toEqual('BINARY_TARGETS_ENV_VAR_TEST')\n\n    expect(omit(generator, ['binaryTargets'])).toMatchInlineSnapshot(`\n              Object {\n                \"config\": Object {},\n                \"name\": \"gen_env\",\n                \"previewFeatures\": Array [],\n                \"provider\": Object {\n                  \"fromEnvVar\": null,\n                  \"value\": \"predefined-generator\",\n                },\n              }\n          `)\n\n    generators.forEach((g) => g.stop())\n  })","file":"getGenerators/getGenerators.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"basic - binaryTargets as env var - darwin, windows, debian","suites":["getGenerators"],"updatePoint":{"line":360,"column":64},"line":360,"code":"  it('basic - binaryTargets as env var - darwin, windows, debian', async () => {\n    process.env.BINARY_TARGETS_ENV_VAR_TEST = '[\"darwin\", \"windows\", \"debian-openssl-1.1.x\"]'\n\n    const aliases = {\n      'predefined-generator': {\n        generatorPath: generatorPath,\n        outputPath: __dirname,\n      },\n    }\n\n    const generators = await getGenerators({\n      schemaPath: path.join(__dirname, 'valid-minimal-schema-binaryTargets-env-var.prisma'),\n      providerAliases: aliases,\n    })\n\n    expect(generators.map((g) => g.manifest)).toMatchInlineSnapshot(`\n              Array [\n                Object {\n                  \"defaultOutput\": \"default-output\",\n                  \"denylist\": Array [\n                    \"SomeForbiddenType\",\n                  ],\n                  \"prettyName\": \"This is a pretty pretty name\",\n                  \"requiresEngines\": Array [\n                    \"queryEngine\",\n                    \"migrationEngine\",\n                  ],\n                },\n              ]\n          `)\n\n    expect(pick(generators[0].options!, ['datamodel', 'datasources', 'otherGenerators'])).toMatchInlineSnapshot(`\n      Object {\n        \"datamodel\": \"datasource db {\n        provider = \\\\\"sqlite\\\\\"\n        url      = \\\\\"file:./dev.db\\\\\"\n      }\n\n      generator gen_env {\n        provider      = \\\\\"predefined-generator\\\\\"\n        binaryTargets = env(\\\\\"BINARY_TARGETS_ENV_VAR_TEST\\\\\")\n      }\n\n      model User {\n        id   Int    @id\n        name String\n      }\n      \",\n        \"datasources\": Array [\n          Object {\n            \"activeProvider\": \"sqlite\",\n            \"name\": \"db\",\n            \"provider\": \"sqlite\",\n            \"url\": Object {\n              \"fromEnvVar\": null,\n              \"value\": \"file:./dev.db\",\n            },\n          },\n        ],\n        \"otherGenerators\": Array [],\n      }\n    `)\n\n    expect(omit(generators[0].options!.generator, ['output'])).toMatchInlineSnapshot(`\n              Object {\n                \"binaryTargets\": Array [\n                  Object {\n                    \"fromEnvVar\": \"BINARY_TARGETS_ENV_VAR_TEST\",\n                    \"value\": \"darwin\",\n                  },\n                  Object {\n                    \"fromEnvVar\": \"BINARY_TARGETS_ENV_VAR_TEST\",\n                    \"value\": \"windows\",\n                  },\n                  Object {\n                    \"fromEnvVar\": \"BINARY_TARGETS_ENV_VAR_TEST\",\n                    \"value\": \"debian-openssl-1.1.x\",\n                  },\n                ],\n                \"config\": Object {},\n                \"name\": \"gen_env\",\n                \"previewFeatures\": Array [],\n                \"provider\": Object {\n                  \"fromEnvVar\": null,\n                  \"value\": \"predefined-generator\",\n                },\n              }\n          `)\n\n    generators.forEach((g) => g.stop())\n  })","file":"getGenerators/getGenerators.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"inject engines","suites":["getGenerators"],"updatePoint":{"line":452,"column":22},"line":452,"code":"  test('inject engines', async () => {\n    const aliases = {\n      'predefined-generator': {\n        generatorPath: generatorPath,\n        outputPath: __dirname,\n      },\n    }\n\n    const migrationEngine = await resolveBinary(BinaryType.migrationEngine)\n\n    const queryEngineBinaryType = getCliQueryEngineBinaryType()\n    const queryEnginePath = await resolveBinary(queryEngineBinaryType)\n\n    const generators = await getGenerators({\n      schemaPath: path.join(__dirname, 'valid-minimal-schema.prisma'),\n      providerAliases: aliases,\n      binaryPathsOverride: {\n        queryEngine: queryEnginePath,\n      },\n    })\n\n    const options = generators.map((g) => g.options?.binaryPaths)\n\n    const platform = await getPlatform()\n\n    // we override queryEngine, so its paths should be equal to the one of the generator\n    expect(options[0]?.queryEngine?.[platform]).toBe(queryEnginePath)\n    // we did not override the migrationEngine, so their paths should not be equal\n    expect(options[0]?.migrationEngine?.[platform]).not.toBe(migrationEngine)\n\n    generators.forEach((g) => g.stop())\n  })","file":"getGenerators/getGenerators.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"fail on platforms","suites":["getGenerators"],"updatePoint":{"line":485,"column":25},"line":485,"code":"  test('fail on platforms', async () => {\n    const aliases = {\n      'predefined-generator': {\n        generatorPath: generatorPath,\n        outputPath: __dirname,\n      },\n    }\n\n    await expect(\n      getGenerators({\n        schemaPath: path.join(__dirname, 'invalid-platforms-schema.prisma'),\n        providerAliases: aliases,\n      }),\n    ).rejects.toThrow('deprecated')\n  })","file":"getGenerators/getGenerators.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"fail on invalid binaryTarget","suites":["getGenerators"],"updatePoint":{"line":501,"column":36},"line":501,"code":"  test('fail on invalid binaryTarget', async () => {\n    const aliases = {\n      'predefined-generator': {\n        generatorPath: generatorPath,\n        outputPath: __dirname,\n      },\n    }\n\n    await expect(\n      getGenerators({\n        schemaPath: path.join(__dirname, 'invalid-binary-target-schema.prisma'),\n        providerAliases: aliases,\n      }),\n    ).rejects.toThrow('Unknown')\n  })","file":"getGenerators/getGenerators.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"fail if datasource is missing","suites":["getGenerators"],"updatePoint":{"line":517,"column":37},"line":517,"code":"  test('fail if datasource is missing', async () => {\n    expect.assertions(1)\n    const aliases = {\n      'predefined-generator': {\n        generatorPath: generatorPath,\n        outputPath: __dirname,\n      },\n    }\n\n    try {\n      await getGenerators({\n        schemaPath: path.join(__dirname, 'missing-datasource-schema.prisma'),\n        providerAliases: aliases,\n      })\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchInlineSnapshot(`\n        \"\n        You don't have any datasource defined in your schema.prisma.\n        You can define a datasource like this:\n\n        datasource db {\n          provider = \\\\\"postgresql\\\\\"\n          url      = env(\\\\\"DB_URL\\\\\")\n        }\n\n        More information in our documentation:\n        https://pris.ly/d/prisma-schema\n        \"\n      `)\n    }\n  })","file":"getGenerators/getGenerators.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"fail if no model(s) found - sqlite","suites":["getGenerators"],"updatePoint":{"line":549,"column":42},"line":549,"code":"  test('fail if no model(s) found - sqlite', async () => {\n    expect.assertions(1)\n    const aliases = {\n      'predefined-generator': {\n        generatorPath: generatorPath,\n        outputPath: __dirname,\n      },\n    }\n\n    try {\n      await getGenerators({\n        schemaPath: path.join(__dirname, 'missing-models-sqlite-schema.prisma'),\n        providerAliases: aliases,\n      })\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchInlineSnapshot(`\n        \"\n        You don't have any models defined in your schema.prisma, so nothing will be generated.\n        You can define a model like this:\n\n        model User {\n          id    Int     @id @default(autoincrement())\n          email String  @unique\n          name  String?\n        }\n\n        More information in our documentation:\n        https://pris.ly/d/prisma-schema\n        \"\n      `)\n    }\n  })","file":"getGenerators/getGenerators.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"fail if no model(s) found - mongodb","suites":["getGenerators"],"updatePoint":{"line":582,"column":43},"line":582,"code":"  test('fail if no model(s) found - mongodb', async () => {\n    expect.assertions(1)\n    const aliases = {\n      'predefined-generator': {\n        generatorPath: generatorPath,\n        outputPath: __dirname,\n      },\n    }\n\n    try {\n      await getGenerators({\n        schemaPath: path.join(__dirname, 'missing-models-mongodb-schema.prisma'),\n        providerAliases: aliases,\n      })\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchInlineSnapshot(`\n        \"\n        You don't have any models defined in your schema.prisma, so nothing will be generated.\n        You can define a model like this:\n\n        model User {\n          id    String  @id @default(dbgenerated()) @map(\\\\\"_id\\\\\") @db.ObjectId\n          email String  @unique\n          name  String?\n        }\n\n        More information in our documentation:\n        https://pris.ly/d/prisma-schema\n        \"\n      `)\n    }\n  })","file":"getGenerators/getGenerators.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"fail if mongoDb not found in previewFeatures - prisma-client-js - mongodb","suites":["getGenerators"],"updatePoint":{"line":615,"column":81},"line":615,"code":"  test('fail if mongoDb not found in previewFeatures - prisma-client-js - mongodb', async () => {\n    expect.assertions(1)\n    const aliases = {\n      'predefined-generator': {\n        generatorPath: generatorPath,\n        outputPath: __dirname,\n      },\n    }\n\n    try {\n      await getGenerators({\n        schemaPath: path.join(__dirname, 'missing-mongoDb-from-previewFeatures-client-js.prisma'),\n        providerAliases: aliases,\n        skipDownload: true,\n      })\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchInlineSnapshot(`\n\"\nIn order to use the mongodb provider,\nyou need to set the mongodb feature flag.\nYou can define the feature flag like this:\n\ngenerator client {\n    provider = \\\\\"prisma-client-js\\\\\"\n    previewFeatures = [\\\\\"mongoDb\\\\\"]\n}\n\nMore information in our documentation:\nhttps://pris.ly/d/prisma-schema\n\"\n`)\n    }\n  })","file":"getGenerators/getGenerators.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"fail if mongoDb not found in previewFeatures - prisma-client-go - mongodb","suites":["getGenerators"],"updatePoint":{"line":649,"column":81},"line":649,"code":"  test('fail if mongoDb not found in previewFeatures - prisma-client-go - mongodb', async () => {\n    expect.assertions(1)\n    const aliases = {\n      'predefined-generator': {\n        generatorPath: generatorPath,\n        outputPath: __dirname,\n      },\n    }\n\n    try {\n      await getGenerators({\n        schemaPath: path.join(__dirname, 'missing-mongoDb-from-previewFeatures-client-go.prisma'),\n        providerAliases: aliases,\n        skipDownload: true,\n      })\n    } catch (e) {\n      expect(stripAnsi(e.message)).toMatchInlineSnapshot(`\n\"\nIn order to use the mongodb provider,\nyou need to set the mongodb feature flag.\nYou can define the feature flag like this:\n\ngenerator client {\n    provider = \\\\\"prisma-client-js\\\\\"\n    previewFeatures = [\\\\\"mongoDb\\\\\"]\n}\n\nMore information in our documentation:\nhttps://pris.ly/d/prisma-schema\n\"\n`)\n    }\n  })","file":"getGenerators/getGenerators.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"should not be blocked with mongoDb in previewFeatures - prisma-client-go - mongodb","suites":["getGenerators"],"line":685,"code":"  test.skip('should not be blocked with mongoDb in previewFeatures - prisma-client-go - mongodb', async () => {","file":"getGenerators/getGenerators.test.ts","skipped":true,"dir":"packages/sdk/src/__tests__"},{"name":"test argument vulnerability","suites":["getPackedPackage"],"updatePoint":{"line":6,"column":33},"line":6,"code":"  it('test argument vulnerability', async () => {\n    jest.setTimeout(10000)\n    \n    const outputDir = '/tmp/some-prisma-target-folder'\n    const packageDir = 'foo`touch /tmp/getPackedPackage-exploit`'\n\n    try {\n      await getPackedPackage('@prisma/client', path.join(__dirname, outputDir), packageDir)\n    } catch (e) {\n      //\n    } finally {\n      expect(fs.existsSync('/tmp/getPackedPackage-exploit')).toBe(false)\n    }\n  })","file":"getPackedPackage.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"returns null if no schema is found","suites":[],"updatePoint":{"line":66,"column":38},"line":66,"code":"it('returns null if no schema is found', async () => {\n  const res = await testSchemaPath('no-schema')\n\n  expect(res).toMatchInlineSnapshot(`\n    Object {\n      \"async\": null,\n      \"sync\": null,\n    }\n  `)\n})","file":"getSchema.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"reads from --schema args first even if package.json is provided","suites":[],"updatePoint":{"line":77,"column":67},"line":77,"code":"it('reads from --schema args first even if package.json is provided', async () => {\n  const res = await testSchemaPath(\n    'pkg-json-with-schema-args',\n    path.resolve(FIXTURE_CWD, 'pkg-json-with-schema-args', 'schema.prisma'),\n  )\n\n  expect(res).toMatchInlineSnapshot(`\nObject {\n  \"async\": \"src/__tests__/__fixtures__/getSchema/pkg-json-with-schema-args/schema.prisma\",\n  \"sync\": \"src/__tests__/__fixtures__/getSchema/pkg-json-with-schema-args/schema.prisma\",\n}\n`)\n})","file":"getSchema.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"throws if schema args path is invalid","suites":[],"updatePoint":{"line":91,"column":41},"line":91,"code":"it('throws if schema args path is invalid', async () => {\n  const res = await testSchemaPath('pkg-json-with-schema-args', path.resolve(FIXTURE_CWD, 'wrong_path'))\n\n  expect(res).toMatchInlineSnapshot(`\nObject {\n  \"async\": [Error: Provided --schema at ./__fixtures__/getSchema/wrong_path doesn't exist.],\n  \"sync\": [Error: Provided --schema at ./__fixtures__/getSchema/wrong_path doesn't exist.],\n}\n`)\n})","file":"getSchema.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"reads relative schema path from the nearest package.json","suites":[],"updatePoint":{"line":102,"column":60},"line":102,"code":"it('reads relative schema path from the nearest package.json', async () => {\n  const res = await testSchemaPath('pkg-json-valid-relative-path')\n\n  expect(res).toMatchInlineSnapshot(`\nObject {\n  \"async\": \"src/__tests__/__fixtures__/getSchema/pkg-json-valid-relative-path/db/schema.prisma\",\n  \"sync\": \"src/__tests__/__fixtures__/getSchema/pkg-json-valid-relative-path/db/schema.prisma\",\n}\n`)\n})","file":"getSchema.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"reads schema path from the nearest package.json and throws if path does not exist","suites":[],"updatePoint":{"line":113,"column":85},"line":113,"code":"it('reads schema path from the nearest package.json and throws if path does not exist', async () => {\n  const res = await testSchemaPath('pkg-json-invalid-path')\n\n  expect(res).toMatchInlineSnapshot(`\n    Object {\n      \"async\": [Error: Provided schema path \\`wrong-path\\` from \\`package.json\\` doesn't exist.],\n      \"sync\": [Error: Provided schema path \\`wrong-path\\` from \\`package.json\\` doesn't exist.],\n    }\n  `)\n})","file":"getSchema.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"reads schema path from the nearest package.json and throws if path is not of type string","suites":[],"updatePoint":{"line":124,"column":92},"line":124,"code":"it('reads schema path from the nearest package.json and throws if path is not of type string', async () => {\n  const res = await testSchemaPath('pkg-json-invalid-path-not-string')\n\n  expect(res).toMatchInlineSnapshot(`\n    Object {\n      \"async\": [Error: Provided schema path \\`123\\` from \\`package.json\\` must be of type string],\n      \"sync\": [Error: Provided schema path \\`123\\` from \\`package.json\\` must be of type string],\n    }\n  `)\n})","file":"getSchema.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"reads from the nearest package.json of the cwd","suites":[],"updatePoint":{"line":135,"column":50},"line":135,"code":"it('reads from the nearest package.json of the cwd', async () => {\n  const res = await testSchemaPath('pkg-json-nearest/packages/a')\n\n  expect(res).toMatchInlineSnapshot(`\nObject {\n  \"async\": \"src/__tests__/__fixtures__/getSchema/pkg-json-nearest/packages/a/db/schema.prisma\",\n  \"sync\": \"src/__tests__/__fixtures__/getSchema/pkg-json-nearest/packages/a/db/schema.prisma\",\n}\n`)\n})","file":"getSchema.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"finds the conventional prisma/schema path without configuration","suites":[],"updatePoint":{"line":146,"column":67},"line":146,"code":"it('finds the conventional prisma/schema path without configuration', async () => {\n  const res = await testSchemaPath('conventional-path')\n\n  expect(res).toMatchInlineSnapshot(`\nObject {\n  \"async\": \"src/__tests__/__fixtures__/getSchema/conventional-path/prisma/schema.prisma\",\n  \"sync\": \"src/__tests__/__fixtures__/getSchema/conventional-path/prisma/schema.prisma\",\n}\n`)\n})","file":"getSchema.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"finds the schema path in the root package.json of a yarn workspace from a child package","suites":[],"updatePoint":{"line":157,"column":91},"line":157,"code":"it('finds the schema path in the root package.json of a yarn workspace from a child package', async () => {\n  const res = await testSchemaPath('pkg-json-workspace-parent/packages/a')\n\n  expect(res).toMatchInlineSnapshot(`\nObject {\n  \"async\": \"src/__tests__/__fixtures__/getSchema/pkg-json-workspace-parent/db/prisma.schema\",\n  \"sync\": \"src/__tests__/__fixtures__/getSchema/pkg-json-workspace-parent/db/prisma.schema\",\n}\n`)\n})","file":"getSchema.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"finds the conventional schema path with yarn workspaces","suites":[],"updatePoint":{"line":168,"column":59},"line":168,"code":"it('finds the conventional schema path with yarn workspaces', async () => {\n  const res = await testSchemaPath('conventional-path-workspaces')\n\n  expect(res).toMatchInlineSnapshot(`\nObject {\n  \"async\": \"src/__tests__/__fixtures__/getSchema/conventional-path-workspaces/packages/b/schema.prisma\",\n  \"sync\": \"src/__tests__/__fixtures__/getSchema/conventional-path-workspaces/packages/b/schema.prisma\",\n}\n`)\n})","file":"getSchema.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"introspection basic","suites":[],"updatePoint":{"line":3,"column":25},"line":3,"code":"test('introspection basic', async () => {\n  const engine = new IntrospectionEngine({\n    cwd: __dirname,\n  })\n\n  const url = `file:./blog.db`\n\n  const schema = `datasource ds {\n    provider = \"sqlite\"\n    url = \"${url}\"\n  }`\n\n  const result = await engine.introspect(schema)\n  expect(result).toMatchInlineSnapshot(`\n    Object {\n      \"datamodel\": \"datasource ds {\n      provider = \\\\\"sqlite\\\\\"\n      url      = \\\\\"file:./blog.db\\\\\"\n    }\n\n    model Post {\n      author    Int\n      content   String?\n      createdAt DateTime @default(dbgenerated(\\\\\"'1970-01-01 00:00:00'\\\\\"))\n      kind      String?\n      published Boolean  @default(false)\n      title     String   @default(\\\\\"\\\\\")\n      updatedAt DateTime @default(dbgenerated(\\\\\"'1970-01-01 00:00:00'\\\\\"))\n      uuid      String   @id @unique(map: \\\\\"Post.uuid\\\\\")\n      User      User     @relation(fields: [author], references: [id], onUpdate: NoAction)\n    }\n\n    model User {\n      age     Int     @default(0)\n      amount  Float   @default(0)\n      balance Float   @default(0)\n      email   String  @unique(map: \\\\\"User.email\\\\\") @default(\\\\\"\\\\\")\n      id      Int     @id @unique(map: \\\\\"User.id\\\\\") @default(autoincrement())\n      name    String?\n      role    String  @default(\\\\\"USER\\\\\")\n      Post    Post[]\n    }\n    \",\n      \"version\": \"NonPrisma\",\n      \"warnings\": Array [],\n    }\n  `)\n  const metadata = await engine.getDatabaseMetadata(schema)\n  expect(metadata).toMatchInlineSnapshot(`\n    Object {\n      \"size_in_bytes\": 53248,\n      \"table_count\": 3,\n    }\n  `)\n  const databases = await engine.listDatabases(schema)\n  expect(databases).toMatchInlineSnapshot(`\n    Array [\n      \"blog.db\",\n    ]\n  `)\n\n  const dbVersion = await engine.getDatabaseVersion(schema)\n  expect(dbVersion.length > 0).toBe(true)\n\n  const description = await engine.getDatabaseDescription(schema)\n\n  expect(description).toMatchInlineSnapshot(`\n    \"{\n      \\\\\"tables\\\\\": [\n        {\n          \\\\\"name\\\\\": \\\\\"Post\\\\\",\n          \\\\\"columns\\\\\": [\n            {\n              \\\\\"name\\\\\": \\\\\"author\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"INTEGER\\\\\",\n                \\\\\"family\\\\\": \\\\\"Int\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Required\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": null,\n              \\\\\"auto_increment\\\\\": false\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"content\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"TEXT\\\\\",\n                \\\\\"family\\\\\": \\\\\"String\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Nullable\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": null,\n              \\\\\"auto_increment\\\\\": false\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"createdAt\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"DATE\\\\\",\n                \\\\\"family\\\\\": \\\\\"DateTime\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Required\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": {\n                \\\\\"kind\\\\\": {\n                  \\\\\"DbGenerated\\\\\": \\\\\"'1970-01-01 00:00:00'\\\\\"\n                },\n                \\\\\"constraint_name\\\\\": null\n              },\n              \\\\\"auto_increment\\\\\": false\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"kind\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"TEXT\\\\\",\n                \\\\\"family\\\\\": \\\\\"String\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Nullable\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": null,\n              \\\\\"auto_increment\\\\\": false\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"published\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"BOOLEAN\\\\\",\n                \\\\\"family\\\\\": \\\\\"Boolean\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Required\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": {\n                \\\\\"kind\\\\\": {\n                  \\\\\"Value\\\\\": false\n                },\n                \\\\\"constraint_name\\\\\": null\n              },\n              \\\\\"auto_increment\\\\\": false\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"title\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"TEXT\\\\\",\n                \\\\\"family\\\\\": \\\\\"String\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Required\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": {\n                \\\\\"kind\\\\\": {\n                  \\\\\"Value\\\\\": \\\\\"\\\\\"\n                },\n                \\\\\"constraint_name\\\\\": null\n              },\n              \\\\\"auto_increment\\\\\": false\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"updatedAt\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"DATE\\\\\",\n                \\\\\"family\\\\\": \\\\\"DateTime\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Required\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": {\n                \\\\\"kind\\\\\": {\n                  \\\\\"DbGenerated\\\\\": \\\\\"'1970-01-01 00:00:00'\\\\\"\n                },\n                \\\\\"constraint_name\\\\\": null\n              },\n              \\\\\"auto_increment\\\\\": false\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"uuid\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"TEXT\\\\\",\n                \\\\\"family\\\\\": \\\\\"String\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Required\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": null,\n              \\\\\"auto_increment\\\\\": false\n            }\n          ],\n          \\\\\"indices\\\\\": [\n            {\n              \\\\\"name\\\\\": \\\\\"Post.uuid\\\\\",\n              \\\\\"columns\\\\\": [\n                {\n                  \\\\\"name\\\\\": \\\\\"uuid\\\\\",\n                  \\\\\"sort_order\\\\\": \\\\\"Asc\\\\\",\n                  \\\\\"length\\\\\": null\n                }\n              ],\n              \\\\\"tpe\\\\\": \\\\\"Unique\\\\\",\n              \\\\\"algorithm\\\\\": null\n            }\n          ],\n          \\\\\"primary_key\\\\\": {\n            \\\\\"columns\\\\\": [\n              {\n                \\\\\"name\\\\\": \\\\\"uuid\\\\\",\n                \\\\\"length\\\\\": null,\n                \\\\\"sort_order\\\\\": null\n              }\n            ],\n            \\\\\"sequence\\\\\": null,\n            \\\\\"constraint_name\\\\\": null\n          },\n          \\\\\"foreign_keys\\\\\": [\n            {\n              \\\\\"constraint_name\\\\\": null,\n              \\\\\"columns\\\\\": [\n                \\\\\"author\\\\\"\n              ],\n              \\\\\"referenced_table\\\\\": \\\\\"User\\\\\",\n              \\\\\"referenced_columns\\\\\": [\n                \\\\\"id\\\\\"\n              ],\n              \\\\\"on_delete_action\\\\\": \\\\\"Restrict\\\\\",\n              \\\\\"on_update_action\\\\\": \\\\\"NoAction\\\\\"\n            }\n          ]\n        },\n        {\n          \\\\\"name\\\\\": \\\\\"User\\\\\",\n          \\\\\"columns\\\\\": [\n            {\n              \\\\\"name\\\\\": \\\\\"age\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"INTEGER\\\\\",\n                \\\\\"family\\\\\": \\\\\"Int\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Required\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": {\n                \\\\\"kind\\\\\": {\n                  \\\\\"Value\\\\\": 0\n                },\n                \\\\\"constraint_name\\\\\": null\n              },\n              \\\\\"auto_increment\\\\\": false\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"amount\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"REAL\\\\\",\n                \\\\\"family\\\\\": \\\\\"Float\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Required\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": {\n                \\\\\"kind\\\\\": {\n                  \\\\\"Value\\\\\": 0.0\n                },\n                \\\\\"constraint_name\\\\\": null\n              },\n              \\\\\"auto_increment\\\\\": false\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"balance\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"REAL\\\\\",\n                \\\\\"family\\\\\": \\\\\"Float\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Required\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": {\n                \\\\\"kind\\\\\": {\n                  \\\\\"Value\\\\\": 0.0\n                },\n                \\\\\"constraint_name\\\\\": null\n              },\n              \\\\\"auto_increment\\\\\": false\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"email\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"TEXT\\\\\",\n                \\\\\"family\\\\\": \\\\\"String\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Required\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": {\n                \\\\\"kind\\\\\": {\n                  \\\\\"Value\\\\\": \\\\\"\\\\\"\n                },\n                \\\\\"constraint_name\\\\\": null\n              },\n              \\\\\"auto_increment\\\\\": false\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"id\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"INTEGER\\\\\",\n                \\\\\"family\\\\\": \\\\\"Int\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Required\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": null,\n              \\\\\"auto_increment\\\\\": true\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"name\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"TEXT\\\\\",\n                \\\\\"family\\\\\": \\\\\"String\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Nullable\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": null,\n              \\\\\"auto_increment\\\\\": false\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"role\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"TEXT\\\\\",\n                \\\\\"family\\\\\": \\\\\"String\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Required\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": {\n                \\\\\"kind\\\\\": {\n                  \\\\\"Value\\\\\": \\\\\"USER\\\\\"\n                },\n                \\\\\"constraint_name\\\\\": null\n              },\n              \\\\\"auto_increment\\\\\": false\n            }\n          ],\n          \\\\\"indices\\\\\": [\n            {\n              \\\\\"name\\\\\": \\\\\"User.email\\\\\",\n              \\\\\"columns\\\\\": [\n                {\n                  \\\\\"name\\\\\": \\\\\"email\\\\\",\n                  \\\\\"sort_order\\\\\": \\\\\"Asc\\\\\",\n                  \\\\\"length\\\\\": null\n                }\n              ],\n              \\\\\"tpe\\\\\": \\\\\"Unique\\\\\",\n              \\\\\"algorithm\\\\\": null\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"User.id\\\\\",\n              \\\\\"columns\\\\\": [\n                {\n                  \\\\\"name\\\\\": \\\\\"id\\\\\",\n                  \\\\\"sort_order\\\\\": \\\\\"Asc\\\\\",\n                  \\\\\"length\\\\\": null\n                }\n              ],\n              \\\\\"tpe\\\\\": \\\\\"Unique\\\\\",\n              \\\\\"algorithm\\\\\": null\n            }\n          ],\n          \\\\\"primary_key\\\\\": {\n            \\\\\"columns\\\\\": [\n              {\n                \\\\\"name\\\\\": \\\\\"id\\\\\",\n                \\\\\"length\\\\\": null,\n                \\\\\"sort_order\\\\\": null\n              }\n            ],\n            \\\\\"sequence\\\\\": null,\n            \\\\\"constraint_name\\\\\": null\n          },\n          \\\\\"foreign_keys\\\\\": []\n        },\n        {\n          \\\\\"name\\\\\": \\\\\"_Migration\\\\\",\n          \\\\\"columns\\\\\": [\n            {\n              \\\\\"name\\\\\": \\\\\"revision\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"INTEGER\\\\\",\n                \\\\\"family\\\\\": \\\\\"Int\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Required\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": null,\n              \\\\\"auto_increment\\\\\": true\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"name\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"TEXT\\\\\",\n                \\\\\"family\\\\\": \\\\\"String\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Required\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": null,\n              \\\\\"auto_increment\\\\\": false\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"datamodel\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"TEXT\\\\\",\n                \\\\\"family\\\\\": \\\\\"String\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Required\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": null,\n              \\\\\"auto_increment\\\\\": false\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"status\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"TEXT\\\\\",\n                \\\\\"family\\\\\": \\\\\"String\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Required\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": null,\n              \\\\\"auto_increment\\\\\": false\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"applied\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"INTEGER\\\\\",\n                \\\\\"family\\\\\": \\\\\"Int\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Required\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": null,\n              \\\\\"auto_increment\\\\\": false\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"rolled_back\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"INTEGER\\\\\",\n                \\\\\"family\\\\\": \\\\\"Int\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Required\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": null,\n              \\\\\"auto_increment\\\\\": false\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"datamodel_steps\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"TEXT\\\\\",\n                \\\\\"family\\\\\": \\\\\"String\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Required\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": null,\n              \\\\\"auto_increment\\\\\": false\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"database_migration\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"TEXT\\\\\",\n                \\\\\"family\\\\\": \\\\\"String\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Required\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": null,\n              \\\\\"auto_increment\\\\\": false\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"errors\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"TEXT\\\\\",\n                \\\\\"family\\\\\": \\\\\"String\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Required\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": null,\n              \\\\\"auto_increment\\\\\": false\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"started_at\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"DATE\\\\\",\n                \\\\\"family\\\\\": \\\\\"DateTime\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Required\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": null,\n              \\\\\"auto_increment\\\\\": false\n            },\n            {\n              \\\\\"name\\\\\": \\\\\"finished_at\\\\\",\n              \\\\\"tpe\\\\\": {\n                \\\\\"full_data_type\\\\\": \\\\\"DATE\\\\\",\n                \\\\\"family\\\\\": \\\\\"DateTime\\\\\",\n                \\\\\"arity\\\\\": \\\\\"Nullable\\\\\",\n                \\\\\"native_type\\\\\": null\n              },\n              \\\\\"default\\\\\": null,\n              \\\\\"auto_increment\\\\\": false\n            }\n          ],\n          \\\\\"indices\\\\\": [],\n          \\\\\"primary_key\\\\\": {\n            \\\\\"columns\\\\\": [\n              {\n                \\\\\"name\\\\\": \\\\\"revision\\\\\",\n                \\\\\"length\\\\\": null,\n                \\\\\"sort_order\\\\\": null\n              }\n            ],\n            \\\\\"sequence\\\\\": null,\n            \\\\\"constraint_name\\\\\": null\n          },\n          \\\\\"foreign_keys\\\\\": []\n        }\n      ],\n      \\\\\"enums\\\\\": [],\n      \\\\\"sequences\\\\\": [],\n      \\\\\"views\\\\\": [],\n      \\\\\"procedures\\\\\": [],\n      \\\\\"user_defined_types\\\\\": []\n    }\"\n  `)\n  engine.stop()\n})","file":"introspection/introspection.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"check if connection string is in error","suites":["execaCommand"],"updatePoint":{"line":19,"column":46},"line":19,"code":"  test('check if connection string is in error', async () => {\n    try {\n      await execaCommand({\n        connectionString: 'postgresql://user:mysecret@localhost',\n        cwd: process.cwd(),\n        migrationEnginePath: undefined,\n        engineCommandName: 'drop-database',\n      })\n    } catch (e) {\n      const message = e.message as string\n      expect(message.includes('mysecret')).toBeFalsy()\n      expect(message.includes('<REDACTED>')).toBeTruthy()\n    }\n  })","file":"migrateEngineCommands.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"exist - sqlite:","suites":["doesSqliteDbExist"],"updatePoint":{"line":36,"column":23},"line":36,"code":"  test('exist - sqlite:', async () => {\n    await expect(doesSqliteDbExist('sqlite:./introspection/blog.db', __dirname)).resolves.toEqual(true)\n  })","file":"migrateEngineCommands.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"exist - file:","suites":["doesSqliteDbExist"],"updatePoint":{"line":40,"column":21},"line":40,"code":"  test('exist - file:', async () => {\n    await expect(doesSqliteDbExist('file:./introspection/blog.db', __dirname)).resolves.toEqual(true)\n  })","file":"migrateEngineCommands.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"does not exist - sqlite:","suites":["doesSqliteDbExist"],"updatePoint":{"line":44,"column":32},"line":44,"code":"  test('does not exist - sqlite:', async () => {\n    await expect(doesSqliteDbExist('sqlite:./doesnotexist.db', __dirname)).resolves.toEqual(false)\n  })","file":"migrateEngineCommands.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"does not exist - file:","suites":["doesSqliteDbExist"],"updatePoint":{"line":48,"column":30},"line":48,"code":"  test('does not exist - file:', async () => {\n    await expect(doesSqliteDbExist('file:./doesnotexist.db', __dirname)).resolves.toEqual(false)\n  })","file":"migrateEngineCommands.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"should error if no schemaDir and no schema found","suites":["doesSqliteDbExist"],"updatePoint":{"line":52,"column":56},"line":52,"code":"  test('should error if no schemaDir and no schema found', async () => {\n    await expect(doesSqliteDbExist('file:./doesnotexist.db')).rejects.toThrowError()\n  })","file":"migrateEngineCommands.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"sqlite - can","suites":["canConnectToDatabase"],"updatePoint":{"line":58,"column":20},"line":58,"code":"  test('sqlite - can', async () => {\n    await expect(canConnectToDatabase('sqlite:./introspection/blog.db', __dirname)).resolves.toEqual(true)\n  })","file":"migrateEngineCommands.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"sqlite - cannot","suites":["canConnectToDatabase"],"updatePoint":{"line":62,"column":23},"line":62,"code":"  test('sqlite - cannot', async () => {\n    await expect(canConnectToDatabase('file:./doesnotexist.db')).resolves.toMatchInlineSnapshot(`\n            Object {\n              \"code\": \"P1003\",\n              \"message\": \"SQLite database file doesn't exist\",\n            }\n          `)\n  })","file":"migrateEngineCommands.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"postgresql - server does not exist","suites":["canConnectToDatabase"],"updatePoint":{"line":71,"column":42},"line":71,"code":"  test('postgresql - server does not exist', async () => {\n    await expect(\n      canConnectToDatabase('postgresql://johndoe:randompassword@doesnotexist:5432/mydb?schema=public', __dirname),\n    ).resolves.toMatchInlineSnapshot(`\n            Object {\n              \"code\": \"P1001\",\n              \"message\": \"Can't reach database server at \\`doesnotexist\\`:\\`5432\\`\n\n            Please make sure your database server is running at \\`doesnotexist\\`:\\`5432\\`.\",\n            }\n          `)\n  }, 10000)","file":"migrateEngineCommands.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"sqlite - already exists","suites":["createDatabase"],"updatePoint":{"line":86,"column":31},"line":86,"code":"  test('sqlite - already exists', async () => {\n    await expect(createDatabase('sqlite:./introspection/blog.db', __dirname)).resolves.toEqual(false)\n  })","file":"migrateEngineCommands.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"sqlite - file does not exists","suites":["createDatabase"],"updatePoint":{"line":90,"column":37},"line":90,"code":"  test('sqlite - file does not exists', async () => {\n    await expect(createDatabase('sqlite:./doesnotexist.db', tempy.directory())).resolves.toEqual(true)\n  })","file":"migrateEngineCommands.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"sqlite - invalid cwd (file path instead of directory)","suites":["createDatabase"],"updatePoint":{"line":94,"column":61},"line":94,"code":"  test('sqlite - invalid cwd (file path instead of directory)', async () => {\n    await expect(createDatabase('sqlite:./doesnotexist.db', tempy.file())).rejects.toThrowErrorMatchingInlineSnapshot(\n      `\"Migration engine exited.\"`,\n    )\n  })","file":"migrateEngineCommands.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"postgresql - create database","suites":["createDatabase"],"updatePoint":{"line":100,"column":36},"line":100,"code":"  test('postgresql - create database', async () => {\n    const uri = process.env.TEST_POSTGRES_URI!\n    const credentials = uriToCredentials(uri)\n    credentials.database = 'can-create-a-db'\n    const uriFromCredentials = credentialsToUri(credentials)\n    try {\n      await dropDatabase(uriFromCredentials, __dirname)\n    } catch (e) {}\n    await expect(createDatabase(uriFromCredentials, __dirname)).resolves.toEqual(true)\n  })","file":"migrateEngineCommands.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"postgresql - server does not exist","suites":["createDatabase"],"updatePoint":{"line":111,"column":42},"line":111,"code":"  test('postgresql - server does not exist', async () => {\n    await expect(createDatabase('postgresql://johndoe:randompassword@doesnotexist:5432/mydb?schema=public', __dirname))\n      .rejects.toThrowErrorMatchingInlineSnapshot(`\n            \"P1001: Can't reach database server at \\`doesnotexist\\`:\\`5432\\`\n\n            Please make sure your database server is running at \\`doesnotexist\\`:\\`5432\\`.\"\n          `)\n  }, 30000)","file":"migrateEngineCommands.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"postgresql - database already exists","suites":["createDatabase"],"updatePoint":{"line":120,"column":44},"line":120,"code":"  test('postgresql - database already exists', async () => {\n    const uri = process.env.TEST_POSTGRES_URI!\n    const credentials = uriToCredentials(uri)\n    credentials.database = 'postgres'\n    const uriFromCredentials = credentialsToUri(credentials)\n    await expect(createDatabase(uriFromCredentials, __dirname)).resolves.toEqual(false)\n  })","file":"migrateEngineCommands.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"mysql - create database","suites":["createDatabase"],"updatePoint":{"line":128,"column":31},"line":128,"code":"  test('mysql - create database', async () => {\n    const uri = process.env.TEST_MYSQL_URI!\n    const credentials = uriToCredentials(uri)\n    credentials.database = 'can-create-a-db'\n    const uriFromCredentials = credentialsToUri(credentials)\n    try {\n      await dropDatabase(uriFromCredentials, __dirname)\n    } catch (e) {}\n    await expect(createDatabase(uriFromCredentials, __dirname)).resolves.toEqual(true)\n  })","file":"migrateEngineCommands.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"mysql - database already exists","suites":["createDatabase"],"updatePoint":{"line":139,"column":39},"line":139,"code":"  test('mysql - database already exists', async () => {\n    const uri = process.env.TEST_MYSQL_URI!\n    const credentials = uriToCredentials(uri)\n    credentials.database = 'alreadyexists'\n    const uriFromCredentials = credentialsToUri(credentials)\n\n    try {\n      await dropDatabase(uriFromCredentials, __dirname)\n    } catch (e) {}\n    await expect(createDatabase(uriFromCredentials, __dirname)).resolves.toEqual(true)\n    await expect(createDatabase(uriFromCredentials, __dirname)).resolves.toEqual(false)\n  })","file":"migrateEngineCommands.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"invalid database type","suites":["createDatabase"],"updatePoint":{"line":166,"column":29},"line":166,"code":"  test('invalid database type', async () => {\n    await expect(createDatabase('invalid:somedburl')).rejects.toThrowErrorMatchingInlineSnapshot(\n      `\"Unknown database type invalid:\"`,\n    )\n  })","file":"migrateEngineCommands.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"},{"name":"empty connection string","suites":["createDatabase"],"updatePoint":{"line":172,"column":31},"line":172,"code":"  test('empty connection string', async () => {\n    await expect(createDatabase('')).rejects.toThrowErrorMatchingInlineSnapshot(\n      `\"Connection url is empty. See https://www.prisma.io/docs/reference/database-reference/connection-urls\"`,\n    )\n  })","file":"migrateEngineCommands.test.ts","skipped":false,"dir":"packages/sdk/src/__tests__"}]}