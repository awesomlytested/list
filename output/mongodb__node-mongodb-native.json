{"repo":"mongodb/node-mongodb-native","url":"https://github.com/mongodb/node-mongodb-native","branch":"main","configs":[{"package":"mongodb","lang":"js","dir":"test","framework":"mocha","pattern":"**/*[._-]{test,spec,unittest,unit}.{ts,js}"}],"tests":[{"name":"should auth  when explicitly specifying ","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":97,"column":85,"index":3077},"line":97,"code":"          it(`should auth ${user.description} when explicitly specifying ${mechanism}`, {\n            metadata: {\n              requires: {\n                mongodb: '>=3.7.3'\n              }\n            },\n            test: function () {\n              const options = {\n                auth: {\n                  username: user.username,\n                  password: user.password\n                },\n                authMechanism: mechanism,\n                authSource: this.configuration.db\n              };\n              return withClient(this.configuration.newClient({}, options), client => {\n                return client.db(this.configuration.db).stats();\n              });\n            }\n          });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should auth  when explicitly specifying  in url","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":117,"column":92,"index":3789},"line":117,"code":"          it(`should auth ${user.description} when explicitly specifying ${mechanism} in url`, {\n            metadata: {\n              requires: {\n                mongodb: '>=3.7.3'\n              }\n            },\n            test: function () {\n              const username = encodeURIComponent(user.username);\n              const password = encodeURIComponent(user.password);\n              const url = `${makeConnectionString(this.configuration, username, password)}authMechanism=${mechanism}`;\n              const client = this.configuration.newClient(url);\n              return withClient(client, client => {\n                return client.db(this.configuration.db).stats();\n              });\n            }\n          });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should auth  using mechanism negotiaton","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":134,"column":70,"index":4502},"line":134,"code":"        it(`should auth ${user.description} using mechanism negotiaton`, {\n          metadata: {\n            requires: {\n              mongodb: '>=3.7.3'\n            }\n          },\n          test: function () {\n            const options = {\n              auth: {\n                username: user.username,\n                password: user.password\n              },\n              authSource: this.configuration.db\n            };\n            return withClient(this.configuration.newClient({}, options), client => {\n              return client.db(this.configuration.db).stats();\n            });\n          }\n        });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should auth  using mechanism negotiaton and url","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":153,"column":78,"index":5122},"line":153,"code":"        it(`should auth ${user.description} using mechanism negotiaton and url`, {\n          metadata: {\n            requires: {\n              mongodb: '>=3.7.3'\n            }\n          },\n          test: function () {\n            const username = encodeURIComponent(user.username);\n            const password = encodeURIComponent(user.password);\n            const url = makeConnectionString(this.configuration, username, password);\n            const client = this.configuration.newClient(url);\n            return withClient(client, client => {\n              return client.db(this.configuration.db).stats();\n            });\n          }\n        });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should select SCRAM-SHA-256 for a user that supports both auth mechanisms","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":176,"column":83,"index":5977},"line":176,"code":"      it('should select SCRAM-SHA-256 for a user that supports both auth mechanisms', {\n        metadata: {\n          requires: {\n            mongodb: '>=3.7.3'\n          }\n        },\n        test: function () {\n          const options = {\n            auth: {\n              username: userMap.both.username,\n              password: userMap.both.password\n            },\n            authSource: this.configuration.db\n          };\n          test.sandbox.spy(ScramSHA256.prototype, 'auth');\n          return withClient(this.configuration.newClient({}, options), () => {\n            expect(ScramSHA256.prototype.auth.called).to.equal(true);\n          });\n        }\n      }); // TODO: not spec","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should shorten SCRAM conversations if the server supports it","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":197,"column":70,"index":6652},"line":197,"code":"      it('should shorten SCRAM conversations if the server supports it', {\n        metadata: {\n          requires: {\n            mongodb: '>=4.4',\n            topology: ['single']\n          }\n        },\n        test: function () {\n          const options = {\n            auth: {\n              username: userMap.both.username,\n              password: userMap.both.password\n            },\n            authSource: this.configuration.db\n          };\n          let runCommandSpy;\n          test.sandbox.stub(ScramSHA256.prototype, 'auth').callsFake(function (authContext, callback) {\n            const connection = authContext.connection;\n            const auth = ScramSHA256.prototype.auth.wrappedMethod;\n            runCommandSpy = test.sandbox.spy(connection, 'command');\n\n            function _callback(err, res) {\n              runCommandSpy.restore();\n              callback(err, res);\n            }\n\n            auth.apply(this, [authContext, _callback]);\n          });\n          return withClient(this.configuration.newClient({}, options), () => {\n            expect(runCommandSpy.callCount).to.equal(1);\n          });\n        }\n      });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail to connect if incorrect auth mechanism is explicitly specified","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":235,"column":84,"index":7962},"line":235,"code":"      it('should fail to connect if incorrect auth mechanism is explicitly specified', {\n        metadata: {\n          requires: {\n            mongodb: '>=3.7.3'\n          }\n        },\n        test: function () {\n          const options = {\n            auth: {\n              username: userMap.sha256.username,\n              password: userMap.sha256.password\n            },\n            authSource: this.configuration.db,\n            authMechanism: 'SCRAM-SHA-1'\n          };\n          return withClient(this.configuration.newClient({}, options), () => Promise.reject(new Error('This request should have failed to authenticate')), err => expect(err).to.match(/Authentication failed/));\n        }\n      });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail for a nonexistent username with same error type as bad password","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":263,"column":85,"index":9261},"line":263,"code":"      it('should fail for a nonexistent username with same error type as bad password', {\n        metadata: {\n          requires: {\n            mongodb: '>=3.7.3'\n          }\n        },\n        test: function () {\n          const noUsernameOptions = {\n            auth: {\n              username: 'roth',\n              password: 'pencil'\n            },\n            authSource: 'admin'\n          };\n          const badPasswordOptions = {\n            auth: {\n              username: 'both',\n              password: 'pencil'\n            },\n            authSource: 'admin'\n          };\n\n          const getErrorMsg = options => withClient(this.configuration.newClient({}, options), () => Promise.reject(new Error('This request should have failed to authenticate')), err => expect(err).to.match(/Authentication failed/));\n\n          return Promise.all([getErrorMsg(noUsernameOptions), getErrorMsg(badPasswordOptions)]);\n        }\n      });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should send speculativeAuthenticate on initial handshake on MongoDB 4.4+","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Steps 1-3"],"updatePoint":{"line":290,"column":82,"index":10192},"line":290,"code":"      it('should send speculativeAuthenticate on initial handshake on MongoDB 4.4+', {\n        metadata: {\n          requires: {\n            mongodb: '>=4.4',\n            topology: ['single']\n          }\n        },\n        test: function () {\n          const options = {\n            auth: {\n              username: userMap.both.username,\n              password: userMap.both.password\n            },\n            authSource: this.configuration.db\n          };\n          const commandSpy = test.sandbox.spy(Connection.prototype, 'command');\n          return withClient(this.configuration.newClient({}, options), () => {\n            const calls = commandSpy.getCalls().filter(c => c.thisValue.id !== '<monitor>') // ignore all monitor connections\n            .filter(c => c.args[1][LEGACY_HELLO_COMMAND]); // only consider handshakes\n\n            expect(calls).to.have.length(1);\n            const handshakeDoc = calls[0].args[1];\n            expect(handshakeDoc).to.have.property('speculativeAuthenticate');\n          });\n        }\n      });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should be able to login with username \"\" and password \"\"","suites":["auth prose tests","SCRAM-SHA-256 prose test","SCRAM-SHA-256 prose test Step 4"],"updatePoint":{"line":386,"column":90,"index":13886},"line":386,"code":"        it(`should be able to login with username \"${username}\" and password \"${password}\"`, {\n          metadata: {\n            requires: {\n              mongodb: '>=3.7.3'\n            }\n          },\n          test: function () {\n            const options = {\n              auth: {\n                username,\n                password\n              },\n              authSource: 'admin',\n              authMechanism: 'SCRAM-SHA-256'\n            };\n            return withClient(this.configuration.newClient(options), client => {\n              return client.db('admin').stats();\n            });\n          }\n        });","file":"integration/auth/auth.prose.test.js","skipped":false,"dir":"test"},{"name":"should not authorize when not authenticated","suites":["MONGODB-AWS"],"updatePoint":{"line":32,"column":49,"index":661},"line":32,"code":"  it('should not authorize when not authenticated', function (done) {\n    const config = this.configuration;\n    const url = removeAuthFromConnectionString(config.url());\n    const client = config.newClient(url); // strip provided URI of credentials\n\n    client.connect(err => {\n      expect(err).to.not.exist;\n      this.defer(() => client.close());\n      client.db('aws').command({\n        count: 'test'\n      }, (err, count) => {\n        expect(err).to.exist;\n        expect(count).to.not.exist;\n        done();\n      });\n    });\n  });","file":"integration/auth/mongodb_aws.test.js","skipped":false,"dir":"test"},{"name":"should authorize when successfully authenticated","suites":["MONGODB-AWS"],"updatePoint":{"line":49,"column":54,"index":1205},"line":49,"code":"  it('should authorize when successfully authenticated', function (done) {\n    const config = this.configuration;\n    const client = config.newClient(process.env.MONGODB_URI); // use the URI built by the test environment\n\n    client.connect(err => {\n      expect(err).to.not.exist;\n      this.defer(() => client.close());\n      client.db('aws').command({\n        count: 'test'\n      }, (err, count) => {\n        expect(err).to.not.exist;\n        expect(count).to.exist;\n        done();\n      });\n    });\n  });","file":"integration/auth/mongodb_aws.test.js","skipped":false,"dir":"test"},{"name":"should allow empty string in authMechanismProperties.AWS_SESSION_TOKEN to override AWS_SESSION_TOKEN environment variable","suites":["MONGODB-AWS"],"updatePoint":{"line":65,"column":127,"index":1788},"line":65,"code":"  it('should allow empty string in authMechanismProperties.AWS_SESSION_TOKEN to override AWS_SESSION_TOKEN environment variable', function () {\n    const client = this.configuration.newClient(this.configuration.url(), {\n      authMechanismProperties: {\n        AWS_SESSION_TOKEN: ''\n      }\n    });\n    expect(client).to.have.nested.property('options.credentials.mechanismProperties.AWS_SESSION_TOKEN').that.equals('');\n  });","file":"integration/auth/mongodb_aws.test.js","skipped":false,"dir":"test"},{"name":"should respect the default timeout of 10000ms","suites":["MONGODB-AWS","EC2 with missing credentials"],"updatePoint":{"line":94,"column":53,"index":2715},"line":94,"code":"    it('should respect the default timeout of 10000ms', async function () {\n      const config = this.configuration;\n      client = config.newClient(process.env.MONGODB_URI, {\n        authMechanism: 'MONGODB-AWS'\n      }); // use the URI built by the test environment\n\n      const startTime = performance.now();\n      let caughtError = null;\n      await client.connect().catch(err => {\n        caughtError = err;\n      });\n      const endTime = performance.now();\n      const timeTaken = endTime - startTime;\n      expect(caughtError).to.be.instanceOf(MongoAWSError);\n      expect(caughtError).property('message').match(/timed out after/);\n      expect(timeTaken).to.be.within(10000, 12000);\n    });","file":"integration/auth/mongodb_aws.test.js","skipped":false,"dir":"test"},{"name":"Should correctly authenticate against scram","suites":["SCRAM"],"updatePoint":{"line":24,"column":49,"index":455},"line":24,"code":"  it('Should correctly authenticate against scram', {\n    metadata: {\n      requires: {\n        topology: 'scram',\n        mongodb: '>=3.2.0'\n      }\n    },\n    test: function (done) {\n      // User and password\n      var user = 'test';\n      var password = 'test'; // Connect to the server\n\n      MongoClient.connect('mongodb://localhost:27017/test', function (err, db) {\n        expect(err).to.not.exist; // Create an admin user\n\n        db.admin().addUser(user, password, function (err) {\n          expect(err).to.not.exist;\n          db.close(); // Attempt to reconnect authenticating against the admin database\n\n          MongoClient.connect('mongodb://test:test@localhost:27017/test?authMechanism=SCRAM-SHA-1&authSource=admin&maxPoolSize=5', function (err, client) {\n            expect(err).to.not.exist;\n            db.collection('test').insert({\n              a: 1\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              test.ok(r != null); // Wait for a reconnect to happen\n\n              client.topology.once('reconnect', function () {\n                // Perform an insert after reconnect\n                db.collection('test').insert({\n                  a: 1\n                }, function (err, r) {\n                  expect(err).to.not.exist;\n                  test.ok(r != null); // Attempt to reconnect authenticating against the admin database\n\n                  MongoClient.connect('mongodb://test:test@localhost:27017/test?authMechanism=SCRAM-SHA-1&authSource=admin&maxPoolSize=5', function (err) {\n                    expect(err).to.not.exist; // Remove the user\n\n                    db.admin().removeUser(user, function (err) {\n                      expect(err).to.not.exist;\n                      db.close();\n                      done();\n                    });\n                  });\n                });\n              }); // Attempt disconnect again\n\n              client.topology.connections()[0].destroy();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/auth/scram_sha_1.test.js","skipped":false,"dir":"test"},{"name":"should shorten SCRAM conversations if the server supports it","suites":["SCRAM_SHA_256"],"updatePoint":{"line":64,"column":66,"index":1735},"line":64,"code":"  it('should shorten SCRAM conversations if the server supports it', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.4',\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const options = {\n        auth: {\n          username: userMap.both.username,\n          password: userMap.both.password\n        },\n        authSource: this.configuration.db\n      };\n      let runCommandSpy;\n      test.sandbox.stub(ScramSHA256.prototype, 'auth').callsFake(function (authContext, callback) {\n        const connection = authContext.connection;\n        const auth = ScramSHA256.prototype.auth.wrappedMethod;\n        runCommandSpy = test.sandbox.spy(connection, 'command');\n\n        function _callback(err, res) {\n          runCommandSpy.restore();\n          callback(err, res);\n        }\n\n        auth.apply(this, [authContext, _callback]);\n      });\n      return withClient(this.configuration.newClient({}, options), () => {\n        expect(runCommandSpy.callCount).to.equal(1);\n      });\n    }\n  });","file":"integration/auth/scram_sha_256.test.js","skipped":false,"dir":"test"},{"name":"should send speculativeAuthenticate on initial handshake on MongoDB 4.4+","suites":["SCRAM_SHA_256"],"updatePoint":{"line":97,"column":78,"index":2765},"line":97,"code":"  it('should send speculativeAuthenticate on initial handshake on MongoDB 4.4+', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.4',\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const options = {\n        auth: {\n          username: userMap.both.username,\n          password: userMap.both.password\n        },\n        authSource: this.configuration.db\n      };\n      const commandSpy = test.sandbox.spy(Connection.prototype, 'command');\n      return withClient(this.configuration.newClient({}, options), () => {\n        const calls = commandSpy.getCalls().filter(c => c.thisValue.id !== '<monitor>') // ignore all monitor connections\n        .filter(c => c.args[1][LEGACY_HELLO_COMMAND]); // only consider handshakes\n\n        expect(calls).to.have.length(1);\n        const handshakeDoc = calls[0].args[1];\n        expect(handshakeDoc).to.have.property('speculativeAuthenticate');\n      });\n    }\n  });","file":"integration/auth/scram_sha_256.test.js","skipped":false,"dir":"test"},{"name":"Should correctly authenticate using x509","suites":["SSL (x509)"],"updatePoint":{"line":26,"column":46,"index":393},"line":26,"code":"  it('Should correctly authenticate using x509', {\n    metadata: {\n      requires: {\n        topology: 'ssl'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n\n      var ServerManager = require('mongodb-topology-manager').Server; // Read the cert and key\n\n\n      var cert = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n      var key = fs.readFileSync(__dirname + '/ssl/x509/client.pem'); // User name\n\n      var userName = 'CN=client,OU=kerneluser,O=10Gen,L=New York City,ST=New York,C=US'; // Create server manager\n\n      var serverManager = new ServerManager('mongod', {\n        bind_ip: 'server',\n        port: 27019,\n        dbpath: f('%s/../db/27019', __dirname),\n        sslPEMKeyFile: __dirname + '/ssl/x509/server.pem',\n        sslCAFile: __dirname + '/ssl/x509/ca.pem',\n        sslCRLFile: __dirname + '/ssl/x509/crl.pem',\n        sslMode: 'requireSSL',\n        sslWeakCertificateValidation: null\n      }, {\n        ssl: true,\n        host: 'server',\n        key: cert,\n        cert: cert,\n        rejectUnauthorized: false\n      }); // Purge the set\n\n      serverManager.purge().then(function () {\n        // Start the server\n        serverManager.start().then(function () {\n          // Connect and validate the server certificate\n          MongoClient.connect('mongodb://server:27019/test?ssl=true&maxPoolSize=1', {\n            server: {\n              sslKey: key,\n              sslCert: cert,\n              sslValidate: false\n            }\n          }, function (err, client) {\n            expect(err).to.not.exist;\n            var db = client.db(configuration.db); // Execute build info\n\n            db.command({\n              buildInfo: 1\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              var version = parseInt(result.versionArray.slice(0, 3).join(''), 10);\n\n              if (version < 253) {\n                client.close();\n                return done();\n              } // Add the X509 auth user to the $external db\n\n\n              var ext = client.db('$external');\n              ext.addUser(userName, {\n                roles: [{\n                  role: 'readWriteAnyDatabase',\n                  db: 'admin'\n                }, {\n                  role: 'userAdminAnyDatabase',\n                  db: 'admin'\n                }]\n              }, function (err, result) {\n                expect(err).to.not.exist;\n                test.equal(userName, result[0].user);\n                test.equal('', result[0].pwd);\n                client.close(); // Connect using X509 authentication\n\n                MongoClient.connect(f('mongodb://%s@server:27019/test?authMechanism=%s&ssl=true&maxPoolSize=1', encodeURIComponent(userName), 'MONGODB-X509'), {\n                  server: {\n                    sslKey: key,\n                    sslCert: cert,\n                    sslValidate: false\n                  }\n                }, function (err, client) {\n                  expect(err).to.not.exist;\n                  client.close();\n                  serverManager.stop().then(function () {\n                    done();\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/auth/ssl_x509_connect.test.js","skipped":false,"dir":"test"},{"name":"Should correctly handle bad x509 certificate","suites":["SSL (x509)"],"updatePoint":{"line":121,"column":50,"index":3636},"line":121,"code":"  it('Should correctly handle bad x509 certificate', {\n    metadata: {\n      requires: {\n        topology: 'ssl'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n\n      var ServerManager = require('mongodb-topology-manager').Server; // Read the cert and key\n\n\n      var cert = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n      var key = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n      var serverPem = fs.readFileSync(__dirname + '/ssl/x509/server.pem'); // User name\n\n      var userName = 'CN=client,OU=kerneluser,O=10Gen,L=New York City,ST=New York,C=US'; // Create server manager\n\n      var serverManager = new ServerManager('mongod', {\n        bind_ip: 'server',\n        port: 27019,\n        dbpath: f('%s/../db/27019', __dirname),\n        sslPEMKeyFile: __dirname + '/ssl/x509/server.pem',\n        sslCAFile: __dirname + '/ssl/x509/ca.pem',\n        sslCRLFile: __dirname + '/ssl/x509/crl.pem',\n        sslMode: 'requireSSL',\n        sslWeakCertificateValidation: null\n      }, {\n        ssl: true,\n        host: 'server',\n        key: cert,\n        cert: cert,\n        rejectUnauthorized: false\n      }); // Purge the set\n\n      serverManager.purge().then(function () {\n        // Start the server\n        serverManager.start().then(function () {\n          // Connect and validate the server certificate\n          MongoClient.connect('mongodb://server:27019/test?ssl=true&maxPoolSize=1', {\n            server: {\n              sslKey: key,\n              sslCert: cert,\n              sslValidate: false\n            }\n          }, function (err, client) {\n            expect(err).to.not.exist;\n            var db = client.db(configuration.db); // Execute build info\n\n            db.command({\n              buildInfo: 1\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              var version = parseInt(result.versionArray.slice(0, 3).join(''), 10);\n\n              if (version < 253) {\n                client.close();\n                return done();\n              } // Add the X509 auth user to the $external db\n\n\n              var ext = client.db('$external');\n              ext.addUser(userName, {\n                roles: [{\n                  role: 'readWriteAnyDatabase',\n                  db: 'admin'\n                }, {\n                  role: 'userAdminAnyDatabase',\n                  db: 'admin'\n                }]\n              }, function (err, result) {\n                expect(err).to.not.exist;\n                test.equal(userName, result[0].user);\n                test.equal('', result[0].pwd);\n                client.close(); // Connect using X509 authentication\n\n                MongoClient.connect(f('mongodb://%s@server:27019/test?authMechanism=%s&ssl=true&maxPoolSize=1', encodeURIComponent(userName), 'MONGODB-X509'), {\n                  server: {\n                    sslKey: serverPem,\n                    sslCert: serverPem,\n                    sslValidate: false\n                  }\n                }, function (err) {\n                  test.equal(0, err.ok);\n                  test.equal('auth failed', err.errmsg);\n                  serverManager.stop().then(function () {\n                    done();\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/auth/ssl_x509_connect.test.js","skipped":false,"dir":"test"},{"name":"Should give reasonable error on x509 authentication failure","suites":["SSL (x509)"],"updatePoint":{"line":217,"column":65,"index":6992},"line":217,"code":"  it('Should give reasonable error on x509 authentication failure', {\n    metadata: {\n      requires: {\n        topology: 'ssl'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n\n      var ServerManager = require('mongodb-topology-manager').Server; // Read the cert and key\n\n\n      var cert = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n      var key = fs.readFileSync(__dirname + '/ssl/x509/client.pem'); // User name\n\n      var userName = 'CN=client,OU=kerneluser,O=10Gen,L=New York City,ST=New York,C=US'; // Create server manager\n\n      var serverManager = new ServerManager('mongod', {\n        bind_ip: 'server',\n        port: 27019,\n        dbpath: f('%s/../db/27019', __dirname),\n        sslPEMKeyFile: __dirname + '/ssl/x509/server.pem',\n        sslCAFile: __dirname + '/ssl/x509/ca.pem',\n        sslCRLFile: __dirname + '/ssl/x509/crl.pem',\n        sslMode: 'requireSSL',\n        sslWeakCertificateValidation: null\n      }, {\n        ssl: true,\n        host: 'server',\n        key: cert,\n        cert: cert,\n        rejectUnauthorized: false\n      }); // Purge the set\n\n      serverManager.purge().then(function () {\n        // Start the server\n        serverManager.start().then(function () {\n          // Connect and validate the server certificate\n          MongoClient.connect('mongodb://server:27019/test?ssl=true&maxPoolSize=1', {\n            server: {\n              sslKey: key,\n              sslCert: cert,\n              sslValidate: false\n            }\n          }, function (err, client) {\n            expect(err).to.not.exist;\n            var db = client.db(configuration.db); // Execute build info\n\n            db.command({\n              buildInfo: 1\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              var version = parseInt(result.versionArray.slice(0, 3).join(''), 10);\n\n              if (version < 253) {\n                client.close();\n                return done();\n              } // Add the X509 auth user to the $external db\n\n\n              var ext = client.db('$external');\n              ext.addUser(userName, {\n                roles: [{\n                  role: 'readWriteAnyDatabase',\n                  db: 'admin'\n                }, {\n                  role: 'userAdminAnyDatabase',\n                  db: 'admin'\n                }]\n              }, function (err, result) {\n                expect(err).to.not.exist;\n                test.equal(userName, result[0].user);\n                test.equal('', result[0].pwd);\n                client.close(); // Connect using X509 authentication\n\n                MongoClient.connect(f('mongodb://%s@server:27019/test?authMechanism=%s&ssl=true&maxPoolSize=1', encodeURIComponent('WRONG_USERNAME'), 'MONGODB-X509'), {\n                  server: {\n                    sslKey: key,\n                    sslCert: cert,\n                    sslValidate: false\n                  }\n                }, function (err) {\n                  test.equal(0, err.ok);\n                  test.equal('auth failed', err.errmsg);\n                  serverManager.stop().then(function () {\n                    done();\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/auth/ssl_x509_connect.test.js","skipped":false,"dir":"test"},{"name":"Should give helpful error when attempting to use x509 without SSL","suites":["SSL (x509)"],"updatePoint":{"line":312,"column":71,"index":10276},"line":312,"code":"  it('Should give helpful error when attempting to use x509 without SSL', {\n    metadata: {\n      requires: {\n        topology: 'ssl'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n\n      var ServerManager = require('mongodb-topology-manager').Server; // Read the cert and key\n\n\n      var cert = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n      var key = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n      var serverPem = fs.readFileSync(__dirname + '/ssl/x509/server.pem'); // User name\n\n      var userName = 'CN=client,OU=kerneluser,O=10Gen,L=New York City,ST=New York,C=US'; // Create server manager\n\n      var serverManager = new ServerManager('mongod', {\n        bind_ip: 'server',\n        port: 27019,\n        dbpath: f('%s/../db/27019', __dirname)\n      }, {}); // Purge the set\n\n      serverManager.purge().then(function () {\n        // Start the server\n        serverManager.start().then(function () {\n          // Connect and validate the server certificate\n          MongoClient.connect('mongodb://server:27019/test?ssl=false&maxPoolSize=1', {\n            server: {\n              sslKey: key,\n              sslCert: cert,\n              sslValidate: false\n            }\n          }, function (err, client) {\n            expect(err).to.not.exist;\n            var db = client.db(configuration.db); // Execute build info\n\n            db.command({\n              buildInfo: 1\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              var version = parseInt(result.versionArray.slice(0, 3).join(''), 10);\n\n              if (version < 253) {\n                client.close();\n                return done();\n              } // Add the X509 auth user to the $external db\n\n\n              var ext = client.db('$external');\n              ext.addUser(userName, {\n                roles: [{\n                  role: 'readWriteAnyDatabase',\n                  db: 'admin'\n                }, {\n                  role: 'userAdminAnyDatabase',\n                  db: 'admin'\n                }]\n              }, function (err, result) {\n                expect(err).to.not.exist;\n                test.equal(userName, result[0].user);\n                test.equal('', result[0].pwd);\n                client.close(); // Connect using X509 authentication\n\n                MongoClient.connect(f('mongodb://%s@server:27019/test?authMechanism=%s&ssl=false&maxPoolSize=1', encodeURIComponent(userName), 'MONGODB-X509'), {\n                  server: {\n                    sslKey: serverPem,\n                    sslCert: serverPem,\n                    sslValidate: false\n                  }\n                }, function (err) {\n                  test.ok(!!err);\n                  test.equal(0, err.ok);\n                  test.equal('SSL support is required for the MONGODB-X509 mechanism.', err.errmsg);\n                  serverManager.stop().then(function () {\n                    done();\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/auth/ssl_x509_connect.test.js","skipped":false,"dir":"test"},{"name":"Should correctly reauthenticate against x509","suites":["SSL (x509)"],"updatePoint":{"line":398,"column":50,"index":13336},"line":398,"code":"  it('Should correctly reauthenticate against x509', {\n    metadata: {\n      requires: {\n        topology: 'ssl'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n\n      var ServerManager = require('mongodb-topology-manager').Server; // Read the cert and key\n\n\n      var cert = fs.readFileSync(__dirname + '/ssl/x509/client.pem');\n      var key = fs.readFileSync(__dirname + '/ssl/x509/client.pem'); // User name\n\n      var userName = 'CN=client,OU=kerneluser,O=10Gen,L=New York City,ST=New York,C=US'; // Create server manager\n\n      var serverManager = new ServerManager('mongod', {\n        bind_ip: 'server',\n        port: 27019,\n        dbpath: f('%s/../db/27019', __dirname),\n        sslPEMKeyFile: __dirname + '/ssl/x509/server.pem',\n        sslCAFile: __dirname + '/ssl/x509/ca.pem',\n        sslCRLFile: __dirname + '/ssl/x509/crl.pem',\n        sslMode: 'requireSSL',\n        sslWeakCertificateValidation: null\n      }, {\n        ssl: true,\n        host: 'server',\n        key: cert,\n        cert: cert,\n        rejectUnauthorized: false\n      }); // Purge the set\n\n      serverManager.purge().then(function () {\n        // Start the server\n        serverManager.start().then(function () {\n          // Connect and validate the server certificate\n          MongoClient.connect('mongodb://server:27019/test?ssl=true&maxPoolSize=1', {\n            server: {\n              sslKey: key,\n              sslCert: cert,\n              sslValidate: false\n            }\n          }, function (err, client) {\n            expect(err).to.not.exist;\n            var db = client.db(configuration.db); // Execute build info\n\n            db.command({\n              buildInfo: 1\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              var version = parseInt(result.versionArray.slice(0, 3).join(''), 10);\n\n              if (version < 253) {\n                client.close();\n                return done();\n              } // Add the X509 auth user to the $external db\n\n\n              var ext = client.db('$external');\n              ext.addUser(userName, {\n                roles: [{\n                  role: 'readWriteAnyDatabase',\n                  db: 'admin'\n                }, {\n                  role: 'userAdminAnyDatabase',\n                  db: 'admin'\n                }]\n              }, function (err, result) {\n                expect(err).to.not.exist;\n                test.equal(userName, result[0].user);\n                test.equal('', result[0].pwd);\n                client.close(); // Connect using X509 authentication\n\n                MongoClient.connect(f('mongodb://%s@server:27019/test?authMechanism=%s&ssl=true&maxPoolSize=1', encodeURIComponent(userName), 'MONGODB-X509'), {\n                  server: {\n                    sslKey: key,\n                    sslCert: cert,\n                    sslValidate: false\n                  }\n                }, function (err, client) {\n                  expect(err).to.not.exist;\n                  var db = client.db(configuration.db);\n                  db.collection('x509collection').insert({\n                    a: 1\n                  }, function (err) {\n                    expect(err).to.not.exist;\n                    db.collection('x509collection').findOne(function (err, doc) {\n                      expect(err).to.not.exist;\n                      test.equal(1, doc.a);\n                      client.topology.once('reconnect', function () {\n                        // Await reconnect and re-authentication\n                        db.collection('x509collection').findOne(function (err, doc) {\n                          expect(err).to.not.exist;\n                          test.equal(1, doc.a); // Attempt disconnect again\n\n                          client.topology.connections()[0].destroy(); // Await reconnect and re-authentication\n\n                          db.collection('x509collection').findOne(function (err, doc) {\n                            expect(err).to.not.exist;\n                            test.equal(1, doc.a);\n                            client.close();\n                            serverManager.stop().then(function () {\n                              done();\n                            });\n                          });\n                        });\n                      }); // Force close\n\n                      client.topology.connections()[0].destroy();\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/auth/ssl_x509_connect.test.js","skipped":false,"dir":"test"},{"name":"should correctly insert decimal128 value","suites":["Decimal128"],"updatePoint":{"line":23,"column":46,"index":365},"line":23,"code":"  it('should correctly insert decimal128 value', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>=3.3.6',\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var object = {\n          id: 1,\n          value: Decimal128.fromString('1')\n        };\n        db.collection('decimal128').insertOne(object, function (err) {\n          expect(err).to.not.exist;\n          db.collection('decimal128').findOne({\n            id: 1\n          }, function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc.value instanceof Decimal128);\n            test.equal('1', doc.value.toString());\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/bson-decimal128/decimal128.test.js","skipped":false,"dir":"test"},{"name":"2. The first read in a causally consistent session must not send afterClusterTime to the server","suites":["Causal Consistency - prose tests"],"updatePoint":{"line":56,"column":101,"index":1846},"line":56,"code":"  it('2. The first read in a causally consistent session must not send afterClusterTime to the server',\n  /**\n   * session = client.startSession(causalConsistency = true)\n   * document = collection.anyReadOperation(session, ...)\n   * capture the command sent to the server (using APM or other mechanism)\n   * assert that the command does not have an afterClusterTime\n   */\n  {\n    metadata: {\n      requires: {\n        topology: ['replicaset', 'sharded']\n      },\n      // Skipping session leak tests b/c these are explicit sessions\n      sessions: {\n        skipLeakTests: true\n      }\n    },\n    test: function () {\n      const session = test.client.startSession({\n        causalConsistency: true\n      });\n      const db = test.client.db(this.configuration.db);\n      return db.collection('causal_test').findOne({}, {\n        session: session\n      }).then(() => {\n        expect(test.commands.started).to.have.length(1);\n        expect(test.commands.succeeded).to.have.length(1);\n        const findCommand = test.commands.started[0].command;\n        expect(findCommand).to.have.property('find', 'causal_test');\n        expect(findCommand).to.not.have.key('readConcern');\n      });\n    }\n  }); // TODO(NODE-3882): need to do this for one write in addition to the read; and also test with errors","file":"integration/causal-consistency/causal_consistency.prose.test.js","skipped":false,"dir":"test"},{"name":"case: successful read with causal consistency","suites":["Causal Consistency - prose tests","3. The first read or write on a ClientSession should update the operationTime of the ClientSession, even if there is an error"],"updatePoint":{"line":98,"column":53,"index":3684},"line":98,"code":"    it('case: successful read with causal consistency', {\n      metadata: {\n        requires: {\n          topology: ['replicaset', 'sharded']\n        },\n        // Skipping session leak tests b/c these are explicit sessions\n        sessions: {\n          skipLeakTests: true\n        }\n      },\n      test: function () {\n        const session = test.client.startSession({\n          causalConsistency: true\n        });\n        const db = test.client.db(this.configuration.db);\n        expect(session.operationTime).to.not.exist;\n        return db.collection('causal_test').findOne({}, {\n          session: session\n        }).then(() => {\n          expect(test.commands.started).to.have.length(1);\n          expect(test.commands.succeeded).to.have.length(1);\n          const lastReply = test.commands.succeeded[0].reply;\n\n          const maybeLong = val => typeof val.equals === 'function' ? val.toNumber() : val;\n\n          expect(maybeLong(session.operationTime)).to.equal(maybeLong(lastReply.operationTime));\n        });\n      }\n    });","file":"integration/causal-consistency/causal_consistency.prose.test.js","skipped":false,"dir":"test"},{"name":"case: second operation is findOne","suites":["Causal Consistency - prose tests","4. A findOne followed by any other read operation should include the operationTime returned by the server for the first operation in the afterClusterTime parameter of the second operation"],"updatePoint":{"line":137,"column":41,"index":5362},"line":137,"code":"    it('case: second operation is findOne', {\n      metadata: {\n        requires: {\n          topology: ['replicaset', 'sharded']\n        },\n        // Skipping session leak tests b/c these are explicit sessions\n        sessions: {\n          skipLeakTests: true\n        }\n      },\n      test: function () {\n        const session = test.client.startSession({\n          causalConsistency: true\n        });\n        const db = test.client.db(this.configuration.db);\n        expect(session.operationTime).to.not.exist;\n        let firstOperationTime;\n        return db.collection('causal_test').findOne({}, {\n          session: session\n        }).then(() => {\n          const firstFindCommand = test.commands.started[0].command;\n          expect(firstFindCommand).to.not.have.key('readConcern');\n          firstOperationTime = test.commands.succeeded[0].reply.operationTime;\n          return db.collection('causal_test').findOne({}, {\n            session: session\n          });\n        }).then(() => {\n          const secondFindCommand = test.commands.started[1].command;\n          expect(secondFindCommand).to.have.any.key('readConcern');\n          expect(secondFindCommand.readConcern).to.have.any.key('afterClusterTime');\n          expect(secondFindCommand.readConcern.afterClusterTime).to.eql(firstOperationTime);\n        });\n      }\n    });","file":"integration/causal-consistency/causal_consistency.prose.test.js","skipped":false,"dir":"test"},{"name":"case: successful insert","suites":["Causal Consistency - prose tests","5. Any write operation followed by a findOne operation should include the operationTime of the first operation in the afterClusterTime parameter of the second operation"],"updatePoint":{"line":182,"column":31,"index":7417},"line":182,"code":"    it('case: successful insert', {\n      metadata: {\n        requires: {\n          topology: ['replicaset', 'sharded']\n        },\n        // Skipping session leak tests b/c these are explicit sessions\n        sessions: {\n          skipLeakTests: true\n        }\n      },\n      test: function () {\n        const session = test.client.startSession({\n          causalConsistency: true\n        });\n        const db = test.client.db(this.configuration.db);\n        expect(session.operationTime).to.not.exist;\n        let firstOperationTime;\n        return db.collection('causal_test').insert({}, {\n          session: session\n        }).then(() => {\n          firstOperationTime = test.commands.succeeded[0].reply.operationTime;\n          return db.collection('causal_test').findOne({}, {\n            session: session\n          });\n        }).then(() => {\n          const secondFindCommand = test.commands.started[1].command;\n          expect(secondFindCommand).to.have.any.key('readConcern');\n          expect(secondFindCommand.readConcern).to.have.any.key('afterClusterTime');\n          expect(secondFindCommand.readConcern.afterClusterTime).to.eql(firstOperationTime);\n        });\n      }\n    });","file":"integration/causal-consistency/causal_consistency.prose.test.js","skipped":false,"dir":"test"},{"name":"6. A read operation in a ClientSession that is not causally consistent should not include the afterClusterTime parameter in the command sent to the server","suites":["Causal Consistency - prose tests","5. Any write operation followed by a findOne operation should include the operationTime of the first operation in the afterClusterTime parameter of the second operation"],"updatePoint":{"line":215,"column":160,"index":8746},"line":215,"code":"  it('6. A read operation in a ClientSession that is not causally consistent should not include the afterClusterTime parameter in the command sent to the server',\n  /**\n   * session = client.startSession(causalConsistency = false)\n   * collection.anyReadOperation(session, {})\n   * operationTime = session.operationTime\n   * capture the command sent to the server (using APM or other mechanism)\n   * assert that the command does not have an afterClusterTime field\n   */\n  {\n    metadata: {\n      requires: {\n        topology: ['replicaset', 'sharded']\n      },\n      // Skipping session leak tests b/c these are explicit sessions\n      sessions: {\n        skipLeakTests: true\n      }\n    },\n    test: function () {\n      const session = test.client.startSession({\n        causalConsistency: false\n      });\n      const db = test.client.db(this.configuration.db);\n      const coll = db.collection('causal_test', {\n        readConcern: {\n          level: 'majority'\n        }\n      });\n      return coll.findOne({}, {\n        session: session\n      }).then(() => coll.findOne({}, {\n        session: session\n      })).then(() => {\n        const commands = test.commands.started.map(command => command.command);\n        expect(commands).to.have.length(2);\n\n        for (const command of commands) {\n          expect(command).to.have.any.key('readConcern');\n          expect(command.readConcern).to.not.have.any.key('afterClusterTime');\n        }\n      });\n    }\n  });","file":"integration/causal-consistency/causal_consistency.prose.test.js","skipped":false,"dir":"test"},{"name":"7. A read operation in a causally consistent session against a deployment that does not support cluster times does not include the afterClusterTime parameter in the command sent to the server","suites":["Causal Consistency - prose tests","5. Any write operation followed by a findOne operation should include the operationTime of the first operation in the afterClusterTime parameter of the second operation"],"updatePoint":{"line":258,"column":197,"index":10247},"line":258,"code":"  it('7. A read operation in a causally consistent session against a deployment that does not support cluster times does not include the afterClusterTime parameter in the command sent to the server',\n  /**\n   * session = client.startSession(causalConsistency = true)\n   * collection.anyReadOperation(session, {})\n   * capture the command sent to the server (using APM or other mechanism)\n   * assert that the command does not have an afterClusterTime field\n   */\n  {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const db = test.client.db(this.configuration.db);\n      const coll = db.collection('causal_test', {\n        readConcern: {\n          level: 'local'\n        }\n      });\n      return coll.findOne({}).then(() => coll.findOne({})).then(() => {\n        const command = test.commands.started[1].command;\n        expect(command).to.have.any.key('readConcern');\n        expect(command.readConcern).to.not.have.any.key('afterClusterTime');\n      });\n    }\n  }); // #10 is removed by DRIVERS-1374/NODE-3883","file":"integration/causal-consistency/causal_consistency.prose.test.js","skipped":false,"dir":"test"},{"name":"should pass corpus  client schema","suites":["Client Side Encryption Prose Corpus Test"],"updatePoint":{"line":213,"column":84,"index":8347},"line":213,"code":"    it(`should pass corpus ${useClientSideSchema ? 'with' : 'without'} client schema`, metadata, function () {\n      const corpusCopied = {};\n      return Promise.resolve().then(() => {\n        // 5. Load `corpus/corpus.json <../corpus/corpus.json>`_ to a variable named ``corpus``. The corpus contains subdocuments with the following fields:\n        //\n        //    - ``kms`` is either ``aws`` or ``local``\n        //    - ``type`` is a BSON type string `names coming from here <https://docs.mongodb.com/manual/reference/operator/query/type/>`_)\n        //    - ``algo`` is either ``rand`` or ``det`` for random or deterministic encryption\n        //    - ``method`` is either ``auto``, for automatic encryption or ``explicit`` for  explicit encryption\n        //    - ``identifier`` is either ``id`` or ``altname`` for the key identifier\n        //    - ``allowed`` is a boolean indicating whether the encryption for the given parameters is permitted.\n        //    - ``value`` is the value to be tested.\n        //\n        //    Create a new BSON document, named ``corpus_copied``.\n        //\n        //    Iterate over each field of ``corpus``.\n        //    - If the field name is ``_id``, ``altname_aws`` and ``altname_local``, copy the field to ``corpus_copied``.\n        //    - If ``method`` is ``auto``, copy the field to ``corpus_copied``.\n        //    - If ``method`` is ``explicit``, use ``client_encryption`` to explicitly encrypt the value.\n        //      - Encrypt with the algorithm described by ``algo``.\n        //      - If ``identifier`` is ``id``\n        //        - If ``kms`` is ``local`` set the key_id to the UUID with base64 value ``LOCALAAAAAAAAAAAAAAAAA==``.\n        //        - If ``kms`` is ``aws`` set the key_id to the UUID with base64 value ``AWSAAAAAAAAAAAAAAAAAAA==``.\n        //      - If ``identifier`` is ``altname``\n        //        - If ``kms`` is ``local`` set the key_alt_name to \"local\".\n        //        - If ``kms`` is ``aws`` set the key_alt_name to \"aws\".\n        //      If ``allowed`` is true, copy the field and encrypted value to ``corpus_copied``.\n        //      If ``allowed`` is false. verify that an exception is thrown. Copy the unencrypted value to to ``corpus_copied``.\n        return forEachP(Object.keys(corpus), key => {\n          const field = corpus[key];\n\n          if (copyOverValues.has(key)) {\n            corpusCopied[key] = field;\n            return;\n          }\n\n          if (field.method === 'auto') {\n            corpusCopied[key] = Object.assign({}, field);\n            return;\n          }\n\n          if (field.method === 'explicit') {\n            const encryptOptions = {\n              algorithm: algorithmMap.get(field.algo)\n            };\n\n            if (field.identifier === 'id') {\n              encryptOptions.keyId = identifierMap.get(field.kms);\n            } else if (field.identifier === 'altname') {\n              encryptOptions.keyAltName = keyAltNameMap.get(field.kms);\n            } else {\n              throw new Error('Unexpected identifier: ' + field.identifier);\n            }\n\n            return Promise.resolve().then(() => clientEncryption.encrypt(field.value, encryptOptions)).then(encryptedValue => {\n              if (field.allowed === true) {\n                corpusCopied[key] = Object.assign({}, field, {\n                  value: encryptedValue\n                });\n              } else {\n                throw new Error(`Expected encryption to fail for case ${key} on value ${field.value}`);\n              }\n            }, e => {\n              if (field.allowed === false) {\n                corpusCopied[key] = Object.assign({}, field);\n              } else {\n                throw e;\n              }\n            });\n          }\n\n          throw new Error('Unexpected method: ' + field.method);\n        });\n      }).then(() => {\n        // 6. Using ``client_encrypted``, insert ``corpus_copied`` into ``db.coll``.\n        return clientEncrypted.db(dataDbName).collection(dataCollName).insertOne(corpusCopied);\n      }).then(() => {\n        // 7. Using ``client_encrypted``, find the inserted document from ``db.coll`` to a variable named ``corpus_decrypted``.\n        // Since it should have been automatically decrypted, assert the document exactly matches ``corpus``.\n        return clientEncrypted.db(dataDbName).collection(dataCollName).findOne({\n          _id: corpusCopied._id\n        }, {\n          promoteLongs: false,\n          promoteValues: false\n        });\n      }).then(corpusDecrypted => {\n        expect(toComparableExtendedJSON(corpusDecrypted)).to.deep.equal(toComparableExtendedJSON(corpus));\n      }).then(() => {\n        // 8. Load `corpus/corpus_encrypted.json <../corpus/corpus-encrypted.json>`_ to a variable named ``corpus_encrypted_expected``.\n        //    Using ``client`` find the inserted document from ``db.coll`` to a variable named ``corpus_encrypted_actual``.\n        //    Iterate over each field of ``corpus_encrypted_expected`` and check the following:\n        //    - If the ``algo`` is ``det``, that the value equals the value of the corresponding field in ``corpus_encrypted_actual``.\n        //    - If the ``algo`` is ``rand`` and ``allowed`` is true, that the value does not equal the value of the corresponding field in ``corpus_encrypted_actual``.\n        //    - If ``allowed`` is true, decrypt the value with ``client_encryption``. Decrypt the value of the corresponding field of ``corpus_encrypted`` and validate that they are both equal.\n        //    - If ``allowed`` is false, validate the value exactly equals the value of the corresponding field of ``corpus`` (neither was encrypted).\n        return client.db(dataDbName).collection(dataCollName).findOne({\n          _id: corpusCopied._id\n        }, {\n          promoteLongs: false,\n          promoteValues: false\n        });\n      }).then(corpusEncryptedActual => {\n        return forEachP(Object.keys(corpusEncryptedExpected), key => {\n          return assertion(clientEncryption, key, corpusEncryptedExpected[key], corpusEncryptedActual[key]);\n        });\n      });\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.corpus.test.js","skipped":false,"dir":"test"},{"name":"should work for local KMS provider","suites":["Client Side Encryption Prose Tests","Data key and double encryption"],"updatePoint":{"line":151,"column":42,"index":5445},"line":151,"code":"    it('should work for local KMS provider', metadata, function () {\n      let localDatakeyId;\n      let localEncrypted;\n      return Promise.resolve().then(() => {\n        // #. Call ``client_encryption.createDataKey()`` with the ``local`` KMS provider and keyAltNames set to ``[\"local_altname\"]``.\n        // - Expect a BSON binary with subtype 4 to be returned, referred to as ``local_datakey_id``.\n        // - Use ``client`` to run a ``find`` on ``keyvault.datakeys`` by querying with the ``_id`` set to the ``local_datakey_id``.\n        // - Expect that exactly one document is returned with the \"masterKey.provider\" equal to \"local\".\n        // - Check that ``client`` captured a command_started event for the ``insert`` command containing a majority writeConcern.\n        this.commandStartedEvents.clear();\n        return this.clientEncryption.createDataKey('local', {\n          keyAltNames: ['local_altname']\n        }).then(result => {\n          localDatakeyId = result;\n          expect(localDatakeyId).to.have.property('sub_type', 4);\n        }).then(() => {\n          return this.client.db(keyVaultDbName).collection(keyVaultCollName).find({\n            _id: localDatakeyId\n          }).toArray();\n        }).then(results => {\n          expect(results).to.have.a.lengthOf(1).and.to.have.nested.property('0.masterKey.provider', 'local');\n          expect(this.commandStartedEvents.events).to.containSubset([{\n            commandName: 'insert',\n            command: {\n              writeConcern: {\n                w: 'majority'\n              }\n            }\n          }]);\n        });\n      }).then(() => {\n        // #. Call ``client_encryption.encrypt()`` with the value \"hello local\", the algorithm ``AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic``, and the ``key_id`` of ``local_datakey_id``.\n        // - Expect the return value to be a BSON binary subtype 6, referred to as ``local_encrypted``.\n        // - Use ``client_encrypted`` to insert ``{ _id: \"local\", \"value\": <local_encrypted> }`` into ``db.coll``.\n        // - Use ``client_encrypted`` to run a find querying with ``_id`` of \"local\" and expect ``value`` to be \"hello local\".\n        const coll = this.clientEncrypted.db(dataDbName).collection(dataCollName);\n        return this.clientEncryption.encrypt('hello local', {\n          algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic',\n          keyId: localDatakeyId\n        }).then(value => {\n          localEncrypted = value;\n          expect(localEncrypted).to.have.property('sub_type', 6);\n        }).then(() => coll.insertOne({\n          _id: 'local',\n          value: localEncrypted\n        })).then(() => coll.findOne({\n          _id: 'local'\n        })).then(result => {\n          expect(result).to.have.property('value', 'hello local');\n        });\n      }).then(() => {\n        // #. Call ``client_encryption.encrypt()`` with the value \"hello local\", the algorithm ``AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic``, and the ``key_alt_name`` of ``local_altname``.\n        // - Expect the return value to be a BSON binary subtype 6. Expect the value to exactly match the value of ``local_encrypted``.\n        return this.clientEncryption.encrypt('hello local', {\n          algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic',\n          keyId: localDatakeyId\n        }).then(encrypted => {\n          expect(encrypted).to.deep.equal(localEncrypted);\n        });\n      });\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should work for aws KMS provider","suites":["Client Side Encryption Prose Tests","Data key and double encryption"],"updatePoint":{"line":212,"column":40,"index":8862},"line":212,"code":"    it('should work for aws KMS provider', metadata, function () {\n      // Then, repeat the above tests with the ``aws`` KMS provider:\n      let awsDatakeyId;\n      let awsEncrypted;\n      return Promise.resolve().then(() => {\n        // #. Call ``client_encryption.createDataKey()`` with the ``aws`` KMS provider, keyAltNames set to ``[\"aws_altname\"]``, and ``masterKey`` as follows:\n        //    .. code:: javascript\n        //       {\n        //         region: \"us-east-1\",\n        //         key: \"arn:aws:kms:us-east-1:579766882180:key/89fcc2c4-08b0-4bd9-9f25-e30687b580d0\"\n        //       }\n        //    - Expect a BSON binary with subtype 4 to be returned, referred to as ``aws_datakey_id``.\n        //    - Use ``client`` to run a ``find`` on ``keyvault.datakeys`` by querying with the ``_id`` set to the ``aws_datakey_id``.\n        //    - Expect that exactly one document is returned with the \"masterKey.provider\" equal to \"aws\".\n        //    - Check that ``client`` captured a command_started event for the ``insert`` command containing a majority writeConcern.\n        this.commandStartedEvents.clear();\n        const masterKey = {\n          region: 'us-east-1',\n          key: 'arn:aws:kms:us-east-1:579766882180:key/89fcc2c4-08b0-4bd9-9f25-e30687b580d0'\n        };\n        return this.clientEncryption.createDataKey('aws', {\n          masterKey,\n          keyAltNames: ['aws_altname']\n        }).then(result => {\n          awsDatakeyId = result;\n          expect(awsDatakeyId).to.have.property('sub_type', 4);\n        }).then(() => {\n          return this.client.db(keyVaultDbName).collection(keyVaultCollName).find({\n            _id: awsDatakeyId\n          }).toArray();\n        }).then(results => {\n          expect(results).to.have.a.lengthOf(1).and.to.have.nested.property('0.masterKey.provider', 'aws');\n          expect(this.commandStartedEvents.events).to.containSubset([{\n            commandName: 'insert',\n            command: {\n              writeConcern: {\n                w: 'majority'\n              }\n            }\n          }]);\n        });\n      }).then(() => {\n        // #. Call ``client_encryption.encrypt()`` with the value \"hello aws\", the algorithm ``AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic``, and the ``key_id`` of ``aws_datakey_id``.\n        //    - Expect the return value to be a BSON binary subtype 6, referred to as ``aws_encrypted``.\n        //    - Use ``client_encrypted`` to insert ``{ _id: \"aws\", \"value\": <aws_encrypted> }`` into ``db.coll``.\n        //    - Use ``client_encrypted`` to run a find querying with ``_id`` of \"aws\" and expect ``value`` to be \"hello aws\".\n        const coll = this.clientEncrypted.db(dataDbName).collection(dataCollName);\n        return this.clientEncryption.encrypt('hello aws', {\n          algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic',\n          keyId: awsDatakeyId\n        }).then(value => {\n          awsEncrypted = value;\n          expect(awsEncrypted).to.have.property('sub_type', 6);\n        }).then(() => coll.insertOne({\n          _id: 'aws',\n          value: awsEncrypted\n        })).then(() => coll.findOne({\n          _id: 'aws'\n        })).then(result => {\n          expect(result).to.have.property('value', 'hello aws');\n        });\n      }).then(() => {\n        // #. Call ``client_encryption.encrypt()`` with the value \"hello aws\", the algorithm ``AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic``, and the ``key_alt_name`` of ``aws_altname``.\n        //    - Expect the return value to be a BSON binary subtype 6. Expect the value to exactly match the value of ``aws_encrypted``.\n        return this.clientEncryption.encrypt('hello aws', {\n          algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic',\n          keyId: awsDatakeyId\n        }).then(encrypted => {\n          expect(encrypted).to.deep.equal(awsEncrypted);\n        });\n      });\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should error on an attempt to double-encrypt a value","suites":["Client Side Encryption Prose Tests","Data key and double encryption"],"updatePoint":{"line":284,"column":60,"index":12750},"line":284,"code":"    it('should error on an attempt to double-encrypt a value', metadata, function () {\n      // Then, run the following final tests:\n      // #. Test explicit encrypting an auto encrypted field.\n      //    - Use ``client_encrypted`` to attempt to insert ``{ \"encrypted_placeholder\": (local_encrypted) }``\n      //    - Expect an exception to be thrown, since this is an attempt to auto encrypt an already encrypted value.\n      return Promise.resolve().then(() => this.clientEncryption.createDataKey('local')).then(keyId => this.clientEncryption.encrypt('hello double', {\n        keyId,\n        algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic'\n      })).then(encrypted => this.clientEncrypted.db(dataDbName).collection(dataCollName).insertOne({\n        encrypted_placeholder: encrypted\n      }).then(() => {\n        throw new Error('Expected double-encryption to fail, but it has succeeded');\n      }, err => {\n        expect(err).to.be.an.instanceOf(Error);\n      }));\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should work  external key vault","suites":["Client Side Encryption Prose Tests","External Key Vault Test"],"updatePoint":{"line":343,"column":85,"index":15689},"line":343,"code":"      it(`should work ${withExternalKeyVault ? 'with' : 'without'} external key vault`, metadata, function () {\n        const ClientEncryption = this.configuration.mongodbClientEncryption.ClientEncryption;\n        return Promise.resolve().then(() => {\n          //    If ``withExternalKeyVault == true``, configure both objects with an external key vault client. The external client MUST connect to the same\n          //    MongoDB cluster that is being tested against, except it MUST use the username ``fake-user`` and password ``fake-pwd``.\n          this.externalClient = this.configuration.newClient( // this.configuration.url('fake-user', 'fake-pwd'),\n          // TODO: Do this properly\n          {}, {\n            monitorCommands: true\n          });\n          this.commandStartedEvents = new APMEventCollector(this.externalClient, 'commandStarted', {\n            include: ['find']\n          });\n          return this.externalClient.connect();\n        }) // 3. Create the following:\n        //    - A MongoClient configured with auto encryption (referred to as ``client_encrypted``)\n        //    - A ``ClientEncryption`` object (referred to as ``client_encryption``)\n        //    Configure both objects with the ``local`` KMS providers as follows:\n        //    .. code:: javascript\n        //       { \"local\": { \"key\": <base64 decoding of LOCAL_MASTERKEY> } }\n        //    Configure both objects with ``keyVaultNamespace`` set to ``keyvault.datakeys``.\n        //    Configure ``client_encrypted`` to use the schema `external/external-schema.json <../external/external-schema.json>`_  for ``db.coll`` by setting a schema map like: ``{ \"db.coll\": <contents of external-schema.json>}``\n        .then(() => {\n          const options = {\n            bson: BSON,\n            keyVaultNamespace,\n            kmsProviders: getKmsProviders(LOCAL_KEY)\n          };\n\n          if (withExternalKeyVault) {\n            options.keyVaultClient = this.externalClient;\n          }\n\n          this.clientEncryption = new ClientEncryption(this.client, Object.assign({}, options));\n          this.clientEncrypted = this.configuration.newClient({}, {\n            autoEncryption: Object.assign({}, options, {\n              schemaMap: {\n                'db.coll': externalSchema\n              }\n            })\n          });\n          return this.clientEncrypted.connect();\n        }).then(() => {\n          // 4. Use ``client_encrypted`` to insert the document ``{\"encrypted\": \"test\"}`` into ``db.coll``.\n          //    If ``withExternalKeyVault == true``, expect an authentication exception to be thrown. Otherwise, expect the insert to succeed.\n          this.commandStartedEvents.clear();\n          return this.clientEncrypted.db(dataDbName).collection(dataCollName).insertOne({\n            encrypted: 'test'\n          }).then(() => {\n            if (withExternalKeyVault) {\n              expect(this.commandStartedEvents.events).to.containSubset([{\n                commandName: 'find',\n                databaseName: keyVaultDbName,\n                command: {\n                  find: keyVaultCollName\n                }\n              }]);\n            } else {\n              expect(this.commandStartedEvents.events).to.not.containSubset([{\n                commandName: 'find',\n                databaseName: keyVaultDbName,\n                command: {\n                  find: keyVaultCollName\n                }\n              }]);\n            }\n          }); // TODO: Do this in the spec-compliant way using bad auth credentials\n          // .then(\n          //   () => {\n          //     if (withExternalKeyVault) {\n          //       throw new Error(\n          //         'expected insert to fail with authentication error, but it passed'\n          //       );\n          //     }\n          //   },\n          //   err => {\n          //     if (!withExternalKeyVault) {\n          //       throw err;\n          //     }\n          //     expect(err).to.be.an.instanceOf(Error);\n          //   }\n          // );\n        }).then(() => {\n          // 5. Use ``client_encryption`` to explicitly encrypt the string ``\"test\"`` with key ID ``LOCALAAAAAAAAAAAAAAAAA==`` and deterministic algorithm.\n          //    If ``withExternalKeyVault == true``, expect an authentication exception to be thrown. Otherwise, expect the insert to succeed.\n          this.commandStartedEvents.clear();\n          return this.clientEncryption.encrypt('test', {\n            keyId: externalKey._id,\n            algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic'\n          }).then(() => {\n            if (withExternalKeyVault) {\n              expect(this.commandStartedEvents.events).to.containSubset([{\n                commandName: 'find',\n                databaseName: keyVaultDbName,\n                command: {\n                  find: keyVaultCollName\n                }\n              }]);\n            } else {\n              expect(this.commandStartedEvents.events).to.not.containSubset([{\n                commandName: 'find',\n                databaseName: keyVaultDbName,\n                command: {\n                  find: keyVaultCollName\n                }\n              }]);\n            }\n          }); // TODO: Do this in the spec-compliant way using bad auth credentials\n          // .then(\n          //   () => {\n          //     if (withExternalKeyVault) {\n          //       throw new Error(\n          //         'expected insert to fail with authentication error, but it passed'\n          //       );\n          //     }\n          //   },\n          //   err => {\n          //     if (!withExternalKeyVault) {\n          //       throw err;\n          //     }\n          //     expect(err).to.be.an.instanceOf(Error);\n          //   }\n          // );\n        });\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should error when inserting into a view with autoEncryption","suites":["Client Side Encryption Prose Tests","Views are prohibited"],"updatePoint":{"line":712,"column":67,"index":32140},"line":712,"code":"    it('should error when inserting into a view with autoEncryption', metadata, function () {\n      return this.clientEncrypted.db(dataDbName).collection('view').insertOne({\n        a: 1\n      }).then(() => {\n        throw new Error('Expected insert to fail, but it succeeded');\n      }, err => {\n        expect(err).to.have.property('message').that.matches(/cannot auto encrypt a view/);\n      });\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"runs in a separate suite","suites":["Client Side Encryption Prose Tests","Corpus Test"],"updatePoint":{"line":723,"column":32,"index":32558},"line":723,"code":"    it('runs in a separate suite', () => {\n      expect(() => fs.statSync(path.resolve(__dirname, './client_side_encryption.prose.corpus.test.js'))).not.to.throw();\n    });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"Via mongocryptdBypassSpawn","suites":["Client Side Encryption Prose Tests","Bypass spawning mongocryptd"],"line":950,"code":"    it.skip('Via mongocryptdBypassSpawn', () => {}).skipReason = 'TODO(NODE-2422): Implement \"Bypass spawning mongocryptd\" tests';","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":true,"dir":"test"},{"name":"Via bypassAutoEncryption","suites":["Client Side Encryption Prose Tests","Bypass spawning mongocryptd"],"line":951,"code":"    it.skip('Via bypassAutoEncryption', () => {}).skipReason = 'TODO(NODE-2422): Implement \"Bypass spawning mongocryptd\" tests';","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":true,"dir":"test"},{"name":"TBD","suites":["Client Side Encryption Prose Tests","KMS TLS Tests"],"line":958,"code":"    it.skip('TBD', () => {}).skipReason = 'TODO(NODE-3151): Implement \"KMS TLS Tests\"';","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":true,"dir":"test"},{"name":"should fail with no TLS","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 1: AWS"],"updatePoint":{"line":1097,"column":33,"index":46274},"line":1097,"code":"      it('should fail with no TLS', metadata, async function () {\n        try {\n          await clientEncryptionNoTls.createDataKey('aws', {\n            masterKey\n          });\n          expect.fail('it must fail with no tls');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed.\n          expect(e.originalError.message).to.include('certificate required');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should succeed with valid TLS options","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 1: AWS"],"updatePoint":{"line":1108,"column":47,"index":46698},"line":1108,"code":"      it('should succeed with valid TLS options', metadata, async function () {\n        try {\n          await clientEncryptionWithTls.createDataKey('aws', {\n            masterKey\n          });\n          expect.fail('it must fail to parse response');\n        } catch (e) {\n          // Expect an error from libmongocrypt with a message containing the string: \"parse error\".\n          // This implies TLS handshake succeeded.\n          expect(e.message).to.include('parse error');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an expired certificate","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 1: AWS"],"updatePoint":{"line":1120,"column":49,"index":47199},"line":1120,"code":"      it('should fail with an expired certificate', async function () {\n        try {\n          await clientEncryptionWithTlsExpired.createDataKey('aws', {\n            masterKey: masterKeyExpired\n          });\n          expect.fail('it must fail with invalid certificate');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an expired certificate.\n          expect(e.originalError.message).to.include('certificate has expired');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an invalid hostname","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 1: AWS"],"updatePoint":{"line":1131,"column":46,"index":47685},"line":1131,"code":"      it('should fail with an invalid hostname', metadata, async function () {\n        try {\n          await clientEncryptionWithInvalidHostname.createDataKey('aws', {\n            masterKey: masterKeyInvalidHostname\n          });\n          expect.fail('it must fail with invalid hostnames');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an invalid hostname.\n          expect(e.originalError.message).to.include('does not match certificate');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with no TLS","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 2: Azure"],"updatePoint":{"line":1149,"column":33,"index":48358},"line":1149,"code":"      it('should fail with no TLS', metadata, async function () {\n        try {\n          await clientEncryptionNoTls.createDataKey('azure', {\n            masterKey\n          });\n          expect.fail('it must fail with no tls');\n        } catch (e) {\n          //Expect an error indicating TLS handshake failed.\n          expect(e.originalError.message).to.include('certificate required');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should succeed with valid TLS options","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 2: Azure"],"updatePoint":{"line":1160,"column":47,"index":48783},"line":1160,"code":"      it('should succeed with valid TLS options', metadata, async function () {\n        try {\n          await clientEncryptionWithTls.createDataKey('azure', {\n            masterKey\n          });\n          expect.fail('it must fail with HTTP 404');\n        } catch (e) {\n          // Expect an error from libmongocrypt with a message containing the string: \"HTTP status=404\".\n          // This implies TLS handshake succeeded.\n          expect(e.message).to.include('HTTP status=404');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an expired certificate","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 2: Azure"],"updatePoint":{"line":1172,"column":49,"index":49290},"line":1172,"code":"      it('should fail with an expired certificate', async function () {\n        try {\n          await clientEncryptionWithTlsExpired.createDataKey('azure', {\n            masterKey\n          });\n          expect.fail('it must fail with expired certificates');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an expired certificate.\n          expect(e.originalError.message).to.include('certificate has expired');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an invalid hostname","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 2: Azure"],"updatePoint":{"line":1183,"column":46,"index":49761},"line":1183,"code":"      it('should fail with an invalid hostname', metadata, async function () {\n        try {\n          await clientEncryptionWithInvalidHostname.createDataKey('azure', {\n            masterKey\n          });\n          expect.fail('it must fail with invalid hostnames');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an invalid hostname.\n          expect(e.originalError.message).to.include('does not match certificate');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with no TLS","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 3: GCP"],"updatePoint":{"line":1203,"column":33,"index":50435},"line":1203,"code":"      it('should fail with no TLS', metadata, async function () {\n        try {\n          await clientEncryptionNoTls.createDataKey('gcp', {\n            masterKey\n          });\n          expect.fail('it must fail with no tls');\n        } catch (e) {\n          //Expect an error indicating TLS handshake failed.\n          expect(e.originalError.message).to.include('certificate required');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should succeed with valid TLS options","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 3: GCP"],"updatePoint":{"line":1214,"column":47,"index":50858},"line":1214,"code":"      it('should succeed with valid TLS options', metadata, async function () {\n        try {\n          await clientEncryptionWithTls.createDataKey('gcp', {\n            masterKey\n          });\n          expect.fail('it must fail with HTTP 404');\n        } catch (e) {\n          // Expect an error from libmongocrypt with a message containing the string: \"HTTP status=404\".\n          // This implies TLS handshake succeeded.\n          expect(e.message).to.include('HTTP status=404');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an expired certificate","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 3: GCP"],"updatePoint":{"line":1226,"column":49,"index":51363},"line":1226,"code":"      it('should fail with an expired certificate', async function () {\n        try {\n          await clientEncryptionWithTlsExpired.createDataKey('gcp', {\n            masterKey\n          });\n          expect.fail('it must fail with expired certificates');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an expired certificate.\n          expect(e.originalError.message).to.include('certificate has expired');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an invalid hostname","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 3: GCP"],"updatePoint":{"line":1237,"column":46,"index":51832},"line":1237,"code":"      it('should fail with an invalid hostname', metadata, async function () {\n        try {\n          await clientEncryptionWithInvalidHostname.createDataKey('gcp', {\n            masterKey\n          });\n          expect.fail('it must fail with invalid hostnames');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an invalid hostname.\n          expect(e.originalError.message).to.include('does not match certificate');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with no TLS","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 4: KMIP"],"updatePoint":{"line":1252,"column":33,"index":52400},"line":1252,"code":"      it('should fail with no TLS', metadata, async function () {\n        try {\n          await clientEncryptionNoTls.createDataKey('kmip', {\n            masterKey\n          });\n          expect.fail('it must fail with no tls');\n        } catch (e) {\n          //Expect an error indicating TLS handshake failed.\n          expect(e.originalError.message).to.include('before secure TLS connection');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should succeed with valid TLS options","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 4: KMIP"],"updatePoint":{"line":1263,"column":47,"index":52832},"line":1263,"code":"      it('should succeed with valid TLS options', metadata, async function () {\n        const keyId = await clientEncryptionWithTls.createDataKey('kmip', {\n          masterKey\n        }); // expect success\n\n        expect(keyId).to.be.an('object');\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an expired certificate","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 4: KMIP"],"updatePoint":{"line":1270,"column":49,"index":53093},"line":1270,"code":"      it('should fail with an expired certificate', async function () {\n        try {\n          await clientEncryptionWithTlsExpired.createDataKey('kmip', {\n            masterKey\n          });\n          expect.fail('it must fail with expired certificates');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an expired certificate.\n          expect(e.originalError.message).to.include('certificate has expired');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"should fail with an invalid hostname","suites":["Client Side Encryption Prose Tests","KMS TLS Options Tests","Case 4: KMIP"],"updatePoint":{"line":1281,"column":46,"index":53563},"line":1281,"code":"      it('should fail with an invalid hostname', metadata, async function () {\n        try {\n          await clientEncryptionWithInvalidHostname.createDataKey('kmip', {\n            masterKey\n          });\n          expect.fail('it must fail with invalid hostnames');\n        } catch (e) {\n          // Expect an error indicating TLS handshake failed due to an invalid hostname.\n          expect(e.originalError.message).to.include('does not match certificate');\n        }\n      });","file":"integration/client-side-encryption/client_side_encryption.prose.test.js","skipped":false,"dir":"test"},{"name":"CSFLE_KMS_PROVIDERS should be valid EJSON","suites":["Client Side Encryption Functional"],"updatePoint":{"line":23,"column":47,"index":592},"line":23,"code":"  it('CSFLE_KMS_PROVIDERS should be valid EJSON', function () {\n    if (process.env.CSFLE_KMS_PROVIDERS) {\n      /**\n       * The shape of CSFLE_KMS_PROVIDERS is as follows:\n       *\n       * interface CSFLE_kms_providers {\n       *    aws: {\n       *      accessKeyId: string;\n       *      secretAccessKey: string;\n       *   };\n       *   azure: {\n       *     tenantId: string;\n       *     clientId: string;\n       *     clientSecret: string;\n       *   };\n       *   gcp: {\n       *     email: string;\n       *     privateKey: string;\n       *   };\n       *   local: {\n       *     // EJSON handle converting this, its actually the canonical -> { $binary: { base64: string; subType: string } }\n       *     // **NOTE**: The dollar sign has to be escaped when using this as an ENV variable\n       *     key: Binary;\n       *   }\n       * }\n       */\n      expect(() => BSON.EJSON.parse(process.env.CSFLE_KMS_PROVIDERS)).to.not.throw(SyntaxError);\n    } else {\n      this.skip();\n    }\n  });","file":"integration/client-side-encryption/driver.test.js","skipped":false,"dir":"test"},{"name":"cursor count method should return the correct number when used with collation set","suites":["Collation"],"updatePoint":{"line":15,"column":87,"index":304},"line":15,"code":"  it('cursor count method should return the correct number when used with collation set', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.4.0'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      });\n      client.connect().then(() => {\n        const db = client.db(configuration.db);\n        const docs = [{\n          _id: 0,\n          name: 'foo'\n        }, {\n          _id: 1,\n          name: 'Foo'\n        }];\n        const collation = {\n          locale: 'en_US',\n          strength: 2\n        };\n        let collection, cursor;\n\n        const close = e => cursor.close(() => client.close(() => done(e)));\n\n        Promise.resolve().then(() => db.createCollection('cursor_collation_count')).then(() => collection = db.collection('cursor_collation_count')).then(() => collection.insertMany(docs)).then(() => collection.find({\n          name: 'foo'\n        }).collation(collation)).then(_cursor => cursor = _cursor).then(() => cursor.count()).then(val => expect(val).to.equal(2)).then(() => close()).catch(e => close(e));\n      });\n    }\n  });","file":"integration/collation/collations.test.js","skipped":false,"dir":"test"},{"name":"Should correctly create index with collation","suites":["Collation"],"updatePoint":{"line":60,"column":50,"index":2020},"line":60,"code":"  it('Should correctly create index with collation', {\n    metadata: {\n      requires: {\n        topology: 'single',\n        mongodb: '>=3.3.12'\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient();\n      return client.connect().then(() => {\n        const db = client.db(configuration.db);\n        const col = db.collection('collation_test');\n        return col.createIndexes([{\n          key: {\n            a: 1\n          },\n          collation: {\n            locale: 'nn'\n          },\n          name: 'collation_test'\n        }]).then(() => col.listIndexes().toArray()).then(r => {\n          const indexes = r.filter(i => i.name === 'collation_test');\n          expect(indexes).to.have.length(1);\n          expect(indexes[0]).to.have.property('collation');\n          expect(indexes[0].collation).to.exist;\n          return client.close();\n        });\n      });\n    }\n  });","file":"integration/collation/collations.test.js","skipped":false,"dir":"test"},{"name":"Should correctly create collection with collation","suites":["Collation"],"updatePoint":{"line":91,"column":55,"index":2981},"line":91,"code":"  it('Should correctly create collection with collation', {\n    metadata: {\n      requires: {\n        topology: 'single',\n        mongodb: '>=3.3.12'\n      }\n    },\n    test: function () {\n      const configuration = this.configuration;\n      const client = configuration.newClient();\n      return client.connect().then(() => {\n        const db = client.db(configuration.db);\n        return db.createCollection('collation_test2', {\n          collation: {\n            locale: 'nn'\n          }\n        }).then(() => db.listCollections({\n          name: 'collation_test2'\n        }).toArray()).then(collections => {\n          expect(collections).to.have.length(1);\n          expect(collections[0].name).to.equal('collation_test2');\n          expect(collections[0].options.collation).to.exist;\n          return client.close();\n        });\n      });\n    }\n  });","file":"integration/collation/collations.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute basic collection methods","suites":["Collection","standard collection tests"],"updatePoint":{"line":42,"column":57,"index":995},"line":42,"code":"    it('should correctly execute basic collection methods', function (done) {\n      db.createCollection('test_collection_methods', (err, collection) => {\n        // Verify that all the result are correct coming back (should contain the value ok)\n        expect(collection.collectionName).to.equal('test_collection_methods'); // Let's check that the collection was created correctly\n\n        db.listCollections().toArray((err, documents) => {\n          expect(err).to.not.exist;\n          let found = false;\n          documents.forEach(doc => {\n            if (doc.name === 'test_collection_methods') found = true;\n          });\n          expect(found).to.be.true; // Rename the collection and check that it's gone\n\n          db.renameCollection('test_collection_methods', 'test_collection_methods2', err => {\n            expect(err).to.not.exist; // Drop the collection and check that it's gone\n\n            db.dropCollection('test_collection_methods2', (err, result) => {\n              expect(result).to.be.true;\n            });\n            db.createCollection('test_collection_methods3', (err, collection) => {\n              // Verify that all the result are correct coming back (should contain the value ok)\n              expect(collection.collectionName).to.equal('test_collection_methods3');\n              db.createCollection('test_collection_methods4', (err, collection) => {\n                // Verify that all the result are correct coming back (should contain the value ok)\n                expect(collection.collectionName).to.equal('test_collection_methods4'); // Rename the collection and with the dropTarget boolean, and check to make sure only onen exists.\n\n                db.renameCollection('test_collection_methods4', 'test_collection_methods3', {\n                  dropTarget: true\n                }, err => {\n                  expect(err).to.not.exist;\n                  db.dropCollection('test_collection_methods3', (err, result) => {\n                    expect(result).to.be.true;\n                    done();\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"should correctly access collection names","suites":["Collection","standard collection tests"],"updatePoint":{"line":83,"column":48,"index":3135},"line":83,"code":"    it('should correctly access collection names', function (done) {\n      // Create two collections\n      db.createCollection('test.spiderman', () => {\n        db.createCollection('test.mario', () => {\n          // Insert test documents (creates collections)\n          const spiderman_collection = db.collection('test.spiderman');\n          spiderman_collection.insertOne({\n            foo: 5\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const mario_collection = db.collection('test.mario');\n            mario_collection.insertOne({\n              bar: 0\n            }, configuration.writeConcernMax(), err => {\n              expect(err).to.not.exist; // Assert collections\n\n              db.collections((err, collections) => {\n                expect(err).to.not.exist;\n                let found_spiderman = false;\n                let found_mario = false;\n                let found_does_not_exist = false;\n                collections.forEach(collection => {\n                  if (collection.collectionName === 'test.spiderman') {\n                    found_spiderman = true;\n                  }\n\n                  if (collection.collectionName === 'test.mario') found_mario = true;\n                  if (collection.collectionName === 'does_not_exist') found_does_not_exist = true;\n                });\n                expect(found_spiderman).to.be.true;\n                expect(found_mario).to.be.true;\n                expect(found_does_not_exist).to.be.false;\n                done();\n              });\n            });\n          });\n        });\n      });\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"should correctly retrieve listCollections","suites":["Collection","standard collection tests"],"updatePoint":{"line":122,"column":49,"index":4756},"line":122,"code":"    it('should correctly retrieve listCollections', function (done) {\n      db.createCollection('test_collection_names', err => {\n        expect(err).to.not.exist;\n        db.listCollections().toArray((err, documents) => {\n          let found = false;\n          let found2 = false;\n          documents.forEach(document => {\n            if (document.name === configuration.db + '.test_collection_names' || document.name === 'test_collection_names') found = true;\n          });\n          expect(found).to.be.true; // Insert a document in an non-existing collection should create the collection\n\n          const collection = db.collection('test_collection_names2');\n          collection.insertOne({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            db.listCollections().toArray((err, documents) => {\n              documents.forEach(document => {\n                if (document.name === configuration.db + '.test_collection_names2' || document.name === 'test_collection_names2') found = true;\n                if (document.name === configuration.db + '.test_collection_names' || document.name === 'test_collection_names') found2 = true;\n              });\n              expect(found).to.be.true;\n              expect(found2).to.be.true; // Let's close the db\n\n              done();\n            });\n          });\n        });\n      });\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"should permit insert of dot and dollar keys if requested","suites":["Collection","standard collection tests"],"updatePoint":{"line":152,"column":64,"index":6177},"line":152,"code":"    it('should permit insert of dot and dollar keys if requested', function () {\n      const collection = db.collection('test_invalid_key_names');\n      return Promise.all([collection.insertOne({\n        hel$lo: 0\n      }, {\n        checkKeys: false\n      }), collection.insertOne({\n        hello: {\n          $hello: 0\n        }\n      }, {\n        checkKeys: false\n      }), // embedded document can have a leading dollar\n      collection.insertOne({\n        'hel.lo': 0\n      }, {\n        checkKeys: false\n      }), collection.drop()]);\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"should fail due to illegal listCollections","suites":["Collection","standard collection tests"],"updatePoint":{"line":171,"column":50,"index":6710},"line":171,"code":"    it('should fail due to illegal listCollections', function (done) {\n      expect(() => db.collection(5)).to.throw('Collection name must be a String');\n      expect(() => db.collection('')).to.throw('Collection names cannot be empty');\n      expect(() => db.collection('te$t')).to.throw(\"Collection names must not contain '$'\");\n      expect(() => db.collection('.test')).to.throw(\"Collection names must not start or end with '.'\");\n      expect(() => db.collection('test.')).to.throw(\"Collection names must not start or end with '.'\");\n      expect(() => db.collection('test..t')).to.throw('Collection names cannot be empty');\n      done();\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"should correctly count on non-existent collection","suites":["Collection","standard collection tests"],"updatePoint":{"line":180,"column":57,"index":7369},"line":180,"code":"    it('should correctly count on non-existent collection', function (done) {\n      const collection = db.collection('test_multiple_insert_2');\n      collection.countDocuments((err, count) => {\n        expect(count).to.equal(0); // Let's close the db\n\n        done();\n      });\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute insert update delete safe mode","suites":["Collection","standard collection tests"],"updatePoint":{"line":188,"column":63,"index":7661},"line":188,"code":"    it('should correctly execute insert update delete safe mode', function (done) {\n      db.createCollection('test_should_execute_insert_update_delete_safe_mode', (err, collection) => {\n        expect(collection.collectionName).to.equal('test_should_execute_insert_update_delete_safe_mode');\n        collection.insertOne({\n          i: 1\n        }, configuration.writeConcernMax(), (err, r) => {\n          expect(err).to.not.exist;\n          expect(r).property('insertedId').to.exist;\n          expect(r.insertedId.toHexString()).to.have.lengthOf(24); // Update the record\n\n          collection.updateOne({\n            i: 1\n          }, {\n            $set: {\n              i: 2\n            }\n          }, configuration.writeConcernMax(), (err, r) => {\n            expect(err).to.not.exist;\n            expect(r).property('modifiedCount').to.equal(1); // Remove safely\n\n            collection.deleteOne({}, configuration.writeConcernMax(), err => {\n              expect(err).to.not.exist;\n              done();\n            });\n          });\n        });\n      });\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"should perform collection remove with no callback","suites":["Collection","standard collection tests"],"updatePoint":{"line":216,"column":57,"index":8726},"line":216,"code":"    it('should perform collection remove with no callback', function (done) {\n      const collection = db.collection('remove_with_no_callback_bug_test');\n      collection.insertOne({\n        a: 1\n      }, configuration.writeConcernMax(), err => {\n        expect(err).to.not.exist;\n        collection.insertOne({\n          b: 1\n        }, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n          collection.insertOne({\n            c: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            collection.remove({\n              a: 1\n            }, configuration.writeConcernMax(), err => {\n              expect(err).to.not.exist; // Let's perform a count\n\n              collection.countDocuments((err, count) => {\n                expect(err).to.not.exist;\n                expect(count).to.equal(2);\n                done();\n              });\n            });\n          });\n        });\n      });\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"should correctly read back document with null","suites":["Collection","standard collection tests"],"updatePoint":{"line":245,"column":53,"index":9700},"line":245,"code":"    it('should correctly read back document with null', function (done) {\n      db.createCollection('shouldCorrectlyReadBackDocumentWithNull', {}, (err, collection) => {\n        // Insert a document with a date\n        collection.insertOne({\n          test: null\n        }, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n          collection.findOne((err, result) => {\n            expect(err).to.not.exist;\n            expect(result.test).to.not.exist;\n            done();\n          });\n        });\n      });\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"should throw error due to illegal update","suites":["Collection","standard collection tests"],"updatePoint":{"line":260,"column":48,"index":10243},"line":260,"code":"    it('should throw error due to illegal update', function (done) {\n      db.createCollection('shouldThrowErrorDueToIllegalUpdate', {}, (err, coll) => {\n        expect(() => coll.update({}, null)).to.throw(/Document must be a valid JavaScript object/);\n        expect(() => coll.update(null, null)).to.throw(/Selector must be a valid JavaScript object/);\n        done();\n      });\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"should filter correctly with index during list","suites":["Collection","standard collection tests"],"updatePoint":{"line":363,"column":54,"index":13482},"line":363,"code":"    it('should filter correctly with index during list', function (done) {\n      const testCollection = 'collection_124'; // Create a collection\n\n      db.createCollection(testCollection, err => {\n        expect(err).to.not.exist; // Index name happens to be the same as collection name\n\n        db.createIndex(testCollection, 'collection_124', {\n          writeConcern: {\n            w: 1\n          }\n        }, (err, indexName) => {\n          expect(err).to.not.exist;\n          expect(indexName).to.equal('collection_124_1');\n          db.listCollections().toArray((err, documents) => {\n            expect(err).to.not.exist;\n            expect(documents.length > 1).to.be.true;\n            let found = false;\n            documents.forEach(document => {\n              if (document.name === testCollection) found = true;\n            });\n            expect(found).to.be.true;\n            done();\n          });\n        });\n      });\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"should correctly list multipleCollections","suites":["Collection","standard collection tests"],"updatePoint":{"line":389,"column":49,"index":14417},"line":389,"code":"    it('should correctly list multipleCollections', function (done) {\n      const emptyDb = client.db('listCollectionsDb');\n      emptyDb.createCollection('test1', err => {\n        expect(err).to.not.exist;\n        emptyDb.createCollection('test2', err => {\n          expect(err).to.not.exist;\n          emptyDb.createCollection('test3', err => {\n            expect(err).to.not.exist;\n            emptyDb.listCollections().toArray((err, collections) => {\n              expect(err).to.not.exist;\n              let names = [];\n\n              for (let i = 0; i < collections.length; i++) {\n                names.push(collections[i].name);\n              }\n\n              expect(names).to.include('test1');\n              expect(names).to.include('test2');\n              expect(names).to.include('test3');\n              done();\n            });\n          });\n        });\n      });\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"should correctly handle namespace when using collections method","suites":["Collection","standard collection tests"],"updatePoint":{"line":414,"column":71,"index":15321},"line":414,"code":"    it('should correctly handle namespace when using collections method', function (done) {\n      const emptyDb = client.db('listCollectionsDb2');\n      emptyDb.createCollection('test1', err => {\n        expect(err).to.not.exist;\n        emptyDb.createCollection('test.test', err => {\n          expect(err).to.not.exist;\n          emptyDb.createCollection('test3', err => {\n            expect(err).to.not.exist;\n            emptyDb.collections((err, collections) => {\n              collections = collections.map(collection => {\n                return {\n                  collectionName: collection.collectionName,\n                  namespace: collection.namespace\n                };\n              });\n              let foundCollection = false;\n              collections.forEach(x => {\n                if (x.namespace === 'listCollectionsDb2.test.test' && x.collectionName === 'test.test') {\n                  foundCollection = true;\n                }\n              });\n              expect(foundCollection).to.be.true;\n              done();\n            });\n          });\n        });\n      });\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"should provide access to the database name","suites":["Collection","standard collection tests"],"updatePoint":{"line":442,"column":50,"index":16401},"line":442,"code":"    it('should provide access to the database name', function () {\n      return client.db('test_db').createCollection('test1').then(coll => {\n        expect(coll.dbName).to.equal('test_db');\n      });\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"should correctly create TTL collection with index using createIndex","suites":["Collection","standard collection tests"],"updatePoint":{"line":447,"column":75,"index":16635},"line":447,"code":"    it('should correctly create TTL collection with index using createIndex', function (done) {\n      db.createCollection('shouldCorrectlyCreateTTLCollectionWithIndexCreateIndex', (err, collection) => {\n        const errorCallBack = err => {\n          expect(err).to.not.exist; // Insert a document with a date\n\n          collection.insertOne({\n            a: 1,\n            createdAt: new Date()\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            collection.indexInformation({\n              full: true\n            }, (err, indexes) => {\n              expect(err).to.not.exist;\n\n              for (let i = 0; i < indexes.length; i++) {\n                if (indexes[i].name === 'createdAt_1') {\n                  expect(indexes[i].expireAfterSeconds).to.equal(1);\n                  break;\n                }\n              }\n\n              done();\n            });\n          });\n        };\n\n        collection.createIndex({\n          createdAt: 1\n        }, {\n          expireAfterSeconds: 1,\n          writeConcern: {\n            w: 1\n          }\n        }, errorCallBack);\n      });\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"should support createIndex with no options","suites":["Collection","standard collection tests"],"updatePoint":{"line":484,"column":50,"index":17752},"line":484,"code":"    it('should support createIndex with no options', function (done) {\n      db.createCollection('create_index_without_options', {}, (err, collection) => {\n        collection.createIndex({\n          createdAt: 1\n        }, err => {\n          expect(err).to.not.exist;\n          collection.indexInformation({\n            full: true\n          }, (err, indexes) => {\n            expect(err).to.not.exist;\n            const indexNames = indexes.map(i => i.name);\n            expect(indexNames).to.include('createdAt_1');\n            done();\n          });\n        });\n      });\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"returns the total documents in the collection","suites":["Collection","#estimatedDocumentCount"],"updatePoint":{"line":521,"column":53,"index":18827},"line":521,"code":"    it('returns the total documents in the collection', async function () {\n      const result = await collection.estimatedDocumentCount();\n      expect(result).to.equal(1);\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"returns 0","suites":["Collection","#countDocuments","when passing a non-matching query"],"updatePoint":{"line":546,"column":19,"index":19521},"line":546,"code":"      it('returns 0', async function () {\n        const result = await collection.countDocuments({\n          a: 'b'\n        });\n        expect(result).to.equal(0);\n      });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"returns a promise","suites":["Collection","#countDocuments","when no callback passed"],"updatePoint":{"line":554,"column":27,"index":19764},"line":554,"code":"      it('returns a promise', function () {\n        const docsPromise = collection.countDocuments();\n        expect(docsPromise).to.exist.and.to.be.an.instanceof(Promise);\n        return docsPromise.then(result => expect(result).to.equal(1));\n      });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"does not return a promise","suites":["Collection","#countDocuments","when a callback is passed"],"updatePoint":{"line":561,"column":35,"index":20088},"line":561,"code":"      it('does not return a promise', function (done) {\n        const notPromise = collection.countDocuments({\n          a: 1\n        }, () => {\n          expect(notPromise).to.be.undefined;\n          done();\n        });\n      });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"calls the callback","suites":["Collection","#countDocuments","when a callback is passed"],"updatePoint":{"line":569,"column":28,"index":20312},"line":569,"code":"      it('calls the callback', function (done) {\n        const docs = [{\n          a: 1\n        }, {\n          a: 2\n        }];\n        collection.insertMany(docs).then(() => collection.countDocuments({\n          a: 1\n        }, (err, data) => {\n          expect(data).to.equal(1);\n          done(err);\n        }));\n      });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"countDocuments should return appropriate error if aggregation fails with callback given","suites":["Collection","countDocuments with mock server"],"updatePoint":{"line":625,"column":95,"index":21831},"line":625,"code":"    it('countDocuments should return appropriate error if aggregation fails with callback given', function (done) {\n      const replyHandler = () => {};\n\n      const executeCountDocuments = (collection, close) => {\n        collection.countDocuments(err => {\n          expect(err).to.exist;\n          expect(err.errmsg).to.equal('aggregation error - callback');\n          close();\n        });\n      };\n\n      testCountDocMock(configuration, {\n        replyHandler,\n        executeCountDocuments,\n        reply: {\n          ok: 0,\n          errmsg: 'aggregation error - callback'\n        }\n      }, done);\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"countDocuments should error if aggregation fails using Promises","suites":["Collection","countDocuments with mock server"],"updatePoint":{"line":645,"column":71,"index":22419},"line":645,"code":"    it('countDocuments should error if aggregation fails using Promises', function (done) {\n      const replyHandler = () => {};\n\n      const executeCountDocuments = (collection, close) => {\n        collection.countDocuments().then(() => expect(false).to.equal(true)) // should never get here; error should be caught\n        .catch(e => {\n          expect(e.errmsg).to.equal('aggregation error - promise');\n          close();\n        });\n      };\n\n      testCountDocMock(configuration, {\n        replyHandler,\n        executeCountDocuments,\n        reply: {\n          ok: 0,\n          errmsg: 'aggregation error - promise'\n        }\n      }, done);\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"countDocuments pipeline should be correct with skip and limit applied","suites":["Collection","countDocuments with mock server"],"updatePoint":{"line":665,"column":77,"index":23082},"line":665,"code":"    it('countDocuments pipeline should be correct with skip and limit applied', function (done) {\n      const replyHandler = doc => {\n        expect(doc.pipeline).to.deep.include({\n          $skip: 1\n        });\n        expect(doc.pipeline).to.deep.include({\n          $limit: 1\n        });\n      };\n\n      const executeCountDocuments = (collection, close) => {\n        collection.countDocuments({}, {\n          limit: 1,\n          skip: 1\n        }, err => {\n          expect(err).to.not.exist;\n          close();\n        });\n      };\n\n      testCountDocMock(configuration, {\n        replyHandler,\n        executeCountDocuments,\n        reply: {\n          ok: 1\n        }\n      }, done);\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"isCapped should return false for uncapped collections","suites":["Collection","countDocuments with mock server"],"updatePoint":{"line":709,"column":59,"index":24270},"line":709,"code":"  it('isCapped should return false for uncapped collections', function (done) {\n    testCapped(configuration, {\n      config: configuration,\n      collName: 'uncapped',\n      opts: {\n        capped: false\n      }\n    }, done);\n  });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"isCapped should return false for collections instantiated without specifying capped","suites":["Collection","countDocuments with mock server"],"updatePoint":{"line":718,"column":89,"index":24533},"line":718,"code":"  it('isCapped should return false for collections instantiated without specifying capped', function (done) {\n    testCapped(configuration, {\n      config: configuration,\n      collName: 'uncapped2',\n      opts: {}\n    }, done);\n  });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"should succeed with retryWrite=true when using updateMany","suites":["Collection","Retryable Writes on bulk ops"],"updatePoint":{"line":750,"column":65,"index":25427},"line":750,"code":"    it('should succeed with retryWrite=true when using updateMany', {\n      metadata,\n      test: function () {\n        return collection.updateMany({\n          name: 'foobar'\n        }, {\n          $set: {\n            name: 'fizzbuzz'\n          }\n        });\n      }\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"should succeed with retryWrite=true when using update with multi=true","suites":["Collection","Retryable Writes on bulk ops"],"updatePoint":{"line":762,"column":77,"index":25715},"line":762,"code":"    it('should succeed with retryWrite=true when using update with multi=true', {\n      metadata,\n      test: function () {\n        return collection.updateOne({\n          name: 'foobar'\n        }, {\n          $set: {\n            name: 'fizzbuzz'\n          }\n        }, {\n          multi: true\n        });\n      }\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"should succeed with retryWrite=true when using remove without option single","suites":["Collection","Retryable Writes on bulk ops"],"updatePoint":{"line":776,"column":83,"index":26043},"line":776,"code":"    it('should succeed with retryWrite=true when using remove without option single', {\n      metadata,\n      test: function () {\n        return collection.deleteOne({\n          name: 'foobar'\n        });\n      }\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"should succeed with retryWrite=true when using deleteMany","suites":["Collection","Retryable Writes on bulk ops"],"updatePoint":{"line":784,"column":65,"index":26246},"line":784,"code":"    it('should succeed with retryWrite=true when using deleteMany', {\n      metadata,\n      test: function () {\n        return collection.deleteMany({\n          name: 'foobar'\n        });\n      }\n    });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"should allow an empty replacement document for findOneAndReplace","suites":["Collection","Retryable Writes on bulk ops"],"updatePoint":{"line":793,"column":70,"index":26461},"line":793,"code":"  it('should allow an empty replacement document for findOneAndReplace', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0.0'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient({\n        w: 1\n      });\n\n      let finish = err => {\n        finish = () => {};\n\n        client.close(_err => done(err || _err));\n      };\n\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        const db = client.db(configuration.db);\n        const collection = db.collection('find_one_and_replace');\n        collection.insertOne({\n          a: 1\n        }, err => {\n          expect(err).to.not.exist;\n\n          try {\n            collection.findOneAndReplace({\n              a: 1\n            }, {}, finish);\n          } catch (e) {\n            finish(e);\n          }\n        });\n      });\n    }\n  });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"should correctly update with pipeline","suites":["Collection","Retryable Writes on bulk ops"],"updatePoint":{"line":831,"column":43,"index":27337},"line":831,"code":"  it('should correctly update with pipeline', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.2.0'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        const db = client.db(configuration.db);\n        db.createCollection('test_should_correctly_do_update_with_pipeline', (err, collection) => {\n          collection.updateOne({}, [{\n            $set: {\n              a: 1\n            }\n          }, {\n            $set: {\n              b: 1\n            }\n          }, {\n            $set: {\n              d: 1\n            }\n          }], configuration.writeConcernMax(), (err, r) => {\n            expect(err).to.not.exist;\n            expect(r).property('matchedCount').to.equal(0);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/collection-management/collection.test.js","skipped":false,"dir":"test"},{"name":"Should correctly createCollection using Promise","suites":["Collection Management and Db Management (promise tests)"],"updatePoint":{"line":15,"column":53,"index":379},"line":15,"code":"  it('Should correctly createCollection using Promise', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({}, {\n      maxPoolSize: 5\n    });\n    client.connect().then(function (client) {\n      client.db(configuration.db).createCollection('promiseCollection').then(function (col) {\n        test.ok(col != null);\n        client.close(done);\n      }).catch(function (err) {\n        test.ok(err != null);\n      });\n    });\n  });","file":"integration/collection-management/promise_collection_db_management.test.js","skipped":false,"dir":"test"},{"name":"Should correctly rename and drop collection using Promise","suites":["Collection Management and Db Management (promise tests)"],"updatePoint":{"line":29,"column":63,"index":871},"line":29,"code":"  it('Should correctly rename and drop collection using Promise', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({}, {\n      maxPoolSize: 5\n    });\n    client.connect().then(function (client) {\n      const db = client.db(configuration.db);\n      db.createCollection('promiseCollection1').then(function (col) {\n        test.ok(col != null);\n        const db = client.db(configuration.db);\n        db.renameCollection('promiseCollection1', 'promiseCollection2').then(function (col) {\n          test.ok(col != null);\n          db.dropCollection('promiseCollection2').then(function (r) {\n            test.ok(r);\n            client.close(done);\n          });\n        });\n      });\n    });\n  });","file":"integration/collection-management/promise_collection_db_management.test.js","skipped":false,"dir":"test"},{"name":"Should correctly drop database using Promise","suites":["Collection Management and Db Management (promise tests)"],"updatePoint":{"line":49,"column":50,"index":1608},"line":49,"code":"  it('Should correctly drop database using Promise', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({}, {\n      maxPoolSize: 5\n    });\n    client.connect().then(function (client) {\n      client.db(configuration.db).dropDatabase().then(function (r) {\n        test.ok(r);\n        client.close(done);\n      }).catch(function (e) {\n        test.ok(e != null);\n      });\n    });\n  });","file":"integration/collection-management/promise_collection_db_management.test.js","skipped":false,"dir":"test"},{"name":"Should correctly createCollections and call collections with Promise","suites":["Collection Management and Db Management (promise tests)"],"updatePoint":{"line":63,"column":74,"index":2072},"line":63,"code":"  it('Should correctly createCollections and call collections with Promise', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({}, {\n      maxPoolSize: 5\n    });\n    client.connect().then(function (client) {\n      const db = client.db(configuration.db);\n      db.createCollection('promiseCollectionCollections1').then(function (col) {\n        test.ok(col != null);\n        db.createCollection('promiseCollectionCollections2').then(function (col) {\n          test.ok(col != null);\n          db.collections().then(function (r) {\n            test.ok(Array.isArray(r));\n            client.close(done);\n          });\n        });\n      });\n    });\n  });","file":"integration/collection-management/promise_collection_db_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly receive the APM events for an insert","suites":["APM"],"updatePoint":{"line":21,"column":59,"index":382},"line":21,"code":"  it('should correctly receive the APM events for an insert', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      client.on('commandStarted', filterForCommands('insert', started));\n      client.on('commandSucceeded', filterForCommands('insert', succeeded));\n      return client.connect().then(client => client.db(this.configuration.db).collection('apm_test').insertOne({\n        a: 1\n      })).then(r => {\n        expect(r).property('insertedId').to.exist;\n        expect(started.length).to.equal(1);\n        expect(started[0].commandName).to.equal('insert');\n        expect(started[0].command.insert).to.equal('apm_test');\n        expect(succeeded.length).to.equal(1);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.js","skipped":false,"dir":"test"},{"name":"should correctly handle cursor.close when no cursor existed","suites":["APM"],"updatePoint":{"line":52,"column":65,"index":1424},"line":52,"code":"  it('should correctly handle cursor.close when no cursor existed', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const started = [];\n      const succeeded = [];\n      const self = this;\n      const client = this.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      client.on('commandStarted', filterForCommands('insert', started));\n      client.on('commandSucceeded', filterForCommands('insert', succeeded));\n      return client.connect().then(client => {\n        const db = client.db(self.configuration.db);\n        const collection = db.collection('apm_test_cursor');\n        return collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }]).then(r => {\n          expect(r).property('insertedCount').to.equal(3);\n          const cursor = collection.find({});\n          return cursor.count().then(() => {\n            cursor.close(); // <-- Will cause error in APM module.\n\n            return client.close();\n          });\n        });\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.js","skipped":false,"dir":"test"},{"name":"should correctly receive the APM events for a listCollections command","suites":["APM"],"updatePoint":{"line":93,"column":75,"index":2622},"line":93,"code":"  it('should correctly receive the APM events for a listCollections command', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.0.0'\n      }\n    },\n    test: function () {\n      const self = this;\n      const started = [];\n      const succeeded = [];\n      const client = self.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      client.on('commandStarted', filterForCommands('listCollections', started));\n      client.on('commandSucceeded', filterForCommands('listCollections', succeeded));\n      return client.connect().then(client => {\n        const db = client.db(self.configuration.db);\n        return db.collection('apm_test_list_collections').insertOne({\n          a: 1\n        }, self.configuration.writeConcernMax()).then(r => {\n          expect(r).property('insertedId').to.exist;\n          return db.listCollections({}, {\n            readPreference: ReadPreference.primary\n          }).toArray();\n        }).then(() => db.listCollections({}, {\n          readPreference: ReadPreference.secondary\n        }).toArray()).then(() => {\n          expect(started).to.have.lengthOf(2);\n          expect(started[0]).property('address').to.not.equal(started[1].address);\n          return client.close();\n        });\n      }).catch(err => expect(err).to.not.exist);\n    }\n  }); // NODE-3308","file":"integration/command-monitoring/command_monitoring.test.js","skipped":false,"dir":"test"},{"name":"should correctly receive the APM events for a listIndexes command","suites":["APM"],"line":134,"code":"  it.skip('should correctly receive the APM events for a listIndexes command', {","file":"integration/command-monitoring/command_monitoring.test.js","skipped":true,"dir":"test"},{"name":"should correctly receive the APM events for a find with getmore and killcursor","suites":["APM"],"updatePoint":{"line":175,"column":84,"index":5556},"line":175,"code":"  it('should correctly receive the APM events for a find with getmore and killcursor', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const self = this;\n      const started = [];\n      const succeeded = [];\n      const failed = [];\n      const client = self.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['find', 'getMore', 'killCursors'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      client.on('commandFailed', filterForCommands(desiredEvents, failed));\n      return client.connect().then(client => {\n        const db = client.db(self.configuration.db); // Drop the collection\n\n        return db.collection('apm_test_2').drop().catch(ignoreNsNotFound).then(() => {\n          // Insert test documents\n          return db.collection('apm_test_2').insertMany([{\n            a: 1\n          }, {\n            a: 1\n          }, {\n            a: 1\n          }, {\n            a: 1\n          }, {\n            a: 1\n          }, {\n            a: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(r => {\n          expect(r).property('insertedCount').to.equal(6);\n          return db.collection('apm_test_2').find({\n            a: 1\n          }).project({\n            _id: 1,\n            a: 1\n          }).hint({\n            _id: 1\n          }).skip(1).limit(100).batchSize(2).comment('some comment').maxTimeMS(5000).withReadPreference(ReadPreference.PRIMARY).addCursorFlag('noCursorTimeout', true).toArray();\n        }).then(docs => {\n          // Assert basic documents\n          expect(docs).to.have.length(5);\n          expect(started).to.have.length(3);\n          expect(succeeded).to.have.length(3);\n          expect(failed).to.have.length(0); // Success messages\n\n          expect(succeeded[0].reply).to.not.be.null;\n          expect(succeeded[0].operationId).to.equal(succeeded[1].operationId);\n          expect(succeeded[0].operationId).to.equal(succeeded[2].operationId);\n          expect(succeeded[1].reply).to.not.be.null;\n          expect(succeeded[2].reply).to.not.be.null; // Started\n\n          expect(started[0].operationId).to.equal(started[1].operationId);\n          expect(started[0].operationId).to.equal(started[2].operationId);\n          return client.close();\n        });\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.js","skipped":false,"dir":"test"},{"name":"should correctly receive the APM failure event for find","suites":["APM"],"updatePoint":{"line":250,"column":61,"index":8126},"line":250,"code":"  it('should correctly receive the APM failure event for find', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset'],\n        mongodb: '>=2.6.0'\n      }\n    },\n    test: function () {\n      const self = this;\n      const started = [];\n      const succeeded = [];\n      const failed = [];\n      const client = self.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['find', 'getMore', 'killCursors'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      client.on('commandFailed', filterForCommands(desiredEvents, failed));\n      return client.connect().then(client => {\n        const db = client.db(self.configuration.db); // Drop the collection\n\n        return db.collection('apm_test_2').drop().catch(ignoreNsNotFound).then(() => {\n          // Insert test documents\n          return db.collection('apm_test_2').insertMany([{\n            a: 1\n          }, {\n            a: 1\n          }, {\n            a: 1\n          }, {\n            a: 1\n          }, {\n            a: 1\n          }, {\n            a: 1\n          }]);\n        }).then(r => {\n          expect(r).property('insertedCount').to.equal(6);\n          return db.collection('apm_test_2').find({\n            $illegalfield: 1\n          }).project({\n            _id: 1,\n            a: 1\n          }).hint({\n            _id: 1\n          }).skip(1).limit(100).batchSize(2).comment('some comment').maxTimeMS(5000).withReadPreference(ReadPreference.PRIMARY).addCursorFlag('noCursorTimeout', true).toArray();\n        }).then(() => {\n          throw new Error('this should not happen');\n        }).catch(() => {\n          expect(failed).to.have.length(1);\n          return client.close();\n        });\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.js","skipped":false,"dir":"test"},{"name":"should correctly receive the APM events for a bulk operation","suites":["APM"],"updatePoint":{"line":311,"column":66,"index":10071},"line":311,"code":"  it('should correctly receive the APM events for a bulk operation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const self = this;\n      const started = [];\n      const succeeded = [];\n      const client = self.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['insert', 'update', 'delete'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      return client.connect().then(client => {\n        const db = client.db(self.configuration.db);\n        return db.collection('apm_test_3').bulkWrite([{\n          insertOne: {\n            document: {\n              a: 1\n            }\n          }\n        }, {\n          updateOne: {\n            filter: {\n              a: 2\n            },\n            update: {\n              $set: {\n                a: 2\n              }\n            },\n            upsert: true\n          }\n        }, {\n          deleteOne: {\n            filter: {\n              c: 1\n            }\n          }\n        }], {\n          ordered: true\n        }).then(() => {\n          expect(started).to.have.length(3);\n          expect(succeeded).to.have.length(3);\n          expect(started[0].operationId).to.equal(started[1].operationId);\n          expect(started[0].operationId).to.equal(started[2].operationId);\n          expect(succeeded[0].operationId).to.equal(succeeded[1].operationId);\n          expect(succeeded[0].operationId).to.equal(succeeded[2].operationId);\n          return client.close();\n        });\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.js","skipped":false,"dir":"test"},{"name":"should correctly receive the APM explain command","suites":["APM"],"updatePoint":{"line":372,"column":54,"index":11826},"line":372,"code":"  it('should correctly receive the APM explain command', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const self = this;\n      const started = [];\n      const succeeded = [];\n      const failed = [];\n      const client = self.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['find', 'getMore', 'killCursors', 'explain'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      client.on('commandFailed', filterForCommands(desiredEvents, failed));\n      return client.connect().then(client => {\n        const db = client.db(self.configuration.db);\n        return db.collection('apm_test_2').drop().catch(ignoreNsNotFound).then(() => db.collection('apm_test_2').insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        })).then(r => {\n          expect(r).property('insertedCount').to.equal(6);\n          return db.collection('apm_test_2').find({\n            a: 1\n          }).explain();\n        }).then(explain => {\n          expect(explain).to.not.be.null;\n          expect(started).to.have.length(1);\n          expect(started[0].commandName).to.equal('explain');\n          expect(started[0].command.explain.find).to.equal('apm_test_2');\n          expect(succeeded).to.have.length(1);\n          expect(succeeded[0].commandName).to.equal('explain');\n          expect(started[0].operationId).to.equal(succeeded[0].operationId);\n          return client.close();\n        });\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.js","skipped":false,"dir":"test"},{"name":"should correctly filter out sensitive commands","suites":["APM"],"updatePoint":{"line":431,"column":52,"index":13724},"line":431,"code":"  it('should correctly filter out sensitive commands', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const self = this;\n      const started = [];\n      const succeeded = [];\n      const failed = [];\n      const client = self.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['getnonce'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      client.on('commandFailed', filterForCommands(desiredEvents, failed));\n      return client.connect().then(client => client.db(self.configuration.db).command({\n        getnonce: true\n      })).then(r => {\n        expect(r).to.exist;\n        expect(started).to.have.length(1);\n        expect(succeeded).to.have.length(1);\n        expect(failed).to.have.length(0);\n        expect(started[0].command).to.eql({});\n        expect(succeeded[0].reply).to.eql({});\n        return client.close();\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.js","skipped":false,"dir":"test"},{"name":"should correctly receive the APM events for an updateOne","suites":["APM"],"updatePoint":{"line":467,"column":62,"index":14903},"line":467,"code":"  it('should correctly receive the APM events for an updateOne', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const self = this;\n      const started = [];\n      const succeeded = [];\n      const client = self.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['update'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      return client.connect().then(client => client.db(self.configuration.db).collection('apm_test_u_1').updateOne({\n        a: 1\n      }, {\n        $set: {\n          b: 1\n        }\n      }, {\n        upsert: true\n      })).then(r => {\n        expect(r).to.exist;\n        expect(started).to.have.length(1);\n        expect(started[0].commandName).to.equal('update');\n        expect(started[0].command.update).to.equal('apm_test_u_1');\n        expect(succeeded).to.have.length(1);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.js","skipped":false,"dir":"test"},{"name":"should correctly receive the APM events for an updateMany","suites":["APM"],"updatePoint":{"line":506,"column":63,"index":16074},"line":506,"code":"  it('should correctly receive the APM events for an updateMany', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const self = this;\n      const started = [];\n      const succeeded = [];\n      const client = self.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['update'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      return client.connect().then(client => client.db(self.configuration.db).collection('apm_test_u_2').updateMany({\n        a: 1\n      }, {\n        $set: {\n          b: 1\n        }\n      }, {\n        upsert: true\n      })).then(r => {\n        expect(r).to.exist;\n        expect(started).to.have.length(1);\n        expect(started[0].commandName).to.equal('update');\n        expect(started[0].command.update).to.equal('apm_test_u_2');\n        expect(succeeded).to.have.length(1);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.js","skipped":false,"dir":"test"},{"name":"should correctly receive the APM events for deleteOne","suites":["APM"],"updatePoint":{"line":545,"column":59,"index":17242},"line":545,"code":"  it('should correctly receive the APM events for deleteOne', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      const self = this;\n      const started = [];\n      const succeeded = [];\n      const client = self.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['delete'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      return client.connect().then(client => client.db(self.configuration.db).collection('apm_test_u_3').deleteOne({\n        a: 1\n      })).then(r => {\n        expect(r).to.exist;\n        expect(started).to.have.length(1);\n        expect(started[0].commandName).to.equal('delete');\n        expect(started[0].command.delete).to.equal('apm_test_u_3');\n        expect(succeeded).to.have.length(1);\n        return client.close();\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.js","skipped":false,"dir":"test"},{"name":"should ensure killcursor commands are sent on 3.0 or earlier when APM is enabled","suites":["APM"],"updatePoint":{"line":578,"column":86,"index":18352},"line":578,"code":"  it('should ensure killcursor commands are sent on 3.0 or earlier when APM is enabled', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset'],\n        mongodb: '<=3.0.x'\n      }\n    },\n    test: function () {\n      const self = this;\n      const client = self.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      return client.connect().then(client => {\n        const db = client.db(self.configuration.db);\n        const admindb = db.admin();\n        let cursorCountBefore;\n        let cursorCountAfter;\n        const collection = db.collection('apm_killcursor_tests'); // make sure collection has records (more than 2)\n\n        return collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }]).then(r => {\n          expect(r).to.exist;\n          return admindb.serverStatus();\n        }).then(result => {\n          cursorCountBefore = result.cursors.clientCursors_size;\n          let cursor = collection.find({}).limit(2);\n          return cursor.toArray().then(r => {\n            expect(r).to.exist;\n            return cursor.close();\n          });\n        }).then(() => admindb.serverStatus()).then(result => {\n          cursorCountAfter = result.cursors.clientCursors_size;\n          expect(cursorCountBefore).to.equal(cursorCountAfter);\n          return client.close();\n        });\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.js","skipped":false,"dir":"test"},{"name":"should correctly decorate the apm result for aggregation with cursorId","suites":["APM"],"updatePoint":{"line":626,"column":76,"index":19829},"line":626,"code":"  it('should correctly decorate the apm result for aggregation with cursorId', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset'],\n        mongodb: '>=3.0.0'\n      }\n    },\n    test: function () {\n      const self = this;\n      const started = [];\n      const succeeded = []; // Generate docs\n\n      const docs = [];\n\n      for (let i = 0; i < 2500; i++) docs.push({\n        a: i\n      });\n\n      const client = self.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['aggregate', 'getMore'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      return client.connect().then(() => {\n        const db = client.db(self.configuration.db);\n        return db.collection('apm_test_u_4').drop().catch(ignoreNsNotFound).then(() => db.collection('apm_test_u_4').insertMany(docs)).then(r => {\n          expect(r).to.exist;\n          return db.collection('apm_test_u_4').aggregate([{\n            $match: {}\n          }]).toArray();\n        }).then(r => {\n          expect(r).to.exist;\n          expect(started).to.have.length(4);\n          expect(succeeded).to.have.length(4);\n          const cursors = succeeded.map(x => x.reply.cursor); // Check we have a cursor\n\n          expect(cursors[0].id).to.exist;\n          expect(cursors[0].id.toString()).to.equal(cursors[1].id.toString());\n          expect(cursors[3].id.toString()).to.equal('0');\n          return client.close();\n        });\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.js","skipped":false,"dir":"test"},{"name":"should correctly decorate the apm result for listCollections with cursorId","suites":["APM"],"updatePoint":{"line":676,"column":80,"index":21503},"line":676,"code":"  it('should correctly decorate the apm result for listCollections with cursorId', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset'],\n        mongodb: '>=3.0.0'\n      }\n    },\n    test: function () {\n      const self = this;\n      const started = [];\n      const succeeded = [];\n      const client = self.configuration.newClient({\n        writeConcern: {\n          w: 1\n        }\n      }, {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const desiredEvents = ['listCollections'];\n      client.on('commandStarted', filterForCommands(desiredEvents, started));\n      client.on('commandSucceeded', filterForCommands(desiredEvents, succeeded));\n      return client.connect().then(client => {\n        const db = client.db(self.configuration.db);\n        const promises = [];\n\n        for (let i = 0; i < 20; i++) {\n          promises.push(db.collection('_mass_collection_' + i).insertOne({\n            a: 1\n          }));\n        }\n\n        return Promise.all(promises).then(r => {\n          expect(r).to.exist;\n          return db.listCollections().batchSize(10).toArray();\n        }).then(r => {\n          expect(r).to.exist;\n          expect(started).to.have.length(1);\n          expect(succeeded).to.have.length(1);\n          const cursors = succeeded.map(x => x.reply.cursor);\n          expect(cursors[0].id).to.exist;\n          return client.close();\n        });\n      });\n    }\n  });","file":"integration/command-monitoring/command_monitoring.test.js","skipped":false,"dir":"test"},{"name":"should not allow mutation of internal state from commands returned by event monitoring","suites":["APM","Internal state references"],"updatePoint":{"line":738,"column":94,"index":23312},"line":738,"code":"    it('should not allow mutation of internal state from commands returned by event monitoring', function () {\n      const started = [];\n      const succeeded = [];\n      client.on('commandStarted', filterForCommands('insert', started));\n      client.on('commandSucceeded', filterForCommands('insert', succeeded));\n      let documentToInsert = {\n        a: {\n          b: 1\n        }\n      };\n      return client.connect().then(client => {\n        const db = client.db(this.configuration.db);\n        return db.collection('apm_test').insertOne(documentToInsert);\n      }).then(r => {\n        expect(r).to.have.property('insertedId').that.is.an('object');\n        expect(started).to.have.lengthOf(1); // Check if contents of returned document are equal to document inserted (by value)\n\n        expect(documentToInsert).to.deep.equal(started[0].command.documents[0]); // Check if the returned document is a clone of the original. This confirms that the\n        // reference is not the same.\n\n        expect(documentToInsert !== started[0].command.documents[0]).to.equal(true);\n        expect(documentToInsert.a !== started[0].command.documents[0].a).to.equal(true);\n        started[0].command.documents[0].a.b = 2;\n        expect(documentToInsert.a.b).to.equal(1);\n        expect(started[0].commandName).to.equal('insert');\n        expect(started[0].command.insert).to.equal('apm_test');\n        expect(succeeded).to.have.lengthOf(1);\n      });\n    });","file":"integration/command-monitoring/command_monitoring.test.js","skipped":false,"dir":"test"},{"name":"should execute a command against a server","suites":["Connection","Connection - functional/cmap"],"updatePoint":{"line":51,"column":49,"index":1060},"line":51,"code":"    it('should execute a command against a server', {\n      metadata: {\n        requires: {\n          apiVersion: false,\n          topology: '!load-balanced'\n        }\n      },\n      test: function (done) {\n        const connectOptions = Object.assign({\n          connectionType: Connection\n        }, this.configuration.options);\n        connect(connectOptions, (err, conn) => {\n          expect(err).to.not.exist;\n          this.defer(_done => conn.destroy(_done));\n          conn.command(ns('admin.$cmd'), {\n            [LEGACY_HELLO_COMMAND]: 1\n          }, undefined, (err, hello) => {\n            expect(err).to.not.exist;\n            expect(hello).to.exist;\n            expect(hello.ok).to.equal(1);\n            done();\n          });\n        });\n      }\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.js","skipped":false,"dir":"test"},{"name":"should emit command monitoring events","suites":["Connection","Connection - functional/cmap"],"updatePoint":{"line":76,"column":45,"index":1825},"line":76,"code":"    it('should emit command monitoring events', {\n      metadata: {\n        requires: {\n          apiVersion: false,\n          topology: '!load-balanced'\n        }\n      },\n      test: function (done) {\n        const connectOptions = Object.assign({\n          connectionType: Connection,\n          monitorCommands: true\n        }, this.configuration.options);\n        connect(connectOptions, (err, conn) => {\n          expect(err).to.not.exist;\n          this.defer(_done => conn.destroy(_done));\n          const events = [];\n          conn.on('commandStarted', event => events.push(event));\n          conn.on('commandSucceeded', event => events.push(event));\n          conn.on('commandFailed', event => events.push(event));\n          conn.command(ns('admin.$cmd'), {\n            [LEGACY_HELLO_COMMAND]: 1\n          }, undefined, (err, hello) => {\n            expect(err).to.not.exist;\n            expect(hello).to.exist;\n            expect(hello.ok).to.equal(1);\n            expect(events).to.have.length(2);\n            done();\n          });\n        });\n      }\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.js","skipped":false,"dir":"test"},{"name":"should support socket timeouts","suites":["Connection","Connection - functional/cmap"],"line":107,"code":"    it.skip('should support socket timeouts', {","file":"integration/connection-monitoring-and-pooling/connection.test.js","skipped":true,"dir":"test"},{"name":"should support calling back multiple times on exhaust commands","suites":["Connection","Connection - functional/cmap"],"updatePoint":{"line":128,"column":70,"index":3476},"line":128,"code":"    it('should support calling back multiple times on exhaust commands', {\n      metadata: {\n        requires: {\n          apiVersion: false,\n          mongodb: '>=4.2.0',\n          topology: ['single']\n        }\n      },\n      test: function (done) {\n        const namespace = ns(`${this.configuration.db}.$cmd`);\n        const connectOptions = Object.assign({\n          connectionType: Connection\n        }, this.configuration.options);\n        connect(connectOptions, (err, conn) => {\n          expect(err).to.not.exist;\n          this.defer(_done => conn.destroy(_done));\n          const documents = Array.from(Array(10000), (_, idx) => ({\n            test: Math.floor(Math.random() * idx)\n          }));\n          conn.command(namespace, {\n            drop: 'test'\n          }, undefined, () => {\n            conn.command(namespace, {\n              insert: 'test',\n              documents\n            }, undefined, (err, res) => {\n              expect(err).to.not.exist;\n              expect(res).nested.property('n').to.equal(documents.length);\n              let totalDocumentsRead = 0;\n              conn.command(namespace, {\n                find: 'test',\n                batchSize: 100\n              }, undefined, (err, result) => {\n                expect(err).to.not.exist;\n                expect(result).nested.property('cursor').to.exist;\n                const cursor = result.cursor;\n                totalDocumentsRead += cursor.firstBatch.length;\n                conn.command(namespace, {\n                  getMore: cursor.id,\n                  collection: 'test',\n                  batchSize: 100\n                }, {\n                  exhaustAllowed: true\n                }, (err, result) => {\n                  expect(err).to.not.exist;\n                  expect(result).nested.property('cursor').to.exist;\n                  const cursor = result.cursor;\n                  totalDocumentsRead += cursor.nextBatch.length;\n\n                  if (cursor.id === 0 || cursor.id.isZero()) {\n                    expect(totalDocumentsRead).to.equal(documents.length);\n                    done();\n                  }\n                });\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.js","skipped":false,"dir":"test"},{"name":"should correctly start monitoring for single server connection","suites":["Connection","Connection - functional"],"updatePoint":{"line":215,"column":70,"index":6187},"line":215,"code":"    it('should correctly start monitoring for single server connection', {\n      metadata: {\n        requires: {\n          topology: 'single',\n          os: '!win32'\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        client = configuration.newClient(`mongodb://${encodeURIComponent('/tmp/mongodb-27017.sock')}?w=1`, {\n          maxPoolSize: 1,\n          heartbeatFrequencyMS: 250\n        });\n        let isMonitoring = false;\n        client.once('serverHeartbeatStarted', event => {\n          // just to be sure we get what we expect, checking the instanceof\n          isMonitoring = event instanceof ServerHeartbeatStartedEvent;\n        });\n        client.connect().then(() => {\n          expect(isMonitoring);\n          done();\n        });\n      }\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.js","skipped":false,"dir":"test"},{"name":"should correctly connect to server using domain socket","suites":["Connection","Connection - functional"],"updatePoint":{"line":239,"column":62,"index":6991},"line":239,"code":"    it('should correctly connect to server using domain socket', {\n      metadata: {\n        requires: {\n          topology: 'single',\n          os: '!win32'\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        client = configuration.newClient(`mongodb://${encodeURIComponent('/tmp/mongodb-27017.sock')}?w=1`, {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          expect(err).to.not.exist;\n          var db = client.db(configuration.db);\n          db.collection('domainSocketCollection0').insert({\n            a: 1\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n            db.collection('domainSocketCollection0').find({\n              a: 1\n            }).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(1, items.length);\n              done();\n            });\n          });\n        });\n      }\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.js","skipped":false,"dir":"test"},{"name":"should only pass one argument (topology and not error) for topology \"open\" events","suites":["Connection","Connection - functional"],"updatePoint":{"line":273,"column":89,"index":8061},"line":273,"code":"    it('should only pass one argument (topology and not error) for topology \"open\" events', function (done) {\n      const configuration = this.configuration;\n      client = configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      });\n      client.on('topologyOpening', () => {\n        client.topology.on('open', (...args) => {\n          expect(args).to.have.lengthOf(1);\n          expect(args[0]).to.be.instanceOf(Topology);\n          done();\n        });\n      });\n      client.connect();\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.js","skipped":false,"dir":"test"},{"name":"should correctly connect to server using just events","suites":["Connection","Connection - functional"],"updatePoint":{"line":289,"column":60,"index":8551},"line":289,"code":"    it('should correctly connect to server using just events', function (done) {\n      var configuration = this.configuration;\n      client = configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      });\n      client.on('open', clientFromEvent => {\n        expect(clientFromEvent).to.be.instanceOf(MongoClient);\n        expect(clientFromEvent).to.equal(client);\n        done();\n      });\n      client.connect();\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.js","skipped":false,"dir":"test"},{"name":"should correctly connect to server using big connection pool","suites":["Connection","Connection - functional"],"updatePoint":{"line":303,"column":68,"index":9000},"line":303,"code":"    it('should correctly connect to server using big connection pool', {\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        client = configuration.newClient({\n          w: 1\n        }, {\n          maxPoolSize: 2000\n        });\n        client.on('open', function () {\n          done();\n        });\n        client.connect();\n      }\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.js","skipped":false,"dir":"test"},{"name":"test connect no options","suites":["Connection","Connection - functional"],"updatePoint":{"line":352,"column":31,"index":10308},"line":352,"code":"    it('test connect no options', {\n      metadata: {\n        requires: {\n          topology: 'single'\n        }\n      },\n      test: function (done) {\n        const configuration = this.configuration;\n        client = configuration.newClient();\n        client.connect(connectionTester(configuration, 'testConnectNoOptions', function () {\n          done();\n        }));\n      }\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.js","skipped":false,"dir":"test"},{"name":"test connect good auth","suites":["Connection","Connection - functional"],"updatePoint":{"line":366,"column":30,"index":10693},"line":366,"code":"    it('test connect good auth', {\n      metadata: {\n        requires: {\n          topology: 'single'\n        }\n      },\n      test: function (done) {\n        const configuration = this.configuration;\n        const username = 'testConnectGoodAuth';\n        const password = 'password';\n        client = configuration.newClient(); // First add a user.\n\n        client.connect(function (err, client) {\n          expect(err).to.not.exist;\n          var db = client.db(configuration.db);\n          db.addUser(username, password, function (err) {\n            expect(err).to.not.exist;\n            restOfTest();\n          });\n        });\n\n        function restOfTest() {\n          testClient = configuration.newClient(configuration.url({\n            username,\n            password\n          }));\n          testClient.connect(connectionTester(configuration, 'testConnectGoodAuth', function () {\n            done();\n          }));\n        }\n      }\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.js","skipped":false,"dir":"test"},{"name":"test connect good auth as option","suites":["Connection","Connection - functional"],"updatePoint":{"line":398,"column":40,"index":11652},"line":398,"code":"    it('test connect good auth as option', {\n      metadata: {\n        requires: {\n          topology: 'single'\n        }\n      },\n      test: function (done) {\n        const configuration = this.configuration;\n        const username = 'testConnectGoodAuthAsOption';\n        const password = 'password'; // First add a user.\n\n        client = configuration.newClient();\n        client.connect(function (err, client) {\n          expect(err).to.not.exist;\n          var db = client.db(configuration.db);\n          db.addUser(username, password, {\n            roles: ['readWrite', 'dbAdmin']\n          }, function (err) {\n            expect(err).to.not.exist;\n            restOfTest();\n          });\n        });\n\n        function restOfTest() {\n          var opts = {\n            auth: {\n              username,\n              password\n            },\n            authSource: configuration.db\n          };\n          testClient = configuration.newClient(opts);\n          testClient.connect(connectionTester(configuration, 'testConnectGoodAuthAsOption', function () {\n            done();\n          }));\n        }\n      }\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.js","skipped":false,"dir":"test"},{"name":"test connect bad auth","suites":["Connection","Connection - functional"],"updatePoint":{"line":436,"column":29,"index":12763},"line":436,"code":"    it('test connect bad auth', {\n      metadata: {\n        requires: {\n          topology: 'single'\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        client = configuration.newClient({\n          auth: {\n            username: 'slithy',\n            password: 'toves'\n          }\n        });\n        client.connect(function (err, client) {\n          expect(err).to.exist;\n          expect(client).to.not.exist;\n          done();\n        });\n      }\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.js","skipped":false,"dir":"test"},{"name":"test connect bad url","suites":["Connection","Connection - functional"],"updatePoint":{"line":457,"column":28,"index":13272},"line":457,"code":"    it('test connect bad url', {\n      metadata: {\n        requires: {\n          topology: 'single'\n        }\n      },\n      test: function () {\n        const configuration = this.configuration;\n        expect(() => configuration.newClient('mangodb://localhost:27017/test?safe=false')).to.throw();\n      }\n    });","file":"integration/connection-monitoring-and-pooling/connection.test.js","skipped":false,"dir":"test"},{"name":"should be able to connect again after close","suites":["Connection","Connection - functional"],"updatePoint":{"line":468,"column":51,"index":13609},"line":468,"code":"    it('should be able to connect again after close', withClient(function (client, done) {\n      const collection = client.db('shouldConnectAfterClose').collection('test');\n      collection.insertOne({\n        a: 1,\n        b: 2\n      }, (err, result) => {\n        expect(err).to.not.exist;\n        expect(result).to.exist;\n        client.close(err => {\n          expect(err).to.not.exist;\n          client.connect(err => {\n            expect(err).to.not.exist;\n            collection.findOne({\n              a: 1\n            }, (err, result) => {\n              expect(err).to.not.exist;\n              expect(result).to.exist;\n              expect(result).to.have.property('a', 1);\n              expect(result).to.have.property('b', 2);\n              expect(client.topology.isDestroyed()).to.be.false;\n              done();\n            });\n          });\n        });\n      });\n    }));","file":"integration/connection-monitoring-and-pooling/connection.test.js","skipped":false,"dir":"test"},{"name":"should be able to use the same connection for two different databases in a MongoClient","suites":["Multiple Databases"],"updatePoint":{"line":16,"column":92,"index":358},"line":16,"code":"  it('should be able to use the same connection for two different databases in a MongoClient', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    const second_test_database_client = configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    }); // Just create second database\n\n    client.connect(function (err, client) {\n      second_test_database_client.connect(function (err, second_test_database) {\n        const db = client.db(configuration.db); // Close second database\n\n        second_test_database.close(); // Let's grab a connection to the different db resusing our connection pools\n\n        const secondDb = client.db('integration_tests2');\n        secondDb.createCollection('same_connection_two_dbs', function (err, collection) {\n          // Insert a dummy document\n          collection.insert({\n            a: 20\n          }, {\n            safe: true\n          }, function (err) {\n            expect(err).to.not.exist; // Query it\n\n            collection.findOne({}, function (err, item) {\n              test.equal(20, item.a); // Use the other db\n\n              db.createCollection('same_connection_two_dbs', function (err, collection) {\n                expect(err).to.not.exist; // Insert a dummy document\n\n                collection.insert({\n                  b: 20\n                }, {\n                  safe: true\n                }, function (err) {\n                  expect(err).to.not.exist; // Query it\n\n                  collection.findOne({}, function (err, item) {\n                    test.equal(20, item.b);\n                    expect(err).to.not.exist;\n                    second_test_database.close(() => client.close(done));\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    });\n  });","file":"integration/connection-monitoring-and-pooling/multiple_db.test.js","skipped":false,"dir":"test"},{"name":"getMore iteration","suites":[],"updatePoint":{"line":71,"column":23,"index":2343},"line":71,"code":"  it('getMore iteration', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.2.0',\n        topology: 'replicaset'\n      }\n    },\n    test: function () {\n      return collection.insertMany([{\n        a: 1\n      }, {\n        a: 2\n      }, {\n        a: 3\n      }, {\n        a: 4\n      }, {\n        a: 5\n      }], {\n        writeConcern: {\n          w: 'majority'\n        }\n      }).then(result => expect(result.insertedCount).to.equal(5)).then(() => {\n        const cursor = collection.find({}, {\n          batchSize: 2\n        });\n        deferred.push(() => cursor.close());\n        return cursor.next().then(item => expect(item.a).to.equal(1)).then(() => cursor.next()).then(item => expect(item.a).to.equal(2)).then(() => {\n          return connectionCount(checkClient).then(initialConnectionCount => {\n            return client.db('admin').command({\n              replSetFreeze: 0\n            }, {\n              readPreference: 'secondary'\n            }).then(result => expect(result).property('info').to.equal('unfreezing')).then(() => client.db('admin').command({\n              replSetStepDown: 30,\n              force: true\n            }, {\n              readPreference: 'primary'\n            })).then(() => cursor.next()).then(item => expect(item.a).to.equal(3)).then(() => connectionCount(checkClient).then(expectPoolWasNotCleared(initialConnectionCount)));\n          });\n        });\n      });\n    }\n  });","file":"integration/connections-survive-step-down/connections_survive_step_down.prose.test.js","skipped":false,"dir":"test"},{"name":"Not Primary - Keep Connection Pool","suites":[],"updatePoint":{"line":141,"column":40,"index":4615},"line":141,"code":"  it('Not Primary - Keep Connection Pool', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.2.0',\n        topology: 'replicaset'\n      }\n    },\n    test: function () {\n      return runStepownScenario(10107, expectPoolWasNotCleared);\n    }\n  });","file":"integration/connections-survive-step-down/connections_survive_step_down.prose.test.js","skipped":false,"dir":"test"},{"name":"Not Primary - Reset Connection Pool","suites":[],"updatePoint":{"line":152,"column":41,"index":4870},"line":152,"code":"  it('Not Primary - Reset Connection Pool', {\n    metadata: {\n      requires: {\n        mongodb: '4.0.x',\n        topology: 'replicaset'\n      }\n    },\n    test: function () {\n      return runStepownScenario(10107, expectPoolWasCleared);\n    }\n  });","file":"integration/connections-survive-step-down/connections_survive_step_down.prose.test.js","skipped":false,"dir":"test"},{"name":"Shutdown in progress - Reset Connection Pool","suites":[],"updatePoint":{"line":163,"column":50,"index":5129},"line":163,"code":"  it('Shutdown in progress - Reset Connection Pool', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.0.0',\n        topology: 'replicaset'\n      }\n    },\n    test: function () {\n      return runStepownScenario(91, expectPoolWasCleared);\n    }\n  });","file":"integration/connections-survive-step-down/connections_survive_step_down.prose.test.js","skipped":false,"dir":"test"},{"name":"Interrupted at shutdown - Reset Connection Pool","suites":[],"updatePoint":{"line":174,"column":53,"index":5390},"line":174,"code":"  it('Interrupted at shutdown - Reset Connection Pool', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.0.0',\n        topology: 'replicaset'\n      }\n    },\n    test: function () {\n      return runStepownScenario(11600, expectPoolWasCleared);\n    }\n  });","file":"integration/connections-survive-step-down/connections_survive_step_down.prose.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute simple aggregation pipeline using array","suites":["Aggregation"],"updatePoint":{"line":18,"column":70,"index":373},"line":18,"code":"  it('should correctly execute simple aggregation pipeline using array', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n          databaseName = this.configuration.db; // LINE var MongoClient = require('mongodb').MongoClient;\n      // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n      // REPLACE this.configuration.writeConcernMax() WITH {w:1}\n      // REMOVE-LINE test.\n      // BEGIN\n\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(databaseName); // Some docs for insertion\n\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }]; // Create a collection\n\n        var collection = db.collection('shouldCorrectlyExecuteSimpleAggregationPipelineUsingArray'); // Insert the docs\n\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          expect(result).to.exist;\n          expect(err).to.not.exist; // Execute aggregate, notice the pipeline is expressed as an Array\n\n          const cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }, {\n            $sort: {\n              _id: -1\n            }\n          }]);\n          cursor.toArray(function (err, result) {\n            expect(err).to.not.exist;\n            expect(result[0]._id.tags).to.equal('good');\n            expect(result[0].authors).to.eql(['bob']);\n            expect(result[1]._id.tags).to.equal('fun');\n            expect(result[1].authors).to.eql(['bob']);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/crud/aggregation.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute db.aggregate() with $currentOp","suites":["Aggregation"],"updatePoint":{"line":104,"column":61,"index":2992},"line":104,"code":"  it('should correctly execute db.aggregate() with $currentOp', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.0.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      const client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        const db = client.db('admin');\n        const cursor = db.aggregate([{\n          $currentOp: {\n            localOps: true\n          }\n        }]);\n        cursor.toArray((err, result) => {\n          expect(err).to.not.exist;\n          const aggregateOperation = result.filter(op => op.command && op.command.aggregate)[0];\n          expect(aggregateOperation.command.aggregate).to.equal(1);\n          expect(aggregateOperation.command.pipeline).to.eql([{\n            $currentOp: {\n              localOps: true\n            }\n          }]);\n          expect(aggregateOperation.command.cursor).to.deep.equal({});\n          expect(aggregateOperation.command['$db']).to.equal('admin');\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/aggregation.test.js","skipped":false,"dir":"test"},{"name":"should fail when executing simple aggregation pipeline using arguments not an array","suites":["Aggregation"],"updatePoint":{"line":148,"column":89,"index":4388},"line":148,"code":"  it('should fail when executing simple aggregation pipeline using arguments not an array', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n          databaseName = this.configuration.db; // LINE var MongoClient = require('mongodb').MongoClient;\n      // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n      // REPLACE this.configuration.writeConcernMax() WITH {w:1}\n      // REMOVE-LINE test.\n      // BEGIN\n\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(databaseName); // Some docs for insertion\n\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }]; // Create a collection\n\n        var collection = db.collection('shouldCorrectlyExecuteSimpleAggregationPipelineUsingArguments'); // Insert the docs\n\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          expect(result).to.exist;\n          expect(err).to.not.exist; // Execute aggregate, notice the pipeline is expressed as function call parameters\n          // instead of an Array.\n\n          const cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }, {\n            $sort: {\n              _id: -1\n            }\n          }]);\n          cursor.toArray(function (err, result) {\n            expect(err).to.not.exist;\n            expect(result[0]._id.tags).to.equal('good');\n            expect(result[0].authors).to.eql(['bob']);\n            expect(result[1]._id.tags).to.equal('fun');\n            expect(result[1].authors).to.eql(['bob']);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/crud/aggregation.test.js","skipped":false,"dir":"test"},{"name":"should fail when executing simple aggregation pipeline using arguments using single object","suites":["Aggregation"],"updatePoint":{"line":242,"column":96,"index":7270},"line":242,"code":"  it('should fail when executing simple aggregation pipeline using arguments using single object', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n          databaseName = this.configuration.db; // LINE var MongoClient = require('mongodb').MongoClient;\n      // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n      // REPLACE this.configuration.writeConcernMax() WITH {w:1}\n      // REMOVE-LINE test.\n      // BEGIN\n\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(databaseName); // Some docs for insertion\n\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }]; // Create a collection\n\n        var collection = db.collection('shouldCorrectlyExecuteSimpleAggregationPipelineUsingArguments'); // Insert the docs\n\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          expect(result).to.exist;\n          expect(err).to.not.exist; // Execute aggregate, notice the pipeline is expressed as function call parameters\n          // instead of an Array.\n\n          const cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }, {\n            $sort: {\n              _id: -1\n            }\n          }]);\n          cursor.toArray(function (err, result) {\n            expect(err).to.not.exist;\n            expect(result[0]._id.tags).to.equal('good');\n            expect(result[0].authors).to.eql(['bob']);\n            expect(result[1]._id.tags).to.equal('fun');\n            expect(result[1].authors).to.eql(['bob']);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/crud/aggregation.test.js","skipped":false,"dir":"test"},{"name":"should correctly return and iterate over all the cursor results","suites":["Aggregation"],"updatePoint":{"line":336,"column":69,"index":10096},"line":336,"code":"  it('should correctly return and iterate over all the cursor results', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n          databaseName = this.configuration.db; // LINE var MongoClient = require('mongodb').MongoClient;\n      // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n      // REPLACE this.configuration.writeConcernMax() WITH {w:1}\n      // REMOVE-LINE test.\n      // BEGIN\n\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(databaseName); // Some docs for insertion\n\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }]; // Create a collection\n\n        var collection = db.collection('shouldCorrectlyDoAggWithCursorGet'); // Insert the docs\n\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          expect(err).to.not.exist;\n          expect(result).to.exist; // Execute aggregate, notice the pipeline is expressed as an Array\n\n          var cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }]); // Iterate over all the items in the cursor\n\n          cursor.toArray(function (err, result) {\n            expect(err).to.not.exist;\n            expect(result).to.exist;\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/crud/aggregation.test.js","skipped":false,"dir":"test"},{"name":"should correctly return a cursor and call explain","suites":["Aggregation"],"updatePoint":{"line":423,"column":55,"index":12576},"line":423,"code":"  it('should correctly return a cursor and call explain', {\n    metadata: {\n      requires: {\n        mongodb: '>2.5.3',\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var client = this.configuration.newClient({\n        maxPoolSize: 1\n      }),\n          databaseName = this.configuration.db; // LINE var MongoClient = require('mongodb').MongoClient;\n      // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n      // REPLACE this.configuration.writeConcernMax() WITH {w:1}\n      // REMOVE-LINE test.\n      // BEGIN\n\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(databaseName); // Some docs for insertion\n\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }]; // Create a collection\n\n        var collection = db.collection('shouldCorrectlyDoAggWithCursorGet'); // Insert the docs\n\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          expect(result).to.exist;\n          expect(err).to.not.exist; // Execute aggregate, notice the pipeline is expressed as an Array\n\n          var cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }], {\n            cursor: {\n              batchSize: 100\n            }\n          }); // Iterate over all the items in the cursor\n\n          cursor.explain(function (err, result) {\n            expect(err).to.not.exist;\n            expect(result.stages).to.have.lengthOf.at.least(1);\n            expect(result.stages[0]).to.have.property('$cursor');\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/crud/aggregation.test.js","skipped":false,"dir":"test"},{"name":"should correctly return a cursor with batchSize 1 and call next","suites":["Aggregation"],"updatePoint":{"line":511,"column":69,"index":15124},"line":511,"code":"  it('should correctly return a cursor with batchSize 1 and call next', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.5.3',\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n          databaseName = this.configuration.db; // LINE var MongoClient = require('mongodb').MongoClient;\n      // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n      // REPLACE this.configuration.writeConcernMax() WITH {w:1}\n      // REMOVE-LINE test.\n      // BEGIN\n\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(databaseName); // Some docs for insertion\n\n        const docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }]; // Create a collection\n\n        const collection = db.collection('shouldCorrectlyDoAggWithCursorGet'); // Insert the docs\n\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, (err, result) => {\n          expect(result).to.exist;\n          expect(err).to.not.exist; // Execute aggregate, notice the pipeline is expressed as an Array\n\n          const cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }, {\n            $sort: {\n              _id: -1\n            }\n          }], {\n            cursor: {\n              batchSize: 1\n            }\n          });\n          this.defer(() => cursor.close()); // Iterate over all the items in the cursor\n\n          cursor.next((err, result) => {\n            expect(err).to.not.exist;\n            expect(result._id.tags).to.equal('good');\n            expect(result.authors).to.eql(['bob']);\n            done();\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/crud/aggregation.test.js","skipped":false,"dir":"test"},{"name":"should correctly write the results out to a new collection","suites":["Aggregation"],"updatePoint":{"line":609,"column":64,"index":17899},"line":609,"code":"  it('should correctly write the results out to a new collection', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.5.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n          databaseName = this.configuration.db; // LINE var MongoClient = require('mongodb').MongoClient;\n      // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n      // REPLACE this.configuration.writeConcernMax() WITH {w:1}\n      // REMOVE-LINE test.\n      // BEGIN\n\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(databaseName); // Some docs for insertion\n\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }]; // Create a collection\n\n        var collection = db.collection('shouldCorrectlyDoAggWithCursorGet'); // Insert the docs\n\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          expect(result).to.exist;\n          expect(err).to.not.exist; // Execute aggregate, notice the pipeline is expressed as an Array\n\n          const cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }], {\n            out: 'testingOutCollectionForAggregation'\n          });\n          cursor.toArray(function (err, results) {\n            expect(err).to.not.exist;\n            expect(results).to.be.empty;\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/crud/aggregation.test.js","skipped":false,"dir":"test"},{"name":"should correctly use allowDiskUse when performing an aggregation","suites":["Aggregation"],"updatePoint":{"line":697,"column":70,"index":20462},"line":697,"code":"  it('should correctly use allowDiskUse when performing an aggregation', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.5.5',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n          databaseName = this.configuration.db; // LINE var MongoClient = require('mongodb').MongoClient;\n      // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n      // REPLACE this.configuration.writeConcernMax() WITH {w:1}\n      // REMOVE-LINE test.\n      // BEGIN\n\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(databaseName); // Some docs for insertion\n\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }]; // Create a collection\n\n        var collection = db.collection('shouldCorrectlyDoAggWithCursorGet'); // Insert the docs\n\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          expect(result).to.exist;\n          expect(err).to.not.exist; // Execute aggregate, notice the pipeline is expressed as an Array\n\n          const cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }, {\n            $sort: {\n              _id: -1\n            }\n          }], {\n            allowDiskUse: true\n          });\n          cursor.toArray(function (err, results) {\n            expect(err).to.not.exist;\n            expect(results[0]._id.tags).to.equal('good');\n            expect(results[0].authors).to.eql(['bob']);\n            expect(results[1]._id.tags).to.equal('fun');\n            expect(results[1].authors).to.eql(['bob']);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/crud/aggregation.test.js","skipped":false,"dir":"test"},{"name":"should perform a simple group aggregation","suites":["Aggregation"],"updatePoint":{"line":789,"column":47,"index":23143},"line":789,"code":"  it('should perform a simple group aggregation', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.5.5',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var databaseName = this.configuration.db;\n      var client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(databaseName); // Create a collection\n\n        var col = db.collection('shouldPerformSimpleGroupAggregation');\n        col.remove({}, function (err) {\n          expect(err).to.not.exist; // Insert a single document\n\n          col.insertMany([{\n            a: 1\n          }, {\n            a: 1\n          }, {\n            a: 1\n          }], function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(3); // Get first two documents that match the query\n\n            col.aggregate([{\n              $match: {}\n            }, {\n              $group: {\n                _id: '$a',\n                total: {\n                  $sum: '$a'\n                }\n              }\n            }]).toArray(function (err, docs) {\n              expect(err).to.not.exist;\n              expect(docs[0].total).to.equal(3);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/aggregation.test.js","skipped":false,"dir":"test"},{"name":"should correctly perform an aggregation using a collection name with dot in it","suites":["Aggregation"],"updatePoint":{"line":844,"column":84,"index":24826},"line":844,"code":"  it('should correctly perform an aggregation using a collection name with dot in it', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.5.5',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var databaseName = this.configuration.db;\n      var client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(databaseName);\n        const col = db.collection('te.st');\n        var count = 0;\n        col.insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }], function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedCount').to.equal(3);\n          const cursor = col.aggregate([{\n            $project: {\n              a: 1\n            }\n          }]);\n          cursor.toArray(function (err, docs) {\n            expect(err).to.not.exist;\n            expect(docs.length).to.be.greaterThan(0); //Using cursor - KO\n\n            col.aggregate([{\n              $project: {\n                a: 1\n              }\n            }], {\n              cursor: {\n                batchSize: 10000\n              }\n            }).forEach(function () {\n              count = count + 1;\n            }, function (err) {\n              expect(err).to.not.exist;\n              expect(count).to.be.greaterThan(0);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/aggregation.test.js","skipped":false,"dir":"test"},{"name":"should fail aggregation due to illegal cursor option and streams","suites":["Aggregation"],"updatePoint":{"line":905,"column":70,"index":26680},"line":905,"code":"  it('should fail aggregation due to illegal cursor option and streams', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.5.3',\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var databaseName = this.configuration.db;\n      var client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(databaseName); // Some docs for insertion\n\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }]; // Create a collection\n\n        var collection = db.collection('shouldCorrectlyDoAggWithCursorGetStream'); // Insert the docs\n\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          expect(result).to.exist;\n          expect(err).to.not.exist;\n\n          try {\n            // Execute aggregate, notice the pipeline is expressed as an Array\n            const cursor = collection.aggregate([{\n              $project: {\n                author: 1,\n                tags: 1\n              }\n            }, {\n              $unwind: '$tags'\n            }, {\n              $group: {\n                _id: {\n                  tags: '$tags'\n                },\n                authors: {\n                  $addToSet: '$author'\n                }\n              }\n            }], {\n              cursor: 1\n            });\n            cursor.next();\n          } catch (err) {\n            client.close(done);\n            return;\n          } // should never happen\n\n\n          expect(true).to.be.false;\n        });\n      });\n    }\n  });","file":"integration/crud/aggregation.test.js","skipped":false,"dir":"test"},{"name":"should fail if you try to use explain flag with writeConcern","suites":["Aggregation"],"updatePoint":{"line":984,"column":66,"index":28843},"line":984,"code":"  it('should fail if you try to use explain flag with writeConcern', {\n    metadata: {\n      requires: {\n        mongodb: '>3.6.0',\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var databaseName = this.configuration.db;\n      var client = this.configuration.newClient({\n        maxPoolSize: 1\n      });\n      const testCases = [{\n        writeConcern: {\n          j: true\n        }\n      }, {\n        readConcern: {\n          level: 'local'\n        },\n        writeConcern: {\n          j: true\n        }\n      }];\n      client.connect(function (err, client) {\n        const wrapup = err => {\n          client.close(err2 => done(err || err2));\n        };\n\n        const db = client.db(databaseName);\n        Promise.all(testCases.map(testCase => {\n          const stringifiedTestCase = JSON.stringify(testCase);\n          const collection = db.collection('foo');\n          Object.assign(collection.s, testCase);\n\n          try {\n            const promise = collection.aggregate([{\n              $project: {\n                _id: 0\n              }\n            }, {\n              $out: 'bar'\n            }], {\n              explain: true\n            }).toArray().then(() => {\n              throw new Error('Expected aggregation to not succeed for options ' + stringifiedTestCase);\n            }, () => {\n              throw new Error('Expected aggregation to fail on client instead of server for options ' + stringifiedTestCase);\n            });\n            return promise;\n          } catch (e) {\n            expect(e).to.exist;\n            return Promise.resolve();\n          }\n        })).then(() => wrapup(), wrapup);\n      });\n    }\n  });","file":"integration/crud/aggregation.test.js","skipped":false,"dir":"test"},{"name":"should ensure MaxTimeMS is correctly passed down into command execution when using a cursor","suites":["Aggregation"],"updatePoint":{"line":1046,"column":97,"index":30675},"line":1046,"code":"  it('should ensure MaxTimeMS is correctly passed down into command execution when using a cursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      const client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      }),\n            databaseName = this.configuration.db; // DOC_LINE var db = new Db('test', new Server('localhost', 27017));\n      // DOC_START\n\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(databaseName);\n        const docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }]; // Create a collection\n\n        const collection = db.collection('shouldCorrectlyDoAggWithCursorMaxTimeMSSet'); // Insert the docs\n\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, (err, result) => {\n          expect(result).to.exist;\n          expect(err).to.not.exist; // Execute aggregate, notice the pipeline is expressed as an Array\n\n          const cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }, {\n            $sort: {\n              _id: -1\n            }\n          }], {\n            cursor: {\n              batchSize: 1\n            },\n            maxTimeMS: 1000\n          });\n          this.defer(() => cursor.close()); // Override the db.command to validate the correct command\n          // is executed\n\n          const cmd = db.command; // Validate the command\n\n          db.command = function (c) {\n            expect(err).to.not.exist;\n            expect(c.maxTimeMS).to.equal(1000); // Apply to existing command\n\n            cmd.apply(db, Array.prototype.slice.call(arguments, 0));\n          }; // Iterate over all the items in the cursor\n\n\n          cursor.next((err, result) => {\n            expect(err).to.not.exist;\n            expect(result._id.tags).to.equal('good');\n            expect(result.authors).to.eql(['bob']); // Validate the command\n\n            db.command = function (c) {\n              expect(err).to.not.exist;\n              expect(c.maxTimeMS).to.equal(1000); // Apply to existing command\n\n              cmd.apply(db, Array.prototype.slice.call(arguments, 0));\n            }; // Execute aggregate, notice the pipeline is expressed as an Array\n\n\n            const secondCursor = collection.aggregate([{\n              $project: {\n                author: 1,\n                tags: 1\n              }\n            }, {\n              $unwind: '$tags'\n            }, {\n              $group: {\n                _id: {\n                  tags: '$tags'\n                },\n                authors: {\n                  $addToSet: '$author'\n                }\n              }\n            }], {\n              maxTimeMS: 1000\n            });\n            this.defer(() => secondCursor.close());\n            expect(secondCursor).to.exist; // Return the command\n\n            db.command = cmd;\n            done();\n          });\n        });\n      }); // DOC_END\n    }\n  });","file":"integration/crud/aggregation.test.js","skipped":false,"dir":"test"},{"name":"should pass a comment down via the aggregation command","suites":["Aggregation"],"updatePoint":{"line":1177,"column":60,"index":34486},"line":1177,"code":"  it('should pass a comment down via the aggregation command', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.5.0',\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      const client = this.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      });\n      const databaseName = this.configuration.db;\n      const comment = 'Darmok and Jalad at Tanagra';\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        const db = client.db(databaseName);\n        const collection = db.collection('testingPassingDownTheAggregationCommand');\n        const command = db.command;\n\n        db.command = function (c) {\n          expect(c).to.be.an('object');\n          expect(c.comment).to.be.a('string').and.to.equal('comment');\n          command.apply(db, Array.prototype.slice.call(arguments, 0));\n        };\n\n        const cursor = collection.aggregate([{\n          $project: {\n            _id: 1\n          }\n        }], {\n          comment\n        });\n        expect(cursor).to.not.be.null;\n        client.close(done);\n      });\n    }\n  });","file":"integration/crud/aggregation.test.js","skipped":false,"dir":"test"},{"name":"should correctly handle ISODate date matches in aggregation framework","suites":["Aggregation"],"updatePoint":{"line":1220,"column":75,"index":35750},"line":1220,"code":"  it('should correctly handle ISODate date matches in aggregation framework', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var databaseName = this.configuration.db;\n      var client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      }); // DOC_LINE var client = new MongoClient(new Server('localhost', 27017));\n      // DOC_START\n\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(databaseName);\n        var date1 = new Date();\n        date1.setHours(date1.getHours() - 1); // Some docs for insertion\n\n        var docs = [{\n          a: date1,\n          b: 1\n        }, {\n          a: new Date(),\n          b: 2\n        }]; // Create a collection\n\n        var collection = db.collection('shouldCorrectlyQueryUsingISODate'); // Insert the docs\n\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          expect(result).to.exist;\n          expect(err).to.not.exist; // Execute aggregate, notice the pipeline is expressed as an Array\n\n          var cursor = collection.aggregate([{\n            $match: {\n              a: new Date(date1.toISOString())\n            }\n          }]); // Iterate over all the items in the cursor\n\n          cursor.next(function (err, result) {\n            expect(err).to.not.exist;\n            expect(result.b).to.equal(1);\n            client.close(done);\n          });\n        });\n      }); // DOC_END\n    }\n  });","file":"integration/crud/aggregation.test.js","skipped":false,"dir":"test"},{"name":"should correctly exercise hasNext function on aggregation cursor","suites":["Aggregation"],"updatePoint":{"line":1279,"column":70,"index":37628},"line":1279,"code":"  it('should correctly exercise hasNext function on aggregation cursor', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var databaseName = this.configuration.db;\n      var client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      }); // DOC_LINE var client = new MongoClient(new Server('localhost', 27017));\n      // DOC_START\n\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(databaseName); // Create a collection\n\n        var collection = db.collection('shouldCorrectlyQueryUsingISODate3'); // Insert the docs\n\n        collection.insertMany([{\n          a: 1\n        }, {\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          expect(result).to.exist;\n          expect(err).to.not.exist; // Execute aggregate, notice the pipeline is expressed as an Array\n\n          var cursor = collection.aggregate([{\n            $match: {}\n          }]); // Iterate over all the items in the cursor\n\n          cursor.hasNext(function (err, result) {\n            expect(err).to.not.exist;\n            expect(result).to.equal(true);\n            client.close(done);\n          });\n        });\n      }); // DOC_END\n    }\n  });","file":"integration/crud/aggregation.test.js","skipped":false,"dir":"test"},{"name":"should not send a batchSize for aggregations with an out stage","suites":["Aggregation"],"updatePoint":{"line":1324,"column":68,"index":39011},"line":1324,"code":"  it('should not send a batchSize for aggregations with an out stage', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function (done) {\n      const databaseName = this.configuration.db;\n      const client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      let err;\n      let coll1;\n      let coll2;\n      const events = [];\n      client.on('commandStarted', filterForCommands(['aggregate'], events));\n      client.connect().then(() => {\n        coll1 = client.db(databaseName).collection('coll1');\n        coll2 = client.db(databaseName).collection('coll2');\n        return Promise.all([coll1.deleteMany({}), coll2.deleteMany({})]);\n      }).then(() => {\n        const docs = Array.from({\n          length: 10\n        }).map(() => ({\n          a: 1\n        }));\n        return Promise.all([coll1.insertMany(docs), client.db(databaseName).createCollection('coll2').catch(() => {})]);\n      }).then(() => {\n        return Promise.all([coll1.aggregate([{\n          $out: 'coll2'\n        }]), coll1.aggregate([{\n          $out: 'coll2'\n        }], {\n          batchSize: 0\n        }), coll1.aggregate([{\n          $out: 'coll2'\n        }], {\n          batchSize: 1\n        }), coll1.aggregate([{\n          $out: 'coll2'\n        }], {\n          batchSize: 30\n        }), coll1.aggregate([{\n          $match: {\n            a: 1\n          }\n        }, {\n          $out: 'coll2'\n        }]), coll1.aggregate([{\n          $match: {\n            a: 1\n          }\n        }, {\n          $out: 'coll2'\n        }], {\n          batchSize: 0\n        }), coll1.aggregate([{\n          $match: {\n            a: 1\n          }\n        }, {\n          $out: 'coll2'\n        }], {\n          batchSize: 1\n        }), coll1.aggregate([{\n          $match: {\n            a: 1\n          }\n        }, {\n          $out: 'coll2'\n        }], {\n          batchSize: 30\n        })].map(cursor => cursor.toArray()));\n      }).then(() => {\n        expect(events).to.be.an('array').with.a.lengthOf(8);\n        events.forEach(event => {\n          expect(event).to.have.property('commandName', 'aggregate');\n          expect(event).to.have.property('command').that.has.property('cursor').that.does.not.have.property('batchSize');\n        });\n      }).catch(_err => {\n        err = _err;\n      }).then(() => client.close()).then(() => done(err));\n    }\n  });","file":"integration/crud/aggregation.test.js","skipped":false,"dir":"test"},{"name":"should use the same session for every operation","suites":["Bulk executeOperation"],"updatePoint":{"line":12,"column":53,"index":335},"line":12,"code":"  it('should use the same session for every operation', async () => {\n    const collection = client.db().collection('bulk_execute_operation');\n    const batch = collection.initializeOrderedBulkOp();\n    const events = [];\n    client.on('commandStarted', ev => events.push(ev));\n    batch.insert({\n      a: 1\n    });\n    batch.find({\n      a: 1\n    }).update({\n      $set: {\n        b: 1\n      }\n    });\n    batch.find({\n      b: 1\n    }).deleteOne();\n    await batch.execute();\n    expect(events).to.have.lengthOf(3);\n    const sessions = events.map(ev => ev.command.lsid.id.toString('hex'));\n    expect(new Set(sessions)).to.have.property('size', 1);\n  });","file":"integration/crud/bulk_execute_operation.test.ts","skipped":false,"dir":"test"},{"name":"should throw a MongoInvalidArgument error ","suites":["Bulk","BulkOperationBase","#raw()","when called with an undefined operation"],"updatePoint":{"line":43,"column":54,"index":1013},"line":43,"code":"        it('should throw a MongoInvalidArgument error ', async function () {\n          const bulkOp = client.db('test').collection('test').initializeUnorderedBulkOp();\n          expect(() => bulkOp.raw(undefined)).to.throw(MongoInvalidArgumentError);\n          expect(() => bulkOp.raw(true)).to.throw(MongoInvalidArgumentError);\n          expect(() => bulkOp.raw(3)).to.throw(MongoInvalidArgumentError);\n        });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should throw an error with the specifc message: \"Operation must be an object with an operation key\"","suites":["Bulk","BulkOperationBase","#raw()","when called with an undefined operation"],"updatePoint":{"line":49,"column":111,"index":1486},"line":49,"code":"        it('should throw an error with the specifc message: \"Operation must be an object with an operation key\"', async function () {\n          const bulkOp = client.db('test').collection('test').initializeUnorderedBulkOp();\n          expect(() => bulkOp.raw(undefined)).to.throw(MongoInvalidArgumentError).to.match(/Operation must be an object with an operation key/);\n        });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should not throw a MongoInvalidArgument error","suites":["Bulk","BulkOperationBase","#raw()","when called with a valid operation"],"updatePoint":{"line":55,"column":57,"index":1890},"line":55,"code":"        it('should not throw a MongoInvalidArgument error', async function () {\n          try {\n            client.db('test').collection('test').initializeUnorderedBulkOp().raw({\n              insertOne: {}\n            });\n          } catch (error) {\n            expect(error).not.to.exist;\n          }\n        });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should throw a MongoInvalidArgument error","suites":["Bulk","Collection","#insertMany()","when passed an invalid docs argument"],"updatePoint":{"line":78,"column":53,"index":2598},"line":78,"code":"        it('should throw a MongoInvalidArgument error', async function () {\n          try {\n            const docs = [];\n            docs[1] = {\n              color: 'red'\n            };\n            await client.db('test').collection('test').insertMany(docs);\n            expect.fail('Expected insertMany to throw error, failed to throw error');\n          } catch (error) {\n            expect(error).to.be.instanceOf(MongoInvalidArgumentError);\n            expect(error.message).to.equal('Collection.insertMany() cannot be called with an array that has null/undefined values');\n          }\n        });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"insertMany should not throw a MongoInvalidArgument error when called with a valid operation","suites":["Bulk","Collection","#insertMany()","when passed a valid document list"],"updatePoint":{"line":93,"column":103,"index":3325},"line":93,"code":"        it('insertMany should not throw a MongoInvalidArgument error when called with a valid operation', async function () {\n          try {\n            let result = await client.db('test').collection('test').insertMany([{\n              color: 'blue'\n            }]);\n            expect(result).to.exist;\n          } catch (error) {\n            expect(error).not.to.exist;\n          }\n        });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute unordered bulk operation in promise form","suites":["Bulk","promise tests"],"updatePoint":{"line":107,"column":73,"index":3752},"line":107,"code":"    it('Should correctly execute unordered bulk operation in promise form', function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient({}, {\n        maxPoolSize: 100\n      });\n      client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        const bulk = db.collection('unordered_bulk_promise_form').initializeUnorderedBulkOp({\n          writeConcern: {\n            w: 1\n          }\n        });\n        bulk.insert({\n          a: 1\n        });\n        return bulk.execute().then(function (r) {\n          test.ok(r);\n          test.deepEqual({\n            w: 1\n          }, bulk.s.writeConcern);\n          client.close(done);\n        }).catch(done);\n      });\n    });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute ordered bulk operation in promise form","suites":["Bulk","promise tests"],"updatePoint":{"line":131,"column":71,"index":4507},"line":131,"code":"    it('Should correctly execute ordered bulk operation in promise form', function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient({}, {\n        maxPoolSize: 100\n      });\n      client.connect().then(function (client) {\n        var db = client.db(configuration.db);\n        var bulk = db.collection('unordered_bulk_promise_form').initializeOrderedBulkOp({\n          writeConcern: {\n            w: 1\n          }\n        });\n        bulk.insert({\n          a: 1\n        });\n        return bulk.execute().then(function (r) {\n          test.ok(r);\n          test.deepEqual({\n            w: 1\n          }, bulk.s.writeConcern);\n          client.close(done);\n        }).catch(done);\n      });\n    });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"Should correctly handle bulkWrite with no options","suites":["Bulk","promise tests"],"updatePoint":{"line":155,"column":57,"index":5240},"line":155,"code":"    it('Should correctly handle bulkWrite with no options', function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      let error = null;\n      let result = null;\n      client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        const col = db.collection('find_one_and_replace_with_promise_no_option');\n        return col.bulkWrite([{\n          insertOne: {\n            document: {\n              a: 1\n            }\n          }\n        }]);\n      }).then(function (r) {\n        result = r;\n      }).catch(function (err) {\n        error = err;\n      }).then(function () {\n        expect(error).to.not.exist;\n        test.ok(result != null);\n        client.close(done);\n      });\n    });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should correctly handle ordered single batch api write command error","suites":["Bulk","promise tests"],"updatePoint":{"line":192,"column":74,"index":6365},"line":192,"code":"  it('should correctly handle ordered single batch api write command error', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var col = db.collection('batch_write_ordered_ops_10'); // Add unique index on b field causing all updates to fail\n\n        col.createIndex({\n          a: 1\n        }, {\n          unique: true,\n          sparse: false\n        }, function (err) {\n          expect(err).to.not.exist;\n          var batch = col.initializeOrderedBulkOp();\n          batch.insert({\n            b: 1,\n            a: 1\n          });\n          batch.find({\n            b: 2\n          }).upsert().updateOne({\n            $set: {\n              a: 1\n            }\n          });\n          batch.insert({\n            b: 3,\n            a: 2\n          });\n          batch.execute(function (err, result) {\n            expect(err).to.exist;\n            expect(result).to.not.exist;\n            result = err.result; // Basic properties check\n\n            test.equal(1, result.nInserted);\n            test.equal(true, result.hasWriteErrors());\n            test.equal(1, result.getWriteErrorCount()); // Get the write error\n\n            var error = result.getWriteErrorAt(0);\n            test.equal(11000, error.code);\n            test.ok(error.errmsg != null); // Get the operation that caused the error\n\n            var op = error.getOperation();\n            test.equal(2, op.q.b);\n            test.equal(1, op.u['$set'].a);\n            expect(op.multi).to.not.be.true;\n            test.equal(true, op.upsert); // Get the first error\n\n            error = result.getWriteErrorAt(1);\n            expect(error).to.not.exist; // Finish up test\n\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should use arrayFilters for updateMany","suites":["Bulk","promise tests"],"updatePoint":{"line":258,"column":44,"index":8408},"line":258,"code":"  it('should use arrayFilters for updateMany', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.6.x'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient({\n        w: 1\n      });\n      client.connect((err, client) => {\n        const db = client.db(configuration.db);\n        const collection = db.collection('arrayfilterstest');\n        const docs = [{\n          a: [{\n            x: 1\n          }, {\n            x: 2\n          }]\n        }, {\n          a: [{\n            x: 3\n          }, {\n            x: 4\n          }]\n        }];\n\n        const close = e => client.close(() => done(e));\n\n        collection.insertMany(docs).then(() => collection.updateMany({}, {\n          $set: {\n            'a.$[i].x': 5\n          }\n        }, {\n          arrayFilters: [{\n            'i.x': 5\n          }]\n        }, (err, data) => {\n          expect(err).to.not.exist;\n          expect(data.matchedCount).to.equal(2);\n          close(err);\n        }));\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should ignore undefined values in unordered bulk operation if `ignoreUndefined` specified","suites":["Bulk","promise tests"],"updatePoint":{"line":304,"column":95,"index":9518},"line":304,"code":"  it('should ignore undefined values in unordered bulk operation if `ignoreUndefined` specified', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      const client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(client => {\n        const db = client.db(this.configuration.db);\n        const col = db.collection('batch_write_unordered_ops_1');\n        return col.initializeUnorderedBulkOp({\n          ignoreUndefined: true\n        }).insert({\n          a: 1,\n          b: undefined\n        }).execute().then(() => col.find({}).toArray()).then(docs => {\n          expect(docs[0]['a']).to.equal(1);\n          expect(docs[0]['b']).to.not.exist;\n        });\n      }).then(() => client.close());\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should ignore undefined values in ordered bulk operation if `ignoreUndefined` specified","suites":["Bulk","promise tests"],"updatePoint":{"line":329,"column":93,"index":10366},"line":329,"code":"  it('should ignore undefined values in ordered bulk operation if `ignoreUndefined` specified', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(client => {\n        var db = client.db(this.configuration.db);\n        var col = db.collection('batch_write_ordered_ops_3');\n        return col.initializeOrderedBulkOp({\n          ignoreUndefined: true\n        }).insert({\n          a: 1,\n          b: undefined\n        }).execute().then(() => col.find({}).toArray()).then(docs => {\n          expect(docs[0]['a']).to.equal(1);\n          expect(docs[0]['b']).to.not.exist;\n        }).then(() => client.close());\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should inherit promote long false from db during unordered bulk operation","suites":["Bulk","promise tests"],"updatePoint":{"line":354,"column":79,"index":11190},"line":354,"code":"  it('should inherit promote long false from db during unordered bulk operation', function () {\n    const client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n      promoteLongs: true\n    });\n    return withClient.call(this, client, (client, done) => {\n      const db = client.db('shouldInheritPromoteLongFalseFromDb1', {\n        promoteLongs: false\n      });\n      const coll = db.collection('test');\n      const batch = coll.initializeUnorderedBulkOp();\n      batch.insert({\n        a: Long.fromNumber(10)\n      });\n      batch.execute((err, result) => {\n        expect(err).to.not.exist;\n        expect(result).to.exist;\n        coll.findOne((err, item) => {\n          expect(err).to.not.exist;\n          expect(item.a).to.not.be.a('number');\n          expect(item.a).to.have.property('_bsontype');\n          expect(item.a._bsontype).to.be.equal('Long');\n          done();\n        });\n      });\n    });\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should inherit promote long false from collection during unordered bulk operation","suites":["Bulk","promise tests"],"updatePoint":{"line":380,"column":87,"index":12135},"line":380,"code":"  it('should inherit promote long false from collection during unordered bulk operation', withClient(function (client, done) {\n    const db = client.db('shouldInheritPromoteLongFalseFromColl1', {\n      promoteLongs: true\n    });\n    const coll = db.collection('test', {\n      promoteLongs: false\n    });\n    const batch = coll.initializeUnorderedBulkOp();\n    batch.insert({\n      a: Long.fromNumber(10)\n    });\n    batch.execute((err, result) => {\n      expect(err).to.not.exist;\n      expect(result).to.exist;\n      coll.findOne((err, item) => {\n        expect(err).to.not.exist;\n        expect(item.a).to.not.be.a('number');\n        expect(item.a).to.have.property('_bsontype');\n        expect(item.a._bsontype).to.be.equal('Long');\n        done();\n      });\n    });\n  }));","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should inherit promote long false from db during ordered bulk operation","suites":["Bulk","promise tests"],"updatePoint":{"line":403,"column":77,"index":12902},"line":403,"code":"  it('should inherit promote long false from db during ordered bulk operation', function () {\n    const client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n      promoteLongs: true\n    });\n    return withClient.call(this, client, (client, done) => {\n      const db = client.db('shouldInheritPromoteLongFalseFromDb2', {\n        promoteLongs: false\n      });\n      const coll = db.collection('test');\n      const batch = coll.initializeOrderedBulkOp();\n      batch.insert({\n        a: Long.fromNumber(10)\n      });\n      batch.execute((err, result) => {\n        expect(err).to.not.exist;\n        expect(result).to.exist;\n        coll.findOne((err, item) => {\n          expect(err).to.not.exist;\n          expect(item.a).to.not.be.a('number');\n          expect(item.a).to.have.property('_bsontype');\n          expect(item.a._bsontype).to.be.equal('Long');\n          done();\n        });\n      });\n    });\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should inherit promote long false from collection during ordered bulk operation","suites":["Bulk","promise tests"],"updatePoint":{"line":429,"column":85,"index":13843},"line":429,"code":"  it('should inherit promote long false from collection during ordered bulk operation', withClient(function (client, done) {\n    const db = client.db('shouldInheritPromoteLongFalseFromColl2', {\n      promoteLongs: true\n    });\n    const coll = db.collection('test', {\n      promoteLongs: false\n    });\n    const batch = coll.initializeOrderedBulkOp();\n    batch.insert({\n      a: Long.fromNumber(10)\n    });\n    batch.execute((err, result) => {\n      expect(err).to.not.exist;\n      expect(result).to.exist;\n      coll.findOne((err, item) => {\n        expect(err).to.not.exist;\n        expect(item.a).to.not.be.a('number');\n        expect(item.a).to.have.property('_bsontype');\n        expect(item.a._bsontype).to.be.equal('Long');\n        done();\n      });\n    });\n  }));","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should correctly handle ordered multiple batch api write command errors","suites":["Bulk","promise tests"],"updatePoint":{"line":452,"column":77,"index":14608},"line":452,"code":"  it('should correctly handle ordered multiple batch api write command errors', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var col = db.collection('batch_write_ordered_ops_2'); // Add unique index on field `a` causing all updates to fail\n\n        col.createIndex({\n          a: 1\n        }, {\n          unique: true,\n          sparse: false\n        }, function (err) {\n          expect(err).to.not.exist;\n          var batch = col.initializeOrderedBulkOp();\n          batch.insert({\n            b: 1,\n            a: 1\n          });\n          batch.find({\n            b: 2\n          }).upsert().updateOne({\n            $set: {\n              a: 1\n            }\n          });\n          batch.find({\n            b: 3\n          }).upsert().updateOne({\n            $set: {\n              a: 2\n            }\n          });\n          batch.find({\n            b: 2\n          }).upsert().updateOne({\n            $set: {\n              a: 1\n            }\n          });\n          batch.insert({\n            b: 4,\n            a: 3\n          });\n          batch.insert({\n            b: 5,\n            a: 1\n          });\n          batch.execute(function (err, result) {\n            expect(err).to.exist;\n            expect(result).to.not.exist; // Basic properties check\n\n            result = err.result;\n            test.equal(err instanceof Error, true);\n            test.equal(1, result.nInserted);\n            test.equal(true, result.hasWriteErrors());\n            test.ok(1, result.getWriteErrorCount()); // Individual error checking\n\n            var error = result.getWriteErrorAt(0);\n            test.equal(1, error.index);\n            test.equal(11000, error.code);\n            test.ok(error.errmsg != null);\n            test.equal(2, error.getOperation().q.b);\n            test.equal(1, error.getOperation().u['$set'].a);\n            expect(error.getOperation().multi).to.not.be.true;\n            test.equal(true, error.getOperation().upsert); // Finish up test\n\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should fail due to ordered document being to big","suites":["Bulk","promise tests"],"updatePoint":{"line":533,"column":54,"index":16987},"line":533,"code":"  it('should fail due to ordered document being to big', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var coll = db.collection('batch_write_ordered_ops_3'); // Set up a giant string to blow through the max message size\n\n        var hugeString = ''; // Create it bigger than 16MB\n\n        for (var i = 0; i < 1024 * 1100; i++) {\n          hugeString = hugeString + '1234567890123456';\n        } // Set up the batch\n\n\n        var batch = coll.initializeOrderedBulkOp();\n        batch.insert({\n          b: 1,\n          a: 1\n        }); // should fail on insert due to string being to big\n\n        try {\n          batch.insert({\n            string: hugeString\n          });\n          test.ok(false);\n        } catch (err) {} // eslint-disable-line\n        // Finish up test\n\n\n        client.close(done);\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should correctly split up ordered messages into more batches","suites":["Bulk","promise tests"],"updatePoint":{"line":574,"column":66,"index":18188},"line":574,"code":"  it('should correctly split up ordered messages into more batches', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var coll = db.collection('batch_write_ordered_ops_4'); // Set up a giant string to blow through the max message size\n\n        var hugeString = ''; // Create it bigger than 16MB\n\n        for (var i = 0; i < 1024 * 256; i++) {\n          hugeString = hugeString + '1234567890123456';\n        } // Insert the string a couple of times, should force split into multiple batches\n\n\n        var batch = coll.initializeOrderedBulkOp();\n        batch.insert({\n          a: 1,\n          b: hugeString\n        });\n        batch.insert({\n          a: 2,\n          b: hugeString\n        });\n        batch.insert({\n          a: 3,\n          b: hugeString\n        });\n        batch.insert({\n          a: 4,\n          b: hugeString\n        });\n        batch.insert({\n          a: 5,\n          b: hugeString\n        });\n        batch.insert({\n          a: 6,\n          b: hugeString\n        }); // Execute the operations\n\n        batch.execute(function (err, result) {\n          // Basic properties check\n          test.equal(6, result.nInserted);\n          test.equal(false, result.hasWriteErrors()); // Finish up test\n\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should Correctly Execute Ordered Batch of Write Operations with duplicate key errors on updates","suites":["Bulk","promise tests"],"updatePoint":{"line":632,"column":101,"index":19869},"line":632,"code":"  it('should Correctly Execute Ordered Batch of Write Operations with duplicate key errors on updates', async function () {\n    const db = client.db(this.configuration.db);\n    const col = db.collection('batch_write_ordered_ops_6'); // Add unique index on b field causing all updates to fail\n\n    await col.createIndex({\n      b: 1\n    }, {\n      unique: true,\n      sparse: false\n    });\n    const batch = col.initializeOrderedBulkOp(); // Add some operations to be executed in order\n\n    batch.insert({\n      a: 1\n    });\n    batch.find({\n      a: 1\n    }).update({\n      $set: {\n        b: 1\n      }\n    });\n    batch.insert({\n      b: 1\n    });\n    const thrownError = await batch.execute().catch(error => error);\n    expect(thrownError).to.instanceOf(Error); // Test basic settings\n\n    const result = thrownError.result;\n    expect(result).to.have.property('nInserted', 1);\n    expect(result).to.have.property('nMatched', 1);\n    expect(result).to.have.property('nModified').that.satisfies(v => v == null || v === 1);\n    expect(result).to.have.property('hasWriteErrors').that.is.a('function');\n    expect(result).to.have.property('getWriteErrorCount').that.is.a('function');\n    expect(result.hasWriteErrors()).to.be.true;\n    expect(result.getWriteErrorCount()).to.equal(1); // Individual error checking\n\n    const writeError = result.getWriteErrorAt(0);\n    expect(writeError).to.have.property('index', 2);\n    expect(writeError).to.have.property('code', 11000);\n    expect(writeError).to.have.property('errmsg').that.is.a('string');\n    expect(writeError.getOperation()).to.have.property('b', 1);\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should Correctly Execute Ordered Batch of Write Operations with upserts causing duplicate key errors on updates","suites":["Bulk","promise tests"],"updatePoint":{"line":675,"column":117,"index":21498},"line":675,"code":"  it('should Correctly Execute Ordered Batch of Write Operations with upserts causing duplicate key errors on updates', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var col = db.collection('batch_write_ordered_ops_7'); // Add unique index on b field causing all updates to fail\n\n        col.createIndex({\n          b: 1\n        }, {\n          unique: true,\n          sparse: false\n        }, function (err) {\n          expect(err).to.not.exist;\n          var batch = col.initializeOrderedBulkOp();\n          batch.insert({\n            a: 1\n          });\n          batch.find({\n            a: 1\n          }).update({\n            $set: {\n              b: 1\n            }\n          });\n          batch.find({\n            a: 2\n          }).upsert().update({\n            $set: {\n              b: 2\n            }\n          });\n          batch.find({\n            a: 3\n          }).upsert().update({\n            $set: {\n              b: 3\n            }\n          });\n          batch.insert({\n            b: 1\n          }); // Execute the operations\n\n          batch.execute(function (err, result) {\n            expect(err).to.exist;\n            expect(result).to.not.exist; // Test basic settings\n\n            result = err.result;\n            test.equal(1, result.nInserted);\n            test.equal(2, result.nUpserted);\n            test.equal(1, result.nMatched);\n            test.ok(1 === result.nModified || result.nModified == null);\n            test.equal(true, result.hasWriteErrors());\n            test.ok(1, result.getWriteErrorCount()); // Individual error checking\n\n            var error = result.getWriteErrorAt(0);\n            test.equal(4, error.index);\n            test.equal(11000, error.code);\n            test.ok(error.errmsg != null);\n            test.equal(1, error.getOperation().b); // Check for upserted values\n\n            var ids = result.getUpsertedIds();\n            test.equal(2, ids.length);\n            test.equal(2, ids[0].index);\n            test.ok(ids[0]._id != null);\n            test.equal(3, ids[1].index);\n            test.ok(ids[1]._id != null);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should correctly perform ordered upsert with custom _id","suites":["Bulk","promise tests"],"updatePoint":{"line":756,"column":61,"index":23964},"line":756,"code":"  it('should correctly perform ordered upsert with custom _id', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var col = db.collection('batch_write_ordered_ops_8');\n        var batch = col.initializeOrderedBulkOp(); // Add some operations to be executed in order\n\n        batch.find({\n          _id: 2\n        }).upsert().updateOne({\n          $set: {\n            b: 2\n          }\n        }); // Execute the operations\n\n        batch.execute(function (err, result) {\n          // Check state of result\n          test.equal(1, result.nUpserted);\n          test.equal(0, result.nInserted);\n          test.equal(0, result.nMatched);\n          test.ok(0 === result.nModified || result.nModified == null);\n          test.equal(0, result.nRemoved);\n          var upserts = result.getUpsertedIds();\n          test.equal(1, upserts.length);\n          test.equal(0, upserts[0].index);\n          test.equal(2, upserts[0]._id); // Finish up test\n\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should return an error when no operations in ordered batch","suites":["Bulk","promise tests"],"updatePoint":{"line":797,"column":64,"index":25331},"line":797,"code":"  it('should return an error when no operations in ordered batch', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var col = db.collection('batch_write_ordered_ops_8');\n        col.initializeOrderedBulkOp().execute(function (err) {\n          expect(err).to.be.instanceOf(MongoDriverError);\n          expect(err).to.have.property('message', 'Invalid BulkOperation, Batch cannot be empty');\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute ordered batch using w:0","suites":["Bulk","promise tests"],"updatePoint":{"line":821,"column":54,"index":26123},"line":821,"code":"  it('should correctly execute ordered batch using w:0', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var col = db.collection('batch_write_ordered_ops_9');\n        var bulk = col.initializeOrderedBulkOp();\n\n        for (var i = 0; i < 100; i++) {\n          bulk.insert({\n            a: 1\n          });\n        }\n\n        bulk.find({\n          b: 1\n        }).upsert().update({\n          b: 1\n        });\n        bulk.find({\n          c: 1\n        }).delete();\n        bulk.execute({\n          writeConcern: {\n            w: 0\n          }\n        }, function (err, result) {\n          expect(err).to.not.exist;\n          test.equal(0, result.nUpserted);\n          test.equal(0, result.nInserted);\n          test.equal(0, result.nMatched);\n          test.ok(0 === result.nModified || result.nModified == null);\n          test.equal(0, result.nRemoved);\n          test.equal(false, result.hasWriteErrors());\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should correctly handle single unordered batch API","suites":["Bulk","promise tests"],"updatePoint":{"line":868,"column":56,"index":27460},"line":868,"code":"  it('should correctly handle single unordered batch API', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var col = db.collection('batch_write_unordered_ops_legacy_1'); // Add unique index on b field causing all updates to fail\n\n        col.createIndex({\n          a: 1\n        }, {\n          unique: true,\n          sparse: false\n        }, function (err) {\n          expect(err).to.not.exist; // Initialize the unordered Batch\n\n          var batch = col.initializeUnorderedBulkOp(); // Add some operations to be executed in order\n\n          batch.insert({\n            b: 1,\n            a: 1\n          });\n          batch.find({\n            b: 2\n          }).upsert().updateOne({\n            $set: {\n              a: 1\n            }\n          });\n          batch.insert({\n            b: 3,\n            a: 2\n          }); // Execute the operations\n\n          batch.execute(function (err, result) {\n            expect(err).to.exist;\n            expect(result).to.not.exist; // Basic properties check\n\n            result = err.result;\n            test.equal(err instanceof Error, true);\n            test.equal(2, result.nInserted);\n            test.equal(0, result.nUpserted);\n            test.equal(0, result.nMatched);\n            test.ok(0 === result.nModified || result.nModified == null);\n            test.equal(true, result.hasWriteErrors());\n            test.equal(1, result.getWriteErrorCount()); // Get the first error\n\n            var error = result.getWriteErrorAt(0);\n            test.equal(11000, error.code);\n            test.ok(error.errmsg != null); // Get the operation that caused the error\n\n            var op = error.getOperation();\n            test.equal(2, op.q.b);\n            test.equal(1, op.u['$set'].a);\n            expect(op.multi).to.not.be.true;\n            test.equal(true, op.upsert); // Get the first error\n\n            error = result.getWriteErrorAt(1);\n            expect(error).to.not.exist; // Finish up test\n\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should correctly handle multiple unordered batch API","suites":["Bulk","promise tests"],"updatePoint":{"line":941,"column":58,"index":29840},"line":941,"code":"  it('should correctly handle multiple unordered batch API', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient(configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    client.connect((err, client) => {\n      const db = client.db(configuration.db);\n      const col = db.collection('batch_write_unordered_ops_legacy_2'); // Add unique index on b field causing all updates to fail\n\n      col.createIndex({\n        a: 1\n      }, {\n        unique: true,\n        sparse: false\n      }, err => {\n        expect(err).to.not.exist; // Initialize the unordered Batch\n\n        const batch = col.initializeUnorderedBulkOp({\n          useLegacyOps: true\n        }); // Add some operations to be executed in order\n\n        batch.insert({\n          b: 1,\n          a: 1\n        });\n        batch.insert({\n          b: 5,\n          a: 1\n        }); // Execute the operations\n\n        batch.execute((err, result) => {\n          expect(err).to.exist;\n          expect(result).to.not.exist; // Basic properties check\n\n          result = err.result;\n          expect(result.nInserted).to.equal(1);\n          expect(result.hasWriteErrors()).to.equal(true);\n          expect(result.getWriteErrorCount()).to.equal(1); // Go over the error\n\n          const error = result.getWriteErrorAt(0);\n          expect(error.code).to.equal(11000);\n          expect(error.errmsg).to.exist;\n          expect(error.getOperation().b).to.equal(5);\n          expect(error.getOperation().a).to.equal(1); // Finish up test\n\n          client.close(done);\n        });\n      });\n    });\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should fail due to document being to big for unordered batch","suites":["Bulk","promise tests"],"updatePoint":{"line":991,"column":66,"index":31464},"line":991,"code":"  it('should fail due to document being to big for unordered batch', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var coll = db.collection('batch_write_unordered_ops_legacy_3'); // Set up a giant string to blow through the max message size\n\n        var hugeString = ''; // Create it bigger than 16MB\n\n        for (var i = 0; i < 1024 * 1100; i++) {\n          hugeString = hugeString + '1234567890123456';\n        } // Set up the batch\n\n\n        var batch = coll.initializeUnorderedBulkOp();\n        batch.insert({\n          b: 1,\n          a: 1\n        }); // should fail on insert due to string being to big\n\n        try {\n          batch.insert({\n            string: hugeString\n          });\n          test.ok(false);\n        } catch (err) {} // eslint-disable-line\n        // Finish up test\n\n\n        client.close(done);\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should correctly split up messages into more batches for unordered batches","suites":["Bulk","promise tests"],"updatePoint":{"line":1032,"column":80,"index":32679},"line":1032,"code":"  it('should correctly split up messages into more batches for unordered batches', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var coll = db.collection('batch_write_unordered_ops_legacy_4'); // Set up a giant string to blow through the max message size\n\n        var hugeString = ''; // Create it bigger than 16MB\n\n        for (var i = 0; i < 1024 * 256; i++) {\n          hugeString = hugeString + '1234567890123456';\n        } // Insert the string a couple of times, should force split into multiple batches\n\n\n        var batch = coll.initializeUnorderedBulkOp();\n        batch.insert({\n          a: 1,\n          b: hugeString\n        });\n        batch.insert({\n          a: 2,\n          b: hugeString\n        });\n        batch.insert({\n          a: 3,\n          b: hugeString\n        });\n        batch.insert({\n          a: 4,\n          b: hugeString\n        });\n        batch.insert({\n          a: 5,\n          b: hugeString\n        });\n        batch.insert({\n          a: 6,\n          b: hugeString\n        }); // Execute the operations\n\n        batch.execute(function (err, result) {\n          // Basic properties check\n          test.equal(6, result.nInserted);\n          test.equal(false, result.hasWriteErrors()); // Finish up test\n\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should Correctly Execute Unordered Batch with duplicate key errors on updates","suites":["Bulk","promise tests"],"updatePoint":{"line":1090,"column":83,"index":34342},"line":1090,"code":"  it('should Correctly Execute Unordered Batch with duplicate key errors on updates', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var col = db.collection('batch_write_unordered_ops_legacy_6'); // Write concern\n\n        var writeConcern = self.configuration.writeConcernMax();\n        writeConcern.unique = true;\n        writeConcern.sparse = false; // Add unique index on b field causing all updates to fail\n\n        col.createIndex({\n          b: 1\n        }, writeConcern, function (err) {\n          expect(err).to.not.exist; // Initialize the unordered Batch\n\n          var batch = col.initializeUnorderedBulkOp(); // Add some operations to be executed in order\n\n          batch.insert({\n            a: 1\n          });\n          batch.find({\n            a: 1\n          }).update({\n            $set: {\n              b: 1\n            }\n          });\n          batch.insert({\n            b: 1\n          });\n          batch.insert({\n            b: 1\n          });\n          batch.insert({\n            b: 1\n          });\n          batch.insert({\n            b: 1\n          }); // Execute the operations\n\n          batch.execute(self.configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.exist;\n            expect(result).to.not.exist; // Test basic settings\n\n            result = err.result;\n            test.equal(2, result.nInserted);\n            test.equal(true, result.hasWriteErrors());\n            test.ok(result.getWriteErrorCount() === 4 || result.getWriteErrorCount() === 3); // Individual error checking\n\n            var error = result.getWriteErrorAt(0);\n            test.ok(error.code === 11000 || error.code === 11001);\n            test.ok(error.errmsg != null);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should provide descriptive error message for unordered batch with duplicate key errors on inserts","suites":["Bulk","promise tests"],"updatePoint":{"line":1157,"column":103,"index":36503},"line":1157,"code":"  it('should provide descriptive error message for unordered batch with duplicate key errors on inserts', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient(configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    client.connect((err, client) => {\n      const db = client.db(configuration.db);\n      const col = db.collection('err_batch_write_unordered_ops_legacy_6'); // Add unique index on a field causing all inserts to fail\n\n      col.createIndexes([{\n        name: 'err_batch_write_unordered_ops_legacy_6',\n        key: {\n          a: 1\n        },\n        unique: true\n      }], err => {\n        expect(err).to.not.exist; // Initialize the unordered Batch\n\n        const batch = col.initializeUnorderedBulkOp(); // Add some operations to be executed in order\n\n        batch.insert({\n          a: 1\n        });\n        batch.insert({\n          a: 1\n        }); // Execute the operations\n\n        batch.execute(configuration.writeConcernMax(), (err, result) => {\n          expect(err).to.exist;\n          expect(result).to.not.exist; // Test basic settings\n\n          result = err.result;\n          expect(result.nInserted).to.equal(1);\n          expect(result.hasWriteErrors()).to.equal(true);\n          expect(result.getWriteErrorCount() === 1).to.equal(true); // Individual error checking\n\n          const error = result.getWriteErrorAt(0);\n          expect(error.code === 11000).to.equal(true);\n          expect(error.errmsg).to.exist;\n          expect(err.message).to.equal(error.errmsg);\n          client.close(done);\n        });\n      });\n    });\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should Correctly Execute Unordered Batch of with upserts causing duplicate key errors on updates","suites":["Bulk","promise tests"],"updatePoint":{"line":1202,"column":102,"index":38132},"line":1202,"code":"  it('should Correctly Execute Unordered Batch of with upserts causing duplicate key errors on updates', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var col = db.collection('batch_write_unordered_ops_legacy_7'); // Add unique index on b field causing all updates to fail\n\n        col.createIndex({\n          b: 1\n        }, {\n          unique: true,\n          sparse: false\n        }, function (err) {\n          expect(err).to.not.exist; // Initialize the unordered Batch\n\n          var batch = col.initializeUnorderedBulkOp(); // Add some operations to be executed in order\n\n          batch.insert({\n            a: 1\n          });\n          batch.find({\n            a: 1\n          }).update({\n            $set: {\n              b: 1\n            }\n          });\n          batch.find({\n            a: 2\n          }).upsert().update({\n            $set: {\n              b: 2\n            }\n          });\n          batch.find({\n            a: 3\n          }).upsert().update({\n            $set: {\n              b: 3\n            }\n          });\n          batch.find({\n            a: 1\n          }).update({\n            $set: {\n              b: 1\n            }\n          });\n          batch.insert({\n            b: 1\n          }); // Execute the operations\n\n          batch.execute(self.configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.exist;\n            expect(result).to.not.exist; // Test basic settings\n\n            result = err.result;\n            test.equal(2, result.nInserted);\n            test.equal(2, result.nUpserted);\n            test.ok(0 === result.nModified || result.nModified == null);\n            test.equal(0, result.nRemoved);\n            test.equal(true, result.hasWriteErrors());\n            test.ok(1, result.getWriteErrorCount()); // Individual error checking\n\n            var error = result.getWriteErrorAt(0);\n            test.ok(error.code === 11000 || error.code === 11001);\n            test.ok(error.errmsg != null);\n            test.equal(1, error.getOperation().u['$set'].b); // Check for upserted values\n\n            var ids = result.getUpsertedIds();\n            test.equal(2, ids.length);\n            test.equal(2, ids[0].index);\n            test.ok(ids[0]._id != null);\n            test.equal(3, ids[1].index);\n            test.ok(ids[1]._id != null);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should correctly perform unordered upsert with custom _id","suites":["Bulk","promise tests"],"updatePoint":{"line":1291,"column":63,"index":40844},"line":1291,"code":"  it('should correctly perform unordered upsert with custom _id', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var col = db.collection('batch_write_unordered_ops_legacy_8');\n        var batch = col.initializeUnorderedBulkOp(); // Add some operations to be executed in order\n\n        batch.find({\n          _id: 2\n        }).upsert().updateOne({\n          $set: {\n            b: 2\n          }\n        }); // Execute the operations\n\n        batch.execute(self.configuration.writeConcernMax(), function (err, result) {\n          // Check state of result\n          test.equal(1, result.nUpserted);\n          test.equal(0, result.nInserted);\n          test.equal(0, result.nMatched);\n          test.ok(0 === result.nModified || result.nModified == null);\n          test.equal(0, result.nRemoved);\n          var upserts = result.getUpsertedIds();\n          test.equal(1, upserts.length);\n          test.equal(0, upserts[0].index);\n          test.equal(2, upserts[0]._id); // Finish up test\n\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should prohibit batch finds with no selector","suites":["Bulk","promise tests"],"updatePoint":{"line":1332,"column":50,"index":42235},"line":1332,"code":"  it('should prohibit batch finds with no selector', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(self.configuration.db);\n        var col = db.collection('batch_write_unordered_ops_legacy_9');\n        var unorderedBatch = col.initializeUnorderedBulkOp();\n        var orderedBatch = col.initializeOrderedBulkOp();\n\n        try {\n          unorderedBatch.find();\n          test.ok(false);\n        } catch (e) {\n          expect(e).to.match(/Bulk find operation must specify a selector/);\n        }\n\n        try {\n          orderedBatch.find();\n          test.ok(false);\n        } catch (e) {\n          expect(e).to.match(/Bulk find operation must specify a selector/);\n        }\n\n        client.close(done);\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should return an error when no operations in unordered batch","suites":["Bulk","promise tests"],"updatePoint":{"line":1368,"column":66,"index":43336},"line":1368,"code":"  it('should return an error when no operations in unordered batch', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var col = db.collection('batch_write_ordered_ops_8');\n        col.initializeUnorderedBulkOp().execute(self.configuration.writeConcernMax(), function (err) {\n          expect(err).to.be.instanceOf(MongoDriverError);\n          expect(err).to.have.property('message', 'Invalid BulkOperation, Batch cannot be empty');\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute unordered batch using w:0","suites":["Bulk","promise tests"],"updatePoint":{"line":1392,"column":56,"index":44159},"line":1392,"code":"  it('should correctly execute unordered batch using w:0', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var col = db.collection('batch_write_ordered_ops_9');\n        var bulk = col.initializeUnorderedBulkOp();\n\n        for (var i = 0; i < 100; i++) {\n          bulk.insert({\n            a: 1\n          });\n        }\n\n        bulk.find({\n          b: 1\n        }).upsert().update({\n          b: 1\n        });\n        bulk.find({\n          c: 1\n        }).delete();\n        bulk.execute({\n          writeConcern: {\n            w: 0\n          }\n        }, function (err, result) {\n          expect(err).to.not.exist;\n          test.equal(0, result.nUpserted);\n          test.equal(0, result.nInserted);\n          test.equal(0, result.nMatched);\n          test.ok(0 === result.nModified || result.nModified == null);\n          test.equal(0, result.nRemoved);\n          test.equal(false, result.hasWriteErrors());\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should provide an accessor for operations on ordered bulk ops","suites":["Bulk","promise tests"],"updatePoint":{"line":1445,"column":67,"index":45665},"line":1445,"code":"  it('should provide an accessor for operations on ordered bulk ops', function (done) {\n    var self = this;\n    var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    client.connect(function (err, client) {\n      var db = client.db(self.configuration.db);\n      var col = db.collection('bulk_get_operations_test');\n      var batch = col.initializeOrderedBulkOp();\n      batch.insert({\n        b: 1,\n        a: 1\n      });\n      batch.find({\n        b: 2\n      }).upsert().updateOne({\n        $set: {\n          a: 1\n        }\n      });\n      batch.insert({\n        b: 3,\n        a: 2\n      });\n      const batches = batch.batches;\n      expect(batches).to.have.lengthOf(3);\n      expect(batches[0].operations[0]).to.containSubset({\n        b: 1,\n        a: 1\n      });\n      expect(batches[1].operations[0]).to.containSubset({\n        q: {\n          b: 2\n        },\n        u: {\n          $set: {\n            a: 1\n          }\n        },\n        upsert: true\n      });\n      expect(batches[2].operations[0]).to.containSubset({\n        b: 3,\n        a: 2\n      });\n      client.close(done);\n    });\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should fail with w:2 and wtimeout write concern due single mongod instance ordered","suites":["Bulk","promise tests"],"updatePoint":{"line":1493,"column":88,"index":46849},"line":1493,"code":"  it('should fail with w:2 and wtimeout write concern due single mongod instance ordered', {\n    metadata: {\n      requires: {\n        topology: 'single',\n        mongodb: '>2.5.4'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var col = db.collection('batch_write_concerns_ops_1');\n        var batch = col.initializeOrderedBulkOp();\n        batch.insert({\n          a: 1\n        });\n        batch.insert({\n          a: 2\n        });\n        batch.execute({\n          writeConcern: {\n            w: 2,\n            wtimeoutMS: 1000\n          }\n        }, function (err) {\n          test.ok(err != null);\n          test.ok(err.code != null);\n          test.ok(err.errmsg != null);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should correctly handle bulk operation split for ordered bulk operation","suites":["Bulk","promise tests"],"updatePoint":{"line":1529,"column":77,"index":47826},"line":1529,"code":"  it('should correctly handle bulk operation split for ordered bulk operation', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var docs = [];\n\n        for (var i = 0; i < 5; i++) {\n          docs.push({\n            s: new Array(6000000).join('x')\n          });\n        }\n\n        db.collection('bigdocs_ordered').insertMany(docs, function (err) {\n          expect(err).to.not.exist;\n          db.collection('bigdocs_ordered').count(function (err, c) {\n            expect(err).to.not.exist;\n            test.equal(5, c);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should provide an accessor for operations on unordered bulk ops","suites":["Bulk","promise tests"],"updatePoint":{"line":1570,"column":69,"index":49054},"line":1570,"code":"  it('should provide an accessor for operations on unordered bulk ops', function (done) {\n    var self = this;\n    var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    client.connect(function (err, client) {\n      var db = client.db(self.configuration.db);\n      var col = db.collection('bulk_get_operations_test');\n      var batch = col.initializeUnorderedBulkOp();\n      batch.insert({\n        b: 1,\n        a: 1\n      });\n      batch.find({\n        b: 2\n      }).upsert().updateOne({\n        $set: {\n          a: 1\n        }\n      });\n      batch.insert({\n        b: 3,\n        a: 2\n      });\n      const batches = batch.batches;\n      expect(batches).to.have.lengthOf(2);\n      expect(batches[0].operations[0]).to.containSubset({\n        b: 1,\n        a: 1\n      });\n      expect(batches[0].operations[1]).to.containSubset({\n        b: 3,\n        a: 2\n      });\n      expect(batches[1].operations[0]).to.containSubset({\n        q: {\n          b: 2\n        },\n        u: {\n          $set: {\n            a: 1\n          }\n        },\n        upsert: true\n      });\n      client.close(done);\n    });\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should fail with w:2 and wtimeout write concern due single mongod instance unordered","suites":["Bulk","promise tests"],"updatePoint":{"line":1618,"column":90,"index":50242},"line":1618,"code":"  it('should fail with w:2 and wtimeout write concern due single mongod instance unordered', {\n    metadata: {\n      requires: {\n        topology: 'single',\n        mongodb: '>2.5.4'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var col = db.collection('batch_write_concerns_ops_1');\n        var batch = col.initializeUnorderedBulkOp();\n        batch.insert({\n          a: 1\n        });\n        batch.insert({\n          a: 2\n        });\n        batch.execute({\n          writeConcern: {\n            w: 2,\n            wtimeoutMS: 1000\n          }\n        }, function (err) {\n          test.ok(err != null);\n          test.ok(err.code != null);\n          test.ok(err.errmsg != null);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should correctly return the number of operations in the bulk","suites":["Bulk","promise tests"],"updatePoint":{"line":1654,"column":66,"index":51210},"line":1654,"code":"  it('should correctly return the number of operations in the bulk', {\n    metadata: {\n      requires: {\n        topology: 'single',\n        mongodb: '>2.5.4'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var col = db.collection('batch_write_concerns_ops_1');\n        var batch = col.initializeOrderedBulkOp();\n        batch.insert({\n          a: 1\n        });\n        batch.find({}).upsert().update({\n          $set: {\n            b: 1\n          }\n        });\n        test.equal(2, batch.length);\n        batch = col.initializeUnorderedBulkOp();\n        batch.insert({\n          a: 1\n        });\n        batch.find({}).upsert().update({\n          $set: {\n            b: 1\n          }\n        });\n        test.equal(2, batch.length);\n        client.close(done);\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should correctly split unordered bulk batch","suites":["Bulk","promise tests"],"updatePoint":{"line":1693,"column":49,"index":52223},"line":1693,"code":"  it('should correctly split unordered bulk batch', {\n    metadata: {\n      requires: {\n        topology: 'single',\n        mongodb: '>2.5.4'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var insertFirst = false;\n        var batchSize = 1000;\n        var collection = db.collection('batch_write_unordered_split_test');\n        var operation = collection.initializeUnorderedBulkOp(),\n            documents = [];\n\n        for (var i = 0; i < 10000; i++) {\n          var document = {\n            name: 'bob' + i\n          };\n          documents.push(document);\n          operation.insert(document);\n        }\n\n        operation.execute(function (err) {\n          expect(err).to.not.exist;\n          operation = collection.initializeUnorderedBulkOp();\n\n          if (insertFirst) {\n            // if you add the inserts to the batch first, it works fine.\n            insertDocuments();\n            replaceDocuments();\n          } else {\n            // if you add the updates to the batch first, it fails with the error \"insert must contain at least one document\"\n            replaceDocuments();\n            insertDocuments();\n          }\n\n          operation.execute(function (err) {\n            expect(err).to.not.exist;\n            client.close(done);\n          });\n        });\n\n        function insertDocuments() {\n          for (i = 10000; i < 10200; i++) {\n            operation.insert({\n              name: 'bob' + i\n            });\n          }\n        }\n\n        function replaceDocuments() {\n          for (var i = 0; i < batchSize; i++) {\n            operation.find({\n              _id: documents[i]._id\n            }).replaceOne({\n              name: 'joe' + i\n            });\n          }\n        }\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should correctly split ordered bulk batch","suites":["Bulk","promise tests"],"updatePoint":{"line":1761,"column":47,"index":54194},"line":1761,"code":"  it('should correctly split ordered bulk batch', {\n    metadata: {\n      requires: {\n        topology: 'single',\n        mongodb: '>2.5.4'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var insertFirst = false;\n        var batchSize = 1000;\n        var collection = db.collection('batch_write_ordered_split_test');\n        var operation = collection.initializeOrderedBulkOp(),\n            documents = [];\n\n        for (var i = 0; i < 10000; i++) {\n          var document = {\n            name: 'bob' + i\n          };\n          documents.push(document);\n          operation.insert(document);\n        }\n\n        operation.execute(function (err) {\n          expect(err).to.not.exist;\n          operation = collection.initializeOrderedBulkOp();\n\n          if (insertFirst) {\n            // if you add the inserts to the batch first, it works fine.\n            insertDocuments();\n            replaceDocuments();\n          } else {\n            // if you add the updates to the batch first, it fails with the error \"insert must contain at least one document\"\n            replaceDocuments();\n            insertDocuments();\n          }\n\n          operation.execute(function (err) {\n            expect(err).to.not.exist;\n            client.close(done);\n          });\n        });\n\n        function insertDocuments() {\n          for (i = 10000; i < 10200; i++) {\n            operation.insert({\n              name: 'bob' + i\n            });\n          }\n        }\n\n        function replaceDocuments() {\n          for (var i = 0; i < batchSize; i++) {\n            operation.find({\n              _id: documents[i]._id\n            }).replaceOne({\n              name: 'joe' + i\n            });\n          }\n        }\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should correctly handle bulk operation split for unordered bulk operation","suites":["Bulk","promise tests"],"updatePoint":{"line":1829,"column":79,"index":56191},"line":1829,"code":"  it('should correctly handle bulk operation split for unordered bulk operation', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var docs = [];\n\n        for (var i = 0; i < 5; i++) {\n          docs.push({\n            s: new Array(6000000).join('x')\n          });\n        }\n\n        db.collection('bigdocs_unordered').insertMany(docs, {\n          ordered: false\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('bigdocs_unordered').count(function (err, c) {\n            expect(err).to.not.exist;\n            test.equal(5, c);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should return an error instead of throwing when no operations are provided for ordered bulk operation execute","suites":["Bulk","promise tests"],"updatePoint":{"line":1866,"column":115,"index":57338},"line":1866,"code":"  it('should return an error instead of throwing when no operations are provided for ordered bulk operation execute', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        db.collection('doesnt_matter').insertMany([], function (err) {\n          expect(err).to.be.instanceOf(MongoDriverError);\n          expect(err).to.have.property('message', 'Invalid BulkOperation, Batch cannot be empty');\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should return an error instead of throwing when no operations are provided for unordered bulk operation execute","suites":["Bulk","promise tests"],"updatePoint":{"line":1890,"column":117,"index":58111},"line":1890,"code":"  it('should return an error instead of throwing when no operations are provided for unordered bulk operation execute', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        db.collection('doesnt_matter').insertMany([], {\n          ordered: false\n        }, function (err) {\n          expect(err).to.be.instanceOf(MongoDriverError);\n          expect(err).to.have.property('message', 'Invalid BulkOperation, Batch cannot be empty');\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should return an error instead of throwing when an empty bulk operation is submitted (with promise)","suites":["Bulk","promise tests"],"updatePoint":{"line":1916,"column":105,"index":58910},"line":1916,"code":"  it('should return an error instead of throwing when an empty bulk operation is submitted (with promise)', function () {\n    var self = this;\n    var client = self.configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    return client.connect().then(function () {\n      var db = client.db(self.configuration.db);\n      return db.collection('doesnt_matter').insertMany([]);\n    }).then(function () {\n      test.equal(false, true); // this should not happen!\n    }).catch(function (err) {\n      expect(err).to.be.instanceOf(MongoDriverError);\n      expect(err).to.have.property('message', 'Invalid BulkOperation, Batch cannot be empty');\n    }).then(function () {\n      return client.close();\n    });\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should properly account for array key size in bulk unordered inserts","suites":["Bulk","promise tests"],"updatePoint":{"line":1935,"column":74,"index":59607},"line":1935,"code":"  it('should properly account for array key size in bulk unordered inserts', function (done) {\n    const client = this.configuration.newClient();\n    const documents = new Array(20000).fill('').map(() => ({\n      arr: new Array(19).fill('aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa')\n    }));\n    let db;\n    client.connect() // NOTE: Hack to get around unrelated strange error in bulkWrites for right now.\n    .then(() => {\n      db = client.db(this.configuration.db);\n      return db.dropCollection('doesnt_matter').catch(() => {});\n    }).then(() => {\n      return db.createCollection('doesnt_matter');\n    }).then(() => {\n      const coll = db.collection('doesnt_matter');\n      coll.insertMany(documents, {\n        ordered: false\n      }, err => {\n        client.close(() => {\n          done(err);\n        });\n      });\n    });\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should properly account for array key size in bulk ordered inserts","suites":["Bulk","promise tests"],"updatePoint":{"line":1958,"column":72,"index":60438},"line":1958,"code":"  it('should properly account for array key size in bulk ordered inserts', function (done) {\n    const client = this.configuration.newClient();\n    const documents = new Array(20000).fill('').map(() => ({\n      arr: new Array(19).fill('aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa')\n    }));\n    let db;\n    client.connect() // NOTE: Hack to get around unrelated strange error in bulkWrites for right now.\n    .then(() => {\n      db = client.db(this.configuration.db);\n      return db.dropCollection('doesnt_matter').catch(() => {});\n    }).then(() => {\n      return db.createCollection('doesnt_matter');\n    }).then(() => {\n      const coll = db.collection('doesnt_matter');\n      coll.insertMany(documents, {\n        ordered: true\n      }, err => {\n        client.close(() => {\n          done(err);\n        });\n      });\n    });\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"properly accounts for bson size in bytes in bulk ordered inserts","suites":["Bulk","promise tests"],"updatePoint":{"line":1981,"column":70,"index":61266},"line":1981,"code":"  it('properly accounts for bson size in bytes in bulk ordered inserts', function () {\n    const client = this.configuration.newClient();\n    const size = MAX_BSON_SIZE / 2;\n    const largeString = crypto.randomBytes(size - 100).toString('hex');\n    const documents = [{\n      s: largeString\n    }, {\n      s: largeString\n    }];\n    let db;\n    return client.connect().then(() => {\n      db = client.db(this.configuration.db);\n      return db.dropCollection('doesnt_matter').catch(() => {});\n    }).then(() => {\n      return db.createCollection('doesnt_matter');\n    }).then(() => {\n      const coll = db.collection('doesnt_matter');\n      return coll.insertMany(documents, {\n        ordered: true\n      });\n    }).finally(() => client.close());\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"properly accounts for bson size in bytes in bulk unordered inserts","suites":["Bulk","promise tests"],"updatePoint":{"line":2003,"column":72,"index":62021},"line":2003,"code":"  it('properly accounts for bson size in bytes in bulk unordered inserts', function () {\n    const client = this.configuration.newClient();\n    const size = MAX_BSON_SIZE / 2;\n    const largeString = crypto.randomBytes(size - 100).toString('hex');\n    const documents = [{\n      s: largeString\n    }, {\n      s: largeString\n    }];\n    let db;\n    return client.connect().then(() => {\n      db = client.db(this.configuration.db);\n      return db.dropCollection('doesnt_matter').catch(() => {});\n    }).then(() => {\n      return db.createCollection('doesnt_matter');\n    }).then(() => {\n      const coll = db.collection('doesnt_matter');\n      return coll.insertMany(documents, {\n        ordered: false\n      });\n    }).finally(() => client.close());\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should propagate the proper error from executing an empty ordered batch","suites":["Bulk","promise tests"],"updatePoint":{"line":2034,"column":77,"index":63025},"line":2034,"code":"  it('should propagate the proper error from executing an empty ordered batch', function () {\n    const client = this.configuration.newClient();\n    return client.connect().then(() => {\n      const collection = client.db(this.configuration.db).collection('doesnt_matter');\n      return testPropagationOfBulkWriteError(collection.initializeOrderedBulkOp());\n    }).then(() => client.close());\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should propagate the proper error from executing an empty unordered batch","suites":["Bulk","promise tests"],"updatePoint":{"line":2041,"column":79,"index":63425},"line":2041,"code":"  it('should propagate the proper error from executing an empty unordered batch', function () {\n    const client = this.configuration.newClient();\n    return client.connect().then(() => {\n      const collection = client.db(this.configuration.db).collection('doesnt_matter');\n      return testPropagationOfBulkWriteError(collection.initializeUnorderedBulkOp());\n    }).then(() => client.close());\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should promote a single error to the top-level message, and preserve writeErrors","suites":["Bulk","promise tests"],"updatePoint":{"line":2048,"column":86,"index":63834},"line":2048,"code":"  it('should promote a single error to the top-level message, and preserve writeErrors', function () {\n    const client = this.configuration.newClient();\n    return client.connect().then(() => {\n      this.defer(() => client.close());\n      const coll = client.db().collection('single_bulk_write_error');\n      return coll.drop().catch(ignoreNsNotFound).then(() => coll.insert(Array.from({\n        length: 4\n      }, (_, i) => ({\n        _id: i,\n        a: i\n      })))).then(() => coll.bulkWrite([{\n        insertOne: {\n          _id: 5,\n          a: 0\n        }\n      }, {\n        insertOne: {\n          _id: 5,\n          a: 0\n        }\n      }])).then(() => {\n        throw new Error('expected a bulk error');\n      }, err => {\n        expect(err).property('message').to.match(/E11000/);\n        expect(err).to.have.property('writeErrors').with.length(1);\n      });\n    });\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should preserve order of operation index in unordered bulkWrite","suites":["Bulk","promise tests"],"updatePoint":{"line":2076,"column":69,"index":64700},"line":2076,"code":"  it('should preserve order of operation index in unordered bulkWrite', function () {\n    const client = this.configuration.newClient();\n    return client.connect().then(() => {\n      this.defer(() => client.close());\n      const coll = client.db().collection('bulk_write_ordering_test');\n      return coll.drop().catch(ignoreNsNotFound).then(() => coll.insert(Array.from({\n        length: 4\n      }, (_, i) => ({\n        _id: i,\n        a: i\n      })))).then(() => coll.createIndex({\n        a: 1\n      }, {\n        unique: true\n      }).then(() => coll.bulkWrite([{\n        insertOne: {\n          _id: 5,\n          a: 0\n        }\n      }, {\n        updateOne: {\n          filter: {\n            _id: 1\n          },\n          update: {\n            $set: {\n              a: 15\n            }\n          }\n        }\n      }, {\n        insertOne: {\n          _id: 6,\n          a: 0\n        }\n      }, {\n        updateOne: {\n          filter: {\n            _id: 2\n          },\n          update: {\n            $set: {\n              a: 42\n            }\n          }\n        }\n      }], {\n        ordered: false\n      }))).then(() => {\n        throw new Error('expected a bulk error');\n      }, err => {\n        expect(err).to.have.property('writeErrors').with.length(2);\n        expect(err).to.have.nested.property('writeErrors[0].err.index', 0);\n        expect(err).to.have.nested.property('writeErrors[1].err.index', 2);\n      });\n    });\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should preserve order of operation index in unordered bulk operation","suites":["Bulk","promise tests"],"updatePoint":{"line":2133,"column":74,"index":66143},"line":2133,"code":"  it('should preserve order of operation index in unordered bulk operation', function () {\n    const client = this.configuration.newClient();\n    return client.connect().then(() => {\n      this.defer(() => client.close());\n      const coll = client.db().collection('unordered_preserve_order');\n      return coll.drop().catch(ignoreNsNotFound).then(() => {\n        const batch = coll.initializeUnorderedBulkOp();\n        batch.insert({\n          _id: 1,\n          a: 0\n        });\n        batch.insert({\n          _id: 1,\n          a: 0\n        });\n        batch.insert({\n          _id: 2,\n          a: 0\n        });\n        batch.insert({\n          _id: 2,\n          a: 0\n        });\n        return batch.execute();\n      }).then(() => {\n        throw new Error('expected a bulk error');\n      }, err => {\n        expect(err).to.have.property('writeErrors').with.length(2);\n        expect(err).to.have.nested.property('writeErrors[0].err.index', 1);\n        expect(err).to.have.nested.property('writeErrors[1].err.index', 3);\n      });\n    });\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should not fail on the first error in an unorderd bulkWrite","suites":["Bulk","promise tests"],"updatePoint":{"line":2166,"column":65,"index":67184},"line":2166,"code":"  it('should not fail on the first error in an unorderd bulkWrite', function () {\n    const client = this.configuration.newClient();\n    return client.connect().then(() => {\n      this.defer(() => client.close());\n      const coll = client.db().collection('bulk_op_ordering_test');\n      return coll.drop().catch(ignoreNsNotFound).then(() => coll.createIndex({\n        email: 1\n      }, {\n        unique: 1,\n        background: false\n      })).then(() => Promise.all([coll.updateOne({\n        email: 'adam@gmail.com'\n      }, {\n        $set: {\n          name: 'Adam Smith',\n          age: 29\n        }\n      }, {\n        upsert: true\n      }), coll.updateOne({\n        email: 'john@gmail.com'\n      }, {\n        $set: {\n          name: 'John Doe',\n          age: 32\n        }\n      }, {\n        upsert: true\n      })])).then(() => coll.bulkWrite([{\n        updateOne: {\n          filter: {\n            email: 'adam@gmail.com'\n          },\n          update: {\n            $set: {\n              age: 39\n            }\n          }\n        }\n      }, {\n        insertOne: {\n          document: {\n            email: 'john@gmail.com'\n          }\n        }\n      }], {\n        ordered: false\n      })).then(() => {\n        throw new Error('expected a bulk error');\n      }, err => expect(err).property('code').to.equal(11000)).then(() => coll.findOne({\n        email: 'adam@gmail.com'\n      })).then(updatedAdam => expect(updatedAdam).property('age').to.equal(39));\n    });\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should return correct ids for documents with generated ids","suites":["Bulk","promise tests"],"updatePoint":{"line":2220,"column":64,"index":68655},"line":2220,"code":"  it('should return correct ids for documents with generated ids', withClientV2(function (client, done) {\n    const bulk = client.db().collection('coll').initializeUnorderedBulkOp();\n\n    for (let i = 0; i < 2; i++) bulk.insert({\n      x: 1\n    });\n\n    bulk.execute((err, result) => {\n      expect(err).to.not.exist;\n      expect(result).property('insertedIds').to.exist;\n      expect(Object.keys(result.insertedIds)).to.have.length(2);\n      expect(result.insertedIds[0]).to.exist;\n      expect(result.insertedIds[1]).to.exist;\n      done();\n    });\n  }));","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if bulk execute is called more than once","suites":["Bulk","promise tests"],"updatePoint":{"line":2236,"column":68,"index":69218},"line":2236,"code":"  it('should throw an error if bulk execute is called more than once', withClientV2(function (client, done) {\n    const bulk = client.db().collection('coll').initializeUnorderedBulkOp();\n    bulk.insert({});\n    bulk.execute((err, result) => {\n      expect(err).to.not.exist;\n      expect(result).to.exist;\n      bulk.execute(err => {\n        expect(err).to.be.instanceof(MongoBatchReExecutionError);\n        done();\n      });\n    });\n  }));","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should apply collation via FindOperators","suites":["Bulk","promise tests"],"updatePoint":{"line":2248,"column":46,"index":69638},"line":2248,"code":"  it('should apply collation via FindOperators', {\n    metadata: {\n      requires: {\n        mongodb: '>= 3.4'\n      }\n    },\n    test: withMonitoredClient(['update', 'delete'], function (client, events, done) {\n      const locales = ['fr', 'de', 'es'];\n      const bulk = client.db().collection('coll').initializeOrderedBulkOp(); // updates\n\n      bulk.find({\n        b: 1\n      }).collation({\n        locale: locales[0]\n      }).updateOne({\n        $set: {\n          b: 2\n        }\n      });\n      bulk.find({\n        b: 2\n      }).collation({\n        locale: locales[1]\n      }).update({\n        $set: {\n          b: 3\n        }\n      });\n      bulk.find({\n        b: 3\n      }).collation({\n        locale: locales[2]\n      }).replaceOne({\n        b: 2\n      }); // deletes\n\n      bulk.find({\n        b: 2\n      }).collation({\n        locale: locales[0]\n      }).deleteOne();\n      bulk.find({\n        b: 1\n      }).collation({\n        locale: locales[1]\n      }).delete();\n      bulk.execute(err => {\n        expect(err).to.not.exist;\n        expect(events).to.be.an('array').with.length.at.least(1);\n        expect(events[0]).property('commandName').to.equal('update');\n        const updateCommand = events[0].command;\n        expect(updateCommand).property('updates').to.be.an('array').with.length(3);\n        updateCommand.updates.forEach((statement, idx) => {\n          expect(statement).property('collation').to.eql({\n            locale: locales[idx]\n          });\n        });\n        expect(events[1]).property('commandName').to.equal('delete');\n        const deleteCommand = events[1].command;\n        expect(deleteCommand).property('deletes').to.be.an('array').with.length(2);\n        deleteCommand.deletes.forEach((statement, idx) => {\n          expect(statement).property('collation').to.eql({\n            locale: locales[idx]\n          });\n        });\n        client.close(done);\n      });\n    })\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should apply arrayFilters to bulk updates via FindOperators","suites":["Bulk","promise tests"],"updatePoint":{"line":2317,"column":65,"index":71575},"line":2317,"code":"  it('should apply arrayFilters to bulk updates via FindOperators', {\n    metadata: {\n      requires: {\n        mongodb: '>= 3.6'\n      }\n    },\n    test: withMonitoredClient(['update', 'delete'], function (client, events, done) {\n      client.db().dropCollection('bulkArrayFilters', () => {\n        const coll = client.db().collection('bulkArrayFilters');\n        const bulk = coll.initializeOrderedBulkOp();\n        bulk.insert({\n          person: 'Foo',\n          scores: [4, 9, 12]\n        });\n        bulk.insert({\n          person: 'Bar',\n          scores: [13, 0, 52]\n        });\n        bulk.find({\n          scores: {\n            $lt: 1\n          }\n        }).arrayFilters([{\n          e: {\n            $lt: 1\n          }\n        }]).updateOne({\n          $set: {\n            'scores.$[e]': 1\n          }\n        });\n        bulk.find({\n          scores: {\n            $gte: 10\n          }\n        }).arrayFilters([{\n          e: {\n            $gte: 10\n          }\n        }]).update({\n          $set: {\n            'scores.$[e]': 10\n          }\n        });\n        bulk.execute(err => {\n          expect(err).to.not.exist;\n          expect(events).to.be.an('array').with.lengthOf(1);\n          expect(events[0]).to.have.property('commandName', 'update');\n          const updateCommand = events[0].command;\n          expect(updateCommand).property('updates').to.be.an('array').with.lengthOf(2);\n          updateCommand.updates.forEach(update => expect(update).to.have.property('arrayFilters'));\n          coll.find({}).toArray((err, result) => {\n            expect(err).to.not.exist;\n            expect(result[0]).to.containSubset({\n              person: 'Foo',\n              scores: [4, 9, 10]\n            });\n            expect(result[1]).to.containSubset({\n              person: 'Bar',\n              scores: [10, 1, 10]\n            });\n            client.close(done);\n          });\n        });\n      });\n    })\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if raw operations are passed to bulkWrite","suites":["Bulk","promise tests"],"updatePoint":{"line":2384,"column":69,"index":73508},"line":2384,"code":"  it('should throw an error if raw operations are passed to bulkWrite', function () {\n    const client = this.configuration.newClient();\n    return client.connect().then(() => {\n      this.defer(() => client.close());\n      const coll = client.db().collection('single_bulk_write_error');\n      return coll.bulkWrite([{\n        updateOne: {\n          q: {\n            a: 2\n          },\n          u: {\n            $set: {\n              a: 2\n            }\n          },\n          upsert: true\n        }\n      }, {\n        deleteOne: {\n          q: {\n            c: 1\n          }\n        }\n      }]).then(() => {\n        throw new Error('expected a bulk error');\n      }, err => {\n        expect(err).to.match(/Raw operations are not allowed/);\n      });\n    });\n  });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should abort ordered bulk operation writes","suites":["Bulk","Bulk operation transaction rollback"],"updatePoint":{"line":2436,"column":50,"index":75019},"line":2436,"code":"    it('should abort ordered bulk operation writes', {\n      metadata: {\n        requires: {\n          mongodb: '>= 4.2',\n          topology: ['replicaset']\n        }\n      },\n\n      async test() {\n        const session = client.startSession();\n        session.startTransaction({\n          readConcern: {\n            level: 'local'\n          },\n          writeConcern: {\n            w: 'majority'\n          }\n        });\n        let bulk = undefined;\n        bulk = collection.initializeOrderedBulkOp({\n          session\n        });\n        bulk.insert({\n          answer: 42\n        });\n        await bulk.execute();\n        await session.abortTransaction();\n        await session.endSession();\n        const documents = await collection.find().toArray();\n        expect(documents).to.have.lengthOf(0, 'bulk operation writes were made outside of transaction');\n      }\n\n    });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should abort unordered bulk operation writes","suites":["Bulk","Bulk operation transaction rollback"],"updatePoint":{"line":2469,"column":52,"index":75900},"line":2469,"code":"    it('should abort unordered bulk operation writes', {\n      metadata: {\n        requires: {\n          mongodb: '>= 4.2',\n          topology: ['replicaset']\n        }\n      },\n\n      async test() {\n        const session = client.startSession();\n        session.startTransaction({\n          readConcern: {\n            level: 'local'\n          },\n          writeConcern: {\n            w: 'majority'\n          }\n        });\n        let bulk = undefined;\n        bulk = collection.initializeUnorderedBulkOp({\n          session\n        });\n        bulk.insert({\n          answer: 42\n        });\n        await bulk.execute();\n        await session.abortTransaction();\n        await session.endSession();\n        const documents = await collection.find().toArray();\n        expect(documents).to.have.lengthOf(0, 'bulk operation writes were made outside of transaction');\n      }\n\n    });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should abort unordered bulk operation writes using withTransaction","suites":["Bulk","Bulk operation transaction rollback"],"updatePoint":{"line":2502,"column":74,"index":76805},"line":2502,"code":"    it('should abort unordered bulk operation writes using withTransaction', {\n      metadata: {\n        requires: {\n          mongodb: '>= 4.2',\n          topology: ['replicaset']\n        }\n      },\n\n      async test() {\n        const session = client.startSession();\n        await session.withTransaction(async () => {\n          let bulk = undefined;\n          bulk = collection.initializeUnorderedBulkOp({\n            session\n          });\n          bulk.insert({\n            answer: 42\n          });\n          await bulk.execute();\n          await session.abortTransaction();\n        }, {\n          readConcern: {\n            level: 'local'\n          },\n          writeConcern: {\n            w: 'majority'\n          }\n        });\n        await session.endSession();\n        const documents = await collection.find().toArray();\n        expect(documents).to.have.lengthOf(0, 'bulk operation writes were made outside of transaction');\n      }\n\n    });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should abort ordered bulk operation writes using withTransaction","suites":["Bulk","Bulk operation transaction rollback"],"updatePoint":{"line":2536,"column":72,"index":77756},"line":2536,"code":"    it('should abort ordered bulk operation writes using withTransaction', {\n      metadata: {\n        requires: {\n          mongodb: '>= 4.2',\n          topology: ['replicaset']\n        }\n      },\n\n      async test() {\n        const session = client.startSession();\n        await session.withTransaction(async () => {\n          let bulk = undefined;\n          bulk = collection.initializeOrderedBulkOp({\n            session\n          });\n          bulk.insert({\n            answer: 42\n          });\n          await bulk.execute();\n          await session.abortTransaction();\n        }, {\n          readConcern: {\n            level: 'local'\n          },\n          writeConcern: {\n            w: 'majority'\n          }\n        });\n        await session.endSession();\n        const documents = await collection.find().toArray();\n        expect(documents).to.have.lengthOf(0, 'bulk operation writes were made outside of transaction');\n      }\n\n    });","file":"integration/crud/bulk.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute findOne method using crud api","suites":["CRUD API"],"updatePoint":{"line":25,"column":60,"index":596},"line":25,"code":"  it('should correctly execute findOne method using crud api', async function () {\n    const configuration = this.configuration;\n    const client = configuration.newClient();\n    await client.connect();\n    const db = client.db(configuration.db);\n    const collection = db.collection('t');\n    await collection.insertOne({\n      findOneTest: 1\n    });\n    const findOneResult = await collection.findOne({\n      findOneTest: 1\n    });\n    expect(findOneResult).to.have.property('findOneTest', 1);\n    expect(findOneResult).to.have.property('_id').that.is.instanceOf(ObjectId);\n    const findNoneResult = await collection.findOne({\n      findOneTest: 2\n    });\n    expect(findNoneResult).to.be.null;\n    await collection.drop();\n    await client.close();\n  });","file":"integration/crud/crud_api.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute find method using crud api","suites":["CRUD API"],"updatePoint":{"line":46,"column":57,"index":1352},"line":46,"code":"  it('should correctly execute find method using crud api', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('t').insert([{\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }], function (err) {\n          expect(err).to.not.exist; //\n          // Cursor\n          // --------------------------------------------------\n\n          const makeCursor = () => {\n            // Possible methods on the the cursor instance\n            return db.collection('t').find({}).filter({\n              a: 1\n            }).addCursorFlag('noCursorTimeout', true).addQueryModifier('$comment', 'some comment').batchSize(2).comment('some comment 2').limit(2).maxTimeMS(50).project({\n              a: 1\n            }).skip(0).sort({\n              a: 1\n            });\n          }; //\n          // Exercise count method\n          // -------------------------------------------------\n\n\n          var countMethod = function () {\n            // Execute the different methods supported by the cursor\n            const cursor = makeCursor();\n            cursor.count(function (err, count) {\n              expect(err).to.not.exist;\n              test.equal(2, count);\n              eachMethod();\n            });\n          }; //\n          // Exercise legacy method each\n          // -------------------------------------------------\n\n\n          var eachMethod = function () {\n            var count = 0;\n            const cursor = makeCursor();\n            cursor.forEach(() => {\n              count = count + 1;\n            }, err => {\n              expect(err).to.not.exist;\n              test.equal(2, count);\n              toArrayMethod();\n            });\n          }; //\n          // Exercise toArray\n          // -------------------------------------------------\n\n\n          var toArrayMethod = function () {\n            const cursor = makeCursor();\n            cursor.toArray(function (err, docs) {\n              expect(err).to.not.exist;\n              test.equal(2, docs.length);\n              nextMethod();\n            });\n          }; //\n          // Exercise next method\n          // -------------------------------------------------\n\n\n          var nextMethod = function () {\n            const cursor = makeCursor();\n            cursor.next(function (err, doc) {\n              expect(err).to.not.exist;\n              test.ok(doc != null);\n              cursor.next(function (err, doc) {\n                expect(err).to.not.exist;\n                test.ok(doc != null);\n                cursor.next(function (err, doc) {\n                  expect(err).to.not.exist;\n                  expect(doc).to.not.exist;\n                  streamMethod();\n                });\n              });\n            });\n          }; //\n          // Exercise stream\n          // -------------------------------------------------\n\n\n          var streamMethod = function () {\n            var count = 0;\n            const cursor = makeCursor();\n            const stream = cursor.stream();\n            stream.on('data', function () {\n              count = count + 1;\n            });\n            cursor.once('close', function () {\n              test.equal(2, count);\n              explainMethod();\n            });\n          }; //\n          // Explain method\n          // -------------------------------------------------\n\n\n          var explainMethod = function () {\n            const cursor = makeCursor();\n            cursor.explain(function (err, result) {\n              expect(err).to.not.exist;\n              test.ok(result != null);\n              client.close(done);\n            });\n          }; // Execute all the methods\n\n\n          countMethod();\n        });\n      });\n    }\n  });","file":"integration/crud/crud_api.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute aggregation method using crud api","suites":["CRUD API"],"updatePoint":{"line":179,"column":64,"index":5568},"line":179,"code":"  it('should correctly execute aggregation method using crud api', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('t1').insert([{\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 1\n        }], function (err) {\n          expect(err).to.not.exist;\n\n          var testAllMethods = function () {\n            // Get the cursor\n            var cursor = db.collection('t1').aggregate([{\n              $match: {}\n            }], {\n              allowDiskUse: true,\n              batchSize: 2,\n              maxTimeMS: 50\n            }); // Exercise all the options\n\n            cursor.geoNear({\n              geo: 1\n            }).group({\n              group: 1\n            }).limit(10).match({\n              match: 1\n            }).maxTimeMS(10).out('collection').project({\n              project: 1\n            }).redact({\n              redact: 1\n            }).skip(1).sort({\n              sort: 1\n            }).batchSize(10).unwind('name'); // Execute the command with all steps defined\n            // will fail\n\n            cursor.toArray(function (err) {\n              test.ok(err != null);\n              testToArray();\n            });\n          }; //\n          // Exercise toArray\n          // -------------------------------------------------\n\n\n          var testToArray = function () {\n            var cursor = db.collection('t1').aggregate();\n            cursor.match({\n              a: 1\n            });\n            cursor.toArray(function (err, docs) {\n              expect(err).to.not.exist;\n              test.equal(3, docs.length);\n              testNext();\n            });\n          }; //\n          // Exercise next\n          // -------------------------------------------------\n\n\n          var testNext = function () {\n            var cursor = db.collection('t1').aggregate();\n            cursor.match({\n              a: 1\n            });\n            cursor.next(function (err) {\n              expect(err).to.not.exist;\n              testEach();\n            });\n          }; //\n          // Exercise each\n          // -------------------------------------------------\n\n\n          var testEach = function () {\n            var count = 0;\n            var cursor = db.collection('t1').aggregate();\n            cursor.match({\n              a: 1\n            });\n            cursor.forEach(() => {\n              count = count + 1;\n            }, err => {\n              expect(err).to.not.exist;\n              test.equal(3, count);\n              testStream();\n            });\n          }; //\n          // Exercise stream\n          // -------------------------------------------------\n\n\n          var testStream = function () {\n            var cursor = db.collection('t1').aggregate();\n            var count = 0;\n            cursor.match({\n              a: 1\n            });\n            const stream = cursor.stream();\n            stream.on('data', function () {\n              count = count + 1;\n            });\n            stream.once('end', function () {\n              test.equal(3, count);\n              testExplain();\n            });\n          }; //\n          // Explain method\n          // -------------------------------------------------\n\n\n          var testExplain = function () {\n            var cursor = db.collection('t1').aggregate();\n            cursor.explain(function (err, result) {\n              expect(err).to.not.exist;\n              test.ok(result != null);\n              client.close(done);\n            });\n          };\n\n          testAllMethods();\n        });\n      });\n    }\n  });","file":"integration/crud/crud_api.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute insert methods using crud api","suites":["CRUD API"],"updatePoint":{"line":319,"column":60,"index":9600},"line":319,"code":"  it('should correctly execute insert methods using crud api', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db); //\n        // Legacy insert method\n        // -------------------------------------------------\n\n        var legacyInsert = function () {\n          db.collection('t2_1').insertMany([{\n            a: 1\n          }, {\n            a: 2\n          }], function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(2);\n            bulkAPIInsert();\n          });\n        }; //\n        // Bulk api insert method\n        // -------------------------------------------------\n\n\n        var bulkAPIInsert = function () {\n          var bulk = db.collection('t2_2').initializeOrderedBulkOp();\n          bulk.insert({\n            a: 1\n          });\n          bulk.insert({\n            a: 1\n          });\n          bulk.execute(function (err) {\n            expect(err).to.not.exist;\n            insertOne();\n          });\n        }; //\n        // Insert one method\n        // -------------------------------------------------\n\n\n        var insertOne = function () {\n          db.collection('t2_3').insertOne({\n            a: 1\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedId').to.exist;\n            insertMany();\n          });\n        }; //\n        // Insert many method\n        // -------------------------------------------------\n\n\n        var insertMany = function () {\n          var docs = [{\n            a: 1\n          }, {\n            a: 1\n          }];\n          db.collection('t2_4').insertMany(docs, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(2); // Ordered bulk unordered\n\n            bulkWriteUnOrdered();\n          });\n        }; //\n        // Bulk write method unordered\n        // -------------------------------------------------\n\n\n        var bulkWriteUnOrdered = function () {\n          db.collection('t2_5').insertMany([{\n            c: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(1);\n            db.collection('t2_5').bulkWrite([{\n              insertOne: {\n                document: {\n                  a: 1\n                }\n              }\n            }, {\n              insertOne: {\n                document: {\n                  g: 1\n                }\n              }\n            }, {\n              insertOne: {\n                document: {\n                  g: 2\n                }\n              }\n            }, {\n              updateOne: {\n                filter: {\n                  a: 2\n                },\n                update: {\n                  $set: {\n                    a: 2\n                  }\n                },\n                upsert: true\n              }\n            }, {\n              updateMany: {\n                filter: {\n                  a: 2\n                },\n                update: {\n                  $set: {\n                    a: 2\n                  }\n                },\n                upsert: true\n              }\n            }, {\n              deleteOne: {\n                filter: {\n                  c: 1\n                }\n              }\n            }, {\n              deleteMany: {\n                filter: {\n                  c: 1\n                }\n              }\n            }], {\n              ordered: false,\n              writeConcern: {\n                w: 1\n              }\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              test.equal(3, r.nInserted);\n              test.equal(1, r.nUpserted);\n              test.equal(1, r.nRemoved); // Crud fields\n\n              test.equal(3, r.insertedCount);\n              test.equal(3, Object.keys(r.insertedIds).length);\n              test.equal(1, r.matchedCount);\n              test.equal(1, r.deletedCount);\n              test.equal(1, r.upsertedCount);\n              test.equal(1, Object.keys(r.upsertedIds).length); // Ordered bulk operation\n\n              bulkWriteUnOrderedSpec();\n            });\n          });\n        }; //\n        // Bulk write method unordered\n        // -------------------------------------------------\n\n\n        var bulkWriteUnOrderedSpec = function () {\n          db.collection('t2_6').insertMany([{\n            c: 1\n          }, {\n            c: 2\n          }, {\n            c: 3\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(3);\n            db.collection('t2_6').bulkWrite([{\n              insertOne: {\n                document: {\n                  a: 1\n                }\n              }\n            }, {\n              updateOne: {\n                filter: {\n                  a: 2\n                },\n                update: {\n                  $set: {\n                    a: 2\n                  }\n                },\n                upsert: true\n              }\n            }, {\n              updateMany: {\n                filter: {\n                  a: 3\n                },\n                update: {\n                  $set: {\n                    a: 3\n                  }\n                },\n                upsert: true\n              }\n            }, {\n              deleteOne: {\n                filter: {\n                  c: 1\n                }\n              }\n            }, {\n              deleteMany: {\n                filter: {\n                  c: 2\n                }\n              }\n            }, {\n              replaceOne: {\n                filter: {\n                  c: 3\n                },\n                replacement: {\n                  c: 4\n                },\n                upsert: true\n              }\n            }], {\n              ordered: false,\n              writeConcern: {\n                w: 1\n              }\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              test.equal(1, r.nInserted);\n              test.equal(2, r.nUpserted);\n              test.equal(2, r.nRemoved); // Crud fields\n\n              test.equal(1, r.insertedCount);\n              test.equal(1, Object.keys(r.insertedIds).length);\n              test.equal(1, r.matchedCount);\n              test.equal(2, r.deletedCount);\n              test.equal(2, r.upsertedCount);\n              test.equal(2, Object.keys(r.upsertedIds).length); // Ordered bulk operation\n\n              bulkWriteOrdered();\n            });\n          });\n        }; //\n        // Bulk write method ordered\n        // -------------------------------------------------\n\n\n        var bulkWriteOrdered = function () {\n          db.collection('t2_7').insertMany([{\n            c: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(1);\n            db.collection('t2_7').bulkWrite([{\n              insertOne: {\n                document: {\n                  a: 1\n                }\n              }\n            }, {\n              insertOne: {\n                document: {\n                  g: 1\n                }\n              }\n            }, {\n              insertOne: {\n                document: {\n                  g: 2\n                }\n              }\n            }, {\n              updateOne: {\n                filter: {\n                  a: 2\n                },\n                update: {\n                  $set: {\n                    a: 2\n                  }\n                },\n                upsert: true\n              }\n            }, {\n              updateMany: {\n                filter: {\n                  a: 2\n                },\n                update: {\n                  $set: {\n                    a: 2\n                  }\n                },\n                upsert: true\n              }\n            }, {\n              deleteOne: {\n                filter: {\n                  c: 1\n                }\n              }\n            }, {\n              deleteMany: {\n                filter: {\n                  c: 1\n                }\n              }\n            }], {\n              ordered: true,\n              writeConcern: {\n                w: 1\n              }\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              test.equal(3, r.nInserted);\n              test.equal(1, r.nUpserted);\n              test.equal(1, r.nRemoved); // Crud fields\n\n              test.equal(3, r.insertedCount);\n              test.equal(3, Object.keys(r.insertedIds).length);\n              test.equal(1, r.matchedCount);\n              test.equal(1, r.deletedCount);\n              test.equal(1, r.upsertedCount);\n              test.equal(1, Object.keys(r.upsertedIds).length);\n              bulkWriteOrderedCrudSpec();\n            });\n          });\n        }; //\n        // Bulk write method ordered\n        // -------------------------------------------------\n\n\n        var bulkWriteOrderedCrudSpec = function () {\n          db.collection('t2_8').insertMany([{\n            c: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(1);\n            db.collection('t2_8').bulkWrite([{\n              insertOne: {\n                document: {\n                  a: 1\n                }\n              }\n            }, {\n              updateOne: {\n                filter: {\n                  a: 2\n                },\n                update: {\n                  $set: {\n                    a: 2\n                  }\n                },\n                upsert: true\n              }\n            }, {\n              updateMany: {\n                filter: {\n                  a: 2\n                },\n                update: {\n                  $set: {\n                    a: 2\n                  }\n                },\n                upsert: true\n              }\n            }, {\n              deleteOne: {\n                filter: {\n                  c: 1\n                }\n              }\n            }, {\n              deleteMany: {\n                filter: {\n                  c: 1\n                }\n              }\n            }, {\n              replaceOne: {\n                filter: {\n                  c: 3\n                },\n                replacement: {\n                  c: 4\n                },\n                upsert: true\n              }\n            }], {\n              ordered: true,\n              writeConcern: {\n                w: 1\n              }\n            }, function (err, r) {\n              // expect(err).to.not.exist;\n              test.equal(1, r.nInserted);\n              test.equal(2, r.nUpserted);\n              test.equal(1, r.nRemoved); // Crud fields\n\n              test.equal(1, r.insertedCount);\n              test.equal(1, Object.keys(r.insertedIds).length);\n              test.equal(1, r.matchedCount);\n              test.equal(1, r.deletedCount);\n              test.equal(2, r.upsertedCount);\n              test.equal(2, Object.keys(r.upsertedIds).length);\n              client.close(done);\n            });\n          });\n        };\n\n        legacyInsert();\n      });\n    }\n  });","file":"integration/crud/crud_api.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute update methods using crud api","suites":["CRUD API"],"updatePoint":{"line":766,"column":60,"index":21640},"line":766,"code":"  it('should correctly execute update methods using crud api', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db); //\n        // Legacy update method\n        // -------------------------------------------------\n\n        var legacyUpdate = function () {\n          db.collection('t3_1').update({\n            a: 1\n          }, {\n            $set: {\n              a: 2\n            }\n          }, {\n            upsert: true\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('upsertedCount').to.equal(1);\n            updateOne();\n          });\n        }; //\n        // Update one method\n        // -------------------------------------------------\n\n\n        var updateOne = function () {\n          db.collection('t3_2').insertMany([{\n            c: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(1);\n            db.collection('t3_2').updateOne({\n              a: 1\n            }, {\n              $set: {\n                a: 1\n              }\n            }, {\n              upsert: true\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              expect(r).property('upsertedCount').to.equal(1);\n              test.equal(0, r.matchedCount);\n              test.ok(r.upsertedId != null);\n              db.collection('t3_2').updateOne({\n                c: 1\n              }, {\n                $set: {\n                  a: 1\n                }\n              }, function (err, r) {\n                expect(err).to.not.exist;\n                expect(r).property('modifiedCount').to.equal(1);\n                test.equal(1, r.matchedCount);\n                test.ok(r.upsertedId == null);\n                replaceOne();\n              });\n            });\n          });\n        }; //\n        // Replace one method\n        // -------------------------------------------------\n\n\n        var replaceOne = function () {\n          db.collection('t3_3').replaceOne({\n            a: 1\n          }, {\n            a: 2\n          }, {\n            upsert: true\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('upsertedCount').to.equal(1);\n            test.equal(0, r.matchedCount);\n            test.ok(r.upsertedId != null);\n            db.collection('t3_3').replaceOne({\n              a: 2\n            }, {\n              a: 3\n            }, {\n              upsert: true\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              expect(r).property('modifiedCount').to.equal(1);\n              expect(r).property('upsertedCount').to.equal(0);\n              expect(r).property('matchedCount').to.equal(1);\n              updateMany();\n            });\n          });\n        }; //\n        // Update many method\n        // -------------------------------------------------\n\n\n        var updateMany = function () {\n          db.collection('t3_4').insertMany([{\n            a: 1\n          }, {\n            a: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(2);\n            db.collection('t3_4').updateMany({\n              a: 1\n            }, {\n              $set: {\n                a: 2\n              }\n            }, {\n              upsert: true,\n              writeConcern: {\n                w: 1\n              }\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              expect(r).property('modifiedCount').to.equal(2);\n              test.equal(2, r.matchedCount);\n              test.ok(r.upsertedId == null);\n              db.collection('t3_4').updateMany({\n                c: 1\n              }, {\n                $set: {\n                  d: 2\n                }\n              }, {\n                upsert: true,\n                writeConcern: {\n                  w: 1\n                }\n              }, function (err, r) {\n                expect(err).to.not.exist;\n                test.equal(0, r.matchedCount);\n                test.ok(r.upsertedId != null);\n                client.close(done);\n              });\n            });\n          });\n        };\n\n        legacyUpdate();\n      });\n    }\n  });","file":"integration/crud/crud_api.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute remove methods using crud api","suites":["CRUD API"],"updatePoint":{"line":930,"column":60,"index":26506},"line":930,"code":"  it('should correctly execute remove methods using crud api', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db); //\n        // Legacy update method\n        // -------------------------------------------------\n\n        var legacyRemove = function () {\n          db.collection('t4_1').insertMany([{\n            a: 1\n          }, {\n            a: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            test.equal(2, r.insertedCount);\n            db.collection('t4_1').remove({\n              a: 1\n            }, {\n              single: true\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              test.equal(1, r.deletedCount);\n              deleteOne();\n            });\n          });\n        }; //\n        // Update one method\n        // -------------------------------------------------\n\n\n        var deleteOne = function () {\n          db.collection('t4_2').insertMany([{\n            a: 1\n          }, {\n            a: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, (err, r) => {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(2);\n            db.collection('t4_2').deleteOne({\n              a: 1\n            }, (err, r) => {\n              expect(err).to.not.exist;\n              expect(r).property('deletedCount').to.equal(1);\n              deleteMany();\n            });\n          });\n        }; //\n        // Update many method\n        // -------------------------------------------------\n\n\n        var deleteMany = function () {\n          db.collection('t4_3').insertMany([{\n            a: 1\n          }, {\n            a: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, (err, r) => {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(2);\n            db.collection('t4_3').deleteMany({\n              a: 1\n            }, (err, r) => {\n              expect(err).to.not.exist;\n              expect(r).property('deletedCount').to.equal(2);\n              client.close(done);\n            });\n          });\n        };\n\n        legacyRemove();\n      });\n    }\n  });","file":"integration/crud/crud_api.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute findAndModify methods using crud api","suites":["CRUD API"],"updatePoint":{"line":1026,"column":67,"index":29285},"line":1026,"code":"  it('should correctly execute findAndModify methods using crud api', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db); //\n        // findOneAndRemove method\n        // -------------------------------------------------\n\n        var findOneAndRemove = function () {\n          db.collection('t5_1').insertMany([{\n            a: 1,\n            b: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(1);\n            db.collection('t5_1').findOneAndDelete({\n              a: 1\n            }, {\n              projection: {\n                b: 1\n              },\n              sort: {\n                a: 1\n              }\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              test.equal(1, r.lastErrorObject.n);\n              test.equal(1, r.value.b);\n              findOneAndReplace();\n            });\n          });\n        }; //\n        // findOneAndRemove method\n        // -------------------------------------------------\n\n\n        var findOneAndReplace = function () {\n          db.collection('t5_2').insertMany([{\n            a: 1,\n            b: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(1);\n            db.collection('t5_2').findOneAndReplace({\n              a: 1\n            }, {\n              c: 1,\n              b: 1\n            }, {\n              projection: {\n                b: 1,\n                c: 1\n              },\n              sort: {\n                a: 1\n              },\n              returnDocument: ReturnDocument.AFTER,\n              upsert: true\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              test.equal(1, r.lastErrorObject.n);\n              test.equal(1, r.value.b);\n              test.equal(1, r.value.c);\n              findOneAndUpdate();\n            });\n          });\n        }; //\n        // findOneAndRemove method\n        // -------------------------------------------------\n\n\n        var findOneAndUpdate = function () {\n          db.collection('t5_3').insertMany([{\n            a: 1,\n            b: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(1);\n            db.collection('t5_3').findOneAndUpdate({\n              a: 1\n            }, {\n              $set: {\n                d: 1\n              }\n            }, {\n              projection: {\n                b: 1,\n                d: 1\n              },\n              sort: {\n                a: 1\n              },\n              returnDocument: ReturnDocument.AFTER,\n              upsert: true\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              test.equal(1, r.lastErrorObject.n);\n              test.equal(1, r.value.b);\n              test.equal(1, r.value.d);\n              client.close(done);\n            });\n          });\n        };\n\n        findOneAndRemove();\n      });\n    }\n  });","file":"integration/crud/crud_api.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute removeMany with no selector","suites":["CRUD API"],"updatePoint":{"line":1156,"column":58,"index":33027},"line":1156,"code":"  it('should correctly execute removeMany with no selector', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Delete all items with no selector\n\n        db.collection('t6_1').deleteMany({}, function (err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/crud_api.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute crud operations with w:0","suites":["CRUD API"],"updatePoint":{"line":1180,"column":55,"index":33861},"line":1180,"code":"  it('should correctly execute crud operations with w:0', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        var col = db.collection('shouldCorrectlyExecuteInsertOneWithW0');\n        col.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 0\n          }\n        }, function (err, result) {\n          expect(err).to.not.exist;\n          expect(result).property('acknowledged').to.be.false;\n          expect(result).property('insertedId').to.exist;\n          col.insertMany([{\n            a: 1\n          }], {\n            writeConcern: {\n              w: 0\n            }\n          }, function (err, result) {\n            expect(err).to.not.exist;\n            expect(result).to.exist;\n            col.updateOne({\n              a: 1\n            }, {\n              $set: {\n                b: 1\n              }\n            }, {\n              writeConcern: {\n                w: 0\n              }\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              expect(result).to.exist;\n              col.updateMany({\n                a: 1\n              }, {\n                $set: {\n                  b: 1\n                }\n              }, {\n                writeConcern: {\n                  w: 0\n                }\n              }, function (err, result) {\n                expect(err).to.not.exist;\n                expect(result).to.exist;\n                col.deleteOne({\n                  a: 1\n                }, {\n                  writeConcern: {\n                    w: 0\n                  }\n                }, function (err, result) {\n                  expect(err).to.not.exist;\n                  expect(result).to.exist;\n                  col.deleteMany({\n                    a: 1\n                  }, {\n                    writeConcern: {\n                      w: 0\n                    }\n                  }, function (err, result) {\n                    expect(err).to.not.exist;\n                    expect(result).to.exist;\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/crud_api.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute updateOne operations with w:0 and upsert","suites":["CRUD API"],"updatePoint":{"line":1270,"column":71,"index":36554},"line":1270,"code":"  it('should correctly execute updateOne operations with w:0 and upsert', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        db.collection('try').updateOne({\n          _id: 1\n        }, {\n          $set: {\n            x: 1\n          }\n        }, {\n          upsert: true,\n          writeConcern: {\n            w: 0\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          test.ok(r != null);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/crud_api.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute crud operations using w:0","suites":["CRUD API"],"updatePoint":{"line":1305,"column":56,"index":37560},"line":1305,"code":"  it('should correctly execute crud operations using w:0', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        var collection = db.collection('w0crudoperations');\n        collection.insertOne({}, function (err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        }); // collection.insertOne({a:1});\n        // collection.insertMany([{b:1}]);\n        // collection.updateOne({c:1}, {$set:{a:1}}, {upsert:true});\n        // db.collection('try').updateOne({_id:1}, {$set:{x:1}}, {upsert:true, w:0}, function(err, r) {\n        //   expect(err).to.not.exist;\n        //   test.ok(r != null);\n        //   client.close();\n        //   done();\n        // });\n      });\n    }\n  });","file":"integration/crud/crud_api.test.js","skipped":false,"dir":"test"},{"name":"should correctly throw error on illegal callback when unordered bulkWrite encounters error","suites":["CRUD API"],"updatePoint":{"line":1337,"column":96,"index":38830},"line":1337,"code":"  it('should correctly throw error on illegal callback when unordered bulkWrite encounters error', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var ops = []; // Create a set of operations that go over the 1000 limit causing two messages\n\n      for (var i = 0; i < 1005; i++) {\n        ops.push({\n          insertOne: {\n            _id: i,\n            a: i\n          }\n        });\n      }\n\n      ops.push({\n        insertOne: {\n          _id: 0,\n          a: i\n        }\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        db.collection('t20_1').bulkWrite(ops, {\n          ordered: false,\n          writeConcern: {\n            w: 1\n          }\n        }, function (err) {\n          test.ok(err !== null);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/crud_api.test.js","skipped":false,"dir":"test"},{"name":"should correctly throw error on illegal callback when ordered bulkWrite encounters error","suites":["CRUD API"],"updatePoint":{"line":1382,"column":94,"index":40099},"line":1382,"code":"  it('should correctly throw error on illegal callback when ordered bulkWrite encounters error', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var ops = []; // Create a set of operations that go over the 1000 limit causing two messages\n\n      for (var i = 0; i < 1005; i++) {\n        ops.push({\n          insertOne: {\n            _id: i,\n            a: i\n          }\n        });\n      }\n\n      ops.push({\n        insertOne: {\n          _id: 0,\n          a: i\n        }\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        db.collection('t20_1').bulkWrite(ops, {\n          ordered: true,\n          writeConcern: {\n            w: 1\n          }\n        }, function (err) {\n          test.ok(err !== null);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/crud_api.test.js","skipped":false,"dir":"test"},{"name":"1. WriteConcernError.details exposes writeConcernError.errInfo","suites":["CRUD Prose Spec Tests"],"line":29,"code":"  it.skip('1. WriteConcernError.details exposes writeConcernError.errInfo', {","file":"integration/crud/crud.prose.test.js","skipped":true,"dir":"test"},{"name":"test case: insert MongoServerError","suites":["CRUD Prose Spec Tests","2. WriteError.details exposes writeErrors[].errInfo"],"updatePoint":{"line":100,"column":42,"index":3029},"line":100,"code":"    it('test case: insert MongoServerError', {\n      metadata: {\n        requires: {\n          mongodb: '>=5.0.0'\n        }\n      },\n\n      async test() {\n        const evCapture = once(client, 'commandSucceeded');\n        let errInfoFromError;\n\n        try {\n          await collection.insertOne({\n            x: /not a string/\n          });\n          expect.fail('The insert should fail the validation that x must be a string');\n        } catch (error) {\n          expect(error).to.be.instanceOf(MongoServerError);\n          expect(error).to.have.property('code', 121);\n          expect(error).to.have.property('errInfo').that.is.an('object');\n          errInfoFromError = error.errInfo;\n        }\n\n        const commandSucceededEvents = await evCapture;\n        expect(commandSucceededEvents).to.have.lengthOf(1);\n        const ev = commandSucceededEvents[0];\n        expect(ev).to.have.nested.property('reply.writeErrors[0].errInfo').that.is.an('object');\n        const errInfoFromEvent = ev.reply.writeErrors[0].errInfo;\n        expect(errInfoFromError).to.deep.equal(errInfoFromEvent);\n      }\n\n    });","file":"integration/crud/crud.prose.test.js","skipped":false,"dir":"test"},{"name":"test case: insertMany MongoBulkWriteError","suites":["CRUD Prose Spec Tests","2. WriteError.details exposes writeErrors[].errInfo"],"updatePoint":{"line":132,"column":49,"index":4145},"line":132,"code":"    it('test case: insertMany MongoBulkWriteError', {\n      metadata: {\n        requires: {\n          mongodb: '>=5.0.0'\n        }\n      },\n\n      async test() {\n        const evCapture = once(client, 'commandSucceeded');\n        let errInfoFromError;\n\n        try {\n          await collection.insertMany([{\n            x: /not a string/\n          }]);\n          expect.fail('The insert should fail the validation that x must be a string');\n        } catch (error) {\n          expect(error).to.be.instanceOf(MongoBulkWriteError);\n          expect(error).to.have.property('code', 121);\n          expect(error).to.have.property('writeErrors').that.is.an('array');\n          expect(error.writeErrors[0]).to.have.property('errInfo').that.is.an('object');\n          errInfoFromError = error.writeErrors[0].errInfo;\n        }\n\n        const commandSucceededEvents = await evCapture;\n        expect(commandSucceededEvents).to.have.lengthOf(1);\n        const ev = commandSucceededEvents[0];\n        expect(ev).to.have.nested.property('reply.writeErrors[0].errInfo').that.is.an('object');\n        const errInfoFromEvent = ev.reply.writeErrors[0].errInfo;\n        expect(errInfoFromError).to.deep.equal(errInfoFromEvent);\n      }\n\n    });","file":"integration/crud/crud.prose.test.js","skipped":false,"dir":"test"},{"name":"should allow bypassing document validation in 3.2 or higher on inserts","suites":["Document Validation"],"updatePoint":{"line":16,"column":76,"index":319},"line":16,"code":"  it('should allow bypassing document validation in 3.2 or higher on inserts', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>=3.1.7',\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Get collection\n\n        var col = db.collection('createValidationCollection'); // Drop the collection\n\n        col.drop(function () {\n          // Create a collection with a validator\n          db.createCollection('createValidationCollection', {\n            validator: {\n              a: {\n                $exists: true\n              }\n            }\n          }, function (err) {\n            expect(err).to.not.exist; // Ensure validation was correctly applied\n\n            col.insert({\n              b: 1\n            }, function (err) {\n              test.ok(err != null); // Ensure validation was correctly applied\n\n              col.insert({\n                b: 1\n              }, {\n                bypassDocumentValidation: true\n              }, function (err) {\n                expect(err).to.not.exist; // Bypass valiation on insert\n\n                col.insertOne({\n                  b: 1\n                }, {\n                  bypassDocumentValidation: true\n                }, function (err) {\n                  expect(err).to.not.exist; // Bypass valiation on insert\n\n                  col.insertMany([{\n                    b: 1\n                  }], {\n                    bypassDocumentValidation: true\n                  }, function (err) {\n                    expect(err).to.not.exist;\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/document_validation.test.js","skipped":false,"dir":"test"},{"name":"should allow bypassing document validation in 3.2 or higher on updates","suites":["Document Validation"],"updatePoint":{"line":82,"column":76,"index":2435},"line":82,"code":"  it('should allow bypassing document validation in 3.2 or higher on updates', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>=3.1.7',\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Get collection\n\n        var col = db.collection('createValidationCollection'); // Drop the collection\n\n        col.drop(function () {\n          // Create a collection with a validator\n          db.createCollection('createValidationCollection', {\n            validator: {\n              a: {\n                $exists: true\n              }\n            }\n          }, function (err) {\n            expect(err).to.not.exist; // Should fail\n\n            col.update({\n              b: 1\n            }, {\n              $set: {\n                b: 1\n              }\n            }, {\n              upsert: true\n            }, function (err) {\n              expect(err).to.exist; // Ensure validation was correctly applied\n\n              col.update({\n                b: 1\n              }, {\n                $set: {\n                  b: 1\n                }\n              }, {\n                upsert: true,\n                bypassDocumentValidation: true\n              }, function (err) {\n                expect(err).to.not.exist; // updateOne\n\n                col.updateOne({\n                  c: 1\n                }, {\n                  $set: {\n                    c: 1\n                  }\n                }, {\n                  upsert: true,\n                  bypassDocumentValidation: true\n                }, function (err) {\n                  expect(err).to.not.exist; // updateMany\n\n                  col.updateMany({\n                    d: 1\n                  }, {\n                    $set: {\n                      d: 1\n                    }\n                  }, {\n                    upsert: true,\n                    bypassDocumentValidation: true\n                  }, function (err) {\n                    expect(err).to.not.exist; // updateMany\n\n                    col.replaceOne({\n                      e: 1\n                    }, {\n                      e: 1\n                    }, {\n                      upsert: true,\n                      bypassDocumentValidation: true\n                    }, function (err) {\n                      expect(err).to.not.exist;\n                      client.close(done);\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/document_validation.test.js","skipped":false,"dir":"test"},{"name":"should allow bypassing document validation in 3.2 or higher on bulkWrite","suites":["Document Validation"],"updatePoint":{"line":180,"column":78,"index":5341},"line":180,"code":"  it('should allow bypassing document validation in 3.2 or higher on bulkWrite', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>=3.1.7',\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Get collection\n\n        var col = db.collection('createValidationCollection'); // Drop the collection\n\n        col.drop(function () {\n          // Create a collection with a validator\n          db.createCollection('createValidationCollection', {\n            validator: {\n              a: {\n                $exists: true\n              }\n            }\n          }, function (err) {\n            expect(err).to.not.exist; // Should fail\n\n            col.bulkWrite([{\n              insertOne: {\n                b: 1\n              }\n            }], function (err) {\n              test.ok(err != null);\n              col.bulkWrite([{\n                insertOne: {\n                  b: 1\n                }\n              }], {\n                bypassDocumentValidation: true\n              }, function (err) {\n                expect(err).to.not.exist;\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/document_validation.test.js","skipped":false,"dir":"test"},{"name":"should allow bypassing document validation in 3.2 or higher on findAndModify","suites":["Document Validation"],"updatePoint":{"line":233,"column":82,"index":6962},"line":233,"code":"  it('should allow bypassing document validation in 3.2 or higher on findAndModify', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>=3.1.7',\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Get collection\n\n        var col = db.collection('createValidationCollection'); // Drop the collection\n\n        col.drop(function () {\n          // Create a collection with a validator\n          db.createCollection('createValidationCollection', {\n            validator: {\n              a: {\n                $exists: true\n              }\n            }\n          }, function (err) {\n            expect(err).to.not.exist; // Should fail\n\n            col.findOneAndUpdate({\n              b: 1\n            }, {\n              $set: {\n                b: 1\n              }\n            }, {\n              upsert: true\n            }, function (err) {\n              test.ok(err != null); // Should pass\n\n              col.findOneAndUpdate({\n                b: 1\n              }, {\n                $set: {\n                  b: 1\n                }\n              }, {\n                upsert: true,\n                bypassDocumentValidation: true\n              }, function (err) {\n                expect(err).to.not.exist; // Should pass\n\n                col.findOneAndReplace({\n                  c: 1\n                }, {\n                  c: 1\n                }, {\n                  upsert: true,\n                  bypassDocumentValidation: true\n                }, function (err) {\n                  expect(err).to.not.exist;\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/document_validation.test.js","skipped":false,"dir":"test"},{"name":"should correctly bypass validation for aggregation using out","suites":["Document Validation"],"updatePoint":{"line":305,"column":66,"index":9060},"line":305,"code":"  it('should correctly bypass validation for aggregation using out', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>=3.1.7',\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db); // Some docs for insertion\n\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }]; // Get collection\n\n        var col = db.collection('createValidationCollectionOut'); // Drop the collection\n\n        col.drop(function () {\n          // Create a collection with a validator\n          db.createCollection('createValidationCollectionOut', {\n            validator: {\n              a: {\n                $exists: true\n              }\n            }\n          }, function (err) {\n            expect(err).to.not.exist; // Insert the docs\n\n            col.insertMany(docs, {\n              writeConcern: {\n                w: 1\n              },\n              bypassDocumentValidation: true\n            }, function (err) {\n              expect(err).to.not.exist; // Execute aggregate, notice the pipeline is expressed as an Array\n\n              const cursor = col.aggregate([{\n                $project: {\n                  author: 1,\n                  tags: 1\n                }\n              }, {\n                $unwind: '$tags'\n              }, {\n                $group: {\n                  _id: {\n                    tags: '$tags'\n                  },\n                  authors: {\n                    $addToSet: '$author'\n                  }\n                }\n              }, {\n                $out: 'createValidationCollectionOut'\n              }], {\n                bypassDocumentValidation: true\n              });\n              cursor.toArray(function (err) {\n                expect(err).to.not.exist;\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/document_validation.test.js","skipped":false,"dir":"test"},{"name":"should correctly bypass validation for mapReduce using out","suites":["Document Validation"],"updatePoint":{"line":392,"column":64,"index":11638},"line":392,"code":"  it('should correctly bypass validation for mapReduce using out', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>=3.1.7',\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db); // Get collection\n\n        var col = db.collection('createValidationCollectionOut'); // Drop the collection\n\n        col.drop(function () {\n          // Create a collection with a validator\n          db.createCollection('createValidationCollectionOut', {\n            validator: {\n              a: {\n                $exists: true\n              }\n            }\n          }, function (err) {\n            expect(err).to.not.exist; // Get write concern\n\n            var writeConcern = configuration.writeConcernMax();\n            writeConcern.bypassDocumentValidation = true; // Insert documents\n\n            col.insertMany([{\n              user_id: 1\n            }, {\n              user_id: 2\n            }], {\n              bypassDocumentValidation: true\n            }, function (err) {\n              expect(err).to.not.exist; // String functions\n\n              var map = 'function() { emit(this.user_id, 1); }';\n              var reduce = 'function(k,vals) { return 1; }';\n              col.mapReduce(map, reduce, {\n                out: {\n                  replace: 'createValidationCollectionOut'\n                },\n                bypassDocumentValidation: true\n              }, function (err) {\n                expect(err).to.not.exist;\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/document_validation.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with delete one","suites":["Explain"],"updatePoint":{"line":19,"column":50,"index":356},"line":19,"code":"  it('should honor boolean explain with delete one', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: withClient(function (client, done) {\n      var db = client.db('shouldHonorBooleanExplainWithDeleteOne');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.deleteOne({\n          a: 1\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with delete many","suites":["Explain"],"updatePoint":{"line":46,"column":51,"index":1090},"line":46,"code":"  it('should honor boolean explain with delete many', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: withClient(function (client, done) {\n      var db = client.db('shouldHonorBooleanExplainWithDeleteMany');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.deleteMany({\n          a: 1\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with update one","suites":["Explain"],"updatePoint":{"line":73,"column":50,"index":1825},"line":73,"code":"  it('should honor boolean explain with update one', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: withClient(function (client, done) {\n      var db = client.db('shouldHonorBooleanExplainWithUpdateOne');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.updateOne({\n          a: 1\n        }, {\n          $inc: {\n            a: 2\n          }\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with update many","suites":["Explain"],"updatePoint":{"line":104,"column":51,"index":2619},"line":104,"code":"  it('should honor boolean explain with update many', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: withClient(function (client, done) {\n      var db = client.db('shouldHonorBooleanExplainWithUpdateMany');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.updateMany({\n          a: 1\n        }, {\n          $inc: {\n            a: 2\n          }\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).nested.property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with remove one","suites":["Explain"],"updatePoint":{"line":135,"column":50,"index":3421},"line":135,"code":"  it('should honor boolean explain with remove one', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: withClient(function (client, done) {\n      var db = client.db('shouldHonorBooleanExplainWithRemoveOne');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.deleteOne({\n          a: 1\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with remove many","suites":["Explain"],"updatePoint":{"line":162,"column":51,"index":4155},"line":162,"code":"  it('should honor boolean explain with remove many', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: withClient(function (client, done) {\n      var db = client.db('shouldHonorBooleanExplainWithRemoveMany');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.deleteMany({\n          a: 1\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with distinct","suites":["Explain"],"updatePoint":{"line":189,"column":48,"index":4888},"line":189,"code":"  it('should honor boolean explain with distinct', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.2'\n      }\n    },\n    test: withClient(function (client, done) {\n      var db = client.db('shouldHonorBooleanExplainWithDistinct');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.distinct('a', {}, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with findOneAndModify","suites":["Explain"],"updatePoint":{"line":214,"column":56,"index":5606},"line":214,"code":"  it('should honor boolean explain with findOneAndModify', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.2'\n      }\n    },\n    test: withClient(function (client, done) {\n      var db = client.db('shouldHonorBooleanExplainWithFindOneAndModify');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.findOneAndDelete({\n          a: 1\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with mapReduce","suites":["Explain"],"updatePoint":{"line":241,"column":49,"index":6352},"line":241,"code":"  it('should honor boolean explain with mapReduce', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.4'\n      }\n    },\n    test: withClient(function (client, done) {\n      var db = client.db('shouldHonorBooleanExplainWithMapReduce');\n      var collection = db.collection('test');\n      collection.insertMany([{\n        user_id: 1\n      }, {\n        user_id: 2\n      }], (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        var map = 'function() { emit(this.user_id, 1); }';\n        var reduce = 'function(k,vals) { return 1; }';\n        collection.mapReduce(map, reduce, {\n          out: {\n            replace: 'tempCollection'\n          },\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('stages').to.exist;\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should use allPlansExecution as true explain verbosity","suites":["Explain"],"updatePoint":{"line":273,"column":60,"index":7295},"line":273,"code":"  it('should use allPlansExecution as true explain verbosity', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: withClient(function (client, done) {\n      var db = client.db('shouldUseAllPlansExecutionAsTrueExplainVerbosity');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist; // Verify explanation result contains properties of allPlansExecution output\n\n        collection.deleteOne({\n          a: 1\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).nested.property('executionStats.allPlansExecution').to.exist;\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should use queryPlanner as false explain verbosity","suites":["Explain"],"updatePoint":{"line":302,"column":56,"index":8214},"line":302,"code":"  it('should use queryPlanner as false explain verbosity', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: withClient(function (client, done) {\n      var db = client.db('shouldUseQueryPlannerAsFalseExplainVerbosity');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist; // Verify explanation result contains properties of queryPlanner output\n\n        collection.deleteOne({\n          a: 1\n        }, {\n          explain: false\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).to.not.have.property('executionStats');\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor queryPlanner string explain","suites":["Explain"],"updatePoint":{"line":331,"column":46,"index":9093},"line":331,"code":"  it('should honor queryPlanner string explain', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: withClient(function (client, done) {\n      var db = client.db('shouldHonorQueryPlannerStringExplain');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist; // Verify explanation result contains properties of queryPlanner output\n\n        collection.deleteOne({\n          a: 1\n        }, {\n          explain: 'queryPlanner'\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).to.not.have.property('executionStats');\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor executionStats string explain","suites":["Explain"],"updatePoint":{"line":360,"column":48,"index":9975},"line":360,"code":"  it('should honor executionStats string explain', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: withClient(function (client, done) {\n      var db = client.db('shouldHonorExecutionStatsStringExplain');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist; // Verify explanation result contains properties of executionStats output\n\n        collection.deleteMany({\n          a: 1\n        }, {\n          explain: 'executionStats'\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).property('executionStats').to.exist;\n          expect(explanation.executionStats).to.not.have.property('allPlansExecution');\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor allPlansExecution string explain","suites":["Explain"],"updatePoint":{"line":390,"column":51,"index":10952},"line":390,"code":"  it('should honor allPlansExecution string explain', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: withClient(function (client, done) {\n      var db = client.db('shouldHonorAllPlansStringExplain');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist; // Verify explanation result contains properties of allPlansExecution output\n\n        collection.deleteOne({\n          a: 1\n        }, {\n          explain: 'allPlansExecution'\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).nested.property('executionStats.allPlansExecution').to.exist;\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor string explain with distinct","suites":["Explain"],"updatePoint":{"line":419,"column":47,"index":11861},"line":419,"code":"  it('should honor string explain with distinct', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.2'\n      }\n    },\n    test: withClient(function (client, done) {\n      var db = client.db('shouldHonorStringExplainWithDistinct');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.distinct('a', {}, {\n          explain: 'executionStats'\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).property('executionStats').to.exist;\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor string explain with findOneAndModify","suites":["Explain"],"updatePoint":{"line":445,"column":55,"index":12656},"line":445,"code":"  it('should honor string explain with findOneAndModify', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.2'\n      }\n    },\n    test: withClient(function (client, done) {\n      var db = client.db('shouldHonorStringExplainWithFindOneAndModify');\n      var collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.findOneAndReplace({\n          a: 1\n        }, {\n          a: 2\n        }, {\n          explain: 'queryPlanner'\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor string explain with mapReduce","suites":["Explain"],"updatePoint":{"line":474,"column":48,"index":13439},"line":474,"code":"  it('should honor string explain with mapReduce', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.4'\n      }\n    },\n    test: withClient(function (client, done) {\n      var db = client.db('shouldHonorStringExplainWithMapReduce');\n      var collection = db.collection('test');\n      collection.insertMany([{\n        user_id: 1\n      }, {\n        user_id: 2\n      }], (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        var map = 'function() { emit(this.user_id, 1); }';\n        var reduce = 'function(k,vals) { return 1; }';\n        collection.mapReduce(map, reduce, {\n          out: {\n            replace: 'tempCollection'\n          },\n          explain: 'executionStats'\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('stages').to.exist;\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with find","suites":["Explain"],"updatePoint":{"line":506,"column":44,"index":14377},"line":506,"code":"  it('should honor boolean explain with find', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: withClient(function (client, done) {\n      const db = client.db('shouldHonorBooleanExplainWithFind');\n      const collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.find({\n          a: 1\n        }, {\n          explain: true\n        }).toArray((err, docs) => {\n          expect(err).to.not.exist;\n          const explanation = docs[0];\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor string explain with find","suites":["Explain"],"updatePoint":{"line":534,"column":43,"index":15137},"line":534,"code":"  it('should honor string explain with find', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: withClient(function (client, done) {\n      const db = client.db('shouldHonorStringExplainWithFind');\n      const collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.find({\n          a: 1\n        }, {\n          explain: 'executionStats'\n        }).toArray((err, docs) => {\n          expect(err).to.not.exist;\n          const explanation = docs[0];\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).property('executionStats').to.exist;\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with findOne","suites":["Explain"],"updatePoint":{"line":563,"column":47,"index":15979},"line":563,"code":"  it('should honor boolean explain with findOne', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: withClient(function (client, done) {\n      const db = client.db('shouldHonorBooleanExplainWithFindOne');\n      const collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.findOne({\n          a: 1\n        }, {\n          explain: true\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor string explain with findOne","suites":["Explain"],"updatePoint":{"line":590,"column":46,"index":16708},"line":590,"code":"  it('should honor string explain with findOne', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: withClient(function (client, done) {\n      const db = client.db('shouldHonorStringExplainWithFindOne');\n      const collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.findOne({\n          a: 1\n        }, {\n          explain: 'executionStats'\n        }, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).property('executionStats').to.exist;\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain specified on cursor with find","suites":["Explain"],"updatePoint":{"line":618,"column":64,"index":17533},"line":618,"code":"  it('should honor boolean explain specified on cursor with find', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: withClient(function (client, done) {\n      const db = client.db('shouldHonorBooleanExplainSpecifiedOnCursor');\n      const collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.find({\n          a: 1\n        }).explain(false, (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor string explain specified on cursor with find","suites":["Explain"],"updatePoint":{"line":643,"column":63,"index":18260},"line":643,"code":"  it('should honor string explain specified on cursor with find', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.0'\n      }\n    },\n    test: withClient(function (client, done) {\n      const db = client.db('shouldHonorStringExplainSpecifiedOnCursor');\n      const collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.find({\n          a: 1\n        }).explain('allPlansExecution', (err, explanation) => {\n          expect(err).to.not.exist;\n          expect(explanation).to.exist;\n          expect(explanation).property('queryPlanner').to.exist;\n          expect(explanation).property('executionStats').to.exist;\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor legacy explain with find","suites":["Explain"],"updatePoint":{"line":669,"column":43,"index":19047},"line":669,"code":"  it('should honor legacy explain with find', {\n    metadata: {\n      requires: {\n        mongodb: '<3.0'\n      }\n    },\n    test: withClient(function (client, done) {\n      const db = client.db('shouldHonorLegacyExplainWithFind');\n      const collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.find({\n          a: 1\n        }).explain((err, result) => {\n          expect(err).to.not.exist;\n          expect(result).to.have.property('allPlans');\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain with aggregate","suites":["Explain"],"updatePoint":{"line":693,"column":49,"index":19687},"line":693,"code":"  it('should honor boolean explain with aggregate', withClient(function (client, done) {\n    const db = client.db('shouldHonorBooleanExplainWithAggregate');\n    const collection = db.collection('test');\n    collection.insertOne({\n      a: 1\n    }, (err, res) => {\n      expect(err).to.not.exist;\n      expect(res).to.exist;\n      collection.aggregate([{\n        $project: {\n          a: 1\n        }\n      }, {\n        $group: {\n          _id: '$a'\n        }\n      }], {\n        explain: true\n      }).toArray((err, docs) => {\n        expect(err).to.not.exist;\n        const result = JSON.stringify(docs[0]);\n        expect(result).to.include('\"queryPlanner\"');\n        expect(result).to.include('\"executionStats\"');\n        done();\n      });\n    });\n  }));","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor string explain with aggregate","suites":["Explain"],"updatePoint":{"line":720,"column":48,"index":20443},"line":720,"code":"  it('should honor string explain with aggregate', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.6.0'\n      }\n    },\n    test: withClient(function (client, done) {\n      const db = client.db('shouldHonorStringExplainWithAggregate');\n      const collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.aggregate([{\n          $project: {\n            a: 1\n          }\n        }, {\n          $group: {\n            _id: '$a'\n          }\n        }], {\n          explain: 'executionStats'\n        }).toArray((err, docs) => {\n          expect(err).to.not.exist;\n          const result = JSON.stringify(docs[0]);\n          expect(result).to.include('\"queryPlanner\"');\n          expect(result).to.include('\"executionStats\"');\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor boolean explain specified on cursor with aggregate","suites":["Explain"],"updatePoint":{"line":754,"column":69,"index":21375},"line":754,"code":"  it('should honor boolean explain specified on cursor with aggregate', withClient(function (client, done) {\n    const db = client.db('shouldHonorBooleanExplainSpecifiedOnCursor');\n    const collection = db.collection('test');\n    collection.insertOne({\n      a: 1\n    }, (err, res) => {\n      expect(err).to.not.exist;\n      expect(res).to.exist;\n      collection.aggregate([{\n        $project: {\n          a: 1\n        }\n      }, {\n        $group: {\n          _id: '$a'\n        }\n      }]).explain(false, (err, res) => {\n        expect(err).to.not.exist;\n        const result = JSON.stringify(res);\n        expect(result).to.include('\"queryPlanner\"');\n        expect(result).not.to.include('\"executionStats\"');\n        done();\n      });\n    });\n  }));","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor string explain specified on cursor with aggregate","suites":["Explain"],"updatePoint":{"line":779,"column":68,"index":22128},"line":779,"code":"  it('should honor string explain specified on cursor with aggregate', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.6'\n      }\n    },\n    test: withClient(function (client, done) {\n      const db = client.db('shouldHonorStringExplainSpecifiedOnCursor');\n      const collection = db.collection('test');\n      collection.insertOne({\n        a: 1\n      }, (err, res) => {\n        expect(err).to.not.exist;\n        expect(res).to.exist;\n        collection.aggregate([{\n          $project: {\n            a: 1\n          }\n        }, {\n          $group: {\n            _id: '$a'\n          }\n        }]).explain('allPlansExecution', (err, res) => {\n          expect(err).to.not.exist;\n          expect(res).to.exist;\n          const result = JSON.stringify(res);\n          expect(result).to.include('\"queryPlanner\"');\n          expect(result).to.include('\"executionStats\"');\n          done();\n        });\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should honor legacy explain with aggregate","suites":["Explain"],"updatePoint":{"line":812,"column":48,"index":23040},"line":812,"code":"  it('should honor legacy explain with aggregate', withClient(function (client, done) {\n    const db = client.db('shouldHonorLegacyExplainWithAggregate');\n    const collection = db.collection('test');\n    collection.insertOne({\n      a: 1\n    }, (err, res) => {\n      expect(err).to.not.exist;\n      expect(res).to.exist;\n      collection.aggregate([{\n        $project: {\n          a: 1\n        }\n      }, {\n        $group: {\n          _id: '$a'\n        }\n      }]).explain((err, res) => {\n        expect(err).to.not.exist;\n        const result = JSON.stringify(res);\n        expect(result).to.include('\"queryPlanner\"');\n        expect(result).to.include('\"executionStats\"');\n        done();\n      });\n    });\n  }));","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should throw a catchable error with invalid explain string (promise)","suites":["Explain"],"updatePoint":{"line":837,"column":74,"index":23783},"line":837,"code":"  it('should throw a catchable error with invalid explain string (promise)', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.4'\n      }\n    },\n    test: withClient(function (client, done) {\n      const db = client.db('shouldThrowCatchableError');\n      const collection = db.collection('test');\n      collection.find({\n        a: 1\n      }).explain('invalidExplain').then(() => done(new Error('expected explain to fail but it succeeded'))).catch(err => {\n        expect(err).to.exist;\n        expect(err).to.be.instanceOf(MongoServerError);\n        done();\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"should throw a catchable error with invalid explain string (callback)","suites":["Explain"],"updatePoint":{"line":855,"column":75,"index":24374},"line":855,"code":"  it('should throw a catchable error with invalid explain string (callback)', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.4'\n      }\n    },\n    test: withClient(function (client, done) {\n      const db = client.db('shouldThrowCatchableError');\n      const collection = db.collection('test');\n      collection.find({\n        a: 1\n      }).explain('invalidExplain', (err, result) => {\n        expect(err).to.exist;\n        expect(result).to.not.exist;\n        expect(err).to.be.instanceOf(MongoServerError);\n        done();\n      });\n    })\n  });","file":"integration/crud/explain.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndDelete operation With Promises and no options passed in","suites":["Find and Modify","promise tests"],"updatePoint":{"line":22,"column":98,"index":434},"line":22,"code":"    it('Should correctly execute findOneAndDelete operation With Promises and no options passed in', function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        const col = db.collection('find_one_and_delete_with_promise_no_option');\n        col.insertMany([{\n          a: 1,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (r) {\n          expect(r).property('insertedCount').to.equal(1);\n          col.findOneAndDelete({\n            a: 1\n          }).then(function (r) {\n            test.equal(1, r.lastErrorObject.n);\n            test.equal(1, r.value.b);\n            client.close(done);\n          }).catch(function (err) {\n            test.ok(err != null);\n          });\n        });\n      });\n    });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndUpate operation With Promises and no options passed in","suites":["Find and Modify","promise tests"],"updatePoint":{"line":51,"column":97,"index":1417},"line":51,"code":"    it('Should correctly execute findOneAndUpate operation With Promises and no options passed in', function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        const col = db.collection('find_one_and_update_with_promise_no_option');\n        col.insertMany([{\n          a: 1,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (r) {\n          expect(r).property('insertedCount').to.equal(1);\n          col.findOneAndUpdate({\n            a: 1\n          }, {\n            $set: {\n              a: 1\n            }\n          }).then(function (r) {\n            test.equal(1, r.lastErrorObject.n);\n            test.equal(1, r.value.b);\n            client.close(done);\n          }).catch(function (err) {\n            test.ok(err != null);\n          });\n        });\n      });\n    });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndReplace operation With Promises and no options passed in","suites":["Find and Modify","promise tests"],"updatePoint":{"line":84,"column":99,"index":2470},"line":84,"code":"    it('Should correctly execute findOneAndReplace operation With Promises and no options passed in', function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        const col = db.collection('find_one_and_replace_with_promise_no_option');\n        col.insertMany([{\n          a: 1,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (r) {\n          expect(r).property('insertedCount').to.equal(1);\n          col.findOneAndReplace({\n            a: 1\n          }, {\n            a: 1\n          }).then(function (r) {\n            test.equal(1, r.lastErrorObject.n);\n            test.equal(1, r.value.b);\n            client.close(done);\n          }).catch(function (err) {\n            test.ok(err != null);\n          });\n        });\n      });\n    });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"should pass through writeConcern to all findAndModify commands at command level","suites":["Find and Modify","promise tests"],"updatePoint":{"line":116,"column":85,"index":3481},"line":116,"code":"  it('should pass through writeConcern to all findAndModify commands at command level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var started = [];\n      var succeeded = [];\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      client.on('commandStarted', function (event) {\n        if (event.commandName === 'findAndModify') started.push(event);\n      });\n      client.on('commandSucceeded', function (event) {\n        if (event.commandName === 'findAndModify') succeeded.push(event);\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        var collection = db.collection('findAndModifyTEST'); // Execute findOneAndUpdate\n\n        collection.findOneAndUpdate({}, {\n          $set: {\n            a: 1\n          }\n        }, {\n          writeConcern: {\n            fsync: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          test.deepEqual({\n            fsync: 1\n          }, started[0].command.writeConcern); // Cleanup\n\n          started = [];\n          succeeded = []; // Execute findOneAndReplace\n\n          collection.findOneAndReplace({}, {\n            b: 1\n          }, {\n            writeConcern: {\n              fsync: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n            test.deepEqual({\n              fsync: 1\n            }, started[0].command.writeConcern); // Cleanup\n\n            started = [];\n            succeeded = []; // Execute findOneAndReplace\n\n            collection.findOneAndDelete({}, {\n              writeConcern: {\n                fsync: 1\n              }\n            }, function (err) {\n              expect(err).to.not.exist;\n              test.deepEqual({\n                fsync: 1\n              }, started[0].command.writeConcern);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"should pass through writeConcern to all findAndModify at collection level","suites":["Find and Modify","promise tests"],"updatePoint":{"line":191,"column":79,"index":5797},"line":191,"code":"  it('should pass through writeConcern to all findAndModify at collection level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var started = [];\n      var succeeded = [];\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      client.on('commandStarted', function (event) {\n        if (event.commandName === 'findAndModify') started.push(event);\n      });\n      client.on('commandSucceeded', function (event) {\n        if (event.commandName === 'findAndModify') succeeded.push(event);\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        var collection = db.collection('findAndModifyTEST', {\n          writeConcern: {\n            fsync: 1\n          }\n        }); // Execute findOneAndUpdate\n\n        collection.findOneAndUpdate({}, {\n          $set: {\n            a: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          test.deepEqual({\n            fsync: 1\n          }, started[0].command.writeConcern); // Cleanup\n\n          started = [];\n          succeeded = []; // Execute findOneAndReplace\n\n          collection.findOneAndReplace({}, {\n            b: 1\n          }, function (err) {\n            expect(err).to.not.exist;\n            test.deepEqual({\n              fsync: 1\n            }, started[0].command.writeConcern); // Cleanup\n\n            started = [];\n            succeeded = []; // Execute findOneAndReplace\n\n            collection.findOneAndDelete({}, function (err) {\n              expect(err).to.not.exist;\n              test.deepEqual({\n                fsync: 1\n              }, started[0].command.writeConcern);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"should pass through writeConcern to all findAndModify at db level","suites":["Find and Modify","promise tests"],"updatePoint":{"line":258,"column":71,"index":7937},"line":258,"code":"  it('should pass through writeConcern to all findAndModify at db level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var started = [];\n      var succeeded = [];\n      var url = configuration.url();\n      url = url.indexOf('?') !== -1 ? f('%s&%s', url, 'fsync=true') : f('%s?%s', url, 'fsync=true'); // Establish connection to db\n\n      const client = configuration.newClient(url, {\n        sslValidate: false,\n        monitorCommands: true\n      });\n      client.on('commandStarted', function (event) {\n        if (event.commandName === 'findAndModify') started.push(event);\n      });\n      client.on('commandSucceeded', function (event) {\n        if (event.commandName === 'findAndModify') succeeded.push(event);\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(configuration.db);\n        var collection = db.collection('findAndModifyTEST'); // Execute findOneAndUpdate\n\n        collection.findOneAndUpdate({}, {\n          $set: {\n            a: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          test.deepEqual({\n            fsync: true\n          }, started[0].command.writeConcern); // Cleanup\n\n          started = [];\n          succeeded = []; // Execute findOneAndReplace\n\n          collection.findOneAndReplace({}, {\n            b: 1\n          }, function (err) {\n            expect(err).to.not.exist;\n            test.deepEqual({\n              fsync: true\n            }, started[0].command.writeConcern); // Cleanup\n\n            started = [];\n            succeeded = []; // Execute findOneAndReplace\n\n            collection.findOneAndDelete({}, function (err) {\n              expect(err).to.not.exist;\n              test.deepEqual({\n                fsync: true\n              }, started[0].command.writeConcern);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"should allow all findAndModify commands with non-primary readPreference","suites":["Find and Modify","promise tests"],"updatePoint":{"line":324,"column":77,"index":10167},"line":324,"code":"  it('should allow all findAndModify commands with non-primary readPreference', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'replicaset'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient({\n        readPreference: 'secondary'\n      }, {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        const db = client.db(configuration.db);\n        const collection = db.collection('findAndModifyTEST'); // Execute findOneAndUpdate\n\n        collection.findOneAndUpdate({}, {\n          $set: {\n            a: 1\n          }\n        }, err => {\n          expect(err).to.not.exist;\n          client.close(true, done);\n        });\n      });\n    }\n  });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"should not allow atomic operators for findOneAndReplace","suites":["Find and Modify","promise tests"],"updatePoint":{"line":355,"column":61,"index":11076},"line":355,"code":"  it('should not allow atomic operators for findOneAndReplace', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: withClient((client, done) => {\n      const db = client.db('fakeDb');\n      const collection = db.collection('test');\n      expect(() => {\n        collection.findOneAndReplace({\n          a: 1\n        }, {\n          $set: {\n            a: 14\n          }\n        });\n      }).to.throw(/must not contain atomic operators/);\n      done();\n    })\n  });","file":"integration/crud/find_and_modify.test.js","skipped":false,"dir":"test"},{"name":"should support a batch size","suites":["Find Cursor","#next"],"updatePoint":{"line":32,"column":35,"index":614},"line":32,"code":"    it('should support a batch size', withClientV2(function (client, done) {\n      const commands = [];\n      client.on('commandStarted', filterForCommands(['getMore'], commands));\n      const coll = client.db().collection('abstract_cursor');\n      const cursor = coll.find({}, {\n        batchSize: 2\n      });\n      this.defer(() => cursor.close());\n      cursor.toArray((err, docs) => {\n        expect(err).to.not.exist;\n        expect(docs).to.have.length(6);\n        expect(commands).to.have.length(3);\n        done();\n      });\n    }));","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should support reading buffered documents","suites":["Find Cursor","#readBufferedDocuments"],"updatePoint":{"line":49,"column":49,"index":1226},"line":49,"code":"    it('should support reading buffered documents', withClientV2(function (client, done) {\n      const coll = client.db().collection('abstract_cursor');\n      const cursor = coll.find({}, {\n        batchSize: 5\n      });\n      cursor.next((err, doc) => {\n        expect(err).to.not.exist;\n        expect(doc).property('a').to.equal(1);\n        expect(cursor.bufferedCount()).to.equal(4); // Read the buffered Count\n\n        cursor.readBufferedDocuments(cursor.bufferedCount()); // Get the next item\n\n        cursor.next((err, doc) => {\n          expect(err).to.not.exist;\n          expect(doc).to.exist;\n          cursor.next((err, doc) => {\n            expect(err).to.not.exist;\n            expect(doc).to.be.null;\n            done();\n          });\n        });\n      });\n    }));","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should send a killCursors command when closed before completely iterated","suites":["Find Cursor","#close"],"updatePoint":{"line":74,"column":80,"index":2078},"line":74,"code":"    it('should send a killCursors command when closed before completely iterated', withClientV2(function (client, done) {\n      const commands = [];\n      client.on('commandStarted', filterForCommands(['killCursors'], commands));\n      const coll = client.db().collection('abstract_cursor');\n      const cursor = coll.find({}, {\n        batchSize: 2\n      });\n      cursor.next(err => {\n        expect(err).to.not.exist;\n        cursor.close(err => {\n          expect(err).to.not.exist;\n          expect(commands).to.have.length(1);\n          done();\n        });\n      });\n    }));","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should not send a killCursors command when closed after completely iterated","suites":["Find Cursor","#close"],"updatePoint":{"line":90,"column":83,"index":2663},"line":90,"code":"    it('should not send a killCursors command when closed after completely iterated', withClientV2(function (client, done) {\n      const commands = [];\n      client.on('commandStarted', filterForCommands(['killCursors'], commands));\n      const coll = client.db().collection('abstract_cursor');\n      const cursor = coll.find({}, {\n        batchSize: 2\n      });\n      cursor.toArray(err => {\n        expect(err).to.not.exist;\n        cursor.close(err => {\n          expect(err).to.not.exist;\n          expect(commands).to.have.length(0);\n          done();\n        });\n      });\n    }));","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should not send a killCursors command when closed before initialization","suites":["Find Cursor","#close"],"updatePoint":{"line":106,"column":79,"index":3247},"line":106,"code":"    it('should not send a killCursors command when closed before initialization', withClientV2(function (client, done) {\n      const commands = [];\n      client.on('commandStarted', filterForCommands(['killCursors'], commands));\n      const coll = client.db().collection('abstract_cursor');\n      const cursor = coll.find({}, {\n        batchSize: 2\n      });\n      cursor.close(err => {\n        expect(err).to.not.exist;\n        expect(commands).to.have.length(0);\n        done();\n      });\n    }));","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should iterate each document in a cursor","suites":["Find Cursor","#forEach"],"updatePoint":{"line":121,"column":48,"index":3758},"line":121,"code":"    it('should iterate each document in a cursor', withClientV2(function (client, done) {\n      const coll = client.db().collection('abstract_cursor');\n      const cursor = coll.find({}, {\n        batchSize: 2\n      });\n      const bag = [];\n      cursor.forEach(doc => bag.push(doc), err => {\n        expect(err).to.not.exist;\n        expect(bag).to.have.lengthOf(6);\n        done();\n      });\n    }));","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should return control to the user if an empty batch is returned","suites":["Find Cursor","#tryNext"],"updatePoint":{"line":135,"column":71,"index":4227},"line":135,"code":"    it('should return control to the user if an empty batch is returned', withClientV2(function (client, done) {\n      const db = client.db();\n      db.createCollection('try_next', {\n        capped: true,\n        size: 10000000\n      }, () => {\n        const coll = db.collection('try_next');\n        coll.insertMany([{}, {}], err => {\n          expect(err).to.not.exist;\n          const cursor = coll.find({}, {\n            tailable: true,\n            awaitData: true\n          });\n          this.defer(() => cursor.close());\n          cursor.tryNext((err, doc) => {\n            expect(err).to.not.exist;\n            expect(doc).to.exist;\n            cursor.tryNext((err, doc) => {\n              expect(err).to.not.exist;\n              expect(doc).to.exist;\n              cursor.tryNext((err, doc) => {\n                expect(err).to.not.exist;\n                expect(doc).to.be.null;\n                done();\n              });\n            });\n          });\n        });\n      });\n    }));","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should clone a find cursor","suites":["Find Cursor","#clone"],"updatePoint":{"line":167,"column":34,"index":5219},"line":167,"code":"    it('should clone a find cursor', withClientV2(function (client, done) {\n      const coll = client.db().collection('abstract_cursor');\n      const cursor = coll.find({});\n      this.defer(() => cursor.close());\n      cursor.toArray((err, docs) => {\n        expect(err).to.not.exist;\n        expect(docs).to.have.length(6);\n        expect(cursor).property('closed').to.be.true;\n        const clonedCursor = cursor.clone();\n        this.defer(() => clonedCursor.close());\n        clonedCursor.toArray((err, docs) => {\n          expect(err).to.not.exist;\n          expect(docs).to.have.length(6);\n          expect(clonedCursor).property('closed').to.be.true;\n          done();\n        });\n      });\n    }));","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should clone an aggregate cursor","suites":["Find Cursor","#clone"],"updatePoint":{"line":185,"column":40,"index":5933},"line":185,"code":"    it('should clone an aggregate cursor', withClientV2(function (client, done) {\n      const coll = client.db().collection('abstract_cursor');\n      const cursor = coll.aggregate([{\n        $match: {}\n      }]);\n      this.defer(() => cursor.close());\n      cursor.toArray((err, docs) => {\n        expect(err).to.not.exist;\n        expect(docs).to.have.length(6);\n        expect(cursor).property('closed').to.be.true;\n        const clonedCursor = cursor.clone();\n        this.defer(() => clonedCursor.close());\n        clonedCursor.toArray((err, docs) => {\n          expect(err).to.not.exist;\n          expect(docs).to.have.length(6);\n          expect(clonedCursor).property('closed').to.be.true;\n          done();\n        });\n      });\n    }));","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should rewind a cursor","suites":["Find Cursor","#rewind"],"updatePoint":{"line":207,"column":30,"index":6711},"line":207,"code":"    it('should rewind a cursor', withClientV2(function (client, done) {\n      const coll = client.db().collection('abstract_cursor');\n      const cursor = coll.find({});\n      this.defer(() => cursor.close());\n      cursor.toArray((err, docs) => {\n        expect(err).to.not.exist;\n        expect(docs).to.have.length(6);\n        cursor.rewind();\n        cursor.toArray((err, docs) => {\n          expect(err).to.not.exist;\n          expect(docs).to.have.length(6);\n          done();\n        });\n      });\n    }));","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should end an implicit session on rewind","suites":["Find Cursor","#rewind"],"updatePoint":{"line":222,"column":48,"index":7243},"line":222,"code":"    it('should end an implicit session on rewind', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.6'\n        }\n      },\n      test: withClientV2(function (client, done) {\n        const coll = client.db().collection('abstract_cursor');\n        const cursor = coll.find({}, {\n          batchSize: 1\n        });\n        this.defer(() => cursor.close());\n        cursor.next((err, doc) => {\n          expect(err).to.not.exist;\n          expect(doc).to.exist;\n          const session = cursor.session;\n          expect(session).property('hasEnded').to.be.false;\n          cursor.rewind();\n          expect(session).property('hasEnded').to.be.true;\n          done();\n        });\n      })\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should not end an explicit session on rewind","suites":["Find Cursor","#rewind"],"updatePoint":{"line":245,"column":52,"index":7954},"line":245,"code":"    it('should not end an explicit session on rewind', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.6'\n        }\n      },\n      test: withClientV2(function (client, done) {\n        const coll = client.db().collection('abstract_cursor');\n        const session = client.startSession();\n        const cursor = coll.find({}, {\n          batchSize: 1,\n          session\n        });\n        this.defer(() => cursor.close());\n        cursor.next((err, doc) => {\n          expect(err).to.not.exist;\n          expect(doc).to.exist;\n          const session = cursor.session;\n          expect(session).property('hasEnded').to.be.false;\n          cursor.rewind();\n          expect(session).property('hasEnded').to.be.false;\n          session.endSession(done);\n        });\n      })\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should set allowDiskUse to true by default","suites":["Find Cursor","#allowDiskUse"],"updatePoint":{"line":272,"column":50,"index":8795},"line":272,"code":"    it('should set allowDiskUse to true by default', {\n      metadata: {\n        requires: {\n          mongodb: '>=4.4'\n        }\n      },\n      test: withClientV2(function (client, done) {\n        const commands = [];\n        client.on('commandStarted', filterForCommands(['find'], commands));\n        const coll = client.db().collection('abstract_cursor');\n        const cursor = coll.find({}, {\n          sort: 'foo'\n        });\n        cursor.allowDiskUse();\n        this.defer(() => cursor.close());\n        cursor.toArray(err => {\n          expect(err).to.not.exist;\n          expect(commands).to.have.length(1);\n          expect(commands[0].command.allowDiskUse).to.equal(true);\n          done();\n        });\n      })\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"should set allowDiskUse to false if specified","suites":["Find Cursor","#allowDiskUse"],"updatePoint":{"line":295,"column":53,"index":9531},"line":295,"code":"    it('should set allowDiskUse to false if specified', {\n      metadata: {\n        requires: {\n          mongodb: '>=4.4'\n        }\n      },\n      test: withClientV2(function (client, done) {\n        const commands = [];\n        client.on('commandStarted', filterForCommands(['find'], commands));\n        const coll = client.db().collection('abstract_cursor');\n        const cursor = coll.find({}, {\n          sort: 'foo'\n        });\n        cursor.allowDiskUse(false);\n        this.defer(() => cursor.close());\n        cursor.toArray(err => {\n          expect(err).to.not.exist;\n          expect(commands).to.have.length(1);\n          expect(commands[0].command.allowDiskUse).to.equal(false);\n          done();\n        });\n      })\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"throws if the query does not have sort specified","suites":["Find Cursor","#allowDiskUse"],"updatePoint":{"line":318,"column":56,"index":10276},"line":318,"code":"    it('throws if the query does not have sort specified', {\n      metadata: {\n        requires: {\n          mongodb: '>=4.4'\n        }\n      },\n      test: withClientV2(function (client, done) {\n        const coll = client.db().collection('abstract_cursor');\n        const cursor = coll.find({});\n        expect(() => cursor.allowDiskUse(false)).to.throw('Option \"allowDiskUse\" requires a sort specification');\n        done();\n      })\n    });","file":"integration/crud/find_cursor_methods.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformSimpleFind","suites":["Find"],"updatePoint":{"line":31,"column":38,"index":452},"line":31,"code":"  it('shouldCorrectlyPerformSimpleFind', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(configuration.db);\n        const collection = db.collection('test_find_simple');\n        const docs = [{\n          a: 2\n        }, {\n          b: 3\n        }]; // Insert some test documents\n\n        collection.insert(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist; // Ensure correct insertion testing via the cursor and the count function\n\n          collection.find().toArray(function (err, documents) {\n            expect(err).to.not.exist;\n            test.equal(2, documents.length);\n            collection.count(function (err, count) {\n              expect(err).to.not.exist;\n              test.equal(2, count); // Fetch values by selection\n\n              collection.find({\n                a: docs[0].a\n              }).toArray(function (err, documents) {\n                expect(err).to.not.exist;\n                test.equal(1, documents.length);\n                test.equal(docs[0].a, documents[0].a); // Let's close the db\n\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformSimpleChainedFind","suites":["Find"],"updatePoint":{"line":81,"column":45,"index":2054},"line":81,"code":"  it('shouldCorrectlyPerformSimpleChainedFind', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_simple_chained', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_find_simple_chained');\n          const docs = [{\n            a: 2\n          }, {\n            b: 3\n          }]; // Insert some test documents\n\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist; // Ensure correct insertion testing via the cursor and the count function\n\n            collection.find().toArray(function (err, documents) {\n              test.equal(2, documents.length);\n              collection.count(function (err, count) {\n                test.equal(2, count); // Fetch values by selection\n\n                collection.find({\n                  a: docs[0].a\n                }).toArray(function (err, documents) {\n                  test.equal(1, documents.length);\n                  test.equal(docs[0].a, documents[0].a); // Let's close the db\n\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformAdvancedFinds","suites":["Find"],"updatePoint":{"line":130,"column":41,"index":3663},"line":130,"code":"  it('shouldCorrectlyPerformAdvancedFinds', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('test_find_advanced');\n        const docs = [{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          b: 3\n        }]; // Insert some test documents\n\n        collection.insert(docs, configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist; // Locate by less than\n\n          collection.find({\n            a: {\n              $lt: 10\n            }\n          }).toArray(function (err, documents) {\n            test.equal(2, documents.length); // Check that the correct documents are returned\n\n            var results = []; // Check that we have all the results we want\n\n            documents.forEach(function (doc) {\n              if (doc.a === 1 || doc.a === 2) results.push(1);\n            });\n            test.equal(2, results.length); // Locate by greater than\n\n            collection.find({\n              a: {\n                $gt: 1\n              }\n            }).toArray(function (err, documents) {\n              test.equal(1, documents.length);\n              test.equal(2, documents[0].a); // Locate by less than or equal to\n\n              collection.find({\n                a: {\n                  $lte: 1\n                }\n              }).toArray(function (err, documents) {\n                test.equal(1, documents.length);\n                test.equal(1, documents[0].a); // Locate by greater than or equal to\n\n                collection.find({\n                  a: {\n                    $gte: 1\n                  }\n                }).toArray(function (err, documents) {\n                  test.equal(2, documents.length); // Check that the correct documents are returned\n\n                  var results = []; // Check that we have all the results we want\n\n                  documents.forEach(function (doc) {\n                    if (doc.a === 1 || doc.a === 2) results.push(1);\n                  });\n                  test.equal(2, results.length); // Locate by between\n\n                  collection.find({\n                    a: {\n                      $gt: 1,\n                      $lt: 3\n                    }\n                  }).toArray(function (err, documents) {\n                    test.equal(1, documents.length);\n                    test.equal(2, documents[0].a); // Locate in clause\n\n                    collection.find({\n                      a: {\n                        $in: [1, 2]\n                      }\n                    }).toArray(function (err, documents) {\n                      test.equal(2, documents.length); // Check that the correct documents are returned\n\n                      var results = []; // Check that we have all the results we want\n\n                      documents.forEach(function (doc) {\n                        if (doc.a === 1 || doc.a === 2) results.push(1);\n                      });\n                      test.equal(2, results.length); // Locate in _id clause\n\n                      collection.find({\n                        _id: {\n                          $in: [docs[0]['_id'], docs[1]['_id']]\n                        }\n                      }).toArray(function (err, documents) {\n                        test.equal(2, documents.length); // Check that the correct documents are returned\n\n                        var results = []; // Check that we have all the results we want\n\n                        documents.forEach(function (doc) {\n                          if (doc.a === 1 || doc.a === 2) results.push(1);\n                        });\n                        test.equal(2, results.length); // Let's close the db\n\n                        client.close(done);\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformFindWithSort","suites":["Find"],"updatePoint":{"line":252,"column":40,"index":7920},"line":252,"code":"  it('shouldCorrectlyPerformFindWithSort', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_sorting', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_find_sorting'); // Insert some test documents\n\n          collection.insert([{\n            a: 1,\n            b: 2\n          }, {\n            a: 2,\n            b: 1\n          }, {\n            a: 3,\n            b: 2\n          }, {\n            a: 4,\n            b: 1\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // Test sorting (ascending)\n\n            collection.find({\n              a: {\n                $lt: 10\n              }\n            }, {\n              sort: [['a', 1]]\n            }).toArray(function (err, documents) {\n              test.equal(4, documents.length);\n              test.equal(1, documents[0].a);\n              test.equal(2, documents[1].a);\n              test.equal(3, documents[2].a);\n              test.equal(4, documents[3].a); // Test sorting (descending)\n\n              collection.find({\n                a: {\n                  $lt: 10\n                }\n              }, {\n                sort: [['a', -1]]\n              }).toArray(function (err, documents) {\n                test.equal(4, documents.length);\n                test.equal(4, documents[0].a);\n                test.equal(3, documents[1].a);\n                test.equal(2, documents[2].a);\n                test.equal(1, documents[3].a); // Test sorting (descending), sort is hash\n\n                collection.find({\n                  a: {\n                    $lt: 10\n                  }\n                }, {\n                  sort: {\n                    a: -1\n                  }\n                }).toArray(function (err, documents) {\n                  test.equal(4, documents.length);\n                  test.equal(4, documents[0].a);\n                  test.equal(3, documents[1].a);\n                  test.equal(2, documents[2].a);\n                  test.equal(1, documents[3].a); // Sorting using array of names, assumes ascending order\n\n                  collection.find({\n                    a: {\n                      $lt: 10\n                    }\n                  }, {\n                    sort: ['a']\n                  }).toArray(function (err, documents) {\n                    test.equal(4, documents.length);\n                    test.equal(1, documents[0].a);\n                    test.equal(2, documents[1].a);\n                    test.equal(3, documents[2].a);\n                    test.equal(4, documents[3].a); // Sorting using single name, assumes ascending order\n\n                    collection.find({\n                      a: {\n                        $lt: 10\n                      }\n                    }, {\n                      sort: 'a'\n                    }).toArray(function (err, documents) {\n                      test.equal(4, documents.length);\n                      test.equal(1, documents[0].a);\n                      test.equal(2, documents[1].a);\n                      test.equal(3, documents[2].a);\n                      test.equal(4, documents[3].a); // Sorting using single name, assumes ascending order, sort is hash\n\n                      collection.find({\n                        a: {\n                          $lt: 10\n                        }\n                      }, {\n                        sort: {\n                          a: 1\n                        }\n                      }).toArray(function (err, documents) {\n                        test.equal(4, documents.length);\n                        test.equal(1, documents[0].a);\n                        test.equal(2, documents[1].a);\n                        test.equal(3, documents[2].a);\n                        test.equal(4, documents[3].a);\n                        collection.find({\n                          a: {\n                            $lt: 10\n                          }\n                        }, {\n                          sort: ['b', 'a']\n                        }).toArray(function (err, documents) {\n                          test.equal(4, documents.length);\n                          test.equal(2, documents[0].a);\n                          test.equal(4, documents[1].a);\n                          test.equal(1, documents[2].a);\n                          test.equal(3, documents[3].a); // Sorting using empty array, no order guarantee should not blow up\n\n                          collection.find({\n                            a: {\n                              $lt: 10\n                            }\n                          }, {\n                            sort: []\n                          }).toArray(function (err, documents) {\n                            test.equal(4, documents.length);\n                            /* NONACTUAL */\n                            // Sorting using ordered hash\n\n                            collection.find({\n                              a: {\n                                $lt: 10\n                              }\n                            }, {\n                              sort: {\n                                a: -1\n                              }\n                            }).toArray(function (err, documents) {\n                              // Fail test if not an error\n                              test.equal(4, documents.length); // Let's close the db\n\n                              client.close(done);\n                            });\n                          });\n                        });\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformFindWithLimit","suites":["Find"],"updatePoint":{"line":420,"column":41,"index":14042},"line":420,"code":"  it('shouldCorrectlyPerformFindWithLimit', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_limits', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_find_limits'); // Insert some test documents\n\n          collection.insert([{\n            a: 1\n          }, {\n            b: 2\n          }, {\n            c: 3\n          }, {\n            d: 4\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // Test limits\n\n            collection.find({}, {\n              limit: 1\n            }).toArray(function (err, documents) {\n              test.equal(1, documents.length);\n              collection.find({}, {\n                limit: 2\n              }).toArray(function (err, documents) {\n                test.equal(2, documents.length);\n                collection.find({}, {\n                  limit: 3\n                }).toArray(function (err, documents) {\n                  test.equal(3, documents.length);\n                  collection.find({}, {\n                    limit: 4\n                  }).toArray(function (err, documents) {\n                    test.equal(4, documents.length);\n                    collection.find({}, {}).toArray(function (err, documents) {\n                      test.equal(4, documents.length);\n                      collection.find({}, {\n                        limit: 99\n                      }).toArray(function (err, documents) {\n                        test.equal(4, documents.length); // Let's close the db\n\n                        client.close(done);\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyFindWithNonQuotedValues","suites":["Find"],"updatePoint":{"line":487,"column":44,"index":16260},"line":487,"code":"  it('shouldCorrectlyFindWithNonQuotedValues', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_non_quoted_values', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_find_non_quoted_values'); // insert test document\n\n          collection.insert([{\n            a: 19,\n            b: 'teststring',\n            c: 59920303\n          }, {\n            a: '19',\n            b: 'teststring',\n            c: 3984929\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.find({\n              a: 19\n            }).toArray(function (err, documents) {\n              test.equal(1, documents.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyFindEmbeddedDocument","suites":["Find"],"updatePoint":{"line":529,"column":41,"index":17552},"line":529,"code":"  it('shouldCorrectlyFindEmbeddedDocument', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_embedded_document', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_find_embedded_document'); // insert test document\n\n          collection.insert([{\n            a: {\n              id: 10,\n              value: 'foo'\n            },\n            b: 'bar',\n            c: {\n              id: 20,\n              value: 'foobar'\n            }\n          }, {\n            a: {\n              id: 11,\n              value: 'foo'\n            },\n            b: 'bar2',\n            c: {\n              id: 20,\n              value: 'foobar'\n            }\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // test using integer value\n\n            collection.find({\n              'a.id': 10\n            }).toArray(function (err, documents) {\n              test.equal(1, documents.length);\n              test.equal('bar', documents[0].b); // test using string value\n\n              collection.find({\n                'a.value': 'foo'\n              }).toArray(function (err, documents) {\n                // should yield 2 documents\n                test.equal(2, documents.length);\n                test.equal('bar', documents[0].b);\n                test.equal('bar2', documents[1].b);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyFindNoRecords","suites":["Find"],"updatePoint":{"line":594,"column":34,"index":19458},"line":594,"code":"  it('shouldCorrectlyFindNoRecords', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_one_no_records', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_find_one_no_records');\n          expect(err).to.not.exist;\n          collection.find({\n            a: 1\n          }, {}).toArray(function (err, documents) {\n            test.equal(0, documents.length); // Let's close the db\n\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformFindByWhere","suites":["Find"],"updatePoint":{"line":622,"column":39,"index":20374},"line":622,"code":"  it('shouldCorrectlyPerformFindByWhere', {\n    metadata: {\n      requires: {\n        mongodb: '<=4.2.x',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_where', function (err, collection) {\n          collection.insert([{\n            a: 1\n          }, {\n            a: 2\n          }, {\n            a: 3\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.count(function (err, count) {\n              expect(err).to.not.exist;\n              test.equal(3, count); // Let's test usage of the $where statement\n\n              collection.find({\n                $where: new Code('this.a > 2')\n              }).count(function (err, count) {\n                expect(err).to.not.exist;\n                test.equal(1, count);\n                collection.find({\n                  $where: new Code('this.a > i', {\n                    i: 1\n                  })\n                }).count(function (err, count) {\n                  expect(err).to.not.exist;\n                  test.equal(2, count); // Let's close the db\n\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformFindsWithHintTurnedOn","suites":["Find"],"updatePoint":{"line":671,"column":49,"index":21957},"line":671,"code":"  it('shouldCorrectlyPerformFindsWithHintTurnedOn', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_hint', function (err, collection) {\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            db.createIndex(collection.collectionName, 'a', configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist;\n              collection.find({\n                a: 1\n              }, {\n                hint: 'a'\n              }).toArray(function (err) {\n                test.ok(err != null);\n                collection.find({\n                  a: 1\n                }, {\n                  hint: ['a']\n                }).toArray(function (err, items) {\n                  expect(err).to.not.exist;\n                  test.equal(1, items.length);\n                  collection.find({\n                    a: 1\n                  }, {\n                    hint: {\n                      a: 1\n                    }\n                  }).toArray(function (err, items) {\n                    test.equal(1, items.length); // Modify hints\n\n                    collection.hint = 'a_1';\n                    test.equal('a_1', collection.hint);\n                    collection.find({\n                      a: 1\n                    }).toArray(function (err, items) {\n                      test.equal(1, items.length);\n                      collection.hint = ['a'];\n                      test.equal(1, collection.hint['a']);\n                      collection.find({\n                        a: 1\n                      }).toArray(function (err, items) {\n                        test.equal(1, items.length);\n                        collection.hint = {\n                          a: 1\n                        };\n                        test.equal(1, collection.hint['a']);\n                        collection.find({\n                          a: 1\n                        }).toArray(function (err, items) {\n                          test.equal(1, items.length);\n                          collection.hint = null;\n                          test.ok(collection.hint == null);\n                          collection.find({\n                            a: 1\n                          }).toArray(function (err, items) {\n                            test.equal(1, items.length); // Let's close the db\n\n                            client.close(done);\n                          });\n                        });\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformFindByObjectId","suites":["Find"],"updatePoint":{"line":754,"column":42,"index":25003},"line":754,"code":"  it('shouldCorrectlyPerformFindByObjectId', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_by_oid', (err, collection) => {\n          collection.insertOne({\n            hello: 'mike'\n          }, configuration.writeConcernMax(), (err, r) => {\n            expect(err).to.not.exist;\n            expect(r).property('insertedId').to.exist;\n            collection.findOne({\n              _id: r.insertedId\n            }, (err, doc) => {\n              test.equal('mike', doc.hello);\n\n              var id = doc._id.toString();\n\n              collection.findOne({\n                _id: new ObjectId(id)\n              }, (err, doc) => {\n                test.equal('mike', doc.hello); // Let's close the db\n\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyReturnDocumentWithOriginalStructure","suites":["Find"],"updatePoint":{"line":794,"column":56,"index":26264},"line":794,"code":"  it('shouldCorrectlyReturnDocumentWithOriginalStructure', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_by_oid_with_subdocs', function (err, collection) {\n          var c1 = {\n            _id: new ObjectId(),\n            comments: [],\n            title: 'number 1'\n          };\n          var c2 = {\n            _id: new ObjectId(),\n            comments: [],\n            title: 'number 2'\n          };\n          var doc = {\n            numbers: [],\n            owners: [],\n            comments: [c1, c2],\n            _id: new ObjectId()\n          };\n          collection.insert(doc, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.findOne({\n              _id: doc._id\n            }, {\n              writeConcern: {\n                w: 1\n              },\n              projection: undefined\n            }, function (err, doc) {\n              expect(err).to.not.exist;\n              test.equal(2, doc.comments.length);\n              test.equal('number 1', doc.comments[0].title);\n              test.equal('number 2', doc.comments[1].title);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveSingleRecord","suites":["Find"],"updatePoint":{"line":845,"column":41,"index":27852},"line":845,"code":"  it('shouldCorrectlyRetrieveSingleRecord', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var p_client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      p_client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_should_correctly_retrieve_one_record', function (err, collection) {\n          collection.insert({\n            a: 0\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            const usercollection = db.collection('test_should_correctly_retrieve_one_record');\n            usercollection.findOne({\n              a: 0\n            }, function (err) {\n              expect(err).to.not.exist;\n              p_client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleError","suites":["Find"],"updatePoint":{"line":875,"column":32,"index":28875},"line":875,"code":"  it('shouldCorrectlyHandleError', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_one_error_handling', function (err, collection) {\n          // Try to fetch an object using a totally invalid and wrong hex string... what we're interested in here\n          // is the error handling of the findOne Method\n          try {\n            collection.findOne({\n              _id: ObjectId.createFromHexString('5e9bd59248305adf18ebc15703a1')\n            }, function () {});\n          } catch (err) {\n            client.close(done);\n          }\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformFindWithOptions","suites":["Find"],"updatePoint":{"line":906,"column":43,"index":29906},"line":906,"code":"  it('shouldCorrectlyPerformFindWithOptions', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_field_select_with_options', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_field_select_with_options');\n          var docCount = 25,\n              docs = []; // Insert some test documents\n\n          while (docCount--) docs.push({\n            a: docCount,\n            b: docCount\n          });\n\n          collection.insert(docs, configuration.writeConcernMax(), function (err, retDocs) {\n            docs = retDocs;\n            collection.find({}, {\n              limit: 3,\n              sort: [['a', -1]],\n              projection: {\n                a: 1\n              }\n            }).toArray(function (err, documents) {\n              test.equal(3, documents.length);\n              documents.forEach(function (doc, idx) {\n                expect(doc.b).to.not.exist; // making sure field select works\n\n                test.equal(24 - idx, doc.a); // checking limit sort object with field select\n              });\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyfindOneAndUpdateDocument","suites":["Find"],"updatePoint":{"line":956,"column":45,"index":31516},"line":956,"code":"  it('shouldCorrectlyfindOneAndUpdateDocument', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_and_modify_a_document_1', function (err, collection) {\n          // Test return new document on change\n          collection.insert({\n            a: 1,\n            b: 2\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // Let's modify the document in place\n\n            collection.findOneAndUpdate({\n              a: 1\n            }, {\n              $set: {\n                b: 3\n              }\n            }, {\n              returnDocument: ReturnDocument.AFTER\n            }, function (err, updated_doc) {\n              test.equal(1, updated_doc.value.a);\n              test.equal(3, updated_doc.value.b); // Test return old document on change\n\n              collection.insert({\n                a: 2,\n                b: 2\n              }, configuration.writeConcernMax(), function (err) {\n                expect(err).to.not.exist; // Let's modify the document in place\n\n                collection.findOneAndUpdate({\n                  a: 2\n                }, {\n                  $set: {\n                    b: 3\n                  }\n                }, configuration.writeConcernMax(), function (err, result) {\n                  test.equal(2, result.value.a);\n                  test.equal(2, result.value.b); // Test remove object on change\n\n                  collection.insert({\n                    a: 3,\n                    b: 2\n                  }, configuration.writeConcernMax(), function (err) {\n                    expect(err).to.not.exist; // Let's modify the document in place\n\n                    collection.findOneAndUpdate({\n                      a: 3\n                    }, {\n                      $set: {\n                        b: 3\n                      }\n                    }, {\n                      remove: true\n                    }, function (err, updated_doc) {\n                      test.equal(3, updated_doc.value.a);\n                      test.equal(2, updated_doc.value.b); // Let's upsert!\n\n                      collection.findOneAndUpdate({\n                        a: 4\n                      }, {\n                        $set: {\n                          b: 3\n                        }\n                      }, {\n                        returnDocument: ReturnDocument.AFTER,\n                        upsert: true\n                      }, function (err, updated_doc) {\n                        test.equal(4, updated_doc.value.a);\n                        test.equal(3, updated_doc.value.b); // Test selecting a subset of fields\n\n                        collection.insert({\n                          a: 100,\n                          b: 101\n                        }, configuration.writeConcernMax(), function (err, r) {\n                          expect(err).to.not.exist;\n                          collection.findOneAndUpdate({\n                            a: 100\n                          }, {\n                            $set: {\n                              b: 5\n                            }\n                          }, {\n                            returnDocument: ReturnDocument.AFTER,\n                            projection: {\n                              b: 1\n                            }\n                          }, function (err, updated_doc) {\n                            test.equal(2, Object.keys(updated_doc.value).length);\n                            test.equal(r.insertedIds[0].toHexString(), updated_doc.value._id.toHexString());\n                            test.equal(5, updated_doc.value.b);\n                            test.equal('undefined', typeof updated_doc.value.a);\n                            client.close(done);\n                          });\n                        });\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyfindOneAndUpdateDocumentAndReturnSelectedFieldsOnly","suites":["Find"],"updatePoint":{"line":1075,"column":72,"index":35953},"line":1075,"code":"  it('shouldCorrectlyfindOneAndUpdateDocumentAndReturnSelectedFieldsOnly', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_and_modify_a_document_2', function (err, collection) {\n          // Test return new document on change\n          collection.insert({\n            a: 1,\n            b: 2\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // Let's modify the document in place\n\n            collection.findOneAndUpdate({\n              a: 1\n            }, {\n              $set: {\n                b: 3\n              }\n            }, {\n              returnDocument: ReturnDocument.AFTER,\n              projection: {\n                a: 1\n              }\n            }, function (err, updated_doc) {\n              test.equal(2, Object.keys(updated_doc.value).length);\n              test.equal(1, updated_doc.value.a);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"ShouldCorrectlyLocatePostAndIncValues","suites":["Find"],"updatePoint":{"line":1117,"column":43,"index":37289},"line":1117,"code":"  it('ShouldCorrectlyLocatePostAndIncValues', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('shouldCorrectlyExecuteFindOneWithAnInSearchTag', function (err, collection) {\n          // Test return new document on change\n          collection.insert({\n            title: 'Tobi',\n            author: 'Brian',\n            newTitle: 'Woot',\n            meta: {\n              visitors: 0\n            }\n          }, configuration.writeConcernMax(), function (err, r) {\n            // Fetch the id\n            var id = r.insertedIds[0];\n            collection.update({\n              _id: id\n            }, {\n              $inc: {\n                'meta.visitors': 1\n              }\n            }, configuration.writeConcernMax(), function (err, r) {\n              expect(r).property('matchedCount').to.equal(1);\n              expect(err).to.not.exist;\n              collection.findOne({\n                _id: id\n              }, function (err, item) {\n                test.equal(1, item.meta.visitors);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly Handle findOneAndUpdate Duplicate Key Error","suites":["Find"],"updatePoint":{"line":1167,"column":66,"index":38866},"line":1167,"code":"  it('Should Correctly Handle findOneAndUpdate Duplicate Key Error', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(configuration.db);\n        db.createCollection('findOneAndUpdateDuplicateKeyError', function (err, collection) {\n          expect(err).to.not.exist;\n          collection.createIndex(['name', 1], {\n            unique: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist; // Test return new document on change\n\n            collection.insert([{\n              name: 'test1'\n            }, {\n              name: 'test2'\n            }], configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist; // Let's modify the document in place\n\n              collection.findOneAndUpdate({\n                name: 'test1'\n              }, {\n                $set: {\n                  name: 'test2'\n                }\n              }, {}, function (err, updated_doc) {\n                expect(err).to.exist;\n                expect(updated_doc).to.not.exist;\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly return null when attempting to modify a non-existing document","suites":["Find"],"updatePoint":{"line":1215,"column":84,"index":40445},"line":1215,"code":"  it('Should correctly return null when attempting to modify a non-existing document', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('AttemptTofindOneAndUpdateNonExistingDocument', function (err, collection) {\n          // Let's modify the document in place\n          collection.findOneAndUpdate({\n            name: 'test1'\n          }, {\n            $set: {\n              name: 'test2'\n            }\n          }, {}, function (err, updated_doc) {\n            expect(updated_doc.value).to.not.exist;\n            test.ok(err == null || err.errmsg.match('No matching object found'));\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly handle chained skip and limit on find with toArray","suites":["Find"],"updatePoint":{"line":1245,"column":73,"index":41489},"line":1245,"code":"  it('Should correctly handle chained skip and limit on find with toArray', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('skipAndLimitOnFindWithToArray', function (err, collection) {\n          collection.insert([{\n            a: 1\n          }, {\n            b: 2\n          }, {\n            c: 3\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.find().skip(1).limit(-1).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(1, items.length);\n              test.equal(2, items[0].b);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly handle chained skip and negative limit on find with toArray","suites":["Find"],"updatePoint":{"line":1278,"column":82,"index":42591},"line":1278,"code":"  it('Should correctly handle chained skip and negative limit on find with toArray', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('skipAndNegativeLimitOnFindWithToArray', function (err, collection) {\n          collection.insert([{\n            a: 1\n          }, {\n            b: 2\n          }, {\n            c: 3\n          }, {\n            d: 4\n          }, {\n            e: 5\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.find().skip(1).limit(-3).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(3, items.length);\n              test.equal(2, items[0].b);\n              test.equal(3, items[1].c);\n              test.equal(4, items[2].d);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"should support a timeout option for find operations","suites":["Find"],"updatePoint":{"line":1317,"column":57,"index":43822},"line":1317,"code":"  it('should support a timeout option for find operations', withMonitoredClient(['find'], function (client, events, done) {\n    const db = client.db(this.configuration.db);\n    db.createCollection('cursor_timeout_false_0', (err, collection) => {\n      expect(err).to.not.exist;\n      const cursor = collection.find({}, {\n        timeout: false\n      });\n      cursor.toArray(err => {\n        expect(err).to.not.exist;\n        expect(events[0]).nested.property('command.noCursorTimeout').to.equal(true);\n        done();\n      });\n    });\n  }));","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyfindOneAndUpdateDocumentWithDBStrict","suites":["Find"],"updatePoint":{"line":1335,"column":57,"index":44442},"line":1335,"code":"  it('shouldCorrectlyfindOneAndUpdateDocumentWithDBStrict', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var p_client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      p_client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('shouldCorrectlyfindOneAndUpdateDocumentWithDBStrict', function (err, collection) {\n          // Test return old document on change\n          collection.insert({\n            a: 2,\n            b: 2\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // Let's modify the document in place\n\n            collection.findOneAndUpdate({\n              a: 2\n            }, {\n              $set: {\n                b: 3\n              }\n            }, {\n              returnDocument: ReturnDocument.AFTER\n            }, function (err, result) {\n              test.equal(2, result.value.a);\n              test.equal(3, result.value.b);\n              p_client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyfindOneAndUpdateDocumentThatFailsInFirstStep","suites":["Find"],"updatePoint":{"line":1378,"column":65,"index":45813},"line":1378,"code":"  it('shouldCorrectlyfindOneAndUpdateDocumentThatFailsInFirstStep', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(configuration.db);\n        db.createCollection('shouldCorrectlyfindOneAndUpdateDocumentThatFailsInFirstStep', function (err, collection) {\n          expect(err).to.not.exist; // Set up an index to force duplicate index erro\n\n          collection.createIndex([['failIndex', 1]], {\n            unique: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist; // Setup a new document\n\n            collection.insert({\n              a: 2,\n              b: 2,\n              failIndex: 2\n            }, configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist; // Let's attempt to upsert with a duplicate key error\n\n              collection.findOneAndUpdate({\n                c: 2\n              }, {\n                $set: {\n                  a: 10,\n                  b: 10,\n                  failIndex: 2\n                }\n              }, {\n                writeConcern: {\n                  w: 1\n                },\n                upsert: true\n              }, function (err, result) {\n                expect(result).to.not.exist;\n                expect(err).property('errmsg').to.match(/duplicate key/);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly return new modified document","suites":["Find"],"updatePoint":{"line":1434,"column":51,"index":47620},"line":1434,"code":"  it('Should correctly return new modified document', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('Should_correctly_return_new_modified_document', function (err, collection) {\n          var id = new ObjectId();\n          var doc = {\n            _id: id,\n            a: 1,\n            b: 1,\n            c: {\n              a: 1,\n              b: 1\n            }\n          };\n          collection.insert(doc, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // Find and modify returning the new object\n\n            collection.findOneAndUpdate({\n              _id: id\n            }, {\n              $set: {\n                'c.c': 100\n              }\n            }, {\n              returnDocument: ReturnDocument.AFTER\n            }, function (err, item) {\n              test.equal(doc._id.toString(), item.value._id.toString());\n              test.equal(doc.a, item.value.a);\n              test.equal(doc.b, item.value.b);\n              test.equal(doc.c.a, item.value.c.a);\n              test.equal(doc.c.b, item.value.c.b);\n              test.equal(100, item.value.c.c);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecutefindOneAndUpdate","suites":["Find"],"updatePoint":{"line":1487,"column":44,"index":49298},"line":1487,"code":"  it('shouldCorrectlyExecutefindOneAndUpdate', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('execute_find_and_modify', function (err, collection) {\n          var self = {\n            _id: new ObjectId()\n          };\n          var _uuid = 'sddffdss';\n          collection.findOneAndUpdate({\n            _id: self._id,\n            'plays.uuid': _uuid\n          }, {\n            $set: {\n              'plays.$.active': true\n            }\n          }, {\n            returnDocument: ReturnDocument.AFTER,\n            projection: {\n              plays: 0,\n              results: 0\n            },\n            safe: true\n          }, function (err) {\n            expect(err).to.not.exist;\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly return record with 64-bit id","suites":["Find"],"updatePoint":{"line":1527,"column":51,"index":50460},"line":1527,"code":"  it('Should correctly return record with 64-bit id', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('should_correctly_return_record_with_64bit_id', function (err, collection) {\n          var _lowerId = new ObjectId();\n\n          var _higherId = new ObjectId();\n\n          var lowerId = Long.fromString('133118461172916224', 10);\n          var higherId = Long.fromString('133118461172916225', 10);\n          var lowerDoc = {\n            _id: _lowerId,\n            id: lowerId\n          };\n          var higherDoc = {\n            _id: _higherId,\n            id: higherId\n          };\n          collection.insert([lowerDoc, higherDoc], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // Select record with id of 133118461172916225 using $gt directive\n\n            collection.find({\n              id: {\n                $gt: lowerId\n              }\n            }, {}).toArray(function (err, arr) {\n              test.ok(err == null);\n              test.equal(arr.length, 1, 'Selecting record via $gt directive on 64-bit integer should return a record with higher Id');\n              test.equal(arr[0].id.toString(), '133118461172916225', 'Returned Id should be equal to 133118461172916225');\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly find a Document using findOne excluding _id field","suites":["Find"],"updatePoint":{"line":1573,"column":72,"index":52199},"line":1573,"code":"  it('Should Correctly find a Document using findOne excluding _id field', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var p_client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      p_client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('Should_Correctly_find_a_Document_using_findOne_excluding__id_field', function (err, collection) {\n          var doc = {\n            _id: new ObjectId(),\n            a: 1,\n            c: 2\n          }; // insert doc\n\n          collection.insert(doc, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // Get one document, excluding the _id field\n\n            collection.findOne({\n              a: 1\n            }, {\n              projection: {\n                _id: 0\n              }\n            }, function (err, item) {\n              expect(item._id).to.not.exist;\n              test.equal(1, item.a);\n              test.equal(2, item.c);\n              collection.find({\n                a: 1\n              }, {\n                projection: {\n                  _id: 0\n                }\n              }).toArray(function (err, items) {\n                var item = items[0];\n                expect(item._id).to.not.exist;\n                test.equal(1, item.a);\n                test.equal(2, item.c);\n                p_client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute find queries with selector set to null","suites":["Find"],"updatePoint":{"line":1625,"column":69,"index":53867},"line":1625,"code":"  it('Should correctly execute find queries with selector set to null', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('Should_correctly_execute_find_and_findOne_queries_in_the_same_way', function (err, collection) {\n          var doc = {\n            _id: new ObjectId(),\n            a: 1,\n            c: 2,\n            comments: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n          }; // insert doc\n\n          collection.insert(doc, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.find({\n              _id: doc._id\n            }).project({\n              comments: {\n                $slice: -5\n              }\n            }).toArray(function (err, docs) {\n              test.equal(5, docs[0].comments.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandlerErrorForfindOneAndUpdateWhenNoRecordExists","suites":["Find"],"updatePoint":{"line":1663,"column":70,"index":55119},"line":1663,"code":"  it('shouldCorrectlyHandlerErrorForfindOneAndUpdateWhenNoRecordExists', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('shouldCorrectlyHandlerErrorForfindOneAndUpdateWhenNoRecordExists', function (err, collection) {\n          collection.findOneAndUpdate({\n            a: 1\n          }, {\n            $set: {\n              b: 3\n            }\n          }, {\n            returnDocument: ReturnDocument.AFTER\n          }, function (err, updated_doc) {\n            expect(err).to.not.exist;\n            expect(updated_doc.value).to.not.exist;\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecutefindOneAndUpdateShouldGenerateCorrectBSON","suites":["Find"],"updatePoint":{"line":1694,"column":69,"index":56129},"line":1694,"code":"  it('shouldCorrectlyExecutefindOneAndUpdateShouldGenerateCorrectBSON', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var transaction = {};\n        transaction.document = {};\n        transaction.document.type = 'documentType';\n        transaction.document.id = new ObjectId();\n        transaction.transactionId = new ObjectId();\n        transaction.amount = 12.3333;\n        var transactions = [];\n        transactions.push(transaction); // Wrapping object\n\n        var wrapingObject = {\n          funds: {\n            remaining: 100.5\n          },\n          transactions: transactions\n        };\n        db.createCollection('find_and_modify_generate_correct_bson', function (err, collection) {\n          expect(err).to.not.exist;\n          collection.insert(wrapingObject, configuration.writeConcernMax(), function (err, r) {\n            expect(err).to.not.exist;\n            collection.findOne({\n              _id: r.insertedIds[0],\n              'funds.remaining': {\n                $gte: 3.0\n              },\n              'transactions.id': {\n                $ne: transaction.transactionId\n              }\n            }, function (err, item) {\n              test.ok(item != null);\n              collection.findOneAndUpdate({\n                _id: r.insertedIds[0],\n                'funds.remaining': {\n                  $gte: 3.0\n                },\n                'transactions.id': {\n                  $ne: transaction.transactionId\n                }\n              }, {\n                $push: {\n                  transactions: transaction\n                }\n              }, {\n                returnDocument: ReturnDocument.AFTER,\n                safe: true\n              }, function (err) {\n                expect(err).to.not.exist;\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteMultipleFindsInParallel","suites":["Find"],"updatePoint":{"line":1761,"column":51,"index":58341},"line":1761,"code":"  it('shouldCorrectlyExecuteMultipleFindsInParallel', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var p_client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      p_client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('tasks', function (err, collection) {\n          var numberOfOperations = 0; // Test return old document on change\n\n          collection.insert({\n            a: 2,\n            b: 2\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.find({\n              user_id: '4e9fc8d55883d90100000003',\n              lc_status: {\n                $ne: 'deleted'\n              },\n              owner_rating: {\n                $exists: false\n              }\n            }, {\n              skip: 0,\n              limit: 10,\n              sort: {\n                updated: -1\n              }\n            }).count(function (err) {\n              expect(err).to.not.exist;\n              numberOfOperations = numberOfOperations + 1;\n\n              if (numberOfOperations === 2) {\n                p_client.close(done);\n              }\n            });\n            collection.find({\n              user_id: '4e9fc8d55883d90100000003',\n              lc_status: {\n                $ne: 'deleted'\n              },\n              owner_rating: {\n                $exists: false\n              }\n            }, {\n              skip: 0,\n              limit: 10,\n              sort: {\n                updated: -1\n              }\n            }).count(function (err) {\n              expect(err).to.not.exist;\n              numberOfOperations = numberOfOperations + 1;\n\n              if (numberOfOperations === 2) {\n                p_client.close(done);\n              }\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyReturnErrorFromMongodbOnfindOneAndUpdateForcedError","suites":["Find"],"updatePoint":{"line":1831,"column":72,"index":60424},"line":1831,"code":"  it('shouldCorrectlyReturnErrorFromMongodbOnfindOneAndUpdateForcedError', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('shouldCorrectlyReturnErrorFromMongodbOnfindOneAndUpdateForcedError', function (err, collection) {\n          var q = {\n            x: 1\n          };\n          var set = {\n            y: 2,\n            _id: new ObjectId()\n          };\n          var opts = {\n            returnDocument: ReturnDocument.AFTER,\n            upsert: true\n          }; // Original doc\n\n          var doc = {\n            _id: new ObjectId(),\n            x: 1\n          }; // Insert original doc\n\n          collection.insert(doc, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.findOneAndUpdate(q, {\n              $set: set\n            }, opts, function\n              /* err */\n            () {\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecutefindOneAndUpdateUnderConcurrentLoad","suites":["Find"],"updatePoint":{"line":1876,"column":63,"index":61759},"line":1876,"code":"  it('shouldCorrectlyExecutefindOneAndUpdateUnderConcurrentLoad', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var p_client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      var running = true;\n      p_client.connect(function (err, client) {\n        var db = client.db(configuration.db); // Create a collection\n\n        db.createCollection('collection1', function (err, collection) {\n          // Wait a bit and then execute something that will throw a duplicate error\n          setTimeout(function () {\n            var id = new ObjectId();\n            collection.insert({\n              _id: id,\n              a: 1\n            }, configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist;\n              collection.insert({\n                _id: id,\n                a: 1\n              }, configuration.writeConcernMax(), function (err) {\n                test.ok(err !== null);\n                running = false;\n                p_client.close(done);\n              });\n            });\n          }, 200);\n        });\n        db.createCollection('collection2', function (err, collection) {\n          // Keep hammering in inserts\n          var insert;\n\n          insert = function () {\n            process.nextTick(function () {\n              collection.insert({\n                a: 1\n              });\n              if (running) process.nextTick(insert);\n            });\n          };\n        });\n      });\n    }\n  }); // TODO: NODE-3819: Unskip flaky tests.","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyIterateOverCollection","suites":["Find"],"line":1928,"code":"  it.skip('shouldCorrectlyIterateOverCollection', {","file":"integration/crud/find.test.js","skipped":true,"dir":"test"},{"name":"shouldCorrectlyErrorOutfindOneAndUpdateOnDuplicateRecord","suites":["Find"],"updatePoint":{"line":1978,"column":62,"index":64968},"line":1978,"code":"  it('shouldCorrectlyErrorOutfindOneAndUpdateOnDuplicateRecord', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var p_client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      p_client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        db.createCollection('shouldCorrectlyErrorOutfindOneAndUpdateOnDuplicateRecord', function (err, collection) {\n          expect(err).to.not.exist; // Test return old document on change\n\n          collection.insert([{\n            login: 'user1'\n          }, {\n            login: 'user2'\n          }], configuration.writeConcernMax(), function (err, r) {\n            expect(err).to.not.exist;\n            var id = r.insertedIds[1]; // Set an index\n\n            collection.createIndex('login', {\n              unique: true,\n              writeConcern: {\n                w: 1\n              }\n            }, function (err) {\n              expect(err).to.not.exist; // Attemp to modify document\n\n              collection.findOneAndUpdate({\n                _id: id\n              }, {\n                $set: {\n                  login: 'user1'\n                }\n              }, {}, function (err) {\n                test.ok(err !== null);\n                p_client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformSimpleFindInArray","suites":["Find"],"updatePoint":{"line":2031,"column":36,"index":66585},"line":2031,"code":"  it('shouldPerformSimpleFindInArray', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db); // Create a collection we want to drop later\n\n        db.createCollection('simple_find_in_array', function (err, collection) {\n          expect(err).to.not.exist;\n          var docs = [];\n\n          for (var i = 0; i < 100; i++) docs.push({\n            a: i\n          }); // Insert some test documentations\n\n\n          collection.insert(docs, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // Find all the variables in a specific array\n\n            for (var i = 0; i < 100; i++) docs.push(i); // Fin all in\n\n\n            collection.find({\n              a: {\n                $in: docs\n              }\n            }).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(100, items.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldReturnInstanceofErrorWithBadFieldSelection","suites":["Find"],"updatePoint":{"line":2074,"column":54,"index":67924},"line":2074,"code":"  it('shouldReturnInstanceofErrorWithBadFieldSelection', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        var col = db.collection('bad_field_selection');\n        col.insert([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          col.find({}, {\n            skip: 1,\n            limit: 1,\n            projection: {\n              a: 1,\n              b: 0\n            }\n          }).toArray(function (err) {\n            test.ok(err instanceof Error);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleLimitSkipFindWithFields","suites":["Find"],"updatePoint":{"line":2119,"column":49,"index":69079},"line":2119,"code":"  it('shouldPerformASimpleLimitSkipFindWithFields', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db); // Create a collection we want to drop later\n\n        db.createCollection('simple_find_with_fields', function (err, collection) {\n          expect(err).to.not.exist; // Insert a bunch of documents for the testing\n\n          collection.insert([{\n            a: 1,\n            b: 1\n          }, {\n            a: 2,\n            b: 2\n          }, {\n            a: 3,\n            b: 3\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // Perform a simple find and return all the documents\n\n            collection.find({\n              a: 2\n            }).project({\n              b: 1\n            }).toArray(function (err, docs) {\n              expect(err).to.not.exist;\n              test.equal(1, docs.length);\n              expect(docs[0].a).to.not.exist;\n              test.equal(2, docs[0].b); // Perform a simple find and return all the documents\n\n              collection.find({\n                a: 2\n              }).project({\n                b: 1\n              }).toArray(function (err, docs) {\n                expect(err).to.not.exist;\n                test.equal(1, docs.length);\n                expect(docs[0].a).to.not.exist;\n                test.equal(2, docs[0].b);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleLimitSkipFindWithFields2","suites":["Find"],"updatePoint":{"line":2179,"column":50,"index":70940},"line":2179,"code":"  it('shouldPerformASimpleLimitSkipFindWithFields2', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db); // Create a collection we want to drop later\n\n        db.createCollection('simple_find_with_fields_2', function (err, collection) {\n          expect(err).to.not.exist; // Insert a bunch of documents for the testing\n\n          collection.insert([{\n            a: 1,\n            b: 1\n          }, {\n            a: 2,\n            b: 2\n          }, {\n            a: 3,\n            b: 3\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // Perform a simple find and return all the documents\n\n            collection.find({\n              a: 2\n            }).project({\n              b: 1\n            }).toArray(function (err, docs) {\n              expect(err).to.not.exist;\n              test.equal(1, docs.length);\n              expect(docs[0].a).to.not.exist;\n              test.equal(2, docs[0].b);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformQueryWithBatchSizeDifferentToStandard","suites":["Find"],"updatePoint":{"line":2228,"column":56,"index":72414},"line":2228,"code":"  it('shouldPerformQueryWithBatchSizeDifferentToStandard', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db); // Create a collection we want to drop later\n\n        db.createCollection('shouldPerformQueryWithBatchSizeDifferentToStandard', function (err, collection) {\n          expect(err).to.not.exist;\n          var docs = [];\n\n          for (var i = 0; i < 1000; i++) {\n            docs.push({\n              a: i\n            });\n          } // Insert a bunch of documents for the testing\n\n\n          collection.insert(docs, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // Perform a simple find and return all the documents\n\n            collection.find({}, {\n              batchSize: 1000\n            }).toArray(function (err, docs) {\n              expect(err).to.not.exist;\n              test.equal(1000, docs.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformNegativeLimit","suites":["Find"],"updatePoint":{"line":2272,"column":41,"index":73774},"line":2272,"code":"  it('shouldCorrectlyPerformNegativeLimit', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db); // Create a collection we want to drop later\n\n        const collection = db.collection('shouldCorrectlyPerformNegativeLimit');\n        var docs = [];\n\n        for (var i = 0; i < 1000; i++) {\n          docs.push({\n            a: 1,\n            b: 'helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld'\n          });\n        } // Insert a bunch of documents\n\n\n        collection.insert(docs, configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist; // Perform a simple find and return all the documents\n\n          collection.find({}).limit(-10).toArray(function (err, docs) {\n            expect(err).to.not.exist;\n            test.equal(10, docs.length);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteExhaustQuery","suites":["Find"],"updatePoint":{"line":2313,"column":40,"index":75103},"line":2313,"code":"  it('shouldCorrectlyExecuteExhaustQuery', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db); // Create a collection we want to drop later\n\n        db.createCollection('shouldCorrectlyExecuteExhaustQuery', function (err, collection) {\n          expect(err).to.not.exist;\n          var docs1 = [];\n\n          for (var i = 0; i < 1000; i++) {\n            docs1.push({\n              a: 1,\n              b: 'helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld',\n              c: new Binary(Buffer.alloc(1024))\n            });\n          } // Insert a bunch of documents\n\n\n          collection.insert(docs1, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n\n            for (var i = 0; i < 1000; i++) {\n              var docs2 = [];\n              docs2.push({\n                a: 1,\n                b: 'helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld',\n                c: new Binary(Buffer.alloc(1024))\n              });\n            }\n\n            collection.insert(docs2, configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist; // Perform a simple find and return all the documents\n\n              collection.find({}, {\n                exhaust: true\n              }).toArray(function (err, docs3) {\n                expect(err).to.not.exist;\n                test.equal(docs1.length + docs2.length, docs3.length);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Readpreferences should work fine when using a single server instance","suites":["Find"],"updatePoint":{"line":2368,"column":74,"index":77073},"line":2368,"code":"  it('Readpreferences should work fine when using a single server instance', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        var docs = [];\n\n        for (var i = 0; i < 1; i++) {\n          docs.push({\n            a: 1,\n            b: 'helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld helloworld'\n          });\n        } // Create a collection we want to drop later\n\n\n        db.createCollection('Readpreferencesshouldworkfine', function (err, collection) {\n          // Insert a bunch of documents\n          collection.insert(docs, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // Perform a simple find and return all the documents\n\n            collection.find({}, {\n              exhaust: true\n            }).toArray(function (err, docs2) {\n              expect(err).to.not.exist;\n              test.equal(docs.length, docs2.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Each should not hang on iterating over no results","suites":["Find"],"updatePoint":{"line":2409,"column":55,"index":78484},"line":2409,"code":"  it('Each should not hang on iterating over no results', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Create a collection we want to drop later\n\n        const collection = db.collection('noresultAvailableForEachToIterate'); // Perform a simple find and return all the documents\n\n        collection.find({}).forEach(doc => {\n          expect(doc).to.not.exist;\n        }, err => {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyFindDocumentsByRegExp","suites":["Find"],"updatePoint":{"line":2435,"column":42,"index":79355},"line":2435,"code":"  it('shouldCorrectlyFindDocumentsByRegExp', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db); // Serialized regexes contain extra trailing chars. Sometimes these trailing chars contain / which makes\n        // the original regex invalid, and leads to segmentation fault.\n\n        db.createCollection('test_regex_serialization', function (err, collection) {\n          collection.insert({\n            keywords: ['test', 'segmentation', 'fault', 'regex', 'serialization', 'native']\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            let count = 0;\n\n            for (let i = 0; i <= 20; ++i) {\n              // search by regex\n              collection.findOne({\n                keywords: {\n                  $all: [/ser/, /test/, /seg/, /fault/, /nat/]\n                }\n              }, function (err, item) {\n                expect(err).to.not.exist;\n                expect(item).property('keywords').to.have.length(6);\n\n                if (count++ === 20) {\n                  client.close(done);\n                }\n              });\n            }\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDoFindMinMax","suites":["Find"],"updatePoint":{"line":2477,"column":33,"index":80823},"line":2477,"code":"  it('shouldCorrectlyDoFindMinMax', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db); // Serialized regexes contain extra trailing chars. Sometimes these trailing chars contain / which makes\n        // the original regex invalid, and leads to segmentation fault.\n\n        db.createCollection('shouldCorrectlyDoFindMinMax', function (err, collection) {\n          collection.insert({\n            _id: 123,\n            name: 'some name',\n            min: 1,\n            max: 10\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.find({\n              _id: {\n                $in: ['some', 'value', 123]\n              }\n            }).project({\n              _id: 1,\n              max: 1\n            }).toArray(function (err, docs) {\n              expect(err).to.not.exist;\n              test.equal(10, docs[0].max);\n              collection.find({\n                _id: {\n                  $in: ['some', 'value', 123]\n                }\n              }, {\n                projection: {\n                  _id: 1,\n                  max: 1\n                }\n              }).toArray(function (err, docs) {\n                expect(err).to.not.exist;\n                test.equal(10, docs[0].max);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly sort using text search on 2.6 or higher in find","suites":["Find"],"updatePoint":{"line":2530,"column":70,"index":82595},"line":2530,"code":"  it('Should correctly sort using text search on 2.6 or higher in find', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.5.5',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db); // Get the collection\n\n        var collection = db.collection('textSearchWithSort');\n        collection.createIndex({\n          s: 'text'\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.insert([{\n            s: 'spam'\n          }, {\n            s: 'spam eggs and spam'\n          }, {\n            s: 'sausage and eggs'\n          }], function (err) {\n            expect(err).to.not.exist;\n            collection.find({\n              $text: {\n                $search: 'spam'\n              }\n            }, {\n              projection: {\n                _id: false,\n                s: true,\n                score: {\n                  $meta: 'textScore'\n                }\n              }\n            }).sort({\n              score: {\n                $meta: 'textScore'\n              }\n            }).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal('spam eggs and spam', items[0].s);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"shouldNotMutateUserOptions","suites":["Find"],"updatePoint":{"line":2586,"column":32,"index":84259},"line":2586,"code":"  it('shouldNotMutateUserOptions', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('shouldNotMutateUserOptions');\n        var options = {\n          raw: 'TEST'\n        };\n        collection.find({}, options);\n        expect(options.skip).to.not.exist;\n        expect(options.limit).to.not.exist;\n        test.equal('TEST', options.raw);\n        client.close(done);\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute a findOneAndUpdateWithAWriteConcern","suites":["Find"],"updatePoint":{"line":2615,"column":66,"index":85165},"line":2615,"code":"  it('should correctly execute a findOneAndUpdateWithAWriteConcern', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_find_and_modify_a_document_3', function (err, collection) {\n          // Test return new document on change\n          collection.insert({\n            a: 1,\n            b: 2\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // Let's modify the document in place\n\n            collection.findOneAndUpdate({\n              a: 1\n            }, {\n              $set: {\n                b: 3\n              }\n            }, {\n              returnDocument: ReturnDocument.AFTER\n            }, function (err, updated_doc) {\n              test.equal(1, updated_doc.value.a);\n              test.equal(3, updated_doc.value.b);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"should execute query using batchSize of 0","suites":["Find"],"updatePoint":{"line":2658,"column":47,"index":86458},"line":2658,"code":"  it('should execute query using batchSize of 0', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        const collection = db.collection('test_find_simple_batchsize_0'); // Insert some test documents\n\n        collection.insert([{\n          a: 2\n        }, {\n          b: 3\n        }, {\n          b: 4\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist; // Ensure correct insertion testing via the cursor and the count function\n\n          collection.find().batchSize(-5).toArray(function (err, documents) {\n            expect(err).to.not.exist;\n            test.equal(3, documents.length); // Let's close the db\n\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"should execute query using limit of 0","suites":["Find"],"updatePoint":{"line":2696,"column":43,"index":87594},"line":2696,"code":"  it('should execute query using limit of 0', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        const collection = db.collection('test_find_simple_limit_0'); // Insert some test documents\n\n        collection.insert([{\n          a: 2\n        }, {\n          b: 3\n        }, {\n          b: 4\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist; // Ensure correct insertion testing via the cursor and the count function\n\n          collection.find().limit(-5).toArray(function (err, documents) {\n            expect(err).to.not.exist;\n            test.equal(3, documents.length); // Let's close the db\n\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"should execute query using $elemMatch","suites":["Find"],"updatePoint":{"line":2734,"column":43,"index":88722},"line":2734,"code":"  it('should execute query using $elemMatch', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        const collection = db.collection('elem_match_test'); // Insert some test documents\n\n        collection.insert([{\n          _id: 1,\n          results: [82, 85, 88]\n        }, {\n          _id: 2,\n          results: [75, 88, 89]\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist; // Ensure correct insertion testing via the cursor and the count function\n\n          collection.find({\n            results: {\n              $elemMatch: {\n                $gte: 80,\n                $lt: 85\n              }\n            }\n          }).toArray(function (err, documents) {\n            expect(err).to.not.exist;\n            test.deepEqual([{\n              _id: 1,\n              results: [82, 85, 88]\n            }], documents); // Let's close the db\n\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"should execute query using limit of 101","suites":["Find"],"updatePoint":{"line":2782,"column":45,"index":90090},"line":2782,"code":"  it('should execute query using limit of 101', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        const collection = db.collection('test_find_simple_limit_101');\n\n        function clone(obj) {\n          var o = {};\n\n          for (var name in obj) o[name] = obj[name];\n\n          return o;\n        }\n\n        var template = {\n          linkid: '12633170',\n          advertisercid: '4612127',\n          websitename: 'Car Rental 8',\n          destinationurl: 'https://www.carrental8.com/en/',\n          who: '8027061-12633170-1467924618000',\n          href: 'http://www.tkqlhce.com',\n          src: 'http://www.awltovhc.com',\n          r1: 3,\n          r2: 44,\n          r3: 24,\n          r4: 58\n        };\n        var docs = [];\n\n        for (var i = 0; i < 1000; i++) {\n          docs.push(clone(template));\n        } // Insert some test documents\n\n\n        collection.insertMany(docs, configuration.writeConcernMax(), function (err, r) {\n          expect(err).to.not.exist;\n          test.ok(r); // Ensure correct insertion testing via the cursor and the count function\n\n          collection.find().limit(200).toArray(function (err, documents) {\n            expect(err).to.not.exist;\n            test.equal(200, documents.length); // Let's close the db\n\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply db level options to find cursor","suites":["Find"],"updatePoint":{"line":2843,"column":60,"index":91846},"line":2843,"code":"  it('Should correctly apply db level options to find cursor', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient({}, {\n        ignoreUndefined: true\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('test_find_simple_cursor_inheritance'); // Insert some test documents\n\n        collection.insert([{\n          a: 2\n        }, {\n          b: 3,\n          c: undefined\n        }], function (err) {\n          expect(err).to.not.exist; // Ensure correct insertion testing via the cursor and the count function\n\n          var cursor = collection.find({\n            c: undefined\n          });\n          cursor.toArray(function (err, documents) {\n            test.equal(2, documents.length); // Let's close the db\n\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"should respect client-level read preference","suites":["Find"],"updatePoint":{"line":2878,"column":49,"index":92862},"line":2878,"code":"  it('should respect client-level read preference', {\n    metadata: {\n      requires: {\n        topology: ['replicaset']\n      }\n    },\n    test: function (done) {\n      const config = this.configuration;\n      const client = config.newClient({}, {\n        monitorCommands: true,\n        readPreference: 'secondary'\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        let selectedServer;\n        const topology = client.topology;\n        const selectServerStub = sinon.stub(topology, 'selectServer').callsFake(function () {\n          const args = Array.prototype.slice.call(arguments);\n          const originalCallback = args.pop();\n          args.push((err, server) => {\n            selectedServer = server;\n            originalCallback(err, server);\n          });\n          return topology.selectServer.wrappedMethod.apply(this, args);\n        });\n        const collection = client.db().collection('test_read_preference');\n        collection.find().toArray(err => {\n          expect(err).to.not.exist;\n          expect(selectedServer.description.type).to.eql('RSSecondary');\n          client.close(err => {\n            selectServerStub.restore();\n            done(err);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/find.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute Collection.prototype.insertOne","suites":["crud - insert","insert promise tests"],"updatePoint":{"line":76,"column":63,"index":1793},"line":76,"code":"    it('Should correctly execute Collection.prototype.insertOne', function (done) {\n      const configuration = this.configuration;\n      let url = configuration.url();\n      url = url.indexOf('?') !== -1 ? f('%s&%s', url, 'maxPoolSize=100') : f('%s?%s', url, 'maxPoolSize=100');\n      const client = configuration.newClient(url);\n      client.connect().then(function (client) {\n        const db = client.db(configuration.db);\n        db.collection('insertOne').insertOne({\n          a: 1\n        }).then(function (r) {\n          expect(r).property('insertedId').to.exist;\n          client.close(done);\n        });\n      });\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should correctly return failing Promise when no document array passed into insertMany","suites":["crud - insert","insert promise tests"],"updatePoint":{"line":91,"column":93,"index":2456},"line":91,"code":"    it('Should correctly return failing Promise when no document array passed into insertMany', function (done) {\n      const configuration = this.configuration;\n      let url = configuration.url();\n      url = url.indexOf('?') !== -1 ? f('%s&%s', url, 'maxPoolSize=100') : f('%s?%s', url, 'maxPoolSize=100');\n      const client = configuration.newClient(url);\n      client.connect().then(() => {\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        expect(() => {\n          db.collection('insertMany_Promise_error').insertMany({\n            a: 1\n          });\n        }).to.throw(/Argument \"docs\" must be an array of documents/);\n        done();\n      });\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformSingleInsert","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":112,"column":42,"index":3250},"line":112,"code":"    it('shouldCorrectlyPerformSingleInsert', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyPerformSingleInsert');\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.findOne(function (err, item) {\n              test.equal(1, item.a);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleMultipleDocumentInsert","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":140,"column":51,"index":4285},"line":140,"code":"    it('shouldCorrectlyHandleMultipleDocumentInsert', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_multiple_insert');\n          var docs = [{\n            a: 1\n          }, {\n            a: 2\n          }];\n          collection.insert(docs, configuration.writeConcernMax(), function (err, r) {\n            expect(r).property('insertedCount').to.equal(2);\n            test.ok(r.insertedIds[0]._bsontype === 'ObjectID');\n            test.ok(r.insertedIds[1]._bsontype === 'ObjectID'); // Let's ensure we have both documents\n\n            collection.find().toArray(function (err, docs) {\n              test.equal(2, docs.length);\n              var results = []; // Check that we have all the results we want\n\n              docs.forEach(function (doc) {\n                if (doc.a === 1 || doc.a === 2) results.push(1);\n              });\n              test.equal(2, results.length); // Let's close the db\n\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertAndRetrieveLargeIntegratedArrayDocument","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":181,"column":68,"index":5864},"line":181,"code":"    it('shouldCorrectlyInsertAndRetrieveLargeIntegratedArrayDocument', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_should_deserialize_large_integrated_array');\n          var doc = {\n            a: 0,\n            b: ['tmp1', 'tmp2', 'tmp3', 'tmp4', 'tmp5', 'tmp6', 'tmp7', 'tmp8', 'tmp9', 'tmp10', 'tmp11', 'tmp12', 'tmp13', 'tmp14', 'tmp15', 'tmp16']\n          }; // Insert the collection\n\n          collection.insert(doc, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // Fetch and check the collection\n\n            collection.findOne({\n              a: 0\n            }, function (err, result) {\n              test.deepEqual(doc.a, result.a);\n              test.deepEqual(doc.b, result.b);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertAndRetrieveDocumentWithAllTypes","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":216,"column":60,"index":7253},"line":216,"code":"    it('shouldCorrectlyInsertAndRetrieveDocumentWithAllTypes', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_all_serialization_types');\n          var date = new Date();\n          var oid = new ObjectId();\n          var string = 'binstring';\n          var bin = new Binary();\n\n          for (var index = 0; index < string.length; index++) {\n            bin.put(string.charAt(index));\n          }\n\n          var motherOfAllDocuments = {\n            string: 'hello',\n            array: [1, 2, 3],\n            hash: {\n              a: 1,\n              b: 2\n            },\n            date: date,\n            oid: oid,\n            binary: bin,\n            int: 42,\n            float: 33.3333,\n            regexp: /regexp/,\n            boolean: true,\n            long: date.getTime(),\n            where: new Code('this.a > i', {\n              i: 1\n            }),\n            dbref: new DBRef('namespace', oid, 'integration_tests_')\n          };\n          collection.insert(motherOfAllDocuments, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.findOne(function (err, doc) {\n              // Assert correct deserialization of the values\n              test.equal(motherOfAllDocuments.string, doc.string);\n              test.deepEqual(motherOfAllDocuments.array, doc.array);\n              test.equal(motherOfAllDocuments.hash.a, doc.hash.a);\n              test.equal(motherOfAllDocuments.hash.b, doc.hash.b);\n              test.equal(date.getTime(), doc.long);\n              test.equal(date.toString(), doc.date.toString());\n              test.equal(date.getTime(), doc.date.getTime());\n              test.equal(motherOfAllDocuments.oid.toHexString(), doc.oid.toHexString());\n              test.equal(motherOfAllDocuments.binary.value(), doc.binary.value());\n              test.equal(motherOfAllDocuments.int, doc.int);\n              test.equal(motherOfAllDocuments.long, doc.long);\n              test.equal(motherOfAllDocuments.float, doc.float);\n              test.equal(motherOfAllDocuments.regexp.toString(), doc.regexp.toString());\n              test.equal(motherOfAllDocuments.boolean, doc.boolean);\n              test.equal(motherOfAllDocuments.where.code, doc.where.code);\n              test.equal(motherOfAllDocuments.where.scope['i'], doc.where.scope.i);\n              test.equal(motherOfAllDocuments.dbref.namespace, doc.dbref.namespace);\n              test.equal(motherOfAllDocuments.dbref.oid.toHexString(), doc.dbref.oid.toHexString());\n              test.equal(motherOfAllDocuments.dbref.db, doc.dbref.db);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertAndUpdateDocumentWithNewScriptContext","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":290,"column":66,"index":10498},"line":290,"code":"    it('shouldCorrectlyInsertAndUpdateDocumentWithNewScriptContext', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db); //convience curried handler for functions of type 'a -> (err, result)\n\n          function getResult(callback) {\n            return function (error, result) {\n              test.ok(error == null);\n              return callback(result);\n            };\n          }\n\n          db.createCollection('users', getResult(function (user_collection) {\n            user_collection.remove({}, configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist; //first, create a user object\n\n              var newUser = {\n                name: 'Test Account',\n                settings: {}\n              };\n              user_collection.insert([newUser], configuration.writeConcernMax(), getResult(function () {\n                var scriptCode = \"settings.block = []; settings.block.push('test');\";\n                var context = {\n                  settings: {\n                    thisOneWorks: 'somestring'\n                  }\n                };\n                Script.runInNewContext(scriptCode, context, 'testScript'); //now create update command and issue it\n\n                var updateCommand = {\n                  $set: context\n                };\n                user_collection.update({\n                  _id: newUser._id\n                }, updateCommand, configuration.writeConcernMax(), getResult(function () {\n                  // Fetch the object and check that the changes are persisted\n                  user_collection.findOne({\n                    _id: newUser._id\n                  }, function (err, doc) {\n                    test.ok(err == null);\n                    test.equal('Test Account', doc.name);\n                    test.equal('somestring', doc.settings.thisOneWorks);\n                    test.equal('test', doc.settings.block[0]);\n                    client.close(done);\n                  });\n                }));\n              }));\n            });\n          }));\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlySerializeDocumentWithAllTypesInNewContext","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":353,"column":64,"index":13062},"line":353,"code":"    it('shouldCorrectlySerializeDocumentWithAllTypesInNewContext', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_all_serialization_types_new_context');\n          var date = new Date();\n          var scriptCode = \"var string = 'binstring'\\n\" + 'var bin = new mongo.Binary()\\n' + 'for(var index = 0; index < string.length; index++) {\\n' + '  bin.put(string.charAt(index))\\n' + '}\\n' + \"motherOfAllDocuments['string'] = 'hello';\" + \"motherOfAllDocuments['array'] = [1,2,3];\" + \"motherOfAllDocuments['hash'] = {'a':1, 'b':2};\" + \"motherOfAllDocuments['date'] = date;\" + \"motherOfAllDocuments['oid'] = new mongo.ObjectId();\" + \"motherOfAllDocuments['binary'] = bin;\" + \"motherOfAllDocuments['int'] = 42;\" + \"motherOfAllDocuments['float'] = 33.3333;\" + \"motherOfAllDocuments['regexp'] = /regexp/;\" + \"motherOfAllDocuments['boolean'] = true;\" + \"motherOfAllDocuments['long'] = motherOfAllDocuments['date'].getTime();\" + \"motherOfAllDocuments['where'] = new mongo.Code('this.a > i', {i:1});\" + \"motherOfAllDocuments['dbref'] = new mongo.DBRef('namespace', motherOfAllDocuments['oid'], 'integration_tests_');\";\n          var context = {\n            motherOfAllDocuments: {},\n            mongo: {\n              ObjectId: ObjectId,\n              Binary: Binary,\n              Code: Code,\n              DBRef: DBRef\n            },\n            date: date\n          }; // Execute function in context\n\n          Script.runInNewContext(scriptCode, context, 'testScript'); // sys.puts(sys.inspect(context.motherOfAllDocuments))\n\n          var motherOfAllDocuments = context.motherOfAllDocuments;\n          collection.insert(context.motherOfAllDocuments, configuration.writeConcernMax(), function (err, docs) {\n            test.ok(docs);\n            collection.findOne(function (err, doc) {\n              // Assert correct deserialization of the values\n              test.equal(motherOfAllDocuments.string, doc.string);\n              test.deepEqual(motherOfAllDocuments.array, doc.array);\n              test.equal(motherOfAllDocuments.hash.a, doc.hash.a);\n              test.equal(motherOfAllDocuments.hash.b, doc.hash.b);\n              test.equal(date.getTime(), doc.long);\n              test.equal(date.toString(), doc.date.toString());\n              test.equal(date.getTime(), doc.date.getTime());\n              test.equal(motherOfAllDocuments.oid.toHexString(), doc.oid.toHexString());\n              test.equal(motherOfAllDocuments.binary.value(), doc.binary.value());\n              test.equal(motherOfAllDocuments.int, doc.int);\n              test.equal(motherOfAllDocuments.long, doc.long);\n              test.equal(motherOfAllDocuments.float, doc.float);\n              test.equal(motherOfAllDocuments.regexp.toString(), doc.regexp.toString());\n              test.equal(motherOfAllDocuments.boolean, doc.boolean);\n              test.equal(motherOfAllDocuments.where.code, doc.where.code);\n              test.equal(motherOfAllDocuments.where.scope['i'], doc.where.scope.i);\n              test.equal(motherOfAllDocuments.dbref.namespace, doc.dbref.namespace);\n              test.equal(motherOfAllDocuments.dbref.oid.toHexString(), doc.dbref.oid.toHexString());\n              test.equal(motherOfAllDocuments.dbref.db, doc.dbref.db);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDoToJsonForLongValue","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":414,"column":43,"index":16922},"line":414,"code":"    it('shouldCorrectlyDoToJsonForLongValue', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_to_json_for_long');\n          collection.insert([{\n            value: Long.fromNumber(32222432)\n          }], configuration.writeConcernMax(), function (err, ids) {\n            test.ok(ids);\n            collection.findOne({}, function (err, item) {\n              test.equal(32222432, item.value);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldInsertAndQueryTimestamp","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":442,"column":37,"index":17968},"line":442,"code":"    it('shouldInsertAndQueryTimestamp', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_insert_and_query_timestamp'); // Insert the update\n\n          collection.insert({\n            i: Timestamp.fromNumber(100),\n            j: Long.fromNumber(200)\n          }, configuration.writeConcernMax(), function (err, r) {\n            test.ok(r); // Locate document\n\n            collection.findOne({}, function (err, item) {\n              test.ok(item.i._bsontype === 'Timestamp');\n              test.equal(100, item.i.toInt());\n              test.equal(200, item.j);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertAndQueryUndefined","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":475,"column":46,"index":19197},"line":475,"code":"    it('shouldCorrectlyInsertAndQueryUndefined', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_insert_and_query_undefined'); // Insert the update\n\n          collection.insert({\n            i: undefined\n          }, configuration.writeConcernMax(), function (err, r) {\n            expect(err).to.not.exist;\n            test.ok(r); // Locate document\n\n            collection.findOne({}, function (err, item) {\n              expect(item.i).to.not.exist;\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlySerializeDBRefToJSON","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":506,"column":43,"index":20308},"line":506,"code":"    it('shouldCorrectlySerializeDBRefToJSON', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var dbref = new DBRef('foo', ObjectId.createFromHexString('fc24a04d4560531f00000000'), null);\n        JSON.stringify(dbref);\n        done();\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldThrowErrorIfSerializingFunctionOrdered","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":520,"column":52,"index":20837},"line":520,"code":"    it('shouldThrowErrorIfSerializingFunctionOrdered', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_should_throw_error_if_serializing_function');\n\n          var func = function () {\n            return 1;\n          }; // Insert the update\n\n\n          collection.insert({\n            i: 1,\n            z: func\n          }, {\n            writeConcern: {\n              w: 1\n            },\n            serializeFunctions: true\n          }, function (err, result) {\n            expect(err).to.not.exist;\n            collection.findOne({\n              _id: result.insertedIds[0]\n            }, function (err, object) {\n              expect(err).to.not.exist;\n              test.equal(normalizedFunctionString(func), object.z.code);\n              test.equal(1, object.i);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldThrowErrorIfSerializingFunctionUnOrdered","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":564,"column":54,"index":22267},"line":564,"code":"    it('shouldThrowErrorIfSerializingFunctionUnOrdered', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_should_throw_error_if_serializing_function_1');\n\n          var func = function () {\n            return 1;\n          }; // Insert the update\n\n\n          collection.insert({\n            i: 1,\n            z: func\n          }, {\n            writeConcern: {\n              w: 1\n            },\n            serializeFunctions: true,\n            ordered: false\n          }, function (err, result) {\n            expect(err).to.not.exist;\n            collection.findOne({\n              _id: result.insertedIds[0]\n            }, function (err, object) {\n              expect(err).to.not.exist;\n              test.equal(normalizedFunctionString(func), object.z.code);\n              test.equal(1, object.i);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertDocumentWithUUID","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":609,"column":45,"index":23707},"line":609,"code":"    it('shouldCorrectlyInsertDocumentWithUUID', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('insert_doc_with_uuid');\n          collection.insert({\n            _id: '12345678123456781234567812345678',\n            field: '1'\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.find({\n              _id: '12345678123456781234567812345678'\n            }).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(items[0]._id, '12345678123456781234567812345678');\n              test.equal(items[0].field, '1'); // Generate a binary id\n\n              var binaryUUID = new Binary('00000078123456781234567812345678', Binary.SUBTYPE_UUID);\n              collection.insert({\n                _id: binaryUUID,\n                field: '2'\n              }, configuration.writeConcernMax(), function (err, result) {\n                expect(err).to.not.exist;\n                test.ok(result);\n                collection.find({\n                  _id: binaryUUID\n                }).toArray(function (err, items) {\n                  expect(err).to.not.exist;\n                  test.equal(items[0].field, '2');\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCallCallbackWithDbDriverInStrictMode","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":658,"column":59,"index":25660},"line":658,"code":"    it('shouldCorrectlyCallCallbackWithDbDriverInStrictMode', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('test_insert_and_update_no_callback_strict');\n          collection.insert({\n            _id: '12345678123456781234567812345678',\n            field: '1'\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.updateOne({\n              _id: '12345678123456781234567812345678'\n            }, {\n              $set: {\n                field: 0\n              }\n            }, configuration.writeConcernMax(), function (err, r) {\n              expect(err).to.not.exist;\n              expect(r).property('matchedCount').to.equal(1);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertDBRefWithDbNotDefined","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":695,"column":50,"index":27045},"line":695,"code":"    it('shouldCorrectlyInsertDBRefWithDbNotDefined', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyInsertDBRefWithDbNotDefined');\n          var doc = {\n            _id: new ObjectId()\n          };\n          var doc2 = {\n            _id: new ObjectId()\n          };\n          var doc3 = {\n            _id: new ObjectId()\n          };\n          collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result); // Create object with dbref\n\n            doc2.ref = new DBRef('shouldCorrectlyInsertDBRefWithDbNotDefined', doc._id);\n            doc3.ref = new DBRef('shouldCorrectlyInsertDBRefWithDbNotDefined', doc._id, configuration.db_name);\n            collection.insert([doc2, doc3], configuration.writeConcernMax(), function (err, result) {\n              expect(err).to.not.exist;\n              test.ok(result); // Get all items\n\n              collection.find().toArray(function (err, items) {\n                test.equal('shouldCorrectlyInsertDBRefWithDbNotDefined', items[1].ref.namespace);\n                test.equal(doc._id.toString(), items[1].ref.oid.toString());\n                expect(items[1].ref.db).to.not.exist;\n                test.equal('shouldCorrectlyInsertDBRefWithDbNotDefined', items[2].ref.namespace);\n                test.equal(doc._id.toString(), items[2].ref.oid.toString());\n                expect(items[2].ref.db).to.not.exist;\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertUpdateRemoveWithNoOptions","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":744,"column":54,"index":29176},"line":744,"code":"    it('shouldCorrectlyInsertUpdateRemoveWithNoOptions', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyInsertUpdateRemoveWithNoOptions');\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.update({\n              a: 1\n            }, {\n              $set: {\n                a: 2\n              }\n            }, configuration.writeConcernMax(), function (err, result) {\n              expect(err).to.not.exist;\n              test.ok(result);\n              collection.remove({\n                a: 2\n              }, configuration.writeConcernMax(), function (err, result) {\n                expect(err).to.not.exist;\n                test.ok(result);\n                collection.count(function (err, count) {\n                  test.equal(0, count);\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteMultipleFetches","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":789,"column":45,"index":30778},"line":789,"code":"    it('shouldCorrectlyExecuteMultipleFetches', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        // Search parameter\n        var to = 'ralph';\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyExecuteMultipleFetches'); // Execute query\n\n          collection.insert({\n            addresses: {\n              localPart: 'ralph'\n            }\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result); // Let's find our user\n\n            collection.findOne({\n              'addresses.localPart': to\n            }, function (err, doc) {\n              expect(err).to.not.exist;\n              test.equal(to, doc.addresses.localPart);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyFailWhenNoObjectToUpdate","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":827,"column":47,"index":32114},"line":827,"code":"    it('shouldCorrectlyFailWhenNoObjectToUpdate', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyFailWhenNoObjectToUpdate');\n          collection.update({\n            _id: new ObjectId()\n          }, {\n            $set: {\n              email: 'update'\n            }\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            expect(result).property('matchedCount').to.equal(0);\n            client.close(done);\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should correctly insert object and retrieve it when containing array and IsoDate","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":857,"column":88,"index":33249},"line":857,"code":"    it('Should correctly insert object and retrieve it when containing array and IsoDate', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var doc = {\n          _id: new ObjectId('4e886e687ff7ef5e00000162'),\n          str: 'foreign',\n          type: 2,\n          timestamp: ISODate('2011-10-02T14:00:08.383Z'),\n          links: ['http://www.reddit.com/r/worldnews/comments/kybm0/uk_home_secretary_calls_for_the_scrapping_of_the/']\n        };\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('Should_correctly_insert_object_and_retrieve_it_when_containing_array_and_IsoDate');\n          collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n            test.ok(err == null);\n            test.ok(result);\n            collection.findOne(function (err, item) {\n              test.ok(err == null);\n              test.deepEqual(doc, item);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should correctly insert object with timestamps","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":892,"column":54,"index":34690},"line":892,"code":"    it('Should correctly insert object with timestamps', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var doc = {\n          _id: new ObjectId('4e886e687ff7ef5e00000162'),\n          str: 'foreign',\n          type: 2,\n          timestamp: new Timestamp(10000),\n          links: ['http://www.reddit.com/r/worldnews/comments/kybm0/uk_home_secretary_calls_for_the_scrapping_of_the/'],\n          timestamp2: new Timestamp(33333)\n        };\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('Should_correctly_insert_object_with_timestamps');\n          collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n            test.ok(err == null);\n            test.ok(result);\n            collection.findOne(function (err, item) {\n              test.ok(err == null);\n              test.deepEqual(doc, item);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly allow for control of serialization of functions on command level","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":928,"column":89,"index":36161},"line":928,"code":"    it('Should Correctly allow for control of serialization of functions on command level', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var doc = {\n          str: 'String',\n          func: function () {}\n        };\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('Should_Correctly_allow_for_control_of_serialization_of_functions_on_command_level');\n          collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.update({\n              str: 'String'\n            }, {\n              $set: {\n                c: 1,\n                d: function () {}\n              }\n            }, {\n              writeConcern: {\n                w: 1\n              },\n              serializeFunctions: false\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              expect(result).property('matchedCount').to.equal(1);\n              collection.findOne({\n                str: 'String'\n              }, function (err, item) {\n                expect(item.d).to.not.exist; // Execute a safe insert with replication to two servers\n\n                collection.findOneAndUpdate({\n                  str: 'String'\n                }, {\n                  $set: {\n                    f: function () {}\n                  }\n                }, {\n                  returnDocument: ReturnDocument.AFTER,\n                  safe: true,\n                  serializeFunctions: true\n                }, function (err, result) {\n                  test.ok(result.value.f._bsontype === 'Code');\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly allow for control of serialization of functions on collection level","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":991,"column":92,"index":38424},"line":991,"code":"    it('Should Correctly allow for control of serialization of functions on collection level', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var doc = {\n          str: 'String',\n          func: function () {}\n        };\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('Should_Correctly_allow_for_control_of_serialization_of_functions_on_collection_level', {\n            serializeFunctions: true\n          });\n          collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({\n              str: 'String'\n            }, function (err, item) {\n              test.ok(item.func._bsontype === 'Code');\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly allow for using a Date object as _id","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1026,"column":61,"index":39731},"line":1026,"code":"    it('Should Correctly allow for using a Date object as _id', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var doc = {\n          _id: new Date(),\n          str: 'hello'\n        };\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('Should_Correctly_allow_for_using_a_Date_object_as__id');\n          collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({\n              str: 'hello'\n            }, function (err, item) {\n              test.ok(item._id instanceof Date);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly fail to update returning 0 results","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1059,"column":59,"index":40940},"line":1059,"code":"    it('Should Correctly fail to update returning 0 results', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('Should_Correctly_fail_to_update_returning_0_results');\n          collection.updateMany({\n            a: 1\n          }, {\n            $set: {\n              a: 1\n            }\n          }, configuration.writeConcernMax(), function (err, r) {\n            expect(r).property('matchedCount').to.equal(0);\n            client.close(done);\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly update two fields including a sub field","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1088,"column":64,"index":41993},"line":1088,"code":"    it('Should Correctly update two fields including a sub field', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var doc = {\n          _id: new ObjectId(),\n          Prop1: 'p1',\n          Prop2: 'p2',\n          More: {\n            Sub1: 's1',\n            Sub2: 's2',\n            Sub3: 's3'\n          }\n        };\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('Should_Correctly_update_two_fields_including_a_sub_field');\n          collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result); // Update two fields\n\n            collection.update({\n              _id: doc._id\n            }, {\n              $set: {\n                Prop1: 'p1_2',\n                'More.Sub2': 's2_2'\n              }\n            }, configuration.writeConcernMax(), function (err, r) {\n              expect(err).to.not.exist;\n              expect(r).property('matchedCount').to.equal(1);\n              collection.findOne({\n                _id: doc._id\n              }, function (err, item) {\n                expect(err).to.not.exist;\n                test.equal('p1_2', item.Prop1);\n                test.equal('s2_2', item.More.Sub2);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should correctly fail due to duplicate key for _id","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1141,"column":58,"index":43824},"line":1141,"code":"    it('Should correctly fail due to duplicate key for _id', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('Should_Correctly_update_two_fields_including_a_sub_field_2');\n          collection.insertOne({\n            _id: 1\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result); // Update two fields\n\n            collection.insertOne({\n              _id: 1\n            }, configuration.writeConcernMax(), function (err, r) {\n              expect(err).to.exist;\n              expect(r).to.not.exist;\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertDocWithCustomId","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1174,"column":44,"index":45047},"line":1174,"code":"    it('shouldCorrectlyInsertDocWithCustomId', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyInsertDocWithCustomId'); // Insert the update\n\n          collection.insert({\n            _id: 0,\n            test: 'hello'\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({\n              _id: 0\n            }, function (err, item) {\n              test.equal(0, item._id);\n              test.equal('hello', item.test);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformUpsertAgainstNewDocumentAndExistingOne","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1208,"column":68,"index":46275},"line":1208,"code":"    it('shouldCorrectlyPerformUpsertAgainstNewDocumentAndExistingOne', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyPerformUpsertAgainstNewDocumentAndExistingOne'); // Upsert a new doc\n\n          collection.update({\n            a: 1\n          }, {\n            $set: {\n              a: 1\n            }\n          }, {\n            upsert: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, result) {\n            expect(err).to.not.exist;\n            expect(result).property('upsertedCount').to.equal(1); // Upsert an existing doc\n\n            collection.update({\n              a: 1\n            }, {\n              $set: {\n                a: 1\n              }\n            }, {\n              upsert: true,\n              writeConcern: {\n                w: 1\n              }\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              expect(result).property('matchedCount').to.equal(1);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformLargeTextInsert","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1260,"column":45,"index":47884},"line":1260,"code":"    it('shouldCorrectlyPerformLargeTextInsert', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyPerformLargeTextInsert'); // Create large string, insert and then retrive\n\n          var string = ''; // Create large text field\n\n          for (var i = 0; i < 50000; i++) {\n            string = string + 'a';\n          }\n\n          collection.insert({\n            a: 1,\n            string: string\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({\n              a: 1\n            }, function (err, doc) {\n              expect(err).to.not.exist;\n              test.equal(50000, doc.string.length);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformInsertOfObjectsUsingToBSON","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1300,"column":56,"index":49278},"line":1300,"code":"    it('shouldCorrectlyPerformInsertOfObjectsUsingToBSON', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyPerformInsertOfObjectsUsingToBSON'); // Create document with toBSON method\n\n          var doc = {\n            a: 1,\n            b: 1\n          };\n\n          doc.toBSON = function () {\n            return {\n              c: this.a\n            };\n          };\n\n          collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({\n              c: 1\n            }, function (err, doc) {\n              expect(err).to.not.exist;\n              test.deepEqual(1, doc.c);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldAttempToForceBsonSize","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1342,"column":35,"index":50620},"line":1342,"code":"    it('shouldAttempToForceBsonSize', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: 'single'\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          db.createCollection('shouldAttempToForceBsonSize', function (err, collection) {\n            // var doc = {a:1, b:new Binary(Buffer.alloc(16777216)/5)}\n            var doc = [{\n              a: 1,\n              b: new Binary(Buffer.alloc(16777216 / 3))\n            }, {\n              a: 1,\n              b: new Binary(Buffer.alloc(16777216 / 3))\n            }, {\n              a: 1,\n              b: new Binary(Buffer.alloc(16777216 / 3))\n            }];\n            collection.insert(doc, configuration.writeConcernMax(), function (err, result) {\n              expect(err).to.not.exist;\n              test.ok(result);\n              collection.findOne({\n                a: 1\n              }, function (err, doc) {\n                expect(err).to.not.exist;\n                test.deepEqual(1, doc.a);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUseCustomObjectToUpdateDocument","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1384,"column":54,"index":52110},"line":1384,"code":"    it('shouldCorrectlyUseCustomObjectToUpdateDocument', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyUseCustomObjectToUpdateDocument');\n          collection.insert({\n            a: {\n              b: {\n                c: 1\n              }\n            }\n          }, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result); // Dynamically build query\n\n            var query = {};\n            query['a'] = {};\n            query.a['b'] = {};\n            query.a.b['c'] = 1; // Update document\n\n            collection.update(query, {\n              $set: {\n                'a.b.d': 1\n              }\n            }, configuration.writeConcernMax(), function (err, r) {\n              expect(err).to.not.exist;\n              expect(r).property('matchedCount').to.equal(1);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldExecuteInsertWithNoCallbackAndWriteConcern","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1428,"column":56,"index":53620},"line":1428,"code":"    it('shouldExecuteInsertWithNoCallbackAndWriteConcern', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldExecuteInsertWithNoCallbackAndWriteConcern');\n          collection.insert({\n            a: {\n              b: {\n                c: 1\n              }\n            }\n          }).then(() => {\n            client.close(done);\n          }, err => {\n            client.close(err2 => done(err || err2));\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"executesCallbackOnceWithOveriddenDefaultDbWriteConcern","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1458,"column":62,"index":54641},"line":1458,"code":"    it('executesCallbackOnceWithOveriddenDefaultDbWriteConcern', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        function cb(err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        }\n\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('gh-completely2');\n          collection.insert({\n            a: 1\n          }, {\n            writeConcern: {\n              w: 0\n            }\n          }, cb);\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"executesCallbackOnceWithOveriddenDefaultDbWriteConcernWithUpdate","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1489,"column":72,"index":55608},"line":1489,"code":"    it('executesCallbackOnceWithOveriddenDefaultDbWriteConcernWithUpdate', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        function cb(err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        }\n\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('gh-completely3');\n          collection.update({\n            a: 1\n          }, {\n            $set: {\n              a: 2\n            }\n          }, {\n            upsert: true,\n            writeConcern: {\n              w: 0\n            }\n          }, cb);\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"executesCallbackOnceWithOveriddenDefaultDbWriteConcernWithRemove","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1525,"column":72,"index":56669},"line":1525,"code":"    it('executesCallbackOnceWithOveriddenDefaultDbWriteConcernWithRemove', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        function cb(err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        }\n\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('gh-completely1');\n          collection.remove({\n            a: 1\n          }, {\n            writeConcern: {\n              w: 0\n            }\n          }, cb);\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"handleBSONTypeInsertsCorrectly","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1556,"column":38,"index":57602},"line":1556,"code":"    it('handleBSONTypeInsertsCorrectly', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger'],\n          mongodb: '<2.8.0'\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('bson_types_insert');\n          var document = {\n            symbol: new BSONSymbol('abcdefghijkl'),\n            objid: new ObjectId('abcdefghijkl'),\n            double: new Double(1),\n            binary: new Binary(Buffer.from('hello world')),\n            minkey: new MinKey(),\n            maxkey: new MaxKey(),\n            code: new Code('function () {}', {\n              a: 55\n            })\n          };\n          collection.insert(document, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({\n              symbol: new BSONSymbol('abcdefghijkl')\n            }, function (err, doc) {\n              expect(err).to.not.exist;\n              test.equal('abcdefghijkl', doc.symbol.toString());\n              collection.findOne({\n                objid: new ObjectId('abcdefghijkl')\n              }, function (err, doc) {\n                expect(err).to.not.exist;\n                test.equal('6162636465666768696a6b6c', doc.objid.toString());\n                collection.findOne({\n                  double: new Double(1)\n                }, function (err, doc) {\n                  expect(err).to.not.exist;\n                  test.equal(1, doc.double);\n                  collection.findOne({\n                    binary: new Binary(Buffer.from('hello world'))\n                  }, function (err, doc) {\n                    expect(err).to.not.exist;\n                    test.equal('hello world', doc.binary.toString());\n                    collection.findOne({\n                      minkey: new MinKey()\n                    }, function (err, doc) {\n                      expect(err).to.not.exist;\n                      test.ok(doc.minkey._bsontype === 'MinKey');\n                      collection.findOne({\n                        maxkey: new MaxKey()\n                      }, function (err, doc) {\n                        expect(err).to.not.exist;\n                        test.ok(doc.maxkey._bsontype === 'MaxKey');\n                        collection.findOne({\n                          code: new Code('function () {}', {\n                            a: 55\n                          })\n                        }, function (err, doc) {\n                          expect(err).to.not.exist;\n                          test.ok(doc != null);\n                          client.close(done);\n                        });\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"handleBSONTypeInsertsCorrectlyFor28OrHigher","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1636,"column":51,"index":60858},"line":1636,"code":"    it('handleBSONTypeInsertsCorrectlyFor28OrHigher', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger'],\n          mongodb: '>=2.8.0'\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('bson_types_insert_1');\n          var document = {\n            string: 'abcdefghijkl',\n            objid: new ObjectId('abcdefghijkl'),\n            double: new Double(1),\n            binary: new Binary(Buffer.from('hello world')),\n            minkey: new MinKey(),\n            maxkey: new MaxKey(),\n            code: new Code('function () {}', {\n              a: 55\n            })\n          };\n          collection.insert(document, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({\n              string: 'abcdefghijkl'\n            }, function (err, doc) {\n              expect(err).to.not.exist;\n              test.equal('abcdefghijkl', doc.string.toString());\n              collection.findOne({\n                objid: new ObjectId('abcdefghijkl')\n              }, function (err, doc) {\n                expect(err).to.not.exist;\n                test.equal('6162636465666768696a6b6c', doc.objid.toString());\n                collection.findOne({\n                  double: new Double(1)\n                }, function (err, doc) {\n                  expect(err).to.not.exist;\n                  test.equal(1, doc.double);\n                  collection.findOne({\n                    binary: new Binary(Buffer.from('hello world'))\n                  }, function (err, doc) {\n                    expect(err).to.not.exist;\n                    test.equal('hello world', doc.binary.toString());\n                    collection.findOne({\n                      minkey: new MinKey()\n                    }, function (err, doc) {\n                      expect(err).to.not.exist;\n                      test.ok(doc.minkey._bsontype === 'MinKey');\n                      collection.findOne({\n                        maxkey: new MaxKey()\n                      }, function (err, doc) {\n                        expect(err).to.not.exist;\n                        test.ok(doc.maxkey._bsontype === 'MaxKey');\n                        collection.findOne({\n                          code: new Code('function () {}', {\n                            a: 55\n                          })\n                        }, function (err, doc) {\n                          expect(err).to.not.exist;\n                          test.ok(doc != null);\n                          client.close(done);\n                        });\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"mixedTimestampAndDateQuery","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1716,"column":34,"index":64068},"line":1716,"code":"    it('mixedTimestampAndDateQuery', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('timestamp_date');\n          var d = new Date();\n          var documents = [{\n            x: new Timestamp(1, 2)\n          }, {\n            x: d\n          }];\n          collection.insert(documents, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({\n              x: new Timestamp(1, 2)\n            }, function (err, doc) {\n              expect(err).to.not.exist;\n              test.ok(doc != null);\n              collection.findOne({\n                x: d\n              }, function (err, doc) {\n                expect(err).to.not.exist;\n                test.ok(doc != null);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"positiveAndNegativeInfinity","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1758,"column":35,"index":65510},"line":1758,"code":"    it('positiveAndNegativeInfinity', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('negative_pos');\n          var document = {\n            pos: Number.POSITIVE_INFINITY,\n            neg: Number.NEGATIVE_INFINITY\n          };\n          collection.insert(document, configuration.writeConcernMax(), function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            collection.findOne({}, function (err, doc) {\n              expect(err).to.not.exist;\n              test.equal(Number.POSITIVE_INFINITY, doc.pos);\n              test.equal(Number.NEGATIVE_INFINITY, doc.neg);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertSimpleRegExpDocument","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1791,"column":49,"index":66789},"line":1791,"code":"    it('shouldCorrectlyInsertSimpleRegExpDocument', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var regexp = /foobar/i;\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          db.createCollection('test_regex', function (err, collection) {\n            collection.insert({\n              b: regexp\n            }, configuration.writeConcernMax(), function (err, ids) {\n              expect(err).to.not.exist;\n              test.ok(ids);\n              collection.find({}).project({\n                b: 1\n              }).toArray(function (err, items) {\n                test.equal('' + regexp, '' + items[0].b); // Let's close the db\n\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertSimpleUTF8Regexp","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1825,"column":45,"index":68013},"line":1825,"code":"    it('shouldCorrectlyInsertSimpleUTF8Regexp', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var regexp = /foobaré/;\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var collection = db.collection('shouldCorrectlyInsertSimpleUTF8Regexp');\n          collection.insert({\n            b: regexp\n          }, configuration.writeConcernMax(), function (err, ids) {\n            expect(err).to.not.exist;\n            test.ok(ids);\n            collection.find({}).project({\n              b: 1\n            }).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal('' + regexp, '' + items[0].b); // Let's close the db\n\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyThrowDueToIllegalCollectionName","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1859,"column":54,"index":69258},"line":1859,"code":"    it('shouldCorrectlyThrowDueToIllegalCollectionName', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var k = Buffer.alloc(15);\n\n          for (var i = 0; i < 15; i++) k[i] = 0;\n\n          k.write('hello');\n          k[6] = 0x06;\n          k.write('world', 10);\n\n          try {\n            db.collection(k.toString());\n            test.fail(false);\n          } catch (err) {} // eslint-disable-line\n\n\n          client.close(done);\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHonorPromoteLongFalseNativeBSON","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1892,"column":54,"index":70253},"line":1892,"code":"    it('shouldCorrectlyHonorPromoteLongFalseNativeBSON', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var o = configuration.writeConcernMax();\n        o.promoteLongs = false;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1,\n          promoteLongs: false\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          db.collection('shouldCorrectlyHonorPromoteLong').insert({\n            doc: Long.fromNumber(10),\n            array: [[Long.fromNumber(10)]]\n          }, function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc);\n            db.collection('shouldCorrectlyHonorPromoteLong').findOne(function (err, doc) {\n              expect(err).to.not.exist;\n              test.ok(doc.doc._bsontype === 'Long');\n              test.ok(doc.array[0][0]._bsontype === 'Long');\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHonorPromoteLongFalseNativeBSONWithGetMore","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":1926,"column":65,"index":71588},"line":1926,"code":"    it('shouldCorrectlyHonorPromoteLongFalseNativeBSONWithGetMore', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var o = configuration.writeConcernMax();\n        o.promoteLongs = false;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1,\n          promoteLongs: false\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          db.collection('shouldCorrectlyHonorPromoteLongFalseNativeBSONWithGetMore').insertMany([{\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }, {\n            a: Long.fromNumber(10)\n          }], function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc);\n            db.collection('shouldCorrectlyHonorPromoteLongFalseNativeBSONWithGetMore').find({}).batchSize(2).toArray(function (err, docs) {\n              expect(err).to.not.exist;\n              var doc = docs.pop();\n              test.ok(doc.a._bsontype === 'Long');\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInheritPromoteLongFalseNativeBSONWithGetMore","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2005,"column":67,"index":74083},"line":2005,"code":"    it('shouldCorrectlyInheritPromoteLongFalseNativeBSONWithGetMore', {\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: withClient((client, done) => {\n        const db = client.db('shouldCorrectlyInheritPromoteLongFalseNativeBSONWithGetMore', {\n          promoteLongs: true\n        });\n        const collection = db.collection('test', {\n          promoteLongs: false\n        });\n        collection.insertMany([{\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }, {\n          a: Long.fromNumber(10)\n        }], (err, doc) => {\n          expect(err).to.not.exist;\n          test.ok(doc);\n          collection.find({}).batchSize(2).toArray((err, docs) => {\n            expect(err).to.not.exist;\n            docs.forEach((d, i) => {\n              expect(d.a, `Failed on the document at index ${i}`).to.not.be.a('number');\n              expect(d.a, `Failed on the document at index ${i}`).to.have.property('_bsontype');\n              expect(d.a._bsontype, `Failed on the document at index ${i}`).to.be.equal('Long');\n            });\n            done();\n          });\n        });\n      })\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHonorPromoteLongTrueNativeBSON","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2081,"column":53,"index":76271},"line":2081,"code":"    it('shouldCorrectlyHonorPromoteLongTrueNativeBSON', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          db.collection('shouldCorrectlyHonorPromoteLongTrueNativeBSON').insert({\n            doc: Long.fromNumber(10),\n            array: [[Long.fromNumber(10)]]\n          }, function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc);\n            db.collection('shouldCorrectlyHonorPromoteLongTrueNativeBSON').findOne(function (err, doc) {\n              expect(err).to.not.exist;\n              expect(err).to.not.exist;\n              test.ok('number', typeof doc.doc);\n              test.ok('number', typeof doc.array[0][0]);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHonorPromoteLongFalseJSBSON","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2113,"column":50,"index":77539},"line":2113,"code":"    it('shouldCorrectlyHonorPromoteLongFalseJSBSON', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1,\n          promoteLongs: false\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          db.collection('shouldCorrectlyHonorPromoteLongFalseJSBSON').insert({\n            doc: Long.fromNumber(10),\n            array: [[Long.fromNumber(10)]]\n          }, function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc);\n            db.collection('shouldCorrectlyHonorPromoteLongFalseJSBSON').findOne(function (err, doc) {\n              expect(err).to.not.exist;\n              expect(err).to.not.exist;\n              test.ok(doc.doc._bsontype === 'Long');\n              test.ok(doc.array[0][0]._bsontype === 'Long');\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHonorPromoteLongTrueJSBSON","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2146,"column":49,"index":78839},"line":2146,"code":"    it('shouldCorrectlyHonorPromoteLongTrueJSBSON', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          db.collection('shouldCorrectlyHonorPromoteLongTrueJSBSON').insert({\n            doc: Long.fromNumber(10),\n            array: [[Long.fromNumber(10)]]\n          }, function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc);\n            db.collection('shouldCorrectlyHonorPromoteLongTrueJSBSON').findOne(function (err, doc) {\n              expect(err).to.not.exist;\n              expect(err).to.not.exist;\n              test.ok('number', typeof doc.doc);\n              test.ok('number', typeof doc.array[0][0]);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyWorkWithCheckKeys","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2178,"column":40,"index":80089},"line":2178,"code":"    it('shouldCorrectlyWorkWithCheckKeys', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          db.collection('shouldCorrectlyOverrideCheckKeysJSOnUpdate').update({\n            'ps.op.t': 1\n          }, {\n            $set: {\n              b: 1\n            }\n          }, {\n            checkKeys: false\n          }, function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc);\n            client.close(done);\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyApplyBitOperator","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2209,"column":39,"index":81090},"line":2209,"code":"    it('shouldCorrectlyApplyBitOperator', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var col = db.collection('shouldCorrectlyApplyBitOperator');\n          col.insert({\n            a: 1,\n            b: 1\n          }, function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            col.update({\n              a: 1\n            }, {\n              $bit: {\n                b: {\n                  and: 0\n                }\n              }\n            }, function (err, result) {\n              expect(err).to.not.exist;\n              test.ok(result);\n              col.findOne({\n                a: 1\n              }, function (err, doc) {\n                expect(err).to.not.exist;\n                test.equal(1, doc.a);\n                test.equal(0, doc.b);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformInsertAndUpdateWithFunctionSerialization","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2260,"column":70,"index":82646},"line":2260,"code":"    it('shouldCorrectlyPerformInsertAndUpdateWithFunctionSerialization', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var col = db.collection('shouldCorrectlyPerformInsertAndUpdateWithFunctionSerialization', {\n            serializeFunctions: true\n          });\n          col.insert({\n            a: 1,\n            f: function (x) {\n              return x;\n            }\n          }, function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc);\n            col.update({\n              a: 1\n            }, {\n              $set: {\n                f: function (y) {\n                  return y;\n                }\n              }\n            }, function (err, doc) {\n              expect(err).to.not.exist;\n              test.ok(doc);\n              col.findOne({\n                a: 1\n              }, function (err, doc) {\n                expect(err).to.not.exist;\n                test.equal(trim('function (y){return y;}'), trim(doc.f.code));\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"should correctly insert > 1000 docs using insert and insertMany","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2309,"column":71,"index":84256},"line":2309,"code":"    it('should correctly insert > 1000 docs using insert and insertMany', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          var col = db.collection('shouldCorrectlyAllowforMoreThanAThousandDocsInsert', {\n            serializeFunctions: true\n          });\n          var docs = [];\n\n          for (var i = 0; i < 2000; i++) {\n            docs.push({\n              a: i\n            });\n          }\n\n          col.insertMany(docs, function (err, result) {\n            expect(err).to.not.exist;\n            expect(result).property('insertedCount').to.equal(2000);\n            docs = [];\n\n            for (var i = 0; i < 2000; i++) {\n              docs.push({\n                a: i\n              });\n            }\n\n            col.insertMany(docs, function (err, res) {\n              expect(err).to.not.exist;\n              expect(res).property('insertedCount').to.equal(2000);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"should return error on unordered insertMany with multiple unique key constraints","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2355,"column":88,"index":85766},"line":2355,"code":"    it('should return error on unordered insertMany with multiple unique key constraints', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db); // Get collection\n\n          var col = db.collection('insertManyMultipleWriteErrors');\n          col.drop(function (err, r) {\n            expect(r).to.not.exist; // Create unique index\n\n            col.createIndex({\n              a: 1\n            }, {\n              unique: true\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              test.ok(r);\n              col.insertMany([{\n                a: 1\n              }, {\n                a: 2\n              }, {\n                a: 1\n              }, {\n                a: 3\n              }, {\n                a: 1\n              }], {\n                ordered: false\n              }, function (err, r) {\n                expect(r).to.not.exist;\n                expect(err).to.exist;\n                expect(err.result).to.exist;\n                expect(err.result.getWriteErrors()).to.have.length(2);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"should return error on unordered insert with multiple unique key constraints","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2406,"column":84,"index":87399},"line":2406,"code":"    it('should return error on unordered insert with multiple unique key constraints', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db); // Get collection\n\n          var col = db.collection('insertManyMultipleWriteErrors1');\n          col.drop(function (err, r) {\n            expect(r).to.not.exist; // Create unique index\n\n            col.createIndex({\n              a: 1\n            }, {\n              unique: true\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              test.ok(r);\n              col.insert([{\n                a: 1\n              }, {\n                a: 2\n              }, {\n                a: 1\n              }, {\n                a: 3\n              }, {\n                a: 1\n              }], {\n                ordered: false\n              }, function (err, r) {\n                expect(r).to.not.exist;\n                expect(err).to.exist;\n                expect(err.result).to.exist;\n                expect(err.result.getWriteErrors()).to.have.length(2);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"should return error on ordered insertMany with multiple unique key constraints","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2457,"column":86,"index":89031},"line":2457,"code":"    it('should return error on ordered insertMany with multiple unique key constraints', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db); // Get collection\n\n          var col = db.collection('insertManyMultipleWriteErrors2');\n          col.drop(function\n            /*err, r*/\n          () {\n            // TODO: reenable once SERVER-36317 is resolved\n            // expect(r).to.not.exist;\n            // Create unique index\n            col.createIndex({\n              a: 1\n            }, {\n              unique: true\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              test.ok(r);\n              col.insertMany([{\n                a: 1\n              }, {\n                a: 2\n              }, {\n                a: 1\n              }, {\n                a: 3\n              }, {\n                a: 1\n              }], {\n                ordered: true\n              }, function (err, r) {\n                expect(r).to.not.exist;\n                test.ok(err != null);\n                test.ok(err.result);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"should return error on ordered insert with multiple unique key constraints","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2510,"column":82,"index":90695},"line":2510,"code":"    it('should return error on ordered insert with multiple unique key constraints', {\n      // Add a tag that our runner can trigger on\n      // in this case we are setting that node needs to be higher than 0.10.X to run\n      metadata: {\n        requires: {\n          topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db); // Get collection\n\n          var col = db.collection('insertManyMultipleWriteErrors3');\n          col.drop(function\n            /*err, r*/\n          () {\n            // TODO: reenable once SERVER-36317 is resolved\n            // expect(r).to.not.exist;\n            // Create unique index\n            col.createIndex({\n              a: 1\n            }, {\n              unique: true\n            }, function (err, r) {\n              expect(err).to.not.exist;\n              test.ok(r);\n              col.insert([{\n                a: 1\n              }, {\n                a: 2\n              }, {\n                a: 1\n              }, {\n                a: 3\n              }, {\n                a: 1\n              }], {\n                ordered: true\n              }, function (err, r) {\n                expect(r).to.not.exist;\n                test.ok(err != null);\n                test.ok(err.result);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Correctly allow forceServerObjectId for insertOne","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2563,"column":57,"index":92330},"line":2563,"code":"    it('Correctly allow forceServerObjectId for insertOne', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n      test: function (done) {\n        var started = [];\n        var succeeded = [];\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1,\n          monitorCommands: true\n        });\n        client.on('commandStarted', function (event) {\n          if (event.commandName === 'insert') started.push(event);\n        });\n        client.on('commandSucceeded', function (event) {\n          if (event.commandName === 'insert') succeeded.push(event);\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          expect(err).to.not.exist;\n          db.collection('apm_test').insertOne({\n            a: 1\n          }, {\n            forceServerObjectId: true\n          }).then(function () {\n            expect(started[0].command.documents[0]._id).to.not.exist;\n            client.close(done);\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Correctly allow forceServerObjectId for insertMany","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2597,"column":58,"index":93461},"line":2597,"code":"    it('Correctly allow forceServerObjectId for insertMany', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n      test: function (done) {\n        var started = [];\n        var succeeded = [];\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1,\n          monitorCommands: true\n        });\n        client.on('commandStarted', function (event) {\n          if (event.commandName === 'insert') started.push(event);\n        });\n        client.on('commandSucceeded', function (event) {\n          if (event.commandName === 'insert') succeeded.push(event);\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          expect(err).to.not.exist;\n          db.collection('apm_test').insertMany([{\n            a: 1\n          }], {\n            forceServerObjectId: true\n          }).then(function () {\n            expect(started[0].command.documents[0]._id).to.not.exist;\n            client.close(done);\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"should return correct number of ids for insertMany { ordered: true }","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2631,"column":76,"index":94613},"line":2631,"code":"    it('should return correct number of ids for insertMany { ordered: true }', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          expect(err).to.not.exist;\n          db.collection('inserted_ids_test').insertMany([{}, {}, {}], {\n            ordered: true\n          }).then(function (r) {\n            expect(r).property('insertedCount').to.equal(3);\n            client.close(done);\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"should return correct number of ids for insertMany { ordered: false }","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2654,"column":77,"index":95376},"line":2654,"code":"    it('should return correct number of ids for insertMany { ordered: false }', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          expect(err).to.not.exist;\n          db.collection('inserted_ids_test').insertMany([{}, {}, {}], {\n            ordered: false\n          }).then(function (r) {\n            expect(err).to.not.exist;\n            expect(r).property('insertedCount').to.equal(3);\n            client.close(done);\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Insert document including sub documents","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2678,"column":47,"index":96148},"line":2678,"code":"    it('Insert document including sub documents', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        client.connect(function (err, client) {\n          var db = client.db(configuration.db);\n          expect(err).to.not.exist;\n          var shipment = {\n            shipment1: 'a'\n          };\n          var supplier = {\n            shipments: [shipment]\n          };\n          var product = {\n            suppliers: [supplier]\n          };\n          var doc = {\n            a: 1,\n            products: [product]\n          };\n          db.collection('sub_documents').insertOne(doc, function (err, r) {\n            expect(err).to.not.exist;\n            test.ok(r);\n            db.collection('sub_documents').find({}).next(function (err, v) {\n              expect(err).to.not.exist;\n              test.equal('a', v.products[0].suppliers[0].shipments[0].shipment1);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"MongoBulkWriteError and BulkWriteResult should respect BulkWrite","suites":["crud - insert","collection.insert()"],"updatePoint":{"line":2717,"column":72,"index":97368},"line":2717,"code":"    it('MongoBulkWriteError and BulkWriteResult should respect BulkWrite', function () {\n      const client = this.configuration.newClient();\n      return client.connect().then(() => {\n        return client.db().collection('test_insertMany_bulkResult').drop();\n      }).catch(ignoreNsNotFound).then(() => {\n        const collection = client.db().collection('test_insertMany_bulkResult');\n        return collection.insertMany([{\n          _id: 2,\n          x: 22\n        }, {\n          _id: 2,\n          x: 22\n        }, {\n          _id: 3,\n          x: 33\n        }], {\n          ordered: false\n        });\n      }).then(() => {\n        expect.fail('InsertMany should fail with multi key error');\n      }).catch(error => {\n        expect(error).to.be.instanceOf(MongoBulkWriteError);\n        expect(error.insertedCount, 'MongoBulkWriteError.insertedCount did not respect BulkResult.nInserted').to.equal(error.result.result.nInserted);\n        expect(error.result.insertedCount, 'BulkWriteResult.insertedCount did not respect BulkResult.nInserted').to.equal(error.result.result.nInserted);\n        expect(error.result.result.nInserted, 'BulkWrite did not correctly represent the operation').to.equal(2);\n      }).finally(() => client.db().collection('test_insertMany_bulkResult').drop()).finally(() => client.close());\n    });","file":"integration/crud/insert.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly respect the maxtimeMs property on count","suites":["MaxTimeMS"],"updatePoint":{"line":16,"column":62,"index":295},"line":16,"code":"  it('Should Correctly respect the maxtimeMs property on count', function (done) {\n    var configuration = this.configuration;\n    var client = configuration.newClient(configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    client.connect(function (err, client) {\n      var db = client.db(configuration.db);\n      var col = db.collection('max_time_ms'); // Insert a couple of docs\n\n      var docs_1 = [{\n        agg_pipe: 1\n      }]; // Simple insert\n\n      col.insert(docs_1, {\n        writeConcern: {\n          w: 1\n        }\n      }, function (err) {\n        expect(err).to.not.exist; // Execute a find command\n\n        col.find({\n          $where: 'sleep(100) || true'\n        }).maxTimeMS(50).count(function (err) {\n          test.ok(err != null);\n          client.close(done);\n        });\n      });\n    });\n  });","file":"integration/crud/maxtimems.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly respect the maxtimeMs property on toArray","suites":["MaxTimeMS"],"updatePoint":{"line":45,"column":64,"index":1128},"line":45,"code":"  it('Should Correctly respect the maxtimeMs property on toArray', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var col = db.collection('max_time_ms_2'); // Insert a couple of docs\n\n        var docs_1 = [{\n          agg_pipe: 1\n        }]; // Simple insert\n\n        col.insert(docs_1, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist; // Execute a find command\n\n          col.find({\n            $where: 'sleep(100) || true'\n          }).maxTimeMS(50).toArray(function (err) {\n            test.ok(err != null);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/maxtimems.test.js","skipped":false,"dir":"test"},{"name":"Should Correctly fail with maxTimeMS error","suites":["MaxTimeMS"],"updatePoint":{"line":81,"column":48,"index":2107},"line":81,"code":"  it('Should Correctly fail with maxTimeMS error', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var col = db.collection('max_time_ms_5'); // Insert a couple of docs\n\n        var docs_1 = [{\n          agg_pipe: 10\n        }]; // Simple insert\n\n        col.insert(docs_1, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.admin().command({\n            configureFailPoint: 'maxTimeAlwaysTimeOut',\n            mode: 'alwaysOn'\n          }, function (err, result) {\n            expect(err).to.not.exist;\n            test.equal(1, result.ok);\n            col.find({}).maxTimeMS(10).toArray(function (err) {\n              test.ok(err != null);\n              db.admin().command({\n                configureFailPoint: 'maxTimeAlwaysTimeOut',\n                mode: 'off'\n              }, function (err, result) {\n                expect(err).to.not.exist;\n                test.equal(1, result.ok);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/maxtimems.test.js","skipped":false,"dir":"test"},{"name":"cursorShouldBeAbleToResetOnToArrayRunningQueryAgain","suites":["Cursor"],"updatePoint":{"line":49,"column":57,"index":851},"line":49,"code":"  it('cursorShouldBeAbleToResetOnToArrayRunningQueryAgain', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_to_a', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find({});\n            this.defer(() => cursor.close());\n            cursor.toArray(err => {\n              expect(err).to.not.exist; // Should fail if called again (cursor should be closed)\n\n              cursor.toArray(err => {\n                expect(err).to.not.exist; // Should fail if called again (cursor should be closed)\n\n                cursor.forEach(() => {}, err => {\n                  expect(err).to.not.exist;\n                  done();\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"cursor should close after first next operation","suites":["Cursor"],"updatePoint":{"line":91,"column":52,"index":2323},"line":91,"code":"  it('cursor should close after first next operation', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('close_on_next', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert([{\n            a: 1\n          }, {\n            a: 1\n          }, {\n            a: 1\n          }], configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            var cursor = collection.find({});\n            this.defer(() => cursor.close());\n            cursor.batchSize(2);\n            cursor.next(err => {\n              expect(err).to.not.exist;\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"cursor should trigger getMore","suites":["Cursor"],"updatePoint":{"line":130,"column":35,"index":3544},"line":130,"code":"  it('cursor should trigger getMore', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('trigger_get_more', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert([{\n            a: 1\n          }, {\n            a: 1\n          }, {\n            a: 1\n          }], configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find({}).batchSize(2);\n            this.defer(() => cursor.close());\n            cursor.toArray(err => {\n              expect(err).to.not.exist;\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteCursorExplain","suites":["Cursor"],"updatePoint":{"line":168,"column":41,"index":4759},"line":168,"code":"  it('shouldCorrectlyExecuteCursorExplain', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_explain', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            collection.find({\n              a: 1\n            }).explain((err, explanation) => {\n              expect(err).to.not.exist;\n              expect(explanation).to.exist;\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteCursorCount","suites":["Cursor"],"updatePoint":{"line":203,"column":39,"index":5899},"line":203,"code":"  it('shouldCorrectlyExecuteCursorCount', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_count', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.find().count(err => {\n            expect(err).to.not.exist;\n\n            function insert(callback) {\n              var total = 10;\n\n              for (var i = 0; i < 10; i++) {\n                collection.insert({\n                  x: i\n                }, configuration.writeConcernMax(), e => {\n                  expect(e).to.not.exist;\n                  total = total - 1;\n                  if (total === 0) callback();\n                });\n              }\n            }\n\n            function finished() {\n              collection.find().count((err, count) => {\n                expect(err).to.not.exist;\n                test.equal(10, count);\n                test.ok(count.constructor === Number);\n                collection.find({}, {\n                  limit: 5\n                }).count((err, count) => {\n                  expect(err).to.not.exist;\n                  test.equal(5, count);\n                  collection.find({}, {\n                    skip: 5\n                  }).count((err, count) => {\n                    expect(err).to.not.exist;\n                    test.equal(5, count);\n                    db.collection('acollectionthatdoesn').count((err, count) => {\n                      expect(err).to.not.exist;\n                      test.equal(0, count);\n                      var cursor = collection.find();\n                      cursor.count((err, count) => {\n                        expect(err).to.not.exist;\n                        test.equal(10, count);\n                        cursor.forEach(() => {}, err => {\n                          expect(err).to.not.exist;\n                          cursor.count((err, count2) => {\n                            expect(err).to.not.exist;\n                            expect(count2).to.equal(10);\n                            expect(count2).to.equal(count);\n                            done();\n                          });\n                        });\n                      });\n                    });\n                  });\n                });\n              });\n            }\n\n            insert(function () {\n              finished();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute cursor count with secondary readPreference","suites":["Cursor"],"updatePoint":{"line":285,"column":73,"index":8836},"line":285,"code":"  it('Should correctly execute cursor count with secondary readPreference', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'replicaset'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      const bag = [];\n      client.on('commandStarted', filterForCommands(['count'], bag));\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        const cursor = db.collection('countTEST').find({\n          qty: {\n            $gt: 4\n          }\n        });\n        cursor.count({\n          readPreference: ReadPreference.SECONDARY\n        }, err => {\n          expect(err).to.not.exist;\n          const selectedServerAddress = bag[0].address.replace('127.0.0.1', 'localhost');\n          const selectedServer = client.topology.description.servers.get(selectedServerAddress);\n          expect(selectedServer).property('type').to.equal(ServerType.RSSecondary);\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteCursorCountWithDottedCollectionName","suites":["Cursor"],"updatePoint":{"line":322,"column":63,"index":10161},"line":322,"code":"  it('shouldCorrectlyExecuteCursorCountWithDottedCollectionName', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_count.ext', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.find().count(err => {\n            expect(err).to.not.exist;\n\n            function insert(callback) {\n              var total = 10;\n\n              for (var i = 0; i < 10; i++) {\n                collection.insert({\n                  x: i\n                }, configuration.writeConcernMax(), e => {\n                  expect(e).to.not.exist;\n                  total = total - 1;\n                  if (total === 0) callback();\n                });\n              }\n            }\n\n            function finished() {\n              collection.find().count((err, count) => {\n                expect(err).to.not.exist;\n                test.equal(10, count);\n                test.ok(count.constructor === Number);\n                collection.find({}, {\n                  limit: 5\n                }).count((err, count) => {\n                  expect(err).to.not.exist;\n                  test.equal(5, count);\n                  collection.find({}, {\n                    skip: 5\n                  }).count((err, count) => {\n                    expect(err).to.not.exist;\n                    test.equal(5, count);\n                    db.collection('acollectionthatdoesn').count((err, count) => {\n                      expect(err).to.not.exist;\n                      test.equal(0, count);\n                      var cursor = collection.find();\n                      cursor.count((err, count) => {\n                        expect(err).to.not.exist;\n                        test.equal(10, count);\n                        cursor.forEach(() => {}, err => {\n                          expect(err).to.not.exist;\n                          cursor.count((err, count2) => {\n                            expect(err).to.not.exist;\n                            expect(count2).to.equal(10);\n                            expect(count2).to.equal(count);\n                            done();\n                          });\n                        });\n                      });\n                    });\n                  });\n                });\n              });\n            }\n\n            insert(function () {\n              finished();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldThrowErrorOnEachWhenMissingCallback","suites":["Cursor"],"updatePoint":{"line":404,"column":47,"index":13076},"line":404,"code":"  it('shouldThrowErrorOnEachWhenMissingCallback', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_each', (err, collection) => {\n          expect(err).to.not.exist;\n\n          function insert(callback) {\n            var total = 10;\n\n            for (var i = 0; i < 10; i++) {\n              collection.insert({\n                x: i\n              }, configuration.writeConcernMax(), e => {\n                expect(e).to.not.exist;\n                total = total - 1;\n                if (total === 0) callback();\n              });\n            }\n          }\n\n          function finished() {\n            const cursor = collection.find();\n            test.throws(function () {\n              cursor.forEach();\n            });\n            done();\n          }\n\n          insert(function () {\n            finished();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleLimitOnCursor","suites":["Cursor"],"updatePoint":{"line":453,"column":40,"index":14496},"line":453,"code":"  it('shouldCorrectlyHandleLimitOnCursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_cursor_limit', (err, collection) => {\n          function insert(callback) {\n            var total = 10;\n\n            for (var i = 0; i < 10; i++) {\n              collection.insert({\n                x: i\n              }, configuration.writeConcernMax(), e => {\n                expect(e).to.not.exist;\n                total = total - 1;\n                if (total === 0) callback();\n              });\n            }\n          }\n\n          function finished() {\n            collection.find().limit(5).toArray((err, items) => {\n              test.equal(5, items.length); // Let's close the db\n\n              expect(err).to.not.exist;\n              done();\n            });\n          }\n\n          insert(function () {\n            finished();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleNegativeOneLimitOnCursor","suites":["Cursor"],"updatePoint":{"line":501,"column":51,"index":15955},"line":501,"code":"  it('shouldCorrectlyHandleNegativeOneLimitOnCursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_cursor_negative_one_limit', (err, collection) => {\n          expect(err).to.not.exist;\n\n          function insert(callback) {\n            var total = 10;\n\n            for (var i = 0; i < 10; i++) {\n              collection.insert({\n                x: i\n              }, configuration.writeConcernMax(), e => {\n                expect(e).to.not.exist;\n                total = total - 1;\n                if (total === 0) callback();\n              });\n            }\n          }\n\n          function finished() {\n            collection.find().limit(-1).toArray((err, items) => {\n              expect(err).to.not.exist;\n              test.equal(1, items.length); // Let's close the db\n\n              done();\n            });\n          }\n\n          insert(function () {\n            finished();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleAnyNegativeLimitOnCursor","suites":["Cursor"],"updatePoint":{"line":551,"column":51,"index":17465},"line":551,"code":"  it('shouldCorrectlyHandleAnyNegativeLimitOnCursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_cursor_any_negative_limit', (err, collection) => {\n          expect(err).to.not.exist;\n\n          function insert(callback) {\n            var total = 10;\n\n            for (var i = 0; i < 10; i++) {\n              collection.insert({\n                x: i\n              }, configuration.writeConcernMax(), e => {\n                expect(e).to.not.exist;\n                total = total - 1;\n                if (total === 0) callback();\n              });\n            }\n          }\n\n          function finished() {\n            collection.find().limit(-5).toArray((err, items) => {\n              expect(err).to.not.exist;\n              test.equal(5, items.length); // Let's close the db\n\n              done();\n            });\n          }\n\n          insert(function () {\n            finished();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyReturnErrorsOnIllegalLimitValuesNotAnInt","suites":["Cursor"],"updatePoint":{"line":601,"column":61,"index":18985},"line":601,"code":"  it('shouldCorrectlyReturnErrorsOnIllegalLimitValuesNotAnInt', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_limit_exceptions_2', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find();\n            this.defer(() => cursor.close());\n\n            try {\n              cursor.limit('not-an-integer');\n            } catch (err) {\n              test.equal('Operation \"limit\" requires an integer', err.message);\n            }\n\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyReturnErrorsOnIllegalLimitValuesIsClosedWithinNext","suites":["Cursor"],"updatePoint":{"line":639,"column":71,"index":20250},"line":639,"code":"  it('shouldCorrectlyReturnErrorsOnIllegalLimitValuesIsClosedWithinNext', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_limit_exceptions', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find();\n            this.defer(() => cursor.close());\n            cursor.next(err => {\n              expect(err).to.not.exist;\n              expect(() => {\n                cursor.limit(1);\n              }).to.throw(/Cursor is already initialized/);\n              done();\n            });\n          });\n        });\n      });\n    }\n  }); // NOTE: who cares what you set when the cursor is closed?","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyReturnErrorsOnIllegalLimitValuesIsClosedWithinClose","suites":["Cursor"],"line":677,"code":"  it.skip('shouldCorrectlyReturnErrorsOnIllegalLimitValuesIsClosedWithinClose', {","file":"integration/crud/misc_cursors.test.js","skipped":true,"dir":"test"},{"name":"shouldCorrectlySkipRecordsOnCursor","suites":["Cursor"],"updatePoint":{"line":713,"column":40,"index":22803},"line":713,"code":"  it('shouldCorrectlySkipRecordsOnCursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_skip', (err, collection) => {\n          expect(err).to.not.exist;\n\n          const insert = callback => {\n            var total = 10;\n\n            for (var i = 0; i < 10; i++) {\n              collection.insert({\n                x: i\n              }, configuration.writeConcernMax(), e => {\n                expect(e).to.not.exist;\n                total = total - 1;\n                if (total === 0) callback();\n              });\n            }\n          };\n\n          insert(() => {\n            const cursor = collection.find();\n            this.defer(() => cursor.close());\n            cursor.count((err, count) => {\n              expect(err).to.not.exist;\n              test.equal(10, count);\n            });\n            const cursor2 = collection.find();\n            this.defer(() => cursor2.close());\n            cursor2.toArray((err, items) => {\n              expect(err).to.not.exist;\n              test.equal(10, items.length);\n              collection.find().skip(2).toArray((err, items2) => {\n                expect(err).to.not.exist;\n                test.equal(8, items2.length); // Check that we have the same elements\n\n                var numberEqual = 0;\n                var sliced = items.slice(2, 10);\n\n                for (var i = 0; i < sliced.length; i++) {\n                  if (sliced[i].x === items2[i].x) numberEqual = numberEqual + 1;\n                }\n\n                test.equal(8, numberEqual);\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyReturnErrorsOnIllegalSkipValues","suites":["Cursor"],"updatePoint":{"line":779,"column":52,"index":25006},"line":779,"code":"  it('shouldCorrectlyReturnErrorsOnIllegalSkipValues', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_skip_exceptions', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n\n            try {\n              collection.find().skip('not-an-integer');\n            } catch (err) {\n              test.equal('Operation \"skip\" requires an integer', err.message);\n            }\n\n            const cursor = collection.find();\n            cursor.next(err => {\n              expect(err).to.not.exist; // NOTE: who cares what you set when closed, if not initialized\n              // expect(() => {\n              //   cursor.skip(1);\n              // }).to.throw(/not extensible/);\n\n              const cursor2 = collection.find();\n              cursor2.close(err => {\n                expect(err).to.not.exist; // NOTE: who cares what you set when closed, if not initialized\n                // expect(() => {\n                //   cursor2.skip(1);\n                // }).to.throw(/not extensible/);\n\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldReturnErrorsOnIllegalBatchSizes","suites":["Cursor"],"updatePoint":{"line":831,"column":43,"index":26809},"line":831,"code":"  it('shouldReturnErrorsOnIllegalBatchSizes', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_batchSize_exceptions', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            let cursor = collection.find();\n\n            try {\n              cursor.batchSize('not-an-integer');\n              test.ok(false);\n            } catch (err) {\n              test.equal('Operation \"batchSize\" requires an integer', err.message);\n            }\n\n            cursor = collection.find();\n            cursor.next(err => {\n              expect(err).to.not.exist;\n              cursor.next(err => {\n                expect(err).to.not.exist; // NOTE: who cares what you set when closed, if not initialized\n                // expect(() => {\n                //   cursor.batchSize(1);\n                // }).to.throw(/not extensible/);\n\n                const cursor2 = collection.find();\n                cursor2.close(err => {\n                  expect(err).to.not.exist; // NOTE: who cares what you set when closed, if not initialized\n                  // expect(() => {\n                  //   cursor2.batchSize(1);\n                  // }).to.throw(/not extensible/);\n\n                  done();\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleBatchSize","suites":["Cursor"],"updatePoint":{"line":888,"column":36,"index":28804},"line":888,"code":"  it('shouldCorrectlyHandleBatchSize', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_multiple_batch_size', (err, collection) => {\n          expect(err).to.not.exist; //test with the last batch that is a multiple of batchSize\n\n          var records = 4;\n          var batchSize = 2;\n          var docs = [];\n\n          for (var i = 0; i < records; i++) {\n            docs.push({\n              a: i\n            });\n          }\n\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find({}, {\n              batchSize: batchSize\n            }); //1st\n\n            cursor.next((err, items) => {\n              expect(err).to.not.exist;\n              test.equal(1, cursor.bufferedCount());\n              test.ok(items != null); //2nd\n\n              cursor.next((err, items) => {\n                expect(err).to.not.exist;\n                test.equal(0, cursor.bufferedCount());\n                test.ok(items != null); //3rd\n\n                cursor.next((err, items) => {\n                  expect(err).to.not.exist;\n                  test.equal(1, cursor.bufferedCount());\n                  test.ok(items != null); //4th\n\n                  cursor.next((err, items) => {\n                    expect(err).to.not.exist;\n                    test.equal(0, cursor.bufferedCount());\n                    test.ok(items != null); //No more\n\n                    cursor.next((err, items) => {\n                      expect(err).to.not.exist;\n                      test.ok(items == null);\n                      test.ok(cursor.closed);\n                      done();\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldHandleWhenLimitBiggerThanBatchSize","suites":["Cursor"],"updatePoint":{"line":959,"column":46,"index":31178},"line":959,"code":"  it('shouldHandleWhenLimitBiggerThanBatchSize', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_limit_greater_than_batch_size', (err, collection) => {\n          expect(err).to.not.exist;\n          var limit = 4;\n          var records = 10;\n          var batchSize = 3;\n          var docs = [];\n\n          for (var i = 0; i < records; i++) {\n            docs.push({\n              a: i\n            });\n          }\n\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            var cursor = collection.find({}, {\n              batchSize: batchSize,\n              limit: limit\n            }); //1st\n\n            cursor.next(err => {\n              expect(err).to.not.exist;\n              test.equal(2, cursor.bufferedCount()); //2nd\n\n              cursor.next(err => {\n                expect(err).to.not.exist;\n                test.equal(1, cursor.bufferedCount()); //3rd\n\n                cursor.next(err => {\n                  expect(err).to.not.exist;\n                  test.equal(0, cursor.bufferedCount()); //4th\n\n                  cursor.next(err => {\n                    expect(err).to.not.exist; //No more\n\n                    cursor.next((err, items) => {\n                      expect(err).to.not.exist;\n                      test.ok(items == null);\n                      test.ok(cursor.closed);\n                      done();\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldHandleLimitLessThanBatchSize","suites":["Cursor"],"updatePoint":{"line":1026,"column":40,"index":33289},"line":1026,"code":"  it('shouldHandleLimitLessThanBatchSize', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_limit_less_than_batch_size', (err, collection) => {\n          expect(err).to.not.exist;\n          var limit = 2;\n          var records = 10;\n          var batchSize = 4;\n          var docs = [];\n\n          for (var i = 0; i < records; i++) {\n            docs.push({\n              a: i\n            });\n          }\n\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            var cursor = collection.find({}, {\n              batchSize: batchSize,\n              limit: limit\n            }); //1st\n\n            cursor.next(err => {\n              expect(err).to.not.exist;\n              test.equal(1, cursor.bufferedCount()); //2nd\n\n              cursor.next(err => {\n                expect(err).to.not.exist;\n                test.equal(0, cursor.bufferedCount()); //No more\n\n                cursor.next((err, items) => {\n                  expect(err).to.not.exist;\n                  test.ok(items == null);\n                  test.ok(cursor.closed);\n                  done();\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldHandleSkipLimitChaining","suites":["Cursor"],"updatePoint":{"line":1084,"column":35,"index":35089},"line":1084,"code":"  it('shouldHandleSkipLimitChaining', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var collection = db.collection('shouldHandleSkipLimitChaining');\n\n        function insert(callback) {\n          var total = 10;\n\n          for (var i = 0; i < 10; i++) {\n            collection.insert({\n              x: i\n            }, configuration.writeConcernMax(), e => {\n              expect(e).to.not.exist;\n              total = total - 1;\n              if (total === 0) callback();\n            });\n          }\n        }\n\n        function finished() {\n          collection.find().toArray((err, items) => {\n            expect(err).to.not.exist;\n            test.equal(10, items.length);\n            collection.find().limit(5).skip(3).toArray(function (err, items2) {\n              expect(err).to.not.exist;\n              test.equal(5, items2.length); // Check that we have the same elements\n\n              var numberEqual = 0;\n              var sliced = items.slice(3, 8);\n\n              for (var i = 0; i < sliced.length; i++) {\n                if (sliced[i].x === items2[i].x) numberEqual = numberEqual + 1;\n              }\n\n              test.equal(5, numberEqual);\n              done();\n            });\n          });\n        }\n\n        insert(function () {\n          finished();\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleLimitSkipChainingInline","suites":["Cursor"],"updatePoint":{"line":1144,"column":50,"index":36962},"line":1144,"code":"  it('shouldCorrectlyHandleLimitSkipChainingInline', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_limit_skip_chaining_inline', (err, collection) => {\n          expect(err).to.not.exist;\n\n          function insert(callback) {\n            var total = 10;\n\n            for (var i = 0; i < 10; i++) {\n              collection.insert({\n                x: i\n              }, configuration.writeConcernMax(), e => {\n                expect(e).to.not.exist;\n                total = total - 1;\n                if (total === 0) callback();\n              });\n            }\n          }\n\n          function finished() {\n            collection.find().toArray((err, items) => {\n              expect(err).to.not.exist;\n              test.equal(10, items.length);\n              collection.find().limit(5).skip(3).toArray(function (err, items2) {\n                expect(err).to.not.exist;\n                test.equal(5, items2.length); // Check that we have the same elements\n\n                var numberEqual = 0;\n                var sliced = items.slice(3, 8);\n\n                for (var i = 0; i < sliced.length; i++) {\n                  if (sliced[i].x === items2[i].x) numberEqual = numberEqual + 1;\n                }\n\n                test.equal(5, numberEqual);\n                done();\n              });\n            });\n          }\n\n          insert(function () {\n            finished();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCloseCursorNoQuerySent","suites":["Cursor"],"updatePoint":{"line":1206,"column":34,"index":38944},"line":1206,"code":"  it('shouldCloseCursorNoQuerySent', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_close_no_query_sent', (err, collection) => {\n          expect(err).to.not.exist;\n          const cursor = collection.find();\n          cursor.close(err => {\n            expect(err).to.not.exist;\n            test.equal(true, cursor.closed);\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRefillViaGetMoreCommand","suites":["Cursor"],"updatePoint":{"line":1235,"column":44,"index":39922},"line":1235,"code":"  it('shouldCorrectlyRefillViaGetMoreCommand', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var COUNT = 1000;\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_refill_via_get_more', (err, collection) => {\n          expect(err).to.not.exist;\n\n          function insert(callback) {\n            var docs = [];\n\n            for (var i = 0; i < COUNT; i++) {\n              docs.push({\n                a: i\n              });\n            }\n\n            collection.insertMany(docs, configuration.writeConcernMax(), callback);\n          }\n\n          function finished() {\n            collection.count((err, count) => {\n              expect(err).to.not.exist;\n              test.equal(COUNT, count);\n            });\n            var total = 0;\n            collection.find({}, {}).forEach(item => {\n              total = total + item.a;\n            }, err => {\n              expect(err).to.not.exist;\n              test.equal(499500, total);\n              collection.count((err, count) => {\n                expect(err).to.not.exist;\n                test.equal(COUNT, count);\n              });\n              collection.count((err, count) => {\n                expect(err).to.not.exist;\n                test.equal(COUNT, count);\n                var total2 = 0;\n                collection.find().forEach(item => {\n                  total2 = total2 + item.a;\n                }, err => {\n                  expect(err).to.not.exist;\n                  test.equal(499500, total2);\n                  collection.count((err, count) => {\n                    expect(err).to.not.exist;\n                    test.equal(COUNT, count);\n                    test.equal(total, total2);\n                    done();\n                  });\n                });\n              });\n            });\n          }\n\n          insert(function () {\n            finished();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRefillViaGetMoreAlternativeCollection","suites":["Cursor"],"updatePoint":{"line":1310,"column":58,"index":42342},"line":1310,"code":"  it('shouldCorrectlyRefillViaGetMoreAlternativeCollection', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_refill_via_get_more_alt_coll', (err, collection) => {\n          expect(err).to.not.exist;\n          var COUNT = 1000;\n\n          function insert(callback) {\n            var docs = [];\n\n            for (var i = 0; i < COUNT; i++) {\n              docs.push({\n                a: i\n              });\n            }\n\n            collection.insertMany(docs, configuration.writeConcernMax(), callback);\n          }\n\n          function finished() {\n            collection.count((err, count) => {\n              expect(err).to.not.exist;\n              test.equal(1000, count);\n            });\n            var total = 0;\n            collection.find().forEach(doc => {\n              total = total + doc.a;\n            }, err => {\n              expect(err).to.not.exist;\n              test.equal(499500, total);\n              collection.count((err, count) => {\n                expect(err).to.not.exist;\n                test.equal(1000, count);\n              });\n              collection.count((err, count) => {\n                expect(err).to.not.exist;\n                test.equal(1000, count);\n                var total2 = 0;\n                collection.find().forEach(doc => {\n                  total2 = total2 + doc.a;\n                }, err => {\n                  expect(err).to.not.exist;\n                  expect(total2).to.equal(499500);\n                  collection.count((err, count) => {\n                    expect(err).to.not.exist;\n                    expect(count).to.equal(1000);\n                    expect(total2).to.equal(total);\n                    done();\n                  });\n                });\n              });\n            });\n          }\n\n          insert(function () {\n            finished();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCloseCursorAfterQueryHasBeenSent","suites":["Cursor"],"updatePoint":{"line":1385,"column":44,"index":44762},"line":1385,"code":"  it('shouldCloseCursorAfterQueryHasBeenSent', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_close_after_query_sent', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find({\n              a: 1\n            });\n            cursor.next(err => {\n              expect(err).to.not.exist;\n              cursor.close(err => {\n                expect(err).to.not.exist;\n                test.equal(true, cursor.closed);\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteCursorCountWithFields","suites":["Cursor"],"updatePoint":{"line":1424,"column":49,"index":46047},"line":1424,"code":"  it('shouldCorrectlyExecuteCursorCountWithFields', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_count_with_fields', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insertOne({\n            x: 1,\n            a: 2\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            collection.find({}).project({\n              a: 1\n            }).toArray((err, items) => {\n              expect(err).to.not.exist;\n              test.equal(1, items.length);\n              test.equal(2, items[0].a);\n              expect(items[0].x).to.not.exist;\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCountWithFieldsUsingExclude","suites":["Cursor"],"updatePoint":{"line":1462,"column":48,"index":47320},"line":1462,"code":"  it('shouldCorrectlyCountWithFieldsUsingExclude', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('test_count_with_fields_using_exclude', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insertOne({\n            x: 1,\n            a: 2\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            collection.find({}, {\n              projection: {\n                x: 0\n              }\n            }).toArray((err, items) => {\n              expect(err).to.not.exist;\n              test.equal(1, items.length);\n              test.equal(2, items[0].a);\n              expect(items[0].x).to.not.exist;\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute count on cursor","suites":["Cursor"],"updatePoint":{"line":1502,"column":46,"index":48643},"line":1502,"code":"  it('Should correctly execute count on cursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n\n      for (var i = 0; i < 1000; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('Should_correctly_execute_count_on_cursor_1', (err, collection) => {\n          expect(err).to.not.exist; // insert all docs\n\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            let total = 0; // Create a cursor for the content\n\n            const cursor = collection.find({});\n            this.defer(() => cursor.close());\n            cursor.count(err => {\n              expect(err).to.not.exist; // Ensure each returns all documents\n\n              cursor.forEach(() => {\n                total++;\n              }, err => {\n                expect(err).to.not.exist;\n                cursor.count((err, c) => {\n                  expect(err).to.not.exist;\n                  expect(c).to.equal(1000);\n                  expect(total).to.equal(1000);\n                  done();\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"does not auto destroy streams","suites":["Cursor"],"updatePoint":{"line":1558,"column":35,"index":50442},"line":1558,"code":"  it('does not auto destroy streams', function (done) {\n    const docs = [];\n\n    for (var i = 0; i < 10; i++) {\n      docs.push({\n        a: i + 1\n      });\n    }\n\n    const configuration = this.configuration;\n    const client = configuration.newClient(configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    client.connect((err, client) => {\n      expect(err).to.not.exist;\n      const db = client.db(configuration.db);\n      db.createCollection('does_not_autodestroy_streams', (err, collection) => {\n        expect(err).to.not.exist;\n        collection.insertMany(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n          const cursor = collection.find();\n          const stream = cursor.stream();\n          stream.on('close', () => {\n            expect.fail('extra close event must not be called');\n          });\n          stream.on('end', () => {\n            client.close();\n            done();\n          });\n          stream.on('data', doc => {\n            expect(doc).to.exist;\n          });\n          stream.resume();\n        });\n      });\n    });\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should be able to stream documents","suites":["Cursor"],"updatePoint":{"line":1595,"column":40,"index":51557},"line":1595,"code":"  it('should be able to stream documents', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n\n      for (var i = 0; i < 1000; i++) {\n        docs[i] = {\n          a: i + 1\n        };\n      }\n\n      var count = 0;\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('Should_be_able_to_stream_documents', (err, collection) => {\n          expect(err).to.not.exist; // insert all docs\n\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            var paused = 0,\n                closed = 0,\n                resumed = 0,\n                i = 0;\n            const cursor = collection.find();\n            const stream = cursor.stream();\n            stream.on('data', function (doc) {\n              test.equal(true, !!doc);\n              test.equal(true, !!doc.a);\n              count = count + 1;\n\n              if (paused > 0 && 0 === resumed) {\n                err = new Error('data emitted during pause');\n                return testDone();\n              }\n\n              if (++i === 3) {\n                stream.pause();\n                paused++;\n                setTimeout(function () {\n                  stream.resume();\n                  resumed++;\n                }, 20);\n              }\n            });\n            stream.once('error', function (er) {\n              err = er;\n              testDone();\n            });\n            stream.once('end', function () {\n              closed++;\n              testDone();\n            });\n\n            function testDone() {\n              expect(err).to.not.exist;\n              test.equal(i, docs.length);\n              test.equal(1, closed);\n              test.equal(1, paused);\n              test.equal(1, resumed);\n              test.strictEqual(cursor.closed, true);\n              done();\n            }\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"immediately destroying a stream prevents the query from executing","suites":["Cursor"],"updatePoint":{"line":1674,"column":71,"index":53984},"line":1674,"code":"  it('immediately destroying a stream prevents the query from executing', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var i = 0,\n          docs = [{\n        b: 2\n      }, {\n        b: 3\n      }],\n          doneCalled = 0;\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('immediately_destroying_a_stream_prevents_the_query_from_executing', (err, collection) => {\n          expect(err).to.not.exist; // insert all docs\n\n          collection.insertMany(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find();\n            const stream = cursor.stream();\n            stream.on('data', function () {\n              i++;\n            });\n            cursor.once('close', testDone('close'));\n            stream.once('error', testDone('error'));\n            stream.destroy();\n\n            function testDone() {\n              return err => {\n                ++doneCalled;\n\n                if (doneCalled === 1) {\n                  expect(err).to.not.exist;\n                  test.strictEqual(0, i);\n                  test.strictEqual(true, cursor.closed);\n                  done();\n                }\n              };\n            }\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"removes session wheen cloning a find cursor","suites":["Cursor"],"updatePoint":{"line":1729,"column":49,"index":55736},"line":1729,"code":"  it('removes session wheen cloning a find cursor', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient(configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    client.connect((err, client) => {\n      expect(err).to.not.exist;\n      const db = client.db(configuration.db);\n      db.createCollection('clone_find_cursor_session', (err, collection) => {\n        expect(err).to.not.exist;\n        collection.insertOne({\n          a: 1\n        }, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n          const cursor = collection.find();\n          const clonedCursor = cursor.clone();\n          cursor.toArray(err => {\n            expect(err).to.not.exist;\n            clonedCursor.toArray(err => {\n              expect(err).to.not.exist;\n              client.close();\n              done();\n            });\n          });\n        });\n      });\n    });\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"removes session wheen cloning an aggregation cursor","suites":["Cursor"],"updatePoint":{"line":1757,"column":57,"index":56693},"line":1757,"code":"  it('removes session wheen cloning an aggregation cursor', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        const db = client.db(configuration.db);\n        db.createCollection('clone_aggregation_cursor_session', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insertOne({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.aggregate([{\n              $match: {\n                a: 1\n              }\n            }]);\n            const clonedCursor = cursor.clone();\n            cursor.toArray(err => {\n              expect(err).to.not.exist;\n              clonedCursor.toArray(err => {\n                expect(err).to.not.exist;\n                client.close();\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"destroying a stream stops it","suites":["Cursor"],"updatePoint":{"line":1796,"column":34,"index":57890},"line":1796,"code":"  it('destroying a stream stops it', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('destroying_a_stream_stops_it', (err, collection) => {\n          expect(err).to.not.exist;\n          var docs = [];\n\n          for (var ii = 0; ii < 10; ++ii) docs.push({\n            b: ii + 1\n          }); // insert all docs\n\n\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            var finished = 0,\n                i = 0;\n            const cursor = collection.find();\n            const stream = cursor.stream();\n            test.strictEqual(false, cursor.closed);\n            stream.on('data', function () {\n              if (++i === 5) {\n                stream.destroy();\n              }\n            });\n            cursor.once('close', testDone);\n            stream.once('error', testDone);\n            stream.once('end', testDone);\n\n            function testDone(err) {\n              ++finished;\n\n              if (finished === 2) {\n                test.strictEqual(undefined, err);\n                test.strictEqual(5, i);\n                test.strictEqual(2, finished);\n                test.strictEqual(true, cursor.closed);\n                done();\n              }\n            }\n          });\n        });\n      });\n    }\n  }); // NOTE: skipped for use of topology manager","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"cursor stream errors","suites":["Cursor"],"line":1855,"code":"  it.skip('cursor stream errors', {","file":"integration/crud/misc_cursors.test.js","skipped":true,"dir":"test"},{"name":"cursor stream pipe","suites":["Cursor"],"updatePoint":{"line":1919,"column":24,"index":61779},"line":1919,"code":"  it('cursor stream pipe', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('cursor_stream_pipe', (err, collection) => {\n          expect(err).to.not.exist;\n          var docs = [];\n          'Aaden Aaron Adrian Aditya Bob Joe'.split(' ').forEach(function (name) {\n            docs.push({\n              name: name\n            });\n          }); // insert all docs\n\n          collection.insertMany(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const filename = path.join(os.tmpdir(), '_nodemongodbnative_stream_out.txt');\n            const out = fs.createWriteStream(filename);\n            const stream = collection.find().stream({\n              transform: doc => JSON.stringify(doc)\n            });\n            stream.pipe(out); // Wait for output stream to close\n\n            out.on('close', testDone);\n\n            function testDone(err) {\n              // Object.prototype.toString = toString;\n              test.strictEqual(undefined, err);\n              var contents = fs.readFileSync(filename, 'utf8');\n              test.ok(/Aaden/.test(contents));\n              test.ok(/Aaron/.test(contents));\n              test.ok(/Adrian/.test(contents));\n              test.ok(/Aditya/.test(contents));\n              test.ok(/Bob/.test(contents));\n              test.ok(/Joe/.test(contents));\n              fs.unlinkSync(filename);\n              done();\n            }\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should close dead tailable cursors","suites":["Cursor"],"updatePoint":{"line":1974,"column":40,"index":63826},"line":1974,"code":"  it('should close dead tailable cursors', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      },\n      sessions: {\n        skipLeakTests: true\n      },\n      os: '!win32' // NODE-2943: timeout on windows\n\n    },\n    test: function (done) {\n      // http://www.mongodb.org/display/DOCS/Tailable+Cursors\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        const options = {\n          capped: true,\n          size: 10000000\n        };\n        db.createCollection('test_if_dead_tailable_cursors_close', options, function (err, collection) {\n          expect(err).to.not.exist;\n          let closeCount = 0;\n          const docs = Array.from({\n            length: 100\n          }).map(() => ({\n            a: 1\n          }));\n          collection.insertMany(docs, {\n            w: 'majority',\n            wtimeoutMS: 5000\n          }, err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find({}, {\n              tailable: true,\n              awaitData: true\n            });\n            const stream = cursor.stream();\n            stream.resume();\n\n            var validator = () => {\n              closeCount++;\n\n              if (closeCount === 2) {\n                done();\n              }\n            }; // we validate that the stream \"ends\" either cleanly or with an error\n\n\n            stream.on('end', validator);\n            stream.on('error', validator);\n            cursor.on('close', validator);\n            const docs = Array.from({\n              length: 100\n            }).map(() => ({\n              a: 1\n            }));\n            collection.insertMany(docs, err => {\n              expect(err).to.not.exist;\n              setTimeout(() => client.close());\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldAwaitData","suites":["Cursor"],"updatePoint":{"line":2047,"column":21,"index":66026},"line":2047,"code":"  it('shouldAwaitData', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      // http://www.mongodb.org/display/DOCS/Tailable+Cursors\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        const options = {\n          capped: true,\n          size: 8\n        };\n        db.createCollection('should_await_data_retry_tailable_cursor', options, (err, collection) => {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist; // Create cursor with awaitData, and timeout after the period specified\n\n            const cursor = collection.find({}, {\n              tailable: true,\n              awaitData: true\n            });\n            this.defer(() => cursor.close()); // Execute each\n\n            cursor.forEach(() => cursor.close(), () => {\n              // Even though cursor is exhausted, should not close session\n              // unless cursor is manually closed, due to awaitData / tailable\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldAwaitDataWithDocumentsAvailable","suites":["Cursor"],"updatePoint":{"line":2092,"column":43,"index":67639},"line":2092,"code":"  it('shouldAwaitDataWithDocumentsAvailable', function (done) {\n    // http://www.mongodb.org/display/DOCS/Tailable+Cursors\n    const configuration = this.configuration;\n    const client = configuration.newClient({\n      maxPoolSize: 1\n    });\n    client.connect((err, client) => {\n      expect(err).to.not.exist;\n      this.defer(() => client.close());\n      const db = client.db(configuration.db);\n      const options = {\n        capped: true,\n        size: 8\n      };\n      db.createCollection('should_await_data_no_docs', options, (err, collection) => {\n        expect(err).to.not.exist; // Create cursor with awaitData, and timeout after the period specified\n\n        const cursor = collection.find({}, {\n          tailable: true,\n          awaitData: true\n        });\n        this.defer(() => cursor.close());\n        cursor.forEach(() => {}, err => {\n          expect(err).to.not.exist;\n          done();\n        });\n      });\n    });\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should block waiting for new data to arrive when the cursor reaches the end of the capped collection","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2131,"column":108,"index":68955},"line":2131,"code":"    it('should block waiting for new data to arrive when the cursor reaches the end of the capped collection', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.2'\n        }\n      },\n\n      async test() {\n        const db = client.db('cursor_tailable');\n\n        try {\n          await db.collection('cursor_tailable').drop(); // eslint-disable-next-line no-empty\n        } catch (_) {}\n\n        const collection = await db.createCollection('cursor_tailable', {\n          capped: true,\n          size: 10000\n        });\n        const res = await collection.insertOne({\n          a: 1\n        });\n        expect(res).property('insertedId').to.exist;\n        cursor = collection.find({}, {\n          batchSize: 2,\n          tailable: true,\n          awaitData: true\n        });\n        const doc0 = await cursor.next();\n        expect(doc0).to.have.property('a', 1); // After 300ms make an insert\n\n        const later = runLater(async () => {\n          const res = await collection.insertOne({\n            b: 2\n          });\n          expect(res).property('insertedId').to.exist;\n        }, 300);\n        const start = new Date();\n        const doc1 = await cursor.next();\n        expect(doc1).to.have.property('b', 2);\n        const end = new Date();\n        await later; // make sure this finished, without a failure\n        // We should see here that cursor.next blocked for at least 300ms\n\n        expect(end.getTime() - start.getTime()).to.be.at.least(300);\n      }\n\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly retry tailable cursor connection","suites":["Cursor","awaiting data core tailable cursor test"],"line":2180,"code":"  it.skip('Should correctly retry tailable cursor connection', {","file":"integration/crud/misc_cursors.test.js","skipped":true,"dir":"test"},{"name":"shouldCorrectExecuteExplainHonoringLimit","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2222,"column":46,"index":71924},"line":2222,"code":"  it('shouldCorrectExecuteExplainHonoringLimit', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      docs[0] = {\n        _keywords: ['compact', 'ii2gd', 'led', '24-48v', 'presse-etoupe', 'bexbgl1d24483', 'flash', '48v', 'eexd', 'feu', 'presse', 'compris', 'rouge', 'etoupe', 'iic', 'ii2gdeexdiict5', 'red', 'aet']\n      };\n      docs[1] = {\n        _keywords: ['reducteur', '06212', 'd20/16', 'manch', 'd20', 'manchon', 'ard', 'sable', 'irl', 'red']\n      };\n      docs[2] = {\n        _keywords: ['reducteur', '06214', 'manch', 'd25/20', 'd25', 'manchon', 'ard', 'sable', 'irl', 'red']\n      };\n      docs[3] = {\n        _keywords: ['bar', 'rac', 'boite', '6790178', '50-240/4-35', '240', 'branch', 'coulee', 'ddc', 'red', 'ip2x']\n      };\n      docs[4] = {\n        _keywords: ['bar', 'ip2x', 'boite', '6790158', 'ddi', '240', 'branch', 'injectee', '50-240/4-35?', 'red']\n      };\n      docs[5] = {\n        _keywords: ['bar', 'ip2x', 'boite', '6790179', 'coulee', '240', 'branch', 'sdc', '50-240/4-35?', 'red', 'rac']\n      };\n      docs[6] = {\n        _keywords: ['bar', 'ip2x', 'boite', '6790159', '240', 'branch', 'injectee', '50-240/4-35?', 'sdi', 'red']\n      };\n      docs[7] = {\n        _keywords: ['6000', 'r-6000', 'resin', 'high', '739680', 'red', 'performance', 'brd', 'with', 'ribbon', 'flanges']\n      };\n      docs[8] = {\n        _keywords: ['804320', 'for', 'paint', 'roads', 'brd', 'red']\n      };\n      docs[9] = {\n        _keywords: ['38mm', 'padlock', 'safety', '813594', 'brd', 'red']\n      };\n      docs[10] = {\n        _keywords: ['114551', 'r6900', 'for', 'red', 'bmp71', 'brd', 'ribbon']\n      };\n      docs[11] = {\n        _keywords: ['catena', 'diameter', '621482', 'rings', 'brd', 'legend', 'red', '2mm']\n      };\n      docs[12] = {\n        _keywords: ['catena', 'diameter', '621491', 'rings', '5mm', 'brd', 'legend', 'red']\n      };\n      docs[13] = {\n        _keywords: ['catena', 'diameter', '621499', 'rings', '3mm', 'brd', 'legend', 'red']\n      };\n      docs[14] = {\n        _keywords: ['catena', 'diameter', '621508', 'rings', '5mm', 'brd', 'legend', 'red']\n      };\n      docs[15] = {\n        _keywords: ['insert', 'for', 'cable', '3mm', 'carrier', '621540', 'blank', 'brd', 'ademark', 'red']\n      };\n      docs[16] = {\n        _keywords: ['insert', 'for', 'cable', '621544', '3mm', 'carrier', 'brd', 'ademark', 'legend', 'red']\n      };\n      docs[17] = {\n        _keywords: ['catena', 'diameter', '6mm', '621518', 'rings', 'brd', 'legend', 'red']\n      };\n      docs[18] = {\n        _keywords: ['catena', 'diameter', '621455', '8mm', 'rings', 'brd', 'legend', 'red']\n      };\n      docs[19] = {\n        _keywords: ['catena', 'diameter', '621464', 'rings', '5mm', 'brd', 'legend', 'red']\n      };\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db); // Insert all the docs\n\n        var collection = db.collection('shouldCorrectExecuteExplainHonoringLimit');\n        collection.insert(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n          collection.createIndex({\n            _keywords: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            collection.find({\n              _keywords: 'red'\n            }).limit(10).toArray(function (err, result) {\n              expect(err).to.not.exist;\n              test.ok(result != null);\n              collection.find({\n                _keywords: 'red'\n              }, {}).limit(10).explain(function (err, result) {\n                expect(err).to.not.exist;\n                test.ok(result != null);\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldNotExplainWhenFalse","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2326,"column":31,"index":76094},"line":2326,"code":"  it('shouldNotExplainWhenFalse', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var doc = {\n        name: 'camera',\n        _keywords: ['compact', 'ii2gd', 'led', 'red', 'aet']\n      };\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var collection = db.collection('shouldNotExplainWhenFalse');\n        collection.insert(doc, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n          collection.find({\n            _keywords: 'red'\n          }).limit(10).toArray(function (err, result) {\n            expect(err).to.not.exist;\n            test.equal('camera', result[0].name);\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldFailToSetReadPreferenceOnCursor","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2361,"column":43,"index":77288},"line":2361,"code":"  it('shouldFailToSetReadPreferenceOnCursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n\n        try {\n          db.collection('shouldFailToSetReadPreferenceOnCursor').find().withReadPreference('notsecondary');\n          test.ok(false);\n        } catch (err) {} // eslint-disable-line\n\n\n        db.collection('shouldFailToSetReadPreferenceOnCursor').find().withReadPreference('secondary');\n        done();\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should allow setting the cursors readConcern through a builder","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2390,"column":68,"index":78288},"line":2390,"code":"  it('should allow setting the cursors readConcern through a builder', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.2'\n      }\n    },\n    test: withMonitoredClient(['find'], function (client, events, done) {\n      const db = client.db(this.configuration.db);\n      const cursor = db.collection('foo').find().withReadConcern('local');\n      expect(cursor).property('readConcern').to.have.property('level').equal('local');\n      cursor.toArray(err => {\n        expect(err).to.not.exist;\n        expect(events).to.have.length(1);\n        const findCommand = events[0];\n        expect(findCommand).nested.property('command.readConcern').to.eql({\n          level: 'local'\n        });\n        done();\n      });\n    })\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldNotFailDueToStackOverflowEach","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2411,"column":41,"index":78992},"line":2411,"code":"  it('shouldNotFailDueToStackOverflowEach', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('shouldNotFailDueToStackOverflowEach', (err, collection) => {\n          expect(err).to.not.exist;\n          var docs = [];\n          var total = 0;\n\n          for (var i = 0; i < 30000; i++) docs.push({\n            a: i\n          });\n\n          var allDocs = [];\n          var left = 0;\n\n          while (docs.length > 0) {\n            allDocs.push(docs.splice(0, 1000));\n          } // Get all batches we must insert\n\n\n          left = allDocs.length;\n          var totalI = 0; // Execute inserts\n\n          for (i = 0; i < left; i++) {\n            collection.insert(allDocs.shift(), configuration.writeConcernMax(), function (err, d) {\n              expect(err).to.not.exist;\n              left = left - 1;\n              totalI = totalI + d.length;\n\n              if (left === 0) {\n                collection.find({}).forEach(() => {\n                  total++;\n                }, err => {\n                  expect(err).to.not.exist;\n                  expect(total).to.equal(30000);\n                  done();\n                });\n              }\n            });\n          }\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldNotFailDueToStackOverflowToArray","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2469,"column":44,"index":80764},"line":2469,"code":"  it('shouldNotFailDueToStackOverflowToArray', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('shouldNotFailDueToStackOverflowToArray', (err, collection) => {\n          expect(err).to.not.exist;\n          var docs = [];\n\n          for (var i = 0; i < 30000; i++) docs.push({\n            a: i\n          });\n\n          var allDocs = [];\n          var left = 0;\n\n          while (docs.length > 0) {\n            allDocs.push(docs.splice(0, 1000));\n          } // Get all batches we must insert\n\n\n          left = allDocs.length;\n          var totalI = 0;\n          var timeout = 0; // Execute inserts\n\n          for (i = 0; i < left; i++) {\n            setTimeout(function () {\n              collection.insert(allDocs.shift(), configuration.writeConcernMax(), function (err, d) {\n                expect(err).to.not.exist;\n                left = left - 1;\n                totalI = totalI + d.length;\n\n                if (left === 0) {\n                  collection.find({}).toArray((err, items) => {\n                    expect(err).to.not.exist;\n                    test.equal(30000, items.length);\n                    done();\n                  });\n                }\n              });\n            }, timeout);\n            timeout = timeout + 100;\n          }\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlySkipAndLimit","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2528,"column":33,"index":82610},"line":2528,"code":"  it('shouldCorrectlySkipAndLimit', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var collection = db.collection('shouldCorrectlySkipAndLimit');\n        var docs = [];\n\n        for (var i = 0; i < 100; i++) docs.push({\n          a: i,\n          OrderNumber: i\n        });\n\n        collection.insert(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n          collection.find({}, {\n            OrderNumber: 1\n          }).skip(10).limit(10).toArray((err, items) => {\n            expect(err).to.not.exist;\n            test.equal(10, items[0].OrderNumber);\n            collection.find({}, {\n              OrderNumber: 1\n            }).skip(10).limit(10).count((err, count) => {\n              expect(err).to.not.exist;\n              test.equal(10, count);\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldFailToTailANormalCollection","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2572,"column":39,"index":84039},"line":2572,"code":"  it('shouldFailToTailANormalCollection', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var collection = db.collection('shouldFailToTailANormalCollection');\n        var docs = [];\n\n        for (var i = 0; i < 100; i++) docs.push({\n          a: i,\n          OrderNumber: i\n        });\n\n        collection.insert(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist;\n          const cursor = collection.find({}, {\n            tailable: true\n          });\n          cursor.forEach(() => {}, err => {\n            test.ok(err instanceof Error);\n            test.ok(typeof err.code === 'number'); // Close cursor b/c we did not exhaust cursor\n\n            cursor.close();\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUseFindAndCursorCount","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2613,"column":42,"index":85357},"line":2613,"code":"  it('shouldCorrectlyUseFindAndCursorCount', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      }); // DOC_LINE var client = new MongoClient(new Server('localhost', 27017));\n      // DOC_START\n      // Establish connection to db\n\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db); // Create a lot of documents to insert\n\n        var docs = [];\n\n        for (var i = 0; i < 100; i++) {\n          docs.push({\n            a: i\n          });\n        } // Create a collection\n\n\n        db.createCollection('test_close_function_on_cursor_2', (err, collection) => {\n          expect(err).to.not.exist; // Insert documents into collection\n\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            const cursor = collection.find({});\n            cursor.count((err, count) => {\n              expect(err).to.not.exist;\n              test.equal(100, count);\n              done();\n            });\n          });\n        });\n      }); // DOC_END\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should correctly apply hint to count command for cursor","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2659,"column":61,"index":86871},"line":2659,"code":"  it('should correctly apply hint to count command for cursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded'],\n        mongodb: '>2.5.5'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      }); // DOC_LINE var client = new MongoClient(new Server('localhost', 27017));\n      // DOC_START\n      // Establish connection to db\n\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var col = db.collection('count_hint');\n        col.insert([{\n          i: 1\n        }, {\n          i: 2\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, err => {\n          expect(err).to.not.exist;\n          col.createIndex({\n            i: 1\n          }, err => {\n            expect(err).to.not.exist;\n            col.find({\n              i: 1\n            }, {\n              hint: '_id_'\n            }).count((err, count) => {\n              expect(err).to.not.exist;\n              test.equal(1, count);\n              col.find({}, {\n                hint: '_id_'\n              }).count((err, count) => {\n                expect(err).to.not.exist;\n                test.equal(2, count);\n                col.find({\n                  i: 1\n                }, {\n                  hint: 'BAD HINT'\n                }).count(err => {\n                  test.ok(err != null);\n                  col.createIndex({\n                    x: 1\n                  }, {\n                    sparse: true\n                  }, err => {\n                    expect(err).to.not.exist;\n                    col.find({\n                      i: 1\n                    }, {\n                      hint: 'x_1'\n                    }).count((err, count) => {\n                      expect(err).to.not.exist;\n                      test.equal(0, count);\n                      col.find({}, {\n                        hint: 'i_1'\n                      }).count((err, count) => {\n                        expect(err).to.not.exist;\n                        test.equal(2, count);\n                        done();\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      }); // DOC_END\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Terminate each after first document by returning false","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2743,"column":60,"index":89466},"line":2743,"code":"  it('Terminate each after first document by returning false', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db); // Create a lot of documents to insert\n\n        var docs = [];\n\n        for (var i = 0; i < 100; i++) {\n          docs.push({\n            a: i\n          });\n        } // Create a collection\n\n\n        db.createCollection('terminate_each_returning_false', (err, collection) => {\n          expect(err).to.not.exist; // Insert documents into collection\n\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist;\n            var finished = false;\n            collection.find({}).forEach(doc => {\n              expect(doc).to.exist;\n              test.equal(finished, false);\n              finished = true;\n              done();\n              return false;\n            }, err => {\n              expect(err).to.not.exist;\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly handle maxTimeMS as part of findOne options","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2790,"column":66,"index":90959},"line":2790,"code":"  it('Should correctly handle maxTimeMS as part of findOne options', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var donkey = {\n          color: 'brown'\n        };\n        db.collection('donkies').insertOne(donkey, function (err, result) {\n          expect(err).to.not.exist;\n          var query = {\n            _id: result.insertedId\n          };\n          var options = {\n            maxTimeMS: 1000\n          };\n          db.collection('donkies').findOne(query, options, function (err, doc) {\n            expect(err).to.not.exist;\n            test.equal('brown', doc.color);\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly handle batchSize of 2","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2827,"column":44,"index":92136},"line":2827,"code":"  it('Should correctly handle batchSize of 2', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        const collectionName = 'should_correctly_handle_batchSize_2';\n        db.collection(collectionName).insert([{\n          x: 1\n        }, {\n          x: 2\n        }, {\n          x: 3\n        }], err => {\n          expect(err).to.not.exist;\n          const cursor = db.collection(collectionName).find({}, {\n            batchSize: 2\n          });\n          this.defer(() => cursor.close());\n          cursor.next(err => {\n            expect(err).to.not.exist;\n            cursor.next(err => {\n              expect(err).to.not.exist;\n              cursor.next(err => {\n                expect(err).to.not.exist;\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should report database name and collection name","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2871,"column":53,"index":93501},"line":2871,"code":"  it('Should report database name and collection name', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        const cursor = db.collection('myCollection').find({});\n        test.equal('myCollection', cursor.namespace.collection);\n        test.equal('integration_tests', cursor.namespace.db);\n        done();\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute count on cursor with maxTimeMS","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2893,"column":61,"index":94226},"line":2893,"code":"  it('Should correctly execute count on cursor with maxTimeMS', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n\n      for (var i = 0; i < 1000; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('Should_correctly_execute_count_on_cursor_2', function (err, collection) {\n          expect(err).to.not.exist; // insert all docs\n\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist; // Create a cursor for the content\n\n            var cursor = collection.find({});\n            cursor.limit(100);\n            cursor.skip(10);\n            cursor.count({\n              maxTimeMS: 1000\n            }, err => {\n              expect(err).to.not.exist; // Create a cursor for the content\n\n              var cursor = collection.find({});\n              cursor.limit(100);\n              cursor.skip(10);\n              cursor.maxTimeMS(100);\n              cursor.count(err => {\n                expect(err).to.not.exist;\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute count on cursor with maxTimeMS set using legacy method","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2948,"column":85,"index":96007},"line":2948,"code":"  it('Should correctly execute count on cursor with maxTimeMS set using legacy method', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n\n      for (var i = 0; i < 1000; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('Should_correctly_execute_count_on_cursor_3', function (err, collection) {\n          expect(err).to.not.exist; // insert all docs\n\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist; // Create a cursor for the content\n\n            var cursor = collection.find({}, {\n              maxTimeMS: 100\n            });\n            cursor.toArray(err => {\n              expect(err).to.not.exist;\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply map to toArray","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":2993,"column":43,"index":97404},"line":2993,"code":"  it('Should correctly apply map to toArray', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n\n      for (var i = 0; i < 1000; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var collection = db.collection('map_toArray'); // insert all docs\n\n        collection.insert(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist; // Create a cursor for the content\n\n          var cursor = collection.find({}).map(function () {\n            return {\n              a: 1\n            };\n          }).batchSize(5).limit(10);\n          cursor.toArray(function (err, docs) {\n            expect(err).to.not.exist;\n            test.equal(10, docs.length); // Ensure all docs where mapped\n\n            docs.forEach(doc => {\n              expect(doc).property('a').to.equal(1);\n            });\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply map to next","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3043,"column":40,"index":98940},"line":3043,"code":"  it('Should correctly apply map to next', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const docs = [];\n\n      for (var i = 0; i < 1000; i++) {\n        const d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        const collection = db.collection('map_next'); // insert all docs\n\n        collection.insert(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist; // Create a cursor for the content\n\n          const cursor = collection.find({}).map(function () {\n            return {\n              a: 1\n            };\n          }).batchSize(5).limit(10);\n          this.defer(() => cursor.close());\n          cursor.next((err, doc) => {\n            expect(err).to.not.exist;\n            test.equal(1, doc.a);\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply map to each","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3090,"column":40,"index":100372},"line":3090,"code":"  it('Should correctly apply map to each', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n\n      for (var i = 0; i < 1000; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        const collection = db.collection('map_each'); // insert all docs\n\n        collection.insert(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist; // Create a cursor for the content\n\n          var cursor = collection.find({}).map(function () {\n            return {\n              a: 1\n            };\n          }).batchSize(5).limit(10);\n          cursor.forEach(doc => {\n            test.equal(1, doc.a);\n          }, err => {\n            expect(err).to.not.exist;\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply map to forEach","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3137,"column":43,"index":101775},"line":3137,"code":"  it('Should correctly apply map to forEach', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n\n      for (var i = 0; i < 1000; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var collection = db.collection('map_forEach'); // insert all docs\n\n        collection.insert(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist; // Create a cursor for the content\n\n          var cursor = collection.find({}).map(function () {\n            return {\n              a: 2\n            };\n          }).map(function (x) {\n            return {\n              a: x.a * x.a\n            };\n          }).batchSize(5).limit(10);\n          cursor.forEach(doc => {\n            test.equal(4, doc.a);\n          }, err => {\n            expect(err).to.not.exist;\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply multiple uses of map and apply forEach","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3188,"column":67,"index":103298},"line":3188,"code":"  it('Should correctly apply multiple uses of map and apply forEach', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n\n      for (var i = 0; i < 1000; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var collection = db.collection('map_mapmapforEach'); // insert all docs\n\n        collection.insert(docs, configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist; // Create a cursor for the content\n\n          var cursor = collection.find({}).map(function () {\n            return {\n              a: 1\n            };\n          }).batchSize(5).limit(10);\n          cursor.forEach(doc => {\n            expect(doc).property('a').to.equal(1);\n          }, err => {\n            expect(err).to.not.exist;\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply skip and limit to large set of documents","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3235,"column":69,"index":104751},"line":3235,"code":"  it('Should correctly apply skip and limit to large set of documents', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var collection = db.collection('cursor_limit_skip_correctly'); // Insert x number of docs\n\n        var ordered = collection.initializeUnorderedBulkOp();\n\n        for (var i = 0; i < 6000; i++) {\n          ordered.insert({\n            a: i\n          });\n        }\n\n        ordered.execute({\n          writeConcern: {\n            w: 1\n          }\n        }, err => {\n          expect(err).to.not.exist; // Let's attempt to skip and limit\n\n          collection.find({}).limit(2016).skip(2016).toArray(function (err, docs) {\n            expect(err).to.not.exist;\n            test.equal(2016, docs.length);\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should tail cursor using maxAwaitTimeMS for 3.2 or higher","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3278,"column":63,"index":106073},"line":3278,"code":"  it('should tail cursor using maxAwaitTimeMS for 3.2 or higher', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>3.1.9'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var options = {\n          capped: true,\n          size: 8\n        };\n        db.createCollection('should_await_data_max_awaittime_ms', options, function (err, collection) {\n          expect(err).to.not.exist;\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist; // Create cursor with awaitData, and timeout after the period specified\n\n            var cursor = collection.find({}).addCursorFlag('tailable', true).addCursorFlag('awaitData', true).maxAwaitTimeMS(500);\n            const s = new Date();\n            cursor.forEach(() => {\n              setTimeout(() => cursor.close(), 300);\n            }, () => {\n              test.ok(new Date().getTime() - s.getTime() >= 500);\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should not emit any events after close event emitted due to cursor killed","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3318,"column":79,"index":107539},"line":3318,"code":"  it('Should not emit any events after close event emitted due to cursor killed', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        var collection = db.collection('cursor_limit_skip_correctly'); // Insert x number of docs\n\n        var ordered = collection.initializeUnorderedBulkOp();\n\n        for (var i = 0; i < 100; i++) {\n          ordered.insert({\n            a: i\n          });\n        }\n\n        ordered.execute({\n          writeConcern: {\n            w: 1\n          }\n        }, err => {\n          expect(err).to.not.exist; // Let's attempt to skip and limit\n\n          var cursor = collection.find({}).batchSize(10);\n          const stream = cursor.stream();\n          stream.on('data', function () {\n            stream.destroy();\n          });\n          cursor.on('close', function () {\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteEnsureIndexWithNoCallback","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3364,"column":53,"index":108914},"line":3364,"code":"  it('shouldCorrectlyExecuteEnsureIndexWithNoCallback', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n\n      for (var i = 0; i < 1; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          createdAt: new Date(d)\n        };\n      }\n\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('shouldCorrectlyExecuteEnsureIndexWithNoCallback', function (err, collection) {\n          expect(err).to.not.exist; // ensure index of createdAt index\n\n          collection.createIndex({\n            createdAt: 1\n          }, err => {\n            expect(err).to.not.exist; // insert all docs\n\n            collection.insert(docs, configuration.writeConcernMax(), err => {\n              expect(err).to.not.exist; // Find with sort\n\n              collection.find().sort(['createdAt', 'asc']).toArray((err, items) => {\n                expect(err).to.not.exist;\n                test.equal(1, items.length);\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute count on cursor with limit and skip","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3412,"column":66,"index":110487},"line":3412,"code":"  it('Should correctly execute count on cursor with limit and skip', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n\n      for (var i = 0; i < 50; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('negative_batch_size_and_limit_set', (err, collection) => {\n          expect(err).to.not.exist; // insert all docs\n\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist; // Create a cursor for the content\n\n            var cursor = collection.find({});\n            cursor.limit(100).skip(0).count(function (err, c) {\n              expect(err).to.not.exist;\n              test.equal(50, c);\n              var cursor = collection.find({});\n              cursor.limit(100).skip(0).toArray(err => {\n                expect(err).to.not.exist;\n                test.equal(50, c);\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Should correctly handle negative batchSize and set the limit","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3461,"column":66,"index":112107},"line":3461,"code":"  it('Should correctly handle negative batchSize and set the limit', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var docs = [];\n      const configuration = this.configuration;\n\n      for (var i = 0; i < 50; i++) {\n        var d = new Date().getTime() + i * 1000;\n        docs[i] = {\n          a: i,\n          createdAt: new Date(d)\n        };\n      }\n\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.createCollection('Should_correctly_execute_count_on_cursor_1_', function (err, collection) {\n          expect(err).to.not.exist; // insert all docs\n\n          collection.insert(docs, configuration.writeConcernMax(), err => {\n            expect(err).to.not.exist; // Create a cursor for the content\n\n            var cursor = collection.find({});\n            cursor.batchSize(-10).next(err => {\n              expect(err).to.not.exist;\n              test.ok(cursor.id.equals(BSON.Long.ZERO));\n              done();\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Correctly decorate the cursor count command with skip, limit, hint, readConcern","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3505,"column":85,"index":113568},"line":3505,"code":"  it('Correctly decorate the cursor count command with skip, limit, hint, readConcern', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var started = [];\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      client.on('commandStarted', function (event) {\n        if (event.commandName === 'count') started.push(event);\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        db.collection('cursor_count_test', {\n          readConcern: {\n            level: 'local'\n          }\n        }).find({\n          project: '123'\n        }).limit(5).skip(5).hint({\n          project: 1\n        }).count(err => {\n          expect(err).to.not.exist;\n          test.equal(1, started.length);\n          if (started[0].command.readConcern) test.deepEqual({\n            level: 'local'\n          }, started[0].command.readConcern);\n          test.deepEqual({\n            project: 1\n          }, started[0].command.hint);\n          test.equal(5, started[0].command.skip);\n          test.equal(5, started[0].command.limit);\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"Correctly decorate the collection count command with skip, limit, hint, readConcern","suites":["Cursor","awaiting data core tailable cursor test"],"line":3551,"code":"  it.skip('Correctly decorate the collection count command with skip, limit, hint, readConcern', {","file":"integration/crud/misc_cursors.test.js","skipped":true,"dir":"test"},{"name":"Should properly kill a cursor","suites":["Cursor","awaiting data core tailable cursor test"],"line":3604,"code":"  it.skip('Should properly kill a cursor', {","file":"integration/crud/misc_cursors.test.js","skipped":true,"dir":"test"},{"name":"should return implicit session to pool when client-side cursor exhausts results on initial query","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3666,"column":102,"index":119124},"line":3666,"code":"  it('should return implicit session to pool when client-side cursor exhausts results on initial query', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded'],\n        mongodb: '>=3.6.0'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        const collection = db.collection('cursor_session_tests');\n        collection.insertMany([{\n          a: 1,\n          b: 2\n        }], err => {\n          expect(err).to.not.exist;\n          const cursor = collection.find({});\n          cursor.next(function () {\n            test.equal(client.topology.s.sessions.size, 0);\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should return implicit session to pool when client-side cursor exhausts results after a getMore","suites":["Cursor","awaiting data core tailable cursor test"],"updatePoint":{"line":3699,"column":101,"index":120102},"line":3699,"code":"  it('should return implicit session to pool when client-side cursor exhausts results after a getMore', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded'],\n        mongodb: '>=3.6.0'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const db = client.db(configuration.db);\n        const collection = db.collection('cursor_session_tests2');\n        const docs = [{\n          a: 1,\n          b: 2\n        }, {\n          a: 3,\n          b: 4\n        }, {\n          a: 5,\n          b: 6\n        }, {\n          a: 7,\n          b: 8\n        }, {\n          a: 9,\n          b: 10\n        }];\n        collection.insertMany(docs, err => {\n          expect(err).to.not.exist;\n          const cursor = collection.find({}, {\n            batchSize: 3\n          });\n          cursor.next(function () {\n            test.equal(client.topology.s.sessions.size, 1);\n            cursor.next(function () {\n              test.equal(client.topology.s.sessions.size, 1);\n              cursor.next(function () {\n                test.equal(client.topology.s.sessions.size, 1);\n                cursor.next(function () {\n                  test.equal(client.topology.s.sessions.size, 0);\n                  done();\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"removes the existing session from the cloned cursor","suites":["Cursor","#clone","when executing on a find cursor"],"updatePoint":{"line":3773,"column":61,"index":122125},"line":3773,"code":"      it('removes the existing session from the cloned cursor', function () {\n        const docs = [{\n          name: 'test1'\n        }, {\n          name: 'test2'\n        }];\n        return collection.insertMany(docs).then(() => {\n          const cursor = collection.find({}, {\n            batchSize: 1\n          });\n          return cursor.next().then(doc => {\n            expect(doc).to.exist;\n            const clonedCursor = cursor.clone();\n            expect(clonedCursor.cursorOptions.session).to.not.exist;\n            expect(clonedCursor.session).to.not.exist;\n          }).finally(() => {\n            return cursor.close();\n          });\n        });\n      });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"removes the existing session from the cloned cursor","suites":["Cursor","#clone","when executing on an aggregation cursor"],"updatePoint":{"line":3795,"column":61,"index":122871},"line":3795,"code":"      it('removes the existing session from the cloned cursor', function () {\n        const docs = [{\n          name: 'test1'\n        }, {\n          name: 'test2'\n        }];\n        return collection.insertMany(docs).then(() => {\n          const cursor = collection.aggregate([{\n            $match: {}\n          }], {\n            batchSize: 1\n          });\n          return cursor.next().then(doc => {\n            expect(doc).to.exist;\n            const clonedCursor = cursor.clone();\n            expect(clonedCursor.cursorOptions.session).to.not.exist;\n            expect(clonedCursor.session).to.not.exist;\n          }).finally(() => {\n            return cursor.close();\n          });\n        });\n      });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should propagate error when exceptions are thrown from an awaited forEach call","suites":["Cursor","Cursor forEach Error propagation"],"updatePoint":{"line":3841,"column":86,"index":124240},"line":3841,"code":"    it('should propagate error when exceptions are thrown from an awaited forEach call', async function () {\n      const docs = [{\n        unique_key_2035: 1\n      }, {\n        unique_key_2035: 2\n      }, {\n        unique_key_2035: 3\n      }];\n      await collection.insertMany(docs).catch(() => {\n        expect.fail('Failed to insert documents');\n      });\n      cursor = collection.find({\n        unique_key_2035: {\n          $exists: true\n        }\n      });\n      await cursor.forEach(() => {\n        throw new Error('FAILURE IN FOREACH CALL');\n      }).then(() => {\n        expect.fail('Error in forEach call not caught');\n      }).catch(err => {\n        expect(err.message).to.deep.equal('FAILURE IN FOREACH CALL');\n      });\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should return a promise when no callback supplied to forEach method","suites":["Cursor","Cursor forEach Error propagation"],"updatePoint":{"line":3866,"column":73,"index":124974},"line":3866,"code":"  it('should return a promise when no callback supplied to forEach method', function () {\n    const configuration = this.configuration;\n    const client = configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    return client.connect().then(() => {\n      this.defer(() => client.close());\n      const db = client.db(configuration.db);\n      const collection = db.collection('cursor_session_tests2');\n      const cursor = collection.find();\n      this.defer(() => cursor.close());\n      const promise = cursor.forEach(() => {});\n      expect(promise).to.exist.and.to.be.an.instanceof(Promise);\n      return promise;\n    });\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should return false when exhausted and hasNext called more than once","suites":["Cursor","Cursor forEach Error propagation"],"updatePoint":{"line":3884,"column":74,"index":125626},"line":3884,"code":"  it('should return false when exhausted and hasNext called more than once', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    client.connect((err, client) => {\n      expect(err).to.not.exist;\n      this.defer(() => client.close());\n      const db = client.db(configuration.db);\n      db.createCollection('cursor_hasNext_test').then(() => {\n        const cursor = db.collection('cursor_hasNext_test').find();\n        this.defer(() => cursor.close());\n        cursor.hasNext().then(val1 => {\n          expect(val1).to.equal(false);\n          return cursor.hasNext();\n        }).then(val2 => {\n          expect(val2).to.equal(false);\n          done();\n        });\n      });\n    });\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"stream should apply the supplied transformation function to each document in the stream","suites":["Cursor","Cursor forEach Error propagation"],"updatePoint":{"line":3964,"column":93,"index":127985},"line":3964,"code":"  it('stream should apply the supplied transformation function to each document in the stream', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    const expectedDocs = [{\n      _id: 0,\n      b: 1,\n      c: 0\n    }, {\n      _id: 1,\n      b: 1,\n      c: 0\n    }, {\n      _id: 2,\n      b: 1,\n      c: 0\n    }];\n    const config = {\n      client: client,\n      configuration: configuration,\n      collectionName: 'stream-test-transform',\n      transformFunc: doc => ({\n        _id: doc._id,\n        b: doc.a.b,\n        c: doc.a.c\n      }),\n      expectedSet: new Set(expectedDocs)\n    };\n    testTransformStream(config, done);\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"stream should return a stream of unmodified docs if no transform function applied","suites":["Cursor","Cursor forEach Error propagation"],"updatePoint":{"line":3997,"column":87,"index":128719},"line":3997,"code":"  it('stream should return a stream of unmodified docs if no transform function applied', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    const expectedDocs = [{\n      _id: 0,\n      a: {\n        b: 1,\n        c: 0\n      }\n    }, {\n      _id: 1,\n      a: {\n        b: 1,\n        c: 0\n      }\n    }, {\n      _id: 2,\n      a: {\n        b: 1,\n        c: 0\n      }\n    }];\n    const config = {\n      client: client,\n      configuration: configuration,\n      collectionName: 'transformStream-test-notransform',\n      transformFunc: null,\n      expectedSet: new Set(expectedDocs)\n    };\n    testTransformStream(config, done);\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should apply parent read preference to count command","suites":["Cursor","Cursor forEach Error propagation"],"line":4032,"code":"  it.skip('should apply parent read preference to count command', function (done) {","file":"integration/crud/misc_cursors.test.js","skipped":true,"dir":"test"},{"name":"should not consume first document on hasNext when streaming","suites":["Cursor","Cursor forEach Error propagation"],"updatePoint":{"line":4054,"column":65,"index":130702},"line":4054,"code":"  it('should not consume first document on hasNext when streaming', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    client.connect(err => {\n      expect(err).to.not.exist;\n      this.defer(() => client.close());\n      const collection = client.db().collection('documents');\n      collection.drop(() => {\n        const docs = [{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }];\n        collection.insertMany(docs, err => {\n          expect(err).to.not.exist;\n          const cursor = collection.find({}, {\n            sort: {\n              a: 1\n            }\n          });\n          cursor.hasNext((err, hasNext) => {\n            expect(err).to.not.exist;\n            expect(hasNext).to.be.true;\n            const collected = [];\n            const stream = new Writable({\n              objectMode: true,\n              write: (chunk, encoding, next) => {\n                collected.push(chunk);\n                next(undefined, chunk);\n              }\n            });\n            const cursorStream = cursor.stream();\n            cursorStream.on('end', () => {\n              expect(collected).to.have.length(3);\n              expect(collected).to.eql(docs);\n              done();\n            });\n            cursorStream.pipe(stream);\n          });\n        });\n      });\n    });\n  });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should correctly apply map transform to cursor as readable stream","suites":["Cursor","transforms"],"updatePoint":{"line":4104,"column":73,"index":132178},"line":4104,"code":"    it('should correctly apply map transform to cursor as readable stream', function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect(err => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const docs = 'Aaden Aaron Adrian Aditya Bob Joe'.split(' ').map(x => ({\n          name: x\n        }));\n        const coll = client.db(configuration.db).collection('cursor_stream_mapping');\n        coll.insertMany(docs, err => {\n          expect(err).to.not.exist;\n          const bag = [];\n          const stream = coll.find().project({\n            _id: 0,\n            name: 1\n          }).map(doc => ({\n            mapped: doc\n          })).stream().on('data', doc => bag.push(doc));\n          stream.on('error', done).on('end', () => {\n            expect(bag.map(x => x.mapped)).to.eql(docs.map(x => ({\n              name: x.name\n            })));\n            done();\n          });\n        });\n      });\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should correctly apply map transform when converting cursor to array","suites":["Cursor","transforms"],"updatePoint":{"line":4132,"column":76,"index":133199},"line":4132,"code":"    it('should correctly apply map transform when converting cursor to array', function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect(err => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close());\n        const docs = 'Aaden Aaron Adrian Aditya Bob Joe'.split(' ').map(x => ({\n          name: x\n        }));\n        const coll = client.db(configuration.db).collection('cursor_toArray_mapping');\n        coll.insertMany(docs, err => {\n          expect(err).to.not.exist;\n          coll.find().project({\n            _id: 0,\n            name: 1\n          }).map(doc => ({\n            mapped: doc\n          })).toArray((err, mappedDocs) => {\n            expect(err).to.not.exist;\n            expect(mappedDocs.map(x => x.mapped)).to.eql(docs.map(x => ({\n              name: x.name\n            })));\n            done();\n          });\n        });\n      });\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use find options object","suites":["Cursor","sort"],"updatePoint":{"line":4187,"column":38,"index":135191},"line":4187,"code":"    it('should use find options object', findSort({\n      alpha: 1\n    }, new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use find options string","suites":["Cursor","sort"],"updatePoint":{"line":4190,"column":38,"index":135292},"line":4190,"code":"    it('should use find options string', findSort('alpha', new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use find options shallow array","suites":["Cursor","sort"],"updatePoint":{"line":4191,"column":45,"index":135385},"line":4191,"code":"    it('should use find options shallow array', findSort(['alpha', 1], new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use find options deep array","suites":["Cursor","sort"],"updatePoint":{"line":4192,"column":42,"index":135480},"line":4192,"code":"    it('should use find options deep array', findSort([['alpha', 1]], new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use cursor.sort object","suites":["Cursor","sort"],"updatePoint":{"line":4193,"column":37,"index":135572},"line":4193,"code":"    it('should use cursor.sort object', cursorSort({\n      alpha: 1\n    }, new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use cursor.sort string","suites":["Cursor","sort"],"updatePoint":{"line":4196,"column":37,"index":135674},"line":4196,"code":"    it('should use cursor.sort string', cursorSort('alpha', new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use cursor.sort shallow array","suites":["Cursor","sort"],"updatePoint":{"line":4197,"column":44,"index":135768},"line":4197,"code":"    it('should use cursor.sort shallow array', cursorSort(['alpha', 1], new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use cursor.sort deep array","suites":["Cursor","sort"],"updatePoint":{"line":4198,"column":41,"index":135864},"line":4198,"code":"    it('should use cursor.sort deep array', cursorSort([['alpha', 1]], new Map([['alpha', 1]])));","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"formatSort - one key","suites":["Cursor","sort"],"updatePoint":{"line":4199,"column":28,"index":135949},"line":4199,"code":"    it('formatSort - one key', () => {\n      // TODO (NODE-3236): These are unit tests for a standalone function and should be moved out of the cursor context file\n      expect(formatSort('alpha')).to.deep.equal(new Map([['alpha', 1]]));\n      expect(formatSort(['alpha'])).to.deep.equal(new Map([['alpha', 1]]));\n      expect(formatSort('alpha', 1)).to.deep.equal(new Map([['alpha', 1]]));\n      expect(formatSort('alpha', 'asc')).to.deep.equal(new Map([['alpha', 1]]));\n      expect(formatSort([['alpha', 'asc']])).to.deep.equal(new Map([['alpha', 1]]));\n      expect(formatSort('alpha', 'ascending')).to.deep.equal(new Map([['alpha', 1]]));\n      expect(formatSort({\n        alpha: 1\n      })).to.deep.equal(new Map([['alpha', 1]]));\n      expect(formatSort('beta')).to.deep.equal(new Map([['beta', 1]]));\n      expect(formatSort(['beta'])).to.deep.equal(new Map([['beta', 1]]));\n      expect(formatSort('beta', -1)).to.deep.equal(new Map([['beta', -1]]));\n      expect(formatSort('beta', 'desc')).to.deep.equal(new Map([['beta', -1]]));\n      expect(formatSort('beta', 'descending')).to.deep.equal(new Map([['beta', -1]]));\n      expect(formatSort({\n        beta: -1\n      })).to.deep.equal(new Map([['beta', -1]]));\n      expect(formatSort({\n        alpha: {\n          $meta: 'hi'\n        }\n      })).to.deep.equal(new Map([['alpha', {\n        $meta: 'hi'\n      }]]));\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"formatSort - multi key","suites":["Cursor","sort"],"updatePoint":{"line":4226,"column":30,"index":137333},"line":4226,"code":"    it('formatSort - multi key', () => {\n      expect(formatSort(['alpha', 'beta'])).to.deep.equal(new Map([['alpha', 1], ['beta', 1]]));\n      expect(formatSort({\n        alpha: 1,\n        beta: 1\n      })).to.deep.equal(new Map([['alpha', 1], ['beta', 1]]));\n      expect(formatSort([['alpha', 'asc'], ['beta', 'ascending']])).to.deep.equal(new Map([['alpha', 1], ['beta', 1]]));\n      expect(formatSort(new Map([['alpha', 'asc'], ['beta', 'ascending']]))).to.deep.equal(new Map([['alpha', 1], ['beta', 1]]));\n      expect(formatSort([['3', 'asc'], ['1', 'ascending']])).to.deep.equal(new Map([['3', 1], ['1', 1]]));\n      expect(formatSort({\n        alpha: {\n          $meta: 'hi'\n        },\n        beta: 'ascending'\n      })).to.deep.equal(new Map([['alpha', {\n        $meta: 'hi'\n      }], ['beta', 1]]));\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should use allowDiskUse option on sort","suites":["Cursor","sort"],"updatePoint":{"line":4244,"column":46,"index":138169},"line":4244,"code":"    it('should use allowDiskUse option on sort', {\n      metadata: {\n        requires: {\n          mongodb: '>=4.4'\n        }\n      },\n      test: withMonitoredClient('find', function (client, events, done) {\n        const db = client.db('test');\n        const collection = db.collection('test_sort_allow_disk_use');\n        const cursor = collection.find({}).sort(['alpha', 1]).allowDiskUse();\n        cursor.next(err => {\n          expect(err).to.not.exist;\n          const {\n            command\n          } = events.shift();\n          expect(command.sort).to.deep.equal(new Map([['alpha', 1]]));\n          expect(command.allowDiskUse).to.be.true;\n          cursor.close(done);\n        });\n      })\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should error if allowDiskUse option used without sort","suites":["Cursor","sort"],"updatePoint":{"line":4265,"column":61,"index":138893},"line":4265,"code":"    it('should error if allowDiskUse option used without sort', {\n      metadata: {\n        requires: {\n          mongodb: '>=4.4'\n        }\n      },\n      test: withClient(function (client, done) {\n        const db = client.db('test');\n        const collection = db.collection('test_sort_allow_disk_use');\n        expect(() => collection.find({}).allowDiskUse()).to.throw(/Option \"allowDiskUse\" requires a sort specification/);\n        done();\n      })\n    });","file":"integration/crud/misc_cursors.test.js","skipped":false,"dir":"test"},{"name":"should create records with custom PK factory","suites":["PkFactory"],"updatePoint":{"line":19,"column":50,"index":331},"line":19,"code":"  it('should create records with custom PK factory', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration; // Custom factory (need to provide a 12 byte array);\n\n      var CustomPKFactory = {\n        createPk() {\n          return new ObjectId('aaaaaaaaaaaa');\n        }\n\n      };\n      var client = configuration.newClient({\n        writeConcern: {\n          w: 1\n        },\n        maxPoolSize: 1\n      }, {\n        pkFactory: CustomPKFactory\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('test_custom_key');\n        collection.insert({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.find({\n            _id: new ObjectId('aaaaaaaaaaaa')\n          }).toArray(function (err, items) {\n            expect(items.length).to.equal(1);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/pk_factory.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute stats using Promise","suites":["stats"],"updatePoint":{"line":17,"column":50,"index":361},"line":17,"code":"  it('Should correctly execute stats using Promise', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var url = configuration.url();\n      url = url.indexOf('?') !== -1 ? f('%s&%s', url, 'maxPoolSize=5') : f('%s?%s', url, 'maxPoolSize=5');\n      const client = configuration.newClient(url);\n      client.connect().then(function (client) {\n        client.db(configuration.db).stats().then(function (stats) {\n          test.ok(stats != null);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/crud/promise_stats.test.js","skipped":false,"dir":"test"},{"name":"should correctly clear out collection","suites":["Remove"],"updatePoint":{"line":15,"column":43,"index":257},"line":15,"code":"  it('should correctly clear out collection', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      const self = this;\n      const client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(self.configuration.db);\n        expect(err).to.not.exist;\n        db.createCollection('test_clear', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_clear');\n          collection.insert({\n            i: 1\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n            collection.insert({\n              i: 2\n            }, {\n              writeConcern: {\n                w: 1\n              }\n            }, function (err) {\n              expect(err).to.not.exist;\n              collection.count(function (err, count) {\n                expect(err).to.not.exist;\n                expect(count).to.equal(2); // Clear the collection\n\n                collection.remove({}, {\n                  writeConcern: {\n                    w: 1\n                  }\n                }, function (err, r) {\n                  expect(err).to.not.exist;\n                  expect(r).property('deletedCount').to.equal(2);\n                  collection.count(function (err, count) {\n                    expect(err).to.not.exist;\n                    expect(count).to.equal(0); // Let's close the db\n\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/remove.test.js","skipped":false,"dir":"test"},{"name":"should correctly remove document using RegExp","suites":["Remove"],"updatePoint":{"line":73,"column":51,"index":2077},"line":73,"code":"  it('should correctly remove document using RegExp', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      const self = this;\n      const client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(self.configuration.db);\n        expect(err).to.not.exist;\n        db.createCollection('test_remove_regexp', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('test_remove_regexp');\n          collection.insert({\n            address: '485 7th ave new york'\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist; // Clear the collection\n\n            collection.remove({\n              address: /485 7th ave/\n            }, {\n              writeConcern: {\n                w: 1\n              }\n            }, function (err, r) {\n              expect(r).property('deletedCount').to.equal(1);\n              collection.count(function (err, count) {\n                expect(err).to.not.exist;\n                expect(count).to.equal(0); // Let's close the db\n\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/remove.test.js","skipped":false,"dir":"test"},{"name":"should correctly remove only first document","suites":["Remove"],"updatePoint":{"line":119,"column":49,"index":3515},"line":119,"code":"  it('should correctly remove only first document', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      const self = this;\n      const client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(self.configuration.db);\n        expect(err).to.not.exist;\n        db.createCollection('shouldCorrectlyRemoveOnlyFirstDocument', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('shouldCorrectlyRemoveOnlyFirstDocument');\n          collection.insert([{\n            a: 1\n          }, {\n            a: 1\n          }, {\n            a: 1\n          }, {\n            a: 1\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist; // Remove the first\n\n            collection.remove({\n              a: 1\n            }, {\n              writeConcern: {\n                w: 1\n              },\n              single: true\n            }, function (err, r) {\n              expect(r).property('deletedCount').to.equal(1);\n              collection.find({\n                a: 1\n              }).count(function (err, result) {\n                expect(result).to.equal(3);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/remove.test.js","skipped":false,"dir":"test"},{"name":"should not error on empty remove","suites":["Remove"],"updatePoint":{"line":172,"column":38,"index":5041},"line":172,"code":"  it('should not error on empty remove', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      const self = this;\n      const client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(self.configuration.db);\n        expect(err).to.not.exist;\n        const collection = db.collection('remove_test');\n        collection.deleteMany({}).then(() => {\n          client.close(done);\n        }, err => {\n          client.close(err2 => done(err || err2));\n        });\n      });\n    }\n  });","file":"integration/crud/remove.test.js","skipped":false,"dir":"test"},{"name":"should fail insert due to unique index","suites":["Errors"],"updatePoint":{"line":28,"column":44,"index":588},"line":28,"code":"  it('should fail insert due to unique index', function (done) {\n    const db = client.db(this.configuration.db);\n    db.createCollection('test_failing_insert_due_to_unique_index', (err, collection) => {\n      expect(err).to.not.exist;\n      collection.createIndexes([{\n        name: 'test_failing_insert_due_to_unique_index',\n        key: {\n          a: 1\n        },\n        unique: true\n      }], {\n        writeConcern: {\n          w: 1\n        }\n      }, err => {\n        expect(err).to.not.exist;\n        collection.insertOne({\n          a: 2\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, err => {\n          expect(err).to.not.exist;\n          collection.insertOne({\n            a: 2\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, err => {\n            expect(err.code).to.equal(11000);\n            done();\n          });\n        });\n      });\n    });\n  });","file":"integration/crud/server_errors.test.js","skipped":false,"dir":"test"},{"name":"should fail insert due to unique index strict","suites":["Errors"],"updatePoint":{"line":66,"column":51,"index":1531},"line":66,"code":"  it('should fail insert due to unique index strict', function (done) {\n    const db = client.db(this.configuration.db);\n    db.dropCollection('test_failing_insert_due_to_unique_index_strict', () => {\n      db.createCollection('test_failing_insert_due_to_unique_index_strict', err => {\n        expect(err).to.not.exist;\n        const collection = db.collection('test_failing_insert_due_to_unique_index_strict');\n        collection.createIndexes([{\n          name: 'test_failing_insert_due_to_unique_index_strict',\n          key: {\n            a: 1\n          },\n          unique: true\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, err => {\n          expect(err).to.not.exist;\n          collection.insertOne({\n            a: 2\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, err => {\n            expect(err).to.not.exist;\n            collection.insertOne({\n              a: 2\n            }, {\n              writeConcern: {\n                w: 1\n              }\n            }, err => {\n              expect(err.code).to.equal(11000);\n              done();\n            });\n          });\n        });\n      });\n    });\n  });","file":"integration/crud/server_errors.test.js","skipped":false,"dir":"test"},{"name":"should return an error object with message when mixing included and excluded fields","suites":["Errors"],"updatePoint":{"line":108,"column":89,"index":2919},"line":108,"code":"  it('should return an error object with message when mixing included and excluded fields', {\n    metadata: {\n      requires: {\n        mongodb: '>3.0'\n      }\n    },\n    test: function (done) {\n      const db = client.db(this.configuration.db);\n      const c = db.collection('test_error_object_should_include_message');\n      c.insertOne({\n        a: 2,\n        b: 5\n      }, {\n        writeConcern: {\n          w: 1\n        }\n      }, err => {\n        expect(err).to.not.exist;\n        c.findOne({\n          a: 2\n        }, {\n          projection: {\n            a: 1,\n            b: 0\n          }\n        }, err => {\n          expect(PROJECTION_ERRORS).to.include(err.errmsg);\n          done();\n        });\n      });\n    }\n  });","file":"integration/crud/server_errors.test.js","skipped":false,"dir":"test"},{"name":"should handle error throw in user callback","suites":["Errors"],"updatePoint":{"line":140,"column":48,"index":3609},"line":140,"code":"  it('should handle error throw in user callback', {\n    metadata: {\n      requires: {\n        mongodb: '>3.0'\n      }\n    },\n    test: function (done) {\n      const db = client.db(this.configuration.db);\n      const c = db.collection('test_error_object_should_include_message');\n      c.findOne({}, {\n        projection: {\n          a: 1,\n          b: 0\n        }\n      }, err => {\n        expect(PROJECTION_ERRORS).to.include(err.errmsg);\n        done();\n      });\n    }\n  });","file":"integration/crud/server_errors.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertUnicodeContainingDocument","suites":["Unicode"],"updatePoint":{"line":16,"column":52,"index":283},"line":16,"code":"  it('shouldCorrectlyInsertUnicodeContainingDocument', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var doc = {\n          statuses_count: 1687,\n          created_at: 'Mon Oct 22 14:55:08 +0000 2007',\n          description: 'NodeJS hacker, Cofounder of Debuggable, CakePHP core alumnus',\n          favourites_count: 6,\n          profile_sidebar_fill_color: 'EADEAA',\n          screen_name: 'felixge',\n          status: {\n            created_at: 'Fri Mar 12 08:59:44 +0000 2010',\n            in_reply_to_screen_name: null,\n            truncated: false,\n            in_reply_to_user_id: null,\n            source: '<a href=\"http://www.atebits.com/\" rel=\"nofollow\">Tweetie</a>',\n            favorited: false,\n            in_reply_to_status_id: null,\n            id: 10364119169,\n            text: '#berlin #snow = #fail : ('\n          },\n          contributors_enabled: false,\n          following: null,\n          geo_enabled: false,\n          time_zone: 'Eastern Time (US & Canada)',\n          profile_sidebar_border_color: 'D9B17E',\n          url: 'http://debuggable.com',\n          verified: false,\n          location: 'Berlin',\n          profile_text_color: '333333',\n          notifications: null,\n          profile_background_image_url: 'http://s.twimg.com/a/1268354287/images/themes/theme8/bg.gif',\n          protected: false,\n          profile_link_color: '9D582E',\n          followers_count: 840,\n          name: 'Felix Geisend\\u00f6rfer',\n          profile_background_tile: false,\n          id: 9599342,\n          lang: 'en',\n          utc_offset: -18000,\n          friends_count: 450,\n          profile_background_color: '8B542B',\n          profile_image_url: 'http://a3.twimg.com/profile_images/107142257/passbild-square_normal.jpg'\n        };\n        db.createCollection('test_should_correctly_insert_unicode_containing_document', function (err, collection) {\n          doc['_id'] = 'felixge';\n          collection.insertOne(doc, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n            collection.findOne(function (err, doc) {\n              test.equal('felixge', doc._id);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/unicode.test.js","skipped":false,"dir":"test"},{"name":"should Correctly Insert Unicode Characters","suites":["Unicode"],"updatePoint":{"line":87,"column":48,"index":2919},"line":87,"code":"  it('should Correctly Insert Unicode Characters', function (done) {\n    const client = this.configuration.newClient(this.configuration.writeConcernMax(), {\n      maxPoolSize: 1\n    });\n    client.connect((err, client) => {\n      expect(err).to.not.exist;\n      const db = client.db(this.configuration.db);\n      db.createCollection('unicode_test_collection', (err, collection) => {\n        expect(err).to.not.exist;\n        const test_strings = ['ouooueauiOUOOUEAUI', 'öüóőúéáűíÖÜÓŐÚÉÁŰÍ', '本荘由利地域に洪水警報'];\n        collection.insert({\n          id: 0,\n          text: test_strings[0]\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, err => {\n          expect(err).to.not.exist;\n          collection.insert({\n            id: 1,\n            text: test_strings[1]\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, err => {\n            expect(err).to.not.exist;\n            collection.find().forEach(doc => {\n              expect(doc).property('text').to.equal(test_strings[doc.id]);\n            }, err => {\n              expect(err).to.not.exist;\n              client.close(done);\n            });\n          });\n        });\n      });\n    });\n  });","file":"integration/crud/unicode.test.js","skipped":false,"dir":"test"},{"name":"shouldCreateObjectWithChineseObjectName","suites":["Unicode"],"updatePoint":{"line":126,"column":45,"index":4129},"line":126,"code":"  it('shouldCreateObjectWithChineseObjectName', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var object = {\n        客家话: 'Hello'\n      };\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('create_object_with_chinese_object_name', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('create_object_with_chinese_object_name');\n          collection.insert(object, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n            collection.findOne(function (err, item) {\n              test.equal(object['客家话'], item['客家话']);\n              collection.find().toArray(function (err, items) {\n                test.equal(object['客家话'], items[0]['客家话']);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/unicode.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleUT8KeyNames","suites":["Unicode"],"updatePoint":{"line":163,"column":38,"index":5358},"line":163,"code":"  it('shouldCorrectlyHandleUT8KeyNames', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_utf8_key_name', function (err, collection) {\n          collection.insert({\n            šđžčćŠĐŽČĆ: 1\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n            collection.find({}).project({\n              šđžčćŠĐŽČĆ: 1\n            }).toArray(function (err, items) {\n              test.equal(1, items[0]['šđžčćŠĐŽČĆ']); // Let's close the db\n\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/crud/unicode.test.js","skipped":false,"dir":"test"},{"name":"Verify that the method returns an Iterable of Document types","suites":["listDatabases() spec prose"],"updatePoint":{"line":40,"column":66,"index":1409},"line":40,"code":"  it('Verify that the method returns an Iterable of Document types', async () => {\n    const dbInfo = await client.db().admin().listDatabases();\n    expect(dbInfo).to.have.property('databases');\n    expect(dbInfo.databases).to.be.an('array');\n    expect(dbInfo.databases).to.have.lengthOf(ENTIRE_DB_LIST.length);\n\n    for (const db of dbInfo.databases) {\n      expect(db).to.be.a('object');\n    }\n  });","file":"integration/enumerate_databases.prose.test.ts","skipped":false,"dir":"test"},{"name":"Verify that all databases on the server are present in the result set","suites":["listDatabases() spec prose"],"updatePoint":{"line":50,"column":75,"index":1821},"line":50,"code":"  it('Verify that all databases on the server are present in the result set', async () => {\n    const dbInfo = await client.db().admin().listDatabases();\n    const namesFromHelper = dbInfo.databases.map(({\n      name\n    }) => name);\n    namesFromHelper.sort();\n    expect(namesFromHelper).to.have.lengthOf(ENTIRE_DB_LIST.length);\n    expect(namesFromHelper).to.deep.equal(ENTIRE_DB_LIST);\n    expect(namesFromHelper).to.include(DB_NAME);\n  });","file":"integration/enumerate_databases.prose.test.ts","skipped":false,"dir":"test"},{"name":"Verify that the result set does not contain duplicates","suites":["listDatabases() spec prose"],"updatePoint":{"line":60,"column":60,"index":2251},"line":60,"code":"  it('Verify that the result set does not contain duplicates', async () => {\n    const dbInfo = await client.db().admin().listDatabases();\n    const databaseNames = dbInfo.databases.map(({\n      name\n    }) => name);\n    const databaseNamesSet = new Set(databaseNames);\n    expect(databaseNames).to.have.lengthOf(databaseNamesSet.size);\n  });","file":"integration/enumerate_databases.prose.test.ts","skipped":false,"dir":"test"},{"name":"should list all databases when admin client sets authorizedDatabases to true","suites":["listDatabases()","authorizedDatabases option"],"updatePoint":{"line":46,"column":84,"index":1685},"line":46,"code":"    it('should list all databases when admin client sets authorizedDatabases to true', metadata, async function () {\n      const adminListDbs = await adminClient.db().admin().listDatabases({\n        authorizedDatabases: true\n      });\n      const adminDbs = adminListDbs.databases.map(({\n        name\n      }) => name); // no change in the dbs listed since we're using the admin user\n\n      expect(adminDbs).to.have.length.greaterThan(1);\n      expect(adminDbs.filter(db => db === mockAuthorizedDb)).to.have.lengthOf(1);\n      expect(adminDbs.filter(db => db !== mockAuthorizedDb)).to.have.length.greaterThan(1);\n    });","file":"integration/enumerate_databases.test.ts","skipped":false,"dir":"test"},{"name":"should list all databases when admin client sets authorizedDatabases to false","suites":["listDatabases()","authorizedDatabases option"],"updatePoint":{"line":58,"column":85,"index":2307},"line":58,"code":"    it('should list all databases when admin client sets authorizedDatabases to false', metadata, async function () {\n      const adminListDbs = await adminClient.db().admin().listDatabases({\n        authorizedDatabases: false\n      });\n      const adminDbs = adminListDbs.databases.map(({\n        name\n      }) => name); // no change in the dbs listed since we're using the admin user\n\n      expect(adminDbs).to.have.length.greaterThan(1);\n      expect(adminDbs.filter(db => db === mockAuthorizedDb)).to.have.lengthOf(1);\n      expect(adminDbs.filter(db => db !== mockAuthorizedDb)).to.have.length.greaterThan(1);\n    });","file":"integration/enumerate_databases.test.ts","skipped":false,"dir":"test"},{"name":"should list authorized databases with authorizedDatabases set to true","suites":["listDatabases()","authorizedDatabases option"],"updatePoint":{"line":70,"column":77,"index":2922},"line":70,"code":"    it('should list authorized databases with authorizedDatabases set to true', metadata, async function () {\n      const adminListDbs = await adminClient.db().admin().listDatabases();\n      const authorizedListDbs = await authorizedClient.db().admin().listDatabases({\n        authorizedDatabases: true\n      });\n      const adminDbs = adminListDbs.databases;\n      const authorizedDbs = authorizedListDbs.databases;\n      expect(adminDbs).to.have.length.greaterThan(1);\n      expect(authorizedDbs).to.have.lengthOf(1);\n      expect(adminDbs.filter(db => db.name === mockAuthorizedDb)).to.have.lengthOf(1);\n      expect(adminDbs.filter(db => db.name !== mockAuthorizedDb)).to.have.length.greaterThan(1);\n      expect(authorizedDbs.filter(db => db.name === mockAuthorizedDb)).to.have.lengthOf(1);\n    });","file":"integration/enumerate_databases.test.ts","skipped":false,"dir":"test"},{"name":"should list authorized databases by default with authorizedDatabases unspecified","suites":["listDatabases()","authorizedDatabases option"],"updatePoint":{"line":83,"column":88,"index":3737},"line":83,"code":"    it('should list authorized databases by default with authorizedDatabases unspecified', metadata, async function () {\n      const adminListDbs = await adminClient.db().admin().listDatabases();\n      const authorizedListDbs = await authorizedClient.db().admin().listDatabases();\n      const adminDbs = adminListDbs.databases;\n      const authorizedDbs = authorizedListDbs.databases;\n      expect(adminDbs).to.have.length.greaterThan(1);\n      expect(authorizedDbs).to.have.lengthOf(1);\n      expect(adminDbs.filter(db => db.name === mockAuthorizedDb)).to.have.lengthOf(1);\n      expect(adminDbs.filter(db => db.name !== mockAuthorizedDb)).to.have.length.greaterThan(1);\n      expect(authorizedDbs.filter(db => db.name === mockAuthorizedDb)).to.have.lengthOf(1);\n    });","file":"integration/enumerate_databases.test.ts","skipped":false,"dir":"test"},{"name":"should not show authorized databases with authorizedDatabases set to false","suites":["listDatabases()","authorizedDatabases option"],"updatePoint":{"line":94,"column":82,"index":4503},"line":94,"code":"    it('should not show authorized databases with authorizedDatabases set to false', metadata, async function () {\n      let thrownError;\n\n      try {\n        await authorizedClient.db().admin().listDatabases({\n          authorizedDatabases: false\n        });\n      } catch (error) {\n        thrownError = error;\n      } // check correctly produces an 'Insufficient permissions to list all databases' error\n\n\n      expect(thrownError).to.be.instanceOf(MongoServerError);\n      expect(thrownError).to.have.property('message').that.includes('list');\n    });","file":"integration/enumerate_databases.test.ts","skipped":false,"dir":"test"},{"name":"should upload from file stream","suites":["GridFS Stream"],"updatePoint":{"line":42,"column":36,"index":686},"line":42,"code":"  it('should upload from file stream', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        db.dropDatabase(function (error) {\n          expect(error).to.not.exist;\n          const bucket = new GridFSBucket(db);\n          const readStream = fs.createReadStream('./LICENSE.md');\n          const uploadStream = bucket.openUploadStream('test.dat');\n          const license = fs.readFileSync('./LICENSE.md');\n          const id = uploadStream.id; // Wait for stream to finish\n\n          uploadStream.once('finish', function () {\n            const chunksColl = db.collection('fs.chunks');\n            const chunksQuery = chunksColl.find({\n              files_id: id\n            }); // Get all the chunks\n\n            chunksQuery.toArray(function (error, docs) {\n              expect(error).to.not.exist;\n              expect(docs.length).to.equal(1);\n              expect(docs[0].data.toString('hex')).to.equal(license.toString('hex'));\n              const filesColl = db.collection('fs.files');\n              const filesQuery = filesColl.find({\n                _id: id\n              });\n              filesQuery.toArray(function (error, docs) {\n                expect(error).to.not.exist;\n                expect(docs.length).to.equal(1);\n                expect(docs[0]).to.not.have.property('md5'); // make sure we created indexes\n\n                filesColl.listIndexes().toArray(function (error, indexes) {\n                  expect(error).to.not.exist;\n                  expect(indexes.length).to.equal(2);\n                  expect(indexes[1].name).to.equal('filename_1_uploadDate_1');\n                  chunksColl.listIndexes().toArray(function (error, indexes) {\n                    expect(error).to.not.exist;\n                    expect(indexes.length).to.equal(2);\n                    expect(indexes[1].name).to.equal('files_id_1_n_1');\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n          readStream.pipe(uploadStream);\n        });\n      });\n    }\n\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"destroy publishes provided error","suites":["GridFS Stream"],"updatePoint":{"line":103,"column":38,"index":3040},"line":103,"code":"  it('destroy publishes provided error', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        db.dropDatabase(function (error) {\n          expect(error).to.not.exist;\n          const bucket = new GridFSBucket(db);\n          const readStream = fs.createReadStream('./LICENSE.md');\n          const uploadStream = bucket.openUploadStream('test.dat');\n          const errorMessage = 'error';\n          uploadStream.once('error', function (e) {\n            expect(e).to.equal(errorMessage);\n            client.close(done);\n          });\n          uploadStream.once('finish', function () {\n            uploadStream.destroy(errorMessage);\n          });\n          readStream.pipe(uploadStream);\n        });\n      });\n    }\n\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should upload from file stream with custom id","suites":["GridFS Stream"],"updatePoint":{"line":143,"column":51,"index":4252},"line":143,"code":"  it('should upload from file stream with custom id', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        db.dropDatabase(function (error) {\n          expect(error).to.not.exist;\n          const bucket = new GridFSBucket(db);\n          const readStream = fs.createReadStream('./LICENSE.md');\n          const uploadStream = bucket.openUploadStreamWithId(1, 'test.dat');\n          const license = fs.readFileSync('./LICENSE.md');\n          const id = uploadStream.id;\n          expect(id).to.equal(1); // Wait for stream to finish\n\n          uploadStream.once('finish', function () {\n            const chunksColl = db.collection('fs.chunks');\n            const chunksQuery = chunksColl.find({\n              files_id: id\n            }); // Get all the chunks\n\n            chunksQuery.toArray(function (error, docs) {\n              expect(error).to.not.exist;\n              expect(docs.length).to.equal(1);\n              expect(docs[0].data.toString('hex')).to.equal(license.toString('hex'));\n              const filesColl = db.collection('fs.files');\n              const filesQuery = filesColl.find({\n                _id: id\n              });\n              filesQuery.toArray(function (error, docs) {\n                expect(error).to.not.exist;\n                expect(docs.length).to.equal(1);\n                expect(docs[0]).to.not.have.property('md5'); // make sure we created indexes\n\n                filesColl.listIndexes().toArray(function (error, indexes) {\n                  expect(error).to.not.exist;\n                  expect(indexes.length).to.equal(2);\n                  expect(indexes[1].name).to.equal('filename_1_uploadDate_1');\n                  chunksColl.listIndexes().toArray(function (error, indexes) {\n                    expect(error).to.not.exist;\n                    expect(indexes.length).to.equal(2);\n                    expect(indexes[1].name).to.equal('files_id_1_n_1');\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n          readStream.pipe(uploadStream);\n        });\n      });\n    }\n\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should download to upload stream","suites":["GridFS Stream"],"updatePoint":{"line":212,"column":38,"index":6812},"line":212,"code":"  it('should download to upload stream', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload'\n        });\n        const CHUNKS_COLL = 'gridfsdownload.chunks';\n        const FILES_COLL = 'gridfsdownload.files';\n        const readStream = fs.createReadStream('./LICENSE.md');\n        let uploadStream = bucket.openUploadStream('test.dat');\n        const license = fs.readFileSync('./LICENSE.md');\n        let id = uploadStream.id;\n        uploadStream.once('finish', function () {\n          const downloadStream = bucket.openDownloadStream(id);\n          uploadStream = bucket.openUploadStream('test2.dat');\n          id = uploadStream.id;\n          downloadStream.pipe(uploadStream).once('finish', function () {\n            const chunksQuery = db.collection(CHUNKS_COLL).find({\n              files_id: id\n            });\n            chunksQuery.toArray(function (error, docs) {\n              expect(error).to.not.exist;\n              expect(docs.length).to.equal(1);\n              expect(docs[0].data.toString('hex')).to.equal(license.toString('hex'));\n              const filesQuery = db.collection(FILES_COLL).find({\n                _id: id\n              });\n              filesQuery.toArray(function (error, docs) {\n                expect(error).to.not.exist;\n                expect(docs.length).to.equal(1);\n                expect(docs[0]).to.not.have.property('md5');\n                client.close(done);\n              });\n            });\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should fail to locate gridfs stream","suites":["GridFS Stream"],"updatePoint":{"line":268,"column":41,"index":8786},"line":268,"code":"  it('should fail to locate gridfs stream', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload'\n        }); // Get an unknown file\n\n        const downloadStream = bucket.openDownloadStream(new ObjectId());\n        downloadStream.on('data', function () {});\n        downloadStream.on('error', function (err) {\n          expect(err.code).to.equal('ENOENT');\n          client.close(done);\n        });\n      });\n    }\n\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"openDownloadStreamByName","suites":["GridFS Stream"],"updatePoint":{"line":303,"column":30,"index":9725},"line":303,"code":"  it('openDownloadStreamByName', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload'\n        });\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('test.dat');\n        uploadStream.once('finish', function () {\n          const downloadStream = bucket.openDownloadStreamByName('test.dat');\n          let gotData = false;\n          downloadStream.on('data', function (data) {\n            expect(gotData).to.equal(false);\n            gotData = true;\n            expect(data.toString('utf8').indexOf('TERMS AND CONDITIONS') !== -1).to.equal(true);\n          });\n          downloadStream.on('end', function () {\n            expect(gotData).to.equal(true);\n            client.close(done);\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"start/end options for openDownloadStream","suites":["GridFS Stream"],"updatePoint":{"line":347,"column":46,"index":11179},"line":347,"code":"  it('start/end options for openDownloadStream', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload',\n          chunkSizeBytes: 2\n        });\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('teststart.dat');\n        uploadStream.once('finish', function () {\n          const downloadStream = bucket.openDownloadStreamByName('teststart.dat', {\n            start: 1\n          }).end(6);\n          downloadStream.on('error', function (error) {\n            expect(error).to.not.exist;\n          });\n          let gotData = 0;\n          let str = '';\n          downloadStream.on('data', function (data) {\n            ++gotData;\n            str += data.toString('utf8');\n          });\n          downloadStream.on('end', function () {\n            // Depending on different versions of node, we may get\n            // different amounts of 'data' events. node 0.10 gives 2,\n            // node >= 0.12 gives 3. Either is correct, but we just\n            // care that we got between 1 and 3, and got the right result\n            expect(gotData >= 1 && gotData <= 3).to.equal(true);\n            expect(str).to.equal('pache');\n            client.close(done);\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should emit close after all chunks are received","suites":["GridFS Stream"],"updatePoint":{"line":395,"column":53,"index":12875},"line":395,"code":"  it('should emit close after all chunks are received', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload',\n          chunkSizeBytes: 6000\n        });\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('teststart.dat');\n        uploadStream.once('finish', function () {\n          const downloadStream = bucket.openDownloadStreamByName('teststart.dat');\n          const events = [];\n          downloadStream.on('data', () => events.push('data'));\n          downloadStream.on('close', () => events.push('close'));\n          downloadStream.on('end', () => {\n            expect(events).to.eql(['data', 'data', 'close']);\n            client.close(done);\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"Deleting a file","suites":["GridFS Stream"],"updatePoint":{"line":438,"column":21,"index":14173},"line":438,"code":"  it('Deleting a file', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload'\n        });\n        const CHUNKS_COLL = 'gridfsdownload.chunks';\n        const FILES_COLL = 'gridfsdownload.files';\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const id = uploadStream.id;\n        uploadStream.once('finish', function () {\n          bucket.delete(id, function (err) {\n            expect(err).to.not.exist;\n            const chunksQuery = db.collection(CHUNKS_COLL).find({\n              files_id: id\n            });\n            chunksQuery.toArray(function (error, docs) {\n              expect(error).to.not.exist;\n              expect(docs.length).to.equal(0);\n              const filesQuery = db.collection(FILES_COLL).find({\n                _id: id\n              });\n              filesQuery.toArray(function (error, docs) {\n                expect(error).to.not.exist;\n                expect(docs.length).to.equal(0);\n                client.close(done);\n              });\n            });\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"Aborting an upload","suites":["GridFS Stream"],"updatePoint":{"line":492,"column":24,"index":15838},"line":492,"code":"  it('Aborting an upload', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsabort',\n          chunkSizeBytes: 1\n        });\n        const CHUNKS_COLL = 'gridfsabort.chunks';\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const id = uploadStream.id;\n        const query = {\n          files_id: id\n        };\n        uploadStream.write('a', 'utf8', function (error) {\n          expect(error).to.not.exist;\n          db.collection(CHUNKS_COLL).count(query, function (error, c) {\n            expect(error).to.not.exist;\n            expect(c).to.equal(1);\n            uploadStream.abort(function (error) {\n              expect(error).to.not.exist;\n              db.collection(CHUNKS_COLL).count(query, function (error, c) {\n                expect(error).to.not.exist;\n                expect(c).to.equal(0);\n                uploadStream.write('b', 'utf8', function (error) {\n                  expect(error.toString()).to.equal('MongoAPIError: Stream has been aborted');\n                  uploadStream.end('c', 'utf8', function (error) {\n                    expect(error.toString()).to.equal('MongoAPIError: Stream has been aborted'); // Fail if user tries to abort an aborted stream\n\n                    uploadStream.abort().then(null, function (error) {\n                      expect(error.toString()).to.equal( // TODO(NODE-3485): Replace with MongoGridFSStreamClosedError\n                      'MongoAPIError: Cannot call abort() on a stream twice');\n                      client.close(done);\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"Destroy an upload","suites":["GridFS Stream"],"updatePoint":{"line":550,"column":23,"index":17918},"line":550,"code":"  it('Destroy an upload', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsabort',\n          chunkSizeBytes: 1\n        });\n        const CHUNKS_COLL = 'gridfsabort.chunks';\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const id = uploadStream.id;\n        const query = {\n          files_id: id\n        };\n        uploadStream.write('a', 'utf8', function (error) {\n          expect(error).to.not.exist;\n          db.collection(CHUNKS_COLL).count(query, function (error, c) {\n            expect(error).to.not.exist;\n            expect(c).to.equal(1);\n            uploadStream.abort(function (error) {\n              expect(error).to.not.exist;\n              db.collection(CHUNKS_COLL).count(query, function (error, c) {\n                expect(error).to.not.exist;\n                expect(c).to.equal(0);\n                uploadStream.write('b', 'utf8', function (error) {\n                  expect(error.toString()).to.equal('MongoAPIError: Stream has been aborted');\n                  uploadStream.end('c', 'utf8', function (error) {\n                    expect(error.toString()).to.equal('MongoAPIError: Stream has been aborted'); // Fail if user tries to abort an aborted stream\n\n                    uploadStream.abort().then(null, function (error) {\n                      expect(error.toString()).to.equal( // TODO(NODE-3485): Replace with MongoGridFSStreamClosedError\n                      'MongoAPIError: Cannot call abort() on a stream twice');\n                      client.close(done);\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"Destroying a download stream","suites":["GridFS Stream"],"updatePoint":{"line":611,"column":34,"index":20109},"line":611,"code":"  it('Destroying a download stream', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        apiVersion: false\n      }\n    },\n\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdestroy',\n          chunkSizeBytes: 10\n        });\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('test.dat'); // Wait for stream to finish\n\n        uploadStream.once('finish', function () {\n          const id = uploadStream.id;\n          const downloadStream = bucket.openDownloadStream(id);\n          const finished = {};\n          downloadStream.on('data', function () {\n            expect.fail('Should be unreachable');\n          });\n          downloadStream.on('error', function () {\n            expect.fail('Should be unreachable');\n          });\n          downloadStream.on('end', function () {\n            expect(downloadStream.s.cursor).to.not.exist;\n\n            if (finished.close) {\n              client.close(done);\n              return;\n            }\n\n            finished.end = true;\n          });\n          downloadStream.on('close', function () {\n            if (finished.end) {\n              client.close(done);\n              return;\n            }\n\n            finished.close = true;\n          });\n          downloadStream.abort(function (error) {\n            expect(error).to.not.exist;\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"Deleting a file using promises","suites":["GridFS Stream"],"updatePoint":{"line":677,"column":36,"index":21994},"line":677,"code":"  it('Deleting a file using promises', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        sessions: {\n          skipLeakTests: true\n        }\n      }\n    },\n\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload'\n        });\n        const CHUNKS_COLL = 'gridfsdownload.chunks';\n        const FILES_COLL = 'gridfsdownload.files';\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const id = uploadStream.id;\n        uploadStream.once('finish', function () {\n          bucket.delete(id).then(function () {\n            const chunksQuery = db.collection(CHUNKS_COLL).find({\n              files_id: id\n            });\n            chunksQuery.toArray(function (error, docs) {\n              expect(error).to.not.exist;\n              expect(docs.length).to.equal(0);\n              const filesQuery = db.collection(FILES_COLL).find({\n                _id: id\n              });\n              filesQuery.toArray(function (error, docs) {\n                expect(error).to.not.exist;\n                expect(docs.length).to.equal(0);\n                client.close(done);\n              });\n            });\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"find()","suites":["GridFS Stream"],"updatePoint":{"line":726,"column":12,"index":23559},"line":726,"code":"  it('find()', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        sessions: {\n          skipLeakTests: true\n        }\n      }\n    },\n\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'fs'\n        }); // We're only making sure this doesn't throw\n\n        bucket.find({\n          batchSize: 1,\n          limit: 2,\n          maxTimeMS: 3,\n          noCursorTimeout: true,\n          skip: 4,\n          sort: {\n            _id: 1\n          }\n        });\n        client.close(done);\n      });\n    }\n\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"drop example","suites":["GridFS Stream"],"updatePoint":{"line":769,"column":18,"index":24501},"line":769,"code":"  it('drop example', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        sessions: {\n          skipLeakTests: true\n        }\n      }\n    },\n\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload'\n        });\n        const CHUNKS_COLL = 'gridfsdownload.chunks';\n        const FILES_COLL = 'gridfsdownload.files';\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const id = uploadStream.id;\n        uploadStream.once('finish', function () {\n          bucket.drop(function (err) {\n            expect(err).to.not.exist;\n            const chunksQuery = db.collection(CHUNKS_COLL).find({\n              files_id: id\n            });\n            chunksQuery.toArray(function (error, docs) {\n              expect(error).to.not.exist;\n              expect(docs.length).to.equal(0);\n              const filesQuery = db.collection(FILES_COLL).find({\n                _id: id\n              });\n              filesQuery.toArray(function (error, docs) {\n                expect(error).to.not.exist;\n                expect(docs.length).to.equal(0);\n                client.close(done);\n              });\n            });\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"drop using promises","suites":["GridFS Stream"],"updatePoint":{"line":826,"column":25,"index":26246},"line":826,"code":"  it('drop using promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload'\n        });\n        const CHUNKS_COLL = 'gridfsdownload.chunks';\n        const FILES_COLL = 'gridfsdownload.files';\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const id = uploadStream.id;\n        uploadStream.once('finish', function () {\n          bucket.drop().then(function () {\n            const chunksQuery = db.collection(CHUNKS_COLL).find({\n              files_id: id\n            });\n            chunksQuery.toArray(function (error, docs) {\n              expect(error).to.not.exist;\n              expect(docs.length).to.equal(0);\n              const filesQuery = db.collection(FILES_COLL).find({\n                _id: id\n              });\n              filesQuery.toArray(function (error, docs) {\n                expect(error).to.not.exist;\n                expect(docs.length).to.equal(0);\n                client.close(done);\n              });\n            });\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"find example","suites":["GridFS Stream"],"updatePoint":{"line":879,"column":18,"index":27873},"line":879,"code":"  it('find example', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload_2'\n        });\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('test.dat');\n        uploadStream.once('finish', function () {\n          bucket.find({}, {\n            batchSize: 1\n          }).toArray(function (err, files) {\n            expect(err).to.not.exist;\n            expect(1).to.equal(files.length);\n            client.close(done);\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"rename example","suites":["GridFS Stream"],"updatePoint":{"line":919,"column":20,"index":28928},"line":919,"code":"  it('rename example', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload_3'\n        });\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const id = uploadStream.id;\n        uploadStream.once('finish', function () {\n          // Rename the file\n          bucket.rename(id, 'renamed_it.dat', function (err) {\n            expect(err).to.not.exist;\n            client.close(done);\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"download empty doc","suites":["GridFS Stream"],"updatePoint":{"line":951,"column":24,"index":29873},"line":951,"code":"  it('download empty doc', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'fs'\n        });\n        db.collection('fs.files').insertMany([{\n          length: 0\n        }], function (error, result) {\n          expect(error).to.not.exist;\n          expect(Object.keys(result.insertedIds).length).to.equal(1);\n          const id = result.insertedIds[0];\n          const stream = bucket.openDownloadStream(id);\n          stream.on('error', function (error) {\n            expect(error).to.not.exist;\n          });\n          stream.on('data', function () {\n            expect.fail('Should be unreachable');\n          });\n          stream.on('end', function () {\n            // As per spec, make sure we didn't actually fire a query\n            // because the document length is 0\n            expect(stream.s.cursor).to.not.exist;\n            client.close(done);\n          });\n        });\n      });\n    }\n\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should use chunkSize for download","suites":["GridFS Stream"],"updatePoint":{"line":992,"column":39,"index":31166},"line":992,"code":"  it('should use chunkSize for download', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n\n    test(done) {\n      if (typeof stream.pipeline !== 'function') {\n        this.skip();\n      }\n\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfs'\n        });\n        const uploadStream = bucket.openUploadStream('test');\n        uploadStream.end(Buffer.alloc(40 * 1024 * 1024), err => {\n          expect(err).to.not.exist;\n          const range = {\n            start: 35191617,\n            end: 35192831\n          };\n          const downloadStream = bucket.openDownloadStreamByName('test', range);\n          const outputStream = fs.createWriteStream('output');\n          stream.pipeline(downloadStream, outputStream, err => {\n            expect(err).to.not.exist;\n            client.close(() => {\n              fs.stat('output', (err, stats) => {\n                expect(err).to.not.exist;\n                expect(range.end - range.start).to.equal(stats.size);\n                done();\n              });\n            });\n          });\n        });\n      });\n    }\n\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should correctly handle calling end function with only a callback","suites":["GridFS Stream"],"updatePoint":{"line":1041,"column":71,"index":32668},"line":1041,"code":"  it('should correctly handle calling end function with only a callback', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsabort',\n          chunkSizeBytes: 1\n        });\n        const CHUNKS_COLL = 'gridfsabort.chunks';\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const id = uploadStream.id;\n        const query = {\n          files_id: id\n        };\n        uploadStream.write('a', 'utf8', function (error) {\n          expect(error).to.not.exist;\n          db.collection(CHUNKS_COLL).count(query, function (error, c) {\n            expect(error).to.not.exist;\n            expect(c).to.equal(1);\n            uploadStream.abort(function (error) {\n              expect(error).to.not.exist;\n              db.collection(CHUNKS_COLL).count(query, function (error, c) {\n                expect(error).to.not.exist;\n                expect(c).to.equal(0);\n                uploadStream.write('b', 'utf8', function (error) {\n                  expect(error.toString()).to.equal('MongoAPIError: Stream has been aborted');\n                  uploadStream.end(function (error) {\n                    expect(error.toString()).to.equal('MongoAPIError: Stream has been aborted'); // Fail if user tries to abort an aborted stream\n\n                    uploadStream.abort().then(null, function (error) {\n                      expect(error.toString()).to.equal( // TODO(NODE-3485): Replace with MongoGridFSStreamClosedError\n                      'MongoAPIError: Cannot call abort() on a stream twice');\n                      client.close(done);\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should not call the callback on repeat calls to end","suites":["GridFS Stream","upload stream end()"],"updatePoint":{"line":1101,"column":59,"index":34883},"line":1101,"code":"    it('should not call the callback on repeat calls to end', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n\n      async test() {\n        const configuration = this.configuration;\n        client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        await client.connect();\n        db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsabort',\n          chunkSizeBytes: 1\n        });\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const endPromise = new Promise(resolve => {\n          uploadStream.end('1', resolve);\n        });\n        const endPromise2 = new Promise((resolve, reject) => {\n          uploadStream.end('2', () => {\n            reject(new Error('Expected callback to not be called on duplicate end'));\n          });\n        });\n        await endPromise; // in the fail case, the callback would be called when the actual write is finished,\n        // so we need to give it a moment\n\n        await Promise.race([endPromise2, sleep(100)]);\n      }\n\n    });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should not write a chunk on repeat calls to end","suites":["GridFS Stream","upload stream end()"],"updatePoint":{"line":1135,"column":55,"index":36026},"line":1135,"code":"    it('should not write a chunk on repeat calls to end', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n\n      async test() {\n        const configuration = this.configuration;\n        client = configuration.newClient(configuration.writeConcernMax(), {\n          maxPoolSize: 1\n        });\n        await client.connect();\n        db = client.db(this.configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsabort',\n          chunkSizeBytes: 1\n        });\n        const uploadStream = bucket.openUploadStream('test.dat');\n        const spy = sinon.spy(uploadStream, 'write');\n        const endPromise = new Promise(resolve => {\n          uploadStream.end('1', resolve);\n        });\n        await endPromise;\n        expect(spy).to.have.been.calledWith('1');\n        uploadStream.end('2'); // wait for potential async calls to happen before we close the client\n        // so that we don't get a client not connected failure in the afterEach\n        // in the failure case since it would be confusing and unnecessary\n        // given the assertions we already have for this case\n\n        await sleep(100);\n        expect(spy).not.to.have.been.calledWith('2');\n        expect(spy.calledOnce).to.be.true;\n      }\n\n    });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"NODE-829 start/end options for openDownloadStream where start-end is < size of chunk","suites":["GridFS Stream","upload stream end()"],"updatePoint":{"line":1179,"column":90,"index":37579},"line":1179,"code":"  it('NODE-829 start/end options for openDownloadStream where start-end is < size of chunk', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n\n    test(done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        const db = client.db(configuration.db);\n        const bucket = new GridFSBucket(db, {\n          bucketName: 'gridfsdownload',\n          chunkSizeBytes: 20\n        });\n        const readStream = fs.createReadStream('./LICENSE.md');\n        const uploadStream = bucket.openUploadStream('teststart.dat');\n        uploadStream.once('finish', function () {\n          const downloadStream = bucket.openDownloadStreamByName('teststart.dat', {\n            start: 1\n          }).end(6);\n          downloadStream.on('error', function (error) {\n            expect(error).to.not.exist;\n          });\n          let gotData = 0;\n          let str = '';\n          downloadStream.on('data', function (data) {\n            ++gotData;\n            str += data.toString('utf8');\n          });\n          downloadStream.on('end', function () {\n            // Depending on different versions of node, we may get\n            // different amounts of 'data' events. node 0.10 gives 2,\n            // node >= 0.12 gives 3. Either is correct, but we just\n            // care that we got between 1 and 3, and got the right result\n            expect(gotData >= 1 && gotData <= 3).to.equal(true);\n            expect(str).to.equal('pache');\n            client.close(done);\n          });\n        });\n        readStream.pipe(uploadStream);\n      });\n    }\n\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"should correctly handle indexes create with BSON.Double","suites":["GridFS Stream","upload stream end()"],"updatePoint":{"line":1227,"column":61,"index":39284},"line":1227,"code":"  it('should correctly handle indexes create with BSON.Double', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient();\n    client.connect((err, client) => {\n      expect(err).to.not.exist;\n      const db = client.db(configuration.db);\n      const col = db.collection('fs.files');\n      col.createIndex({\n        filename: new Double(1.0),\n        uploadDate: new Double(1.0)\n      }, err => {\n        expect(err).to.not.exist;\n        col.listIndexes().toArray((err, indexes) => {\n          expect(err).to.not.exist;\n          const names = indexes.map(i => i.name);\n          expect(names).to.eql(['_id_', 'filename_1_uploadDate_1']);\n          client.close();\n          done();\n        });\n      });\n    });\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"NODE-2623 downloadStream should emit error on end > size","suites":["GridFS Stream","upload stream end()"],"updatePoint":{"line":1249,"column":62,"index":40056},"line":1249,"code":"  it('NODE-2623 downloadStream should emit error on end > size', function () {\n    const configuration = this.configuration;\n    return withClient.bind(this)((client, done) => {\n      const db = client.db(configuration.db);\n      const bucket = new GridFSBucket(db, {\n        bucketName: 'gridfsdownload'\n      });\n      const readStream = fs.createReadStream('./LICENSE.md');\n      const uploadStream = bucket.openUploadStream('test.dat');\n      const actualSize = fs.fstatSync(fs.openSync('./LICENSE.md', 'r')).size;\n      const wrongExpectedSize = Math.floor(actualSize * 1.1);\n      const id = uploadStream.id;\n      uploadStream.once('finish', function () {\n        const downloadStream = bucket.openDownloadStream(id, {\n          end: wrongExpectedSize\n        });\n        downloadStream.on('data', function () {});\n        downloadStream.on('error', function (err) {\n          expect(err.message).to.equal(`Stream end (${wrongExpectedSize}) must not be more than the length of the file (${actualSize})`);\n          done();\n        });\n      });\n      readStream.pipe(uploadStream);\n    });\n  });","file":"integration/gridfs/gridfs_stream.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute createIndex using Promise","suites":["Indexes","promise tests"],"updatePoint":{"line":23,"column":58,"index":441},"line":23,"code":"    it('Should correctly execute createIndex using Promise', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var url = configuration.url();\n        url = url.indexOf('?') !== -1 ? f('%s&%s', url, 'maxPoolSize=5') : f('%s?%s', url, 'maxPoolSize=5');\n        const client = configuration.newClient(url);\n        client.connect().then(function (client) {\n          // Create an index\n          client.db(configuration.db).createIndex('promiseCollectionCollections1', {\n            a: 1\n          }).then(function (r) {\n            test.ok(r != null);\n            client.close(done);\n          });\n        });\n      }\n    });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute ensureIndex using Promise","suites":["Indexes","promise tests"],"updatePoint":{"line":45,"column":58,"index":1191},"line":45,"code":"    it('Should correctly execute ensureIndex using Promise', {\n      metadata: {\n        requires: {\n          topology: ['single']\n        }\n      },\n      test: function (done) {\n        var configuration = this.configuration;\n        var url = configuration.url();\n        url = url.indexOf('?') !== -1 ? f('%s&%s', url, 'maxPoolSize=5') : f('%s?%s', url, 'maxPoolSize=5');\n        const client = configuration.newClient(url);\n        client.connect().then(function (client) {\n          // Create an index\n          client.db(configuration.db).createIndex('promiseCollectionCollections2', {\n            a: 1\n          }).then(function (r) {\n            test.ok(r != null);\n            client.close(done);\n          });\n        });\n      }\n    });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExtractIndexInformation","suites":["Indexes","promise tests"],"updatePoint":{"line":68,"column":44,"index":1933},"line":68,"code":"  it('shouldCorrectlyExtractIndexInformation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_index_information', function (err, collection) {\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // Create an index on the collection\n\n            db.createIndex(collection.collectionName, 'a', configuration.writeConcernMax(), function (err, indexName) {\n              expect(err).to.not.exist;\n              test.equal('a_1', indexName); // Let's fetch the index information\n\n              db.indexInformation(collection.collectionName, function (err, collectionInfo) {\n                expect(err).to.not.exist;\n                test.ok(collectionInfo['_id_'] != null);\n                test.equal('_id', collectionInfo['_id_'][0][0]);\n                test.ok(collectionInfo['a_1'] != null);\n                test.deepEqual([['a', 1]], collectionInfo['a_1']);\n                db.indexInformation(collection.collectionName, function (err, collectionInfo2) {\n                  var count1 = Object.keys(collectionInfo).length,\n                      count2 = Object.keys(collectionInfo2).length; // Tests\n\n                  test.ok(count2 >= count1);\n                  test.ok(collectionInfo2['_id_'] != null);\n                  test.equal('_id', collectionInfo2['_id_'][0][0]);\n                  test.ok(collectionInfo2['a_1'] != null);\n                  test.deepEqual([['a', 1]], collectionInfo2['a_1']);\n                  test.ok(collectionInfo[indexName] != null);\n                  test.deepEqual([['a', 1]], collectionInfo[indexName]); // Let's close the db\n\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleMultipleColumnIndexes","suites":["Indexes","promise tests"],"updatePoint":{"line":118,"column":48,"index":4129},"line":118,"code":"  it('shouldCorrectlyHandleMultipleColumnIndexes', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_multiple_index_cols', function (err, collection) {\n          collection.insert({\n            a: 1\n          }, function (err) {\n            expect(err).to.not.exist; // Create an index on the collection\n\n            db.createIndex(collection.collectionName, [['a', -1], ['b', 1], ['c', -1]], configuration.writeConcernMax(), function (err, indexName) {\n              expect(err).to.not.exist;\n              test.equal('a_-1_b_1_c_-1', indexName); // Let's fetch the index information\n\n              db.indexInformation(collection.collectionName, function (err, collectionInfo) {\n                var count1 = Object.keys(collectionInfo).length; // Test\n\n                test.equal(2, count1);\n                test.ok(collectionInfo[indexName] != null);\n                test.deepEqual([['a', -1], ['b', 1], ['c', -1]], collectionInfo[indexName]); // Let's close the db\n\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleUniqueIndex","suites":["Indexes","promise tests"],"updatePoint":{"line":156,"column":38,"index":5601},"line":156,"code":"  it('shouldCorrectlyHandleUniqueIndex', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db); // Create a non-unique index and test inserts\n\n        db.createCollection('test_unique_index', function (err, collection) {\n          db.createIndex(collection.collectionName, 'hello', configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // Insert some docs\n\n            collection.insert([{\n              hello: 'world'\n            }, {\n              hello: 'mike'\n            }, {\n              hello: 'world'\n            }], configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist; // Create a unique index and test that insert fails\n\n              db.createCollection('test_unique_index2', function (err, collection) {\n                db.createIndex(collection.collectionName, 'hello', {\n                  unique: true,\n                  writeConcern: {\n                    w: 1\n                  }\n                }, function (err) {\n                  expect(err).to.not.exist; // Insert some docs\n\n                  collection.insert([{\n                    hello: 'world'\n                  }, {\n                    hello: 'mike'\n                  }, {\n                    hello: 'world'\n                  }], configuration.writeConcernMax(), function (err) {\n                    test.ok(err != null);\n                    test.equal(11000, err.code);\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateSubfieldIndex","suites":["Indexes","promise tests"],"updatePoint":{"line":213,"column":40,"index":7619},"line":213,"code":"  it('shouldCorrectlyCreateSubfieldIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db); // Create a non-unique index and test inserts\n\n        db.createCollection('test_index_on_subfield', function (err, collection) {\n          collection.insert([{\n            hello: {\n              a: 4,\n              b: 5\n            }\n          }, {\n            hello: {\n              a: 7,\n              b: 2\n            }\n          }, {\n            hello: {\n              a: 4,\n              b: 10\n            }\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // Create a unique subfield index and test that insert fails\n\n            db.createCollection('test_index_on_subfield2', function (err, collection) {\n              db.createIndex(collection.collectionName, 'hello_a', {\n                writeConcern: {\n                  w: 1\n                },\n                unique: true\n              }, function (err) {\n                expect(err).to.not.exist;\n                collection.insert([{\n                  hello: {\n                    a: 4,\n                    b: 5\n                  }\n                }, {\n                  hello: {\n                    a: 7,\n                    b: 2\n                  }\n                }, {\n                  hello: {\n                    a: 4,\n                    b: 10\n                  }\n                }], configuration.writeConcernMax(), function (err) {\n                  // Assert that we have erros\n                  test.ok(err != null);\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDropIndexes","suites":["Indexes","promise tests"],"updatePoint":{"line":281,"column":32,"index":9650},"line":281,"code":"  it('shouldCorrectlyDropIndexes', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_drop_indexes', function (err, collection) {\n          collection.insert({\n            a: 1\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // Create an index on the collection\n\n            db.createIndex(collection.collectionName, 'a', configuration.writeConcernMax(), function (err, indexName) {\n              test.equal('a_1', indexName); // Drop all the indexes\n\n              collection.dropIndexes(function (err, result) {\n                test.equal(true, result);\n                collection.indexInformation(function (err, result) {\n                  test.ok(result['a_1'] == null);\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleDistinctIndexes","suites":["Indexes","promise tests"],"updatePoint":{"line":316,"column":42,"index":10922},"line":316,"code":"  it('shouldCorrectlyHandleDistinctIndexes', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_distinct_queries', function (err, collection) {\n          collection.insert([{\n            a: 0,\n            b: {\n              c: 'a'\n            }\n          }, {\n            a: 1,\n            b: {\n              c: 'b'\n            }\n          }, {\n            a: 1,\n            b: {\n              c: 'c'\n            }\n          }, {\n            a: 2,\n            b: {\n              c: 'a'\n            }\n          }, {\n            a: 3\n          }, {\n            a: 3\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.distinct('a', function (err, docs) {\n              test.deepEqual([0, 1, 2, 3], docs.sort());\n              collection.distinct('b.c', function (err, docs) {\n                test.deepEqual(['a', 'b', 'c'], docs.sort());\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteEnsureIndex","suites":["Indexes","promise tests"],"updatePoint":{"line":368,"column":39,"index":12340},"line":368,"code":"  it('shouldCorrectlyExecuteEnsureIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_ensure_index', function (err, collection) {\n          expect(err).to.not.exist; // Create an index on the collection\n\n          db.createIndex(collection.collectionName, 'a', configuration.writeConcernMax(), function (err, indexName) {\n            expect(err).to.not.exist;\n            test.equal('a_1', indexName); // Let's fetch the index information\n\n            db.indexInformation(collection.collectionName, function (err, collectionInfo) {\n              test.ok(collectionInfo['_id_'] != null);\n              test.equal('_id', collectionInfo['_id_'][0][0]);\n              test.ok(collectionInfo['a_1'] != null);\n              test.deepEqual([['a', 1]], collectionInfo['a_1']);\n              db.createIndex(collection.collectionName, 'a', configuration.writeConcernMax(), function (err, indexName) {\n                test.equal('a_1', indexName); // Let's fetch the index information\n\n                db.indexInformation(collection.collectionName, function (err, collectionInfo) {\n                  test.ok(collectionInfo['_id_'] != null);\n                  test.equal('_id', collectionInfo['_id_'][0][0]);\n                  test.ok(collectionInfo['a_1'] != null);\n                  test.deepEqual([['a', 1]], collectionInfo['a_1']); // Let's close the db\n\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateAndUseSparseIndex","suites":["Indexes","promise tests"],"updatePoint":{"line":411,"column":44,"index":14233},"line":411,"code":"  it('shouldCorrectlyCreateAndUseSparseIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('create_and_use_sparse_index_test', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('create_and_use_sparse_index_test');\n          collection.createIndex({\n            title: 1\n          }, {\n            sparse: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n            collection.insert([{\n              name: 'Jim'\n            }, {\n              name: 'Sarah',\n              title: 'Princess'\n            }], configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist;\n              collection.find({\n                title: {\n                  $ne: null\n                }\n              }).sort({\n                title: 1\n              }).toArray(function (err, items) {\n                test.equal(1, items.length);\n                test.equal('Sarah', items[0].name); // Fetch the info for the indexes\n\n                collection.indexInformation({\n                  full: true\n                }, function (err, indexInfo) {\n                  expect(err).to.not.exist;\n                  test.equal(2, indexInfo.length);\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleGeospatialIndexes","suites":["Indexes","promise tests"],"updatePoint":{"line":467,"column":44,"index":16047},"line":467,"code":"  it('shouldCorrectlyHandleGeospatialIndexes', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.6.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('geospatial_index_test', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('geospatial_index_test');\n          collection.createIndex({\n            loc: '2d'\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.insert({\n              loc: [-100, 100]\n            }, configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist;\n              collection.insert({\n                loc: [200, 200]\n              }, configuration.writeConcernMax(), function (err) {\n                test.ok(err.errmsg.indexOf('point not in interval of') !== -1);\n                test.ok(err.errmsg.indexOf('-180') !== -1);\n                test.ok(err.errmsg.indexOf('180') !== -1);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleGeospatialIndexesAlteredRange","suites":["Indexes","promise tests"],"updatePoint":{"line":508,"column":56,"index":17626},"line":508,"code":"  it('shouldCorrectlyHandleGeospatialIndexesAlteredRange', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.6.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('geospatial_index_altered_test', function (err) {\n          expect(err).to.not.exist;\n          const collection = db.collection('geospatial_index_altered_test');\n          collection.createIndex({\n            loc: '2d'\n          }, {\n            min: 0,\n            max: 1024,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n            collection.insert({\n              loc: [100, 100]\n            }, configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist;\n              collection.insert({\n                loc: [200, 200]\n              }, configuration.writeConcernMax(), function (err) {\n                expect(err).to.not.exist;\n                collection.insert({\n                  loc: [-200, -200]\n                }, configuration.writeConcernMax(), function (err) {\n                  test.ok(err.errmsg.indexOf('point not in interval of') !== -1);\n                  test.ok(err.errmsg.indexOf('0') !== -1);\n                  test.ok(err.errmsg.indexOf('1024') !== -1);\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldThrowDuplicateKeyErrorWhenCreatingIndex","suites":["Indexes","promise tests"],"updatePoint":{"line":560,"column":51,"index":19510},"line":560,"code":"  it('shouldThrowDuplicateKeyErrorWhenCreatingIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('shouldThrowDuplicateKeyErrorWhenCreatingIndex', function (err, collection) {\n          collection.insert([{\n            a: 1\n          }, {\n            a: 1\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.createIndex({\n              a: 1\n            }, {\n              unique: true,\n              writeConcern: {\n                w: 1\n              }\n            }, function (err) {\n              test.ok(err != null);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldThrowDuplicateKeyErrorWhenDriverInStrictMode","suites":["Indexes","promise tests"],"updatePoint":{"line":596,"column":56,"index":20602},"line":596,"code":"  it('shouldThrowDuplicateKeyErrorWhenDriverInStrictMode', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('shouldThrowDuplicateKeyErrorWhenDriverInStrictMode', function (err, collection) {\n          collection.insert([{\n            a: 1\n          }, {\n            a: 1\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.createIndex({\n              a: 1\n            }, {\n              unique: true,\n              writeConcern: {\n                w: 1\n              }\n            }, function (err) {\n              test.ok(err != null);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUseMinMaxForSettingRangeInEnsureIndex","suites":["Indexes","promise tests"],"updatePoint":{"line":632,"column":58,"index":21701},"line":632,"code":"  it('shouldCorrectlyUseMinMaxForSettingRangeInEnsureIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db); // Establish connection to db\n\n        db.createCollection('shouldCorrectlyUseMinMaxForSettingRangeInEnsureIndex', function (err, collection) {\n          expect(err).to.not.exist;\n          collection.createIndex({\n            loc: '2d'\n          }, {\n            min: 200,\n            max: 1400,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n            collection.insert({\n              loc: [600, 600]\n            }, configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist;\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"Should correctly create an index with overriden name","suites":["Indexes","promise tests"],"updatePoint":{"line":669,"column":58,"index":22864},"line":669,"code":"  it('Should correctly create an index with overriden name', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db); // Establish connection to db\n\n        db.createCollection('shouldCorrectlyCreateAnIndexWithOverridenName', function (err, collection) {\n          expect(err).to.not.exist;\n          collection.createIndex('name', {\n            name: 'myfunky_name'\n          }, function (err) {\n            expect(err).to.not.exist; // Fetch full index information\n\n            collection.indexInformation({\n              full: false\n            }, function (err, indexInformation) {\n              test.ok(indexInformation['myfunky_name'] != null);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should handle index declarations using objects from other contexts","suites":["Indexes","promise tests"],"updatePoint":{"line":701,"column":72,"index":23981},"line":701,"code":"  it('should handle index declarations using objects from other contexts', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('indexcontext').createIndex(shared.object, {\n          background: true\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('indexcontext').createIndex(shared.array, {\n            background: true\n          }, function (err) {\n            expect(err).to.not.exist;\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly return error message when applying unique index to duplicate documents","suites":["Indexes","promise tests"],"updatePoint":{"line":728,"column":93,"index":24891},"line":728,"code":"  it('should correctly return error message when applying unique index to duplicate documents', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('should_throw_error_due_to_duplicates');\n        collection.insert([{\n          a: 1\n        }, {\n          a: 1\n        }, {\n          a: 1\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          collection.createIndex({\n            a: 1\n          }, {\n            writeConcern: {\n              w: 1\n            },\n            unique: true\n          }, function (err) {\n            test.ok(err != null);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly drop index with no callback","suites":["Indexes","promise tests"],"updatePoint":{"line":765,"column":50,"index":25931},"line":765,"code":"  it('should correctly drop index with no callback', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('should_correctly_drop_index');\n        collection.insert([{\n          a: 1\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          collection.createIndex({\n            a: 1\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.dropIndex('a_1').then(() => {\n              client.close(done);\n            }).catch(err => {\n              client.close();\n              done(err);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly apply hint to find","suites":["Indexes","promise tests"],"updatePoint":{"line":798,"column":41,"index":26988},"line":798,"code":"  it('should correctly apply hint to find', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('should_correctly_apply_hint');\n        collection.insert([{\n          a: 1\n        }], configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          collection.createIndex({\n            a: 1\n          }, configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist;\n            collection.indexInformation({\n              full: false\n            }, function (err) {\n              expect(err).to.not.exist;\n              collection.find({}, {\n                hint: 'a_1'\n              }).toArray(function (err, docs) {\n                expect(err).to.not.exist;\n                test.equal(1, docs[0].a);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly set language_override option","suites":["Indexes","promise tests"],"updatePoint":{"line":837,"column":51,"index":28273},"line":837,"code":"  it('should correctly set language_override option', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('should_correctly_set_language_override');\n        collection.insert([{\n          text: 'Lorem ipsum dolor sit amet.',\n          langua: 'italian'\n        }], function (err) {\n          expect(err).to.not.exist;\n          collection.createIndex({\n            text: 'text'\n          }, {\n            language_override: 'langua',\n            name: 'language_override_index'\n          }, function (err) {\n            expect(err).to.not.exist;\n            collection.indexInformation({\n              full: true\n            }, function (err, indexInformation) {\n              expect(err).to.not.exist;\n\n              for (var i = 0; i < indexInformation.length; i++) {\n                if (indexInformation[i].name === 'language_override_index') test.equal(indexInformation[i].language_override, 'langua');\n              }\n\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly use listIndexes to retrieve index list","suites":["Indexes","promise tests"],"updatePoint":{"line":880,"column":61,"index":29731},"line":880,"code":"  it('should correctly use listIndexes to retrieve index list', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.4.0',\n        topology: ['single', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('testListIndexes').createIndex({\n          a: 1\n        }, function (err) {\n          expect(err).to.not.exist; // Get the list of indexes\n\n          db.collection('testListIndexes').listIndexes().toArray(function (err, indexes) {\n            expect(err).to.not.exist;\n            test.equal(2, indexes.length);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly use listIndexes to retrieve index list using hasNext","suites":["Indexes","promise tests"],"updatePoint":{"line":908,"column":75,"index":30637},"line":908,"code":"  it('should correctly use listIndexes to retrieve index list using hasNext', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.4.0',\n        topology: ['single', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('testListIndexes_2').createIndex({\n          a: 1\n        }, function (err) {\n          expect(err).to.not.exist; // Get the list of indexes\n\n          db.collection('testListIndexes_2').listIndexes().hasNext(function (err, result) {\n            expect(err).to.not.exist;\n            test.equal(true, result);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly ensureIndex for nested style index name c.d","suites":["Indexes","promise tests"],"updatePoint":{"line":936,"column":66,"index":31532},"line":936,"code":"  it('should correctly ensureIndex for nested style index name c.d', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.4.0',\n        topology: ['single', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('ensureIndexWithNestedStyleIndex').createIndex({\n          'c.d': 1\n        }, function (err) {\n          expect(err).to.not.exist; // Get the list of indexes\n\n          db.collection('ensureIndexWithNestedStyleIndex').listIndexes().toArray(function (err, indexes) {\n            expect(err).to.not.exist;\n            test.equal(2, indexes.length);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute createIndexes with multiple indexes","suites":["Indexes","promise tests"],"updatePoint":{"line":964,"column":66,"index":32465},"line":964,"code":"  it('should correctly execute createIndexes with multiple indexes', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('createIndexes').createIndexes([{\n          key: {\n            a: 1\n          }\n        }, {\n          key: {\n            b: 1\n          },\n          name: 'hello1'\n        }], function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).to.deep.equal(['a_1', 'hello1']);\n          db.collection('createIndexes').listIndexes().toArray(function (err, docs) {\n            expect(err).to.not.exist;\n            var keys = {};\n\n            for (var i = 0; i < docs.length; i++) {\n              keys[docs[i].name] = true;\n            }\n\n            test.ok(keys['a_1']);\n            test.ok(keys['hello1']);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute createIndexes with one index","suites":["Indexes","promise tests"],"updatePoint":{"line":1006,"column":59,"index":33632},"line":1006,"code":"  it('should correctly execute createIndexes with one index', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('createIndexes').createIndexes([{\n          key: {\n            a: 1\n          }\n        }], function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).to.deep.equal(['a_1']);\n          db.collection('createIndexes').listIndexes().toArray(function (err, docs) {\n            expect(err).to.not.exist;\n            var keys = {};\n\n            for (var i = 0; i < docs.length; i++) {\n              keys[docs[i].name] = true;\n            }\n\n            test.ok(keys['a_1']);\n            test.ok(keys['hello1']);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateTextIndex","suites":["Indexes","promise tests"],"updatePoint":{"line":1043,"column":36,"index":34681},"line":1043,"code":"  it('shouldCorrectlyCreateTextIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('text_index').createIndex({\n          '$**': 'text'\n        }, {\n          name: 'TextIndex'\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          test.equal('TextIndex', r); // Let's close the db\n\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly pass partialIndexes through to createIndexCommand","suites":["Indexes","promise tests"],"updatePoint":{"line":1069,"column":72,"index":35474},"line":1069,"code":"  it('should correctly pass partialIndexes through to createIndexCommand', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger'],\n        mongodb: '>=3.1.8'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var started = [];\n      var succeeded = [];\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        monitorCommands: true\n      });\n      client.on('commandStarted', function (event) {\n        if (event.commandName === 'createIndexes') started.push(event);\n      });\n      client.on('commandSucceeded', function (event) {\n        if (event.commandName === 'createIndexes') succeeded.push(event);\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('partialIndexes').createIndex({\n          a: 1\n        }, {\n          partialFilterExpression: {\n            a: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          test.deepEqual({\n            a: 1\n          }, started[0].command.indexes[0].partialFilterExpression);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should not retry partial index expression error","suites":["Indexes","promise tests"],"updatePoint":{"line":1108,"column":53,"index":36713},"line":1108,"code":"  it('should not retry partial index expression error', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded'],\n        mongodb: '>=3.1.8'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (error, client) {\n        var db = client.db(configuration.db);\n        expect(error).to.not.exist; // Can't use $exists: false in partial filter expression, see\n        // https://jira.mongodb.org/browse/SERVER-17853\n\n        var opts = {\n          partialFilterExpression: {\n            a: {\n              $exists: false\n            }\n          }\n        };\n        db.collection('partialIndexes').createIndex({\n          a: 1\n        }, opts, function (err) {\n          test.ok(err);\n          test.equal(err.code, 67);\n          var msg = \"key $exists must not start with '$'\";\n          test.ok(err.toString().indexOf(msg) === -1);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly create index on embedded key","suites":["Indexes","promise tests"],"updatePoint":{"line":1144,"column":51,"index":37816},"line":1144,"code":"  it('should correctly create index on embedded key', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        var collection = db.collection('embedded_key_indes');\n        collection.insertMany([{\n          a: {\n            a: 1\n          }\n        }, {\n          a: {\n            a: 2\n          }\n        }], function (err) {\n          expect(err).to.not.exist;\n          collection.createIndex({\n            'a.a': 1\n          }, function (err) {\n            expect(err).to.not.exist;\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly create index using . keys","suites":["Indexes","promise tests"],"updatePoint":{"line":1179,"column":48,"index":38777},"line":1179,"code":"  it('should correctly create index using . keys', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        var collection = db.collection('embedded_key_indes_1');\n        collection.createIndex({\n          'key.external_id': 1,\n          'key.type': 1\n        }, {\n          unique: true,\n          sparse: true,\n          name: 'indexname'\n        }, function (err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"error on duplicate key index","suites":["Indexes","promise tests"],"updatePoint":{"line":1208,"column":34,"index":39629},"line":1208,"code":"  it('error on duplicate key index', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        var collection = db.collection('embedded_key_indes_2');\n        collection.insertMany([{\n          key: {\n            external_id: 1,\n            type: 1\n          }\n        }, {\n          key: {\n            external_id: 1,\n            type: 1\n          }\n        }], function (err) {\n          expect(err).to.not.exist;\n          collection.createIndex({\n            'key.external_id': 1,\n            'key.type': 1\n          }, {\n            unique: true,\n            sparse: true,\n            name: 'indexname'\n          }, function (err) {\n            test.equal(11000, err.code);\n            client.close(done);\n          });\n        });\n      });\n    }\n  }); // it('should correctly return all indexes'] = {","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly create Index with sub element","suites":["Indexes","promise tests"],"updatePoint":{"line":1279,"column":52,"index":42160},"line":1279,"code":"  it('should correctly create Index with sub element', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db); // insert a doc\n\n        db.collection('messed_up_index').createIndex({\n          temporary: 1,\n          'store.addressLines': 1,\n          lifecycleStatus: 1\n        }, configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly fail detect error code 85 when performing createIndex","suites":["Indexes","promise tests"],"updatePoint":{"line":1304,"column":76,"index":42971},"line":1304,"code":"  it('should correctly fail detect error code 85 when performing createIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger'],\n        mongodb: '>=3.0.0 <=4.8.0'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('messed_up_options');\n        collection.createIndex({\n          'a.one': 1,\n          'a.two': 1\n        }, {\n          name: 'n1',\n          sparse: false\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.createIndex({\n            'a.one': 1,\n            'a.two': 1\n          }, {\n            name: 'n2',\n            sparse: true\n          }, function (err) {\n            test.ok(err);\n            test.equal(85, err.code);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly fail by detecting error code 86 when performing createIndex","suites":["Indexes","promise tests"],"updatePoint":{"line":1342,"column":82,"index":44083},"line":1342,"code":"  it('should correctly fail by detecting error code 86 when performing createIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger'],\n        mongodb: '>=3.0.0'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('messed_up_options');\n        collection.createIndex({\n          'b.one': 1,\n          'b.two': 1\n        }, {\n          name: 'test'\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.createIndex({\n            'b.one': -1,\n            'b.two': -1\n          }, {\n            name: 'test'\n          }, function (err) {\n            test.ok(err);\n            test.equal(86, err.code);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly create Index with sub element running in background","suites":["Indexes","promise tests"],"updatePoint":{"line":1378,"column":74,"index":45134},"line":1378,"code":"  it('should correctly create Index with sub element running in background', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db); // insert a doc\n\n        db.collection('messed_up_index_2').createIndex({\n          'accessControl.get': 1\n        }, {\n          background: true\n        }, function (err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if commitQuorum specified on db.createIndex","suites":["Indexes","commitQuorum"],"updatePoint":{"line":1424,"column":73,"index":46543},"line":1424,"code":"    it('should throw an error if commitQuorum specified on db.createIndex', throwErrorTest((db, collection, cb) => db.createIndex(collection.collectionName, 'a', {\n      commitQuorum: 'all'\n    }, cb)));","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if commitQuorum specified on collection.createIndex","suites":["Indexes","commitQuorum"],"updatePoint":{"line":1427,"column":81,"index":46755},"line":1427,"code":"    it('should throw an error if commitQuorum specified on collection.createIndex', throwErrorTest((db, collection, cb) => collection.createIndex('a', {\n      commitQuorum: 'all'\n    }, cb)));","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if commitQuorum specified on collection.createIndexes","suites":["Indexes","commitQuorum"],"updatePoint":{"line":1430,"column":83,"index":46950},"line":1430,"code":"    it('should throw an error if commitQuorum specified on collection.createIndexes', throwErrorTest((db, collection, cb) => collection.createIndexes([{\n      key: {\n        a: 1\n      }\n    }, {\n      key: {\n        b: 1\n      }\n    }], {\n      commitQuorum: 'all'\n    }, cb)));","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should run command with commitQuorum if specified on db.createIndex","suites":["Indexes","commitQuorum"],"updatePoint":{"line":1471,"column":75,"index":48148},"line":1471,"code":"    it('should run command with commitQuorum if specified on db.createIndex', commitQuorumTest((db, collection, cb) => db.createIndex(collection.collectionName, 'a', {\n      writeConcern: {\n        w: 'majority'\n      },\n      commitQuorum: 0\n    }, cb)));","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should run command with commitQuorum if specified on collection.createIndex","suites":["Indexes","commitQuorum"],"updatePoint":{"line":1477,"column":83,"index":48413},"line":1477,"code":"    it('should run command with commitQuorum if specified on collection.createIndex', commitQuorumTest((db, collection, cb) => collection.createIndex('a', {\n      writeConcern: {\n        w: 'majority'\n      },\n      commitQuorum: 0\n    }, cb)));","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should run command with commitQuorum if specified on collection.createIndexes","suites":["Indexes","commitQuorum"],"updatePoint":{"line":1483,"column":85,"index":48661},"line":1483,"code":"    it('should run command with commitQuorum if specified on collection.createIndexes', commitQuorumTest((db, collection, cb) => collection.createIndexes([{\n      key: {\n        a: 1\n      }\n    }], {\n      writeConcern: {\n        w: 'majority'\n      },\n      commitQuorum: 0\n    }, cb)));","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should create index hidden","suites":["Indexes","commitQuorum"],"updatePoint":{"line":1494,"column":32,"index":48904},"line":1494,"code":"  it('should create index hidden', {\n    metadata: {\n      requires: {\n        mongodb: '>=4.4',\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        const db = client.db(configuration.db);\n        db.createCollection('hidden_index_collection', (err, collection) => {\n          expect(err).to.not.exist;\n          collection.createIndex('a', {\n            hidden: true\n          }, (err, index) => {\n            expect(err).to.not.exist;\n            expect(index).to.equal('a_1');\n            collection.listIndexes().toArray((err, indexes) => {\n              expect(err).to.not.exist;\n              expect(indexes).to.deep.equal([{\n                v: 2,\n                key: {\n                  _id: 1\n                },\n                name: '_id_'\n              }, {\n                v: 2,\n                key: {\n                  a: 1\n                },\n                name: 'a_1',\n                hidden: true\n              }]);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/index_management.test.js","skipped":false,"dir":"test"},{"name":"should correctly set maxStalenessSeconds on Mongos query on connect","suites":["Max Staleness"],"updatePoint":{"line":60,"column":73,"index":1388},"line":60,"code":"  it('should correctly set maxStalenessSeconds on Mongos query on connect', {\n    metadata: {\n      requires: {\n        generators: true,\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      const configuration = this.configuration;\n      const client = configuration.newClient(`mongodb://${test.server.uri()}/test?readPreference=secondary&maxStalenessSeconds=250`);\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(self.configuration.db);\n        db.collection('test').find({}).toArray(function (err) {\n          expect(err).to.not.exist;\n          expect(test.checkCommand).to.containSubset({\n            $query: {\n              find: 'test',\n              filter: {}\n            },\n            $readPreference: {\n              mode: 'secondary',\n              maxStalenessSeconds: 250\n            }\n          });\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/max-staleness/max_staleness.test.js","skipped":false,"dir":"test"},{"name":"should correctly set maxStalenessSeconds on Mongos query using db level readPreference","suites":["Max Staleness"],"updatePoint":{"line":91,"column":92,"index":2391},"line":91,"code":"  it('should correctly set maxStalenessSeconds on Mongos query using db level readPreference', {\n    metadata: {\n      requires: {\n        generators: true,\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient(`mongodb://${test.server.uri()}/test`);\n      client.connect(function (err, client) {\n        expect(err).to.not.exist; // Get a db with a new readPreference\n\n        var db1 = client.db('test', {\n          readPreference: new ReadPreference('secondary', null, {\n            maxStalenessSeconds: 250\n          })\n        });\n        db1.collection('test').find({}).toArray(function (err) {\n          expect(err).to.not.exist;\n          expect(test.checkCommand).to.containSubset({\n            $query: {\n              find: 'test',\n              filter: {}\n            },\n            $readPreference: {\n              mode: 'secondary',\n              maxStalenessSeconds: 250\n            }\n          });\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/max-staleness/max_staleness.test.js","skipped":false,"dir":"test"},{"name":"should correctly set maxStalenessSeconds on Mongos query using collection level readPreference","suites":["Max Staleness"],"updatePoint":{"line":126,"column":100,"index":3485},"line":126,"code":"  it('should correctly set maxStalenessSeconds on Mongos query using collection level readPreference', {\n    metadata: {\n      requires: {\n        generators: true,\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      const configuration = this.configuration;\n      const client = configuration.newClient(`mongodb://${test.server.uri()}/test`);\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(self.configuration.db); // Get a db with a new readPreference\n\n        db.collection('test', {\n          readPreference: new ReadPreference('secondary', null, {\n            maxStalenessSeconds: 250\n          })\n        }).find({}).toArray(function (err) {\n          expect(err).to.not.exist;\n          expect(test.checkCommand).to.containSubset({\n            $query: {\n              find: 'test',\n              filter: {}\n            },\n            $readPreference: {\n              mode: 'secondary',\n              maxStalenessSeconds: 250\n            }\n          });\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/max-staleness/max_staleness.test.js","skipped":false,"dir":"test"},{"name":"should correctly set maxStalenessSeconds on Mongos query using cursor level readPreference","suites":["Max Staleness"],"updatePoint":{"line":162,"column":96,"index":4611},"line":162,"code":"  it('should correctly set maxStalenessSeconds on Mongos query using cursor level readPreference', {\n    metadata: {\n      requires: {\n        generators: true,\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      const configuration = this.configuration;\n      const client = configuration.newClient(`mongodb://${test.server.uri()}/test`);\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(self.configuration.db);\n        var readPreference = new ReadPreference('secondary', null, {\n          maxStalenessSeconds: 250\n        }); // Get a db with a new readPreference\n\n        db.collection('test').find({}).withReadPreference(readPreference).toArray(function (err) {\n          expect(err).to.not.exist;\n          expect(test.checkCommand).to.containSubset({\n            $query: {\n              find: 'test',\n              filter: {}\n            },\n            $readPreference: {\n              mode: 'secondary',\n              maxStalenessSeconds: 250\n            }\n          });\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/max-staleness/max_staleness.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute legacy hello command using Promise","suites":["Handshake"],"updatePoint":{"line":21,"column":65,"index":451},"line":21,"code":"  it('Should correctly execute legacy hello command using Promise', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var url = configuration.url();\n      url = url.indexOf('?') !== -1 ? f('%s&%s', url, 'maxPoolSize=5') : f('%s?%s', url, 'maxPoolSize=5');\n      const client = configuration.newClient(url);\n      client.connect().then(function (client) {\n        // Execute legacy hello command\n        client.db(configuration.db).command({\n          [LEGACY_HELLO_COMMAND]: true\n        }).then(function (result) {\n          test.ok(result !== null);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/mongodb-handshake/promise_handshake.test.js","skipped":false,"dir":"test"},{"name":"should respond with BSONRegExp class with option passed to ","suites":["BSONRegExp","bsonRegExp option"],"updatePoint":{"line":20,"column":84,"index":465},"line":20,"code":"      it(`should respond with BSONRegExp class with option passed to ${passOptionTo}`, async function () {\n        try {\n          client = this.configuration.newClient(passOptionTo === 'client' ? option : undefined);\n          await client.connect();\n          const db = client.db('bson_regex_db', passOptionTo === 'db' ? option : undefined);\n          const collection = db.collection('bson_regex_coll', passOptionTo === 'collection' ? option : undefined);\n          await collection.insertOne({\n            regex: new BSONRegExp('abc', 'imx')\n          });\n          const res = await collection.findOne({\n            regex: new BSONRegExp('abc', 'imx')\n          }, passOptionTo === 'operation' ? option : undefined);\n          expect(res).has.property('regex').that.is.instanceOf(BSONRegExp);\n        } finally {\n          await client.close();\n        }\n      });","file":"integration/node-specific/bson-options/bsonRegExp.test.js","skipped":false,"dir":"test"},{"name":"Should correctly insert document ignoring undefined field","suites":["Ignore Undefined"],"updatePoint":{"line":22,"column":63,"index":388},"line":22,"code":"  it('Should correctly insert document ignoring undefined field', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        ignoreUndefined: true\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('shouldCorrectlyIgnoreUndefinedValue'); // Ignore the undefined field\n\n        collection.insert({\n          a: 1,\n          b: undefined\n        }, configuration.writeConcernMax(), function (err) {\n          expect(err).to.not.exist; // Locate the doument\n\n          collection.findOne(function (err, item) {\n            test.equal(1, item.a);\n            test.ok(item.b === undefined);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"Should correctly connect using MongoClient and perform insert document ignoring undefined field","suites":["Ignore Undefined"],"updatePoint":{"line":53,"column":101,"index":1387},"line":53,"code":"  it('Should correctly connect using MongoClient and perform insert document ignoring undefined field', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient({}, {\n        ignoreUndefined: true,\n        sslValidate: false\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('shouldCorrectlyIgnoreUndefinedValue1');\n        collection.insert({\n          a: 1,\n          b: undefined\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.findOne(function (err, item) {\n            test.equal(1, item.a);\n            test.ok(item.b === undefined);\n            collection.insertOne({\n              a: 2,\n              b: undefined\n            }, function (err) {\n              expect(err).to.not.exist;\n              collection.findOne({\n                a: 2\n              }, function (err, item) {\n                test.equal(2, item.a);\n                test.ok(item.b === undefined);\n                collection.insertMany([{\n                  a: 3,\n                  b: undefined\n                }], function (err) {\n                  expect(err).to.not.exist;\n                  collection.findOne({\n                    a: 3\n                  }, function (err, item) {\n                    test.equal(3, item.a);\n                    test.ok(item.b === undefined);\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"Should correctly update document ignoring undefined field","suites":["Ignore Undefined"],"updatePoint":{"line":106,"column":63,"index":3038},"line":106,"code":"  it('Should correctly update document ignoring undefined field', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        ignoreUndefined: true\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('shouldCorrectlyIgnoreUndefinedValue2');\n        var id = new ObjectId();\n        collection.updateOne({\n          _id: id,\n          a: 1,\n          b: undefined\n        }, {\n          $set: {\n            a: 1,\n            b: undefined\n          }\n        }, {\n          upsert: true\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.findOne({\n            _id: id\n          }, function (err, item) {\n            test.equal(1, item.a);\n            test.ok(item.b === undefined);\n            var id = new ObjectId();\n            collection.updateMany({\n              _id: id,\n              a: 1,\n              b: undefined\n            }, {\n              $set: {\n                a: 1,\n                b: undefined\n              }\n            }, {\n              upsert: true\n            }, function (err) {\n              expect(err).to.not.exist;\n              collection.findOne({\n                _id: id\n              }, function (err, item) {\n                test.equal(1, item.a);\n                test.ok(item.b === undefined);\n                var id = new ObjectId();\n                collection.update({\n                  _id: id,\n                  a: 1,\n                  b: undefined\n                }, {\n                  $set: {\n                    a: 1,\n                    b: undefined\n                  }\n                }, {\n                  upsert: true\n                }, function (err) {\n                  expect(err).to.not.exist;\n                  collection.findOne({\n                    _id: id\n                  }, function (err, item) {\n                    test.equal(1, item.a);\n                    test.ok(item.b === undefined);\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"Should correctly inherit ignore undefined field from db during insert","suites":["Ignore Undefined"],"updatePoint":{"line":188,"column":75,"index":5393},"line":188,"code":"  it('Should correctly inherit ignore undefined field from db during insert', function () {\n    const configuration = this.configuration;\n    const client = configuration.newClient(configuration.writeConcernMax(), {\n      maxPoolSize: 1,\n      ignoreUndefined: false\n    });\n    return withClient.call(this, client, (client, done) => {\n      const db = client.db(configuration.db, {\n        ignoreUndefined: true\n      });\n      const collection = db.collection('shouldCorrectlyIgnoreUndefinedValue3'); // Ignore the undefined field\n\n      collection.insert({\n        a: 1,\n        b: undefined\n      }, configuration.writeConcernMax(), err => {\n        expect(err).to.not.exist; // Locate the doument\n\n        collection.findOne((err, item) => {\n          expect(err).to.not.exist;\n          expect(item).to.have.property('a', 1);\n          expect(item).to.not.have.property('b');\n          done();\n        });\n      });\n    });\n  });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"Should correctly inherit ignore undefined field from collection during insert","suites":["Ignore Undefined"],"updatePoint":{"line":215,"column":83,"index":6337},"line":215,"code":"  it('Should correctly inherit ignore undefined field from collection during insert', withClient(function (client, done) {\n    const db = client.db('shouldCorrectlyIgnoreUndefinedValue4', {\n      ignoreUndefined: false\n    });\n    const collection = db.collection('shouldCorrectlyIgnoreUndefinedValue4', {\n      ignoreUndefined: true\n    }); // Ignore the undefined field\n\n    collection.insert({\n      a: 1,\n      b: undefined\n    }, err => {\n      expect(err).to.not.exist; // Locate the doument\n\n      collection.findOne((err, item) => {\n        expect(err).to.not.exist;\n        expect(item).to.have.property('a', 1);\n        expect(item).to.not.have.property('b');\n        done();\n      });\n    });\n  }));","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"Should correctly inherit ignore undefined field from operation during insert","suites":["Ignore Undefined"],"updatePoint":{"line":237,"column":82,"index":7047},"line":237,"code":"  it('Should correctly inherit ignore undefined field from operation during insert', withClient(function (client, done) {\n    const db = client.db('shouldCorrectlyIgnoreUndefinedValue5');\n    const collection = db.collection('shouldCorrectlyIgnoreUndefinedValue5', {\n      ignoreUndefined: false\n    }); // Ignore the undefined field\n\n    collection.insert({\n      a: 1,\n      b: undefined\n    }, {\n      ignoreUndefined: true\n    }, err => {\n      expect(err).to.not.exist; // Locate the doument\n\n      collection.findOne({}, (err, item) => {\n        expect(err).to.not.exist;\n        expect(item).to.have.property('a', 1);\n        expect(item).to.not.have.property('b');\n        done();\n      });\n    });\n  }));","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"Should correctly inherit ignore undefined field from operation during findOneAndReplace","suites":["Ignore Undefined"],"updatePoint":{"line":259,"column":93,"index":7772},"line":259,"code":"  it('Should correctly inherit ignore undefined field from operation during findOneAndReplace', withClient(function (client, done) {\n    const db = client.db('shouldCorrectlyIgnoreUndefinedValue6');\n    const collection = db.collection('shouldCorrectlyIgnoreUndefinedValue6', {\n      ignoreUndefined: false\n    });\n    collection.insert({\n      a: 1,\n      b: 2\n    }, err => {\n      expect(err).to.not.exist; // Replace the doument, ignoring undefined fields\n\n      collection.findOneAndReplace({}, {\n        a: 1,\n        b: undefined\n      }, {\n        ignoreUndefined: true\n      }, err => {\n        expect(err).to.not.exist; // Locate the doument\n\n        collection.findOne((err, item) => {\n          expect(err).to.not.exist;\n          expect(item).to.have.property('a', 1);\n          expect(item).to.not.have.property('b');\n          done();\n        });\n      });\n    });\n  }));","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"Should correctly ignore undefined field during bulk write","suites":["Ignore Undefined"],"updatePoint":{"line":287,"column":63,"index":8629},"line":287,"code":"  it('Should correctly ignore undefined field during bulk write', withClient(function (client, done) {\n    const db = client.db('shouldCorrectlyIgnoreUndefinedValue7');\n    const collection = db.collection('shouldCorrectlyIgnoreUndefinedValue7'); // Ignore the undefined field\n\n    collection.bulkWrite([{\n      insertOne: {\n        a: 1,\n        b: undefined\n      }\n    }], {\n      ignoreUndefined: true\n    }, err => {\n      expect(err).to.not.exist; // Locate the doument\n\n      collection.findOne((err, item) => {\n        expect(err).to.not.exist;\n        expect(item).to.have.property('a', 1);\n        expect(item).to.not.have.property('b');\n        done();\n      });\n    });\n  }));","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute insert culling undefined","suites":["Ignore Undefined","[ignoreUndefined] A server"],"updatePoint":{"line":310,"column":57,"index":9367},"line":310,"code":"    it('should correctly execute insert culling undefined', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.2'\n        }\n      },\n      test: withClientV2(function (client, done) {\n        const coll = client.db().collection('insert1');\n        coll.drop(() => {\n          const objectId = new ObjectId();\n          coll.insertOne({\n            _id: objectId,\n            a: 1,\n            b: undefined\n          }, {\n            ignoreUndefined: true\n          }, (err, res) => {\n            expect(err).to.not.exist;\n            expect(res).property('insertedId').to.exist;\n            const cursor = coll.find({\n              _id: objectId\n            });\n            this.defer(() => cursor.close());\n            cursor.next((err, doc) => {\n              expect(err).to.not.exist;\n              expect(doc).to.not.have.property('b');\n              done();\n            });\n          });\n        });\n      })\n    });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute update culling undefined","suites":["Ignore Undefined","[ignoreUndefined] A server"],"updatePoint":{"line":342,"column":57,"index":10302},"line":342,"code":"    it('should correctly execute update culling undefined', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.2'\n        }\n      },\n      test: withClientV2(function (client, done) {\n        const coll = client.db().collection('update1');\n        coll.drop(() => {\n          const objectId = new ObjectId();\n          coll.updateOne({\n            _id: objectId,\n            a: 1,\n            b: undefined\n          }, {\n            $set: {\n              a: 1,\n              b: undefined\n            }\n          }, {\n            ignoreUndefined: true,\n            upsert: true\n          }, (err, res) => {\n            expect(err).to.not.exist;\n            expect(res).property('upsertedCount').to.equal(1);\n            const cursor = coll.find({\n              _id: objectId\n            });\n            this.defer(() => cursor.close());\n            cursor.next((err, doc) => {\n              expect(err).to.not.exist;\n              expect(doc).to.not.have.property('b');\n              done();\n            });\n          });\n        });\n      })\n    });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute remove culling undefined","suites":["Ignore Undefined","[ignoreUndefined] A server"],"updatePoint":{"line":380,"column":57,"index":11365},"line":380,"code":"    it('should correctly execute remove culling undefined', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.2'\n        }\n      },\n      test: withClientV2(function (client, done) {\n        const coll = client.db().collection('remove1');\n        coll.drop(() => {\n          const objectId = new ObjectId();\n          coll.insertMany([{\n            id: objectId,\n            a: 1,\n            b: undefined\n          }, {\n            id: objectId,\n            a: 2,\n            b: 1\n          }], (err, res) => {\n            expect(err).to.not.exist;\n            expect(res).property('insertedCount').to.equal(2);\n            coll.deleteMany({\n              b: undefined\n            }, {\n              ignoreUndefined: true\n            }, (err, res) => {\n              expect(err).to.not.exist;\n              expect(res).property('deletedCount').to.equal(2);\n              done();\n            });\n          });\n        });\n      })\n    });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"should correctly execute remove not culling undefined","suites":["Ignore Undefined","[ignoreUndefined] A server"],"updatePoint":{"line":414,"column":61,"index":12322},"line":414,"code":"    it('should correctly execute remove not culling undefined', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.2'\n        }\n      },\n      test: withClientV2(function (client, done) {\n        const coll = client.db().collection('remove1');\n        coll.drop(() => {\n          const objectId = new ObjectId();\n          coll.insertMany([{\n            id: objectId,\n            a: 1,\n            b: undefined\n          }, {\n            id: objectId,\n            a: 2,\n            b: 1\n          }], (err, res) => {\n            expect(err).to.not.exist;\n            expect(res).property('insertedCount').to.equal(2);\n            coll.deleteMany({\n              b: null\n            }, (err, res) => {\n              expect(err).to.not.exist;\n              expect(res).property('deletedCount').to.equal(1);\n              done();\n            });\n          });\n        });\n      })\n    });","file":"integration/node-specific/bson-options/ignore_undefined.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteBuffers when creating an instance using Db","suites":["Promote Buffers"],"updatePoint":{"line":16,"column":78,"index":320},"line":16,"code":"  it('should correctly honor promoteBuffers when creating an instance using Db', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        promoteBuffers: true\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteBuffer1').insert({\n          doc: Buffer.alloc(256)\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteBuffer1').findOne(function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc.doc instanceof Buffer);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_buffers.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteBuffers when creating an instance using MongoClient","suites":["Promote Buffers"],"updatePoint":{"line":45,"column":87,"index":1406},"line":45,"code":"  it('should correctly honor promoteBuffers when creating an instance using MongoClient', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient({}, {\n        promoteBuffers: true\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteBuffer2').insert({\n          doc: Buffer.alloc(256)\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteBuffer2').findOne(function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc.doc instanceof Buffer);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_buffers.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteBuffers at cursor level","suites":["Promote Buffers"],"updatePoint":{"line":73,"column":59,"index":2413},"line":73,"code":"  it('should correctly honor promoteBuffers at cursor level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient({}, {\n        promoteBuffers: true\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteBuffer3').insert({\n          doc: Buffer.alloc(256)\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteBuffer3').find().next(function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc.doc instanceof Buffer);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_buffers.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteBuffers at cursor find level","suites":["Promote Buffers"],"updatePoint":{"line":101,"column":64,"index":3429},"line":101,"code":"  it('should correctly honor promoteBuffers at cursor find level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteBuffer4').insert({\n          doc: Buffer.alloc(256)\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteBuffer4').find({}, {\n            promoteBuffers: true\n          }).next(function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc.doc instanceof Buffer);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_buffers.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteBuffers at aggregate level","suites":["Promote Buffers"],"updatePoint":{"line":129,"column":62,"index":4451},"line":129,"code":"  it('should correctly honor promoteBuffers at aggregate level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger'],\n        mongodb: '>=2.4.0'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteBuffer5').insert({\n          doc: Buffer.alloc(256)\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteBuffer5').aggregate([{\n            $match: {}\n          }], {\n            promoteBuffers: true\n          }).next(function (err, doc) {\n            expect(err).to.not.exist;\n            test.ok(doc.doc instanceof Buffer);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_buffers.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteValues when creating an instance using Db","suites":["Promote Values"],"updatePoint":{"line":22,"column":77,"index":385},"line":22,"code":"  it('should correctly honor promoteValues when creating an instance using Db', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1,\n        promoteValues: false\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteValues').insert({\n          doc: Long.fromNumber(10),\n          int: 10,\n          double: 2.2222,\n          array: [[Long.fromNumber(10)]]\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteValues').findOne(function (err, doc) {\n            expect(err).to.not.exist;\n            test.deepEqual(Long.fromNumber(10), doc.doc);\n            test.deepEqual(new Int32(10), doc.int);\n            test.deepEqual(new Double(2.2222), doc.double);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_values.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteValues when creating an instance using MongoClient","suites":["Promote Values"],"updatePoint":{"line":56,"column":86,"index":1679},"line":56,"code":"  it('should correctly honor promoteValues when creating an instance using MongoClient', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient({}, {\n        promoteValues: false\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteValues').insert({\n          doc: Long.fromNumber(10),\n          int: 10,\n          double: 2.2222,\n          array: [[Long.fromNumber(10)]]\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteValues').findOne(function (err, doc) {\n            expect(err).to.not.exist;\n            test.deepEqual(Long.fromNumber(10), doc.doc);\n            test.deepEqual(new Int32(10), doc.int);\n            test.deepEqual(new Double(2.2222), doc.double);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_values.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteValues at cursor level","suites":["Promote Values"],"updatePoint":{"line":89,"column":58,"index":2894},"line":89,"code":"  it('should correctly honor promoteValues at cursor level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient({}, {\n        promoteValues: false\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteValues').insert({\n          doc: Long.fromNumber(10),\n          int: 10,\n          double: 2.2222,\n          array: [[Long.fromNumber(10)]]\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteValues').find().next(function (err, doc) {\n            expect(err).to.not.exist;\n            test.deepEqual(Long.fromNumber(10), doc.doc);\n            test.deepEqual(new Int32(10), doc.int);\n            test.deepEqual(new Double(2.2222), doc.double);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_values.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteValues at cursor find level","suites":["Promote Values"],"updatePoint":{"line":122,"column":63,"index":4118},"line":122,"code":"  it('should correctly honor promoteValues at cursor find level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteValues').insert({\n          doc: Long.fromNumber(10),\n          int: 10,\n          double: 2.2222,\n          array: [[Long.fromNumber(10)]]\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteValues').find({}, {\n            promoteValues: false\n          }).next(function (err, doc) {\n            expect(err).to.not.exist;\n            test.deepEqual(Long.fromNumber(10), doc.doc);\n            test.deepEqual(new Int32(10), doc.int);\n            test.deepEqual(new Double(2.2222), doc.double);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_values.test.js","skipped":false,"dir":"test"},{"name":"should correctly honor promoteValues at aggregate level","suites":["Promote Values"],"updatePoint":{"line":155,"column":61,"index":5348},"line":155,"code":"  it('should correctly honor promoteValues at aggregate level', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.collection('shouldCorrectlyHonorPromoteValues2').insert({\n          doc: Long.fromNumber(10),\n          int: 10,\n          double: 2.2222,\n          array: [[Long.fromNumber(10)]]\n        }, function (err) {\n          expect(err).to.not.exist;\n          db.collection('shouldCorrectlyHonorPromoteValues2').aggregate([{\n            $match: {}\n          }], {\n            promoteValues: false\n          }).next(function (err, doc) {\n            expect(err).to.not.exist;\n            test.deepEqual(Long.fromNumber(10), doc.doc);\n            test.deepEqual(new Int32(10), doc.int);\n            test.deepEqual(new Double(2.2222), doc.double);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_values.test.js","skipped":false,"dir":"test"},{"name":"Should correctly promoteValues when calling getMore on queries","suites":["Promote Values"],"updatePoint":{"line":190,"column":68,"index":6628},"line":190,"code":"  it('Should correctly promoteValues when calling getMore on queries', {\n    metadata: {\n      requires: {\n        topology: ['single', 'ssl', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect(function (err, client) {\n        var docs = new Array(150).fill(0).map(function (_, i) {\n          return {\n            _id: 'needle_' + i,\n            is_even: i % 2,\n            long: Long.fromString('1234567890'),\n            double: 0.23456,\n            int: 1234\n          };\n        });\n        var db = client.db(configuration.db);\n        db.collection('haystack').insertMany(docs, function (errInsert) {\n          if (errInsert) throw errInsert; // change limit from 102 to 101 and this test passes.\n          // seems to indicate that the promoteValues flag is used for the\n          // initial find, but not for subsequent getMores\n\n          db.collection('haystack').find({}, {\n            limit: 102,\n            promoteValues: false\n          }).stream().on('data', function (doc) {\n            test.equal(typeof doc.int, 'object');\n            test.equal(doc.int._bsontype, 'Int32');\n            test.equal(typeof doc.long, 'object');\n            test.equal(doc.long._bsontype, 'Long');\n            test.equal(typeof doc.double, 'object');\n            test.equal(doc.double._bsontype, 'Double');\n          }).on('end', function () {\n            db.dropCollection('haystack', function () {\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/promote_values.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlySaveDocumentsAndReturnAsRaw","suites":["Raw"],"updatePoint":{"line":22,"column":48,"index":350},"line":22,"code":"  it('shouldCorrectlySaveDocumentsAndReturnAsRaw', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('shouldCorrectlySaveDocumentsAndReturnAsRaw', function (err, collection) {\n          expect(err).to.not.exist; // Insert some documents\n\n          collection.insert([{\n            a: 1\n          }, {\n            b: 2000\n          }, {\n            c: 2.3\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist; // You have to pass at least query + fields before passing options\n\n            collection.find({}, {\n              raw: true,\n              batchSize: 2\n            }).toArray(function (err, items) {\n              var objects = [];\n\n              for (var i = 0; i < items.length; i++) {\n                test.ok(Buffer.isBuffer(items[i]));\n                objects.push(BSON.deserialize(items[i]));\n              }\n\n              test.equal(1, objects[0].a);\n              test.equal(2000, objects[1].b);\n              test.equal(2.3, objects[2].c); // Execute findOne\n\n              collection.findOne({\n                a: 1\n              }, {\n                raw: true\n              }, function (err, item) {\n                test.ok(Buffer.isBuffer(item));\n                var object = BSON.deserialize(item);\n                test.equal(1, object.a);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/raw.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlySaveDocumentsAndReturnAsRawWithRawSetAtCollectionLevel","suites":["Raw"],"updatePoint":{"line":82,"column":75,"index":2237},"line":82,"code":"  it('shouldCorrectlySaveDocumentsAndReturnAsRawWithRawSetAtCollectionLevel', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('shouldCorrectlySaveDocumentsAndReturnAsRaw_2', {\n          raw: true\n        }, function (err, collection) {\n          // Insert some documents\n          collection.insert([{\n            a: 1\n          }, {\n            b: 2000\n          }, {\n            c: 2.3\n          }], {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist;\n            collection.find({}, {\n              batchSize: 2\n            }).toArray(function (err, items) {\n              var objects = [];\n\n              for (var i = 0; i < items.length; i++) {\n                test.ok(Buffer.isBuffer(items[i]));\n                objects.push(BSON.deserialize(items[i]));\n              }\n\n              test.equal(1, objects[0].a);\n              test.equal(2000, objects[1].b);\n              test.equal(2.3, objects[2].c); // Execute findOne\n\n              collection.findOne({\n                a: 1\n              }, {\n                raw: true\n              }, function (err, item) {\n                test.ok(Buffer.isBuffer(item));\n                var object = BSON.deserialize(item);\n                test.equal(1, object.a);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/bson-options/raw.test.js","skipped":false,"dir":"test"},{"name":"should disable validation with option passed to ","suites":["class BinMsg","enableUtf8Validation option set to false"],"updatePoint":{"line":28,"column":73,"index":773},"line":28,"code":"      it(`should disable validation with option passed to ${passOptionTo}`, async function () {\n        try {\n          client = this.configuration.newClient(passOptionTo === 'client' ? option : undefined);\n          await client.connect();\n          const db = client.db('bson_utf8Validation_db', passOptionTo === 'db' ? option : undefined);\n          const collection = db.collection('bson_utf8Validation_coll', passOptionTo === 'collection' ? option : undefined);\n          await collection.insertOne({\n            name: 'John Doe'\n          }, passOptionTo === 'operation' ? option : {});\n          expect(deserializeSpy.called).to.be.true;\n          const validationArgument = deserializeSpy.lastCall.lastArg.validation;\n          expect(validationArgument).to.deep.equal(EXPECTED_VALIDATION_DISABLED_ARGUMENT);\n        } finally {\n          await client.close();\n        }\n      });","file":"integration/node-specific/bson-options/utf8_validation.test.ts","skipped":false,"dir":"test"},{"name":"should enable validation with option passed to ","suites":["class BinMsg","enableUtf8Validation option set to true"],"updatePoint":{"line":54,"column":72,"index":1940},"line":54,"code":"      it(`should enable validation with option passed to ${passOptionTo}`, async function () {\n        try {\n          client = this.configuration.newClient(passOptionTo === 'client' ? option : undefined);\n          await client.connect();\n          const db = client.db('bson_utf8Validation_db', passOptionTo === 'db' ? option : undefined);\n          const collection = db.collection('bson_utf8Validation_coll', passOptionTo === 'collection' ? option : undefined);\n          await collection.insertOne({\n            name: 'John Doe'\n          }, passOptionTo === 'operation' ? option : {});\n          expect(deserializeSpy.called).to.be.true;\n          const validationArgument = deserializeSpy.lastCall.lastArg.validation;\n          expect(validationArgument).to.deep.equal(EXPECTED_VALIDATION_ENABLED_ARGUMENT);\n        } finally {\n          await client.close();\n        }\n      });","file":"integration/node-specific/bson-options/utf8_validation.test.ts","skipped":false,"dir":"test"},{"name":"should default to enabled with option passed to ","suites":["class BinMsg","enableUtf8Validation option not set"],"updatePoint":{"line":79,"column":73,"index":3054},"line":79,"code":"      it(`should default to enabled with option passed to ${passOptionTo}`, async function () {\n        try {\n          client = this.configuration.newClient(passOptionTo === 'client' ? option : undefined);\n          await client.connect();\n          const db = client.db('bson_utf8Validation_db', passOptionTo === 'db' ? option : undefined);\n          const collection = db.collection('bson_utf8Validation_coll', passOptionTo === 'collection' ? option : undefined);\n          await collection.insertOne({\n            name: 'John Doe'\n          }, passOptionTo === 'operation' ? option : {});\n          expect(deserializeSpy.called).to.be.true;\n          const validationArgument = deserializeSpy.lastCall.lastArg.validation;\n          expect(validationArgument).to.deep.equal(EXPECTED_VALIDATION_ENABLED_ARGUMENT);\n        } finally {\n          await client.close();\n        }\n      });","file":"integration/node-specific/bson-options/utf8_validation.test.ts","skipped":false,"dir":"test"},{"name":"should be able to use a for-await loop on a find command cursor","suites":["Cursor Async Iterator Tests","default promise library"],"updatePoint":{"line":40,"column":71,"index":1108},"line":40,"code":"    it('should be able to use a for-await loop on a find command cursor', async function () {\n      const cursor = collection.find({\n        bar: 1\n      });\n      let counter = 0;\n\n      for await (const doc of cursor) {\n        expect(doc).to.have.property('bar', 1);\n        counter += 1;\n      }\n\n      expect(counter).to.equal(1000);\n    });","file":"integration/node-specific/cursor_async_iterator.test.js","skipped":false,"dir":"test"},{"name":"should be able to use a for-await loop on an aggregation cursor","suites":["Cursor Async Iterator Tests","default promise library"],"updatePoint":{"line":53,"column":71,"index":1455},"line":53,"code":"    it('should be able to use a for-await loop on an aggregation cursor', async function () {\n      const cursor = collection.aggregate([{\n        $match: {\n          bar: 1\n        }\n      }]);\n      let counter = 0;\n\n      for await (const doc of cursor) {\n        expect(doc).to.have.property('bar', 1);\n        counter += 1;\n      }\n\n      expect(counter).to.equal(1000);\n    });","file":"integration/node-specific/cursor_async_iterator.test.js","skipped":false,"dir":"test"},{"name":"should be able to use a for-await loop on a command cursor","suites":["Cursor Async Iterator Tests","default promise library"],"updatePoint":{"line":68,"column":66,"index":1834},"line":68,"code":"    it('should be able to use a for-await loop on a command cursor', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.0.0'\n        }\n      },\n      test: async function () {\n        const cursor1 = collection.listIndexes();\n        const cursor2 = collection.listIndexes();\n        const indexes = await cursor1.toArray();\n        let counter = 0;\n\n        for await (const doc of cursor2) {\n          expect(doc).to.exist;\n          counter += 1;\n        }\n\n        expect(counter).to.equal(indexes.length);\n      }\n    });","file":"integration/node-specific/cursor_async_iterator.test.js","skipped":false,"dir":"test"},{"name":"should properly stop when cursor is closed","suites":["Cursor Async Iterator Tests","default promise library"],"updatePoint":{"line":88,"column":50,"index":2358},"line":88,"code":"    it('should properly stop when cursor is closed', async function () {\n      const cursor = collection.find();\n      let count = 0;\n\n      for await (const doc of cursor) {\n        expect(doc).to.exist;\n        count++;\n        await cursor.close();\n      }\n\n      expect(count).to.equal(1);\n    });","file":"integration/node-specific/cursor_async_iterator.test.js","skipped":false,"dir":"test"},{"name":"should properly use custom promise","suites":["Cursor Async Iterator Tests","custom promise library"],"updatePoint":{"line":132,"column":42,"index":3738},"line":132,"code":"    it('should properly use custom promise', async function () {\n      const cursor = collection.find();\n      const countBeforeIteration = promiseSpy.callCount;\n\n      for await (const doc of cursor) {\n        expect(doc).to.exist;\n      }\n\n      expect(countBeforeIteration).to.not.equal(promiseSpy.callCount);\n      expect(promiseSpy.called).to.equal(true);\n    });","file":"integration/node-specific/cursor_async_iterator.test.js","skipped":false,"dir":"test"},{"name":"should properly use custom promise manual iteration","suites":["Cursor Async Iterator Tests","custom promise library"],"updatePoint":{"line":143,"column":59,"index":4124},"line":143,"code":"    it('should properly use custom promise manual iteration', async function () {\n      const cursor = collection.find();\n      const iterator = cursor[Symbol.asyncIterator]();\n      let isDone;\n\n      do {\n        const promiseFromIterator = iterator.next();\n        expect(promiseFromIterator).to.be.instanceOf(BluebirdPromise);\n        const {\n          done,\n          value\n        } = await promiseFromIterator;\n        if (done) expect(value).to.be.a('undefined');\n        isDone = done;\n      } while (!isDone);\n    });","file":"integration/node-specific/cursor_async_iterator.test.js","skipped":false,"dir":"test"},{"name":"should stream documents with pause and resume for fetching","suites":["Cursor Streams"],"updatePoint":{"line":17,"column":64,"index":332},"line":17,"code":"  it('should stream documents with pause and resume for fetching', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var docs = [];\n      var j = 0;\n\n      for (var i = 0; i < 3000; i++) {\n        docs.push({\n          a: i\n        });\n      }\n\n      var allDocs = [];\n\n      while (docs.length > 0) {\n        allDocs.push(docs.splice(0, 1000));\n      }\n\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        db.createCollection('test_streaming_function_with_limit_for_fetching2', function (err, collection) {\n          var left = allDocs.length;\n\n          for (var i = 0; i < allDocs.length; i++) {\n            collection.insert(allDocs[i], {\n              writeConcern: {\n                w: 1\n              }\n            }, function (err) {\n              expect(err).to.not.exist;\n              left = left - 1;\n\n              if (left === 0) {\n                // Perform a find to get a cursor\n                var stream = collection.find({}).stream();\n                var data = []; // For each data item\n\n                stream.on('data', function () {\n                  data.push(1);\n                  j = j + 1;\n                  stream.pause();\n                  collection.findOne({}, function (err) {\n                    expect(err).to.not.exist;\n                    stream.resume();\n                  });\n                }); // When the stream is done\n\n                stream.on('end', function () {\n                  setTimeout(() => {\n                    let err;\n\n                    try {\n                      expect(data).to.have.length(3000);\n                    } catch (e) {\n                      err = e;\n                    }\n\n                    client.close(() => done(err));\n                  }, 1000);\n                });\n              }\n            });\n          }\n        });\n      });\n    }\n  });","file":"integration/node-specific/cursor_stream.test.js","skipped":false,"dir":"test"},{"name":"should stream 10K documents","suites":["Cursor Streams"],"updatePoint":{"line":92,"column":33,"index":2441},"line":92,"code":"  it('should stream 10K documents', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var docs = [];\n\n      for (var i = 0; i < 10000; i++) {\n        docs.push({\n          a: i,\n          bin: new Binary(Buffer.alloc(256))\n        });\n      }\n\n      var j = 0;\n      var allDocs = [];\n\n      while (docs.length > 0) {\n        allDocs.push(docs.splice(0, 1000));\n      }\n\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        db.createCollection('test_streaming_function_with_limit_for_fetching_2', function (err, collection) {\n          var left = allDocs.length;\n\n          for (var i = 0; i < allDocs.length; i++) {\n            collection.insert(allDocs[i], {\n              writeConcern: {\n                w: 1\n              }\n            }, function (err) {\n              expect(err).to.not.exist;\n              left = left - 1;\n\n              if (left === 0) {\n                // Perform a find to get a cursor\n                var stream = collection.find({}).stream();\n                var data = []; // For each data item\n\n                stream.on('data', function () {\n                  j = j + 1;\n                  stream.pause();\n                  data.push(1);\n                  collection.findOne({}, function (err) {\n                    expect(err).to.not.exist;\n                    stream.resume();\n                  });\n                }); // When the stream is done\n\n                stream.on('end', function () {\n                  setTimeout(() => {\n                    let err;\n\n                    try {\n                      expect(data).to.have.length(10000);\n                    } catch (e) {\n                      err = e;\n                    }\n\n                    client.close(err2 => done(err || err2));\n                  }, 1000);\n                });\n              }\n            });\n          }\n        });\n      });\n    }\n  });","file":"integration/node-specific/cursor_stream.test.js","skipped":false,"dir":"test"},{"name":"should trigger massive amount of getMores","suites":["Cursor Streams"],"updatePoint":{"line":168,"column":47,"index":4623},"line":168,"code":"  it('should trigger massive amount of getMores', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var docs = [];\n      var counter = 0;\n      var counter2 = 0;\n\n      for (var i = 0; i < 1000; i++) {\n        docs.push({\n          a: i,\n          bin: new Binary(Buffer.alloc(256))\n        });\n      }\n\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        db.createCollection('test_streaming_function_with_limit_for_fetching_3', function (err, collection) {\n          collection.insert(docs, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err) {\n            expect(err).to.not.exist; // Perform a find to get a cursor\n\n            var stream = collection.find({}).stream(); // For each data item\n\n            stream.on('data', function () {\n              counter++;\n              stream.pause();\n              stream.resume();\n              counter2++;\n            }); // When the stream is done\n\n            stream.on('end', function () {\n              expect(counter).to.equal(1000);\n              expect(counter2).to.equal(1000);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  }); // TODO: NODE-3819: Unskip flaky MacOS tests.","file":"integration/node-specific/cursor_stream.test.js","skipped":false,"dir":"test"},{"name":"should correctly error out stream","suites":["Cursor Streams"],"updatePoint":{"line":290,"column":39,"index":8191},"line":290,"code":"  it('should correctly error out stream', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        const db = client.db(self.configuration.db);\n        const cursor = db.collection('myCollection').find({\n          timestamp: {\n            $ltx: '1111'\n          } // Error in query.\n\n        });\n        let error;\n        const stream = cursor.stream();\n        stream.on('error', err => error = err);\n        cursor.on('close', function () {\n          // NOTE: use `setImmediate` here because the stream implementation uses `nextTick` to emit the error\n          setImmediate(() => {\n            expect(error).to.exist;\n            client.close(done);\n          });\n        });\n        stream.pipe(process.stdout);\n      });\n    }\n  });","file":"integration/node-specific/cursor_stream.test.js","skipped":false,"dir":"test"},{"name":"should correctly stream cursor after stream","suites":["Cursor Streams"],"updatePoint":{"line":323,"column":49,"index":9237},"line":323,"code":"  it('should correctly stream cursor after stream', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var self = this;\n      var client = self.configuration.newClient(self.configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(self.configuration.db);\n        var docs = [];\n        var received = [];\n\n        for (var i = 0; i < 1000; i++) {\n          docs.push({\n            a: i,\n            field: 'hello world'\n          });\n        }\n\n        db.collection('cursor_sort_stream').insertMany(docs, function (err) {\n          expect(err).to.not.exist;\n          var cursor = db.collection('cursor_sort_stream').find({}).project({\n            a: 1\n          }).sort({\n            a: -1\n          });\n          const stream = cursor.stream();\n          stream.on('end', function () {\n            expect(received).to.have.length(1000);\n            client.close(done);\n          });\n          stream.on('data', function (d) {\n            received.push(d);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/cursor_stream.test.js","skipped":false,"dir":"test"},{"name":"should correctly implement custom dependency-less promise","suites":["Optional PromiseLibrary"],"updatePoint":{"line":18,"column":63,"index":387},"line":18,"code":"  it('should correctly implement custom dependency-less promise', function (done) {\n    const getCustomPromise = v => new CustomPromise(resolve => resolve(v));\n\n    const getNativePromise = v => new Promise(resolve => resolve(v));\n\n    expect(getNativePromise()).to.not.have.property('isCustomMongo');\n    expect(getCustomPromise()).to.have.property('isCustomMongo');\n    expect(getNativePromise()).to.have.property('then');\n    expect(getCustomPromise()).to.have.property('then');\n    done();\n  });","file":"integration/node-specific/custom_promise_library.test.js","skipped":false,"dir":"test"},{"name":"should have cursor return native promise","suites":["Optional PromiseLibrary"],"updatePoint":{"line":29,"column":46,"index":870},"line":29,"code":"  it('should have cursor return native promise', function (done) {\n    const configuration = this.configuration;\n    const client = this.configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1\n    });\n    client.connect((err, client) => {\n      expect(err).to.not.exist;\n      const db = client.db(configuration.db);\n      const collection = db.collection('test');\n      const cursor = collection.find({});\n      const isPromise = cursor.toArray();\n      expect(isPromise).to.not.have.property('isCustomMongo');\n      expect(isPromise).to.have.property('then');\n      isPromise.then(() => client.close(done));\n    });\n  });","file":"integration/node-specific/custom_promise_library.test.js","skipped":false,"dir":"test"},{"name":"should have cursor return custom promise from new client options","suites":["Optional PromiseLibrary"],"updatePoint":{"line":47,"column":70,"index":1529},"line":47,"code":"  it('should have cursor return custom promise from new client options', function (done) {\n    const configuration = this.configuration;\n    const client = this.configuration.newClient({\n      w: 1\n    }, {\n      maxPoolSize: 1,\n      promiseLibrary: CustomPromise\n    });\n    client.connect((err, client) => {\n      const db = client.db(configuration.db);\n      expect(err).to.not.exist;\n      const collection = db.collection('test');\n      const cursor = collection.find({});\n      const isPromise = cursor.toArray();\n      expect(isPromise).to.have.property('isCustomMongo');\n      expect(isPromise).to.have.property('then');\n      isPromise.then(() => client.close(done));\n    });\n  });","file":"integration/node-specific/custom_promise_library.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleIllegalDbNames","suites":["Db"],"updatePoint":{"line":21,"column":41,"index":324},"line":21,"code":"  it('shouldCorrectlyHandleIllegalDbNames', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: withClient((client, done) => {\n      expect(() => new Db(client, 5)).to.throw('Database name must be a string');\n      expect(() => new Db(client, '')).to.throw('Database name cannot be the empty string');\n      expect(() => new Db(client, 'te$t')).to.throw(\"database names cannot contain the character '$'\");\n      expect(() => new Db(client, '.test', function () {})).to.throw(\"database names cannot contain the character '.'\");\n      expect(() => new Db(client, '\\\\test', function () {})).to.throw(\"database names cannot contain the character '\\\\'\");\n      expect(() => new Db(client, 'test test', function () {})).to.throw(\"database names cannot contain the character ' '\");\n      done();\n    })\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleFailedConnection","suites":["Db"],"updatePoint":{"line":37,"column":43,"index":1191},"line":37,"code":"  it('shouldCorrectlyHandleFailedConnection', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var fs_client = configuration.newClient('mongodb://127.0.0.1:25117/test', {\n        serverSelectionTimeoutMS: 10\n      });\n      fs_client.connect(function (err) {\n        test.ok(err != null);\n        done();\n      });\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyGetErrorDroppingNonExistingDb","suites":["Db"],"updatePoint":{"line":54,"column":50,"index":1661},"line":54,"code":"  it('shouldCorrectlyGetErrorDroppingNonExistingDb', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var _db = client.db('nonexistingdb');\n\n        _db.dropDatabase(function (err, result) {\n          expect(err).to.not.exist;\n          test.equal(true, result);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyThrowWhenTryingToReOpenConnection","suites":["Db"],"line":76,"code":"  it.skip('shouldCorrectlyThrowWhenTryingToReOpenConnection', {","file":"integration/node-specific/db.test.js","skipped":true,"dir":"test"},{"name":"shouldCorrectlyReconnectWhenError","suites":["Db"],"updatePoint":{"line":99,"column":39,"index":2857},"line":99,"code":"  it('shouldCorrectlyReconnectWhenError', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(`mongodb://127.0.0.1:27088/test`, {\n        maxPoolSize: 4,\n        serverSelectionTimeoutMS: 10\n      }); // Establish connection to db\n\n      client.connect(function (err) {\n        test.ok(err != null);\n        client.connect(function (err) {\n          test.ok(err != null);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"should not cut collection name when it is the same as the database","suites":["Db"],"updatePoint":{"line":121,"column":72,"index":3496},"line":121,"code":"  it('should not cut collection name when it is the same as the database', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db1 = client.db('node972');\n        db1.collection('node972.test').insertOne({\n          a: 1\n        }, function (err) {\n          expect(err).to.not.exist;\n          db1.collections(function (err, collections) {\n            expect(err).to.not.exist;\n            collections = collections.map(function (c) {\n              return c.collectionName;\n            });\n            test.notEqual(-1, collections.indexOf('node972.test'));\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUseCursorWithListCollectionsCommand","suites":["Db"],"updatePoint":{"line":151,"column":56,"index":4449},"line":151,"code":"  it('shouldCorrectlyUseCursorWithListCollectionsCommand', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist; // Get a db we that does not have any collections\n\n        var db1 = client.db('shouldCorrectlyUseCursorWithListCollectionsCommand'); // Create a collection\n\n        db1.collection('test').insertOne({\n          a: 1\n        }, function (err) {\n          expect(err).to.not.exist; // Create a collection\n\n          db1.collection('test1').insertOne({\n            a: 1\n          }, function () {\n            expect(err).to.not.exist; // Get listCollections filtering out the name\n\n            var cursor = db1.listCollections({\n              name: 'test1'\n            });\n            cursor.toArray(function (err, names) {\n              expect(err).to.not.exist;\n              test.equal(1, names.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUseCursorWithListCollectionsCommandAndBatchSize","suites":["Db"],"updatePoint":{"line":190,"column":68,"index":5692},"line":190,"code":"  it('shouldCorrectlyUseCursorWithListCollectionsCommandAndBatchSize', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist; // Get a db we that does not have any collections\n\n        var db1 = client.db('shouldCorrectlyUseCursorWithListCollectionsCommandAndBatchSize'); // Create a collection\n\n        db1.collection('test').insertOne({\n          a: 1\n        }, function (err) {\n          expect(err).to.not.exist; // Create a collection\n\n          db1.collection('test1').insertOne({\n            a: 1\n          }, function () {\n            expect(err).to.not.exist; // Get listCollections filtering out the name\n\n            var cursor = db1.listCollections({\n              name: 'test'\n            }, {\n              batchSize: 1\n            });\n            cursor.toArray(function (err, names) {\n              expect(err).to.not.exist;\n              test.equal(1, names.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"should correctly list collection names with . in the middle","suites":["Db"],"updatePoint":{"line":231,"column":65,"index":6987},"line":231,"code":"  it('should correctly list collection names with . in the middle', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist; // Get a db we that does not have any collections\n\n        var db1 = client.db('shouldCorrectlyListCollectionsWithDotsOnThem'); // Create a collection\n\n        db1.collection('test.collection1').insertOne({\n          a: 1\n        }, function (err) {\n          expect(err).to.not.exist; // Create a collection\n\n          db1.collection('test.collection2').insertOne({\n            a: 1\n          }, function () {\n            expect(err).to.not.exist; // Get listCollections filtering out the name\n\n            var cursor = db1.listCollections({\n              name: /test.collection/\n            });\n            cursor.toArray(function (err, names) {\n              expect(err).to.not.exist;\n              test.equal(2, names.length); // Get listCollections filtering out the name\n\n              var cursor = db1.listCollections({\n                name: 'test.collection1'\n              }, {});\n              cursor.toArray(function (err, names) {\n                expect(err).to.not.exist;\n                test.equal(1, names.length);\n                client.close(done);\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"should correctly list collection names with batchSize 1 for 2.8 or higher","suites":["Db"],"updatePoint":{"line":278,"column":79,"index":8587},"line":278,"code":"  it('should correctly list collection names with batchSize 1 for 2.8 or higher', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist; // Get a db we that does not have any collections\n\n        var db1 = client.db('shouldCorrectlyListCollectionsWithDotsOnThemFor28'); // Create a collection\n\n        db1.collection('test.collection1').insertOne({\n          a: 1\n        }, function (err) {\n          expect(err).to.not.exist; // Create a collection\n\n          db1.collection('test.collection2').insertOne({\n            a: 1\n          }, function () {\n            expect(err).to.not.exist; // Get listCollections filtering out the name\n\n            var cursor = db1.listCollections({\n              name: /test.collection/\n            }, {\n              batchSize: 1\n            });\n            cursor.toArray(function (err, names) {\n              expect(err).to.not.exist;\n              test.equal(2, names.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"should throw if Db.collection is passed a deprecated callback argument","suites":["Db"],"updatePoint":{"line":320,"column":76,"index":9943},"line":320,"code":"  it('should throw if Db.collection is passed a deprecated callback argument', withClient((client, done) => {\n    expect(() => client.db('test').collection('test', () => {})).to.throw('The callback form of this helper has been removed.');\n    done();\n  }));","file":"integration/node-specific/db.test.js","skipped":false,"dir":"test"},{"name":"supports simple aggregation","suites":["examples.aggregaton:"],"updatePoint":{"line":21,"column":33,"index":604},"line":21,"code":"  it('supports simple aggregation', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.8.0',\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // Start aggregate example 1\n      const cursor = collection.aggregate([{\n        $match: {\n          'items.fruit': 'banana'\n        }\n      }, {\n        $sort: {\n          date: 1\n        }\n      }]); // End aggregate example 1\n    }\n  });","file":"integration/node-specific/examples/aggregate.test.js","skipped":false,"dir":"test"},{"name":"supports $match, $group, $project, $unwind, $sum, $sort, $dayOfWeek","suites":["examples.aggregaton:"],"updatePoint":{"line":41,"column":73,"index":1066},"line":41,"code":"  it('supports $match, $group, $project, $unwind, $sum, $sort, $dayOfWeek', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.8.0',\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // Start aggregate example 2\n      const cursor = collection.aggregate([{\n        $unwind: '$items'\n      }, {\n        $match: {\n          'items.fruit': 'banana'\n        }\n      }, {\n        $group: {\n          _id: {\n            day: {\n              $dayOfWeek: '$date'\n            }\n          },\n          count: {\n            $sum: '$items.quantity'\n          }\n        }\n      }, {\n        $project: {\n          dayOfWeek: '$_id.day',\n          numberSold: '$count',\n          _id: 0\n        }\n      }, {\n        $sort: {\n          numberSold: 1\n        }\n      }]); // End aggregate example 2\n    }\n  });","file":"integration/node-specific/examples/aggregate.test.js","skipped":false,"dir":"test"},{"name":"supports $unwind, $group, $sum, $dayOfWeek, $multiply, $project, $cond","suites":["examples.aggregaton:"],"updatePoint":{"line":80,"column":76,"index":1900},"line":80,"code":"  it('supports $unwind, $group, $sum, $dayOfWeek, $multiply, $project, $cond', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.8.0',\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // Start aggregate example 3\n      const cursor = collection.aggregate([{\n        $unwind: '$items'\n      }, {\n        $group: {\n          _id: {\n            day: {\n              $dayOfWeek: '$date'\n            }\n          },\n          items_sold: {\n            $sum: '$items.quantity'\n          },\n          revenue: {\n            $sum: {\n              $multiply: ['$items.quantity', '$items.price']\n            }\n          }\n        }\n      }, {\n        $project: {\n          day: '$_id.day',\n          revenue: 1,\n          items_sold: 1,\n          discount: {\n            $cond: {\n              if: {\n                $lte: ['$revenue', 250]\n              },\n              then: 25,\n              else: 0\n            }\n          }\n        }\n      }]); // End aggregate example 3\n    }\n  });","file":"integration/node-specific/examples/aggregate.test.js","skipped":false,"dir":"test"},{"name":"supports $lookup, $filter, $match","suites":["examples.aggregaton:"],"updatePoint":{"line":125,"column":39,"index":2880},"line":125,"code":"  it('supports $lookup, $filter, $match', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.6.0',\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // Start aggregate example 4\n      const cursor = collection.aggregate([{\n        $lookup: {\n          from: 'air_airlines',\n          let: {\n            constituents: '$airlines'\n          },\n          pipeline: [{\n            $match: {\n              $expr: {\n                $in: ['$name', '$$constituents']\n              }\n            }\n          }],\n          as: 'airlines'\n        }\n      }, {\n        $project: {\n          _id: 0,\n          name: 1,\n          airlines: {\n            $filter: {\n              input: '$airlines',\n              as: 'airline',\n              cond: {\n                $eq: ['$$airline.country', 'Canada']\n              }\n            }\n          }\n        }\n      }]); // End aggregate example 4\n    }\n  });","file":"integration/node-specific/examples/aggregate.test.js","skipped":false,"dir":"test"},{"name":"supports array filters when updating","suites":["examples(array filters):"],"updatePoint":{"line":20,"column":42,"index":589},"line":20,"code":"  it('supports array filters when updating', {\n    metadata: {\n      requires: {\n        mongodb: '>=3.6.x',\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // 3. Exploiting the power of arrays\n      await collection.updateOne({\n        _id: 1\n      }, {\n        $set: {\n          'a.$[i].b': 2\n        }\n      }, {\n        arrayFilters: [{\n          'i.b': 0\n        }]\n      });\n    }\n  });","file":"integration/node-specific/examples/array_filters.test.js","skipped":false,"dir":"test"},{"name":"supports causal consistency","suites":["examples(causal-consistency):"],"updatePoint":{"line":28,"column":33,"index":727},"line":28,"code":"  it('supports causal consistency', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>=3.6.0'\n      },\n      sessions: {\n        skipLeakTests: true\n      }\n    },\n    test: async function () {\n      const session = client.startSession({\n        causalConsistency: true\n      });\n      collection.insertOne({\n        darmok: 'jalad'\n      }, {\n        session\n      });\n      collection.updateOne({\n        darmok: 'jalad'\n      }, {\n        $set: {\n          darmok: 'tanagra'\n        }\n      }, {\n        session\n      });\n      const results = await collection.find({}, {\n        session\n      }).toArray();\n      expect(results).to.exist;\n    }\n  });","file":"integration/node-specific/examples/causal_consistency.test.js","skipped":false,"dir":"test"},{"name":"Open A Change Stream","suites":[],"updatePoint":{"line":57,"column":26,"index":1369},"line":57,"code":"  it('Open A Change Stream', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.6.0'\n      }\n    },\n    test: async function () {\n      const looper = new Looper(() => db.collection('inventory').insertOne({\n        a: 1\n      }));\n      looper.run(); // Start Changestream Example 1\n\n      const collection = db.collection('inventory');\n      const changeStream = collection.watch();\n      changeStream.on('change', next => {// process next document\n      }); // End Changestream Example 1\n      // Start Changestream Example 1 Alternative\n\n      const changeStreamIterator = collection.watch();\n      const next = await changeStreamIterator.next(); // End Changestream Example 1 Alternative\n\n      await changeStream.close();\n      await changeStreamIterator.close();\n      await looper.stop();\n      expect(next).to.have.property('operationType').that.equals('insert');\n    }\n  });","file":"integration/node-specific/examples/change_streams.test.js","skipped":false,"dir":"test"},{"name":"Lookup Full Document for Update Operations","suites":[],"updatePoint":{"line":85,"column":48,"index":2316},"line":85,"code":"  it('Lookup Full Document for Update Operations', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.6.0'\n      }\n    },\n    test: async function () {\n      await db.collection('inventory').insertOne({\n        a: 1,\n        b: 2\n      });\n      const looper = new Looper(() => db.collection('inventory').updateOne({\n        a: 1\n      }, {\n        $set: {\n          a: 2\n        }\n      }));\n      looper.run(); // Start Changestream Example 2\n\n      const collection = db.collection('inventory');\n      const changeStream = collection.watch([], {\n        fullDocument: 'updateLookup'\n      });\n      changeStream.on('change', next => {// process next document\n      }); // End Changestream Example 2\n      // Start Changestream Example 2 Alternative\n\n      const changeStreamIterator = collection.watch([], {\n        fullDocument: 'updateLookup'\n      });\n      const next = await changeStreamIterator.next(); // End Changestream Example 2 Alternative\n\n      await changeStream.close();\n      await changeStreamIterator.close();\n      await looper.stop();\n      expect(next).to.have.property('operationType').that.equals('update');\n      expect(next).to.have.property('fullDocument').that.has.all.keys(['_id', 'a', 'b']);\n    }\n  });","file":"integration/node-specific/examples/change_streams.test.js","skipped":false,"dir":"test"},{"name":"Resume a Change Stream","suites":[],"updatePoint":{"line":126,"column":28,"index":3573},"line":126,"code":"  it('Resume a Change Stream', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.6.0'\n      }\n    },\n    test: async function () {\n      const looper = new Looper(async () => {\n        await db.collection('inventory').insertOne({\n          a: 1\n        });\n        await db.collection('inventory').insertOne({\n          b: 2\n        });\n      });\n      looper.run();\n      let processChange;\n      const streamExampleFinished = new Promise(resolve => {\n        processChange = resolve;\n      }); // Start Changestream Example 3\n\n      const collection = db.collection('inventory');\n      const changeStream = collection.watch();\n      let newChangeStream;\n      changeStream.once('change', next => {\n        const resumeToken = changeStream.resumeToken;\n        changeStream.close();\n        newChangeStream = collection.watch([], {\n          resumeAfter: resumeToken\n        });\n        newChangeStream.on('change', next => {\n          processChange(next);\n        });\n      }); // End Changestream Example 3\n      // Start Changestream Example 3 Alternative\n\n      const changeStreamIterator = collection.watch();\n      const change1 = await changeStreamIterator.next();\n      const resumeToken = changeStreamIterator.resumeToken;\n      changeStreamIterator.close();\n      const newChangeStreamIterator = collection.watch([], {\n        resumeAfter: resumeToken\n      });\n      const change2 = await newChangeStreamIterator.next(); // End Changestream Example 3 Alternative\n\n      await newChangeStreamIterator.close();\n      await streamExampleFinished;\n      await newChangeStream.close();\n      await looper.stop();\n      expect(change1).to.have.nested.property('fullDocument.a', 1);\n      expect(change2).to.have.nested.property('fullDocument.b', 2);\n    }\n  });","file":"integration/node-specific/examples/change_streams.test.js","skipped":false,"dir":"test"},{"name":"Modify Change Stream Output","suites":[],"updatePoint":{"line":180,"column":33,"index":5388},"line":180,"code":"  it('Modify Change Stream Output', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.6.0'\n      }\n    },\n    test: async function () {\n      const looper = new Looper(async () => {\n        await db.collection('inventory').insertOne({\n          username: 'alice'\n        });\n      });\n      looper.run(); // Start Changestream Example 4\n\n      const pipeline = [{\n        $match: {\n          'fullDocument.username': 'alice'\n        }\n      }, {\n        $addFields: {\n          newField: 'this is an added field!'\n        }\n      }];\n      const collection = db.collection('inventory');\n      const changeStream = collection.watch(pipeline);\n      changeStream.on('change', next => {// process next document\n      }); // End Changestream Example 4\n      // Start Changestream Example 4 Alternative\n\n      const changeStreamIterator = collection.watch(pipeline);\n      const next = await changeStreamIterator.next(); // End Changestream Example 4 Alternative\n\n      await changeStream.close();\n      await changeStreamIterator.close();\n      await looper.stop();\n      expect(next).to.have.nested.property('fullDocument.username', 'alice');\n      expect(next).to.have.property('newField', 'this is an added field!');\n    }\n  });","file":"integration/node-specific/examples/change_streams.test.js","skipped":false,"dir":"test"},{"name":"supports building simple ascending index","suites":["examples.createIndex:"],"updatePoint":{"line":20,"column":46,"index":584},"line":20,"code":"  it('supports building simple ascending index', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // Start createIndex example 1\n      await collection.createIndex({\n        score: 1\n      }); // End createIndex example 1\n    }\n  });","file":"integration/node-specific/examples/create_index.test.js","skipped":false,"dir":"test"},{"name":"supports building multikey index with partial filter expression","suites":["examples.createIndex:"],"updatePoint":{"line":33,"column":69,"index":908},"line":33,"code":"  it('supports building multikey index with partial filter expression', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>=3.2.x'\n      }\n    },\n    test: async function () {\n      // Start createIndex example 2\n      await collection.createIndex({\n        cuisine: 1,\n        name: 1\n      }, {\n        partialFilterExpression: {\n          rating: {\n            $gt: 5\n          }\n        }\n      }); // End createIndex example 2\n    }\n  });","file":"integration/node-specific/examples/create_index.test.js","skipped":false,"dir":"test"},{"name":"Insert a Single Document","suites":["examples(insert):"],"updatePoint":{"line":23,"column":30,"index":600},"line":23,"code":"  it('Insert a Single Document', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 1\n      await db.collection('inventory').insertOne({\n        item: 'canvas',\n        qty: 100,\n        tags: ['cotton'],\n        size: {\n          h: 28,\n          w: 35.5,\n          uom: 'cm'\n        }\n      }); // End Example 1\n      // Start Example 2\n\n      const cursor = db.collection('inventory').find({\n        item: 'canvas'\n      }); // End Example 2\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/insert.test.js","skipped":false,"dir":"test"},{"name":"Insert Multiple Documents","suites":["examples(insert):"],"updatePoint":{"line":51,"column":31,"index":1218},"line":51,"code":"  it('Insert Multiple Documents', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 3\n      await db.collection('inventory').insertMany([{\n        item: 'journal',\n        qty: 25,\n        tags: ['blank', 'red'],\n        size: {\n          h: 14,\n          w: 21,\n          uom: 'cm'\n        }\n      }, {\n        item: 'mat',\n        qty: 85,\n        tags: ['gray'],\n        size: {\n          h: 27.9,\n          w: 35.5,\n          uom: 'cm'\n        }\n      }, {\n        item: 'mousepad',\n        qty: 25,\n        tags: ['gel', 'blue'],\n        size: {\n          h: 19,\n          w: 22.85,\n          uom: 'cm'\n        }\n      }]); // End Example 3\n\n      expect(await db.collection('inventory').count({})).to.equal(3);\n    }\n  });","file":"integration/node-specific/examples/insert.test.js","skipped":false,"dir":"test"},{"name":"Return All Fields in Matching Documents","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":88,"column":45,"index":1726},"line":88,"code":"  it('Return All Fields in Matching Documents', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 43\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      }); // End Example 43\n\n      expect(await cursor.count()).to.equal(3);\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Return the Specified Fields and the ``_id`` Field Only","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":104,"column":60,"index":2118},"line":104,"code":"  it('Return the Specified Fields and the ``_id`` Field Only', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 44\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      }).project({\n        item: 1,\n        status: 1\n      }); // End Example 44\n\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.all.keys(['_id', 'item', 'status']);\n        expect(doc).to.not.have.all.keys(['size', 'instock']);\n      });\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Suppress ``_id`` Field","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":127,"column":28,"index":2701},"line":127,"code":"  it('Suppress ``_id`` Field', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 45\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      }).project({\n        item: 1,\n        status: 1,\n        _id: 0\n      }); // End Example 45\n\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.all.keys(['item', 'status']);\n        expect(doc).to.not.have.all.keys(['_id', 'size', 'instock']);\n      });\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Return All But the Excluded Fields","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":151,"column":40,"index":3312},"line":151,"code":"  it('Return All But the Excluded Fields', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 46\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      }).project({\n        status: 0,\n        instock: 0\n      }); // End Example 46\n\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.all.keys(['_id', 'item', 'size']);\n        expect(doc).to.not.have.all.keys(['status', 'instock']);\n      });\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Return Specific Fields in Embedded Documents","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":174,"column":50,"index":3920},"line":174,"code":"  it('Return Specific Fields in Embedded Documents', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 47\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      }).project({\n        item: 1,\n        status: 1,\n        'size.uom': 1\n      }); // End Example 47\n\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.all.keys(['_id', 'item', 'status', 'size']);\n        expect(doc).to.not.have.property('instock');\n        const size = doc.size;\n        expect(size).to.have.property('uom');\n        expect(size).to.not.have.all.keys(['h', 'w']);\n      });\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Suppress Specific Fields in Embedded Documents","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":201,"column":52,"index":4680},"line":201,"code":"  it('Suppress Specific Fields in Embedded Documents', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 48\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      }).project({\n        'size.uom': 0\n      }); // End Example 48\n\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.all.keys(['_id', 'item', 'status', 'size', 'instock']);\n        const size = doc.size;\n        expect(size).to.have.all.keys(['h', 'w']);\n        expect(size).to.not.have.property('uom');\n      });\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Projection on Embedded Documents in an Array","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":225,"column":50,"index":5360},"line":225,"code":"  it('Projection on Embedded Documents in an Array', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 49\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      }).project({\n        item: 1,\n        status: 1,\n        'instock.qty': 1\n      }); // End Example 49\n\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.all.keys(['_id', 'item', 'status', 'instock']);\n        expect(doc).to.not.have.property('size');\n        doc.instock.forEach(function (subdoc) {\n          expect(subdoc).to.have.property('qty');\n          expect(subdoc).to.not.have.property('warehouse');\n        });\n      });\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Project Specific Array Elements in the Returned Array","suites":["examples(project-fields-from-query):"],"updatePoint":{"line":253,"column":59,"index":6168},"line":253,"code":"  it('Project Specific Array Elements in the Returned Array', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 50\n      const cursor = db.collection('inventory').find({\n        status: 'A'\n      }).project({\n        item: 1,\n        status: 1,\n        instock: {\n          $slice: -1\n        }\n      }); // End Example 50\n\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.all.keys(['_id', 'item', 'status', 'instock']);\n        expect(doc).to.not.have.property('size');\n        expect(doc).to.have.property('instock').with.a.lengthOf(1);\n      });\n    }\n  });","file":"integration/node-specific/examples/project_fields_from_query_results.test.js","skipped":false,"dir":"test"},{"name":"Query for a Document Nested in an Array","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":67,"column":45,"index":1419},"line":67,"code":"  it('Query for a Document Nested in an Array', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 30\n      const cursor = db.collection('inventory').find({\n        instock: {\n          warehouse: 'A',\n          qty: 5\n        }\n      }); // End Example 30\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"Query for a Document Nested in an Array - document order","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":86,"column":62,"index":1865},"line":86,"code":"  it('Query for a Document Nested in an Array - document order', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 31\n      const cursor = db.collection('inventory').find({\n        instock: {\n          qty: 5,\n          warehouse: 'A'\n        }\n      }); // End Example 31\n\n      expect(await cursor.count()).to.equal(0);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"Use the Array Index to Query for a Field in the Embedded Document","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":105,"column":71,"index":2320},"line":105,"code":"  it('Use the Array Index to Query for a Field in the Embedded Document', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 32\n      const cursor = db.collection('inventory').find({\n        'instock.0.qty': {\n          $lte: 20\n        }\n      }); // End Example 32\n\n      expect(await cursor.count()).to.equal(3);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"Specify a Query Condition on a Field Embedded in an Array of Documents","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":123,"column":76,"index":2764},"line":123,"code":"  it('Specify a Query Condition on a Field Embedded in an Array of Documents', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 33\n      const cursor = db.collection('inventory').find({\n        'instock.qty': {\n          $lte: 20\n        }\n      }); // End Example 33\n\n      expect(await cursor.count()).to.equal(5);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"A Single Nested Document Meets Multiple Query Conditions on Nested Fields","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":141,"column":79,"index":3209},"line":141,"code":"  it('A Single Nested Document Meets Multiple Query Conditions on Nested Fields', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 34\n      const cursor = db.collection('inventory').find({\n        instock: {\n          $elemMatch: {\n            qty: 5,\n            warehouse: 'A'\n          }\n        }\n      }); // End Example 34\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"A Single Nested Document Meets Multiple Query Conditions on Nested Fields: operators","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":162,"column":90,"index":3723},"line":162,"code":"  it('A Single Nested Document Meets Multiple Query Conditions on Nested Fields: operators', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 35\n      const cursor = db.collection('inventory').find({\n        instock: {\n          $elemMatch: {\n            qty: {\n              $gt: 10,\n              $lte: 20\n            }\n          }\n        }\n      }); // End Example 35\n\n      expect(await cursor.count()).to.equal(3);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"Combination of Elements Satisfies the Criteria","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":185,"column":52,"index":4231},"line":185,"code":"  it('Combination of Elements Satisfies the Criteria', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 36\n      const cursor = db.collection('inventory').find({\n        'instock.qty': {\n          $gt: 10,\n          $lte: 20\n        }\n      }); // End Example 36\n\n      expect(await cursor.count()).to.equal(4);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"Combination of Elements Satisfies the Criteria 2","suites":["examples(query-array-of-documents):"],"updatePoint":{"line":204,"column":54,"index":4670},"line":204,"code":"  it('Combination of Elements Satisfies the Criteria 2', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 37\n      const cursor = db.collection('inventory').find({\n        'instock.qty': 5,\n        'instock.warehouse': 'A'\n      }); // End Example 37\n\n      expect(await cursor.count()).to.equal(2);\n    }\n  });","file":"integration/node-specific/examples/query_array_of_documents.test.js","skipped":false,"dir":"test"},{"name":"Match an Array","suites":["examples(query-arrays):"],"updatePoint":{"line":50,"column":20,"index":1194},"line":50,"code":"  it('Match an Array', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 21\n      const cursor = db.collection('inventory').find({\n        tags: ['red', 'blank']\n      }); // End Example 21\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Match an Array: $all","suites":["examples(query-arrays):"],"updatePoint":{"line":66,"column":26,"index":1563},"line":66,"code":"  it('Match an Array: $all', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 22\n      const cursor = db.collection('inventory').find({\n        tags: {\n          $all: ['red', 'blank']\n        }\n      }); // End Example 22\n\n      expect(await cursor.count()).to.equal(4);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Query an Array for an Element","suites":["examples(query-arrays):"],"updatePoint":{"line":84,"column":35,"index":1969},"line":84,"code":"  it('Query an Array for an Element', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 23\n      const cursor = db.collection('inventory').find({\n        tags: 'red'\n      }); // End Example 23\n\n      expect(await cursor.count()).to.equal(4);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Query an Array for an Element w/ operators","suites":["examples(query-arrays):"],"updatePoint":{"line":100,"column":48,"index":2349},"line":100,"code":"  it('Query an Array for an Element w/ operators', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 24\n      const cursor = db.collection('inventory').find({\n        dim_cm: {\n          $gt: 25\n        }\n      }); // End Example 24\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Query an Array with Compound Filter Conditions on the Array Elements","suites":["examples(query-arrays):"],"updatePoint":{"line":118,"column":74,"index":2781},"line":118,"code":"  it('Query an Array with Compound Filter Conditions on the Array Elements', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 25\n      const cursor = db.collection('inventory').find({\n        dim_cm: {\n          $gt: 15,\n          $lt: 20\n        }\n      }); // End Example 25\n\n      expect(await cursor.count()).to.equal(4);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Query for an Array Element that Meets Multiple Criteria","suites":["examples(query-arrays):"],"updatePoint":{"line":137,"column":61,"index":3219},"line":137,"code":"  it('Query for an Array Element that Meets Multiple Criteria', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 26\n      const cursor = db.collection('inventory').find({\n        dim_cm: {\n          $elemMatch: {\n            $gt: 22,\n            $lt: 30\n          }\n        }\n      }); // End Example 26\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Query for an Element by the Array Index Position","suites":["examples(query-arrays):"],"updatePoint":{"line":158,"column":54,"index":3690},"line":158,"code":"  it('Query for an Element by the Array Index Position', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 27\n      const cursor = db.collection('inventory').find({\n        'dim_cm.1': {\n          $gt: 25\n        }\n      }); // End Example 27\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Query an Array by Array Length","suites":["examples(query-arrays):"],"updatePoint":{"line":176,"column":36,"index":4088},"line":176,"code":"  it('Query an Array by Array Length', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 28\n      const cursor = db.collection('inventory').find({\n        tags: {\n          $size: 3\n        }\n      }); // End Example 28\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_arrays.test.js","skipped":false,"dir":"test"},{"name":"Match an Embedded/Nested Document","suites":["examples(query-embedded-documents):"],"updatePoint":{"line":70,"column":39,"index":1406},"line":70,"code":"  it('Match an Embedded/Nested Document', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 15\n      const cursor = db.collection('inventory').find({\n        size: {\n          h: 14,\n          w: 21,\n          uom: 'cm'\n        }\n      }); // End Example 15\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_embedded_documents.test.js","skipped":false,"dir":"test"},{"name":"Match an Embedded/Nested Document - document order","suites":["examples(query-embedded-documents):"],"updatePoint":{"line":90,"column":56,"index":1854},"line":90,"code":"  it('Match an Embedded/Nested Document - document order', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 16\n      const cursor = db.collection('inventory').find({\n        size: {\n          w: 21,\n          h: 14,\n          uom: 'cm'\n        }\n      }); // End Example 16\n\n      expect(await cursor.count()).to.equal(0);\n    }\n  });","file":"integration/node-specific/examples/query_embedded_documents.test.js","skipped":false,"dir":"test"},{"name":"Specify Equality Match on a Nested Field","suites":["examples(query-embedded-documents):"],"updatePoint":{"line":110,"column":46,"index":2292},"line":110,"code":"  it('Specify Equality Match on a Nested Field', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 17\n      const cursor = db.collection('inventory').find({\n        'size.uom': 'in'\n      }); // End Example 17\n\n      expect(await cursor.count()).to.equal(2);\n    }\n  });","file":"integration/node-specific/examples/query_embedded_documents.test.js","skipped":false,"dir":"test"},{"name":"Specify Match using Query Operator","suites":["examples(query-embedded-documents):"],"updatePoint":{"line":126,"column":40,"index":2669},"line":126,"code":"  it('Specify Match using Query Operator', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 18\n      const cursor = db.collection('inventory').find({\n        'size.h': {\n          $lt: 15\n        }\n      }); // End Example 18\n\n      expect(await cursor.count()).to.equal(4);\n    }\n  });","file":"integration/node-specific/examples/query_embedded_documents.test.js","skipped":false,"dir":"test"},{"name":"Specify ``AND`` Condition","suites":["examples(query-embedded-documents):"],"updatePoint":{"line":144,"column":31,"index":3060},"line":144,"code":"  it('Specify ``AND`` Condition', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 19\n      const cursor = db.collection('inventory').find({\n        'size.h': {\n          $lt: 15\n        },\n        'size.uom': 'in',\n        status: 'D'\n      }); // End Example 19\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_embedded_documents.test.js","skipped":false,"dir":"test"},{"name":"Equality Filter","suites":["examples(query-for-null-fields):"],"updatePoint":{"line":30,"column":21,"index":758},"line":30,"code":"  it('Equality Filter', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 39\n      const cursor = db.collection('inventory').find({\n        item: null\n      }); // End Example 39\n\n      expect(await cursor.count()).to.equal(2);\n    }\n  });","file":"integration/node-specific/examples/query_for_null_fields.test.js","skipped":false,"dir":"test"},{"name":"Type Check","suites":["examples(query-for-null-fields):"],"updatePoint":{"line":46,"column":16,"index":1105},"line":46,"code":"  it('Type Check', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 40\n      const cursor = db.collection('inventory').find({\n        item: {\n          $type: 10\n        }\n      }); // End Example 40\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_for_null_fields.test.js","skipped":false,"dir":"test"},{"name":"Existence Check","suites":["examples(query-for-null-fields):"],"updatePoint":{"line":64,"column":21,"index":1484},"line":64,"code":"  it('Existence Check', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 41\n      const cursor = db.collection('inventory').find({\n        item: {\n          $exists: false\n        }\n      }); // End Example 41\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query_for_null_fields.test.js","skipped":false,"dir":"test"},{"name":"select all documents in a collection","suites":["examples(query):"],"updatePoint":{"line":70,"column":42,"index":1388},"line":70,"code":"  it('select all documents in a collection', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 7\n      const cursor = db.collection('inventory').find({}); // End Example 7\n\n      expect(await cursor.count()).to.equal(5);\n    }\n  });","file":"integration/node-specific/examples/query.test.js","skipped":false,"dir":"test"},{"name":"Specify Equality Condition","suites":["examples(query):"],"updatePoint":{"line":84,"column":32,"index":1723},"line":84,"code":"  it('Specify Equality Condition', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 9\n      const cursor = db.collection('inventory').find({\n        status: 'D'\n      }); // End Example 9\n\n      expect(await cursor.count()).to.equal(2);\n    }\n  });","file":"integration/node-specific/examples/query.test.js","skipped":false,"dir":"test"},{"name":"Specify Conditions Using Query Operators","suites":["examples(query):"],"updatePoint":{"line":100,"column":46,"index":2099},"line":100,"code":"  it('Specify Conditions Using Query Operators', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 10\n      const cursor = db.collection('inventory').find({\n        status: {\n          $in: ['A', 'D']\n        }\n      }); // End Example 10\n\n      expect(await cursor.count()).to.equal(5);\n    }\n  });","file":"integration/node-specific/examples/query.test.js","skipped":false,"dir":"test"},{"name":"Specify ``AND`` Condition","suites":["examples(query):"],"updatePoint":{"line":118,"column":31,"index":2496},"line":118,"code":"  it('Specify ``AND`` Condition', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 11\n      const cursor = db.collection('inventory').find({\n        status: 'A',\n        qty: {\n          $lt: 30\n        }\n      }); // End Example 11\n\n      expect(await cursor.count()).to.equal(1);\n    }\n  });","file":"integration/node-specific/examples/query.test.js","skipped":false,"dir":"test"},{"name":"Specify ``OR`` Condition","suites":["examples(query):"],"updatePoint":{"line":137,"column":30,"index":2902},"line":137,"code":"  it('Specify ``OR`` Condition', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 12\n      const cursor = db.collection('inventory').find({\n        $or: [{\n          status: 'A'\n        }, {\n          qty: {\n            $lt: 30\n          }\n        }]\n      }); // End Example 12\n\n      expect(await cursor.count()).to.equal(3);\n    }\n  });","file":"integration/node-specific/examples/query.test.js","skipped":false,"dir":"test"},{"name":"Specify ``AND`` as well as ``OR`` Conditions","suites":["examples(query):"],"updatePoint":{"line":159,"column":50,"index":3375},"line":159,"code":"  it('Specify ``AND`` as well as ``OR`` Conditions', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 13\n      const cursor = db.collection('inventory').find({\n        status: 'A',\n        $or: [{\n          qty: {\n            $lt: 30\n          }\n        }, {\n          item: {\n            $regex: '^p'\n          }\n        }]\n      }); // End Example 13\n\n      expect(await cursor.count()).to.equal(2);\n    }\n  });","file":"integration/node-specific/examples/query.test.js","skipped":false,"dir":"test"},{"name":"Delete All Documents","suites":["examples(remove-documents):"],"updatePoint":{"line":70,"column":26,"index":1385},"line":70,"code":"  it('Delete All Documents', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 56\n      await db.collection('inventory').deleteMany({}); // End Example 56\n\n      const cursor = db.collection('inventory').find({});\n      expect(await cursor.count()).to.equal(0);\n    }\n  });","file":"integration/node-specific/examples/remove_documents.test.js","skipped":false,"dir":"test"},{"name":"Delete All Documents that Match a Condition","suites":["examples(remove-documents):"],"updatePoint":{"line":85,"column":49,"index":1794},"line":85,"code":"  it('Delete All Documents that Match a Condition', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 57\n      await db.collection('inventory').deleteMany({\n        status: 'A'\n      }); // End Example 57\n\n      const cursor = db.collection('inventory').find({});\n      expect(await cursor.count()).to.equal(3);\n    }\n  });","file":"integration/node-specific/examples/remove_documents.test.js","skipped":false,"dir":"test"},{"name":"Delete Only One Document that Matches a Condition","suites":["examples(remove-documents):"],"updatePoint":{"line":102,"column":55,"index":2236},"line":102,"code":"  it('Delete Only One Document that Matches a Condition', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 58\n      await db.collection('inventory').deleteOne({\n        status: 'D'\n      }); // End Example 58\n\n      const cursor = db.collection('inventory').find({});\n      expect(await cursor.count()).to.equal(4);\n    }\n  });","file":"integration/node-specific/examples/remove_documents.test.js","skipped":false,"dir":"test"},{"name":"supports runCommand 1","suites":["examples.runCommand:"],"updatePoint":{"line":22,"column":27,"index":604},"line":22,"code":"  it('supports runCommand 1', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // Start runCommand example 1\n      await db.command({\n        buildInfo: 1\n      }); // End runCommand example 1\n    }\n  });","file":"integration/node-specific/examples/run_command.test.js","skipped":false,"dir":"test"},{"name":"supports runCommand 2","suites":["examples.runCommand:"],"updatePoint":{"line":35,"column":27,"index":876},"line":35,"code":"  it('supports runCommand 2', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: async function () {\n      // Start runCommand example 2\n      await db.command({\n        collStats: 'restaurants'\n      }); // End runCommand example 2\n    }\n  });","file":"integration/node-specific/examples/run_command.test.js","skipped":false,"dir":"test"},{"name":"Transactions Retry Example 1","suites":["examples(transactions):"],"updatePoint":{"line":31,"column":34,"index":849},"line":31,"code":"  it('Transactions Retry Example 1', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.8.0'\n      }\n    },\n    test: async function () {\n      // Start Transactions Retry Example 1\n      async function runTransactionWithRetry(txnFunc, client, session) {\n        try {\n          await txnFunc(client, session);\n        } catch (error) {\n          console.log('Transaction aborted. Caught exception during transaction.'); // If transient error, retry the whole transaction\n\n          if (error.hasErrorLabel('TransientTransactionError')) {\n            console.log('TransientTransactionError, retrying transaction ...');\n            await runTransactionWithRetry(txnFunc, client, session);\n          } else {\n            throw error;\n          }\n        }\n      } // End Transactions Retry Example 1\n\n\n      async function updateEmployeeInfo(client, session) {\n        session.startTransaction({\n          readConcern: {\n            level: 'snapshot'\n          },\n          writeConcern: {\n            w: 'majority'\n          },\n          readPreference: 'primary'\n        });\n        const employeesCollection = client.db('hr').collection('employees');\n        const eventsCollection = client.db('reporting').collection('events');\n        await employeesCollection.updateOne({\n          employee: 3\n        }, {\n          $set: {\n            status: 'Inactive'\n          }\n        }, {\n          session\n        });\n        await eventsCollection.insertOne({\n          employee: 3,\n          status: {\n            new: 'Inactive',\n            old: 'Active'\n          }\n        }, {\n          session\n        });\n\n        try {\n          await session.commitTransaction();\n        } catch (error) {\n          await session.abortTransaction();\n          throw error;\n        }\n      }\n\n      return client.withSession(session => runTransactionWithRetry(updateEmployeeInfo, client, session));\n    }\n  });","file":"integration/node-specific/examples/transactions.test.js","skipped":false,"dir":"test"},{"name":"Transactions Retry Example 2","suites":["examples(transactions):"],"updatePoint":{"line":98,"column":34,"index":2791},"line":98,"code":"  it('Transactions Retry Example 2', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.8.0'\n      }\n    },\n    test: async function () {\n      // Start Transactions Retry Example 2\n      async function commitWithRetry(session) {\n        try {\n          await session.commitTransaction();\n          console.log('Transaction committed.');\n        } catch (error) {\n          if (error.hasErrorLabel('UnknownTransactionCommitResult')) {\n            console.log('UnknownTransactionCommitResult, retrying commit operation ...');\n            await commitWithRetry(session);\n          } else {\n            console.log('Error during commit ...');\n            throw error;\n          }\n        }\n      } // End Transactions Retry Example 2\n\n\n      async function updateEmployeeInfo(client, session) {\n        session.startTransaction({\n          readConcern: {\n            level: 'snapshot'\n          },\n          writeConcern: {\n            w: 'majority'\n          },\n          readPreference: 'primary'\n        });\n        const employeesCollection = client.db('hr').collection('employees');\n        const eventsCollection = client.db('reporting').collection('events');\n        await employeesCollection.updateOne({\n          employee: 3\n        }, {\n          $set: {\n            status: 'Inactive'\n          }\n        }, {\n          session\n        });\n        await eventsCollection.insertOne({\n          employee: 3,\n          status: {\n            new: 'Inactive',\n            old: 'Active'\n          }\n        }, {\n          session\n        });\n\n        try {\n          await commitWithRetry(session);\n        } catch (error) {\n          await session.abortTransaction();\n          throw error;\n        }\n      }\n\n      return client.withSession(session => updateEmployeeInfo(client, session));\n    }\n  });","file":"integration/node-specific/examples/transactions.test.js","skipped":false,"dir":"test"},{"name":"Transaction Retry Example 3","suites":["examples(transactions):"],"updatePoint":{"line":165,"column":33,"index":4637},"line":165,"code":"  it('Transaction Retry Example 3', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.8.0'\n      }\n    },\n    test: async function () {\n      // Start Transactions Retry Example 3\n      async function commitWithRetry(session) {\n        try {\n          await session.commitTransaction();\n          console.log('Transaction committed.');\n        } catch (error) {\n          if (error.hasErrorLabel('UnknownTransactionCommitResult')) {\n            console.log('UnknownTransactionCommitResult, retrying commit operation ...');\n            await commitWithRetry(session);\n          } else {\n            console.log('Error during commit ...');\n            throw error;\n          }\n        }\n      }\n\n      async function runTransactionWithRetry(txnFunc, client, session) {\n        try {\n          await txnFunc(client, session);\n        } catch (error) {\n          console.log('Transaction aborted. Caught exception during transaction.'); // If transient error, retry the whole transaction\n\n          if (error.hasErrorLabel('TransientTransactionError')) {\n            console.log('TransientTransactionError, retrying transaction ...');\n            await runTransactionWithRetry(txnFunc, client, session);\n          } else {\n            throw error;\n          }\n        }\n      }\n\n      async function updateEmployeeInfo(client, session) {\n        session.startTransaction({\n          readConcern: {\n            level: 'snapshot'\n          },\n          writeConcern: {\n            w: 'majority'\n          },\n          readPreference: 'primary'\n        });\n        const employeesCollection = client.db('hr').collection('employees');\n        const eventsCollection = client.db('reporting').collection('events');\n        await employeesCollection.updateOne({\n          employee: 3\n        }, {\n          $set: {\n            status: 'Inactive'\n          }\n        }, {\n          session\n        });\n        await eventsCollection.insertOne({\n          employee: 3,\n          status: {\n            new: 'Inactive',\n            old: 'Active'\n          }\n        }, {\n          session\n        });\n\n        try {\n          await commitWithRetry(session);\n        } catch (error) {\n          await session.abortTransaction();\n          throw error;\n        }\n      }\n\n      return client.withSession(session => runTransactionWithRetry(updateEmployeeInfo, client, session)); // End Transactions Retry Example 3\n    }\n  });","file":"integration/node-specific/examples/transactions.test.js","skipped":false,"dir":"test"},{"name":"Transactions withTransaction API Example 1","suites":["examples(transactions):"],"updatePoint":{"line":246,"column":48,"index":7103},"line":246,"code":"  it('Transactions withTransaction API Example 1', {\n    metadata: {\n      requires: {\n        topology: ['replicaset'],\n        mongodb: '>=3.8.0'\n      }\n    },\n    test: async function () {\n      const uri = this.configuration.url(); // Start Transactions withTxn API Example 1\n      // For a replica set, include the replica set name and a seedlist of the members in the URI string; e.g.\n      // const uri = 'mongodb://mongodb0.example.com:27017,mongodb1.example.com:27017/?replicaSet=myRepl'\n      // For a sharded cluster, connect to the mongos instances; e.g.\n      // const uri = 'mongodb://mongos0.example.com:27017,mongos1.example.com:27017/'\n\n      const client = new MongoClient(uri);\n      await client.connect(); // Prereq: Create collections.\n\n      await client.db('mydb1').collection('foo').insertOne({\n        abc: 0\n      }, {\n        writeConcern: {\n          w: 'majority'\n        }\n      });\n      await client.db('mydb2').collection('bar').insertOne({\n        xyz: 0\n      }, {\n        writeConcern: {\n          w: 'majority'\n        }\n      }); // Step 1: Start a Client Session\n\n      const session = client.startSession(); // Step 2: Optional. Define options to use for the transaction\n\n      const transactionOptions = {\n        readPreference: 'primary',\n        readConcern: {\n          level: 'local'\n        },\n        writeConcern: {\n          w: 'majority'\n        }\n      }; // Step 3: Use withTransaction to start a transaction, execute the callback, and commit (or abort on error)\n      // Note: The callback for withTransaction MUST be async and/or return a Promise.\n\n      try {\n        await session.withTransaction(async () => {\n          const coll1 = client.db('mydb1').collection('foo');\n          const coll2 = client.db('mydb2').collection('bar'); // Important:: You must pass the session to the operations\n\n          await coll1.insertOne({\n            abc: 1\n          }, {\n            session\n          });\n          await coll2.insertOne({\n            xyz: 999\n          }, {\n            session\n          });\n        }, transactionOptions);\n      } finally {\n        await session.endSession();\n        await client.close();\n      } // End Transactions withTxn API Example 1\n\n    }\n  });","file":"integration/node-specific/examples/transactions.test.js","skipped":false,"dir":"test"},{"name":"Update a Single Document","suites":["examples(update-documents):"],"updatePoint":{"line":115,"column":30,"index":2086},"line":115,"code":"  it('Update a Single Document', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 52\n      await db.collection('inventory').updateOne({\n        item: 'paper'\n      }, {\n        $set: {\n          'size.uom': 'cm',\n          status: 'P'\n        },\n        $currentDate: {\n          lastModified: true\n        }\n      }); // End Example 52\n\n      const cursor = db.collection('inventory').find({\n        item: 'paper'\n      });\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.nested.property('size.uom').that.equals('cm');\n        expect(doc).to.have.property('status').that.equals('P');\n        expect(doc).to.have.property('lastModified');\n      });\n    }\n  });","file":"integration/node-specific/examples/update_documents.test.js","skipped":false,"dir":"test"},{"name":"Update Multiple Documents","suites":["examples(update-documents):"],"updatePoint":{"line":147,"column":31,"index":2920},"line":147,"code":"  it('Update Multiple Documents', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 53\n      await db.collection('inventory').updateMany({\n        qty: {\n          $lt: 50\n        }\n      }, {\n        $set: {\n          'size.uom': 'in',\n          status: 'P'\n        },\n        $currentDate: {\n          lastModified: true\n        }\n      }); // End Example 53\n\n      const cursor = db.collection('inventory').find({\n        qty: {\n          $lt: 50\n        }\n      });\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(doc).to.have.nested.property('size.uom').that.equals('in');\n        expect(doc).to.have.property('status').that.equals('P');\n        expect(doc).to.have.property('lastModified');\n      });\n    }\n  });","file":"integration/node-specific/examples/update_documents.test.js","skipped":false,"dir":"test"},{"name":"Replace a Document","suites":["examples(update-documents):"],"updatePoint":{"line":183,"column":24,"index":3790},"line":183,"code":"  it('Replace a Document', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        mongodb: '>= 2.8.0'\n      }\n    },\n    test: async function () {\n      // Start Example 54\n      await db.collection('inventory').replaceOne({\n        item: 'paper'\n      }, {\n        item: 'paper',\n        instock: [{\n          warehouse: 'A',\n          qty: 60\n        }, {\n          warehouse: 'B',\n          qty: 40\n        }]\n      }); // End Example 54\n\n      const cursor = db.collection('inventory').find({\n        item: 'paper'\n      }).project({\n        _id: 0\n      });\n      const docs = await cursor.toArray();\n      docs.forEach(function (doc) {\n        expect(Object.keys(doc)).to.have.a.lengthOf(2);\n        expect(doc).to.have.property('item');\n        expect(doc).to.have.property('instock').that.has.a.lengthOf(2);\n      });\n    }\n  });","file":"integration/node-specific/examples/update_documents.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformMapReduceWithStringFunctions","suites":["MapReduce"],"updatePoint":{"line":24,"column":47,"index":383},"line":24,"code":"  it('shouldPerformMapReduceWithStringFunctions', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_map_reduce', function (err, collection) {\n          collection.insert([{\n            user_id: 1\n          }, {\n            user_id: 2\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // String functions\n\n            var map = 'function() { emit(this.user_id, 1); }';\n            var reduce = 'function(k,vals) { return 1; }';\n            collection.mapReduce(map, reduce, {\n              out: {\n                replace: 'tempCollection'\n              }\n            }, function (err, collection) {\n              collection.findOne({\n                _id: 1\n              }, function (err, result) {\n                test.equal(1, result.value);\n                collection.findOne({\n                  _id: 2\n                }, function (err, result) {\n                  test.equal(1, result.value);\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/mapreduce.test.js","skipped":false,"dir":"test"},{"name":"shouldForceMapReduceError","suites":["MapReduce"],"updatePoint":{"line":73,"column":31,"index":1855},"line":73,"code":"  it('shouldForceMapReduceError', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>1.7.6',\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(configuration.db);\n        db.createCollection('should_force_map_reduce_error', function (err, collection) {\n          collection.insert([{\n            user_id: 1\n          }, {\n            user_id: 2\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // String functions\n\n            var map = 'function() { emiddft(this.user_id, 1); }';\n            var reduce = 'function(k,vals) { return 1; }';\n            collection.mapReduce(map, reduce, {\n              out: {\n                inline: 1\n              }\n            }, function (err) {\n              test.ok(err != null);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/mapreduce.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformMapReduceWithParametersBeingFunctions","suites":["MapReduce"],"updatePoint":{"line":113,"column":56,"index":3195},"line":113,"code":"  it('shouldPerformMapReduceWithParametersBeingFunctions', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_map_reduce_with_functions_as_arguments', function (err, collection) {\n          expect(err).to.not.exist;\n          collection.insert([{\n            user_id: 1\n          }, {\n            user_id: 2\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // String functions\n\n            var map = function () {\n              emit(this.user_id, 1); // eslint-disable-line\n            };\n\n            var reduce = function () {\n              return 1;\n            };\n\n            collection.mapReduce(map, reduce, {\n              out: {\n                replace: 'tempCollection'\n              }\n            }, function (err, collection) {\n              collection.findOne({\n                _id: 1\n              }, function (err, result) {\n                test.equal(1, result.value);\n                collection.findOne({\n                  _id: 2\n                }, function (err, result) {\n                  test.equal(1, result.value);\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/mapreduce.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformMapReduceWithCodeObjects","suites":["MapReduce"],"updatePoint":{"line":165,"column":43,"index":4778},"line":165,"code":"  it('shouldPerformMapReduceWithCodeObjects', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_map_reduce_with_code_objects', function (err, collection) {\n          collection.insert([{\n            user_id: 1\n          }, {\n            user_id: 2\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // String functions\n\n            var map = new Code('function() { emit(this.user_id, 1); }');\n            var reduce = new Code('function(k,vals) { return 1; }');\n            collection.mapReduce(map, reduce, {\n              out: {\n                replace: 'tempCollection'\n              }\n            }, function (err, collection) {\n              collection.findOne({\n                _id: 1\n              }, function (err, result) {\n                test.equal(1, result.value);\n                collection.findOne({\n                  _id: 2\n                }, function (err, result) {\n                  test.equal(1, result.value);\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/mapreduce.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformMapReduceWithOptions","suites":["MapReduce"],"updatePoint":{"line":210,"column":39,"index":6262},"line":210,"code":"  it('shouldPerformMapReduceWithOptions', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_map_reduce_with_options', function (err, collection) {\n          collection.insert([{\n            user_id: 1\n          }, {\n            user_id: 2\n          }, {\n            user_id: 3\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // String functions\n\n            var map = new Code('function() { emit(this.user_id, 1); }');\n            var reduce = new Code('function(k,vals) { return 1; }');\n            collection.mapReduce(map, reduce, {\n              out: {\n                replace: 'tempCollection'\n              },\n              query: {\n                user_id: {\n                  $gt: 1\n                }\n              }\n            }, function (err, collection) {\n              collection.count(function (err, count) {\n                test.equal(2, count);\n                collection.findOne({\n                  _id: 2\n                }, function (err, result) {\n                  test.equal(1, result.value);\n                  collection.findOne({\n                    _id: 3\n                  }, function (err, result) {\n                    test.equal(1, result.value);\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/mapreduce.test.js","skipped":false,"dir":"test"},{"name":"shouldHandleMapReduceErrors","suites":["MapReduce"],"updatePoint":{"line":265,"column":33,"index":8016},"line":265,"code":"  it('shouldHandleMapReduceErrors', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        db.createCollection('test_map_reduce_error', function (err, collection) {\n          collection.insert([{\n            user_id: 1\n          }, {\n            user_id: 2\n          }, {\n            user_id: 3\n          }], configuration.writeConcernMax(), function (err) {\n            expect(err).to.not.exist; // String functions\n\n            var map = new Code(\"function() { throw 'error'; }\");\n            var reduce = new Code(\"function(k,vals) { throw 'error'; }\");\n            collection.mapReduce(map, reduce, {\n              out: {\n                inline: 1\n              },\n              query: {\n                user_id: {\n                  $gt: 1\n                }\n              }\n            }, function (err) {\n              test.ok(err != null);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/mapreduce.test.js","skipped":false,"dir":"test"},{"name":"shouldSaveDataToDifferentDbFromMapreduce","suites":["MapReduce"],"updatePoint":{"line":308,"column":46,"index":9308},"line":308,"code":"  it('shouldSaveDataToDifferentDbFromMapreduce', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded'],\n        mongodb: '>= 3.4'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        const outDb = client.db('outputCollectionDb'); // Create a test collection\n\n        db.createCollection('test_map_reduce_functions', function (err, collection) {\n          // create the output collection\n          outDb.createCollection('tempCollection', err => {\n            expect(err).to.not.exist; // Insert some documents to perform map reduce over\n\n            collection.insert([{\n              user_id: 1\n            }, {\n              user_id: 2\n            }], configuration.writeConcernMax(), function (err) {\n              expect(err).to.not.exist; // Map function\n\n              var map = function () {\n                emit(this.user_id, 1); // eslint-disable-line\n              }; // Reduce function\n\n\n              var reduce = function () {\n                return 1;\n              }; // Perform the map reduce\n\n\n              collection.mapReduce(map, reduce, {\n                out: {\n                  replace: 'test_map_reduce_functions_temp',\n                  db: 'outputCollectionDb'\n                }\n              }, function (err, collection) {\n                expect(err).to.not.exist; // Mapreduce returns the temporary collection with the results\n\n                collection.findOne({\n                  _id: 1\n                }, function (err, result) {\n                  expect(err).to.not.exist;\n                  test.equal(1, result.value);\n                  collection.findOne({\n                    _id: 2\n                  }, function (err, result) {\n                    expect(err).to.not.exist;\n                    test.equal(1, result.value);\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/mapreduce.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformMapReduceWithScopeContainingFunction","suites":["MapReduce"],"line":378,"code":"  it.skip('shouldPerformMapReduceWithScopeContainingFunction', {","file":"integration/node-specific/mapreduce.test.js","skipped":true,"dir":"test"},{"name":"should correctly pass through extra db options","suites":["class MongoClient"],"updatePoint":{"line":15,"column":52,"index":677},"line":15,"code":"  it('should correctly pass through extra db options', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient({}, {\n        writeConcern: {\n          w: 1,\n          wtimeoutMS: 1000,\n          fsync: true,\n          j: true\n        },\n        readPreference: 'nearest',\n        readPreferenceTags: {\n          loc: 'ny'\n        },\n        forceServerObjectId: true,\n        pkFactory: {\n          createPk() {\n            return 1;\n          }\n\n        },\n        serializeFunctions: true\n      });\n      client.connect(function (err, client) {\n        expect(err).to.be.undefined;\n        const db = client.db(configuration.db);\n        expect(db).to.have.property('writeConcern');\n        expect(db.writeConcern).to.have.property('w', 1);\n        expect(db.writeConcern).to.have.property('wtimeout', 1000);\n        expect(db.writeConcern).to.have.property('fsync', true);\n        expect(db.writeConcern).to.have.property('j', true);\n        expect(db).to.have.property('s');\n        expect(db.s).to.have.property('readPreference');\n        expect(db.s.readPreference).to.have.property('mode', 'nearest');\n        expect(db.s.readPreference).to.have.property('tags').that.deep.equals([{\n          loc: 'ny'\n        }]);\n        expect(db.s).to.have.nested.property('options.forceServerObjectId');\n        expect(db.s.options).to.have.property('forceServerObjectId', true);\n        expect(db.s).to.have.nested.property('pkFactory.createPk').that.is.a('function');\n        expect(db.s.pkFactory.createPk()).to.equal(1);\n        expect(db).to.have.nested.property('bsonOptions.serializeFunctions');\n        client.close(done);\n      });\n    }\n  });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"Should fail due to wrong uri user:password@localhost","suites":["class MongoClient"],"updatePoint":{"line":66,"column":58,"index":2477},"line":66,"code":"  it('Should fail due to wrong uri user:password@localhost', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n\n    test() {\n      expect(() => this.configuration.newClient('user:password@localhost:27017/test')).to.throw('Invalid scheme, expected connection string to start with \"mongodb://\" or \"mongodb+srv://\"');\n    }\n\n  });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"correctly error out when no socket available on MongoClient `connect`","suites":["class MongoClient"],"updatePoint":{"line":78,"column":75,"index":2877},"line":78,"code":"  it('correctly error out when no socket available on MongoClient `connect`', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient('mongodb://localhost:27088/test', {\n        serverSelectionTimeoutMS: 10\n      });\n      client.connect(function (err) {\n        expect(err).to.exist;\n        done();\n      });\n    }\n  });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"should correctly connect to mongodb using domain socket","suites":["class MongoClient"],"updatePoint":{"line":95,"column":61,"index":3356},"line":95,"code":"  it('should correctly connect to mongodb using domain socket', {\n    metadata: {\n      requires: {\n        topology: ['single'],\n        os: '!win32'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient('mongodb://%2Ftmp%2Fmongodb-27017.sock/test');\n      client.connect(function (err) {\n        expect(err).to.not.exist;\n        client.close(done);\n      });\n    }\n  });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"should fail to connect due to unknown host in connection string","suites":["class MongoClient"],"updatePoint":{"line":111,"column":69,"index":3820},"line":111,"code":"  it('should fail to connect due to unknown host in connection string', async function () {\n    const configuration = this.configuration;\n    const client = configuration.newClient('mongodb://iLoveJavascript:36363/ddddd', {\n      serverSelectionTimeoutMS: 10\n    });\n    const error = await client.connect().catch(error => error);\n    expect(error).to.be.instanceOf(MongoServerSelectionError);\n  });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly pass through appname","suites":["class MongoClient"],"updatePoint":{"line":119,"column":43,"index":4194},"line":119,"code":"  it('Should correctly pass through appname', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const options = {\n        appName: 'hello world'\n      };\n      const client = configuration.newClient(options);\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        expect(client).to.have.nested.property('topology.clientMetadata.application.name').to.equal('hello world');\n        client.close(done);\n      });\n    }\n  });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly pass through appname in options","suites":["class MongoClient"],"updatePoint":{"line":138,"column":54,"index":4797},"line":138,"code":"  it('Should correctly pass through appname in options', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const url = configuration.url();\n      const client = configuration.newClient(url, {\n        appname: 'hello world'\n      });\n      client.connect(err => {\n        expect(err).to.not.exist;\n        expect(client).to.have.nested.property('topology.clientMetadata.application.name').to.equal('hello world');\n        client.close(done);\n      });\n    }\n  });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly pass through socketTimeoutMS and connectTimeoutMS","suites":["class MongoClient"],"updatePoint":{"line":157,"column":72,"index":5415},"line":157,"code":"  it('Should correctly pass through socketTimeoutMS and connectTimeoutMS', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient({}, {\n        socketTimeoutMS: 0,\n        connectTimeoutMS: 0\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        const topology = getTopology(client.db(configuration.db));\n        expect(topology).nested.property('s.options.connectTimeoutMS').to.equal(0);\n        expect(topology).nested.property('s.options.socketTimeoutMS').to.equal(0);\n        client.close(done);\n      });\n    }\n  });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"should open a new MongoClient connection","suites":["class MongoClient"],"updatePoint":{"line":178,"column":46,"index":6126},"line":178,"code":"  it('should open a new MongoClient connection', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect(function (err, mongoclient) {\n        expect(err).to.not.exist;\n        mongoclient.db('integration_tests').collection('new_mongo_client_collection').insertOne({\n          a: 1\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).to.be.an('object');\n          mongoclient.close(done);\n        });\n      });\n    }\n  });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"should correctly connect with MongoClient `connect` using Promise","suites":["class MongoClient"],"updatePoint":{"line":199,"column":71,"index":6778},"line":199,"code":"  it('should correctly connect with MongoClient `connect` using Promise', function () {\n    const configuration = this.configuration;\n    let url = configuration.url();\n    url = url.indexOf('?') !== -1 ? `${url}&maxPoolSize=100` : `${url}?maxPoolSize=100`;\n    const client = configuration.newClient(url);\n    return client.connect().then(() => client.close());\n  });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"should open a new MongoClient connection using promise","suites":["class MongoClient"],"updatePoint":{"line":206,"column":60,"index":7136},"line":206,"code":"  it('should open a new MongoClient connection using promise', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect().then(function (mongoclient) {\n        mongoclient.db('integration_tests').collection('new_mongo_client_collection').insertOne({\n          a: 1\n        }).then(function (r) {\n          expect(r).to.exist;\n          mongoclient.close(done);\n        });\n      });\n    }\n  });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"should be able to access a database named \"constructor\"","suites":["class MongoClient"],"updatePoint":{"line":225,"column":61,"index":7700},"line":225,"code":"  it('should be able to access a database named \"constructor\"', function () {\n    const client = this.configuration.newClient();\n    let err;\n    return client.connect().then(() => {\n      const db = client.db('constructor');\n      expect(db).to.not.be.a('function');\n      expect(db).to.be.an.instanceOf(Db);\n    }).catch(_err => err = _err).then(() => client.close()).catch(() => {// ignore\n    }).then(() => {\n      if (err) {\n        throw err;\n      }\n    });\n  });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"should cache a resolved readPreference from options","suites":["class MongoClient"],"updatePoint":{"line":239,"column":57,"index":8167},"line":239,"code":"  it('should cache a resolved readPreference from options', function () {\n    const client = this.configuration.newClient({}, {\n      readPreference: ReadPreference.SECONDARY\n    });\n    expect(client.readPreference).to.be.instanceOf(ReadPreference);\n    expect(client.readPreference).to.have.property('mode', ReadPreference.SECONDARY);\n  });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"should error on unexpected options","suites":["class MongoClient"],"updatePoint":{"line":246,"column":40,"index":8493},"line":246,"code":"  it('should error on unexpected options', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      const configuration = this.configuration;\n      MongoClient.connect(configuration.url(), {\n        maxPoolSize: 4,\n        // @ts-expect-error: unexpected option test\n        notlegal: {},\n        validateOptions: true\n      }, function (err, client) {\n        expect(err).property('message').to.match(/options notlegal, validateoptions are not supported/);\n        expect(client).to.not.exist;\n        done();\n      });\n    }\n  });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"should error on unexpected options (promise)","suites":["class MongoClient"],"updatePoint":{"line":266,"column":50,"index":9091},"line":266,"code":"  it('should error on unexpected options (promise)', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n\n    test() {\n      const options = {\n        maxPoolSize: 4,\n        notlegal: {},\n        validateOptions: true\n      };\n      MongoClient.connect(this.configuration.url(), options).then(() => expect.fail()).catch(err => {\n        expect(err).property('message').to.match(/options notlegal, validateoptions are not supported/);\n      });\n    }\n\n  });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"must respect an infinite connectTimeoutMS for the streaming protocol","suites":["class MongoClient"],"updatePoint":{"line":285,"column":74,"index":9599},"line":285,"code":"  it('must respect an infinite connectTimeoutMS for the streaming protocol', {\n    metadata: {\n      requires: {\n        topology: 'replicaset',\n        mongodb: '>= 4.4'\n      }\n    },\n    test: function (done) {\n      const client = this.configuration.newClient({\n        connectTimeoutMS: 0,\n        heartbeatFrequencyMS: 500\n      });\n      client.connect(err => {\n        expect(err).to.not.exist;\n        const stub = sinon.stub(Connection.prototype, 'command').callsFake(function (...args) {\n          const ns = args[0];\n          const command = args[1];\n          const options = args[2] || {}; // @ts-expect-error: exhaustAllowed is a protocol option\n\n          if (ns.toString() === 'admin.$cmd' && isHello(command) && options.exhaustAllowed) {\n            expect(options).property('socketTimeoutMS').to.equal(0);\n            stub.restore();\n            client.close(done);\n          }\n\n          stub.wrappedMethod.apply(this, args);\n        });\n      });\n    }\n  });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"must respect a finite connectTimeoutMS for the streaming protocol","suites":["class MongoClient"],"updatePoint":{"line":315,"column":71,"index":10577},"line":315,"code":"  it('must respect a finite connectTimeoutMS for the streaming protocol', {\n    metadata: {\n      requires: {\n        topology: 'replicaset',\n        mongodb: '>= 4.4'\n      }\n    },\n    test: function (done) {\n      const client = this.configuration.newClient({\n        connectTimeoutMS: 10,\n        heartbeatFrequencyMS: 500\n      });\n      client.connect(err => {\n        expect(err).to.not.exist;\n        const stub = sinon.stub(Connection.prototype, 'command').callsFake(function (...args) {\n          const ns = args[0];\n          const command = args[1];\n          const options = args[2] || {}; // @ts-expect-error: exhaustAllowed is a protocol option\n\n          if (ns.toString() === 'admin.$cmd' && isHello(command) && options.exhaustAllowed) {\n            expect(options).property('socketTimeoutMS').to.equal(510);\n            stub.restore();\n            client.close(done);\n          }\n\n          stub.wrappedMethod.apply(this, args);\n        });\n      });\n    }\n  });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"creates topology and send ping when auth is enabled","suites":["class MongoClient","explict #connect()"],"updatePoint":{"line":355,"column":59,"index":11821},"line":355,"code":"    it('creates topology and send ping when auth is enabled', {\n      requires: {\n        auth: 'enabled'\n      }\n    }, async function () {\n      const commandToBeStarted = once(client, 'commandStarted');\n      await client.connect();\n      const [pingOnConnect] = await commandToBeStarted;\n      expect(pingOnConnect).to.have.property('commandName', 'ping');\n      expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n    });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"does not send ping when authentication is disabled","suites":["class MongoClient","explict #connect()"],"updatePoint":{"line":366,"column":58,"index":12269},"line":366,"code":"    it('does not send ping when authentication is disabled', {\n      requires: {\n        auth: 'disabled'\n      }\n    }, async function () {\n      const commandToBeStarted = once(client, 'commandStarted');\n      await client.connect();\n      const delayedFind = runLater(async () => {\n        await client.db().collection('test').findOne();\n      }, 300);\n      const [findOneOperation] = await commandToBeStarted; // Proves that the first command started event that is emitted is a find and not a ping\n\n      expect(findOneOperation).to.have.property('commandName', 'find');\n      await delayedFind;\n      expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n    });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"permits operations to be run after connect is called","suites":["class MongoClient","explict #connect()"],"updatePoint":{"line":382,"column":60,"index":12960},"line":382,"code":"    it('permits operations to be run after connect is called', {\n      requires: {\n        auth: 'enabled'\n      }\n    }, async function () {\n      const pingCommandToBeStarted = once(client, 'commandStarted');\n      await client.connect();\n      const [pingOnConnect] = await pingCommandToBeStarted;\n      const findCommandToBeStarted = once(client, 'commandStarted');\n      await client.db('test').collection('test').findOne();\n      const [findCommandStarted] = await findCommandToBeStarted;\n      expect(pingOnConnect).to.have.property('commandName', 'ping');\n      expect(findCommandStarted).to.have.property('commandName', 'find');\n      expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n    });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"automatically connects upon first operation (find)","suites":["class MongoClient","implicit #connect()"],"updatePoint":{"line":408,"column":58,"index":13966},"line":408,"code":"    it('automatically connects upon first operation (find)', {\n      requires: {\n        auth: 'enabled'\n      }\n    }, async function () {\n      const findCommandToBeStarted = once(client, 'commandStarted');\n      await client.db().collection('test').findOne();\n      const [findCommandStarted] = await findCommandToBeStarted;\n      expect(findCommandStarted).to.have.property('commandName', 'find');\n      expect(client.options).to.not.have.property(Symbol.for('@@mdb.skipPingOnConnect'));\n      expect(client.s.options).to.not.have.property(Symbol.for('@@mdb.skipPingOnConnect')); // Assertion is redundant but it shows that no initial ping is run\n\n      expect(findCommandStarted.commandName).to.not.equal('ping');\n      expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n    });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"automatically connects upon first operation (insertOne)","suites":["class MongoClient","implicit #connect()"],"updatePoint":{"line":423,"column":63,"index":14778},"line":423,"code":"    it('automatically connects upon first operation (insertOne)', {\n      requires: {\n        auth: 'enabled'\n      }\n    }, async function () {\n      const insertOneCommandToBeStarted = once(client, 'commandStarted');\n      await client.db().collection('test').insertOne({\n        a: 1\n      });\n      const [insertCommandStarted] = await insertOneCommandToBeStarted;\n      expect(insertCommandStarted).to.have.property('commandName', 'insert');\n      expect(client.options).to.not.have.property(Symbol.for('@@mdb.skipPingOnConnect'));\n      expect(client.s.options).to.not.have.property(Symbol.for('@@mdb.skipPingOnConnect')); // Assertion is redundant but it shows that no initial ping is run\n\n      expect(insertCommandStarted.commandName).to.not.equal('ping');\n      expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n    });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"passes connection errors to the user through the first operation","suites":["class MongoClient","implicit #connect()"],"updatePoint":{"line":440,"column":72,"index":15641},"line":440,"code":"    it('passes connection errors to the user through the first operation', {\n      requires: {\n        auth: 'enabled'\n      }\n    }, async function () {\n      const client = this.configuration.newClient('mongodb://iLoveJavascript?serverSelectionTimeoutMS=100', {\n        monitorCommands: true\n      });\n      const result = await client.db('test').collection('test').findOne().catch(error => error);\n      expect(result).to.be.instanceOf(MongoServerSelectionError);\n      expect(client).to.be.instanceOf(MongoClient);\n      expect(client).to.have.property('topology').that.is.instanceOf(Topology);\n    });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"prevents automatic connection on a closed non-connected client","suites":["class MongoClient","#close()"],"updatePoint":{"line":477,"column":70,"index":16775},"line":477,"code":"    it('prevents automatic connection on a closed non-connected client', async () => {\n      expect(client.s).to.have.ownPropertyDescriptor('hasBeenClosed', INIT_HAS_BEEN_CLOSED);\n      await client.close();\n      expect(client.s).to.have.ownPropertyDescriptor('hasBeenClosed', RD_ONLY_HAS_BEEN_CLOSED);\n      const error = await db.command({\n        ping: 1\n      }).catch(error => error);\n      expect(error).to.be.instanceOf(MongoNotConnectedError);\n    });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"allows explicit connection on a closed non-connected client","suites":["class MongoClient","#close()"],"updatePoint":{"line":486,"column":67,"index":17233},"line":486,"code":"    it('allows explicit connection on a closed non-connected client', async () => {\n      expect(client.s).to.have.ownPropertyDescriptor('hasBeenClosed', INIT_HAS_BEEN_CLOSED);\n      await client.close();\n      expect(client.s).to.have.ownPropertyDescriptor('hasBeenClosed', RD_ONLY_HAS_BEEN_CLOSED);\n      await client.connect();\n      const result = await db.command({\n        ping: 1\n      }).catch(error => error);\n      expect(result).to.not.be.instanceOf(MongoNotConnectedError);\n      expect(result).to.have.property('ok', 1);\n    });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"prevents automatic reconnect on a closed previously explicitly connected client","suites":["class MongoClient","#close()"],"updatePoint":{"line":497,"column":87,"index":17795},"line":497,"code":"    it('prevents automatic reconnect on a closed previously explicitly connected client', async () => {\n      await client.connect();\n      expect(client.s).to.have.ownPropertyDescriptor('hasBeenClosed', INIT_HAS_BEEN_CLOSED);\n      await client.close();\n      expect(client.s).to.have.ownPropertyDescriptor('hasBeenClosed', RD_ONLY_HAS_BEEN_CLOSED);\n      const error = await db.command({\n        ping: 1\n      }).catch(error => error);\n      expect(error).to.be.instanceOf(MongoNotConnectedError);\n    });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"allows explicit reconnect on a closed previously explicitly connected client","suites":["class MongoClient","#close()"],"updatePoint":{"line":507,"column":84,"index":18300},"line":507,"code":"    it('allows explicit reconnect on a closed previously explicitly connected client', async () => {\n      await client.connect();\n      expect(client.s).to.have.ownPropertyDescriptor('hasBeenClosed', INIT_HAS_BEEN_CLOSED);\n      await client.close();\n      expect(client.s).to.have.ownPropertyDescriptor('hasBeenClosed', RD_ONLY_HAS_BEEN_CLOSED);\n      await client.connect();\n      const result = await db.command({\n        ping: 1\n      }).catch(error => error);\n      expect(result).to.not.be.instanceOf(MongoNotConnectedError);\n      expect(result).to.have.property('ok', 1);\n    });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"prevents auto reconnect on closed previously implicitly connected client","suites":["class MongoClient","#close()"],"updatePoint":{"line":519,"column":80,"index":18885},"line":519,"code":"    it('prevents auto reconnect on closed previously implicitly connected client', async () => {\n      expect(client.s).to.have.ownPropertyDescriptor('hasBeenClosed', INIT_HAS_BEEN_CLOSED);\n      const result = await db.command({\n        ping: 1\n      }).catch(error => error); // auto connect\n\n      expect(result).to.not.be.instanceOf(MongoNotConnectedError);\n      expect(result).to.have.property('ok', 1);\n      await client.close();\n      expect(client.s).to.have.ownPropertyDescriptor('hasBeenClosed', RD_ONLY_HAS_BEEN_CLOSED);\n      const error = await db.command({\n        ping: 1\n      }).catch(error => error);\n      expect(error).to.be.instanceOf(MongoNotConnectedError);\n    });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"allows explicit reconnect on closed previously implicitly connected client","suites":["class MongoClient","#close()"],"updatePoint":{"line":534,"column":82,"index":19578},"line":534,"code":"    it('allows explicit reconnect on closed previously implicitly connected client', async () => {\n      expect(client.s).to.have.ownPropertyDescriptor('hasBeenClosed', INIT_HAS_BEEN_CLOSED);\n      const result = await db.command({\n        ping: 1\n      }).catch(error => error); // auto connect\n\n      expect(result).to.not.be.instanceOf(MongoNotConnectedError);\n      expect(result).to.have.property('ok', 1);\n      await client.close();\n      await client.connect();\n      expect(client.s).to.have.ownPropertyDescriptor('hasBeenClosed', RD_ONLY_HAS_BEEN_CLOSED);\n      const result2 = await db.command({\n        ping: 1\n      }).catch(error => error);\n      expect(result2).to.not.be.instanceOf(MongoNotConnectedError);\n      expect(result2).to.have.property('ok', 1);\n    });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"prevents auto reconnect on closed explicitly connected client after an operation","suites":["class MongoClient","#close()"],"updatePoint":{"line":551,"column":88,"index":20364},"line":551,"code":"    it('prevents auto reconnect on closed explicitly connected client after an operation', async () => {\n      expect(client.s).to.have.ownPropertyDescriptor('hasBeenClosed', INIT_HAS_BEEN_CLOSED);\n      await client.connect();\n      const result = await db.command({\n        ping: 1\n      }).catch(error => error);\n      expect(result).to.not.be.instanceOf(MongoNotConnectedError);\n      expect(result).to.have.property('ok', 1);\n      await client.close();\n      expect(client.s).to.have.ownPropertyDescriptor('hasBeenClosed', RD_ONLY_HAS_BEEN_CLOSED);\n      const error = await db.command({\n        ping: 1\n      }).catch(error => error);\n      expect(error).to.be.instanceOf(MongoNotConnectedError);\n    });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"allows explicit reconnect on closed explicitly connected client after an operation","suites":["class MongoClient","#close()"],"updatePoint":{"line":566,"column":90,"index":21078},"line":566,"code":"    it('allows explicit reconnect on closed explicitly connected client after an operation', async () => {\n      expect(client.s).to.have.ownPropertyDescriptor('hasBeenClosed', INIT_HAS_BEEN_CLOSED);\n      await client.connect();\n      const result = await db.command({\n        ping: 1\n      }).catch(error => error);\n      expect(result).to.not.be.instanceOf(MongoNotConnectedError);\n      expect(result).to.have.property('ok', 1);\n      await client.close();\n      await client.connect();\n      expect(client.s).to.have.ownPropertyDescriptor('hasBeenClosed', RD_ONLY_HAS_BEEN_CLOSED);\n      const result2 = await db.command({\n        ping: 1\n      }).catch(error => error);\n      expect(result2).to.not.be.instanceOf(MongoNotConnectedError);\n      expect(result2).to.have.property('ok', 1);\n    });","file":"integration/node-specific/mongo_client.test.ts","skipped":false,"dir":"test"},{"name":"aggregationExample1","suites":["Operation Examples"],"updatePoint":{"line":50,"column":25,"index":1149},"line":50,"code":"  it('aggregationExample1', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Some docs for insertion\n\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }]; // Create a collection\n\n        var collection = db.collection('aggregationExample1'); // Insert the docs\n\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          expect(err).to.not.exist;\n          test.ok(result); // Execute aggregate, notice the pipeline is expressed as an Array\n\n          const cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }, {\n            $sort: {\n              _id: -1\n            }\n          }]);\n          cursor.toArray(function (err, result) {\n            expect(err).to.not.exist;\n            test.equal('good', result[0]._id.tags);\n            test.deepEqual(['bob'], result[0].authors);\n            test.equal('fun', result[1]._id.tags);\n            test.deepEqual(['bob'], result[1].authors);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"aggregationExample2","suites":["Operation Examples"],"updatePoint":{"line":145,"column":25,"index":4036},"line":145,"code":"  it('aggregationExample2', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Some docs for insertion\n\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }]; // Create a collection\n\n        var collection = db.collection('aggregationExample2'); // Insert the docs\n\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          expect(err).to.not.exist;\n          test.ok(result); // Execute aggregate, notice the pipeline is expressed as an Array\n\n          var cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }], {\n            cursor: {\n              batchSize: 1\n            }\n          }); // Get all the aggregation results\n\n          cursor.toArray(function (err, docs) {\n            expect(err).to.not.exist;\n            test.equal(2, docs.length);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Aggregation Cursor toArray Test","suites":["Operation Examples"],"updatePoint":{"line":238,"column":37,"index":6815},"line":238,"code":"  it('Aggregation Cursor toArray Test', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Some docs for insertion\n\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }]; // Create a collection\n\n        var collection = db.collection('aggregation_toArray_example'); // Insert the docs\n\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          expect(err).to.not.exist;\n          test.ok(result); // Execute aggregate, notice the pipeline is expressed as an Array\n\n          var cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }], {\n            cursor: {\n              batchSize: 1\n            }\n          }); // Get all the aggregation results\n\n          cursor.toArray(function (err, docs) {\n            expect(err).to.not.exist;\n            test.equal(2, docs.length);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Aggregation Cursor toArray Test","suites":["Operation Examples"],"updatePoint":{"line":331,"column":37,"index":9596},"line":331,"code":"  it('Aggregation Cursor toArray Test', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close()); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n\n        var db = client.db(configuration.db); // Some docs for insertion\n\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }]; // Create a collection\n\n        var collection = db.collection('aggregation_next_example'); // Insert the docs\n\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, (err, result) => {\n          test.ok(result);\n          expect(err).to.not.exist; // Execute aggregate, notice the pipeline is expressed as an Array\n\n          var cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }], {\n            cursor: {\n              batchSize: 1\n            }\n          });\n          this.defer(() => cursor.close()); // Get all the aggregation results\n\n          cursor.next((err, docs) => {\n            test.ok(docs);\n            expect(err).to.not.exist;\n            done();\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Aggregation Cursor each Test","suites":["Operation Examples"],"updatePoint":{"line":427,"column":34,"index":12438},"line":427,"code":"  it('Aggregation Cursor each Test', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Some docs for insertion\n\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }]; // Create a collection\n\n        var collection = db.collection('aggregation_each_example'); // Insert the docs\n\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Execute aggregate, notice the pipeline is expressed as an Array\n\n          var cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }], {\n            cursor: {\n              batchSize: 1\n            }\n          }); // Get all the aggregation results\n\n          cursor.forEach(() => {}, err => {\n            expect(err).to.not.exist;\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Aggregation Cursor forEach Test","suites":["Operation Examples"],"updatePoint":{"line":519,"column":37,"index":15178},"line":519,"code":"  it('Aggregation Cursor forEach Test', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Some docs for insertion\n\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }]; // Create a collection\n\n        var collection = db.collection('aggregation_forEach_example'); // Insert the docs\n\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Execute aggregate, notice the pipeline is expressed as an Array\n\n          var cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }], {\n            cursor: {\n              batchSize: 1\n            }\n          });\n          var count = 0; // Get all the aggregation results\n\n          cursor.forEach(function (doc) {\n            test.ok(doc != null);\n            count = count + 1;\n          }, function (err) {\n            expect(err).to.not.exist;\n            test.equal(2, count);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"aggregationExample3","suites":["Operation Examples"],"updatePoint":{"line":616,"column":25,"index":18049},"line":616,"code":"  it('aggregationExample3', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Some docs for insertion\n\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }]; // Create a collection\n\n        var collection = db.collection('aggregationExample3'); // Insert the docs\n\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Execute aggregate, notice the pipeline is expressed as an Array\n\n          var cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }], {\n            cursor: {\n              batchSize: 1\n            }\n          });\n          const stream = cursor.stream();\n          var count = 0; // Get all the aggregation results\n\n          stream.on('data', function () {\n            count = count + 1;\n          });\n          stream.once('end', function () {\n            test.equal(2, count);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDoSimpleCountExamples","suites":["Operation Examples"],"updatePoint":{"line":713,"column":42,"index":20934},"line":713,"code":"  it('shouldCorrectlyDoSimpleCountExamples', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Crete the collection for the distinct example\n\n        var collection = db.collection('countExample1'); // Insert documents to perform distinct against\n\n        collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }, {\n          a: 4,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, ids) {\n          test.ok(ids);\n          expect(err).to.not.exist; // Perform a total count command\n\n          collection.count(function (err, count) {\n            expect(err).to.not.exist;\n            test.equal(4, count); // Perform a partial account where b=1\n\n            collection.count({\n              b: 1\n            }, function (err, count) {\n              expect(err).to.not.exist;\n              test.equal(1, count);\n              client.close(done);\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCreateComplexIndexOnTwoFields","suites":["Operation Examples"],"updatePoint":{"line":779,"column":41,"index":23019},"line":779,"code":"  it('shouldCreateComplexIndexOnTwoFields', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection we want to drop later\n\n        var collection = db.collection('createIndexExample1'); // Insert a bunch of documents for the index\n\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Create an index on the a field\n\n          collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, indexName) {\n            test.ok(indexName);\n            expect(err).to.not.exist; // Show that duplicate records got dropped\n\n            collection.find({}).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(4, items.length); // Perform a query, with explain to show we hit the query\n\n              collection.find({\n                a: 2\n              }).explain(function (err, explanation) {\n                expect(err).to.not.exist;\n                test.ok(explanation != null);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCreateASimpleIndexOnASingleField","suites":["Operation Examples"],"updatePoint":{"line":858,"column":44,"index":25523},"line":858,"code":"  it('shouldCreateASimpleIndexOnASingleField', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection we want to drop later\n\n        var collection = db.collection('createIndexExample2'); // Insert a bunch of documents for the index\n\n        collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }, {\n          a: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Create an index on the a field\n\n          collection.createIndex('a', {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, indexName) {\n            test.equal('a_1', indexName); // Perform a query, with explain to show we hit the query\n\n            collection.find({\n              a: 2\n            }).explain(function (err, explanation) {\n              expect(err).to.not.exist;\n              test.ok(explanation != null);\n              client.close(done);\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"createIndexExample3","suites":["Operation Examples"],"updatePoint":{"line":926,"column":25,"index":27649},"line":926,"code":"  it('createIndexExample3', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection we want to drop later\n\n        var collection = db.collection('createIndexExample3'); // Insert a bunch of documents for the index\n\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n          var options = {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          }; // Create an index on the a field\n\n          collection.createIndex({\n            a: 1,\n            b: 1\n          }, options, function (err, indexName) {\n            test.ok(indexName);\n            expect(err).to.not.exist;\n            test.ok(!options.readPreference); // Show that duplicate records got dropped\n\n            collection.find({}).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(4, items.length); // Perform a query, with explain to show we hit the query\n\n              collection.find({\n                a: 2\n              }).explain(function (err, explanation) {\n                expect(err).to.not.exist;\n                test.ok(explanation != null);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleDistinctIndexesWithSubQueryFilter","suites":["Operation Examples"],"updatePoint":{"line":1011,"column":60,"index":30286},"line":1011,"code":"  it('shouldCorrectlyHandleDistinctIndexesWithSubQueryFilter', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Crete the collection for the distinct example\n\n        var collection = db.collection('distinctExample1'); // Insert documents to perform distinct against\n\n        collection.insertMany([{\n          a: 0,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'b'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'c'\n          }\n        }, {\n          a: 2,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 3\n        }, {\n          a: 3\n        }], configuration.writeConcernMax(), function (err, ids) {\n          test.ok(ids);\n          expect(err).to.not.exist; // Perform a distinct query against the a field\n\n          collection.distinct('a', function (err, docs) {\n            test.deepEqual([0, 1, 2, 3], docs.sort()); // Perform a distinct query against the sub-field b.c\n\n            collection.distinct('b.c', function (err, docs) {\n              test.deepEqual(['a', 'b', 'c'], docs.sort());\n              client.close(done);\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleDistinctIndexes","suites":["Operation Examples"],"updatePoint":{"line":1084,"column":42,"index":32514},"line":1084,"code":"  it('shouldCorrectlyHandleDistinctIndexes', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Crete the collection for the distinct example\n\n        var collection = db.collection('distinctExample2'); // Insert documents to perform distinct against\n\n        collection.insertMany([{\n          a: 0,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'b'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'c'\n          }\n        }, {\n          a: 2,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 3\n        }, {\n          a: 3\n        }, {\n          a: 5,\n          c: 1\n        }], configuration.writeConcernMax(), function (err, ids) {\n          test.ok(ids);\n          expect(err).to.not.exist; // Perform a distinct query with a filter against the documents\n\n          collection.distinct('a', {\n            c: 1\n          }, function (err, docs) {\n            test.deepEqual([5], docs.sort());\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDropCollectionWithDropFunction","suites":["Operation Examples"],"updatePoint":{"line":1158,"column":51,"index":34591},"line":1158,"code":"  it('shouldCorrectlyDropCollectionWithDropFunction', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection we want to drop later\n\n        var collection = db.collection('test_other_drop'); // Drop the collection\n\n        collection.drop(function\n          /*err, reply*/\n        () {\n          // TODO: reenable once SERVER-36317 is resolved\n          // expect(err).to.exist;\n          // expect(reply).to.not.exist;\n          // Ensure we don't have the collection in the set of names\n          db.listCollections().toArray(function (err, replies) {\n            var found = false; // For each collection in the list of collection names in this db look for the\n            // dropped collection\n\n            replies.forEach(function (document) {\n              if (document.name === 'test_other_drop') {\n                found = true;\n                return;\n              }\n            }); // Ensure the collection is not found\n\n            test.equal(false, found); // Let's close the db\n\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"dropIndexesExample1","suites":["Operation Examples"],"updatePoint":{"line":1217,"column":25,"index":36686},"line":1217,"code":"  it('dropIndexesExample1', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        db.createCollection('dropExample1', function (err, r) {\n          test.ok(r);\n          expect(err).to.not.exist; // Drop the collection\n\n          db.collection('dropExample1').dropIndexes(function (err, reply) {\n            test.ok(reply);\n            expect(err).to.not.exist; // Let's close the db\n\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateAndDropIndex","suites":["Operation Examples"],"updatePoint":{"line":1261,"column":39,"index":38181},"line":1261,"code":"  it('shouldCorrectlyCreateAndDropIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        var collection = db.collection('dropIndexExample1'); // Insert a bunch of documents for the index\n\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Create an index on the a field\n\n          collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, indexName) {\n            test.ok(indexName);\n            expect(err).to.not.exist; // Drop the index\n\n            collection.dropIndex('a_1_b_1', function (err, result) {\n              test.ok(result);\n              expect(err).to.not.exist; // Verify that the index is gone\n\n              collection.indexInformation(function (err, indexInformation) {\n                test.deepEqual([['_id', 1]], indexInformation._id_);\n                expect(indexInformation.a_1_b_1).to.not.exist;\n                client.close(done);\n              });\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCreateComplexEnsureIndex","suites":["Operation Examples"],"updatePoint":{"line":1341,"column":36,"index":40675},"line":1341,"code":"  it('shouldCreateComplexEnsureIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        var collection = db.collection('ensureIndexExample1'); // Insert a bunch of documents for the index\n\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Create an index on the a field\n\n          db.createIndex('ensureIndexExample1', {\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, indexName) {\n            test.ok(indexName);\n            expect(err).to.not.exist; // Show that duplicate records got dropped\n\n            collection.find({}).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(4, items.length); // Perform a query, with explain to show we hit the query\n\n              collection.find({\n                a: 2\n              }).explain(function (err, explanation) {\n                expect(err).to.not.exist;\n                test.ok(explanation != null);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"ensureIndexExampleWithCompountIndex","suites":["Operation Examples"],"updatePoint":{"line":1419,"column":41,"index":43166},"line":1419,"code":"  it('ensureIndexExampleWithCompountIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        var collection = db.collection('ensureIndexExample2'); // Insert a bunch of documents for the index\n\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Create an index on the a field\n\n          collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, indexName) {\n            test.ok(indexName);\n            expect(err).to.not.exist; // Show that duplicate records got dropped\n\n            collection.find({}).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(4, items.length); // Perform a query, with explain to show we hit the query\n\n              collection.find({\n                a: 2\n              }).explain(function (err, explanation) {\n                expect(err).to.not.exist;\n                test.ok(explanation != null);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleQuery","suites":["Operation Examples"],"updatePoint":{"line":1501,"column":31,"index":45640},"line":1501,"code":"  it('shouldPerformASimpleQuery', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection we want to drop later\n\n        var collection = db.collection('simple_query'); // Insert a bunch of documents for the testing\n\n        collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Perform a simple find and return all the documents\n\n          collection.find().toArray(function (err, docs) {\n            expect(err).to.not.exist;\n            test.equal(3, docs.length);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleExplainQuery","suites":["Operation Examples"],"updatePoint":{"line":1553,"column":38,"index":47386},"line":1553,"code":"  it('shouldPerformASimpleExplainQuery', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection we want to drop later\n\n        var collection = db.collection('simple_explain_query'); // Insert a bunch of documents for the testing\n\n        collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Perform a simple find and return all the documents\n\n          collection.find({}).explain(function (err, explain) {\n            expect(err).to.not.exist;\n            test.ok(explain != null);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleLimitSkipQuery","suites":["Operation Examples"],"updatePoint":{"line":1605,"column":40,"index":49136},"line":1605,"code":"  it('shouldPerformASimpleLimitSkipQuery', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection we want to drop later\n\n        var collection = db.collection('simple_limit_skip_query'); // Insert a bunch of documents for the testing\n\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Perform a simple find and return all the documents\n\n          collection.find({}).skip(1).limit(1).project({\n            b: 1\n          }).toArray(function (err, docs) {\n            expect(err).to.not.exist;\n            test.equal(1, docs.length);\n            expect(docs[0].a).to.not.exist;\n            test.equal(2, docs[0].b);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformSimplefindOneAndUpdateOperations","suites":["Operation Examples"],"updatePoint":{"line":1668,"column":51,"index":51385},"line":1668,"code":"  it('shouldPerformSimplefindOneAndUpdateOperations', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection we want to drop later\n\n        var collection = db.collection('simple_find_and_modify_operations_'); // Insert some test documentations\n\n        collection.insertMany([{\n          a: 1\n        }, {\n          b: 1\n        }, {\n          c: 1\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Simple findOneAndUpdate command returning the new document\n\n          collection.findOneAndUpdate({\n            a: 1\n          }, {\n            $set: {\n              b1: 1\n            }\n          }, {\n            returnDocument: ReturnDocument.AFTER\n          }, function (err, doc) {\n            expect(err).to.not.exist;\n            test.equal(1, doc.value.a);\n            test.equal(1, doc.value.b1); // Simple findOneAndUpdate command returning the new document and\n            // removing it at the same time\n\n            collection.findOneAndUpdate({\n              b: 1\n            }, {\n              $set: {\n                b: 2\n              }\n            }, {\n              remove: true\n            }, function (err, doc) {\n              test.ok(doc);\n              expect(err).to.not.exist; // Verify that the document is gone\n\n              collection.findOne({\n                b: 1\n              }, function (err, item) {\n                expect(err).to.not.exist;\n                expect(item).to.not.exist; // Simple findOneAndUpdate command performing an upsert and returning the new document\n                // executing the command safely\n\n                collection.findOneAndUpdate({\n                  d: 1\n                }, {\n                  $set: {\n                    d: 1,\n                    f: 1\n                  }\n                }, {\n                  returnDocument: ReturnDocument.AFTER,\n                  upsert: true,\n                  writeConcern: {\n                    w: 1\n                  }\n                }, function (err, doc) {\n                  expect(err).to.not.exist;\n                  test.equal(1, doc.value.d);\n                  test.equal(1, doc.value.f);\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformSimplefindOneAndDelete","suites":["Operation Examples"],"updatePoint":{"line":1770,"column":41,"index":54724},"line":1770,"code":"  it('shouldPerformSimplefindOneAndDelete', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection we want to drop later\n\n        var collection = db.collection('simple_find_and_modify_operations_2'); // Insert some test documentations\n\n        collection.insertMany([{\n          a: 1\n        }, {\n          b: 1,\n          d: 1\n        }, {\n          c: 1\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Simple findOneAndDelete command returning the old document and\n          // removing it at the same time\n\n          collection.findOneAndDelete({\n            b: 1\n          }, [['b', 1]], function (err, doc) {\n            expect(err).to.not.exist;\n            test.equal(1, doc.value.b);\n            test.equal(1, doc.value.d); // Verify that the document is gone\n\n            collection.findOne({\n              b: 1\n            }, function (err, item) {\n              expect(err).to.not.exist;\n              expect(item).to.not.exist;\n              client.close(done);\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleLimitSkipFindOneQuery","suites":["Operation Examples"],"updatePoint":{"line":1834,"column":47,"index":56856},"line":1834,"code":"  it('shouldPerformASimpleLimitSkipFindOneQuery', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection we want to drop later\n\n        var collection = db.collection('simple_limit_skip_find_one_query'); // Insert a bunch of documents for the testing\n\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Perform a simple find and return all the documents\n\n          collection.findOne({\n            a: 2\n          }, {\n            projection: {\n              b: 1\n            }\n          }, function (err, doc) {\n            expect(err).to.not.exist;\n            expect(doc.a).to.not.exist;\n            test.equal(2, doc.b);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformSimpleMapReduceFunctions","suites":["Operation Examples"],"updatePoint":{"line":1896,"column":43,"index":58793},"line":1896,"code":"  it('shouldPerformSimpleMapReduceFunctions', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      /* eslint-disable */\n\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a test collection\n\n        var collection = db.collection('test_map_reduce_functions'); // Insert some documents to perform map reduce over\n\n        collection.insertMany([{\n          user_id: 1\n        }, {\n          user_id: 2\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          test.ok(r);\n          expect(err).to.not.exist; // Map function\n\n          var map = function () {\n            emit(this.user_id, 1);\n          }; // Reduce function\n\n\n          var reduce = function (k, vals) {\n            return 1;\n          }; // Perform the map reduce\n\n\n          collection.mapReduce(map, reduce, {\n            out: {\n              replace: 'tempCollection'\n            }\n          }, function (err, collection) {\n            expect(err).to.not.exist; // Mapreduce returns the temporary collection with the results\n\n            collection.findOne({\n              _id: 1\n            }, function (err, result) {\n              test.equal(1, result.value);\n              collection.findOne({\n                _id: 2\n              }, function (err, result) {\n                test.equal(1, result.value);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }); // END\n\n      /* eslint-enable */\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformMapReduceFunctionInline","suites":["Operation Examples"],"updatePoint":{"line":1978,"column":42,"index":61285},"line":1978,"code":"  it('shouldPerformMapReduceFunctionInline', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>1.7.6',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a test collection\n\n        var collection = db.collection('test_map_reduce_functions_inline'); // Insert some test documents\n\n        collection.insertMany([{\n          user_id: 1\n        }, {\n          user_id: 2\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          test.ok(r);\n          expect(err).to.not.exist; // Map function\n\n          var map = function () {\n            emit(this.user_id, 1); // eslint-disable-line\n          }; // Reduce function\n          // eslint-disable-next-line\n\n\n          var reduce = function (k, vals) {\n            return 1;\n          }; // Execute map reduce and return results inline\n\n\n          collection.mapReduce(map, reduce, {\n            out: {\n              inline: 1\n            },\n            verbose: true\n          }, function (err, result) {\n            test.equal(2, result.results.length);\n            test.ok(result.stats != null);\n            collection.mapReduce(map, reduce, {\n              out: {\n                replace: 'mapreduce_integration_test'\n              },\n              verbose: true\n            }, function (err, result) {\n              test.ok(result.stats != null);\n              client.close(done);\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformMapReduceWithContext","suites":["Operation Examples"],"updatePoint":{"line":2059,"column":39,"index":63874},"line":2059,"code":"  it('shouldPerformMapReduceWithContext', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a test collection\n\n        var collection = db.collection('test_map_reduce_functions_scope'); // Insert some test documents\n\n        collection.insertMany([{\n          user_id: 1,\n          timestamp: new Date()\n        }, {\n          user_id: 2,\n          timestamp: new Date()\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          test.ok(r);\n          expect(err).to.not.exist; // Map function\n\n          var map = function () {\n            emit(fn(this.timestamp.getYear()), 1); // eslint-disable-line\n          }; // Reduce function\n\n\n          var reduce = function (k, v) {\n            var count = 0;\n\n            for (var i = 0; i < v.length; i++) {\n              count += v[i];\n            }\n\n            return count;\n          }; // Javascript function available in the map reduce scope\n\n\n          var t = function (val) {\n            return val + 1;\n          }; // Execute the map reduce with the custom scope\n\n\n          var o = {};\n          o.scope = {\n            fn: new Code(t.toString())\n          };\n          o.out = {\n            replace: 'replacethiscollection'\n          };\n          collection.mapReduce(map, reduce, o, function (err, outCollection) {\n            expect(err).to.not.exist; // Find all entries in the map-reduce collection\n\n            outCollection.find().toArray(function (err, results) {\n              expect(err).to.not.exist;\n              test.equal(2, results[0].value); // mapReduce with scope containing plain function\n\n              var o = {};\n              o.scope = {\n                fn: t\n              };\n              o.out = {\n                replace: 'replacethiscollection'\n              };\n              collection.mapReduce(map, reduce, o, function (err, outCollection) {\n                expect(err).to.not.exist; // Find all entries in the map-reduce collection\n\n                outCollection.find().toArray(function (err, results) {\n                  expect(err).to.not.exist;\n                  test.equal(2, results[0].value);\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformMapReduceInContextObjects","suites":["Operation Examples"],"line":2163,"code":"  it.skip('shouldPerformMapReduceInContextObjects', {","file":"integration/node-specific/operation_example.test.js","skipped":true,"dir":"test"},{"name":"shouldCorrectlyRetrieveACollectionsIndexes","suites":["Operation Examples"],"updatePoint":{"line":2270,"column":48,"index":70585},"line":2270,"code":"  it('shouldCorrectlyRetrieveACollectionsIndexes', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Crete the collection for the distinct example\n\n        var collection = db.collection('simple_key_based_distinct'); // Create a geo 2d index\n\n        collection.createIndex({\n          loc: '2d'\n        }, configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Create a simple single field index\n\n          collection.createIndex({\n            a: 1\n          }, configuration.writeConcernMax(), function (err, result) {\n            test.ok(result);\n            expect(err).to.not.exist;\n            setTimeout(function () {\n              // List all of the indexes on the collection\n              collection.indexes(function (err, indexes) {\n                test.equal(3, indexes.length);\n                client.close(done);\n              });\n            }, 1000);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteIndexExists","suites":["Operation Examples"],"updatePoint":{"line":2326,"column":39,"index":72624},"line":2326,"code":"  it('shouldCorrectlyExecuteIndexExists', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a test collection that we are getting the options back from\n\n        var collection = db.collection('test_collection_index_exists', configuration.writeConcernMax());\n        expect(err).to.not.exist; // Create an index on the collection\n\n        collection.createIndex('a', configuration.writeConcernMax(), function (err, indexName) {\n          test.ok(indexName);\n          expect(err).to.not.exist; // Let's test to check if a single index exists\n\n          collection.indexExists('a_1', function (err, result) {\n            test.equal(true, result); // Let's test to check if multiple indexes are available\n\n            collection.indexExists(['a_1', '_id_'], function (err, result) {\n              test.equal(true, result); // Check if a non existing index exists\n\n              collection.indexExists('c_1', function (err, result) {\n                test.equal(false, result);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyShowTheResultsFromIndexInformation","suites":["Operation Examples"],"updatePoint":{"line":2380,"column":55,"index":74766},"line":2380,"code":"  it('shouldCorrectlyShowTheResultsFromIndexInformation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection we want to drop later\n\n        var collection = db.collection('more_index_information_test_2'); // Insert a bunch of documents for the index\n\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Create an index on the a field\n\n          collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, indexName) {\n            test.ok(indexName);\n            expect(err).to.not.exist; // Fetch basic indexInformation for collection\n\n            db.indexInformation('more_index_information_test_2', function (err, indexInformation) {\n              test.deepEqual([['_id', 1]], indexInformation._id_);\n              test.deepEqual([['a', 1], ['b', 1]], indexInformation.a_1_b_1); // Fetch full index information\n\n              collection.indexInformation({\n                full: true\n              }, function (err, indexInformation) {\n                test.deepEqual({\n                  _id: 1\n                }, indexInformation[0].key);\n                test.deepEqual({\n                  a: 1,\n                  b: 1\n                }, indexInformation[1].key);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyShowAllTheResultsFromIndexInformation","suites":["Operation Examples"],"updatePoint":{"line":2464,"column":58,"index":77500},"line":2464,"code":"  it('shouldCorrectlyShowAllTheResultsFromIndexInformation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection we want to drop later\n\n        var collection = db.collection('more_index_information_test_3'); // Insert a bunch of documents for the index\n\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Create an index on the a field\n\n          collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, indexName) {\n            test.ok(indexName);\n            expect(err).to.not.exist; // Fetch basic indexInformation for collection\n\n            collection.indexInformation(function (err, indexInformation) {\n              test.deepEqual([['_id', 1]], indexInformation._id_);\n              test.deepEqual([['a', 1], ['b', 1]], indexInformation.a_1_b_1); // Fetch full index information\n\n              collection.indexInformation({\n                full: true\n              }, function (err, indexInformation) {\n                test.deepEqual({\n                  _id: 1\n                }, indexInformation[0].key);\n                test.deepEqual({\n                  a: 1,\n                  b: 1\n                }, indexInformation[1].key);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformASimpleSingleDocumentInsertNoCallbackNoSafe","suites":["Operation Examples"],"updatePoint":{"line":2552,"column":71,"index":80318},"line":2552,"code":"  it('shouldCorrectlyPerformASimpleSingleDocumentInsertNoCallbackNoSafe', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        var collection = db.collection('simple_document_insert_collection_no_safe'); // Insert a single document\n\n        collection.insertOne({\n          hello: 'world_no_safe'\n        }, err => {\n          expect(err).to.not.exist; // Wait for a second before finishing up, to ensure we have written the item to disk\n\n          setTimeout(function () {\n            // Fetch the document\n            collection.findOne({\n              hello: 'world_no_safe'\n            }, function (err, item) {\n              expect(err).to.not.exist;\n              test.equal('world_no_safe', item.hello);\n              client.close(done);\n            });\n          }, 100);\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformABatchDocumentInsertSafe","suites":["Operation Examples"],"updatePoint":{"line":2605,"column":52,"index":82291},"line":2605,"code":"  it('shouldCorrectlyPerformABatchDocumentInsertSafe', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Fetch a collection to insert document into\n\n        var collection = db.collection('batch_document_insert_collection_safe'); // Insert a single document\n\n        collection.insertMany([{\n          hello: 'world_safe1'\n        }, {\n          hello: 'world_safe2'\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Fetch the document\n\n          collection.findOne({\n            hello: 'world_safe2'\n          }, function (err, item) {\n            expect(err).to.not.exist;\n            test.equal('world_safe2', item.hello);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformASimpleDocumentInsertWithFunctionSafe","suites":["Operation Examples"],"updatePoint":{"line":2659,"column":65,"index":84234},"line":2659,"code":"  it('shouldCorrectlyPerformASimpleDocumentInsertWithFunctionSafe', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Fetch a collection to insert document into\n\n        var collection = db.collection('simple_document_insert_with_function_safe');\n        var o = configuration.writeConcernMax();\n        o.serializeFunctions = true; // Insert a single document\n\n        collection.insertOne({\n          hello: 'world',\n          func: function () {}\n        }, o, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Fetch the document\n\n          collection.findOne({\n            hello: 'world'\n          }, function (err, item) {\n            expect(err).to.not.exist;\n            test.ok('function() {}', item.code);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute insert with keepGoing option on mongod >= 1.9.1","suites":["Operation Examples"],"updatePoint":{"line":2714,"column":78,"index":86280},"line":2714,"code":"  it('Should correctly execute insert with keepGoing option on mongod >= 1.9.1', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>1.9.1',\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection\n\n        var collection = db.collection('keepGoingExample'); // Add an unique index to title to force errors in the batch insert\n\n        collection.createIndex({\n          title: 1\n        }, {\n          unique: true\n        }, function (err, indexName) {\n          test.ok(indexName);\n          expect(err).to.not.exist; // Insert some intial data into the collection\n\n          collection.insertMany([{\n            name: 'Jim'\n          }, {\n            name: 'Sarah',\n            title: 'Princess'\n          }], configuration.writeConcernMax(), function (err, result) {\n            test.ok(result);\n            expect(err).to.not.exist; // Force keep going flag, ignoring unique index issue\n\n            collection.insert([{\n              name: 'Jim'\n            }, {\n              name: 'Sarah',\n              title: 'Princess'\n            }, {\n              name: 'Gump',\n              title: 'Gump'\n            }], {\n              writeConcern: {\n                w: 1\n              },\n              keepGoing: true\n            }, function (err, result) {\n              expect(result).to.not.exist;\n              test.ok(err);\n              test.ok(err.result); // Count the number of documents left (should not include the duplicates)\n\n              collection.count(function (err, count) {\n                test.equal(3, count);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteIsCapped","suites":["Operation Examples"],"updatePoint":{"line":2795,"column":36,"index":89021},"line":2795,"code":"  it('shouldCorrectlyExecuteIsCapped', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a test collection that we are getting the options back from\n\n        db.createCollection('test_collection_is_capped', {\n          capped: true,\n          size: 1024\n        }, function (err, collection) {\n          test.equal('test_collection_is_capped', collection.collectionName); // Let's fetch the collection options\n\n          collection.isCapped(function (err, capped) {\n            test.equal(true, capped);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveCollectionOptions","suites":["Operation Examples"],"updatePoint":{"line":2840,"column":46,"index":90628},"line":2840,"code":"  it('shouldCorrectlyRetrieveCollectionOptions', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a test collection that we are getting the options back from\n\n        db.createCollection('test_collection_options', {\n          capped: true,\n          size: 1024\n        }, function (err, collection) {\n          test.equal('test_collection_options', collection.collectionName); // Let's fetch the collection options\n\n          collection.options(function (err, options) {\n            test.equal(true, options.capped);\n            test.ok(options.size >= 1024);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldRemoveAllDocumentsNoSafe","suites":["Operation Examples"],"updatePoint":{"line":2886,"column":36,"index":92290},"line":2886,"code":"  it('shouldRemoveAllDocumentsNoSafe', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist; // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n\n        const db = client.db(configuration.db);\n        const collection = db.collection('remove_all_documents_no_safe'); // Insert a bunch of documents\n\n        collection.insertMany([{\n          a: 1\n        }, {\n          b: 2\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, (err, result) => {\n          expect(err).to.not.exist;\n          expect(result).to.exist; // Remove all the document\n\n          collection.deleteMany((err, result) => {\n            expect(err).to.not.exist;\n            expect(result).to.exist; // Fetch all results\n\n            collection.find().toArray((err, docs) => {\n              expect(err).to.not.exist;\n              expect(docs).to.have.lengthOf(0);\n              client.close(done);\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldRemoveSubsetOfDocumentsSafeMode","suites":["Operation Examples"],"updatePoint":{"line":2945,"column":43,"index":94224},"line":2945,"code":"  it('shouldRemoveSubsetOfDocumentsSafeMode', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Fetch a collection to insert document into\n\n        var collection = db.collection('remove_subset_of_documents_safe'); // Insert a bunch of documents\n\n        collection.insertMany([{\n          a: 1\n        }, {\n          b: 2\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Remove all the document\n\n          collection.deleteOne({\n            a: 1\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('deletedCount').to.equal(1);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRenameCollection","suites":["Operation Examples"],"updatePoint":{"line":3006,"column":37,"index":96119},"line":3006,"code":"  it('shouldCorrectlyRenameCollection', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Open a couple of collections\n\n        db.createCollection('test_rename_collection', function (err, collection1) {\n          db.createCollection('test_rename_collection2', function (err, collection2) {\n            test.ok(collection2);\n            expect(err).to.not.exist; // Attemp to rename a collection to a number\n\n            try {\n              collection1.rename(5, function (err, collection) {}); // eslint-disable-line\n            } catch (err) {\n              test.ok(err instanceof Error);\n              test.equal('Collection name must be a String', err.message);\n            } // Attemp to rename a collection to an empty string\n\n\n            try {\n              collection1.rename('', function (err, collection) {}); // eslint-disable-line\n            } catch (err) {\n              test.ok(err instanceof Error);\n              test.equal('Collection names cannot be empty', err.message);\n            } // Attemp to rename a collection to an illegal name including the character $\n\n\n            try {\n              collection1.rename('te$t', function (err, collection) {}); // eslint-disable-line\n            } catch (err) {\n              test.ok(err instanceof Error);\n              test.equal(\"Collection names must not contain '$'\", err.message);\n            } // Attemp to rename a collection to an illegal name starting with the character .\n\n\n            try {\n              collection1.rename('.test', function (err, collection) {}); // eslint-disable-line\n            } catch (err) {\n              test.ok(err instanceof Error);\n              test.equal(\"Collection names must not start or end with '.'\", err.message);\n            } // Attemp to rename a collection to an illegal name ending with the character .\n\n\n            try {\n              collection1.rename('test.', function (err, collection) {}); // eslint-disable-line\n            } catch (err) {\n              test.ok(err instanceof Error);\n              test.equal(\"Collection names must not start or end with '.'\", err.message);\n            } // Attemp to rename a collection to an illegal name with an empty middle name\n\n\n            try {\n              collection1.rename('tes..t', function (err, collection) {}); // eslint-disable-line\n            } catch (err) {\n              test.equal('Collection names cannot be empty', err.message);\n            } // Insert a couple of documents\n\n\n            collection1.insertMany([{\n              x: 1\n            }, {\n              x: 2\n            }], configuration.writeConcernMax(), function (err, docs) {\n              test.ok(docs);\n              expect(err).to.not.exist; // Attemp to rename the first collection to the second one, this will fail\n\n              collection1.rename('test_rename_collection2', function (err, collection) {\n                expect(collection).to.not.exist;\n                test.ok(err instanceof Error);\n                test.ok(err.message.length > 0); // Attemp to rename the first collection to a name that does not exist\n                // this will be successful\n\n                collection1.rename('test_rename_collection3', function (err, collection2) {\n                  test.equal('test_rename_collection3', collection2.collectionName); // Ensure that the collection is pointing to the new one\n\n                  collection2.count(function (err, count) {\n                    test.equal(2, count);\n                    client.close(done);\n                  });\n                });\n              });\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUpdateASimpleDocument","suites":["Operation Examples"],"updatePoint":{"line":3118,"column":42,"index":100788},"line":3118,"code":"  it('shouldCorrectlyUpdateASimpleDocument', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Get a collection\n\n        var collection = db.collection('update_a_simple_document'); // Insert a document, then update it\n\n        collection.insertOne({\n          a: 1\n        }, configuration.writeConcernMax(), function (err, doc) {\n          test.ok(doc);\n          expect(err).to.not.exist; // Update the document with an atomic operator\n\n          collection.updateOne({\n            a: 1\n          }, {\n            $set: {\n              b: 2\n            }\n          }); // Wait for a second then fetch the document\n\n          setTimeout(function () {\n            // Fetch the document that we modified\n            collection.findOne({\n              a: 1\n            }, function (err, item) {\n              expect(err).to.not.exist;\n              test.equal(1, item.a);\n              test.equal(2, item.b);\n              client.close(done);\n            });\n          }, 1000);\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUpsertASimpleDocument","suites":["Operation Examples"],"updatePoint":{"line":3180,"column":42,"index":102858},"line":3180,"code":"  it('shouldCorrectlyUpsertASimpleDocument', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Get a collection\n\n        var collection = db.collection('update_a_simple_document_upsert'); // Update the document using an upsert operation, ensuring creation if it does not exist\n\n        collection.updateOne({\n          a: 1\n        }, {\n          $set: {\n            b: 2,\n            a: 1\n          }\n        }, {\n          upsert: true,\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          expect(err).to.not.exist;\n          expect(result).property('upsertedCount').to.equal(1); // Fetch the document that we modified and check if it got inserted correctly\n\n          collection.findOne({\n            a: 1\n          }, function (err, item) {\n            expect(err).to.not.exist;\n            test.equal(1, item.a);\n            test.equal(2, item.b);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUpdateMultipleDocuments","suites":["Operation Examples"],"updatePoint":{"line":3241,"column":44,"index":104870},"line":3241,"code":"  it('shouldCorrectlyUpdateMultipleDocuments', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Get a collection\n\n        var collection = db.collection('update_a_simple_document_multi'); // Insert a couple of documentations\n\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 1,\n          b: 2\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n          var o = configuration.writeConcernMax();\n          collection.updateMany({\n            a: 1\n          }, {\n            $set: {\n              b: 0\n            }\n          }, o, function (err, r) {\n            expect(err).to.not.exist;\n            expect(r).property('matchedCount').to.equal(2); // Fetch all the documents and verify that we have changed the b value\n\n            collection.find().toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(1, items[0].a);\n              test.equal(0, items[0].b);\n              test.equal(1, items[1].a);\n              test.equal(0, items[1].b);\n              client.close(done);\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyReturnACollectionsStats","suites":["Operation Examples"],"updatePoint":{"line":3307,"column":44,"index":107073},"line":3307,"code":"  it('shouldCorrectlyReturnACollectionsStats', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Crete the collection for the distinct example\n\n        var collection = db.collection('collection_stats_test'); // Insert some documents\n\n        collection.insertMany([{\n          a: 1\n        }, {\n          hello: 'world'\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Retrieve the statistics for the collection\n\n          collection.stats(function (err, stats) {\n            test.equal(2, stats.count);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateAndDropAllIndex","suites":["Operation Examples"],"updatePoint":{"line":3356,"column":42,"index":108760},"line":3356,"code":"  it('shouldCorrectlyCreateAndDropAllIndex', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection we want to drop later\n\n        var collection = db.collection('shouldCorrectlyCreateAndDropAllIndex'); // Insert a bunch of documents for the index\n\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4,\n          c: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Create an index on the a field\n\n          collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, indexName) {\n            test.ok(indexName);\n            expect(err).to.not.exist; // Create an additional index\n\n            collection.createIndex({\n              c: 1\n            }, {\n              unique: true,\n              background: true,\n              writeConcern: {\n                w: 1\n              }\n            }, function () {\n              // Drop the index\n              collection.dropIndexes(function (err, result) {\n                test.ok(result);\n                expect(err).to.not.exist; // Verify that the index is gone\n\n                collection.indexInformation(function (err, indexInformation) {\n                  test.deepEqual([['_id', 1]], indexInformation._id_);\n                  expect(indexInformation.a_1_b_1).to.not.exist;\n                  expect(indexInformation.c_1).to.not.exist;\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"accessAdminLevelOperations","suites":["Operation Examples"],"updatePoint":{"line":3456,"column":32,"index":111824},"line":3456,"code":"  it('accessAdminLevelOperations', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Use the admin database for the operation\n\n        var adminDb = db.admin();\n        test.ok(adminDb != null);\n        client.close(done);\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyOpenASimpleDbSingleServerConnection","suites":["Operation Examples"],"updatePoint":{"line":3493,"column":56,"index":113088},"line":3493,"code":"  it('shouldCorrectlyOpenASimpleDbSingleServerConnection', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      }); // NODE-2484: investigate double close event in Unified Topology environment\n      // client.on('close', function() {\n      //   done();\n      // });\n\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        expect(err).to.not.exist;\n        client.close(done);\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyOpenASimpleDbSingleServerConnectionAndCloseWithCallback","suites":["Operation Examples"],"updatePoint":{"line":3531,"column":76,"index":114418},"line":3531,"code":"  it('shouldCorrectlyOpenASimpleDbSingleServerConnectionAndCloseWithCallback', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist; // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        // Close the connection with a callback that is optional\n\n        client.close(function (err) {\n          expect(err).to.not.exist;\n          done();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrievelistCollections","suites":["Operation Examples"],"updatePoint":{"line":3569,"column":44,"index":115701},"line":3569,"code":"  it('shouldCorrectlyRetrievelistCollections', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist; // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        // Get an empty db\n\n        var db1 = client.db('listCollectionTestDb'); // Create a collection\n\n        var collection = db1.collection('shouldCorrectlyRetrievelistCollections'); // Ensure the collection was created\n\n        collection.insertOne({\n          a: 1\n        }, function (err, r) {\n          test.ok(r);\n          expect(err).to.not.exist; // Return the information of a single collection name\n\n          db1.listCollections({\n            name: 'shouldCorrectlyRetrievelistCollections'\n          }).toArray(function (err, items) {\n            expect(err).to.not.exist;\n            test.equal(1, items.length); // Return the information of a all collections, using the callback format\n\n            db1.listCollections().toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.ok(items.length >= 1);\n              client.close(done);\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrievelistCollectionsWiredTiger","suites":["Operation Examples"],"updatePoint":{"line":3619,"column":54,"index":117595},"line":3619,"code":"  it('shouldCorrectlyRetrievelistCollectionsWiredTiger', {\n    metadata: {\n      requires: {\n        topology: ['wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist; // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        // Get an empty db\n\n        var db1 = client.db('listCollectionTestDb2'); // Create a collection\n\n        var collection = db1.collection('shouldCorrectlyRetrievelistCollections'); // Ensure the collection was created\n\n        collection.insertOne({\n          a: 1\n        }, function (err, r) {\n          test.ok(r);\n          expect(err).to.not.exist; // Return the information of a single collection name\n\n          db1.listCollections({\n            name: 'shouldCorrectlyRetrievelistCollections'\n          }).toArray(function (err, items) {\n            test.equal(1, items.length); // Return the information of a all collections, using the callback format\n\n            db1.listCollections().toArray(function (err, items) {\n              test.equal(1, items.length);\n              client.close(done);\n            });\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveAllCollections","suites":["Operation Examples"],"updatePoint":{"line":3674,"column":43,"index":119510},"line":3674,"code":"  it('shouldCorrectlyRetrieveAllCollections', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Retry to get the collection, should work as it's now created\n\n        db.collections(function (err, collections) {\n          expect(err).to.not.exist;\n          test.ok(collections.length > 0);\n          client.close(done);\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyAddUserToDb","suites":["Operation Examples"],"updatePoint":{"line":3714,"column":32,"index":120879},"line":3714,"code":"  it('shouldCorrectlyAddUserToDb', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Add a user to the database\n\n        db.addUser('user', 'name', function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Remove the user from the db\n\n          db.removeUser('user', function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"should correctly create a collection","suites":["Operation Examples"],"updatePoint":{"line":3759,"column":42,"index":122350},"line":3759,"code":"  it('should correctly create a collection', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Create a capped collection with a maximum of 1000 documents\n\n        db.createCollection('a_simple_collection', {\n          capped: true,\n          size: 10000,\n          max: 1000,\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, collection) {\n          expect(err).to.not.exist; // Insert a document in the capped collection\n\n          collection.insertOne({\n            a: 1\n          }, configuration.writeConcernMax(), function (err, result) {\n            test.ok(result);\n            expect(err).to.not.exist;\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteACommandAgainstTheServer","suites":["Operation Examples"],"updatePoint":{"line":3812,"column":52,"index":124168},"line":3812,"code":"  it('shouldCorrectlyExecuteACommandAgainstTheServer', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Execute ping against the server\n\n        db.command({\n          ping: 1\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Create a capped collection with a maximum of 1000 documents\n\n          db.createCollection('a_simple_create_drop_collection', {\n            capped: true,\n            size: 10000,\n            max: 1000,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, collection) {\n            expect(err).to.not.exist; // Insert a document in the capped collection\n\n            collection.insertOne({\n              a: 1\n            }, configuration.writeConcernMax(), function (err, result) {\n              test.ok(result);\n              expect(err).to.not.exist; // Drop the collection from this world\n\n              db.dropCollection('a_simple_create_drop_collection', function (err, result) {\n                test.ok(result);\n                expect(err).to.not.exist; // Verify that the collection is gone\n\n                db.listCollections({\n                  name: 'a_simple_create_drop_collection'\n                }).toArray(function (err, names) {\n                  test.equal(0, names.length);\n                  client.close(done);\n                });\n              });\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateDropAndVerifyThatCollectionIsGone","suites":["Operation Examples"],"updatePoint":{"line":3883,"column":60,"index":126660},"line":3883,"code":"  it('shouldCorrectlyCreateDropAndVerifyThatCollectionIsGone', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Execute ping against the server\n\n        db.command({\n          ping: 1\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRenameACollection","suites":["Operation Examples"],"updatePoint":{"line":3925,"column":38,"index":128073},"line":3925,"code":"  it('shouldCorrectlyRenameACollection', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Create a collection\n\n        db.createCollection('simple_rename_collection', configuration.writeConcernMax(), function (err, collection) {\n          expect(err).to.not.exist; // Insert a document in the collection\n\n          collection.insertOne({\n            a: 1\n          }, configuration.writeConcernMax(), function (err, result) {\n            test.ok(result);\n            expect(err).to.not.exist; // Retrieve the number of documents from the collection\n\n            collection.count(function (err, count) {\n              expect(err).to.not.exist;\n              test.equal(1, count); // Rename the collection\n\n              db.renameCollection('simple_rename_collection', 'simple_rename_collection_2', function (err, collection2) {\n                expect(err).to.not.exist; // Retrieve the number of documents from the collection\n\n                collection2.count(function (err, count) {\n                  test.equal(1, count); // Verify that the collection is gone\n\n                  db.listCollections({\n                    name: 'simple_rename_collection'\n                  }).toArray(function (err, names) {\n                    test.equal(0, names.length); // Verify that the new collection exists\n\n                    db.listCollections({\n                      name: 'simple_rename_collection_2'\n                    }).toArray(function (err, names) {\n                      test.equal(1, names.length);\n                      client.close(done);\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCreateOnDbComplexIndexOnTwoFields","suites":["Operation Examples"],"updatePoint":{"line":3996,"column":45,"index":130868},"line":3996,"code":"  it('shouldCreateOnDbComplexIndexOnTwoFields', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection we want to drop later\n\n        var collection = db.collection('more_complex_index_test'); // Insert a bunch of documents for the index\n\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Create an index on the a field\n\n          db.createIndex('more_complex_index_test', {\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, indexName) {\n            test.ok(indexName);\n            expect(err).to.not.exist; // Show that duplicate records got dropped\n\n            collection.find({}).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(4, items.length); // Perform a query, with explain to show we hit the query\n\n              collection.find({\n                a: 2\n              }).explain(function (err, explanation) {\n                expect(err).to.not.exist;\n                test.ok(explanation != null);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCreateComplexEnsureIndexDb","suites":["Operation Examples"],"updatePoint":{"line":4075,"column":38,"index":133436},"line":4075,"code":"  it('shouldCreateComplexEnsureIndexDb', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection we want to drop later\n\n        var collection = db.collection('more_complex_ensure_index_db_test'); // Insert a bunch of documents for the index\n\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Create an index on the a field\n\n          db.createIndex('more_complex_ensure_index_db_test', {\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, indexName) {\n            test.ok(indexName);\n            expect(err).to.not.exist; // Show that duplicate records got dropped\n\n            collection.find({}).toArray(function (err, items) {\n              expect(err).to.not.exist;\n              test.equal(4, items.length); // Perform a query, with explain to show we hit the query\n\n              collection.find({\n                a: 2\n              }).explain(function (err, explanation) {\n                expect(err).to.not.exist;\n                test.ok(explanation != null);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"should correctly drop the database","suites":["Operation Examples"],"updatePoint":{"line":4154,"column":40,"index":135964},"line":4154,"code":"  it('should correctly drop the database', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection\n\n        var collection = db.collection('more_index_information_test_1'); // Insert a bunch of documents for the index\n\n        collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Let's drop the database\n\n          db.dropDatabase(function (err, result) {\n            test.ok(result);\n            expect(err).to.not.exist; // Wait two seconds to let it replicate across\n\n            setTimeout(function () {\n              // Get the admin database\n              db.admin().listDatabases(function (err, dbs) {\n                // Grab the databases\n                dbs = dbs.databases; // Did we find the db\n\n                var found = false; // Check if we have the db in the list\n\n                for (var i = 0; i < dbs.length; i++) {\n                  if (dbs[i].name === 'integration_tests_to_drop') found = true;\n                } // We should not find the databases\n\n\n                if (process.env['JENKINS'] == null) test.equal(false, found);\n                client.close(done);\n              });\n            }, 2000);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveDbStats","suites":["Operation Examples"],"updatePoint":{"line":4232,"column":36,"index":138409},"line":4232,"code":"  it('shouldCorrectlyRetrieveDbStats', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        db.stats(function (err, stats) {\n          expect(err).to.not.exist;\n          test.ok(stats != null);\n          client.close(done);\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyShareConnectionPoolsAcrossMultipleDbInstances","suites":["Operation Examples"],"updatePoint":{"line":4271,"column":66,"index":139767},"line":4271,"code":"  it('shouldCorrectlyShareConnectionPoolsAcrossMultipleDbInstances', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Reference a different database sharing the same connections\n        // for the data transfer\n\n        var secondDb = client.db('integration_tests_2'); // Fetch the collections\n\n        var multipleColl1 = db.collection('multiple_db_instances');\n        var multipleColl2 = secondDb.collection('multiple_db_instances'); // Write a record into each and then count the records stored\n\n        multipleColl1.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist;\n          multipleColl2.insertOne({\n            a: 1\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          }, function (err, result) {\n            test.ok(result);\n            expect(err).to.not.exist; // Count over the results ensuring only on record in each collection\n\n            multipleColl1.count(function (err, count) {\n              test.equal(1, count);\n              multipleColl2.count(function (err, count) {\n                test.equal(1, count);\n                client.close(done);\n              });\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly connect with default replicasetNoOption","suites":["Operation Examples"],"updatePoint":{"line":4340,"column":62,"index":142155},"line":4340,"code":"  it('Should correctly connect with default replicasetNoOption', {\n    metadata: {\n      requires: {\n        topology: 'replicaset'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration; // Replica configuration\n\n      var client = new Topology(configuration.options.hostAddresses, {\n        replicaSet: configuration.replicasetName\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist; // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n\n        client.close(done);\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveBuildInfo","suites":["Operation Examples"],"updatePoint":{"line":4381,"column":38,"index":143459},"line":4381,"code":"  it('shouldCorrectlyRetrieveBuildInfo', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Use the admin database for the operation\n\n        var adminDb = db.admin(); // Retrieve the build information for the MongoDB instance\n\n        adminDb.buildInfo(function (err, info) {\n          test.ok(info);\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveBuildInfoUsingCommand","suites":["Operation Examples"],"updatePoint":{"line":4422,"column":50,"index":144816},"line":4422,"code":"  it('shouldCorrectlyRetrieveBuildInfoUsingCommand', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Use the admin database for the operation\n\n        var adminDb = db.admin(); // Retrieve the build information using the admin command\n\n        adminDb.command({\n          buildInfo: 1\n        }, function (err, info) {\n          test.ok(info);\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCallValidateCollection","suites":["Operation Examples"],"updatePoint":{"line":4466,"column":43,"index":146319},"line":4466,"code":"  it('shouldCorrectlyCallValidateCollection', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Grab a collection object\n\n        var collection = db.collection('test'); // Force the creation of the collection by inserting a document\n        // Collections are not created until the first document is inserted\n\n        collection.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, doc) {\n          test.ok(doc);\n          expect(err).to.not.exist; // Use the admin database for the operation\n\n          var adminDb = db.admin(); // Validate the 'test' collection\n\n          adminDb.validateCollection('test', function (err, doc) {\n            test.ok(doc);\n            expect(err).to.not.exist;\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPingTheMongoDbInstance","suites":["Operation Examples"],"updatePoint":{"line":4521,"column":43,"index":148102},"line":4521,"code":"  it('shouldCorrectlyPingTheMongoDbInstance', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Use the admin database for the operation\n\n        var adminDb = db.admin(); // Ping the server\n\n        adminDb.ping(function (err, pingResult) {\n          test.ok(pingResult);\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyAddAUserToAdminDb","suites":["Operation Examples"],"updatePoint":{"line":4562,"column":38,"index":149418},"line":4562,"code":"  it('shouldCorrectlyAddAUserToAdminDb', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Use the admin database for the operation\n\n        var adminDb = db.admin(); // Add the new user to the admin database\n\n        adminDb.addUser('admin11', 'admin11', function (err, result) {\n          expect(err).to.not.exist;\n          test.ok(result);\n          adminDb.removeUser('admin11', function (err, result) {\n            expect(err).to.not.exist;\n            test.ok(result);\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyAddAUserAndRemoveItFromAdminDb","suites":["Operation Examples"],"updatePoint":{"line":4607,"column":51,"index":150936},"line":4607,"code":"  it('shouldCorrectlyAddAUserAndRemoveItFromAdminDb', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Use the admin database for the operation\n\n        var adminDb = db.admin(); // Add the new user to the admin database\n\n        adminDb.addUser('admin12', 'admin12', function (err, result) {\n          test.ok(result); // Remove the user\n\n          adminDb.removeUser('admin12', function (err, result) {\n            expect(err).to.not.exist;\n            test.equal(true, result);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"should correctly list all available databases","suites":["Operation Examples"],"updatePoint":{"line":4652,"column":51,"index":152445},"line":4652,"code":"  it('should correctly list all available databases', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Use the admin database for the operation\n\n        var adminDb = db.admin(); // List all the available databases\n\n        adminDb.listDatabases(function (err, dbs) {\n          expect(err).to.not.exist;\n          test.ok(dbs.databases.length > 0);\n          client.close(done);\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"should correctly list all available databases names and no database sizes","suites":["Operation Examples"],"updatePoint":{"line":4686,"column":79,"index":153759},"line":4686,"code":"  it('should correctly list all available databases names and no database sizes', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger'],\n        mongodb: '>=3.2.13'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Use the admin database for the operation\n\n        var adminDb = db.admin(); // List all the available databases\n\n        adminDb.listDatabases({\n          nameOnly: 1\n        }, function (err, dbs) {\n          expect(err).to.not.exist;\n          expect(dbs.databases).to.containSubset([{\n            name: 'admin'\n          }]);\n          client.close(done);\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveServerInfo","suites":["Operation Examples"],"updatePoint":{"line":4732,"column":39,"index":155261},"line":4732,"code":"  it('shouldCorrectlyRetrieveServerInfo', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Grab a collection object\n\n        var collection = db.collection('test'); // Force the creation of the collection by inserting a document\n        // Collections are not created until the first document is inserted\n\n        collection.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, doc) {\n          test.ok(doc);\n          expect(err).to.not.exist; // Use the admin database for the operation\n\n          var adminDb = db.admin(); // Retrieve the server Info\n\n          adminDb.serverStatus(function (err, info) {\n            expect(err).to.not.exist;\n            test.ok(info != null);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveReplSetGetStatus","suites":["Operation Examples"],"updatePoint":{"line":4787,"column":45,"index":157089},"line":4787,"code":"  it('shouldCorrectlyRetrieveReplSetGetStatus', {\n    metadata: {\n      requires: {\n        topology: 'replicaset'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        // Grab a collection object\n\n        var collection = db.collection('test'); // Force the creation of the collection by inserting a document\n        // Collections are not created until the first document is inserted\n\n        collection.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, doc) {\n          test.ok(doc);\n          expect(err).to.not.exist; // Use the admin database for the operation\n\n          var adminDb = db.admin(); // Retrieve the server Info, returns error if we are not\n          // running a replicaset\n\n          adminDb.replSetGetStatus(function (err, info) {\n            test.ok(info);\n            expect(err).to.not.exist;\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteToArray","suites":["Operation Examples"],"updatePoint":{"line":4849,"column":35,"index":159123},"line":4849,"code":"  it('shouldCorrectlyExecuteToArray', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection to hold our documents\n\n        var collection = db.collection('test_array'); // Insert a test document\n\n        collection.insertOne({\n          b: [1, 2, 3]\n        }, configuration.writeConcernMax(), function (err, ids) {\n          test.ok(ids);\n          expect(err).to.not.exist; // Retrieve all the documents in the collection\n\n          collection.find().toArray(function (err, documents) {\n            test.equal(1, documents.length);\n            test.deepEqual([1, 2, 3], documents[0].b);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyFailToArrayDueToFinishedEachOperation","suites":["Operation Examples"],"updatePoint":{"line":4899,"column":58,"index":160989},"line":4899,"code":"  it('shouldCorrectlyFailToArrayDueToFinishedEachOperation', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection\n\n        var collection = db.collection('test_to_a_after_each'); // Insert a document in the collection\n\n        collection.insertOne({\n          a: 1\n        }, configuration.writeConcernMax(), function (err, ids) {\n          test.ok(ids);\n          expect(err).to.not.exist; // Grab a cursor\n\n          var cursor = collection.find(); // Execute the each command, triggers for each document\n\n          cursor.forEach(() => {}, err => {\n            expect(err).to.not.exist; // Show that the cursor is closed\n\n            cursor.toArray((err, docs) => {\n              expect(err).to.not.exist;\n              expect(docs).to.exist; // Let's close the db\n\n              client.close(done);\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly iterate over cursor using forEach","suites":["Operation Examples"],"updatePoint":{"line":4956,"column":56,"index":163035},"line":4956,"code":"  it('Should correctly iterate over cursor using forEach', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection\n\n        var collection = db.collection('test_to_a_after_for_each'); // Insert a document in the collection\n\n        collection.insertOne({\n          a: 1\n        }, configuration.writeConcernMax(), function (err, ids) {\n          test.ok(ids);\n          expect(err).to.not.exist; // Count of documents returned\n\n          var count = 0; // Grab a cursor\n\n          var cursor = collection.find(); // Execute the each command, triggers for each document\n\n          cursor.forEach(function (doc) {\n            test.ok(doc != null);\n            count = count + 1;\n          }, function (err) {\n            expect(err).to.not.exist;\n            test.equal(1, count);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly rewind and restart cursor","suites":["Operation Examples"],"updatePoint":{"line":5013,"column":48,"index":165045},"line":5013,"code":"  it('Should correctly rewind and restart cursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        var docs = []; // Insert 100 documents with some data\n\n        for (var i = 0; i < 100; i++) {\n          var d = new Date().getTime() + i * 1000;\n          docs[i] = {\n            a: i,\n            createdAt: new Date(d)\n          };\n        } // Create collection\n\n\n        var collection = db.collection('Should_correctly_rewind_and_restart_cursor'); // insert all docs\n\n        collection.insertMany(docs, configuration.writeConcernMax(), function (err, result) {\n          test.ok(result);\n          expect(err).to.not.exist; // Grab a cursor using the find\n\n          var cursor = collection.find({}); // Fetch the first object off the cursor\n\n          cursor.next(function (err, item) {\n            test.equal(0, item.a); // Rewind the cursor, resetting it to point to the start of the query\n\n            cursor.rewind(); // Grab the first object again\n\n            cursor.next(function (err, item) {\n              test.equal(0, item.a);\n              client.close(done);\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUseCursorCountFunction","suites":["Operation Examples"],"updatePoint":{"line":5078,"column":43,"index":167328},"line":5078,"code":"  it('shouldCorrectlyUseCursorCountFunction', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Creat collection\n\n        var collection = db.collection('cursor_count_collection'); // Insert some docs\n\n        collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }], configuration.writeConcernMax(), function (err, docs) {\n          test.ok(docs);\n          expect(err).to.not.exist; // Do a find and get the cursor count\n\n          collection.find().count(function (err, count) {\n            expect(err).to.not.exist;\n            test.equal(2, count);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformSimpleSorts","suites":["Operation Examples"],"updatePoint":{"line":5130,"column":39,"index":169115},"line":5130,"code":"  it('shouldCorrectlyPerformSimpleSorts', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection\n\n        var collection = db.collection('simple_sort_collection'); // Insert some documents we can sort on\n\n        collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax(), function (err, docs) {\n          test.ok(docs);\n          expect(err).to.not.exist; // Do normal ascending sort\n\n          collection.find().sort({\n            a: 1\n          }).next(function (err, item) {\n            expect(err).to.not.exist;\n            test.equal(1, item.a); // Do normal descending sort, with new syntax that enforces ordering of sort keys\n\n            collection.find().sort([['a', -1]]).next(function (err, item) {\n              expect(err).to.not.exist;\n              test.equal(3, item.a);\n              client.close(done);\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformLimitOnCursor","suites":["Operation Examples"],"updatePoint":{"line":5191,"column":41,"index":171235},"line":5191,"code":"  it('shouldCorrectlyPerformLimitOnCursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection\n\n        var collection = db.collection('simple_limit_collection'); // Insert some documents we can sort on\n\n        collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax(), function (err, docs) {\n          test.ok(docs);\n          expect(err).to.not.exist; // Limit to only one document returned\n\n          collection.find().limit(1).toArray(function (err, items) {\n            expect(err).to.not.exist;\n            test.equal(1, items.length);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformSkipOnCursor","suites":["Operation Examples"],"updatePoint":{"line":5245,"column":40,"index":173092},"line":5245,"code":"  it('shouldCorrectlyPerformSkipOnCursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection\n\n        var collection = db.collection('simple_skip_collection'); // Insert some documents we can sort on\n\n        collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax(), function (err, docs) {\n          test.ok(docs);\n          expect(err).to.not.exist; // Skip one document\n\n          collection.find().skip(1).next(function (err, item) {\n            expect(err).to.not.exist;\n            test.equal(2, item.a);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformBatchSizeOnCursor","suites":["Operation Examples"],"updatePoint":{"line":5300,"column":45,"index":175064},"line":5300,"code":"  it('shouldCorrectlyPerformBatchSizeOnCursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        this.defer(() => client.close()); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n\n        const db = client.db(configuration.db); // Create a collection\n\n        const collection = db.collection('simple_batch_size_collection'); // Insert some documents we can sort on\n\n        collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax(), (err, docs) => {\n          test.ok(docs);\n          expect(err).to.not.exist; // Do normal ascending sort\n\n          const cursor = collection.find().batchSize(1);\n          this.defer(() => cursor.close());\n          cursor.next((err, item) => {\n            expect(err).to.not.exist;\n            test.equal(1, item.a);\n            done();\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformNextOnCursorWithCallbacks","suites":["Operation Examples"],"updatePoint":{"line":5358,"column":53,"index":177029},"line":5358,"code":"  it('shouldCorrectlyPerformNextOnCursorWithCallbacks', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection\n\n        var collection = db.collection('simple_next_object_collection_with_next'); // Insert some documents we can sort on\n\n        collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax(), function (err, docs) {\n          test.ok(docs);\n          expect(err).to.not.exist; // Do normal ascending sort\n\n          var cursor = collection.find(); // Perform hasNext check\n\n          cursor.hasNext(function (err, r) {\n            expect(err).to.not.exist;\n            test.ok(r);\n            cursor.next(function (err, r) {\n              expect(err).to.not.exist;\n              test.equal(1, r.a);\n              cursor.hasNext(function (err, r) {\n                expect(err).to.not.exist;\n                test.ok(r);\n                cursor.next(function (err, r) {\n                  expect(err).to.not.exist;\n                  test.equal(2, r.a);\n                  cursor.hasNext(function (err, r) {\n                    expect(err).to.not.exist;\n                    test.ok(r);\n                    cursor.next(function (err, r) {\n                      expect(err).to.not.exist;\n                      test.equal(3, r.a);\n                      cursor.hasNext(function (err, r) {\n                        expect(err).to.not.exist;\n                        test.ok(!r);\n                        client.close(done);\n                      });\n                    });\n                  });\n                });\n              });\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformSimpleExplainCursor","suites":["Operation Examples"],"updatePoint":{"line":5438,"column":47,"index":179860},"line":5438,"code":"  it('shouldCorrectlyPerformSimpleExplainCursor', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a collection\n\n        var collection = db.collection('simple_explain_collection'); // Insert some documents we can sort on\n\n        collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax(), function (err, docs) {\n          test.ok(docs);\n          expect(err).to.not.exist; // Do normal ascending sort\n\n          collection.find().explain(function (err, explanation) {\n            test.ok(explanation);\n            expect(err).to.not.exist;\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldStreamDocumentsUsingTheStreamFunction","suites":["Operation Examples"],"updatePoint":{"line":5492,"column":49,"index":181718},"line":5492,"code":"  it('shouldStreamDocumentsUsingTheStreamFunction', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a lot of documents to insert\n\n        var docs = [];\n\n        for (var i = 0; i < 100; i++) {\n          docs.push({\n            a: i\n          });\n        } // Create a collection\n\n\n        var collection = db.collection('test_stream_function'); // Insert documents into collection\n\n        collection.insertMany(docs, configuration.writeConcernMax(), function (err, ids) {\n          test.ok(ids);\n          expect(err).to.not.exist; // Perform a find to get a cursor\n\n          var stream = collection.find().stream(); // Execute find on all the documents\n\n          stream.on('end', function () {\n            client.close(done);\n          });\n          stream.on('data', function (data) {\n            test.ok(data != null);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldStreamDocumentsUsingTheIsCloseFunction","suites":["Operation Examples"],"updatePoint":{"line":5549,"column":50,"index":183686},"line":5549,"code":"  it('shouldStreamDocumentsUsingTheIsCloseFunction', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a lot of documents to insert\n\n        var docs = [];\n\n        for (var i = 0; i < 100; i++) {\n          docs.push({\n            a: i\n          });\n        } // Create a collection\n\n\n        var collection = db.collection('test_is_close_function_on_cursor'); // Insert documents into collection\n\n        collection.insertMany(docs, configuration.writeConcernMax(), function (err, ids) {\n          test.ok(ids);\n          expect(err).to.not.exist; // Perform a find to get a cursor\n\n          var cursor = collection.find(); // Fetch the first object\n\n          cursor.next(function (err, object) {\n            test.ok(object);\n            expect(err).to.not.exist; // Close the cursor, this is the same as reseting the query\n\n            cursor.close(function (err) {\n              expect(err).to.not.exist;\n              test.equal(true, cursor.closed);\n              client.close(done);\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldStreamDocumentsUsingTheCloseFunction","suites":["Operation Examples"],"updatePoint":{"line":5613,"column":48,"index":185889},"line":5613,"code":"  it('shouldStreamDocumentsUsingTheCloseFunction', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a lot of documents to insert\n\n        var docs = [];\n\n        for (var i = 0; i < 100; i++) {\n          docs.push({\n            a: i\n          });\n        } // Create a collection\n\n\n        var collection = db.collection('test_close_function_on_cursor'); // Insert documents into collection\n\n        collection.insertMany(docs, configuration.writeConcernMax(), function (err, ids) {\n          test.ok(ids);\n          expect(err).to.not.exist; // Perform a find to get a cursor\n\n          var cursor = collection.find(); // Fetch the first object\n\n          cursor.next(function (err, object) {\n            test.ok(object);\n            expect(err).to.not.exist; // Close the cursor, this is the same as reseting the query\n\n            cursor.close(function (err) {\n              expect(err).to.not.exist;\n              client.close(done);\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldStreamDocumentsUsingTheCursorStreamPauseFunction","suites":["Operation Examples"],"updatePoint":{"line":5676,"column":60,"index":188061},"line":5676,"code":"  it('shouldStreamDocumentsUsingTheCursorStreamPauseFunction', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a lot of documents to insert\n\n        var docs = [];\n        var fetchedDocs = [];\n\n        for (var i = 0; i < 2; i++) {\n          docs.push({\n            a: i\n          });\n        } // Create a collection\n\n\n        var collection = db.collection('test_cursorstream_pause'); // Insert documents into collection\n\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, ids) {\n          test.ok(ids);\n          expect(err).to.not.exist; // Perform a find to get a cursor\n\n          var stream = collection.find().stream(); // For each data item\n\n          stream.on('data', function (item) {\n            fetchedDocs.push(item); // Pause stream\n\n            stream.pause(); // Restart the stream after 1 miliscecond\n\n            setTimeout(function () {\n              fetchedDocs.push(null);\n              stream.resume();\n            }, 1);\n          }); // When the stream is done\n\n          stream.on('end', function () {\n            expect(fetchedDocs[1]).to.not.exist;\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldStreamDocumentsUsingTheCursorStreamDestroyFunction","suites":["Operation Examples"],"updatePoint":{"line":5748,"column":62,"index":190320},"line":5748,"code":"  it('shouldStreamDocumentsUsingTheCursorStreamDestroyFunction', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Create a lot of documents to insert\n\n        var docs = [];\n\n        for (var i = 0; i < 1; i++) {\n          docs.push({\n            a: i\n          });\n        } // Create a collection\n\n\n        var collection = db.collection('test_cursorstream_destroy'); // Insert documents into collection\n\n        collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, ids) {\n          test.ok(ids);\n          expect(err).to.not.exist; // Perform a find to get a cursor\n\n          const cursor = collection.find();\n          const stream = cursor.stream(); // For each data item\n\n          stream.on('data', function () {\n            // Destroy stream\n            stream.destroy();\n          }); // When the stream is done\n\n          cursor.on('close', function () {\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly connect to a replicaset","suites":["Operation Examples"],"updatePoint":{"line":5818,"column":46,"index":192517},"line":5818,"code":"  it('Should correctly connect to a replicaset', {\n    metadata: {\n      requires: {\n        topology: 'replicaset'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration; // Create url\n\n      var url = f('mongodb://%s,%s/%s?replicaSet=%s&readPreference=%s', f('%s:%s', configuration.host, configuration.port), f('%s:%s', configuration.host, configuration.port + 1), 'integration_test_', configuration.replicasetName, 'primary');\n      const client = configuration.newClient(url);\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n\n        test.ok(db != null);\n        db.collection('replicaset_mongo_client_collection').updateOne({\n          a: 1\n        }, {\n          $set: {\n            b: 1\n          }\n        }, {\n          upsert: true\n        }, function (err, result) {\n          expect(err).to.not.exist;\n          expect(result).property('upsertedCount').to.equal(1);\n          client.close(done);\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should connect to mongos proxies using connectiong string","suites":["Operation Examples"],"updatePoint":{"line":5865,"column":63,"index":194228},"line":5865,"code":"  it('Should connect to mongos proxies using connectiong string', {\n    metadata: {\n      requires: {\n        topology: 'sharded'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var url = f('mongodb://%s:%s,%s:%s/sharded_test_db?w=1', configuration.host, configuration.port, configuration.host, configuration.port + 1);\n      const client = configuration.newClient(url);\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        test.ok(db != null);\n        db.collection('replicaset_mongo_client_collection').updateOne({\n          a: 1\n        }, {\n          $set: {\n            b: 1\n          }\n        }, {\n          upsert: true\n        }, function (err, result) {\n          expect(err).to.not.exist;\n          test.equal(1, result.upsertedCount);\n          client.close(done);\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly connect using MongoClient to a single server using connect","suites":["Operation Examples"],"updatePoint":{"line":5911,"column":81,"index":195821},"line":5911,"code":"  it('Should correctly connect using MongoClient to a single server using connect', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      const client = configuration.newClient(); // DOC_START\n      // Connect using the connection string\n\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        db.collection('mongoclient_test').updateOne({\n          a: 1\n        }, {\n          $set: {\n            b: 1\n          }\n        }, {\n          upsert: true\n        }, function (err, result) {\n          expect(err).to.not.exist;\n          expect(result).property('upsertedCount').to.equal(1);\n          client.close(done);\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyGenerate12ByteStringFromTimestamp","suites":["Operation Examples"],"updatePoint":{"line":5967,"column":54,"index":197639},"line":5967,"code":"  it('shouldCorrectlyGenerate12ByteStringFromTimestamp', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      // LINE var ObjectId = require('mongodb').ObjectId,\n      // LINE   test = require('assert');\n      // REPLACE configuration.writeConcernMax() WITH {w:1}\n      // REMOVE-LINE done();\n      // BEGIN\n      // Get a timestamp in seconds\n      var timestamp = Math.floor(new Date().getTime() / 1000); // Create a date with the timestamp\n\n      var timestampDate = new Date(timestamp * 1000); // Create a new ObjectId with a specific timestamp\n\n      var objectId = new ObjectId(timestamp); // Get the timestamp and validate correctness\n\n      test.equal(timestampDate.toString(), objectId.getTimestamp().toString());\n      done(); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieve24CharacterHexStringFromToHexString","suites":["Operation Examples"],"updatePoint":{"line":5997,"column":64,"index":198671},"line":5997,"code":"  it('shouldCorrectlyRetrieve24CharacterHexStringFromToHexString', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      // LINE var ObjectId = require('mongodb').ObjectId,\n      // LINE   test = require('assert');\n      // REPLACE configuration.writeConcernMax() WITH {w:1}\n      // REMOVE-LINE done();\n      // BEGIN\n      // Create a new ObjectId\n      var objectId = new ObjectId(); // Verify that the hex string is 24 characters long\n\n      test.equal(24, objectId.toHexString().length);\n      done(); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyGetAndSetObjectIdUsingGenerationTimeProperty","suites":["Operation Examples"],"updatePoint":{"line":6023,"column":65,"index":199448},"line":6023,"code":"  it('shouldCorrectlyGetAndSetObjectIdUsingGenerationTimeProperty', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      // LINE var ObjectId = require('mongodb').ObjectId,\n      // LINE   test = require('assert');\n      // REPLACE configuration.writeConcernMax() WITH {w:1}\n      // REMOVE-LINE done();\n      // BEGIN\n      // Create a new ObjectId\n      var objectId = new ObjectId(); // Get the generation time\n\n      var generationTime = objectId.generationTime; // Add 1000 milliseconds to the generation time\n\n      objectId.generationTime = generationTime + 1000; // Create a timestamp\n\n      var timestampDate = new Date();\n      timestampDate.setTime((generationTime + 1000) * 1000); // Get the timestamp and validate correctness\n\n      test.equal(timestampDate.toString(), objectId.getTimestamp().toString());\n      done(); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyTransformObjectIdToHexAndObjectId","suites":["Operation Examples"],"updatePoint":{"line":6056,"column":54,"index":200579},"line":6056,"code":"  it('shouldCorrectlyTransformObjectIdToHexAndObjectId', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      // LINE var ObjectId = require('mongodb').ObjectId,\n      // LINE   test = require('assert');\n      // REPLACE configuration.writeConcernMax() WITH {w:1}\n      // REMOVE-LINE done();\n      // BEGIN\n      // Create a new ObjectId\n      var objectId = new ObjectId(); // Convert the object id to a hex string\n\n      var originalHex = objectId.toHexString(); // Create a new ObjectId using the createFromHexString function\n\n      var newObjectId = ObjectId.createFromHexString(originalHex); // Convert the new ObjectId back into a hex string using the toHexString function\n\n      var newHex = newObjectId.toHexString(); // Compare the two hex strings\n\n      test.equal(originalHex, newHex);\n      done(); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDifferentiateBetweenObjectIdInstances","suites":["Operation Examples"],"updatePoint":{"line":6088,"column":58,"index":201666},"line":6088,"code":"  it('shouldCorrectlyDifferentiateBetweenObjectIdInstances', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      // LINE var ObjectId = require('mongodb').ObjectId,\n      // LINE   test = require('assert');\n      // REPLACE configuration.writeConcernMax() WITH {w:1}\n      // REMOVE-LINE done();\n      // BEGIN\n      // Create a new ObjectId\n      var objectId = new ObjectId(); // Create a new ObjectId Based on the first ObjectId\n\n      var objectId2 = new ObjectId(objectId.id); // Create another ObjectId\n\n      var objectId3 = new ObjectId(); // objectId and objectId2 should be the same\n\n      test.ok(objectId.equals(objectId2)); // objectId and objectId2 should be different\n\n      test.ok(!objectId.equals(objectId3));\n      done(); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUseCreateFromTime","suites":["Operation Examples"],"updatePoint":{"line":6120,"column":38,"index":202675},"line":6120,"code":"  it('shouldCorrectlyUseCreateFromTime', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      // LINE var ObjectId = require('mongodb').ObjectId,\n      // LINE   test = require('assert');\n      // REPLACE configuration.writeConcernMax() WITH {w:1}\n      // REMOVE-LINE done();\n      // BEGIN\n      var objectId = ObjectId.createFromTime(1);\n      test.equal('000000010000000000000000', objectId.toHexString());\n      done(); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute ordered batch with no errors using write commands","suites":["Operation Examples"],"updatePoint":{"line":6150,"column":80,"index":203633},"line":6150,"code":"  it('Should correctly execute ordered batch with no errors using write commands', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Get the collection\n\n        var col = db.collection('batch_write_ordered_ops_0'); // Initialize the Ordered Batch\n\n        var batch = col.initializeOrderedBulkOp(); // Add some operations to be executed in order\n\n        batch.insert({\n          a: 1\n        });\n        batch.find({\n          a: 1\n        }).updateOne({\n          $set: {\n            b: 1\n          }\n        });\n        batch.find({\n          a: 2\n        }).upsert().updateOne({\n          $set: {\n            b: 2\n          }\n        });\n        batch.insert({\n          a: 3\n        });\n        batch.find({\n          a: 3\n        }).delete({\n          a: 3\n        }); // Execute the operations\n\n        batch.execute(function (err, result) {\n          // Check state of result\n          test.equal(2, result.nInserted);\n          test.equal(1, result.nUpserted);\n          test.equal(1, result.nMatched);\n          test.ok(1 === result.nModified || result.nModified == null);\n          test.equal(1, result.nRemoved);\n          var upserts = result.getUpsertedIds();\n          test.equal(1, upserts.length);\n          test.equal(2, upserts[0].index);\n          test.ok(upserts[0]._id != null);\n          var upsert = result.getUpsertedIdAt(0);\n          test.equal(2, upsert.index);\n          test.ok(upsert._id != null); // Finish up test\n\n          client.close(done);\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute unordered batch with no errors","suites":["Operation Examples"],"updatePoint":{"line":6232,"column":61,"index":206179},"line":6232,"code":"  it('Should correctly execute unordered batch with no errors', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Get the collection\n\n        var col = db.collection('batch_write_unordered_ops_legacy_0'); // Initialize the unordered Batch\n\n        var batch = col.initializeUnorderedBulkOp(); // Add some operations to be executed in order\n\n        batch.insert({\n          a: 1\n        });\n        batch.find({\n          a: 1\n        }).updateOne({\n          $set: {\n            b: 1\n          }\n        });\n        batch.find({\n          a: 2\n        }).upsert().updateOne({\n          $set: {\n            b: 2\n          }\n        });\n        batch.insert({\n          a: 3\n        });\n        batch.find({\n          a: 3\n        }).delete({\n          a: 3\n        }); // Execute the operations\n\n        batch.execute(function (err, result) {\n          // Check state of result\n          test.equal(2, result.nInserted);\n          test.equal(1, result.nUpserted);\n          test.equal(1, result.nMatched);\n          test.ok(1 === result.nModified || result.nModified == null);\n          test.equal(1, result.nRemoved);\n          var upserts = result.getUpsertedIds();\n          test.equal(1, upserts.length);\n          test.equal(2, upserts[0].index);\n          test.ok(upserts[0]._id != null);\n          var upsert = result.getUpsertedIdAt(0);\n          test.equal(2, upsert.index);\n          test.ok(upsert._id != null); // Finish up test\n\n          client.close(done);\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute insertOne operation","suites":["Operation Examples"],"updatePoint":{"line":6319,"column":50,"index":208843},"line":6319,"code":"  it('Should correctly execute insertOne operation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Get the collection\n\n        var col = db.collection('insert_one');\n        col.insertOne({\n          a: 1\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedId').to.exist; // Finish up test\n\n          client.close(done);\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute insertMany operation","suites":["Operation Examples"],"updatePoint":{"line":6362,"column":51,"index":210255},"line":6362,"code":"  it('Should correctly execute insertMany operation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Get the collection\n\n        var col = db.collection('insert_many');\n        col.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }], function (err, r) {\n          expect(err).to.not.exist;\n          test.equal(2, r.insertedCount); // Finish up test\n\n          client.close(done);\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute updateOne operation","suites":["Operation Examples"],"updatePoint":{"line":6407,"column":50,"index":211685},"line":6407,"code":"  it('Should correctly execute updateOne operation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Get the collection\n\n        var col = db.collection('update_one');\n        col.updateOne({\n          a: 1\n        }, {\n          $set: {\n            a: 2\n          }\n        }, {\n          upsert: true\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          test.equal(0, r.matchedCount);\n          test.equal(1, r.upsertedCount); // Finish up test\n\n          client.close(done);\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute updateMany operation","suites":["Operation Examples"],"updatePoint":{"line":6457,"column":51,"index":213223},"line":6457,"code":"  it('Should correctly execute updateMany operation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Get the collection\n\n        var col = db.collection('update_many');\n        col.insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }], function (err, r) {\n          expect(err).to.not.exist;\n          test.equal(2, r.insertedCount); // Update all documents\n\n          col.updateMany({\n            a: 1\n          }, {\n            $set: {\n              b: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            test.equal(2, r.matchedCount);\n            test.equal(2, r.modifiedCount); // Finish up test\n\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute deleteOne operation","suites":["Operation Examples"],"updatePoint":{"line":6514,"column":50,"index":214964},"line":6514,"code":"  it('Should correctly execute deleteOne operation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Get the collection\n\n        var col = db.collection('remove_one');\n        col.insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }], function (err, r) {\n          expect(err).to.not.exist;\n          test.equal(2, r.insertedCount);\n          col.deleteOne({\n            a: 1\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            test.equal(1, r.deletedCount); // Finish up test\n\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute removeMany operation","suites":["Operation Examples"],"updatePoint":{"line":6565,"column":51,"index":216569},"line":6565,"code":"  it('Should correctly execute removeMany operation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Get the collection\n\n        var col = db.collection('remove_many');\n        col.insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }], function (err, r) {\n          expect(err).to.not.exist;\n          test.equal(2, r.insertedCount); // Update all documents\n\n          col.deleteMany({\n            a: 1\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            test.equal(2, r.deletedCount); // Finish up test\n\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute bulkWrite operation","suites":["Operation Examples"],"updatePoint":{"line":6617,"column":50,"index":218198},"line":6617,"code":"  it('Should correctly execute bulkWrite operation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Get the collection\n\n        var col = db.collection('bulk_write');\n        col.bulkWrite([{\n          insertOne: {\n            document: {\n              a: 1\n            }\n          }\n        }, {\n          updateOne: {\n            filter: {\n              a: 2\n            },\n            update: {\n              $set: {\n                a: 2\n              }\n            },\n            upsert: true\n          }\n        }, {\n          updateMany: {\n            filter: {\n              a: 2\n            },\n            update: {\n              $set: {\n                a: 2\n              }\n            },\n            upsert: true\n          }\n        }, {\n          deleteOne: {\n            filter: {\n              c: 1\n            }\n          }\n        }, {\n          deleteMany: {\n            filter: {\n              c: 1\n            }\n          }\n        }, {\n          replaceOne: {\n            filter: {\n              c: 3\n            },\n            replacement: {\n              c: 4\n            },\n            upsert: true\n          }\n        }], {\n          ordered: true,\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          test.equal(1, r.nInserted);\n          test.equal(2, r.nUpserted);\n          test.equal(0, r.nRemoved); // Crud fields\n\n          test.equal(1, r.insertedCount);\n          test.equal(1, Object.keys(r.insertedIds).length);\n          test.equal(1, r.matchedCount);\n          test.ok(r.modifiedCount === 0 || r.modifiedCount === 1);\n          test.equal(0, r.deletedCount);\n          test.equal(2, r.upsertedCount);\n          test.equal(2, Object.keys(r.upsertedIds).length); // Ordered bulk operation\n\n          client.close(done);\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndDelete operation","suites":["Operation Examples"],"updatePoint":{"line":6725,"column":57,"index":221086},"line":6725,"code":"  it('Should correctly execute findOneAndDelete operation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Get the collection\n\n        var col = db.collection('find_one_and_delete');\n        col.insertMany([{\n          a: 1,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedCount').to.equal(1);\n          col.findOneAndDelete({\n            a: 1\n          }, {\n            projection: {\n              b: 1\n            },\n            sort: {\n              a: 1\n            }\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            test.equal(1, r.lastErrorObject.n);\n            test.equal(1, r.value.b);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndReplace operation","suites":["Operation Examples"],"updatePoint":{"line":6786,"column":58,"index":222953},"line":6786,"code":"  it('Should correctly execute findOneAndReplace operation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Get the collection\n\n        var col = db.collection('find_one_and_replace');\n        col.insertMany([{\n          a: 1,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedCount').to.equal(1);\n          col.findOneAndReplace({\n            a: 1\n          }, {\n            c: 1,\n            b: 1\n          }, {\n            projection: {\n              b: 1,\n              c: 1\n            },\n            sort: {\n              a: 1\n            },\n            returnDocument: ReturnDocument.AFTER,\n            upsert: true\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            test.equal(1, r.lastErrorObject.n);\n            test.equal(1, r.value.b);\n            test.equal(1, r.value.c);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndUpdate operation","suites":["Operation Examples"],"updatePoint":{"line":6854,"column":57,"index":225003},"line":6854,"code":"  it('Should correctly execute findOneAndUpdate operation', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db); // Get the collection\n\n        var col = db.collection('find_one_and_update');\n        col.insertMany([{\n          a: 1,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedCount').to.equal(1);\n          col.findOneAndUpdate({\n            a: 1\n          }, {\n            $set: {\n              d: 1\n            }\n          }, {\n            projection: {\n              b: 1,\n              d: 1\n            },\n            sort: {\n              a: 1\n            },\n            returnDocument: ReturnDocument.AFTER,\n            upsert: true\n          }, function (err, r) {\n            expect(err).to.not.exist;\n            test.equal(1, r.lastErrorObject.n);\n            test.equal(1, r.value.b);\n            test.equal(1, r.value.d);\n            client.close(done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly add capped collection options to cursor","suites":["Operation Examples"],"updatePoint":{"line":6923,"column":62,"index":227081},"line":6923,"code":"  it('Should correctly add capped collection options to cursor', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect(function(err, client) {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // REMOVE-LINE var db = client.db(configuration.db);\n        // BEGIN\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Create a capped collection with a maximum of 1000 documents\n\n        db.createCollection('a_simple_collection_2', {\n          capped: true,\n          size: 100000,\n          max: 1000,\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, collection) {\n          expect(err).to.not.exist;\n          var docs = [];\n\n          for (var i = 0; i < 1000; i++) docs.push({\n            a: i\n          }); // Insert a document in the capped collection\n\n\n          collection.insertMany(docs, configuration.writeConcernMax(), function (err, result) {\n            test.ok(result);\n            expect(err).to.not.exist;\n            var total = 0; // Get the cursor\n\n            var cursor = collection.find({}).addCursorFlag('tailable', true).addCursorFlag('awaitData', true);\n            const stream = cursor.stream();\n            stream.on('data', function () {\n              total = total + 1;\n\n              if (total === 1000) {\n                cursor.close();\n              }\n            });\n            cursor.on('close', function () {\n              client.close(done);\n            });\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_example.test.js","skipped":false,"dir":"test"},{"name":"aggregationExample2WithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":57,"column":37,"index":1311},"line":57,"code":"  it('aggregationExample2WithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Some docs for insertion\n\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }]; // Create a collection\n\n        var collection = db.collection('aggregationExample2_with_promise'); // Insert the docs\n\n        return collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          test.ok(result); // Execute aggregate, notice the pipeline is expressed as an Array\n\n          var cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }], {\n            cursor: {\n              batchSize: 1\n            }\n          }); // Get all the aggregation results\n\n          return cursor.toArray();\n        }).then(function (docs) {\n          test.equal(2, docs.length);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Aggregation Cursor next Test With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":146,"column":48,"index":3886},"line":146,"code":"  it('Aggregation Cursor next Test With Promises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>2.1.0',\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Some docs for insertion\n\n        var docs = [{\n          title: 'this is my title',\n          author: 'bob',\n          posted: new Date(),\n          pageViews: 5,\n          tags: ['fun', 'good', 'fun'],\n          other: {\n            foo: 5\n          },\n          comments: [{\n            author: 'joe',\n            text: 'this is cool'\n          }, {\n            author: 'sam',\n            text: 'this is bad'\n          }]\n        }]; // Create a collection\n\n        var collection = db.collection('aggregation_next_example_with_promise');\n        let cursor; // Insert the docs\n\n        return collection.insertMany(docs, {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          test.ok(result); // Execute aggregate, notice the pipeline is expressed as an Array\n\n          cursor = collection.aggregate([{\n            $project: {\n              author: 1,\n              tags: 1\n            }\n          }, {\n            $unwind: '$tags'\n          }, {\n            $group: {\n              _id: {\n                tags: '$tags'\n              },\n              authors: {\n                $addToSet: '$author'\n              }\n            }\n          }], {\n            cursor: {\n              batchSize: 1\n            }\n          }); // Get all the aggregation results\n\n          return cursor.next();\n        }).then(function (docs) {\n          test.ok(docs); // Need to close cursor to close implicit session,\n          // since cursor is not exhausted\n\n          return cursor.close();\n        }).then(() => client.close());\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDoSimpleCountExamplesWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":237,"column":54,"index":6571},"line":237,"code":"  it('shouldCorrectlyDoSimpleCountExamplesWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        w: 0\n      }, {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Crete the collection for the distinct example\n\n        var collection = db.collection('countExample1_with_promise'); // Insert documents to perform distinct against\n\n        return collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }, {\n          a: 4,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (ids) {\n          test.ok(ids); // Perform a total count command\n\n          return collection.count();\n        }).then(function (count) {\n          test.equal(4, count); // Perform a partial account where b=1\n\n          return collection.count({\n            b: 1\n          });\n        }).then(function (count) {\n          test.equal(1, count);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCreateComplexIndexOnTwoFieldsWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":300,"column":53,"index":8419},"line":300,"code":"  it('shouldCreateComplexIndexOnTwoFieldsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection we want to drop later\n\n        var collection = db.collection('createIndexExample1_with_promise'); // Insert a bunch of documents for the index\n\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result); // Create an index on the a field\n\n          return collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          test.ok(indexName); // Show that duplicate records got dropped\n\n          return collection.find({}).toArray();\n        }).then(function (items) {\n          test.equal(4, items.length); // Perform a query, with explain to show we hit the query\n\n          return collection.find({\n            a: 2\n          }).explain();\n        }).then(function (explanation) {\n          test.ok(explanation != null);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleDistinctIndexesWithSubQueryFilterWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":373,"column":72,"index":10661},"line":373,"code":"  it('shouldCorrectlyHandleDistinctIndexesWithSubQueryFilterWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Crete the collection for the distinct example\n\n        var collection = db.collection('distinctExample1_with_promise'); // Insert documents to perform distinct against\n\n        return collection.insertMany([{\n          a: 0,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'b'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'c'\n          }\n        }, {\n          a: 2,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 3\n        }, {\n          a: 3\n        }], configuration.writeConcernMax()).then(function (ids) {\n          test.ok(ids); // Perform a distinct query against the a field\n\n          return collection.distinct('a');\n        }).then(function (docs) {\n          test.deepEqual([0, 1, 2, 3], docs.sort()); // Perform a distinct query against the sub-field b.c\n\n          return collection.distinct('b.c');\n        }).then(function (docs) {\n          test.deepEqual(['a', 'b', 'c'], docs.sort());\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyHandleDistinctIndexesWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":440,"column":54,"index":12677},"line":440,"code":"  it('shouldCorrectlyHandleDistinctIndexesWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Crete the collection for the distinct example\n\n        var collection = db.collection('distinctExample2_with_promise'); // Insert documents to perform distinct against\n\n        return collection.insertMany([{\n          a: 0,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'b'\n          }\n        }, {\n          a: 1,\n          b: {\n            c: 'c'\n          }\n        }, {\n          a: 2,\n          b: {\n            c: 'a'\n          }\n        }, {\n          a: 3\n        }, {\n          a: 3\n        }, {\n          a: 5,\n          c: 1\n        }], configuration.writeConcernMax()).then(function (ids) {\n          test.ok(ids); // Perform a distinct query with a filter against the documents\n\n          return collection.distinct('a', {\n            c: 1\n          });\n        }).then(function (docs) {\n          test.deepEqual([5], docs.sort());\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDropCollectionWithDropFunctionWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":511,"column":63,"index":14613},"line":511,"code":"  it('shouldCorrectlyDropCollectionWithDropFunctionWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection we want to drop later\n\n        return db.createCollection('test_other_drop_with_promise').then(function (collection) {\n          // Drop the collection\n          return collection.drop();\n        }).then(function (reply) {\n          test.ok(reply); // Ensure we don't have the collection in the set of names\n\n          return db.listCollections().toArray();\n        }).then(function (replies) {\n          var found = false; // For each collection in the list of collection names in this db look for the\n          // dropped collection\n\n          replies.forEach(function (document) {\n            if (document.name === 'test_other_drop_with_promise') {\n              found = true;\n              return;\n            }\n          }); // Ensure the collection is not found\n\n          test.equal(false, found); // Let's close the db\n\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"dropIndexesExample1WithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":565,"column":37,"index":16510},"line":565,"code":"  it('dropIndexesExample1WithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        return db.createCollection('dropExample1_with_promise').then(function (r) {\n          test.ok(r); // Drop the collection\n\n          return db.collection('dropExample1_with_promise').dropIndexes();\n        }).then(function (reply) {\n          test.ok(reply); // Let's close the db\n\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateAndDropIndexWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":605,"column":51,"index":17834},"line":605,"code":"  it('shouldCorrectlyCreateAndDropIndexWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        var collection = db.collection('dropIndexExample1_with_promise'); // Insert a bunch of documents for the index\n\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          test.ok(result); // Create an index on the a field\n\n          return collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          test.ok(indexName); // Drop the index\n\n          return collection.dropIndex('a_1_b_1');\n        }).then(function (result) {\n          test.ok(result); // Verify that the index is gone\n\n          return collection.indexInformation();\n        }).then(function (indexInformation) {\n          test.deepEqual([['_id', 1]], indexInformation._id_);\n          expect(indexInformation.a_1_b_1).to.not.exist;\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCreateComplexEnsureIndexWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":680,"column":48,"index":20049},"line":680,"code":"  it('shouldCreateComplexEnsureIndexWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        var collection = db.collection('ensureIndexExample1_with_promise'); // Insert a bunch of documents for the index\n\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result); // Create an index on the a field\n\n          return db.createIndex('ensureIndexExample1_with_promise', {\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          test.ok(indexName); // Show that duplicate records got dropped\n\n          return collection.find({}).toArray();\n        }).then(function (items) {\n          test.equal(4, items.length); // Perform a query, with explain to show we hit the query\n\n          return collection.find({\n            a: 2\n          }).explain();\n        }).then(function (explanation) {\n          test.ok(explanation != null);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"ensureIndexExampleWithCompountIndexWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":752,"column":53,"index":22265},"line":752,"code":"  it('ensureIndexExampleWithCompountIndexWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        var collection = db.collection('ensureIndexExample2_with_promise'); // Insert a bunch of documents for the index\n\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          test.ok(result); // Create an index on the a field\n\n          return collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          test.ok(indexName); // Show that duplicate records got dropped\n\n          return collection.find({}).toArray();\n        }).then(function (items) {\n          test.equal(4, items.length); // Perform a query, with explain to show we hit the query\n\n          return collection.find({\n            a: 2\n          }).explain();\n        }).then(function (explanation) {\n          test.ok(explanation != null);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleQueryWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":828,"column":43,"index":24418},"line":828,"code":"  it('shouldPerformASimpleQueryWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection we want to drop later\n\n        var collection = db.collection('simple_query_with_promise'); // Insert a bunch of documents for the testing\n\n        return collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result); // Perform a simple find and return all the documents\n\n          return collection.find().toArray();\n        }).then(function (docs) {\n          test.equal(3, docs.length);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleExplainQueryWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":876,"column":50,"index":25988},"line":876,"code":"  it('shouldPerformASimpleExplainQueryWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection we want to drop later\n\n        var collection = db.collection('simple_explain_query_with_promise'); // Insert a bunch of documents for the testing\n\n        return collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result); // Perform a simple find and return all the documents\n\n          return collection.find({}).explain();\n        }).then(function (docs) {\n          test.ok(docs != null);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleLimitSkipQueryWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":924,"column":52,"index":27556},"line":924,"code":"  it('shouldPerformASimpleLimitSkipQueryWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection we want to drop later\n\n        var collection = db.collection('simple_limit_skip_query_with_promise'); // Insert a bunch of documents for the testing\n\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result); // Perform a simple find and return all the documents\n\n          return collection.find({}).skip(1).limit(1).project({\n            b: 1\n          }).toArray();\n        }).then(function (docs) {\n          test.equal(1, docs.length);\n          expect(docs[0].a).to.not.exist;\n          test.equal(2, docs[0].b);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformSimpleFindAndModifyOperationsWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":983,"column":60,"index":29606},"line":983,"code":"  it('shouldPerformSimpleFindAndModifyOperationsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection we want to drop later\n\n        var collection = db.collection('simple_find_and_modify_operations_with_promise'); // Insert some test documentations\n\n        return collection.insertMany([{\n          a: 1\n        }, {\n          b: 1\n        }, {\n          c: 1\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result); // Simple findAndModify command returning the new document\n\n          return collection.findOneAndUpdate({\n            a: 1\n          }, {\n            $set: {\n              b1: 1\n            }\n          }, {\n            returnDocument: ReturnDocument.AFTER\n          });\n        }).then(function (doc) {\n          test.equal(1, doc.value.a);\n          test.equal(1, doc.value.b1); // Simple findAndModify command returning the new document and\n          // removing it at the same time\n\n          return collection.findOneAndUpdate({\n            b: 1\n          }, {\n            $set: {\n              b: 2\n            }\n          }, {\n            remove: true\n          });\n        }).then(function (doc) {\n          test.ok(doc); // Verify that the document is gone\n\n          return collection.findOne({\n            b: 1\n          });\n        }).then(function (item) {\n          expect(item).to.not.exist; // Simple findAndModify command performing an upsert and returning the new document\n          // executing the command safely\n\n          return collection.findOneAndUpdate({\n            d: 1\n          }, {\n            $set: {\n              d: 1,\n              f: 1\n            }\n          }, {\n            returnDocument: ReturnDocument.AFTER,\n            upsert: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (doc) {\n          test.equal(1, doc.value.d);\n          test.equal(1, doc.value.f);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformSimplefindOneAndDeleteWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1078,"column":53,"index":32478},"line":1078,"code":"  it('shouldPerformSimplefindOneAndDeleteWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection we want to drop later\n\n        var collection = db.collection('simple_find_and_modify_operations_2_with_promise'); // Insert some test documentations\n\n        return collection.insertMany([{\n          a: 1\n        }, {\n          b: 1,\n          d: 1\n        }, {\n          c: 1\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result); // Simple findAndModify command returning the old document and\n          // removing it at the same time\n\n          return collection.findOneAndDelete({\n            b: 1\n          }, [['b', 1]]);\n        }).then(function (doc) {\n          test.equal(1, doc.value.b);\n          test.equal(1, doc.value.d); // Verify that the document is gone\n\n          return collection.findOne({\n            b: 1\n          });\n        }).then(function (item) {\n          expect(item).to.not.exist;\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformASimpleLimitSkipFindOneQueryWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1137,"column":59,"index":34377},"line":1137,"code":"  it('shouldPerformASimpleLimitSkipFindOneQueryWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection we want to drop later\n\n        var collection = db.collection('simple_limit_skip_find_one_query_with_promise'); // Insert a bunch of documents for the testing\n\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result); // Perform a simple find and return all the documents\n\n          return collection.findOne({\n            a: 2\n          }, {\n            projection: {\n              b: 1\n            }\n          });\n        }).then(function (doc) {\n          expect(doc.a).to.not.exist;\n          test.equal(2, doc.b);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformSimpleMapReduceFunctionsWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1195,"column":55,"index":36134},"line":1195,"code":"  it('shouldPerformSimpleMapReduceFunctionsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        w: 0\n      }, {\n        maxPoolSize: 1\n      });\n      /* eslint-disable */\n\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a test collection\n\n        var collection = db.collection('test_map_reduce_functions_with_promise'); // Insert some documents to perform map reduce over\n\n        return collection.insertMany([{\n          user_id: 1\n        }, {\n          user_id: 2\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function () {\n          // Map function\n          var map = function () {\n            emit(this.user_id, 1);\n          }; // Reduce function\n\n\n          var reduce = function (k, vals) {\n            return 1;\n          }; // Perform the map reduce\n\n\n          return collection.mapReduce(map, reduce, {\n            out: {\n              replace: 'tempCollection'\n            }\n          });\n        }).then(function (reducedCollection) {\n          // Mapreduce returns the temporary collection with the results\n          return reducedCollection.findOne({\n            _id: 1\n          }).then(function (result) {\n            test.equal(1, result.value);\n            return reducedCollection;\n          });\n        }).then(function (reducedCollection) {\n          return reducedCollection.findOne({\n            _id: 2\n          });\n        }).then(function (result) {\n          test.equal(1, result.value);\n          return client.close();\n        });\n      }); // END\n\n      /* eslint-enable */\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformMapReduceFunctionInlineWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1276,"column":54,"index":38518},"line":1276,"code":"  it('shouldPerformMapReduceFunctionInlineWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>1.7.6',\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        w: 0\n      }, {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a test collection\n\n        var collection = db.collection('test_map_reduce_functions_inline_with_promise');\n        /* eslint-disable */\n        // Map function\n\n        var map = function () {\n          emit(this.user_id, 1);\n        }; // Reduce function\n\n\n        var reduce = function (k, vals) {\n          return 1;\n        };\n        /* eslint-enable */\n        // Insert some test documents\n\n\n        return collection.insertMany([{\n          user_id: 1\n        }, {\n          user_id: 2\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function () {\n          // Execute map reduce and return results inline\n          return collection.mapReduce(map, reduce, {\n            out: {\n              inline: 1\n            },\n            verbose: true\n          });\n        }).then(function (result) {\n          test.equal(2, result.results.length);\n          test.ok(result.stats != null);\n          return collection.mapReduce(map, reduce, {\n            out: {\n              replace: 'mapreduce_integration_test'\n            },\n            verbose: true\n          });\n        }).then(function (result) {\n          test.ok(result.stats != null);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformMapReduceWithContextWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1358,"column":51,"index":40921},"line":1358,"code":"  it('shouldPerformMapReduceWithContextWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   Code = require('mongodb').Code,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a test collection\n\n        var collection = db.collection('test_map_reduce_functions_scope_with_promise');\n        /* eslint-disable */\n        // Map function\n\n        var map = function () {\n          emit(fn(this.timestamp.getYear()), 1);\n        }; // Reduce function\n\n\n        var reduce = function (k, v) {\n          var count = 0;\n\n          for (var i = 0; i < v.length; i++) {\n            count += v[i];\n          }\n\n          return count;\n        }; // Javascript function available in the map reduce scope\n\n\n        var t = function (val) {\n          return val + 1;\n        }; // Execute the map reduce with the custom scope\n\n\n        var o = {};\n        o.scope = {\n          fn: new Code(t.toString())\n        };\n        o.out = {\n          replace: 'replacethiscollection'\n        };\n        /* eslint-enable */\n        // Insert some test documents\n\n        return collection.insertMany([{\n          user_id: 1,\n          timestamp: new Date()\n        }, {\n          user_id: 2,\n          timestamp: new Date()\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function () {\n          return collection.mapReduce(map, reduce, o);\n        }).then(function (outCollection) {\n          // Find all entries in the map-reduce collection\n          return outCollection.find().toArray();\n        }).then(function (results) {\n          test.equal(2, results[0].value); // mapReduce with scope containing plain function\n\n          var o = {};\n          o.scope = {\n            fn: t\n          };\n          o.out = {\n            replace: 'replacethiscollection'\n          };\n          return collection.mapReduce(map, reduce, o);\n        }).then(function (outCollection) {\n          // Find all entries in the map-reduce collection\n          return outCollection.find().toArray();\n        }).then(function (results) {\n          test.equal(2, results[0].value);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldPerformMapReduceInContextObjectsWithPromises","suites":["Operation (Promises)"],"line":1459,"code":"  it.skip('shouldPerformMapReduceInContextObjectsWithPromises', {","file":"integration/node-specific/operation_promises_example.test.js","skipped":true,"dir":"test"},{"name":"shouldCorrectlyRetrieveACollectionsIndexesWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1566,"column":60,"index":47002},"line":1566,"code":"  it('shouldCorrectlyRetrieveACollectionsIndexesWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Crete the collection for the distinct example\n\n        var collection = db.collection('simple_key_based_distinct_with_promise'); // Create a geo 2d index\n\n        return collection.createIndex({\n          loc: '2d'\n        }, configuration.writeConcernMax()).then(function (result) {\n          test.ok(result); // Create a simple single field index\n\n          return collection.createIndex({\n            a: 1\n          }, configuration.writeConcernMax());\n        }).then(function (result) {\n          test.ok(result);\n          return delay(1000);\n        }).then(function () {\n          // List all of the indexes on the collection\n          return collection.indexes();\n        }).then(function (indexes) {\n          test.equal(3, indexes.length);\n          return client.close();\n        });\n      });\n    } // END\n\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteIndexExistsWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1619,"column":51,"index":48849},"line":1619,"code":"  it('shouldCorrectlyExecuteIndexExistsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a test collection that we are getting the options back from\n\n        var collection = db.collection('test_collection_index_exists_with_promise', configuration.writeConcernMax()); // Create an index on the collection\n\n        return collection.createIndex('a', configuration.writeConcernMax()).then(function (indexName) {\n          test.ok(indexName); // Let's test to check if a single index exists\n\n          return collection.indexExists('a_1');\n        }).then(function (result) {\n          test.equal(true, result); // Let's test to check if multiple indexes are available\n\n          return collection.indexExists(['a_1', '_id_']);\n        }).then(function (result) {\n          test.equal(true, result); // Check if a non existing index exists\n\n          return collection.indexExists('c_1');\n        }).then(function (result) {\n          test.equal(false, result);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyShowTheResultsFromIndexInformationWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1669,"column":67,"index":50801},"line":1669,"code":"  it('shouldCorrectlyShowTheResultsFromIndexInformationWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection we want to drop later\n\n        var collection = db.collection('more_index_information_test_2_with_promise'); // Insert a bunch of documents for the index\n\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result); // Create an index on the a field\n\n          return collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          test.ok(indexName); // Fetch basic indexInformation for collection\n\n          return db.indexInformation('more_index_information_test_2_with_promise');\n        }).then(function (indexInformation) {\n          test.deepEqual([['_id', 1]], indexInformation._id_);\n          test.deepEqual([['a', 1], ['b', 1]], indexInformation.a_1_b_1); // Fetch full index information\n\n          return collection.indexInformation({\n            full: true\n          });\n        }).then(function (indexInformation) {\n          test.deepEqual({\n            _id: 1\n          }, indexInformation[0].key);\n          test.deepEqual({\n            a: 1,\n            b: 1\n          }, indexInformation[1].key);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyShowAllTheResultsFromIndexInformationWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1749,"column":70,"index":53327},"line":1749,"code":"  it('shouldCorrectlyShowAllTheResultsFromIndexInformationWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection we want to drop later\n\n        var collection = db.collection('more_index_information_test_3_with_promise'); // Insert a bunch of documents for the index\n\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          test.ok(result); // Create an index on the a field\n\n          return collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          test.ok(indexName); // Fetch basic indexInformation for collection\n\n          return collection.indexInformation();\n        }).then(function (indexInformation) {\n          test.deepEqual([['_id', 1]], indexInformation._id_);\n          test.deepEqual([['a', 1], ['b', 1]], indexInformation.a_1_b_1); // Fetch full index information\n\n          return collection.indexInformation({\n            full: true\n          });\n        }).then(function (indexInformation) {\n          test.deepEqual({\n            _id: 1\n          }, indexInformation[0].key);\n          test.deepEqual({\n            a: 1,\n            b: 1\n          }, indexInformation[1].key);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformASimpleSingleDocumentInsertNoCallbackNoSafeWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1833,"column":83,"index":55871},"line":1833,"code":"  it('shouldCorrectlyPerformASimpleSingleDocumentInsertNoCallbackNoSafeWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        var collection = db.collection('simple_document_insert_collection_no_safe_with_promise'); // Insert a single document\n\n        return collection.insertOne({\n          hello: 'world_no_safe'\n        }).then(function () {\n          // Fetch the document\n          return collection.findOne({\n            hello: 'world_no_safe'\n          });\n        }).then(function (item) {\n          test.equal('world_no_safe', item.hello);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformABatchDocumentInsertSafeWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1879,"column":64,"index":57512},"line":1879,"code":"  it('shouldCorrectlyPerformABatchDocumentInsertSafeWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Fetch a collection to insert document into\n\n        var collection = db.collection('batch_document_insert_collection_safe_with_promise'); // Insert a single document\n\n        return collection.insertMany([{\n          hello: 'world_safe1'\n        }, {\n          hello: 'world_safe2'\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result); // Fetch the document\n\n          return collection.findOne({\n            hello: 'world_safe2'\n          });\n        }).then(function (item) {\n          test.equal('world_safe2', item.hello);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformASimpleDocumentInsertWithFunctionSafeWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":1929,"column":77,"index":59277},"line":1929,"code":"  it('shouldCorrectlyPerformASimpleDocumentInsertWithFunctionSafeWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Fetch a collection to insert document into\n\n        var collection = db.collection('simple_document_insert_with_function_safe_with_promise');\n        var o = configuration.writeConcernMax();\n        o.serializeFunctions = true; // Insert a single document\n\n        return collection.insertOne({\n          hello: 'world',\n          func: function () {}\n        }, o).then(function (result) {\n          test.ok(result); // Fetch the document\n\n          return collection.findOne({\n            hello: 'world'\n          });\n        }).then(function (item) {\n          test.ok('function() {}', item.code);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute insert with keepGoing option on mongod >= 1.9.1 With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":1980,"column":92,"index":61146},"line":1980,"code":"  it('Should correctly execute insert with keepGoing option on mongod >= 1.9.1 With Promises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        mongodb: '>1.9.1',\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection\n\n        var collection = db.collection('keepGoingExample_with_promise');\n        return collection.drop().catch(function () {}).then(function () {\n          // Add an unique index to title to force errors in the batch insert\n          return collection.createIndex({\n            title: 1\n          }, {\n            unique: true\n          });\n        }).then(function (indexName) {\n          test.ok(indexName); // Insert some intial data into the collection\n\n          return collection.insertMany([{\n            name: 'Jim'\n          }, {\n            name: 'Sarah',\n            title: 'Princess'\n          }], configuration.writeConcernMax());\n        }).then(function (result) {\n          test.ok(result); // Force keep going flag, ignoring unique index issue\n\n          return collection.insert([{\n            name: 'Jim'\n          }, {\n            name: 'Sarah',\n            title: 'Princess'\n          }, {\n            name: 'Gump',\n            title: 'Gump'\n          }], {\n            writeConcern: {\n              w: 1\n            },\n            keepGoing: true\n          });\n        }).catch(function () {\n          // Count the number of documents left (should not include the duplicates)\n          return collection.count();\n        }).then(function (count) {\n          test.equal(3, count);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteIsCappedWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2056,"column":48,"index":63676},"line":2056,"code":"  it('shouldCorrectlyExecuteIsCappedWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a test collection that we are getting the options back from\n\n        return db.createCollection('test_collection_is_capped_with_promise', {\n          capped: true,\n          size: 1024\n        }).then(function (collection) {\n          test.equal('test_collection_is_capped_with_promise', collection.collectionName); // Let's fetch the collection options\n\n          return collection.isCapped();\n        }).then(function (capped) {\n          test.equal(true, capped);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveCollectionOptionsWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2099,"column":58,"index":65193},"line":2099,"code":"  it('shouldCorrectlyRetrieveCollectionOptionsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a test collection that we are getting the options back from\n\n        return db.createCollection('test_collection_options_with_promise', {\n          capped: true,\n          size: 1024\n        }).then(function (collection) {\n          test.equal('test_collection_options_with_promise', collection.collectionName); // Let's fetch the collection options\n\n          return collection.options();\n        }).then(function (options) {\n          test.equal(true, options.capped);\n          test.ok(options.size >= 1024);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldRemoveAllDocumentsNoSafeWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2143,"column":48,"index":66764},"line":2143,"code":"  it('shouldRemoveAllDocumentsNoSafeWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Fetch a collection to insert document into\n\n        var collection = db.collection('remove_all_documents_no_safe_with_promise'); // Insert a bunch of documents\n\n        return collection.insertMany([{\n          a: 1\n        }, {\n          b: 2\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          test.ok(result); // Remove all the document\n\n          return collection.deleteMany();\n        }).then(function () {\n          // Fetch all results\n          return collection.find().toArray();\n        }).then(function (items) {\n          test.equal(0, items.length);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldRemoveSubsetOfDocumentsSafeModeWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2196,"column":55,"index":68436},"line":2196,"code":"  it('shouldRemoveSubsetOfDocumentsSafeModeWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        w: 0\n      }, {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Fetch a collection to insert document into\n\n        var collection = db.collection('remove_subset_of_documents_safe_with_promise'); // Insert a bunch of documents\n\n        return collection.insertMany([{\n          a: 1\n        }, {\n          b: 2\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          test.ok(result); // Remove all the document\n\n          return collection.deleteOne({\n            a: 1\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (r) {\n          expect(r).property('deletedCount').to.equal(1);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRenameCollectionWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2254,"column":49,"index":70110},"line":2254,"code":"  it('shouldCorrectlyRenameCollectionWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      /* eslint-disable */\n\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Open a couple of collections\n\n        var collection1, collection2;\n        return Promise.all([db.createCollection('test_rename_collection_with_promise'), db.createCollection('test_rename_collection2_with_promise')]).then(function (collections) {\n          collection1 = collections[0];\n          collection2 = collections[1];\n          test.ok(collection2); // Attemp to rename a collection to a number\n\n          try {\n            collection1.rename(5, function (err, collection) {});\n          } catch (err) {\n            test.ok(err instanceof Error);\n            test.equal('Collection name must be a String', err.message);\n          } // Attemp to rename a collection to an empty string\n\n\n          try {\n            collection1.rename('', function (err, collection) {});\n          } catch (err) {\n            test.ok(err instanceof Error);\n            test.equal('Collection names cannot be empty', err.message);\n          } // Attemp to rename a collection to an illegal name including the character $\n\n\n          try {\n            collection1.rename('te$t', function (err, collection) {});\n          } catch (err) {\n            test.ok(err instanceof Error);\n            test.equal(\"Collection names must not contain '$'\", err.message);\n          } // Attemp to rename a collection to an illegal name starting with the character .\n\n\n          try {\n            collection1.rename('.test', function (err, collection) {});\n          } catch (err) {\n            test.ok(err instanceof Error);\n            test.equal(\"Collection names must not start or end with '.'\", err.message);\n          } // Attemp to rename a collection to an illegal name ending with the character .\n\n\n          try {\n            collection1.rename('test.', function (err, collection) {});\n          } catch (err) {\n            test.ok(err instanceof Error);\n            test.equal(\"Collection names must not start or end with '.'\", err.message);\n          } // Attemp to rename a collection to an illegal name with an empty middle name\n\n\n          try {\n            collection1.rename('tes..t', function (err, collection) {});\n          } catch (err) {\n            test.equal('Collection names cannot be empty', err.message);\n          } // Insert a couple of documents\n\n\n          return collection1.insertMany([{\n            x: 1\n          }, {\n            x: 2\n          }], configuration.writeConcernMax());\n        }).then(function (docs) {\n          test.ok(docs); // Attemp to rename the first collection to the second one, this will fail\n\n          return collection1.rename('test_rename_collection2_with_promise');\n        }).catch(function (err) {\n          test.ok(err instanceof Error);\n          test.ok(err.message.length > 0); // Attemp to rename the first collection to a name that does not exist\n          // this will be successful\n\n          return collection1.rename('test_rename_collection3_with_promise');\n        }).then(function (collection2) {\n          test.equal('test_rename_collection3_with_promise', collection2.collectionName); // Ensure that the collection is pointing to the new one\n\n          return collection2.count();\n        }).then(function (count) {\n          test.equal(2, count);\n        }).then(() => client.close(), e => {\n          client.close();\n          throw e;\n        });\n      }); // END\n\n      /* eslint-enable */\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUpdateASimpleDocumentWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2368,"column":54,"index":74496},"line":2368,"code":"  it('shouldCorrectlyUpdateASimpleDocumentWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        w: 0\n      }, {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get a collection\n\n        var collection = db.collection('update_a_simple_document_with_promise'); // Insert a document, then update it\n\n        return collection.insertOne({\n          a: 1\n        }, configuration.writeConcernMax()).then(function (doc) {\n          test.ok(doc); // Update the document with an atomic operator\n\n          return collection.updateOne({\n            a: 1\n          }, {\n            $set: {\n              b: 2\n            }\n          });\n        }).then(function () {\n          // Fetch the document that we modified\n          return collection.findOne({\n            a: 1\n          });\n        }).then(function (item) {\n          test.equal(1, item.a);\n          test.equal(2, item.b);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUpsertASimpleDocumentWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2426,"column":54,"index":76292},"line":2426,"code":"  it('shouldCorrectlyUpsertASimpleDocumentWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get a collection\n\n        var collection = db.collection('update_a_simple_document_upsert_with_promise'); // Update the document using an upsert operation, ensuring creation if it does not exist\n\n        return collection.updateOne({\n          a: 1\n        }, {\n          $set: {\n            b: 2,\n            a: 1\n          }\n        }, {\n          upsert: true,\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          expect(result).property('upsertedCount').to.equal(1); // Fetch the document that we modified and check if it got inserted correctly\n\n          return collection.findOne({\n            a: 1\n          });\n        }).then(function (item) {\n          test.equal(1, item.a);\n          test.equal(2, item.b);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUpdateMultipleDocumentsWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2483,"column":56,"index":78123},"line":2483,"code":"  it('shouldCorrectlyUpdateMultipleDocumentsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get a collection\n\n        var collection = db.collection('update_a_simple_document_multi_with_promise'); // Insert a couple of documentations\n\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 1,\n          b: 2\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result);\n          var o = configuration.writeConcernMax();\n          return collection.updateMany({\n            a: 1\n          }, {\n            $set: {\n              b: 0\n            }\n          }, o);\n        }).then(function (r) {\n          expect(r).property('matchedCount').to.equal(2); // Fetch all the documents and verify that we have changed the b value\n\n          return collection.find().toArray();\n        }).then(function (items) {\n          test.equal(1, items[0].a);\n          test.equal(0, items[0].b);\n          test.equal(1, items[1].a);\n          test.equal(0, items[1].b);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyReturnACollectionsStatsWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2544,"column":56,"index":80093},"line":2544,"code":"  it('shouldCorrectlyReturnACollectionsStatsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Crete the collection for the distinct example\n\n        var collection = db.collection('collection_stats_test_with_promise'); // Insert some documents\n\n        return collection.insertMany([{\n          a: 1\n        }, {\n          hello: 'world'\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result); // Retrieve the statistics for the collection\n\n          return collection.stats();\n        }).then(function (stats) {\n          test.equal(2, stats.count);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateAndDropAllIndexWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2590,"column":54,"index":81641},"line":2590,"code":"  it('shouldCorrectlyCreateAndDropAllIndexWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection we want to drop later\n\n        var collection = db.collection('shouldCorrectlyCreateAndDropAllIndex_with_promise'); // Insert a bunch of documents for the index\n\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4,\n          c: 4\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          test.ok(result); // Create an index on the a field\n\n          return collection.createIndex({\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          test.ok(indexName); // Create an additional index\n\n          return collection.createIndex({\n            c: 1\n          }, {\n            unique: true,\n            background: true,\n            sparse: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          test.ok(indexName); // Drop the index\n\n          return collection.dropIndexes();\n        }).then(function (result) {\n          test.ok(result); // Verify that the index is gone\n\n          return collection.indexInformation();\n        }).then(function (indexInformation) {\n          test.deepEqual([['_id', 1]], indexInformation._id_);\n          expect(indexInformation.a_1_b_1).to.not.exist;\n          expect(indexInformation.c_1).to.not.exist;\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyOpenASimpleDbSingleServerConnectionAndCloseWithCallbackWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2687,"column":88,"index":84489},"line":2687,"code":"  it('shouldCorrectlyOpenASimpleDbSingleServerConnectionAndCloseWithCallbackWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Close the connection with a callback that is optional\n        return client.close();\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrievelistCollectionsWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2719,"column":56,"index":85543},"line":2719,"code":"  it('shouldCorrectlyRetrievelistCollectionsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get an empty db\n        var db1 = client.db('listCollectionTestDb2'); // Create a collection\n\n        var collection = db1.collection('shouldCorrectlyRetrievelistCollections_with_promise'); // Ensure the collection was created\n\n        return collection.insertOne({\n          a: 1\n        }).then(function () {\n          // Return the information of a single collection name\n          return db1.listCollections({\n            name: 'shouldCorrectlyRetrievelistCollections_with_promise'\n          }).toArray();\n        }).then(function (items) {\n          test.equal(1, items.length); // Return the information of a all collections, using the callback format\n\n          return db1.listCollections().toArray();\n        }).then(function (items) {\n          test.ok(items.length >= 1);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrievelistCollectionsWiredTigerWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2762,"column":66,"index":87228},"line":2762,"code":"  it('shouldCorrectlyRetrievelistCollectionsWiredTigerWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['wiredtiger']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        // Get an empty db\n        var db1 = client.db('listCollectionTestDb2'); // Create a collection\n\n        var collection = db1.collection('shouldCorrectlyRetrievelistCollections_with_promise'); // Ensure the collection was created\n\n        return collection.insertOne({\n          a: 1\n        }).then(function () {\n          // Return the information of a single collection name\n          return db1.listCollections({\n            name: 'shouldCorrectlyRetrievelistCollections_with_promise'\n          }).toArray();\n        }).then(function (items) {\n          test.equal(1, items.length); // Return the information of a all collections, using the callback format\n\n          return db1.listCollections().toArray();\n        }).then(function (items) {\n          test.equal(1, items.length);\n          return client.close();\n        });\n      });\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveAllCollectionsWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2804,"column":55,"index":88635},"line":2804,"code":"  it('shouldCorrectlyRetrieveAllCollectionsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Retry to get the collection, should work as it's now created\n\n        return db.collections().then(function (collections) {\n          test.ok(collections.length > 0);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyAddUserToDbWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2840,"column":44,"index":89817},"line":2840,"code":"  it('shouldCorrectlyAddUserToDbWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Add a user to the database\n\n        return db.addUser('user', 'name').then(function (result) {\n          test.ok(result); // Remove the user from the db\n\n          return db.removeUser('user');\n        }).then(function (result) {\n          test.ok(result);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyAddAndRemoveUserWithPromises","suites":["Operation (Promises)"],"line":2880,"code":"  it.skip('shouldCorrectlyAddAndRemoveUserWithPromises', {","file":"integration/node-specific/operation_promises_example.test.js","skipped":true,"dir":"test"},{"name":"shouldCorrectlyCreateACollectionWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2937,"column":50,"index":93125},"line":2937,"code":"  it('shouldCorrectlyCreateACollectionWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a capped collection with a maximum of 1000 documents\n\n        return db.createCollection('a_simple_collection_with_promise', {\n          capped: true,\n          size: 10000,\n          max: 1000,\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (collection) {\n          // Insert a document in the capped collection\n          return collection.insertOne({\n            a: 1\n          }, configuration.writeConcernMax());\n        }).then(function (result) {\n          test.ok(result);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteACommandAgainstTheServerWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":2985,"column":64,"index":94739},"line":2985,"code":"  it('shouldCorrectlyExecuteACommandAgainstTheServerWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Execute ping against the server\n\n        return db.command({\n          ping: 1\n        }).then(function (result) {\n          test.ok(result); // Create a capped collection with a maximum of 1000 documents\n\n          return db.createCollection('a_simple_create_drop_collection_with_promise', {\n            capped: true,\n            size: 10000,\n            max: 1000,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (collection) {\n          // Insert a document in the capped collection\n          return collection.insertOne({\n            a: 1\n          }, configuration.writeConcernMax());\n        }).then(function (result) {\n          test.ok(result); // Drop the collection from this world\n\n          return db.dropCollection('a_simple_create_drop_collection_with_promise');\n        }).then(function (result) {\n          test.ok(result); // Verify that the collection is gone\n\n          return db.listCollections({\n            name: 'a_simple_create_drop_collection_with_promise'\n          }).toArray();\n        }).then(function (names) {\n          test.equal(0, names.length);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateDropAndVerifyThatCollectionIsGoneWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3049,"column":72,"index":96926},"line":3049,"code":"  it('shouldCorrectlyCreateDropAndVerifyThatCollectionIsGoneWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Execute ping against the server\n\n        return db.command({\n          ping: 1\n        }).then(function (result) {\n          test.ok(result);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRenameACollectionWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3087,"column":50,"index":98134},"line":3087,"code":"  it('shouldCorrectlyRenameACollectionWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection\n\n        return db.createCollection('simple_rename_collection_with_promise', configuration.writeConcernMax()).then(function (collection) {\n          // Insert a document in the collection\n          return collection.insertOne({\n            a: 1\n          }, configuration.writeConcernMax()).then(function () {\n            return collection;\n          });\n        }).then(function (collection) {\n          // Retrieve the number of documents from the collection\n          return collection.count();\n        }).then(function (count) {\n          test.equal(1, count); // Rename the collection\n\n          return db.renameCollection('simple_rename_collection_with_promise', 'simple_rename_collection_2_with_promise');\n        }).then(function (collection2) {\n          // Retrieve the number of documents from the collection\n          return collection2.count();\n        }).then(function (count) {\n          test.equal(1, count); // Verify that the collection is gone\n\n          return db.listCollections({\n            name: 'simple_rename_collection_with_promise'\n          }).toArray();\n        }).then(function (names) {\n          test.equal(0, names.length); // Verify that the new collection exists\n\n          return db.listCollections({\n            name: 'simple_rename_collection_2_with_promise'\n          }).toArray();\n        }).then(function (names) {\n          test.equal(1, names.length);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCreateOnDbComplexIndexOnTwoFieldsWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3152,"column":57,"index":100647},"line":3152,"code":"  it('shouldCreateOnDbComplexIndexOnTwoFieldsWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection we want to drop later\n\n        var collection = db.collection('more_complex_index_test_with_promise'); // Insert a bunch of documents for the index\n\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result); // Create an index on the a field\n\n          return db.createIndex('more_complex_index_test_with_promise', {\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          test.ok(indexName); // Show that duplicate records got dropped\n\n          return collection.find({}).toArray();\n        }).then(function (items) {\n          test.equal(4, items.length); // Perform a query, with explain to show we hit the query\n\n          return collection.find({\n            a: 2\n          }).explain();\n        }).then(function (explanation) {\n          test.ok(explanation != null);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCreateComplexEnsureIndexDbWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3225,"column":50,"index":102947},"line":3225,"code":"  it('shouldCreateComplexEnsureIndexDbWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection we want to drop later\n\n        var collection = db.collection('more_complex_ensure_index_db_test_with_promise'); // Insert a bunch of documents for the index\n\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result); // Create an index on the a field\n\n          return db.createIndex('more_complex_ensure_index_db_test_with_promise', {\n            a: 1,\n            b: 1\n          }, {\n            unique: true,\n            background: true,\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (indexName) {\n          test.ok(indexName); // Show that duplicate records got dropped\n\n          return collection.find({}).toArray();\n        }).then(function (items) {\n          test.equal(4, items.length); // Perform a query, with explain to show we hit the query\n\n          return collection.find({\n            a: 2\n          }).explain();\n        }).then(function (explanation) {\n          test.ok(explanation != null);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyDropTheDatabaseWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3298,"column":48,"index":105204},"line":3298,"code":"  it('shouldCorrectlyDropTheDatabaseWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection\n\n        var collection = db.collection('more_index_information_test_1_with_promise'); // Insert a bunch of documents for the index\n\n        return collection.insertMany([{\n          a: 1,\n          b: 1\n        }, {\n          a: 1,\n          b: 1\n        }, {\n          a: 2,\n          b: 2\n        }, {\n          a: 3,\n          b: 3\n        }, {\n          a: 4,\n          b: 4\n        }], configuration.writeConcernMax()).then(function (result) {\n          test.ok(result); // Let's drop the database\n\n          return db.dropDatabase();\n        }).then(function (result) {\n          test.ok(result); // Get the admin database\n\n          return db.admin().listDatabases();\n        }).then(function (dbs) {\n          // Grab the databases\n          dbs = dbs.databases; // Did we find the db\n\n          var found = false; // Check if we have the db in the list\n\n          for (var i = 0; i < dbs.length; i++) {\n            if (dbs[i].name === 'integration_tests_to_drop') found = true;\n          } // We should not find the databases\n\n\n          if (process.env['JENKINS'] == null) test.equal(false, found);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveDbStatsWithPromisesWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3369,"column":60,"index":107372},"line":3369,"code":"  it('shouldCorrectlyRetrieveDbStatsWithPromisesWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n\n        return db.stats().then(function (stats) {\n          test.ok(stats != null);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyShareConnectionPoolsAcrossMultipleDbInstancesWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3404,"column":78,"index":108536},"line":3404,"code":"  it('shouldCorrectlyShareConnectionPoolsAcrossMultipleDbInstancesWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Reference a different database sharing the same connections\n        // for the data transfer\n\n        var secondDb = client.db('integration_tests_2'); // Fetch the collections\n\n        var multipleColl1 = db.collection('multiple_db_instances_with_promise');\n        var multipleColl2 = secondDb.collection('multiple_db_instances_with_promise'); // Write a record into each and then count the records stored\n\n        return multipleColl1.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (result) {\n          test.ok(result);\n          return multipleColl2.insertOne({\n            a: 1\n          }, {\n            writeConcern: {\n              w: 1\n            }\n          });\n        }).then(function (result) {\n          test.ok(result); // Count over the results ensuring only on record in each collection\n\n          return multipleColl1.count();\n        }).then(function (count) {\n          test.equal(1, count);\n          return multipleColl2.count();\n        }).then(function (count) {\n          test.equal(1, count);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveBuildInfoWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3474,"column":50,"index":110850},"line":3474,"code":"  it('shouldCorrectlyRetrieveBuildInfoWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n        // Use the admin database for the operation\n\n        var adminDb = db.admin(); // Retrieve the build information for the MongoDB instance\n\n        return adminDb.buildInfo().then(function (info) {\n          test.ok(info);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveBuildInfoUsingCommandWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3513,"column":62,"index":112147},"line":3513,"code":"  it('shouldCorrectlyRetrieveBuildInfoUsingCommandWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n        // Use the admin database for the operation\n\n        var adminDb = db.admin(); // Retrieve the build information using the admin command\n\n        return adminDb.command({\n          buildInfo: 1\n        }).then(function (info) {\n          test.ok(info);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlySetDefaultProfilingLevelWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3554,"column":57,"index":113490},"line":3554,"code":"  it('shouldCorrectlySetDefaultProfilingLevelWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n        // Grab a collection object\n\n        var collection = db.collection('test_with_promise'); // Force the creation of the collection by inserting a document\n        // Collections are not created until the first document is inserted\n\n        return collection.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (doc) {\n          test.ok(doc); // Use the admin database for the operation\n\n          var adminDb = client.db('admin'); // Retrieve the profiling level\n\n          return adminDb.profilingLevel();\n        }).then(function (level) {\n          test.ok(level);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyChangeProfilingLevelWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3607,"column":53,"index":115265},"line":3607,"code":"  it('shouldCorrectlyChangeProfilingLevelWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n        // Grab a collection object\n\n        var collection = db.collection('test_with_promise');\n        var adminDb = client.db('admin'); // Force the creation of the collection by inserting a document\n        // Collections are not created until the first document is inserted\n\n        return collection.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (doc) {\n          test.ok(doc); // Set the profiling level to only profile slow queries\n\n          return adminDb.setProfilingLevel('slow_only');\n        }).then(function (level) {\n          test.ok(level); // Retrieve the profiling level and verify that it's set to slow_only\n\n          return adminDb.profilingLevel();\n        }).then(function (level) {\n          test.equal('slow_only', level); // Turn profiling off\n\n          return adminDb.setProfilingLevel('off');\n        }).then(function (level) {\n          test.ok(level); // Retrieve the profiling level and verify that it's set to off\n\n          return adminDb.profilingLevel();\n        }).then(function (level) {\n          test.equal('off', level); // Set the profiling level to log all queries\n\n          return adminDb.setProfilingLevel('all');\n        }).then(function (level) {\n          test.ok(level); // Retrieve the profiling level and verify that it's set to all\n\n          return adminDb.profilingLevel();\n        }).then(function (level) {\n          test.equal('all', level); // Attempt to set an illegal profiling level\n\n          return adminDb.setProfilingLevel('medium');\n        }).catch(function (err) {\n          test.ok(err instanceof Error);\n          test.equal(`Profiling level must be one of \"${enumToString(ProfilingLevel)}\"`, err.message);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCallValidateCollectionWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3684,"column":55,"index":118200},"line":3684,"code":"  it('shouldCorrectlyCallValidateCollectionWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n        // Grab a collection object\n\n        var collection = db.collection('test_with_promise'); // Force the creation of the collection by inserting a document\n        // Collections are not created until the first document is inserted\n\n        return collection.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (doc) {\n          test.ok(doc); // Use the admin database for the operation\n\n          var adminDb = db.admin(); // Validate the 'test' collection\n\n          return adminDb.validateCollection('test_with_promise');\n        }).then(function (doc) {\n          test.ok(doc);\n          return client.close();\n        });\n      });\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPingTheMongoDbInstanceWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3736,"column":55,"index":119910},"line":3736,"code":"  it('shouldCorrectlyPingTheMongoDbInstanceWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n        // Use the admin database for the operation\n\n        var adminDb = db.admin(); // Ping the server\n\n        return adminDb.ping().then(function (pingResult) {\n          test.ok(pingResult);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyAddAUserToAdminDbWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3775,"column":50,"index":121166},"line":3775,"code":"  it('shouldCorrectlyAddAUserToAdminDbWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n        // Use the admin database for the operation\n\n        var adminDb = db.admin(); // Add the new user to the admin database\n\n        return adminDb.addUser('admin11', 'admin11').then(function (result) {\n          test.ok(result);\n          return adminDb.removeUser('admin11');\n        }).then(function (result) {\n          test.ok(result);\n          return client.close();\n        });\n      });\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyAddAUserAndRemoveItFromAdminDbWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3817,"column":63,"index":122585},"line":3817,"code":"  it('shouldCorrectlyAddAUserAndRemoveItFromAdminDbWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n        // Use the admin database for the operation\n\n        var adminDb = db.admin(); // Add the new user to the admin database\n\n        return adminDb.addUser('admin12', 'admin12').then(function (result) {\n          test.ok(result); // Remove the user\n\n          return adminDb.removeUser('admin12');\n        }).then(function (result) {\n          test.equal(true, result);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyListAllAvailableDatabasesWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3860,"column":58,"index":124026},"line":3860,"code":"  it('shouldCorrectlyListAllAvailableDatabasesWithPromises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n        // Use the admin database for the operation\n\n        var adminDb = db.admin(); // List all the available databases\n\n        return adminDb.listDatabases().then(function (dbs) {\n          test.ok(dbs.databases.length > 0);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieveServerInfoWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3899,"column":51,"index":125302},"line":3899,"code":"  it('shouldCorrectlyRetrieveServerInfoWithPromises', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n        // Grab a collection object\n\n        var collection = db.collection('test_with_promise'); // Use the admin database for the operation\n\n        var adminDb = db.admin(); // Force the creation of the collection by inserting a document\n        // Collections are not created until the first document is inserted\n\n        return collection.insertOne({\n          a: 1\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (doc) {\n          test.ok(doc); // Add the new user to the admin database\n\n          return adminDb.addUser('admin13', 'admin13');\n        }).then(function (result) {\n          test.ok(result); // Retrieve the server Info\n\n          return adminDb.serverStatus();\n        }).then(function (info) {\n          test.ok(info != null);\n          return adminDb.removeUser('admin13');\n        }).then(function (result) {\n          test.ok(result);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyExecuteToArrayWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":3964,"column":47,"index":127460},"line":3964,"code":"  it('shouldCorrectlyExecuteToArrayWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection to hold our documents\n\n        var collection = db.collection('test_array_with_promise'); // Insert a test document\n\n        return collection.insertOne({\n          b: [1, 2, 3]\n        }, configuration.writeConcernMax()).then(function (ids) {\n          test.ok(ids); // Retrieve all the documents in the collection\n\n          return collection.find().toArray();\n        }).then(function (documents) {\n          test.equal(1, documents.length);\n          test.deepEqual([1, 2, 3], documents[0].b);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyUseCursorCountFunctionWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":4012,"column":55,"index":129189},"line":4012,"code":"  it('shouldCorrectlyUseCursorCountFunctionWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n        // Creat collection\n\n        var collection = db.collection('cursor_count_collection_with_promise'); // Insert some docs\n\n        return collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }], configuration.writeConcernMax()).then(function (docs) {\n          test.ok(docs); // Do a find and get the cursor count\n\n          return collection.find().count();\n        }).then(function (count) {\n          test.equal(2, count);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformNextOnCursorWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":4061,"column":52,"index":130824},"line":4061,"code":"  it('shouldCorrectlyPerformNextOnCursorWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection\n\n        var collection = db.collection('simple_next_object_collection_with_promise'); // Insert some documents we can sort on\n\n        return collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax()).then(function (docs) {\n          test.ok(docs); // Do normal ascending sort\n\n          return collection.find().next();\n        }).then(function (item) {\n          test.equal(1, item.a);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyPerformSimpleExplainCursorWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":4112,"column":59,"index":132538},"line":4112,"code":"  it('shouldCorrectlyPerformSimpleExplainCursorWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a collection\n\n        var collection = db.collection('simple_explain_collection_with_promise'); // Insert some documents we can sort on\n\n        return collection.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }, {\n          a: 3\n        }], configuration.writeConcernMax()).then(function (docs) {\n          test.ok(docs); // Do normal ascending sort\n\n          return collection.find().explain();\n        }).then(function (explanation) {\n          test.ok(explanation);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"shouldStreamDocumentsUsingTheCloseFunctionWithPromises","suites":["Operation (Promises)"],"updatePoint":{"line":4163,"column":60,"index":134254},"line":4163,"code":"  it('shouldStreamDocumentsUsingTheCloseFunctionWithPromises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a lot of documents to insert\n\n        var docs = [];\n\n        for (var i = 0; i < 100; i++) {\n          docs.push({\n            a: i\n          });\n        } // Create a collection\n\n\n        var collection = db.collection('test_close_function_on_cursor_with_promise'); // Perform a find to get a cursor\n\n        var cursor = collection.find(); // Insert documents into collection\n\n        return collection.insertMany(docs, configuration.writeConcernMax()).then(function (ids) {\n          test.ok(ids); // Fetch the first object\n\n          return cursor.next();\n        }).then(function (object) {\n          test.ok(object); // Close the cursor, this is the same as reseting the query\n\n          return cursor.close();\n        }).then(function () {\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly connect to a replicaset With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":4227,"column":60,"index":136425},"line":4227,"code":"  it('Should correctly connect to a replicaset With Promises', {\n    metadata: {\n      requires: {\n        topology: 'replicaset'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var url = f('mongodb://%s,%s/%s?replicaSet=%s&readPreference=%s', f('%s:%s', configuration.host, configuration.port), f('%s:%s', configuration.host, configuration.port + 1), 'integration_test_', configuration.replicasetName, 'primary');\n      const client = configuration.newClient(url);\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        test.ok(db != null);\n        return db.collection('replicaset_mongo_client_collection_with_promise').updateOne({\n          a: 1\n        }, {\n          $set: {\n            b: 1\n          }\n        }, {\n          upsert: true\n        }).then(function (result) {\n          expect(result).property('upsertedCount').to.equal(1);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should connect to mongos proxies using connectiong string With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":4270,"column":77,"index":138039},"line":4270,"code":"  it('Should connect to mongos proxies using connectiong string With Promises', {\n    metadata: {\n      requires: {\n        topology: 'sharded'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var url = f('mongodb://%s:%s,%s:%s/sharded_test_db?w=1', configuration.host, configuration.port, configuration.host, configuration.port + 1);\n      const client = configuration.newClient(url);\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        test.ok(db != null);\n        return db.collection('replicaset_mongo_client_collection_with_promise').updateOne({\n          a: 1\n        }, {\n          $set: {\n            b: 1\n          }\n        }, {\n          upsert: true\n        }).then(function (result) {\n          test.equal(1, result.upsertedCount);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly connect using MongoClient to a single server using connect With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":4313,"column":95,"index":139527},"line":4313,"code":"  it('Should correctly connect using MongoClient to a single server using connect With Promises', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      const client = configuration.newClient(); // DOC_START\n      // Connect using the connection string\n\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE restartAndDone\n        // REMOVE-LINE done();\n        // BEGIN\n\n        return db.collection('mongoclient_test_with_promise').updateOne({\n          a: 1\n        }, {\n          $set: {\n            b: 1\n          }\n        }, {\n          upsert: true\n        }).then(function (result) {\n          expect(result).property('upsertedCount').to.equal(1);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute ordered batch with no errors using write commands With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":4365,"column":94,"index":141268},"line":4365,"code":"  it('Should correctly execute ordered batch with no errors using write commands With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n\n        var col = db.collection('batch_write_ordered_ops_0_with_promise'); // Initialize the Ordered Batch\n\n        var batch = col.initializeOrderedBulkOp(); // Add some operations to be executed in order\n\n        batch.insert({\n          a: 1\n        });\n        batch.find({\n          a: 1\n        }).updateOne({\n          $set: {\n            b: 1\n          }\n        });\n        batch.find({\n          a: 2\n        }).upsert().updateOne({\n          $set: {\n            b: 2\n          }\n        });\n        batch.insert({\n          a: 3\n        });\n        batch.find({\n          a: 3\n        }).delete({\n          a: 3\n        }); // Execute the operations\n\n        return batch.execute().then(function (result) {\n          // Check state of result\n          test.equal(2, result.nInserted);\n          test.equal(1, result.nUpserted);\n          test.equal(1, result.nMatched);\n          test.ok(1 === result.nModified || result.nModified === 0 || result.nModified == null);\n          test.equal(1, result.nRemoved);\n          var upserts = result.getUpsertedIds();\n          test.equal(1, upserts.length);\n          test.equal(2, upserts[0].index);\n          test.ok(upserts[0]._id != null);\n          var upsert = result.getUpsertedIdAt(0);\n          test.equal(2, upsert.index);\n          test.ok(upsert._id != null); // Finish up test\n\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute unordered batch with no errors With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":4445,"column":75,"index":143739},"line":4445,"code":"  it('Should correctly execute unordered batch with no errors With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n\n        var col = db.collection('batch_write_unordered_ops_legacy_0_with_promise'); // Initialize the unordered Batch\n\n        var batch = col.initializeUnorderedBulkOp(); // Add some operations to be executed in order\n\n        batch.insert({\n          a: 1\n        });\n        batch.find({\n          a: 1\n        }).updateOne({\n          $set: {\n            b: 1\n          }\n        });\n        batch.find({\n          a: 2\n        }).upsert().updateOne({\n          $set: {\n            b: 2\n          }\n        });\n        batch.insert({\n          a: 3\n        });\n        batch.find({\n          a: 3\n        }).delete({\n          a: 3\n        }); // Execute the operations\n\n        return batch.execute().then(function (result) {\n          // Check state of result\n          test.equal(2, result.nInserted);\n          test.equal(1, result.nUpserted);\n          test.equal(1, result.nMatched);\n          test.ok(1 === result.nModified || result.nModified === 0 || result.nModified == null);\n          test.equal(1, result.nRemoved);\n          var upserts = result.getUpsertedIds();\n          test.equal(1, upserts.length);\n          test.equal(2, upserts[0].index);\n          test.ok(upserts[0]._id != null);\n          var upsert = result.getUpsertedIdAt(0);\n          test.equal(2, upsert.index);\n          test.ok(upsert._id != null); // Finish up test\n\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute insertOne operation With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":4530,"column":64,"index":146339},"line":4530,"code":"  it('Should correctly execute insertOne operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n\n        var col = db.collection('insert_one_with_promise');\n        return col.insertOne({\n          a: 1\n        }).then(function (r) {\n          expect(r).property('insertedId').to.exist; // Finish up test\n\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute insertMany operation With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":4570,"column":65,"index":147612},"line":4570,"code":"  it('Should correctly execute insertMany operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n\n        var col = db.collection('insert_many_with_promise');\n        return col.insertMany([{\n          a: 1\n        }, {\n          a: 2\n        }]).then(function (r) {\n          test.equal(2, r.insertedCount); // Finish up test\n\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute updateOne operation With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":4612,"column":64,"index":148903},"line":4612,"code":"  it('Should correctly execute updateOne operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n\n        var col = db.collection('update_one_with_promise');\n        return col.updateOne({\n          a: 1\n        }, {\n          $set: {\n            a: 2\n          }\n        }, {\n          upsert: true\n        }).then(function (r) {\n          test.equal(0, r.matchedCount);\n          test.equal(1, r.upsertedCount); // Finish up test\n\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute updateMany operation With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":4659,"column":65,"index":150302},"line":4659,"code":"  it('Should correctly execute updateMany operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n\n        var col = db.collection('update_many_with_promise');\n        return col.insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }]).then(function (r) {\n          test.equal(2, r.insertedCount); // Update all documents\n\n          return col.updateMany({\n            a: 1\n          }, {\n            $set: {\n              b: 1\n            }\n          });\n        }).then(function (r) {\n          if (r.n) {\n            test.equal(2, r.n);\n          } else {\n            test.equal(2, r.matchedCount);\n            test.equal(2, r.modifiedCount);\n          } // Finish up test\n\n\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute deleteOne operation With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":4717,"column":64,"index":151954},"line":4717,"code":"  it('Should correctly execute deleteOne operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n\n        var col = db.collection('remove_one_with_promise');\n        return col.insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }]).then(function (r) {\n          test.equal(2, r.insertedCount);\n          return col.deleteOne({\n            a: 1\n          });\n        }).then(function (r) {\n          test.equal(1, r.deletedCount); // Finish up test\n\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute deleteMany operation With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":4764,"column":65,"index":153383},"line":4764,"code":"  it('Should correctly execute deleteMany operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n\n        var col = db.collection('remove_many_with_promise');\n        return col.insertMany([{\n          a: 1\n        }, {\n          a: 1\n        }]).then(function (r) {\n          test.equal(2, r.insertedCount); // Update all documents\n\n          return col.deleteMany({\n            a: 1\n          });\n        }).then(function (r) {\n          test.equal(2, r.deletedCount); // Finish up test\n\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute bulkWrite operation With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":4812,"column":64,"index":154836},"line":4812,"code":"  it('Should correctly execute bulkWrite operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n\n        var col = db.collection('bulk_write_with_promise');\n        return col.bulkWrite([{\n          insertOne: {\n            document: {\n              a: 1\n            }\n          }\n        }, {\n          updateOne: {\n            filter: {\n              a: 2\n            },\n            update: {\n              $set: {\n                a: 2\n              }\n            },\n            upsert: true\n          }\n        }, {\n          updateMany: {\n            filter: {\n              a: 2\n            },\n            update: {\n              $set: {\n                a: 2\n              }\n            },\n            upsert: true\n          }\n        }, {\n          deleteOne: {\n            filter: {\n              c: 1\n            }\n          }\n        }, {\n          deleteMany: {\n            filter: {\n              c: 1\n            }\n          }\n        }, {\n          replaceOne: {\n            filter: {\n              c: 3\n            },\n            replacement: {\n              c: 4\n            },\n            upsert: true\n          }\n        }], {\n          ordered: true,\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (r) {\n          test.equal(1, r.nInserted);\n          test.equal(2, r.nUpserted);\n          test.equal(0, r.nRemoved); // Crud fields\n\n          test.equal(1, r.insertedCount);\n          test.equal(1, Object.keys(r.insertedIds).length);\n          test.equal(1, r.matchedCount);\n          test.ok(r.modifiedCount === 0 || r.modifiedCount === 1);\n          test.equal(0, r.deletedCount);\n          test.equal(2, r.upsertedCount);\n          test.equal(2, Object.keys(r.upsertedIds).length); // Ordered bulk operation\n\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly handle duplicate key error with bulkWrite","suites":["Operation (Promises)"],"updatePoint":{"line":4914,"column":64,"index":157460},"line":4914,"code":"  it('Should correctly handle duplicate key error with bulkWrite', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // Get the collection\n\n        var col = db.collection('bulk_write_with_promise_write_error');\n        return col.bulkWrite([{\n          insertOne: {\n            document: {\n              _id: 1\n            }\n          }\n        }, {\n          insertOne: {\n            document: {\n              _id: 1\n            }\n          }\n        }], {\n          ordered: true,\n          writeConcern: {\n            w: 1\n          }\n        }).catch(function (err) {\n          test.equal(true, err.result.hasWriteErrors()); // Ordered bulk operation\n\n          return client.close();\n        });\n      });\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndDelete operation With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":4961,"column":71,"index":158659},"line":4961,"code":"  it('Should correctly execute findOneAndDelete operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n\n        var col = db.collection('find_one_and_delete_with_promise');\n        return col.insertMany([{\n          a: 1,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (r) {\n          expect(r).property('insertedCount').to.equal(1);\n          return col.findOneAndDelete({\n            a: 1\n          }, {\n            projection: {\n              b: 1\n            },\n            sort: {\n              a: 1\n            }\n          });\n        }).then(function (r) {\n          test.equal(1, r.lastErrorObject.n);\n          test.equal(1, r.value.b);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndReplace operation With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":5018,"column":72,"index":160348},"line":5018,"code":"  it('Should correctly execute findOneAndReplace operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n\n        var col = db.collection('find_one_and_replace_with_promise');\n        return col.insertMany([{\n          a: 1,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (r) {\n          expect(r).property('insertedCount').to.equal(1);\n          return col.findOneAndReplace({\n            a: 1\n          }, {\n            c: 1,\n            b: 1\n          }, {\n            projection: {\n              b: 1,\n              c: 1\n            },\n            sort: {\n              a: 1\n            },\n            returnDocument: ReturnDocument.AFTER,\n            upsert: true\n          }).then(function (r) {\n            test.equal(1, r.lastErrorObject.n);\n            test.equal(1, r.value.b);\n            test.equal(1, r.value.c);\n            return client.close();\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly execute findOneAndUpdate operation With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":5082,"column":71,"index":162228},"line":5082,"code":"  it('Should correctly execute findOneAndUpdate operation With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function () {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      return client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Get the collection\n\n        var col = db.collection('find_one_and_update_with_promise');\n        return col.insertMany([{\n          a: 1,\n          b: 1\n        }], {\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (r) {\n          expect(r).property('insertedCount').to.equal(1);\n          return col.findOneAndUpdate({\n            a: 1\n          }, {\n            $set: {\n              d: 1\n            }\n          }, {\n            projection: {\n              b: 1,\n              d: 1\n            },\n            sort: {\n              a: 1\n            },\n            returnDocument: ReturnDocument.AFTER,\n            upsert: true\n          });\n        }).then(function (r) {\n          test.equal(1, r.lastErrorObject.n);\n          test.equal(1, r.value.b);\n          test.equal(1, r.value.d);\n          return client.close();\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"Should correctly add capped collection options to cursor With Promises","suites":["Operation (Promises)"],"updatePoint":{"line":5147,"column":76,"index":164126},"line":5147,"code":"  it('Should correctly add capped collection options to cursor With Promises', {\n    metadata: {\n      requires: {\n        topology: ['single']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect().then(function (client) {\n        var db = client.db(configuration.db); // LINE var MongoClient = require('mongodb').MongoClient,\n        // LINE   test = require('assert');\n        // LINE const client = new MongoClient('mongodb://localhost:27017/test');\n        // LINE client.connect().then(() => {\n        // LINE   var db = client.db('test);\n        // REPLACE configuration.writeConcernMax() WITH {w:1}\n        // REMOVE-LINE done();\n        // BEGIN\n        // Create a capped collection with a maximum of 1000 documents\n\n        var collection;\n        db.createCollection('a_simple_collection_2_with_promise', {\n          capped: true,\n          size: 100000,\n          max: 1000,\n          writeConcern: {\n            w: 1\n          }\n        }).then(function (_collection) {\n          collection = _collection;\n          var docs = [];\n\n          for (var i = 0; i < 1000; i++) docs.push({\n            a: i\n          }); // Insert a document in the capped collection\n\n\n          return collection.insertMany(docs, configuration.writeConcernMax());\n        }).then(function (result) {\n          test.ok(result);\n          var total = 0; // Get the cursor\n\n          var cursor = collection.find({\n            a: {\n              $gte: 0\n            }\n          }).addCursorFlag('tailable', true).addCursorFlag('awaitData', true);\n          const stream = cursor.stream();\n          stream.on('data', function (d) {\n            test.ok(d);\n            total = total + 1;\n\n            if (total === 1000) {\n              cursor.close();\n            }\n          });\n          cursor.on('close', function () {\n            // TODO: forced because the cursor is still open/active\n            client.close(true, done);\n          });\n        });\n      }); // END\n    }\n  });","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"should be able to run transactions example 1","suites":["Operation (Promises)","Transaction Examples"],"updatePoint":{"line":5220,"column":52,"index":166670},"line":5220,"code":"    it('should be able to run transactions example 1', {\n      metadata: {\n        requires: {\n          topology: ['replicaset'],\n          mongodb: '>=3.8.0'\n        }\n      },\n      test: function () {\n        const configuration = this.configuration;\n        const client = configuration.newClient(configuration.writeConcernMax()); // BEGIN\n\n        function updateEmployeeInfo(client) {\n          return client.withSession(session => {\n            function commit() {\n              return session.commitTransaction().catch(e => {\n                if (e.hasErrorLabel('UnknownTransactionCommitResult')) {\n                  // LINE console.log('Transaction aborted. Caught exception during transaction.');\n                  return commit();\n                } // LINE console.log('Error during commit ...');\n\n\n                throw e;\n              });\n            }\n\n            const employeesCollection = client.db('hr').collection('employees');\n            const eventsCollection = client.db('reporting').collection('events');\n            session.startTransaction({\n              readConcern: {\n                level: 'snapshot'\n              },\n              writeConcern: {\n                w: 'majority'\n              }\n            });\n            return employeesCollection.updateOne({\n              employee: 3\n            }, {\n              $set: {\n                status: 'Inactive'\n              }\n            }, {\n              session\n            }).then(() => {\n              return eventsCollection.insertOne({\n                employee: 3,\n                status: {\n                  new: 'Inactive',\n                  old: 'Active'\n                }\n              }, {\n                session\n              });\n            }).catch(e => {\n              // LINE console.log('caugh exception during transaction, aborting')\n              return session.abortTransaction().then(() => Promise.reject(e));\n            }).then(() => commit()).then(() => {// LINE console.log('Transaction committed');\n            });\n          }); // END\n        }\n\n        return client.connect().then(() => updateEmployeeInfo(client)).then(() => client.close());\n      }\n    }); // End Transactions Intro Example 1","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"should be able to run transactions retry example 1","suites":["Operation (Promises)","Transaction Examples"],"updatePoint":{"line":5286,"column":58,"index":168929},"line":5286,"code":"    it('should be able to run transactions retry example 1', {\n      metadata: {\n        requires: {\n          topology: ['replicaset'],\n          mongodb: '>=3.8.0'\n        }\n      },\n      test: function () {\n        // BEGIN\n        function runTransactionWithRetry(txnFunc, client, session) {\n          return txnFunc(client, session).catch(error => {\n            // LINE console.log('Transaction aborted. Caught exception during transaction.');\n            // If transient error, retry the whole transaction\n            if (error.hasErrorLabel('TransientTransactionError')) {\n              // LINE console.log('TransientTransactionError, retrying transaction ...');\n              return runTransactionWithRetry(txnFunc, client, session);\n            }\n\n            throw error;\n          });\n        } // END\n\n\n        function updateEmployeeInfo(client, session) {\n          session.startTransaction({\n            readConcern: {\n              level: 'snapshot'\n            },\n            writeConcern: {\n              w: 'majority'\n            }\n          });\n          const employeesCollection = client.db('hr').collection('employees');\n          const eventsCollection = client.db('reporting').collection('events');\n          return employeesCollection.updateOne({\n            employee: 3\n          }, {\n            $set: {\n              status: 'Inactive'\n            }\n          }, {\n            session\n          }).then(() => {\n            return eventsCollection.insertOne({\n              employee: 3,\n              status: {\n                new: 'Inactive',\n                old: 'Active'\n              }\n            }, {\n              session\n            });\n          }).then(() => session.commitTransaction()).catch(e => {\n            return session.abortTransaction().then(() => Promise.reject(e));\n          });\n        }\n\n        const configuration = this.configuration;\n        const client = configuration.newClient(configuration.writeConcernMax());\n        return client.connect().then(() => client.withSession(session => runTransactionWithRetry(updateEmployeeInfo, client, session))).then(() => client.close());\n      }\n    }); // End Transactions Retry Example 1","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"should be able to run transactions retry example 2","suites":["Operation (Promises)","Transaction Examples"],"updatePoint":{"line":5350,"column":58,"index":171161},"line":5350,"code":"    it('should be able to run transactions retry example 2', {\n      metadata: {\n        requires: {\n          topology: ['replicaset'],\n          mongodb: '>=3.8.0'\n        }\n      },\n      test: function () {\n        // BEGIN\n        function commitWithRetry(session) {\n          return session.commitTransaction() // LINE .then(() => console.log('Transaction committed.'))\n          .catch(error => {\n            if (error.hasErrorLabel('UnknownTransactionCommitResult')) {\n              // LINE console.log('UnknownTransactionCommitResult, retrying commit operation ...');\n              return commitWithRetry(session);\n            } // LINE console.log('Error during commit ...');\n\n\n            throw error;\n          });\n        } // END\n\n\n        function updateEmployeeInfo(client, session) {\n          session.startTransaction({\n            readConcern: {\n              level: 'snapshot'\n            },\n            writeConcern: {\n              w: 'majority'\n            }\n          });\n          const employeesCollection = client.db('hr').collection('employees');\n          const eventsCollection = client.db('reporting').collection('events');\n          return employeesCollection.updateOne({\n            employee: 3\n          }, {\n            $set: {\n              status: 'Inactive'\n            }\n          }, {\n            session\n          }).then(() => {\n            return eventsCollection.insertOne({\n              employee: 3,\n              status: {\n                new: 'Inactive',\n                old: 'Active'\n              }\n            }, {\n              session\n            });\n          }).then(() => commitWithRetry(session)).catch(e => {\n            return session.abortTransaction().then(() => Promise.reject(e));\n          });\n        }\n\n        const configuration = this.configuration;\n        const client = configuration.newClient(configuration.writeConcernMax());\n        return client.connect().then(() => client.withSession(session => updateEmployeeInfo(client, session))).then(() => client.close());\n      }\n    }); // End Transactions Retry Example 2","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"should be able to run transactions retry example 3","suites":["Operation (Promises)","Transaction Examples"],"updatePoint":{"line":5414,"column":58,"index":173295},"line":5414,"code":"    it('should be able to run transactions retry example 3', {\n      metadata: {\n        requires: {\n          topology: ['replicaset'],\n          mongodb: '>=3.8.0'\n        }\n      },\n      test: function () {\n        const configuration = this.configuration;\n        const client = configuration.newClient(configuration.writeConcernMax()); // BEGIN\n\n        function commitWithRetry(session) {\n          return session.commitTransaction() // LINE .then(() => console.log('Transaction committed.'))\n          .catch(error => {\n            if (error.hasErrorLabel('UnknownTransactionCommitResult')) {\n              // LINE console.log('UnknownTransactionCommitResult, retrying commit operation ...');\n              return commitWithRetry(session);\n            } // LINE console.log('Error during commit ...');\n\n\n            throw error;\n          });\n        }\n\n        function runTransactionWithRetry(txnFunc, client, session) {\n          return txnFunc(client, session).catch(error => {\n            // LINE console.log('Transaction aborted. Caught exception during transaction.');\n            // If transient error, retry the whole transaction\n            if (error.hasErrorLabel('TransientTransactionError')) {\n              // LINE console.log('TransientTransactionError, retrying transaction ...');\n              return runTransactionWithRetry(txnFunc, client, session);\n            }\n\n            throw error;\n          });\n        }\n\n        function updateEmployeeInfo(client, session) {\n          const employeesCollection = client.db('hr').collection('employees');\n          const eventsCollection = client.db('reporting').collection('events');\n          session.startTransaction({\n            readConcern: {\n              level: 'snapshot'\n            },\n            writeConcern: {\n              w: 'majority'\n            }\n          });\n          return employeesCollection.updateOne({\n            employee: 3\n          }, {\n            $set: {\n              status: 'Inactive'\n            }\n          }, {\n            session\n          }).then(() => {\n            return eventsCollection.insertOne({\n              employee: 3,\n              status: {\n                new: 'Inactive',\n                old: 'Active'\n              }\n            }, {\n              session\n            });\n          }).catch(e => {\n            // LINE console.log('caugh exception during transaction, aborting')\n            return session.abortTransaction().then(() => Promise.reject(e));\n          }).then(() => commitWithRetry(session));\n        } // LINE const { MongoClient } = require('mongodb'),\n        // LINE const client = new MongoClient('myRepl/mongodb0.example.net:27017,mongodb1.example.net:27017,mongodb2.example.net:27017');\n\n\n        return client.connect().then(() => client.withSession(session => runTransactionWithRetry(updateEmployeeInfo, client, session))).then(() => client.close()); // END\n      }\n    }); // End Transactions Retry Example 3","file":"integration/node-specific/operation_promises_example.test.js","skipped":false,"dir":"test"},{"name":"should correctly track states of a topology","suites":["Topology"],"updatePoint":{"line":8,"column":49,"index":139},"line":8,"code":"  it('should correctly track states of a topology', {\n    metadata: {\n      requires: {\n        apiVersion: false,\n        topology: '!load-balanced'\n      }\n    },\n    // apiVersion not supported by newTopology()\n    test: function (done) {\n      const topology = this.configuration.newTopology();\n      const states = [];\n      topology.on('stateChanged', (_, newState) => states.push(newState));\n      topology.connect(err => {\n        expect(err).to.not.exist;\n        topology.close(err => {\n          expect(err).to.not.exist;\n          expect(topology.isDestroyed()).to.be.true;\n          expect(states).to.eql(['connecting', 'connected', 'closing', 'closed']);\n          done();\n        });\n      });\n    }\n  });","file":"integration/node-specific/topology.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyGenerateObjectId","suites":["ObjectId"],"updatePoint":{"line":19,"column":37,"index":344},"line":19,"code":"  it('shouldCorrectlyGenerateObjectId', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var number_of_tests_done = 0;\n        var collection = db.collection('test_object_id_generation.data'); // Insert test documents (creates collections and test fetch by query)\n\n        collection.insert({\n          name: 'Fred',\n          age: 42\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          expect(r).property('insertedCount').to.equal(1);\n          const id = r.insertedIds[0];\n          expect(id.toHexString().length).to.equal(24); // Locate the first document inserted\n\n          collection.findOne({\n            name: 'Fred'\n          }, function (err, document) {\n            expect(err).to.not.exist;\n            expect(id.toHexString()).to.equal(document._id.toHexString());\n            number_of_tests_done++;\n          });\n        }); // Insert another test document and collect using ObjectId\n\n        collection.insert({\n          name: 'Pat',\n          age: 21\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          expect(r).property('insertedCount').to.equal(1);\n          const id = r.insertedIds[0];\n          expect(id.toHexString().length).to.equal(24); // Locate the first document inserted\n\n          collection.findOne(id, function (err, document) {\n            expect(err).to.not.exist;\n            expect(id.toHexString()).to.equal(document._id.toHexString());\n            number_of_tests_done++;\n          });\n        }); // Manually created id\n\n        var objectId = new ObjectId(null); // Insert a manually created document with generated oid\n\n        collection.insert({\n          _id: objectId,\n          name: 'Donald',\n          age: 95\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err, r) {\n          expect(err).to.not.exist;\n          expect(r).property('insertedCount').to.equal(1);\n          const id = r.insertedIds[0];\n          expect(id.toHexString().length).to.equal(24);\n          expect(id.toHexString()).to.equal(objectId.toHexString()); // Locate the first document inserted\n\n          collection.findOne(id, function (err, document) {\n            expect(err).to.not.exist;\n            expect(id.toHexString()).to.equal(document._id.toHexString());\n            expect(objectId.toHexString()).to.equal(document._id.toHexString());\n            number_of_tests_done++;\n          });\n        });\n        var intervalId = setInterval(function () {\n          if (number_of_tests_done === 3) {\n            clearInterval(intervalId);\n            client.close(done);\n          }\n        }, 100);\n      });\n    }\n  });","file":"integration/objectid.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieve24CharacterHexStringFromToString","suites":["ObjectId"],"updatePoint":{"line":108,"column":61,"index":3444},"line":108,"code":"  it('shouldCorrectlyRetrieve24CharacterHexStringFromToString', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      // Create a new ObjectId\n      var objectId = new ObjectId(); // Verify that the hex string is 24 characters long\n\n      test.equal(24, objectId.toString().length);\n      done();\n    }\n  });","file":"integration/objectid.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyRetrieve24CharacterHexStringFromToJSON","suites":["ObjectId"],"updatePoint":{"line":122,"column":59,"index":3865},"line":122,"code":"  it('shouldCorrectlyRetrieve24CharacterHexStringFromToJSON', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      // Create a new ObjectId\n      var objectId = new ObjectId(); // Verify that the hex string is 24 characters long\n\n      test.equal(24, objectId.toJSON().length);\n      done();\n    }\n  });","file":"integration/objectid.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateOIDNotUsingObjectId","suites":["ObjectId"],"updatePoint":{"line":136,"column":46,"index":4271},"line":136,"code":"  it('shouldCorrectlyCreateOIDNotUsingObjectId', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        var collection = db.collection('test_non_oid_id');\n        var date = new Date();\n        date.setUTCDate(12);\n        date.setUTCFullYear(2009);\n        date.setUTCMonth(11 - 1);\n        date.setUTCHours(12);\n        date.setUTCMinutes(0);\n        date.setUTCSeconds(30);\n        collection.insert({\n          _id: date\n        }, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          collection.find({\n            _id: date\n          }).toArray(function (err, items) {\n            test.equal('' + date, '' + items[0]._id); // Let's close the db\n\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/objectid.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyGenerateObjectIdFromTimestamp","suites":["ObjectId"],"updatePoint":{"line":176,"column":50,"index":5448},"line":176,"code":"  it('shouldCorrectlyGenerateObjectIdFromTimestamp', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var timestamp = Math.floor(new Date().getTime() / 1000);\n      var objectID = new ObjectId(timestamp);\n      var time2 = objectID.generationTime;\n      test.equal(timestamp, time2);\n      done();\n    }\n  });","file":"integration/objectid.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyCreateAnObjectIdAndOverrideTheTimestamp","suites":["ObjectId"],"updatePoint":{"line":190,"column":60,"index":5887},"line":190,"code":"  it('shouldCorrectlyCreateAnObjectIdAndOverrideTheTimestamp', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var timestamp = 1000;\n      var objectID = new ObjectId();\n      var id1 = objectID.id; // Override the timestamp\n\n      objectID.generationTime = timestamp;\n      var id2 = objectID.id; // Check the timestamp\n\n      if (id1 instanceof Buffer && id2 instanceof Buffer) {\n        test.deepEqual(id1.slice(0, 4), id2.slice(0, 4));\n      } else {\n        test.equal(id1.substr(4), id2.substr(4));\n      }\n\n      done();\n    }\n  });","file":"integration/objectid.test.js","skipped":false,"dir":"test"},{"name":"shouldCorrectlyInsertWithObjectId","suites":["ObjectId"],"updatePoint":{"line":213,"column":39,"index":6526},"line":213,"code":"  it('shouldCorrectlyInsertWithObjectId', {\n    metadata: {\n      requires: {\n        topology: ['single', 'replicaset', 'sharded', 'ssl', 'heap', 'wiredtiger']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(configuration.db);\n        var collection = db.collection('shouldCorrectlyInsertWithObjectId');\n        collection.insert({}, {\n          writeConcern: {\n            w: 1\n          }\n        }, function (err) {\n          expect(err).to.not.exist;\n          const firstCompareDate = new Date();\n          setTimeout(function () {\n            collection.insert({}, {\n              writeConcern: {\n                w: 1\n              }\n            }, function (err) {\n              expect(err).to.not.exist;\n              const secondCompareDate = new Date();\n              collection.find().toArray(function (err, items) {\n                expect(err).to.not.exist; // Date 1\n\n                var date1 = new Date();\n                date1.setTime(items[0]._id.generationTime * 1000); // Date 2\n\n                var date2 = new Date();\n                date2.setTime(items[1]._id.generationTime * 1000); // Compare\n\n                test.equal(firstCompareDate.getFullYear(), date1.getFullYear());\n                test.equal(firstCompareDate.getDate(), date1.getDate());\n                test.equal(firstCompareDate.getMonth(), date1.getMonth());\n                test.equal(firstCompareDate.getHours(), date1.getHours());\n                test.equal(secondCompareDate.getFullYear(), date2.getFullYear());\n                test.equal(secondCompareDate.getDate(), date2.getDate());\n                test.equal(secondCompareDate.getMonth(), date2.getMonth());\n                test.equal(secondCompareDate.getHours(), date2.getHours()); // Let's close the db\n\n                client.close(done);\n              });\n            });\n          }, 2000);\n        });\n      });\n    }\n  });","file":"integration/objectid.test.js","skipped":false,"dir":"test"},{"name":"Should set majority readConcern aggregate command but ignore due to out","suites":["ReadConcern","client-url specific ReadConcern"],"updatePoint":{"line":272,"column":77,"index":8400},"line":272,"code":"  it('Should set majority readConcern aggregate command but ignore due to out', {\n    metadata: {\n      requires: {\n        topology: 'replicaset',\n        mongodb: '>= 3.2 < 4.1'\n      }\n    },\n    test: function (done) {\n      const started = [];\n      const succeeded = []; // Get a new instance\n\n      const configuration = this.configuration;\n      client = configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1,\n        readConcern: {\n          level: 'majority'\n        },\n        monitorCommands: true\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        const db = client.db(configuration.db);\n        expect(db.readConcern).to.deep.equal({\n          level: 'majority'\n        }); // Get a collection\n\n        const collection = db.collection('readConcernCollectionAggregate1'); // Validate readConcern\n\n        expect(collection.readConcern).to.deep.equal({\n          level: 'majority'\n        }); // Listen to apm events\n\n        client.on('commandStarted', filterForCommands('aggregate', started));\n        client.on('commandSucceeded', filterForCommands('aggregate', succeeded)); // Execute find\n\n        collection.aggregate([{\n          $match: {}\n        }, {\n          $out: 'readConcernCollectionAggregate1Output'\n        }]).toArray(err => {\n          expect(err).to.not.exist;\n          validateTestResults(started, succeeded, 'aggregate'); // Execute find\n\n          collection.aggregate([{\n            $match: {}\n          }], {\n            out: 'readConcernCollectionAggregate2Output'\n          }).toArray(err => {\n            expect(err).to.not.exist;\n            validateTestResults(started, succeeded, 'aggregate');\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/read-write-concern/readconcern.test.js","skipped":false,"dir":"test"},{"name":"Should set majority readConcern aggregate command against server >= 4.1","suites":["ReadConcern","client-url specific ReadConcern"],"updatePoint":{"line":330,"column":77,"index":10168},"line":330,"code":"  it('Should set majority readConcern aggregate command against server >= 4.1', {\n    metadata: {\n      requires: {\n        topology: 'replicaset',\n        mongodb: '>= 4.1'\n      }\n    },\n    test: function (done) {\n      const started = [];\n      const succeeded = []; // Get a new instance\n\n      const configuration = this.configuration;\n      client = configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1,\n        readConcern: {\n          level: 'majority'\n        },\n        monitorCommands: true\n      });\n      client.connect().then(() => {\n        // Get a collection\n        const collection = client.db(configuration.db).collection('readConcernCollectionAggregate1'); // Listen to apm events\n\n        client.on('commandStarted', filterForCommands('aggregate', started));\n        client.on('commandSucceeded', filterForCommands('aggregate', succeeded)); // Execute find\n\n        return collection.aggregate([{\n          $match: {}\n        }, {\n          $out: 'readConcernCollectionAggregate1Output'\n        }]).toArray().then(() => {\n          validateTestResults(started, succeeded, 'aggregate', 'majority'); // Execute find\n\n          return collection.aggregate([{\n            $match: {}\n          }], {\n            out: 'readConcernCollectionAggregate2Output'\n          }).toArray().then(() => {\n            validateTestResults(started, succeeded, 'aggregate', 'majority');\n          });\n        });\n      }).then(() => client.close(done), e => client.close(() => done(e)));\n    }\n  });","file":"integration/read-write-concern/readconcern.test.js","skipped":false,"dir":"test"},{"name":"Should set majority readConcern mapReduce command but be ignored","suites":["ReadConcern","client-url specific ReadConcern"],"updatePoint":{"line":376,"column":70,"index":11683},"line":376,"code":"  it('Should set majority readConcern mapReduce command but be ignored', {\n    metadata: {\n      requires: {\n        topology: 'replicaset',\n        mongodb: '>= 3.2'\n      }\n    },\n    test: function (done) {\n      const started = [];\n      const succeeded = []; // Get a new instance\n\n      const configuration = this.configuration;\n      client = configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1,\n        readConcern: {\n          level: 'majority'\n        },\n        monitorCommands: true\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        const db = client.db(configuration.db);\n        expect(db.readConcern).to.deep.equal({\n          level: 'majority'\n        }); // Get the collection\n\n        const collection = db.collection('test_map_reduce_read_concern');\n        collection.insertMany([{\n          user_id: 1\n        }, {\n          user_id: 2\n        }], configuration.writeConcernMax(), err => {\n          expect(err).to.not.exist; // String functions\n\n          const map = 'function() { emit(this.user_id, 1); }';\n          const reduce = 'function(k,vals) { return 1; }'; // Listen to apm events\n\n          client.on('commandStarted', filterForCommands('mapReduce', started));\n          client.on('commandSucceeded', filterForCommands('mapReduce', succeeded)); // Execute mapReduce\n\n          collection.mapReduce(map, reduce, {\n            out: {\n              replace: 'tempCollection'\n            }\n          }, err => {\n            expect(err).to.not.exist;\n            validateTestResults(started, succeeded, 'mapReduce');\n            done();\n          });\n        });\n      });\n    }\n  });","file":"integration/read-write-concern/readconcern.test.js","skipped":false,"dir":"test"},{"name":"Should set local readConcern on db level when using createCollection method","suites":["ReadConcern","client-url specific ReadConcern"],"updatePoint":{"line":431,"column":81,"index":13371},"line":431,"code":"  it('Should set local readConcern on db level when using createCollection method', {\n    metadata: {\n      requires: {\n        topology: 'replicaset',\n        mongodb: '>= 3.2'\n      }\n    },\n    test: function (done) {\n      // Get a new instance\n      const configuration = this.configuration;\n      client = configuration.newClient({\n        w: 1\n      }, {\n        maxPoolSize: 1,\n        readConcern: {\n          level: 'local'\n        }\n      });\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        const db = client.db(configuration.db);\n        expect(db.readConcern).to.deep.equal({\n          level: 'local'\n        }); // Get a collection using createCollection\n\n        db.createCollection('readConcernCollection_createCollection', (err, collection) => {\n          expect(err).to.not.exist; // Validate readConcern\n\n          expect(collection.readConcern).to.deep.equal({\n            level: 'local'\n          });\n          done();\n        });\n      });\n    }\n  });","file":"integration/read-write-concern/readconcern.test.js","skipped":false,"dir":"test"},{"name":"should respect writeConcern from uri","suites":["Write Concern"],"updatePoint":{"line":22,"column":42,"index":374},"line":22,"code":"  it('should respect writeConcern from uri', withMonitoredClient('insert', {\n    queryOptions: {\n      w: 0\n    }\n  }, function (client, events, done) {\n    expect(client.writeConcern).to.eql({\n      w: 0\n    });\n    client.db('test').collection('test').insertOne({\n      a: 1\n    }, (err, result) => {\n      expect(err).to.not.exist;\n      expect(result).to.exist;\n      expect(events).to.be.an('array').with.lengthOf(1);\n      expect(events[0]).to.containSubset({\n        commandName: 'insert',\n        command: {\n          writeConcern: {\n            w: 0\n          }\n        }\n      });\n      done();\n    });\n  })); // TODO: once `read-write-concern/connection-string` spec tests are implemented these can likely be removed","file":"integration/read-write-concern/write_concern.test.js","skipped":false,"dir":"test"},{"name":"should set write concern with j: true client option","suites":["Write Concern","test journal connection string option"],"updatePoint":{"line":71,"column":59,"index":1886},"line":71,"code":"    it('should set write concern with j: true client option', withMonitoredClient('insert', {\n      clientOptions: {\n        writeConcern: {\n          j: true\n        }\n      }\n    }, journalOptionTest)); // ensure query option in connection string passes through","file":"integration/read-write-concern/write_concern.test.js","skipped":false,"dir":"test"},{"name":"should set write concern with journal=true connection string option","suites":["Write Concern","test journal connection string option"],"updatePoint":{"line":79,"column":75,"index":2167},"line":79,"code":"    it('should set write concern with journal=true connection string option', withMonitoredClient('insert', {\n      queryOptions: {\n        journal: true\n      }\n    }, journalOptionTest));","file":"integration/read-write-concern/write_concern.test.js","skipped":false,"dir":"test"},{"name":"should pipe writeConcern from client down to API call","suites":["Write Concern","mock server write concern test"],"line":94,"code":"    it.skip('should pipe writeConcern from client down to API call', function () {","file":"integration/read-write-concern/write_concern.test.js","skipped":true,"dir":"test"},{"name":"retryable writes raise an exception when using the MMAPv1 storage engine","suites":["Retryable Writes Spec Prose"],"updatePoint":{"line":28,"column":78,"index":1329},"line":28,"code":"  it('retryable writes raise an exception when using the MMAPv1 storage engine', async () => {\n    const failPoint = await client.db('admin').command({\n      configureFailPoint: 'failCommand',\n      mode: {\n        times: 1\n      },\n      data: {\n        failCommands: ['insert'],\n        errorCode: 20,\n        // MMAP Error code,\n        closeConnection: false\n      }\n    });\n    expect(failPoint).to.have.property('ok', 1);\n    const error = await client.db('test').collection('test').insertOne({\n      a: 1\n    }).catch(error => error);\n    expect(error).to.exist;\n    expect(error).that.is.instanceOf(MongoServerError);\n    expect(error).to.have.property('originalError').that.instanceOf(MongoError);\n    expect(error.originalError).to.have.property('code', 20);\n    expect(error).to.have.property('message', 'This MongoDB deployment does not support retryable writes. Please add retryWrites=false to your connection string.');\n  });","file":"integration/retryable-writes/retryable_writes.spec.prose.test.ts","skipped":false,"dir":"test"},{"name":"Should use sharded topology","suites":["Sharding (Connection)"],"updatePoint":{"line":20,"column":33,"index":341},"line":20,"code":"  it('Should use sharded topology', {\n    metadata: {\n      requires: {\n        topology: 'sharded'\n      }\n    },\n    test: function () {\n      const client = this.configuration.newClient({});\n      return withClient(client, (client, done) => {\n        expect(client).to.exist;\n        expect(client).nested.property('topology.description.type').to.equal(TopologyType.Sharded);\n        return done();\n      })();\n    }\n  });","file":"integration/server-discovery-and-monitoring/sharding_connection.test.js","skipped":false,"dir":"test"},{"name":"should default to 15ms","suites":["TopologyDescription (integration tests)","options","localThresholdMS"],"updatePoint":{"line":11,"column":32,"index":416},"line":11,"code":"      it('should default to 15ms', async function () {\n        const options = {};\n        client = await this.configuration.newClient(options).connect();\n        const topologyDescription = getTopology(client).description;\n        expect(topologyDescription).to.have.ownProperty('localThresholdMS').to.equal(15);\n      });","file":"integration/server-discovery-and-monitoring/topology_description.test.ts","skipped":false,"dir":"test"},{"name":"should be set to the localThresholdMS option when it is passed in","suites":["TopologyDescription (integration tests)","options","localThresholdMS"],"updatePoint":{"line":17,"column":75,"index":783},"line":17,"code":"      it('should be set to the localThresholdMS option when it is passed in', async function () {\n        const options = {\n          localThresholdMS: 30\n        };\n        client = await this.configuration.newClient(options).connect();\n        const topologyDescription = getTopology(client).description;\n        expect(topologyDescription).to.have.ownProperty('localThresholdMS').to.equal(30);\n      });","file":"integration/server-discovery-and-monitoring/topology_description.test.ts","skipped":false,"dir":"test"},{"name":"is zero after a successful command","suites":["Server Operation Count Tests","load balanced mode with pinnable operations"],"updatePoint":{"line":60,"column":42,"index":1635},"line":60,"code":"    it('is zero after a successful command', loadBalancedTestMetadata, async function () {\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      const commandSpy = sinon.spy(server, 'command');\n      await collection.findOne({\n        count: 1\n      });\n      expect(commandSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"is zero after a command fails","suites":["Server Operation Count Tests","load balanced mode with pinnable operations"],"updatePoint":{"line":70,"column":37,"index":2062},"line":70,"code":"    it('is zero after a command fails', loadBalancedTestMetadata, async function () {\n      await client.db('admin').command(enableFailPointCommand);\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      const commandSpy = sinon.spy(server, 'command');\n      const error = await collection.findOne({\n        count: 1\n      }).catch(e => e);\n      expect(error).to.exist;\n      expect(commandSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"is zero after failing to check out a connection for a command","suites":["Server Operation Count Tests","load balanced mode with pinnable operations"],"updatePoint":{"line":82,"column":69,"index":2643},"line":82,"code":"    it('is zero after failing to check out a connection for a command', loadBalancedTestMetadata, async function () {\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      sinon.stub(ConnectionPool.prototype, 'checkOut').callsFake(function (cb) {\n        cb(new Error('unable to checkout connection'), undefined);\n      });\n      const commandSpy = sinon.spy(server, 'command');\n      const error = await collection.findOne({\n        count: 1\n      }).catch(e => e);\n      expect(error).to.exist;\n      expect(error).to.match(/unable to checkout connection/i);\n      expect(commandSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"is zero after a successful command","suites":["Server Operation Count Tests","operationCount is adjusted properly on successful operation"],"updatePoint":{"line":99,"column":42,"index":3448},"line":99,"code":"    it('is zero after a successful command', testMetadata, async function () {\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      const commandSpy = sinon.spy(server, 'command');\n      const operationPromises = Array.from({\n        length: 10\n      }, () => collection.insertOne({\n        count: 1\n      }));\n      expect(server.s.operationCount).to.equal(10);\n      await Promise.all(operationPromises);\n      expect(commandSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"is zero after a successful getMore","suites":["Server Operation Count Tests","operationCount is adjusted properly on successful operation"],"updatePoint":{"line":113,"column":42,"index":4034},"line":113,"code":"    it('is zero after a successful getMore', testMetadata, async function () {\n      cursor = collection.find({}, {\n        batchSize: 1\n      });\n      await cursor.next();\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      const getMoreSpy = sinon.spy(server, 'getMore');\n      const operation = cursor.next();\n      expect(server.s.operationCount).to.equal(1);\n      await operation;\n      expect(getMoreSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n      await cursor.close();\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"is zero after a successful killCursors","suites":["Server Operation Count Tests","operationCount is adjusted properly on successful operation"],"updatePoint":{"line":128,"column":46,"index":4634},"line":128,"code":"    it('is zero after a successful killCursors', testMetadata, async function () {\n      cursor = collection.find({}, {\n        batchSize: 1\n      });\n      await cursor.next();\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      const killCursorsSpy = sinon.spy(server, 'killCursors');\n      const promise = cursor.close();\n      expect(server.s.operationCount).to.equal(1);\n      await promise;\n      expect(killCursorsSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"is zero after a command fails","suites":["Server Operation Count Tests","operationCount is adjusted properly when operations fail"],"updatePoint":{"line":144,"column":37,"index":5296},"line":144,"code":"    it('is zero after a command fails', testMetadata, async function () {\n      await client.db('admin').command(enableFailPointCommand);\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      const commandSpy = sinon.spy(server, 'command');\n      const error = await collection.insertOne({\n        count: 1\n      }).catch(e => e);\n      expect(error).to.exist;\n      expect(commandSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"is zero after a getMore fails","suites":["Server Operation Count Tests","operationCount is adjusted properly when operations fail"],"updatePoint":{"line":156,"column":37,"index":5835},"line":156,"code":"    it('is zero after a getMore fails', testMetadata, async function () {\n      cursor = collection.find({}, {\n        batchSize: 1\n      });\n      await cursor.next();\n      await client.db('admin').command(enableFailPointCommand);\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      const getMoreSpy = sinon.spy(server, 'getMore');\n      const error = await cursor.next().catch(e => e);\n      expect(error).to.exist;\n      expect(getMoreSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n      await cursor.close();\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"is zero after a killCursors fails","suites":["Server Operation Count Tests","operationCount is adjusted properly when operations fail"],"updatePoint":{"line":171,"column":41,"index":6466},"line":171,"code":"    it('is zero after a killCursors fails', testMetadata, async function () {\n      cursor = collection.find({}, {\n        batchSize: 1\n      });\n      await cursor.next(); // initialize the cursor\n\n      await client.db('admin').command(enableFailPointCommand);\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      const killCursorsSpy = sinon.spy(server, 'killCursors');\n      await cursor.close();\n      expect(killCursorsSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"is zero after failing to check out a connection for a command","suites":["Server Operation Count Tests","operationCount is decremented when the server fails to checkout a connection"],"updatePoint":{"line":187,"column":69,"index":7188},"line":187,"code":"    it('is zero after failing to check out a connection for a command', testMetadata, async function () {\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      sinon.stub(ConnectionPool.prototype, 'checkOut').callsFake(function (cb) {\n        cb(new Error('unable to checkout connection'), undefined);\n      });\n      const commandSpy = sinon.spy(server, 'command');\n      const error = await collection.insertOne({\n        count: 1\n      }).catch(e => e);\n      expect(error).to.exist;\n      expect(error).to.match(/unable to checkout connection/i);\n      expect(commandSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"is zero after failing to check out a connection for a getMore","suites":["Server Operation Count Tests","operationCount is decremented when the server fails to checkout a connection"],"updatePoint":{"line":202,"column":69,"index":7917},"line":202,"code":"    it('is zero after failing to check out a connection for a getMore', testMetadata, async function () {\n      cursor = collection.find({}, {\n        batchSize: 1\n      });\n      await cursor.next();\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      sinon.stub(ConnectionPool.prototype, 'checkOut').callsFake(function (cb) {\n        cb(new Error('unable to checkout connection'), undefined);\n      });\n      const getMoreSpy = sinon.spy(server, 'getMore');\n      const error = await cursor.next().catch(e => e);\n      expect(error).to.exist;\n      expect(error).to.match(/unable to checkout connection/i);\n      expect(getMoreSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"is zero after failing to check out a connection for a killCursors","suites":["Server Operation Count Tests","operationCount is decremented when the server fails to checkout a connection"],"updatePoint":{"line":219,"column":73,"index":8710},"line":219,"code":"    it('is zero after failing to check out a connection for a killCursors', testMetadata, async function () {\n      cursor = collection.find({}, {\n        batchSize: 1\n      });\n      await cursor.next();\n      const server = Array.from(client.topology.s.servers.values())[0];\n      expect(server.s.operationCount).to.equal(0);\n      sinon.stub(ConnectionPool.prototype, 'checkOut').callsFake(function (cb) {\n        cb(new Error('unable to checkout connection'), undefined);\n      });\n      const killCursorsSpy = sinon.spy(server, 'killCursors');\n      await cursor.close();\n      expect(killCursorsSpy.called).to.be.true;\n      expect(server.s.operationCount).to.equal(0);\n    });","file":"integration/server-selection/operation_count.test.ts","skipped":false,"dir":"test"},{"name":"Should correctly apply collection level read Preference to count","suites":["ReadPreference"],"updatePoint":{"line":24,"column":70,"index":467},"line":24,"code":"  it('Should correctly apply collection level read Preference to count', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Set read preference\n\n        var collection = db.collection('read_pref_1', {\n          readPreference: ReadPreference.SECONDARY_PREFERRED\n        }); // Save checkout function\n\n        var command = client.topology.command; // Set up our checker method\n\n        client.topology.command = function () {\n          var args = Array.prototype.slice.call(arguments, 0);\n\n          if (args[0] === 'integration_tests.$cmd') {\n            test.equal(ReadPreference.SECONDARY_PREFERRED, args[2].readPreference.mode);\n          }\n\n          return command.apply(db.s.topology, args);\n        }; // Execute count\n\n\n        collection.count(function (err) {\n          expect(err).to.not.exist;\n          client.topology.command = command;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply collection level read Preference to mapReduce","suites":["ReadPreference"],"updatePoint":{"line":65,"column":74,"index":1765},"line":65,"code":"  it('Should correctly apply collection level read Preference to mapReduce', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Set read preference\n\n        var collection = db.collection('read_pref_1', {\n          readPreference: ReadPreference.SECONDARY_PREFERRED\n        }); // Save checkout function\n\n        var command = client.topology.command; // Set up our checker method\n\n        client.topology.command = function () {\n          var args = Array.prototype.slice.call(arguments, 0);\n\n          if (args[0] === 'integration_tests.$cmd') {\n            test.equal(ReadPreference.SECONDARY_PREFERRED, args[2].readPreference.mode);\n          }\n\n          return command.apply(db.s.topology, args);\n        }; // Map function\n\n\n        var map = function () {\n          emit(this.user_id, 1); // eslint-disable-line\n        }; // Reduce function\n\n\n        var reduce = function\n          /* k, vals */\n        () {\n          return 1;\n        }; // Perform the map reduce\n\n\n        collection.mapReduce(map, reduce, {\n          out: {\n            inline: 1\n          }\n        }, function\n          /* err */\n        () {\n          // expect(err).to.not.exist;\n          // eslint-disable-line\n          client.topology.command = command;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply collection level read Preference to mapReduce backward compatibility","suites":["ReadPreference"],"updatePoint":{"line":125,"column":97,"index":3473},"line":125,"code":"  it('Should correctly apply collection level read Preference to mapReduce backward compatibility', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Set read preference\n\n        var collection = db.collection('read_pref_1', {\n          readPreference: ReadPreference.SECONDARY_PREFERRED\n        }); // Save checkout function\n\n        var command = client.topology.command; // Set up our checker method\n\n        client.topology.command = function () {\n          var args = Array.prototype.slice.call(arguments, 0);\n\n          if (args[0] === 'integration_tests.$cmd') {\n            test.equal(ReadPreference.SECONDARY_PREFERRED, args[2].readPreference.mode);\n          }\n\n          return command.apply(db.s.topology, args);\n        }; // Map function\n\n\n        var map = function () {\n          emit(this.user_id, 1); // eslint-disable-line\n        }; // Reduce function\n\n\n        var reduce = function\n          /* k, vals */\n        () {\n          return 1;\n        }; // Perform the map reduce\n\n\n        collection.mapReduce(map, reduce, {\n          out: 'inline'\n        }, function\n          /* err */\n        () {\n          // expect(err).to.not.exist;\n          client.topology.command = command;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should fail due to not using mapReduce inline with read preference","suites":["ReadPreference"],"updatePoint":{"line":182,"column":72,"index":5096},"line":182,"code":"  it('Should fail due to not using mapReduce inline with read preference', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Set read preference\n\n        var collection = db.collection('read_pref_1', {\n          readPreference: ReadPreference.SECONDARY_PREFERRED\n        }); // Map function\n\n        var map = function () {\n          emit(this.user_id, 1); // eslint-disable-line\n        }; // Reduce function\n\n\n        var reduce = function\n          /* k, vals */\n        () {\n          return 1;\n        }; // Perform the map reduce\n\n\n        collection.mapReduce(map, reduce, {\n          out: {\n            append: 'test'\n          }\n        }, function (err) {\n          test.notEqual(err, null);\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply collection level read Preference to aggregate","suites":["ReadPreference"],"updatePoint":{"line":225,"column":74,"index":6243},"line":225,"code":"  it('Should correctly apply collection level read Preference to aggregate', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Set read preference\n\n        var collection = db.collection('read_pref_1', {\n          readPreference: ReadPreference.SECONDARY_PREFERRED\n        }); // Save checkout function\n\n        var command = client.topology.command; // Set up our checker method\n\n        client.topology.command = function () {\n          var args = Array.prototype.slice.call(arguments, 0);\n\n          if (args[0] === 'integration_tests.$cmd') {\n            test.equal(ReadPreference.SECONDARY_PREFERRED, args[2].readPreference.mode);\n          }\n\n          return command.apply(db.s.topology, args);\n        };\n\n        const cursor = collection.aggregate([{\n          $project: {\n            author: 1,\n            tags: 1\n          }\n        }, {\n          $unwind: '$tags'\n        }, {\n          $group: {\n            _id: {\n              tags: '$tags'\n            },\n            authors: {\n              $addToSet: '$author'\n            }\n          }\n        }]);\n        cursor.toArray(function (err) {\n          expect(err).to.not.exist;\n          client.topology.command = command;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply collection level read Preference to stats","suites":["ReadPreference"],"updatePoint":{"line":282,"column":70,"index":7873},"line":282,"code":"  it('Should correctly apply collection level read Preference to stats', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Set read preference\n\n        var collection = db.collection('read_pref_1', {\n          readPreference: ReadPreference.SECONDARY_PREFERRED\n        }); // Save checkout function\n\n        var command = client.topology.command; // Set up our checker method\n\n        client.topology.command = function () {\n          var args = Array.prototype.slice.call(arguments, 0);\n\n          if (args[0] === 'integration_tests.$cmd') {\n            test.equal(ReadPreference.SECONDARY_PREFERRED, args[2].readPreference.mode);\n          }\n\n          return command.apply(db.s.topology, args);\n        }; // Perform the map reduce\n\n\n        collection.stats(function\n          /* err */\n        () {\n          // expect(err).to.not.exist;\n          client.topology.command = command;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly honor the readPreferences at DB and individual command level","suites":["ReadPreference"],"updatePoint":{"line":325,"column":83,"index":9217},"line":325,"code":"  it('Should correctly honor the readPreferences at DB and individual command level', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient({\n        w: 1,\n        readPreference: 'secondary'\n      }, {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db); // Save checkout function\n\n        var command = client.topology.command; // Set up our checker method\n\n        client.topology.command = function () {\n          var args = Array.prototype.slice.call(arguments, 0);\n\n          if (args[0] === 'integration_tests.$cmd') {\n            test.equal(ReadPreference.SECONDARY, args[2].readPreference.mode);\n          }\n\n          return command.apply(db.s.topology, args);\n        };\n\n        db.command({\n          dbStats: true\n        }, function (err) {\n          expect(err).to.not.exist;\n\n          client.topology.command = function () {\n            var args = Array.prototype.slice.call(arguments, 0);\n\n            if (args[0] === 'integration_tests.$cmd') {\n              test.equal(ReadPreference.SECONDARY_PREFERRED, args[2].readPreference.mode);\n            }\n\n            return command.apply(db.s.topology, args);\n          };\n\n          db.command({\n            dbStats: true\n          }, {\n            readPreference: 'secondaryPreferred'\n          }, function (err) {\n            expect(err).to.not.exist;\n            client.topology.command = command;\n            client.close(done);\n          });\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly apply readPreferences specified as objects","suites":["ReadPreference"],"updatePoint":{"line":383,"column":65,"index":10897},"line":383,"code":"  it('Should correctly apply readPreferences specified as objects', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Create read preference object.\n\n        var mySecondaryPreferred = {\n          mode: 'secondaryPreferred',\n          tags: []\n        };\n        db.command({\n          dbStats: true\n        }, {\n          readPreference: mySecondaryPreferred\n        }, function (err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly pass readPreferences specified as objects to cursors","suites":["ReadPreference"],"updatePoint":{"line":414,"column":75,"index":11774},"line":414,"code":"  it('Should correctly pass readPreferences specified as objects to cursors', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Create read preference object.\n\n        var mySecondaryPreferred = {\n          mode: 'secondaryPreferred',\n          tags: []\n        };\n        db.listCollections({}, {\n          readPreference: mySecondaryPreferred\n        }).toArray(function (err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly pass readPreferences specified as objects to collection methods","suites":["ReadPreference"],"updatePoint":{"line":443,"column":86,"index":12645},"line":443,"code":"  it('Should correctly pass readPreferences specified as objects to collection methods', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist; // Create read preference object.\n\n        var mySecondaryPreferred = {\n          mode: 'secondaryPreferred',\n          tags: []\n        };\n        var cursor = db.collection('test').find({}, {\n          readPreference: mySecondaryPreferred\n        });\n        cursor.toArray(function (err) {\n          expect(err).to.not.exist;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should correctly pass readPreferences on the Collection to listIndexes","suites":["ReadPreference"],"updatePoint":{"line":473,"column":76,"index":13543},"line":473,"code":"  it('Should correctly pass readPreferences on the Collection to listIndexes', {\n    metadata: {\n      requires: {\n        mongodb: '>=2.6.0',\n        topology: ['single', 'ssl']\n      }\n    },\n    test: function (done) {\n      var configuration = this.configuration;\n      var client = configuration.newClient(configuration.writeConcernMax(), {\n        maxPoolSize: 1\n      });\n      client.connect(function (err, client) {\n        var db = client.db(configuration.db);\n        expect(err).to.not.exist;\n        var cursor = db.collection('test', {\n          readPreference: ReadPreference.SECONDARY_PREFERRED\n        }).listIndexes();\n        test.equal(cursor.readPreference.mode, 'secondaryPreferred');\n        client.close(done);\n      });\n    }\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"Should throw an error on an invalid readPreference","suites":["ReadPreference"],"updatePoint":{"line":496,"column":56,"index":14280},"line":496,"code":"  it('Should throw an error on an invalid readPreference', function (done) {\n    const configuration = this.configuration;\n    const client = configuration.newClient();\n    client.connect((err, client) => {\n      const db = client.db(configuration.db);\n      expect(db.collection.bind(db, 'test', {\n        readPreference: 'invalid'\n      })).to.throw('Invalid read preference mode \"invalid\"');\n      client.close(done);\n    });\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"should set hedge using [find option & empty hedge]","suites":["ReadPreference","hedge"],"updatePoint":{"line":508,"column":58,"index":14750},"line":508,"code":"    it('should set hedge using [find option & empty hedge]', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.6.0'\n        }\n      },\n      test: withMonitoredClient(['find'], function (client, events, done) {\n        const rp = new ReadPreference(ReadPreference.SECONDARY, null, {\n          hedge: {}\n        });\n        client.db(this.configuration.db).collection('test').find({}, {\n          readPreference: rp\n        }).toArray(err => {\n          expect(err).to.not.exist;\n          const expected = {\n            mode: ReadPreference.SECONDARY,\n            hedge: {}\n          };\n          expect(events[0]).nested.property('command.$readPreference').to.deep.equal(expected);\n          done();\n        });\n      })\n    });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"should set hedge using [.withReadPreference & empty hedge] ","suites":["ReadPreference","hedge"],"updatePoint":{"line":531,"column":67,"index":15503},"line":531,"code":"    it('should set hedge using [.withReadPreference & empty hedge] ', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.6.0'\n        }\n      },\n      test: withMonitoredClient(['find'], function (client, events, done) {\n        const rp = new ReadPreference(ReadPreference.SECONDARY, null, {\n          hedge: {}\n        });\n        client.db(this.configuration.db).collection('test').find({}).withReadPreference(rp).toArray(err => {\n          expect(err).to.not.exist;\n          const expected = {\n            mode: ReadPreference.SECONDARY,\n            hedge: {}\n          };\n          expect(events[0]).nested.property('command.$readPreference').to.deep.equal(expected);\n          done();\n        });\n      })\n    });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"should set hedge using [.withReadPreference & enabled hedge] ","suites":["ReadPreference","hedge"],"updatePoint":{"line":552,"column":69,"index":16239},"line":552,"code":"    it('should set hedge using [.withReadPreference & enabled hedge] ', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.6.0'\n        }\n      },\n      test: withMonitoredClient(['find'], function (client, events, done) {\n        const rp = new ReadPreference(ReadPreference.SECONDARY, null, {\n          hedge: {\n            enabled: true\n          }\n        });\n        client.db(this.configuration.db).collection('test').find({}).withReadPreference(rp).toArray(err => {\n          expect(err).to.not.exist;\n          const expected = {\n            mode: ReadPreference.SECONDARY,\n            hedge: {\n              enabled: true\n            }\n          };\n          expect(events[0]).nested.property('command.$readPreference').to.deep.equal(expected);\n          done();\n        });\n      })\n    });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"should set hedge using [.withReadPreference & disabled hedge] ","suites":["ReadPreference","hedge"],"updatePoint":{"line":577,"column":70,"index":17054},"line":577,"code":"    it('should set hedge using [.withReadPreference & disabled hedge] ', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.6.0'\n        }\n      },\n      test: withMonitoredClient(['find'], function (client, events, done) {\n        const rp = new ReadPreference(ReadPreference.SECONDARY, null, {\n          hedge: {\n            enabled: false\n          }\n        });\n        client.db(this.configuration.db).collection('test').find({}).withReadPreference(rp).toArray(err => {\n          expect(err).to.not.exist;\n          const expected = {\n            mode: ReadPreference.SECONDARY,\n            hedge: {\n              enabled: false\n            }\n          };\n          expect(events[0]).nested.property('command.$readPreference').to.deep.equal(expected);\n          done();\n        });\n      })\n    });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"should set hedge using [.withReadPreference & undefined hedge] ","suites":["ReadPreference","hedge"],"updatePoint":{"line":602,"column":71,"index":17872},"line":602,"code":"    it('should set hedge using [.withReadPreference & undefined hedge] ', {\n      metadata: {\n        requires: {\n          mongodb: '>=3.6.0'\n        }\n      },\n      test: withMonitoredClient(['find'], function (client, events, done) {\n        const rp = new ReadPreference(ReadPreference.SECONDARY, null);\n        client.db(this.configuration.db).collection('test').find({}).withReadPreference(rp).toArray(err => {\n          expect(err).to.not.exist;\n          const expected = {\n            mode: ReadPreference.SECONDARY\n          };\n          expect(events[0]).nested.property('command.$readPreference').to.deep.equal(expected);\n          done();\n        });\n      })\n    });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"","suites":["ReadPreference","should enforce fixed primary read preference"],"updatePoint":{"line":659,"column":22,"index":19772},"line":659,"code":"      it(`${operation}`, {\n        metadata: {\n          requires: {\n            topology: ['replicaset', 'sharded']\n          }\n        },\n        test: function () {\n          const configuration = this.configuration;\n          const client = this.configuration.newClient(configuration.writeConcernMax(), {\n            readPreference: 'primaryPreferred'\n          });\n          return withClient(client, (client, done) => {\n            const db = client.db(configuration.db);\n            const args = methods[operation];\n            const [parentId, method] = operation.split('#');\n            const collection = db.collection(collectionName);\n            const parent = parentId === 'Collection' ? collection : parentId === 'Db' ? db : null;\n            const selectServerSpy = this.sinon.spy(Topology.prototype, 'selectServer');\n\n            const callback = err => {\n              expect(err).to.not.exist;\n              expect(selectServerSpy.called).to.equal(true);\n\n              if (typeof selectServerSpy.args[0][0] === 'function') {\n                expect(selectServerSpy).nested.property('args[0][1].readPreference.mode').to.equal(ReadPreference.PRIMARY);\n              } else {\n                expect(selectServerSpy).nested.property('args[0][0].readPreference.mode').to.equal(ReadPreference.PRIMARY);\n              }\n\n              done();\n            };\n\n            parent[method].apply(parent, [...args, callback]);\n          });\n        }\n      });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"should respect readPreference from uri","suites":["ReadPreference","should enforce fixed primary read preference"],"updatePoint":{"line":697,"column":44,"index":21275},"line":697,"code":"  it('should respect readPreference from uri', {\n    metadata: {\n      requires: {\n        topology: 'replicaset',\n        mongodb: '>=3.6'\n      }\n    },\n    test: withMonitoredClient('find', {\n      queryOptions: {\n        readPreference: 'secondary'\n      }\n    }, function (client, events, done) {\n      expect(client.readPreference.mode).to.equal('secondary');\n      client.db('test').collection('test').findOne({\n        a: 1\n      }, err => {\n        expect(err).to.not.exist;\n        expect(events).to.be.an('array').with.lengthOf(1);\n        expect(events[0]).to.containSubset({\n          commandName: 'find',\n          command: {\n            $readPreference: {\n              mode: 'secondary'\n            }\n          }\n        });\n        done();\n      });\n    })\n  });","file":"integration/server-selection/readpreference.test.js","skipped":false,"dir":"test"},{"name":"needs to run on exactly two mongoses","suites":["operationCount-based Selection Within Latency Window - Prose Test"],"updatePoint":{"line":95,"column":42,"index":2810},"line":95,"code":"  it('needs to run on exactly two mongoses', TEST_METADATA, function () {\n    expect(seeds).to.have.lengthOf(2);\n  });","file":"integration/server-selection/server_selection.prose.operation_count.test.ts","skipped":false,"dir":"test"},{"name":"sends fewer requests to the overloaded server","suites":["operationCount-based Selection Within Latency Window - Prose Test","when one mongos is overloaded"],"updatePoint":{"line":122,"column":53,"index":3836},"line":122,"code":"    it('sends fewer requests to the overloaded server', TEST_METADATA, async function () {\n      const failingSeed = seeds[0];\n      const collection = client.db('test-db').collection('collection0'); // Step 5: Start 10 concurrent threads / tasks that each run 10 findOne operations with empty filters using that client.\n\n      await Promise.all(Array.from({\n        length: 10\n      }, () => runTaskGroup(collection, 10))); // Step 6: Using command monitoring events, assert that fewer than 25% of the CommandStartedEvents\n      // occurred on the mongos that the failpoint was enabled on.\n\n      const port = failingSeed.split(':')[1];\n      const percentageSentToSlowHost = counts[port] / 100 * 100;\n      expect(percentageSentToSlowHost).to.be.lessThan(25);\n    });","file":"integration/server-selection/server_selection.prose.operation_count.test.ts","skipped":false,"dir":"test"},{"name":"equally distributes operations with both hosts are fine","suites":["operationCount-based Selection Within Latency Window - Prose Test","when one mongos is overloaded"],"updatePoint":{"line":136,"column":61,"index":4620},"line":136,"code":"  it('equally distributes operations with both hosts are fine', TEST_METADATA, async function () {\n    const collection = client.db('test-db').collection('collection0'); // Step 8: Start 10 concurrent threads / tasks that each run 100 findOne operations with empty filters using that client.\n\n    await Promise.all(Array.from({\n      length: 10\n    }, () => runTaskGroup(collection, 100))); // Step 9: Using command monitoring events, assert that each mongos was selected roughly 50% of the time (within +/- 10%).\n\n    const [host1, host2] = seeds.map(seed => seed.split(':')[1]);\n    const percentageToHost1 = counts[host1] / 1000 * 100;\n    const percentageToHost2 = counts[host2] / 1000 * 100;\n    expect(percentageToHost1).to.be.greaterThan(40).and.lessThan(60);\n    expect(percentageToHost2).to.be.greaterThan(40).and.lessThan(60);\n  });","file":"integration/server-selection/server_selection.prose.operation_count.test.ts","skipped":false,"dir":"test"},{"name":"13. may reuse one server session for many operations","suites":["ServerSession"],"updatePoint":{"line":26,"column":58,"index":1248},"line":26,"code":"  it('13. may reuse one server session for many operations', async () => {\n    const events = [];\n    client.on('commandStarted', ev => events.push(ev));\n    const operations = [testCollection.insertOne({\n      _id: 1\n    }), testCollection.deleteOne({\n      _id: 2\n    }), testCollection.updateOne({\n      _id: 3\n    }, {\n      $set: {\n        a: 1\n      }\n    }), testCollection.bulkWrite([{\n      updateOne: {\n        filter: {\n          _id: 4\n        },\n        update: {\n          $set: {\n            a: 1\n          }\n        }\n      }\n    }]), testCollection.findOneAndDelete({\n      _id: 5\n    }), testCollection.findOneAndUpdate({\n      _id: 6\n    }, {\n      $set: {\n        a: 1\n      }\n    }), testCollection.findOneAndReplace({\n      _id: 7\n    }, {\n      a: 8\n    }), testCollection.find().toArray()];\n    const allResults = await Promise.all(operations);\n    expect(allResults).to.have.lengthOf(operations.length);\n    expect(events).to.have.lengthOf(operations.length); // This is a guarantee in node, unless you are performing a transaction (which is not being done in this test)\n\n    expect(new Set(events.map(ev => ev.command.lsid.id.toString('hex'))).size).to.equal(1);\n  });","file":"integration/sessions/sessions.spec.prose.test.ts","skipped":false,"dir":"test"},{"name":"should send endSessions for multiple sessions","suites":["Sessions Spec","Sessions - functional - old format","endSessions"],"updatePoint":{"line":56,"column":55,"index":1880},"line":56,"code":"      it('should send endSessions for multiple sessions', {\n        metadata: {\n          requires: {\n            topology: ['single'],\n            mongodb: '>=3.6.0'\n          },\n          // Skipping session leak tests b/c these are explicit sessions\n          sessions: {\n            skipLeakTests: true\n          }\n        },\n        test: function (done) {\n          const client = test.client;\n          const sessions = [client.startSession(), client.startSession()].map(s => s.id);\n          client.close(err => {\n            expect(err).to.not.exist;\n            expect(test.commands.started).to.have.length(1);\n            expect(test.commands.started[0].commandName).to.equal('endSessions');\n            expect(test.commands.started[0].command.endSessions).to.include.deep.members(sessions);\n            expect(client.s.sessions.size).to.equal(0);\n            done();\n          });\n        }\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"supports passing options to ClientSession","suites":["Sessions Spec","Sessions - functional - old format","withSession"],"updatePoint":{"line":156,"column":51,"index":5643},"line":156,"code":"      it('supports passing options to ClientSession', async function () {\n        let sessionWasEnded = false;\n        await client.withSession({\n          causalConsistency: false\n        }, async session => {\n          session.on('ended', () => {\n            sessionWasEnded = true;\n          });\n          expect(session.supports.causalConsistency).to.be.false;\n          await client.db('test').collection('foo').find({}, {\n            session\n          }).toArray();\n        });\n        expect(client.topology.s.sessionPool.sessions).to.have.length(1);\n        expect(sessionWasEnded).to.be.true;\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should not include session for unacknowledged writes","suites":["Sessions Spec","Sessions - functional - old format","unacknowledged writes"],"updatePoint":{"line":174,"column":62,"index":6319},"line":174,"code":"      it('should not include session for unacknowledged writes', {\n        metadata: {\n          requires: {\n            topology: 'single',\n            mongodb: '>=3.6.0'\n          }\n        },\n        test: withMonitoredClient('insert', {\n          clientOptions: {\n            writeConcern: {\n              w: 0\n            }\n          }\n        }, function (client, events, done) {\n          client.db('test').collection('foo').insertOne({\n            foo: 'bar'\n          }, err => {\n            expect(err).to.not.exist;\n            const event = events[0];\n            expect(event).nested.property('command.writeConcern.w').to.equal(0);\n            expect(event).to.not.have.nested.property('command.lsid');\n            done();\n          });\n        })\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should throw error with explicit session","suites":["Sessions Spec","Sessions - functional - old format","unacknowledged writes"],"updatePoint":{"line":199,"column":50,"index":7078},"line":199,"code":"      it('should throw error with explicit session', {\n        metadata: {\n          requires: {\n            topology: 'replicaset',\n            mongodb: '>=3.6.0'\n          }\n        },\n        test: withMonitoredClient('insert', {\n          clientOptions: {\n            writeConcern: {\n              w: 0\n            }\n          }\n        }, function (client, events, done) {\n          const session = client.startSession({\n            causalConsistency: true\n          });\n          client.db('test').collection('foo').insertOne({\n            foo: 'bar'\n          }, {\n            session\n          }, err => {\n            expect(err).to.exist;\n            expect(err.message).to.equal('Cannot have explicit session with unacknowledged writes');\n            client.close(done);\n          });\n        })\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should result in a usable session when called with a valid cluster time and should not affect any other sessions","suites":["Sessions Spec","Sessions - functional - new format","advanceClusterTime()"],"updatePoint":{"line":276,"column":122,"index":9839},"line":276,"code":"      it('should result in a usable session when called with a valid cluster time and should not affect any other sessions', {\n        metadata: {\n          requires: {\n            mongodb: '>= 3.6.0',\n            topology: ['replicaset']\n          }\n        },\n\n        async test() {\n          // advance cluster time to a new valid value\n          testSession.advanceClusterTime(otherSession.clusterTime);\n          expect(testSession.clusterTime).to.deep.equal(otherSession.clusterTime); // check control session\n\n          expect(controlSession.clusterTime).to.not.deep.equal(testSession.clusterTime); // check that the session still works\n\n          expect(await collection.findOne({}, {\n            session: testSession\n          })).property('apple').to.equal('green');\n        }\n\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should not let an invalid cluster time impact existing sessions","suites":["Sessions Spec","Sessions - functional - new format","advanceClusterTime()"],"updatePoint":{"line":297,"column":73,"index":10589},"line":297,"code":"      it('should not let an invalid cluster time impact existing sessions', {\n        metadata: {\n          requires: {\n            mongodb: '>= 3.6.0',\n            topology: ['replicaset']\n          }\n        },\n\n        async test() {\n          // note, because of our validation, we can't use advanceClusterTime to set an invalid clusterTime\n          // so for testing, we have to set it directly\n          testSession.clusterTime = {\n            clusterTime: {\n              greaterThan: () => true\n            }\n          };\n\n          try {\n            await collection.findOne({}, {\n              session: testSession\n            });\n            expect.fail('expected findOne to fail, but it passed');\n          } catch (err) {\n            expect(err).to.be.instanceOf(MongoServerError);\n          }\n\n          expect(await collection.findOne({}, {\n            session: controlSession\n          })).property('apple').to.equal('green');\n        }\n\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should not let an invalid cluster time impact new sessions","suites":["Sessions Spec","Sessions - functional - new format","advanceClusterTime()"],"updatePoint":{"line":329,"column":68,"index":11549},"line":329,"code":"      it('should not let an invalid cluster time impact new sessions', {\n        metadata: {\n          requires: {\n            mongodb: '>= 3.6.0',\n            topology: ['replicaset']\n          }\n        },\n\n        async test() {\n          // note, because of our validation, we can't use advanceClusterTime to set an invalid clusterTime\n          // so for testing, we have to set it directly\n          testSession.clusterTime = {\n            clusterTime: {\n              greaterThan: () => true\n            }\n          };\n\n          try {\n            await collection.findOne({}, {\n              session: testSession\n            });\n            expect.fail('expected findOne to fail, but it passed');\n          } catch (err) {\n            expect(err).to.be.instanceOf(MongoServerError);\n          }\n\n          await otherSession.endSession();\n          otherSession = client.startSession();\n          expect(await collection.findOne({}, {\n            session: otherSession\n          })).property('apple').to.equal('green');\n        }\n\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should not let an invalid cluster time impact other uses of the client","suites":["Sessions Spec","Sessions - functional - new format","advanceClusterTime()"],"updatePoint":{"line":363,"column":80,"index":12610},"line":363,"code":"      it('should not let an invalid cluster time impact other uses of the client', {\n        metadata: {\n          requires: {\n            mongodb: '>= 3.6.0',\n            topology: ['replicaset']\n          }\n        },\n\n        async test() {\n          // note, because of our validation, we can't use advanceClusterTime to set an invalid clusterTime\n          // so for testing, we have to set it directly\n          testSession.clusterTime = {\n            clusterTime: {\n              greaterThan: () => true\n            }\n          };\n\n          try {\n            await collection.findOne({}, {\n              session: testSession\n            });\n            expect.fail('expected findOne to fail, but it passed');\n          } catch (err) {\n            expect(err).to.be.instanceOf(MongoServerError);\n          }\n\n          expect(await collection.findOne({})).property('apple').to.equal('green');\n        }\n\n      });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should only use one session for many operations when maxPoolSize is 1","suites":["Sessions Spec","Session allocation"],"updatePoint":{"line":410,"column":77,"index":14010},"line":410,"code":"    it('should only use one session for many operations when maxPoolSize is 1', async () => {\n      const documents = Array.from({\n        length: 50\n      }).map((_, idx) => ({\n        _id: idx\n      }));\n      const events = [];\n      client.on('commandStarted', ev => events.push(ev));\n      const allResults = await Promise.all(documents.map(async doc => testCollection.insertOne(doc)));\n      expect(allResults).to.have.lengthOf(documents.length);\n      expect(events).to.have.lengthOf(documents.length);\n      expect(new Set(events.map(ev => ev.command.lsid.id.toString('hex'))).size).to.equal(1);\n    });","file":"integration/sessions/sessions.test.ts","skipped":false,"dir":"test"},{"name":"should throw if arrow function","suites":["shared test utilities","withMonitoredClient"],"updatePoint":{"line":13,"column":38,"index":244},"line":13,"code":"    it('should throw if arrow function', function () {\n      expect(() => {\n        withMonitoredClient(['find'], () => {});\n      }).to.throw();\n    });","file":"integration/shared.test.js","skipped":false,"dir":"test"},{"name":"should not throw if function","suites":["shared test utilities","withMonitoredClient"],"updatePoint":{"line":18,"column":36,"index":396},"line":18,"code":"    it('should not throw if function', function () {\n      expect(() => {\n        function example() {}\n\n        withMonitoredClient(['find'], example);\n      }).to.not.throw();\n    });","file":"integration/shared.test.js","skipped":false,"dir":"test"},{"name":"should call done and close connection with callback","suites":["shared test utilities","withMonitoredClient"],"updatePoint":{"line":25,"column":59,"index":605},"line":25,"code":"    it('should call done and close connection with callback', function (done) {\n      var e = [];\n\n      const fakeDone = () => {\n        expect(e.length).to.equal(1);\n        done();\n      };\n\n      const encapsulatedTest = withMonitoredClient(['find'], function (client, events, innerDone) {\n        e = events;\n        client.db('integration_test').collection('test').find({}).toArray(() => {\n          return innerDone();\n        });\n      }).bind(this);\n      encapsulatedTest().then(fakeDone);\n    });","file":"integration/shared.test.js","skipped":false,"dir":"test"},{"name":"should propagate passed error to done","suites":["shared test utilities","withMonitoredClient"],"updatePoint":{"line":41,"column":45,"index":1099},"line":41,"code":"    it('should propagate passed error to done', function (done) {\n      var e = [];\n\n      const fakeDone = err => {\n        expect(err).to.be.instanceOf(Error);\n        expect(e.length).to.equal(1);\n        done();\n      };\n\n      const encapsulatedTest = withMonitoredClient(['find'], function (client, events, innerDone) {\n        e = events;\n        client.db('integration_test').collection('test').find({}).toArray(() => {\n          return innerDone(new Error('hello world'));\n        });\n      }).bind(this);\n      encapsulatedTest().catch(fakeDone);\n    });","file":"integration/shared.test.js","skipped":false,"dir":"test"},{"name":"should call done and close connection with promise","suites":["shared test utilities","withMonitoredClient"],"updatePoint":{"line":58,"column":58,"index":1677},"line":58,"code":"    it('should call done and close connection with promise', function (done) {\n      var e = [];\n\n      const fakeDone = () => {\n        expect(e.length).to.equal(1);\n        done();\n      };\n\n      const encapsulatedTest = withMonitoredClient(['find'], function (client, events, innerDone) {\n        e = events;\n        client.db('integration_test').collection('test').find({}).toArray().then(() => {\n          return innerDone();\n        });\n      }).bind(this);\n      encapsulatedTest().then(fakeDone);\n    });","file":"integration/shared.test.js","skipped":false,"dir":"test"},{"name":"should propagate passed error to done from promise","suites":["shared test utilities","withMonitoredClient"],"updatePoint":{"line":74,"column":58,"index":2191},"line":74,"code":"    it('should propagate passed error to done from promise', function (done) {\n      var e = [];\n\n      const fakeDone = err => {\n        expect(err).to.be.instanceOf(Error);\n        expect(e.length).to.equal(1);\n        done();\n      };\n\n      const encapsulatedTest = withMonitoredClient(['find'], function (client, events, innerDone) {\n        e = events;\n        client.db('integration_test').collection('test').find({}).toArray().then(() => {\n          return innerDone(new Error('hello world'));\n        });\n      }).bind(this);\n      encapsulatedTest().catch(fakeDone);\n    });","file":"integration/shared.test.js","skipped":false,"dir":"test"},{"name":"should provide a useful error if a Promise is not returned","suites":["Transactions","withTransaction"],"updatePoint":{"line":20,"column":66,"index":781},"line":20,"code":"    it('should provide a useful error if a Promise is not returned', {\n      metadata: {\n        requires: {\n          topology: ['replicaset', 'sharded'],\n          mongodb: '>=4.1.5',\n          serverless: 'forbid'\n        }\n      },\n      test: function (done) {\n        function fnThatDoesntReturnPromise() {\n          return false;\n        } // @ts-expect-error: Testing that a non promise returning function is handled correctly\n\n\n        expect(() => session.withTransaction(fnThatDoesntReturnPromise)).to.throw(/must return a Promise/);\n        session.endSession(done);\n      }\n    });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should return readable error if promise rejected with no reason","suites":["Transactions","withTransaction"],"updatePoint":{"line":38,"column":71,"index":1381},"line":38,"code":"    it('should return readable error if promise rejected with no reason', {\n      metadata: {\n        requires: {\n          topology: ['replicaset', 'sharded'],\n          mongodb: '>=4.2.0',\n          serverless: 'forbid'\n        }\n      },\n      test: function (done) {\n        function fnThatReturnsBadPromise() {\n          return Promise.reject();\n        }\n\n        session.withTransaction(fnThatReturnsBadPromise).then(() => done(Error('Expected error'))).catch(err => {\n          expect(err).to.equal(undefined);\n          session.endSession(done);\n        });\n      }\n    });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should return undefined when transaction is aborted explicitly","suites":["Transactions","withTransaction","return value semantics"],"updatePoint":{"line":74,"column":72,"index":2493},"line":74,"code":"      it('should return undefined when transaction is aborted explicitly', async () => {\n        const session = client.startSession();\n        const withTransactionResult = await session.withTransaction(async session => {\n          await collection.insertOne({\n            a: 1\n          }, {\n            session\n          });\n          await collection.findOne({\n            a: 1\n          }, {\n            session\n          });\n          await session.abortTransaction();\n        }).finally(async () => await session.endSession());\n        expect(withTransactionResult).to.be.undefined;\n      });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should return raw command when transaction is successfully committed","suites":["Transactions","withTransaction","return value semantics"],"updatePoint":{"line":91,"column":78,"index":3099},"line":91,"code":"      it('should return raw command when transaction is successfully committed', async () => {\n        const session = client.startSession();\n        const withTransactionResult = await session.withTransaction(async session => {\n          await collection.insertOne({\n            a: 1\n          }, {\n            session\n          });\n          await collection.findOne({\n            a: 1\n          }, {\n            session\n          });\n        }).finally(async () => await session.endSession());\n        expect(withTransactionResult).to.exist;\n        expect(withTransactionResult).to.be.an('object');\n        expect(withTransactionResult).to.have.property('ok', 1);\n      });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should throw when transaction is aborted due to an error","suites":["Transactions","withTransaction","return value semantics"],"updatePoint":{"line":109,"column":66,"index":3765},"line":109,"code":"      it('should throw when transaction is aborted due to an error', async () => {\n        const session = client.startSession();\n        const withTransactionResult = await session.withTransaction(async session => {\n          await collection.insertOne({\n            a: 1\n          }, {\n            session\n          });\n          await collection.findOne({\n            a: 1\n          }, {\n            session\n          });\n          throw new Error(\"I don't wanna transact anymore!\");\n        }).catch(error => error).finally(async () => await session.endSession());\n        expect(withTransactionResult).to.be.instanceOf(Error);\n        expect(withTransactionResult.message).to.equal(\"I don't wanna transact anymore!\");\n      });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should error if transactions are not supported","suites":["Transactions","startTransaction"],"updatePoint":{"line":130,"column":54,"index":4545},"line":130,"code":"    it('should error if transactions are not supported', {\n      metadata: {\n        requires: {\n          topology: ['sharded'],\n          mongodb: '4.0.x'\n        }\n      },\n      test: function (done) {\n        const configuration = this.configuration;\n        const client = configuration.newClient(configuration.url());\n        client.connect((err, client) => {\n          const session = client.startSession();\n          const db = client.db(configuration.db);\n          const coll = db.collection('transaction_error_test');\n          coll.insertOne({\n            a: 1\n          }, err => {\n            expect(err).to.not.exist;\n            expect(() => session.startTransaction()).to.throw('Transactions are not supported on sharded clusters in MongoDB < 4.2.');\n            session.endSession(() => {\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should not error if transactions are supported","suites":["Transactions","startTransaction"],"updatePoint":{"line":156,"column":54,"index":5445},"line":156,"code":"    it('should not error if transactions are supported', {\n      metadata: {\n        requires: {\n          topology: ['sharded'],\n          mongodb: '>=4.1.0'\n        }\n      },\n      test: function (done) {\n        const configuration = this.configuration;\n        const client = configuration.newClient(configuration.url());\n        client.connect(err => {\n          expect(err).to.not.exist;\n          const session = client.startSession();\n          const db = client.db(configuration.db);\n          const coll = db.collection('transaction_error_test');\n          coll.insertOne({\n            a: 1\n          }, err => {\n            expect(err).to.not.exist;\n            expect(() => session.startTransaction()).to.not.throw();\n            session.abortTransaction(() => session.endSession(() => client.close(done)));\n          });\n        });\n      }\n    });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should have a TransientTransactionError label inside of a transaction","suites":["Transactions","TransientTransactionError"],"updatePoint":{"line":183,"column":77,"index":6391},"line":183,"code":"    it('should have a TransientTransactionError label inside of a transaction', {\n      metadata: {\n        requires: {\n          topology: 'replicaset',\n          mongodb: '>=4.0.0'\n        }\n      },\n      test: function (done) {\n        const configuration = this.configuration;\n        const client = configuration.newClient({\n          w: 1\n        });\n        client.connect(err => {\n          expect(err).to.not.exist;\n          const session = client.startSession();\n          const db = client.db(configuration.db);\n          db.collection('transaction_error_test_2').drop(() => {\n            db.createCollection('transaction_error_test_2', (err, coll) => {\n              expect(err).to.not.exist;\n              session.startTransaction();\n              coll.insertOne({\n                a: 1\n              }, {\n                session\n              }, err => {\n                expect(err).to.not.exist;\n                expect(session.inTransaction()).to.be.true;\n                client.db('admin').command({\n                  configureFailPoint: 'failCommand',\n                  mode: {\n                    times: 1\n                  },\n                  data: {\n                    failCommands: ['insert'],\n                    closeConnection: true\n                  }\n                }, err => {\n                  expect(err).to.not.exist;\n                  expect(session.inTransaction()).to.be.true;\n                  coll.insertOne({\n                    b: 2\n                  }, {\n                    session\n                  }, err => {\n                    expect(err).to.exist.and.to.be.an.instanceof(MongoNetworkError);\n\n                    if (err instanceof MongoNetworkError) {\n                      expect(err.hasErrorLabel('TransientTransactionError')).to.be.true;\n                    }\n\n                    session.abortTransaction(() => session.endSession(() => client.close(done)));\n                  });\n                });\n              });\n            });\n          });\n        });\n      }\n    });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should not have a TransientTransactionError label outside of a transaction","suites":["Transactions","TransientTransactionError"],"updatePoint":{"line":242,"column":82,"index":8425},"line":242,"code":"    it('should not have a TransientTransactionError label outside of a transaction', {\n      metadata: {\n        requires: {\n          topology: 'replicaset',\n          mongodb: '>=4.0.0'\n        }\n      },\n      test: function (done) {\n        const configuration = this.configuration;\n        const client = configuration.newClient({\n          w: 1\n        });\n        client.connect(err => {\n          expect(err).to.not.exist;\n          const db = client.db(configuration.db);\n          const coll = db.collection('transaction_error_test1');\n          client.db('admin').command({\n            configureFailPoint: 'failCommand',\n            mode: {\n              times: 2\n            },\n            data: {\n              failCommands: ['insert'],\n              closeConnection: true\n            }\n          }, err => {\n            expect(err).to.not.exist;\n            coll.insertOne({\n              a: 1\n            }, err => {\n              expect(err).to.exist.and.to.be.an.instanceOf(MongoNetworkError);\n              client.close(done);\n            });\n          });\n        });\n      }\n    });","file":"integration/transactions/transactions.test.ts","skipped":false,"dir":"test"},{"name":"should correctly allow for w:0 overriding on the connect url","suites":["URI"],"updatePoint":{"line":14,"column":66,"index":247},"line":14,"code":"  it('should correctly allow for w:0 overriding on the connect url', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      const authInformation = process.env.AUTH === 'auth' ? 'bob:pwd123@' : ''; // Connect using the connection string\n\n      const client = this.configuration.newClient(`mongodb://${authInformation}localhost:27017/?w=0`);\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var db = client.db(self.configuration.db);\n        db.collection('mongoclient_test').update({\n          a: 1\n        }, {\n          $set: {\n            b: 1\n          }\n        }, {\n          upsert: true\n        }, function (err, result) {\n          expect(err).to.not.exist;\n          expect(result).to.exist;\n          expect(result).property('acknowledged').to.be.false;\n          client.close(done);\n        });\n      });\n    }\n  });","file":"integration/uri-options/uri.test.js","skipped":false,"dir":"test"},{"name":"should correctly connect via domain socket","suites":["URI"],"updatePoint":{"line":47,"column":48,"index":1308},"line":47,"code":"  it('should correctly connect via domain socket', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      if (process.platform === 'win32') {\n        return done();\n      }\n\n      const client = this.configuration.newClient('mongodb://%2Ftmp%2Fmongodb-27017.sock');\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        client.close(done);\n      });\n    }\n  });","file":"integration/uri-options/uri.test.js","skipped":false,"dir":"test"},{"name":"should correctly connect via normal url using ip","suites":["URI"],"updatePoint":{"line":67,"column":54,"index":1898},"line":67,"code":"  it('should correctly connect via normal url using ip', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      const client = this.configuration.newClient('mongodb://127.0.0.1:27017/?fsync=true');\n      client.connect((err, client) => {\n        var db = client.db(this.configuration.db);\n        expect(db.writeConcern.fsync).to.be.true;\n        client.close(done);\n      });\n    }\n  });","file":"integration/uri-options/uri.test.js","skipped":false,"dir":"test"},{"name":"should correctly connect using uri encoded username and password","suites":["URI"],"updatePoint":{"line":84,"column":70,"index":2491},"line":84,"code":"  it('should correctly connect using uri encoded username and password', {\n    // Add a tag that our runner can trigger on\n    // in this case we are setting that node needs to be higher than 0.10.X to run\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      var self = this;\n      const configuration = this.configuration;\n      const client = configuration.newClient();\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        var user = 'u$ser',\n            pass = '$specialch@rs';\n        var db = client.db(self.configuration.db);\n        db.addUser(user, pass, function (err) {\n          expect(err).to.not.exist;\n          var uri = 'mongodb://' + encodeURIComponent(user) + ':' + encodeURIComponent(pass) + '@localhost:27017/integration_tests';\n          configuration.newClient(uri).connect(function (err, c) {\n            expect(err).to.not.exist;\n            c.close(() => client.close(done));\n          });\n        });\n      });\n    }\n  });","file":"integration/uri-options/uri.test.js","skipped":false,"dir":"test"},{"name":"should correctly translate uri options","suites":["URI"],"updatePoint":{"line":112,"column":44,"index":3506},"line":112,"code":"  it('should correctly translate uri options', {\n    metadata: {\n      requires: {\n        topology: 'replicaset'\n      }\n    },\n    test: function (done) {\n      const config = this.configuration;\n      const uri = `mongodb://${config.host}:${config.port}/${config.db}?replicaSet=${config.replicasetName}`;\n      const client = this.configuration.newClient(uri);\n      client.connect((err, client) => {\n        expect(err).to.not.exist;\n        expect(client).to.exist;\n        expect(client.options.replicaSet).to.exist.and.equal(config.replicasetName);\n        client.close(done);\n      });\n    }\n  });","file":"integration/uri-options/uri.test.js","skipped":false,"dir":"test"},{"name":"should generate valid credentials with X509","suites":["URI"],"updatePoint":{"line":130,"column":49,"index":4117},"line":130,"code":"  it('should generate valid credentials with X509', {\n    metadata: {\n      requires: {\n        topology: 'single'\n      }\n    },\n    test: function (done) {\n      function validateConnect(options) {\n        expect(options).to.have.property('credentials');\n        expect(options.credentials.mechanism).to.eql('MONGODB-X509');\n        connectStub.restore();\n        done();\n      }\n\n      const topologyPrototype = Topology.prototype;\n      const connectStub = sinon.stub(topologyPrototype, 'connect').callsFake(validateConnect);\n      const uri = 'mongodb://some-hostname/test?ssl=true&authMechanism=MONGODB-X509&replicaSet=rs0';\n      const client = this.configuration.newClient(uri);\n      client.connect();\n    }\n  });","file":"integration/uri-options/uri.test.js","skipped":false,"dir":"test"},{"name":"","suites":["Atlas Connectivity"],"updatePoint":{"line":36,"column":19,"index":1144},"line":36,"code":"        it(`${name}`, makeConnectionTest(connectionString));","file":"manual/atlas_connectivity.test.js","skipped":false,"dir":"test"},{"name":"should authenticate with original uri","suites":["Kerberos"],"updatePoint":{"line":65,"column":43,"index":1548},"line":65,"code":"  it('should authenticate with original uri', function (done) {\n    const client = new MongoClient(krb5Uri);\n    client.connect(function (err, client) {\n      expect(err).to.not.exist;\n      verifyKerberosAuthentication(client, done);\n    });\n  });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"validate that gssapiCanonicalizeHostName can be passed in","suites":["Kerberos"],"updatePoint":{"line":72,"column":63,"index":1817},"line":72,"code":"  it('validate that gssapiCanonicalizeHostName can be passed in', function (done) {\n    if (process.platform === 'darwin') {\n      this.test.skipReason = 'DNS does not resolve with proper CNAME record on evergreen MacOS';\n      this.skip();\n    }\n\n    const client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:mongodb,gssapiCanonicalizeHostName:true&maxPoolSize=1`);\n    client.connect(function (err, client) {\n      if (err) return done(err);\n      expect(dns.resolveCname).to.be.calledOnceWith(host);\n      verifyKerberosAuthentication(client, done);\n    });\n  });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"authenticates with a forward cname lookup","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is forward"],"updatePoint":{"line":93,"column":51,"index":2730},"line":93,"code":"      it('authenticates with a forward cname lookup', function (done) {\n        const client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:mongodb,CANONICALIZE_HOST_NAME:forward&maxPoolSize=1`);\n        client.connect(function (err, client) {\n          if (err) return done(err);\n          expect(dns.resolveCname).to.be.calledOnceWith(host);\n          verifyKerberosAuthentication(client, done);\n        });\n      });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"authenticates with no dns lookups","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is "],"updatePoint":{"line":105,"column":45,"index":3276},"line":105,"code":"        it('authenticates with no dns lookups', function (done) {\n          const client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:mongodb,CANONICALIZE_HOST_NAME:${option}&maxPoolSize=1`);\n          client.connect(function (err, client) {\n            if (err) return done(err);\n            expect(dns.resolveCname).to.not.be.called; // 2 calls when establishing connection - expect no third call.\n\n            expect(dns.lookup).to.be.calledTwice;\n            verifyKerberosAuthentication(client, done);\n          });\n        });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"authenticates with a forward dns lookup and a reverse ptr lookup","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is ","when the reverse lookup succeeds"],"updatePoint":{"line":129,"column":78,"index":4320},"line":129,"code":"          it('authenticates with a forward dns lookup and a reverse ptr lookup', function (done) {\n            const client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:mongodb,CANONICALIZE_HOST_NAME:${option}&maxPoolSize=1`);\n            client.connect(function (err, client) {\n              if (err) return done(err); // 2 calls to establish connection, 1 call in canonicalization.\n\n              expect(dns.lookup).to.be.calledThrice;\n              expect(dns.resolvePtr).to.be.calledOnce;\n              verifyKerberosAuthentication(client, done);\n            });\n          });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"authenticates with a fallback cname lookup","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is ","when the reverse lookup is empty"],"updatePoint":{"line":149,"column":56,"index":5233},"line":149,"code":"          it('authenticates with a fallback cname lookup', function (done) {\n            const client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:mongodb,CANONICALIZE_HOST_NAME:${option}&maxPoolSize=1`);\n            client.connect(function (err, client) {\n              if (err) return done(err); // 2 calls to establish connection, 1 call in canonicalization.\n\n              expect(dns.lookup).to.be.calledThrice; // This fails.\n\n              expect(dns.resolvePtr).to.be.calledOnce; // Expect the fallback to the host name.\n\n              expect(dns.resolveCname).to.not.be.called;\n              verifyKerberosAuthentication(client, done);\n            });\n          });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"authenticates with a fallback cname lookup","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is ","when the reverse lookup fails"],"updatePoint":{"line":172,"column":56,"index":6278},"line":172,"code":"          it('authenticates with a fallback cname lookup', function (done) {\n            const client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:mongodb,CANONICALIZE_HOST_NAME:${option}&maxPoolSize=1`);\n            client.connect(function (err, client) {\n              if (err) return done(err); // 2 calls to establish connection, 1 call in canonicalization.\n\n              expect(dns.lookup).to.be.calledThrice; // This fails.\n\n              expect(dns.resolvePtr).to.be.calledOnce; // Expect the fallback to be called.\n\n              expect(dns.resolveCname).to.be.calledOnceWith(host);\n              verifyKerberosAuthentication(client, done);\n            });\n          });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"authenticates with a fallback host name","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is ","when the cname lookup fails"],"updatePoint":{"line":195,"column":53,"index":7328},"line":195,"code":"          it('authenticates with a fallback host name', function (done) {\n            const client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:mongodb,CANONICALIZE_HOST_NAME:${option}&maxPoolSize=1`);\n            client.connect(function (err, client) {\n              if (err) return done(err); // 2 calls to establish connection, 1 call in canonicalization.\n\n              expect(dns.lookup).to.be.calledThrice; // This fails.\n\n              expect(dns.resolvePtr).to.be.calledOnce; // Expect the fallback to be called.\n\n              expect(dns.resolveCname).to.be.calledOnceWith(host);\n              verifyKerberosAuthentication(client, done);\n            });\n          });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"authenticates with a fallback host name","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is ","when the cname lookup is empty"],"updatePoint":{"line":218,"column":53,"index":8361},"line":218,"code":"          it('authenticates with a fallback host name', function (done) {\n            const client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:mongodb,CANONICALIZE_HOST_NAME:${option}&maxPoolSize=1`);\n            client.connect(function (err, client) {\n              if (err) return done(err); // 2 calls to establish connection, 1 call in canonicalization.\n\n              expect(dns.lookup).to.be.calledThrice; // This fails.\n\n              expect(dns.resolvePtr).to.be.calledOnce; // Expect the fallback to be called.\n\n              expect(dns.resolveCname).to.be.calledOnceWith(host);\n              verifyKerberosAuthentication(client, done);\n            });\n          });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"validate that SERVICE_REALM and CANONICALIZE_HOST_NAME can be passed in","suites":["Kerberos","when passing in CANONICALIZE_HOST_NAME","when the value is ","when the cname lookup is empty"],"line":236,"code":"  it.skip('validate that SERVICE_REALM and CANONICALIZE_HOST_NAME can be passed in', function (done) {","file":"manual/kerberos.test.js","skipped":true,"dir":"test"},{"name":"fails to authenticate","suites":["Kerberos","when passing SERVICE_HOST as an auth mech option","when the SERVICE_HOST is invalid"],"updatePoint":{"line":250,"column":31,"index":9843},"line":250,"code":"      it('fails to authenticate', async function () {\n        let expectedError;\n        await client.connect().catch(e => {\n          expectedError = e;\n        });\n\n        if (!expectedError) {\n          expect.fail('Expected connect with invalid SERVICE_HOST to fail');\n        }\n\n        expect(expectedError.message).to.match(/GSS failure|UNKNOWN_SERVER/);\n      });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"authenticates","suites":["Kerberos","when passing SERVICE_HOST as an auth mech option","when the SERVICE_HOST is valid"],"updatePoint":{"line":269,"column":23,"index":10442},"line":269,"code":"      it('authenticates', function (done) {\n        client.connect(function (err, client) {\n          expect(err).to.not.exist;\n          verifyKerberosAuthentication(client, done);\n        });\n      });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"as an option handed to the MongoClient","suites":["Kerberos","should use the SERVICE_NAME property"],"updatePoint":{"line":278,"column":46,"index":10748},"line":278,"code":"    it('as an option handed to the MongoClient', function (done) {\n      const client = new MongoClient(`${krb5Uri}&maxPoolSize=1`, {\n        authMechanismProperties: {\n          SERVICE_NAME: 'alternate'\n        }\n      });\n      client.connect(function (err) {\n        expect(err).to.exist;\n        expect(err.message).to.match(/(Error from KDC: LOOKING_UP_SERVER)|(not found in Kerberos database)|(UNKNOWN_SERVER)/);\n        done();\n      });\n    });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"as part of the query string parameters","suites":["Kerberos","should use the SERVICE_NAME property"],"updatePoint":{"line":290,"column":46,"index":11202},"line":290,"code":"    it('as part of the query string parameters', function (done) {\n      const client = new MongoClient(`${krb5Uri}&authMechanismProperties=SERVICE_NAME:alternate&maxPoolSize=1`);\n      client.connect(function (err) {\n        expect(err).to.exist;\n        expect(err.message).to.match(/(Error from KDC: LOOKING_UP_SERVER)|(not found in Kerberos database)|(UNKNOWN_SERVER)/);\n        done();\n      });\n    });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"should fail to authenticate with bad credentials","suites":["Kerberos","should use the SERVICE_NAME property"],"updatePoint":{"line":299,"column":54,"index":11625},"line":299,"code":"  it('should fail to authenticate with bad credentials', function (done) {\n    const client = new MongoClient(krb5Uri.replace(encodeURIComponent(process.env.KRB5_PRINCIPAL), 'bad%40creds.cc'));\n    client.connect(function (err) {\n      expect(err).to.exist;\n      expect(err.message).to.match(/Authentication failed/);\n      done();\n    });\n  });","file":"manual/kerberos.test.js","skipped":false,"dir":"test"},{"name":"Should correctly authenticate against ldap","suites":["LDAP"],"updatePoint":{"line":16,"column":48,"index":321},"line":16,"code":"  it('Should correctly authenticate against ldap', function (done) {\n    const client = new MongoClient(process.env.MONGODB_URI);\n    client.connect(function (err, client) {\n      expect(err).to.not.exist;\n      client.db('ldap').collection('test').findOne(function (err, doc) {\n        expect(err).to.not.exist;\n        expect(doc).property('ldap').to.equal(true);\n        client.close(done);\n      });\n    });\n  });","file":"manual/ldap.test.js","skipped":false,"dir":"test"},{"name":"should support OCSP with tlsInsecure","suites":["OCSP Support"],"updatePoint":{"line":33,"column":42,"index":928},"line":33,"code":"  it('should support OCSP with tlsInsecure', function (done) {\n    // should always succeed\n    connect('tls=true&tlsInsecure=true', done);\n  });","file":"manual/ocsp_support.test.js","skipped":false,"dir":"test"},{"name":"should support OCSP with tlsAllowInvalidCertificates","suites":["OCSP Support"],"updatePoint":{"line":37,"column":58,"index":1090},"line":37,"code":"  it('should support OCSP with tlsAllowInvalidCertificates', function (done) {\n    // should always succeed\n    connect('tls=true&tlsAllowInvalidCertificates=true', done);\n  });","file":"manual/ocsp_support.test.js","skipped":false,"dir":"test"},{"name":"should support OCSP with `tls=true`","suites":["OCSP Support"],"updatePoint":{"line":41,"column":41,"index":1251},"line":41,"code":"  it('should support OCSP with `tls=true`', function (done) {\n    connect('tls=true', err => {\n      if (OCSP_TLS_SHOULD_SUCCEED) {\n        expect(err).to.not.exist;\n        return done();\n      }\n\n      expect(err).to.exist;\n      expect(err).to.match(/invalid status response/);\n      done();\n    });\n  });","file":"manual/ocsp_support.test.js","skipped":false,"dir":"test"},{"name":"fails to connect to a single host (connection string)","suites":["Socks5 Connectivity","with missing required Socks5 auth configuration"],"updatePoint":{"line":39,"column":63,"index":1680},"line":39,"code":"      it('fails to connect to a single host (connection string)', async function () {\n        const cs = singleConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n        cs.searchParams.set('directConnection', 'true');\n\n        try {\n          await testConnection(cs.toString(), {});\n        } catch (err) {\n          expect(err.name).to.equal('MongoServerSelectionError');\n          expect(err.message).to.match(/Received invalid Socks5 initial handshake/);\n          return;\n        }\n\n        expect.fail('missed exception');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"fails to connect to a single host (config options)","suites":["Socks5 Connectivity","with missing required Socks5 auth configuration"],"updatePoint":{"line":55,"column":60,"index":2306},"line":55,"code":"      it('fails to connect to a single host (config options)', async function () {\n        try {\n          await testConnection(singleConnectionString.toString(), {\n            proxyHost,\n            proxyPort,\n            directConnection: true\n          });\n        } catch (err) {\n          expect(err.name).to.equal('MongoServerSelectionError');\n          expect(err.message).to.match(/Received invalid Socks5 initial handshake/);\n          return;\n        }\n\n        expect.fail('missed exception');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"fails to connect to a replica set (connection string)","suites":["Socks5 Connectivity","with missing required Socks5 auth configuration"],"updatePoint":{"line":70,"column":63,"index":2824},"line":70,"code":"      it('fails to connect to a replica set (connection string)', async function () {\n        const cs = rsConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n\n        try {\n          await testConnection(cs.toString(), {});\n        } catch (err) {\n          expect(err.name).to.equal('MongoServerSelectionError');\n          expect(err.message).to.match(/Received invalid Socks5 initial handshake/);\n          return;\n        }\n\n        expect.fail('missed exception');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"fails to connect to a replica set (config options)","suites":["Socks5 Connectivity","with missing required Socks5 auth configuration"],"updatePoint":{"line":85,"column":60,"index":3389},"line":85,"code":"      it('fails to connect to a replica set (config options)', async function () {\n        try {\n          await testConnection(rsConnectionString.toString(), {\n            proxyHost,\n            proxyPort\n          });\n        } catch (err) {\n          expect(err.name).to.equal('MongoServerSelectionError');\n          expect(err.message).to.match(/Received invalid Socks5 initial handshake/);\n          return;\n        }\n\n        expect.fail('missed exception');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"fails to connect to a single host (connection string) if auth is present but wrong","suites":["Socks5 Connectivity","with missing required Socks5 auth configuration"],"updatePoint":{"line":99,"column":92,"index":3896},"line":99,"code":"      it('fails to connect to a single host (connection string) if auth is present but wrong', async function () {\n        const cs = singleConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n        cs.searchParams.set('proxyUsername', 'nonexistentuser');\n        cs.searchParams.set('proxyPassword', 'badauth');\n        cs.searchParams.set('directConnection', 'true');\n\n        try {\n          await testConnection(cs.toString(), {});\n        } catch (err) {\n          expect(err.name).to.equal('MongoServerSelectionError');\n          expect(err.message).to.match(/Socket closed/);\n          return;\n        }\n\n        expect.fail('missed exception');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a single host (connection string)","suites":["Socks5 Connectivity","with extraneous Socks5 auth configuration"],"updatePoint":{"line":125,"column":58,"index":4797},"line":125,"code":"      it('can connect to a single host (connection string)', async function () {\n        const cs = singleConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n        cs.searchParams.set('proxyUsername', 'nonexistentuser');\n        cs.searchParams.set('proxyPassword', 'badauth');\n        cs.searchParams.set('directConnection', 'true');\n        await testConnection(cs.toString(), {});\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a single host (config options)","suites":["Socks5 Connectivity","with extraneous Socks5 auth configuration"],"updatePoint":{"line":134,"column":55,"index":5278},"line":134,"code":"      it('can connect to a single host (config options)', async function () {\n        await testConnection(singleConnectionString.toString(), {\n          proxyHost,\n          proxyPort,\n          ...(proxyUsername ? {} : {\n            proxyUsername: 'nonexistentuser',\n            proxyPassword: 'badauth'\n          }),\n          directConnection: true\n        });\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a replica set (connection string)","suites":["Socks5 Connectivity","with extraneous Socks5 auth configuration"],"updatePoint":{"line":145,"column":58,"index":5656},"line":145,"code":"      it('can connect to a replica set (connection string)', async function () {\n        const cs = rsConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n        cs.searchParams.set('proxyUsername', 'nonexistentuser');\n        cs.searchParams.set('proxyPassword', 'badauth');\n        await testConnection(cs.toString(), {});\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a replica set (config options)","suites":["Socks5 Connectivity","with extraneous Socks5 auth configuration"],"updatePoint":{"line":153,"column":55,"index":6076},"line":153,"code":"      it('can connect to a replica set (config options)', async function () {\n        await testConnection(rsConnectionString.toString(), {\n          proxyHost,\n          proxyPort,\n          ...(proxyUsername ? {} : {\n            proxyUsername: 'nonexistentuser',\n            proxyPassword: 'badauth'\n          })\n        });\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a single host (connection string, with directConnection)","suites":["Socks5 Connectivity","with matching socks5 authentication"],"updatePoint":{"line":165,"column":81,"index":6506},"line":165,"code":"      it('can connect to a single host (connection string, with directConnection)', async function () {\n        const cs = singleConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n\n        if (proxyUsername) {\n          cs.searchParams.set('proxyUsername', proxyUsername);\n          cs.searchParams.set('proxyPassword', proxyPassword);\n        }\n\n        cs.searchParams.set('directConnection', 'true');\n        expect(await testConnection(cs.toString(), {})).to.equal('Single');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a single host (config options, with directConnection)","suites":["Socks5 Connectivity","with matching socks5 authentication"],"updatePoint":{"line":178,"column":78,"index":7082},"line":178,"code":"      it('can connect to a single host (config options, with directConnection)', async function () {\n        expect(await testConnection(singleConnectionString.toString(), {\n          proxyHost,\n          proxyPort,\n          ...(proxyUsername ? {\n            proxyUsername,\n            proxyPassword\n          } : {}),\n          directConnection: true\n        })).to.equal('Single');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a single host (connection string, without directConnection)","suites":["Socks5 Connectivity","with matching socks5 authentication"],"updatePoint":{"line":189,"column":84,"index":7483},"line":189,"code":"      it('can connect to a single host (connection string, without directConnection)', async function () {\n        const cs = singleConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n\n        if (proxyUsername) {\n          cs.searchParams.set('proxyUsername', proxyUsername);\n          cs.searchParams.set('proxyPassword', proxyPassword);\n        }\n\n        cs.searchParams.set('directConnection', 'false');\n        expect(await testConnection(cs.toString(), {})).to.equal('ReplicaSetWithPrimary');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a single host (config options, without directConnection)","suites":["Socks5 Connectivity","with matching socks5 authentication"],"updatePoint":{"line":202,"column":81,"index":8078},"line":202,"code":"      it('can connect to a single host (config options, without directConnection)', async function () {\n        expect(await testConnection(singleConnectionString.toString(), {\n          proxyHost,\n          proxyPort,\n          ...(proxyUsername ? {\n            proxyUsername,\n            proxyPassword\n          } : {}),\n          directConnection: false\n        })).to.equal('ReplicaSetWithPrimary');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a replica set (connection string)","suites":["Socks5 Connectivity","with matching socks5 authentication"],"updatePoint":{"line":213,"column":58,"index":8469},"line":213,"code":"      it('can connect to a replica set (connection string)', async function () {\n        const cs = rsConnectionString.clone();\n        cs.searchParams.set('proxyHost', proxyHost);\n        cs.searchParams.set('proxyPort', String(proxyPort));\n\n        if (proxyUsername) {\n          cs.searchParams.set('proxyUsername', proxyUsername);\n          cs.searchParams.set('proxyPassword', proxyPassword);\n        }\n\n        expect(await testConnection(cs.toString(), {})).to.equal('ReplicaSetWithPrimary');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"can connect to a replica set (config options)","suites":["Socks5 Connectivity","with matching socks5 authentication"],"updatePoint":{"line":225,"column":55,"index":8976},"line":225,"code":"      it('can connect to a replica set (config options)', async function () {\n        expect(await testConnection(rsConnectionString.toString(), {\n          proxyHost,\n          proxyPort,\n          ...(proxyUsername ? {\n            proxyUsername,\n            proxyPassword\n          } : {})\n        })).to.equal('ReplicaSetWithPrimary');\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"does not mention the proxy in command monitoring events","suites":["Socks5 Connectivity","with matching socks5 authentication"],"updatePoint":{"line":235,"column":65,"index":9335},"line":235,"code":"      it('does not mention the proxy in command monitoring events', async function () {\n        const client = new MongoClient(singleConnectionString.toString(), {\n          proxyHost,\n          proxyPort,\n          ...(proxyUsername ? {\n            proxyUsername,\n            proxyPassword\n          } : {}),\n          directConnection: true,\n          monitorCommands: true\n        });\n        const seenCommandAddresses = new Set();\n        client.on('commandSucceeded', ev => seenCommandAddresses.add(ev.address));\n        await client.connect();\n        await client.db('admin').command({\n          [LEGACY_HELLO_COMMAND]: 1\n        });\n        await client.close();\n        expect([...seenCommandAddresses]).to.deep.equal(singleConnectionString.hosts);\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"rejects invalid MongoClient options ","suites":["Socks5 Connectivity","MongoClient option validation"],"updatePoint":{"line":275,"column":77,"index":10538},"line":275,"code":"      it(`rejects invalid MongoClient options ${JSON.stringify(proxyOptions)}`, () => {\n        expect(() => new MongoClient('mongodb://localhost', proxyOptions)).to.throw(MongoParseError);\n      });","file":"manual/socks5.test.ts","skipped":false,"dir":"test"},{"name":"should connect with tls via client options","suites":["TLS Support"],"updatePoint":{"line":27,"column":48,"index":698},"line":27,"code":"  it('should connect with tls via client options', makeConnectionTest(connectionString, tlsSettings));","file":"manual/tls_support.test.js","skipped":false,"dir":"test"},{"name":"should connect with tls via url options","suites":["TLS Support"],"updatePoint":{"line":28,"column":45,"index":798},"line":28,"code":"  it('should connect with tls via url options', makeConnectionTest(`${connectionString}?${Object.keys(tlsSettings).map(key => `${key}=${tlsSettings[key]}`).join('&')}`));","file":"manual/tls_support.test.js","skipped":false,"dir":"test"},{"name":"","suites":["Auth option spec tests"],"updatePoint":{"line":10,"column":31,"index":435},"line":10,"code":"        it(`${test.description}`, function () {\n          if (SKIP.includes(test.description)) {\n            this.test.skipReason = 'NODE-3986: Fix MONGODB-AWS Spec Test';\n            this.skip();\n          }\n\n          executeUriValidationTest(test);\n        });","file":"unit/assorted/auth.spec.test.ts","skipped":false,"dir":"test"},{"name":"should propagate errors","suites":["Bulk Writes"],"updatePoint":{"line":31,"column":29,"index":625},"line":31,"code":"  it('should propagate errors', function (done) {\n    const client = new MongoClient(`mongodb://${test.server.uri()}/test`);\n\n    let close = e => {\n      close = () => {};\n\n      client.close(() => done(e));\n    };\n\n    let hasErrored = false;\n    test.server.setMessageHandler(request => {\n      const doc = request.document;\n\n      if (isHello(doc)) {\n        request.reply(Object.assign({}, mock.HELLO));\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      } else if (doc.insert) {\n        if (hasErrored) {\n          return request.reply({\n            ok: 1\n          });\n        }\n\n        hasErrored = true;\n        return request.reply({\n          ok: 0\n        });\n      } else {\n        close(`Received unknown command ${doc}`);\n      }\n    });\n    client.connect(function (err) {\n      expect(err).to.not.exist;\n      const coll = client.db('foo').collection('bar');\n      coll.insert(documents, {\n        ordered: false\n      }, function (err) {\n        try {\n          expect(err).to.be.an.instanceOf(Error);\n          close();\n        } catch (e) {\n          close(e);\n        }\n      });\n    });\n  });","file":"unit/assorted/bulk_write.test.js","skipped":false,"dir":"test"},{"name":"should let wrapping libraries amend the client metadata","suites":["Client (unit)"],"updatePoint":{"line":26,"column":61,"index":518},"line":26,"code":"  it('should let wrapping libraries amend the client metadata', function () {\n    let handshake;\n    server.setMessageHandler(request => {\n      const doc = request.document;\n\n      if (isHello(doc)) {\n        handshake = doc;\n        request.reply(Object.assign({}, mock.HELLO));\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    client = new MongoClient(`mongodb://${server.uri()}/`, {\n      driverInfo: {\n        name: 'mongoose',\n        version: '5.7.10',\n        platform: 'llama edition'\n      }\n    });\n    return client.connect().then(() => {\n      expect(handshake).to.have.nested.property('client.driver');\n      expect(handshake).nested.property('client.driver.name').to.equal('nodejs|mongoose');\n      expect(handshake).nested.property('client.driver.version').to.match(/|5.7.10/);\n      expect(handshake).nested.property('client.platform').to.match(/llama edition/);\n    });\n  });","file":"unit/assorted/client.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to count command","suites":["Collation"],"updatePoint":{"line":28,"column":58,"index":535},"line":28,"code":"  it('Successfully pass through collation to count command', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.count) {\n        commandResult = doc;\n        request.reply({\n          ok: 1,\n          result: {\n            n: 1\n          }\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_test');\n      return db.collection('test').estimatedDocumentCount({\n        collation: {\n          caseLevel: true\n        }\n      }).then(() => {\n        expect(commandResult).to.have.property('collation');\n        expect(commandResult.collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to aggregation command","suites":["Collation"],"updatePoint":{"line":66,"column":64,"index":1614},"line":66,"code":"  it('Successfully pass through collation to aggregation command', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.aggregate) {\n        commandResult = doc;\n        request.reply({\n          ok: 1,\n          cursor: {\n            id: 0,\n            firstBatch: [],\n            ns: 'collation_test'\n          }\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_test');\n      return db.collection('test').aggregate([{\n        $match: {}\n      }, {\n        $out: 'readConcernCollectionAggregate1Output'\n      }], {\n        collation: {\n          caseLevel: true\n        }\n      }).toArray().then(() => {\n        expect(commandResult).to.have.property('collation');\n        expect(commandResult.collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to distinct command","suites":["Collation"],"updatePoint":{"line":110,"column":61,"index":2851},"line":110,"code":"  it('Successfully pass through collation to distinct command', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      var doc = request.document;\n\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.distinct) {\n        commandResult = doc;\n        request.reply({\n          ok: 1\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').distinct('a', {}, {\n        collation: {\n          caseLevel: true\n        }\n      }).then(() => {\n        expect(commandResult).to.have.property('collation');\n        expect(commandResult.collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to mapReduce command","suites":["Collation"],"updatePoint":{"line":145,"column":62,"index":3872},"line":145,"code":"  it('Successfully pass through collation to mapReduce command', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      var doc = request.document;\n\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.mapReduce) {\n        commandResult = doc;\n        request.reply({\n          ok: 1,\n          result: 'tempCollection'\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      const map = new Code('function() { emit(this.user_id, 1); }');\n      const reduce = new Code('function(k,vals) { return 1; }');\n      return db.collection('test').mapReduce(map, reduce, {\n        out: {\n          replace: 'tempCollection'\n        },\n        collation: {\n          caseLevel: true\n        }\n      }).then(() => {\n        expect(commandResult).to.have.property('collation');\n        expect(commandResult.collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to remove command","suites":["Collation"],"updatePoint":{"line":186,"column":59,"index":5128},"line":186,"code":"  it('Successfully pass through collation to remove command', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      var doc = request.document;\n\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.delete) {\n        commandResult = doc;\n        request.reply({\n          ok: 1\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').deleteMany({}, {\n        collation: {\n          caseLevel: true\n        }\n      }).then(() => {\n        expect(commandResult.deletes).to.have.length.at.least(1);\n        expect(commandResult.deletes[0]).to.have.property('collation');\n        expect(commandResult.deletes[0].collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to update command","suites":["Collation"],"updatePoint":{"line":222,"column":59,"index":6229},"line":222,"code":"  it('Successfully pass through collation to update command', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.update) {\n        commandResult = doc;\n        request.reply({\n          ok: 1\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').updateOne({\n        a: 1\n      }, {\n        $set: {\n          b: 1\n        }\n      }, {\n        collation: {\n          caseLevel: true\n        }\n      }).then(() => {\n        expect(commandResult.updates).to.have.length.at.least(1);\n        expect(commandResult.updates[0]).to.have.property('collation');\n        expect(commandResult.updates[0].collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to find command via options","suites":["Collation"],"updatePoint":{"line":264,"column":69,"index":7413},"line":264,"code":"  it('Successfully pass through collation to find command via options', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.find) {\n        commandResult = doc;\n        request.reply({\n          ok: 1,\n          cursor: {\n            id: 0,\n            firstBatch: []\n          }\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').find({\n        a: 1\n      }, {\n        collation: {\n          caseLevel: true\n        }\n      }).toArray().then(() => {\n        expect(commandResult).to.have.property('collation');\n        expect(commandResult.collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to find command via cursor","suites":["Collation"],"updatePoint":{"line":305,"column":68,"index":8538},"line":305,"code":"  it('Successfully pass through collation to find command via cursor', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.find) {\n        commandResult = doc;\n        request.reply({\n          ok: 1,\n          cursor: {\n            id: 0,\n            firstBatch: []\n          }\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').find({\n        a: 1\n      }).collation({\n        caseLevel: true\n      }).toArray().then(() => {\n        expect(commandResult).to.have.property('collation');\n        expect(commandResult.collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to findOne","suites":["Collation"],"updatePoint":{"line":344,"column":52,"index":9624},"line":344,"code":"  it('Successfully pass through collation to findOne', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.find) {\n        commandResult = doc;\n        request.reply({\n          ok: 1,\n          cursor: {\n            id: 0,\n            firstBatch: []\n          }\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').findOne({\n        a: 1\n      }, {\n        collation: {\n          caseLevel: true\n        }\n      }).then(() => {\n        expect(commandResult).to.have.property('collation');\n        expect(commandResult.collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to createCollection","suites":["Collation"],"updatePoint":{"line":385,"column":61,"index":10735},"line":385,"code":"  it('Successfully pass through collation to createCollection', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.listCollections) {\n        request.reply({\n          ok: 1,\n          cursor: {\n            id: Long.fromNumber(0),\n            ns: 'test.cmd$.listCollections',\n            firstBatch: []\n          }\n        });\n      } else if (doc.create) {\n        commandResult = doc;\n        request.reply({\n          ok: 1\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.createCollection('test', {\n        collation: {\n          caseLevel: true\n        }\n      }).then(() => {\n        expect(commandResult).to.have.property('collation');\n        expect(commandResult.collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully pass through collation to bulkWrite command","suites":["Collation"],"updatePoint":{"line":429,"column":62,"index":11977},"line":429,"code":"  it('Successfully pass through collation to bulkWrite command', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.update) {\n        commandResult = doc;\n        request.reply({\n          ok: 1\n        });\n      } else if (doc.delete) {\n        request.reply({\n          ok: 1\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').bulkWrite([{\n        updateOne: {\n          filter: {\n            a: 2\n          },\n          update: {\n            $set: {\n              a: 2\n            }\n          },\n          upsert: true,\n          collation: {\n            caseLevel: true\n          }\n        }\n      }, {\n        deleteOne: {\n          filter: {\n            c: 1\n          }\n        }\n      }], {\n        ordered: true\n      }).then(() => {\n        expect(commandResult).to.exist;\n        expect(commandResult).to.have.property('updates');\n        expect(commandResult.updates).to.have.length.at.least(1);\n        expect(commandResult.updates[0]).to.have.property('collation');\n        expect(commandResult.updates[0].collation).to.eql({\n          caseLevel: true\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"Successfully create index with collation","suites":["Collation"],"updatePoint":{"line":490,"column":46,"index":13567},"line":490,"code":"  it('Successfully create index with collation', () => {\n    const client = new MongoClient(`mongodb://${testContext.server.uri()}/test`);\n    const primary = [Object.assign({}, mock.HELLO)];\n    let commandResult;\n    testContext.server.setMessageHandler(request => {\n      const doc = request.document;\n\n      if (isHello(doc)) {\n        request.reply(primary[0]);\n      } else if (doc.createIndexes) {\n        commandResult = doc;\n        request.reply({\n          ok: 1\n        });\n      } else if (doc.endSessions) {\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    return client.connect().then(() => {\n      const db = client.db('collation_db');\n      return db.collection('test').createIndex({\n        a: 1\n      }, {\n        collation: {\n          caseLevel: true\n        }\n      }).then(() => {\n        expect(commandResult).to.containSubset({\n          createIndexes: 'test',\n          indexes: [{\n            name: 'a_1',\n            key: {\n              a: 1\n            },\n            collation: {\n              caseLevel: true\n            }\n          }]\n        });\n        return client.close();\n      });\n    });\n  });","file":"unit/assorted/collations.test.js","skipped":false,"dir":"test"},{"name":"multiple functions with the same deprecated options should both warn","suites":["Deprecation Warnings","Deprecation Warnings - unit","Mult functions with same options"],"updatePoint":{"line":65,"column":78,"index":1580},"line":65,"code":"      it('multiple functions with the same deprecated options should both warn', done => {\n        process.nextTick(() => {\n          expect(messages).to.deep.equal(['f1 option [maxScan]' + defaultMessage, 'f2 option [maxScan]' + defaultMessage]);\n          expect(messages).to.have.a.lengthOf(2);\n          done();\n        });\n      });","file":"unit/assorted/deprecate_warning.test.js","skipped":false,"dir":"test"},{"name":"should not warn if empty options object passed in","suites":["Deprecation Warnings","Deprecation Warnings - unit","Empty options object"],"updatePoint":{"line":82,"column":59,"index":2158},"line":82,"code":"      it('should not warn if empty options object passed in', done => {\n        process.nextTick(() => {\n          expect(messages).to.have.a.lengthOf(0);\n          done();\n        });\n      });","file":"unit/assorted/deprecate_warning.test.js","skipped":false,"dir":"test"},{"name":"should use user-specified message handler","suites":["Deprecation Warnings","Deprecation Warnings - unit","Custom Message Handler"],"updatePoint":{"line":107,"column":51,"index":2869},"line":107,"code":"      it('should use user-specified message handler', done => {\n        process.nextTick(() => {\n          expect(messages).to.deep.equal(['custom msg for function f and option maxScan', 'custom msg for function f and option snapshot', 'custom msg for function f and option fields']);\n          expect(messages).to.have.a.lengthOf(3);\n          done();\n        });\n      });","file":"unit/assorted/deprecate_warning.test.js","skipped":false,"dir":"test"},{"name":"each function should only warn once per deprecated option","suites":["Deprecation Warnings","Deprecation Warnings - unit","Warn once"],"updatePoint":{"line":131,"column":67,"index":3631},"line":131,"code":"      it('each function should only warn once per deprecated option', done => {\n        process.nextTick(() => {\n          expect(messages).to.deep.equal(['f option [maxScan]' + defaultMessage, 'f option [fields]' + defaultMessage]);\n          expect(messages).to.have.a.lengthOf(2);\n          done();\n        });\n      });","file":"unit/assorted/deprecate_warning.test.js","skipped":false,"dir":"test"},{"name":"wrapped functions should maintain original functionality","suites":["Deprecation Warnings","Deprecation Warnings - unit","Maintain functionality"],"updatePoint":{"line":167,"column":66,"index":4659},"line":167,"code":"      it('wrapped functions should maintain original functionality', done => {\n        process.nextTick(() => {\n          expect(messages).to.deep.equal(['f option [multiply]' + defaultMessage, 'f option [add]' + defaultMessage]);\n          expect(messages).to.have.a.lengthOf(2);\n          done();\n        });\n      });","file":"unit/assorted/deprecate_warning.test.js","skipped":false,"dir":"test"},{"name":"optionsIndex pointing to undefined should not error","suites":["Deprecation Warnings","Deprecation Warnings - unit","Maintain functionality"],"updatePoint":{"line":175,"column":59,"index":4981},"line":175,"code":"    it('optionsIndex pointing to undefined should not error', () => {\n      const f = makeTestFunction({\n        name: 'f',\n        deprecatedOptions: deprecatedOptions,\n        optionsIndex: 0\n      });\n      expect(f).to.not.throw();\n    });","file":"unit/assorted/deprecate_warning.test.js","skipped":false,"dir":"test"},{"name":"optionsIndex not pointing to object should not error","suites":["Deprecation Warnings","Deprecation Warnings - unit","Maintain functionality"],"updatePoint":{"line":183,"column":60,"index":5226},"line":183,"code":"    it('optionsIndex not pointing to object should not error', () => {\n      const f = makeTestFunction({\n        name: 'f',\n        deprecatedOptions: deprecatedOptions,\n        optionsIndex: 0\n      });\n      expect(() => f('not-an-object')).to.not.throw();\n    });","file":"unit/assorted/deprecate_warning.test.js","skipped":false,"dir":"test"},{"name":"test behavior for classes with an associated logger","suites":["Deprecation Warnings","Deprecation Warnings - functional"],"updatePoint":{"line":196,"column":59,"index":5639},"line":196,"code":"    it('test behavior for classes with an associated logger', function () {\n      const fakeClass = new ClassWithLogger();\n      const logger = fakeClass.getLogger();\n      const stub = sinon.stub(logger, 'warn');\n      fakeClass.f({\n        maxScan: 5,\n        snapshot: true\n      });\n      fakeClass.f({\n        maxScan: 5,\n        snapshot: true\n      });\n      expect(stub).to.have.been.calledTwice;\n      ensureCalledWith(stub, ['f option [maxScan] is deprecated and will be removed in a later version.', 'f option [snapshot] is deprecated and will be removed in a later version.']);\n    });","file":"unit/assorted/deprecate_warning.test.js","skipped":false,"dir":"test"},{"name":"test behavior for classes without an associated logger","suites":["Deprecation Warnings","Deprecation Warnings - functional"],"updatePoint":{"line":211,"column":62,"index":6240},"line":211,"code":"    it('test behavior for classes without an associated logger', function () {\n      const fakeClass = new ClassWithoutLogger();\n\n      function func() {\n        fakeClass.f({\n          maxScan: 5,\n          snapshot: true\n        });\n      }\n\n      expect(func).to.not.throw();\n    });","file":"unit/assorted/deprecate_warning.test.js","skipped":false,"dir":"test"},{"name":"test behavior for classes with an undefined logger","suites":["Deprecation Warnings","Deprecation Warnings - functional"],"updatePoint":{"line":223,"column":58,"index":6523},"line":223,"code":"    it('test behavior for classes with an undefined logger', function () {\n      const fakeClass = new ClassWithUndefinedLogger();\n\n      function func() {\n        fakeClass.f({\n          maxScan: 5,\n          snapshot: true\n        });\n      }\n\n      expect(func).to.not.throw();\n    });","file":"unit/assorted/deprecate_warning.test.js","skipped":false,"dir":"test"},{"name":"should import  directly without issue","suites":["importing mongodb driver"],"updatePoint":{"line":29,"column":75,"index":778},"line":29,"code":"    it(`should import ${sourceFile.slice(sliceFrom)} directly without issue`, () => {\n      execSync(`./node_modules/.bin/ts-node -e \"require('${sourceFile}')\"`);\n    });","file":"unit/assorted/imports.test.ts","skipped":false,"dir":"test"},{"name":"should error if not installed","suites":["optionalRequire","Snappy"],"updatePoint":{"line":41,"column":37,"index":723},"line":41,"code":"    it('should error if not installed', function () {\n      const moduleName = 'snappy';\n\n      if (moduleExistsSync(moduleName)) {\n        return this.skip();\n      }\n\n      compress({\n        options: {\n          agreedCompressor: 'snappy'\n        }\n      }, Buffer.alloc(1), error => {\n        expect(error).to.exist;\n        expect(error.message).includes('not found');\n      });\n    });","file":"unit/assorted/optional_require.test.js","skipped":false,"dir":"test"},{"name":"should error if not installed","suites":["optionalRequire","Kerberos"],"updatePoint":{"line":59,"column":37,"index":1157},"line":59,"code":"    it('should error if not installed', function () {\n      const moduleName = 'kerberos';\n\n      if (moduleExistsSync(moduleName)) {\n        return this.skip();\n      }\n\n      const gssapi = new GSSAPI();\n      gssapi.auth(new AuthContext(null, true, {\n        hostAddress: new HostAddress('a'),\n        credentials: true\n      }), error => {\n        expect(error).to.exist;\n        expect(error.message).includes('not found');\n      });\n    });","file":"unit/assorted/optional_require.test.js","skipped":false,"dir":"test"},{"name":"should error if not installed","suites":["optionalRequire","aws4"],"updatePoint":{"line":77,"column":37,"index":1642},"line":77,"code":"    it('should error if not installed', function () {\n      const moduleName = 'aws4';\n\n      if (moduleExistsSync(moduleName)) {\n        return this.skip();\n      }\n\n      const mdbAWS = new MongoDBAWS();\n      mdbAWS.auth(new AuthContext({\n        hello: {\n          maxWireVersion: 9\n        }\n      }, true, null), error => {\n        expect(error).to.exist;\n        expect(error.message).includes('not found');\n      });\n    });","file":"unit/assorted/optional_require.test.js","skipped":false,"dir":"test"},{"name":"should error if iteration count is less than 4096","suites":["SCRAM Iterations Tests"],"updatePoint":{"line":18,"column":55,"index":679},"line":18,"code":"  it('should error if iteration count is less than 4096', async function () {\n    const scramResponse = 'r=IE+xNFeOcslsupAA+zkDVzHd5HfwoRuP7Wi8S4py+erf8PcNm7XIdXQyT52Nj3+M,s=AzomrlMs99A7oFxDLpgFvVb+CSvdyXuNagoWVw==,i=4000';\n    const credentials = new MongoCredentials({\n      mechanism: 'DEFAULT',\n      source: 'db',\n      username: 'user',\n      password: 'pencil',\n      mechanismProperties: {}\n    });\n    client.s.options.credentials = credentials;\n    server.setMessageHandler(request => {\n      const doc = request.document;\n\n      if (isHello(doc)) {\n        return request.reply(Object.assign({}, mock.HELLO));\n      } else if (doc.saslStart) {\n        return request.reply({\n          ok: 1,\n          done: false,\n          payload: Buffer.from(scramResponse)\n        });\n      } else if (doc.saslContinue) {\n        throw new Error('should not be here');\n      }\n    });\n    const thrownError = await client.connect().catch(error => error);\n    expect(thrownError).to.be.instanceOf(MongoRuntimeError);\n    expect(thrownError).to.have.property('message').that.matches(/Server returned an invalid iteration count/);\n  });","file":"unit/assorted/scram_iterations.test.ts","skipped":false,"dir":"test"},{"name":"should error if server digest is invalid","suites":["SCRAM Iterations Tests"],"updatePoint":{"line":47,"column":46,"index":1803},"line":47,"code":"  it('should error if server digest is invalid', async function () {\n    const credentials = new MongoCredentials({\n      mechanism: 'DEFAULT',\n      source: 'db',\n      username: 'user',\n      password: 'pencil',\n      mechanismProperties: {}\n    });\n    client.s.options.credentials = credentials;\n    server.setMessageHandler(request => {\n      const doc = request.document;\n\n      if (isHello(doc)) {\n        return request.reply(Object.assign({}, mock.HELLO));\n      } else if (doc.saslStart) {\n        return request.reply({\n          ok: 1,\n          done: false,\n          payload: Buffer.from('r=VNnXkRqKflB5+rmfnFiisCWzgDLzez02iRpbvE5mQjMvizb+VkSPRZZ/pDmFzLxq,s=dZTyOb+KZqoeTFdsULiqow==,i=10000')\n        });\n      } else if (doc.saslContinue) {\n        return request.reply({\n          ok: 1,\n          done: false,\n          payload: Buffer.from('v=bWFsaWNpb3VzbWFsaWNpb3VzVzV')\n        });\n      }\n    });\n    const thrownError = await client.connect().catch(error => error);\n    expect(thrownError).to.be.instanceOf(MongoRuntimeError);\n    expect(thrownError).to.have.property('message').that.matches(/Server returned an invalid signature/);\n  });","file":"unit/assorted/scram_iterations.test.ts","skipped":false,"dir":"test"},{"name":"should properly handle network errors on `saslContinue`","suites":["SCRAM Iterations Tests"],"updatePoint":{"line":79,"column":61,"index":2980},"line":79,"code":"  it('should properly handle network errors on `saslContinue`', async function () {\n    const credentials = new MongoCredentials({\n      mechanism: 'DEFAULT',\n      source: 'db',\n      username: 'user',\n      password: 'pencil',\n      mechanismProperties: {}\n    });\n    client.s.options.credentials = credentials;\n    server.setMessageHandler(request => {\n      const doc = request.document;\n\n      if (isHello(doc)) {\n        return request.reply(Object.assign({}, mock.HELLO));\n      } else if (doc.saslStart) {\n        return request.reply({\n          ok: 1,\n          done: false,\n          payload: Buffer.from('r=VNnXkRqKflB5+rmfnFiisCWzgDLzez02iRpbvE5mQjMvizb+VkSPRZZ/pDmFzLxq,s=dZTyOb+KZqoeTFdsULiqow==,i=10000')\n        });\n      } else if (doc.saslContinue) {\n        request.connection.destroy();\n      }\n    });\n    const thrownError = await client.connect().catch(error => error);\n    expect(thrownError).to.be.instanceOf(MongoNetworkError);\n    expect(thrownError).to.have.property('message').that.matches(/connection(.+)closed/);\n  });","file":"unit/assorted/scram_iterations.test.ts","skipped":false,"dir":"test"},{"name":"should not throw a synchronous exception if sessions are not supported","suites":["Sessions - client/unit","Client"],"updatePoint":{"line":28,"column":78,"index":617},"line":28,"code":"    it('should not throw a synchronous exception if sessions are not supported', function () {\n      test.server.setMessageHandler(request => {\n        var doc = request.document;\n\n        if (isHello(doc)) {\n          request.reply(Object.assign({}, mock.HELLO));\n        } else if (doc.endSessions) {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      const client = new MongoClient(`mongodb://${test.server.uri()}/test`);\n      return client.connect().then(() => {\n        expect(() => client.startSession()).to.not.throw('Current topology does not support sessions');\n        return client.close();\n      });\n    });","file":"unit/assorted/sessions_client.test.js","skipped":false,"dir":"test"},{"name":"should throw an exception if sessions are not supported on some servers","suites":["Sessions - client/unit","Client"],"updatePoint":{"line":46,"column":79,"index":1272},"line":46,"code":"    it('should throw an exception if sessions are not supported on some servers', function () {\n      const replicaSetMock = new ReplSetFixture();\n      let testClient;\n      return replicaSetMock.setup({\n        doNotInitHandlers: true\n      }).then(() => {\n        replicaSetMock.firstSecondaryServer.setMessageHandler(request => {\n          var doc = request.document;\n\n          if (isHello(doc)) {\n            const hello = replicaSetMock.firstSecondaryStates[0];\n            hello.logicalSessionTimeoutMinutes = 20;\n            request.reply(hello);\n          } else if (doc.endSessions) {\n            request.reply({\n              ok: 1\n            });\n          }\n        });\n        replicaSetMock.secondSecondaryServer.setMessageHandler(request => {\n          var doc = request.document;\n\n          if (isHello(doc)) {\n            const hello = replicaSetMock.secondSecondaryStates[0];\n            hello.logicalSessionTimeoutMinutes = 10;\n            request.reply(hello);\n          } else if (doc.endSessions) {\n            request.reply({\n              ok: 1\n            });\n          }\n        });\n        replicaSetMock.arbiterServer.setMessageHandler(request => {\n          var doc = request.document;\n\n          if (isHello(doc)) {\n            const hello = replicaSetMock.arbiterStates[0];\n            hello.logicalSessionTimeoutMinutes = 30;\n            request.reply(hello);\n          } else if (doc.endSessions) {\n            request.reply({\n              ok: 1\n            });\n          }\n        });\n        replicaSetMock.primaryServer.setMessageHandler(request => {\n          var doc = request.document;\n\n          if (isHello(doc)) {\n            const hello = replicaSetMock.primaryStates[0];\n            hello.logicalSessionTimeoutMinutes = null;\n            request.reply(hello);\n          } else if (doc.endSessions) {\n            request.reply({\n              ok: 1\n            });\n          }\n        });\n        return replicaSetMock.uri();\n      }).then(uri => {\n        testClient = new MongoClient(uri);\n        return testClient.connect();\n      }).then(client => {\n        const session = client.startSession();\n        return client.db().collection('t').insertOne({\n          a: 1\n        }, {\n          session\n        });\n      }).then(() => {\n        expect.fail('Expected an error to be thrown about not supporting sessions');\n      }).catch(error => {\n        expect(error.message).to.equal('Current topology does not support sessions');\n      }).finally(() => testClient ? testClient.close() : null);\n    });","file":"unit/assorted/sessions_client.test.js","skipped":false,"dir":"test"},{"name":"should return a client session when requested if the topology supports it","suites":["Sessions - client/unit","Client"],"updatePoint":{"line":121,"column":81,"index":3826},"line":121,"code":"    it('should return a client session when requested if the topology supports it', function (done) {\n      test.server.setMessageHandler(request => {\n        var doc = request.document;\n\n        if (isHello(doc)) {\n          request.reply(Object.assign({}, mock.HELLO, {\n            logicalSessionTimeoutMinutes: 10\n          }));\n        } else if (doc.endSessions) {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      const client = new MongoClient(`mongodb://${test.server.uri()}/test`);\n      client.connect(function (err, client) {\n        expect(err).to.not.exist;\n        let session = client.startSession();\n        expect(session).to.exist;\n        session.endSession({\n          skipCommand: true\n        });\n        client.close(done);\n      });\n    });","file":"unit/assorted/sessions_client.test.js","skipped":false,"dir":"test"},{"name":"should include `afterClusterTime` in read command with causal consistency","suites":["Sessions - unit/sessions","Collection"],"updatePoint":{"line":30,"column":81,"index":606},"line":30,"code":"    it('should include `afterClusterTime` in read command with causal consistency', function () {\n      let findCommand;\n      let insertOperationTime = Timestamp.fromNumber(Date.now());\n      test.server.setMessageHandler(request => {\n        const doc = request.document;\n\n        if (isHello(doc)) {\n          request.reply(Object.assign({\n            logicalSessionTimeoutMinutes: 15\n          }, mock.HELLO));\n        } else if (doc.insert) {\n          request.reply({\n            ok: 1,\n            operationTime: insertOperationTime\n          });\n        } else if (doc.find) {\n          findCommand = doc;\n          request.reply({\n            ok: 1,\n            cursor: {\n              id: 0,\n              firstBatch: []\n            }\n          });\n        } else if (doc.endSessions) {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      const client = new MongoClient(`mongodb://${test.server.uri()}/test`);\n      return client.connect().then(client => {\n        const session = client.startSession({\n          causalConsistency: true\n        });\n        const coll = client.db('foo').collection('bar');\n        return coll.insert({\n          a: 42\n        }, {\n          session: session\n        }).then(() => coll.findOne({}, {\n          session: session,\n          readConcern: {\n            level: 'majority'\n          }\n        })).then(() => {\n          expect(findCommand.readConcern).to.have.keys(['level', 'afterClusterTime']);\n          expect(findCommand.readConcern.afterClusterTime).to.eql(insertOperationTime);\n          session.endSession({\n            skipCommand: true\n          });\n          return client.close();\n        });\n      });\n    });","file":"unit/assorted/sessions_collection.test.js","skipped":false,"dir":"test"},{"name":"does not mutate command options","suites":["Sessions - unit/sessions","Collection"],"updatePoint":{"line":85,"column":39,"index":2271},"line":85,"code":"    it('does not mutate command options', function () {\n      const options = Object.freeze({});\n      test.server.setMessageHandler(request => {\n        const doc = request.document;\n\n        if (isHello(doc)) {\n          request.reply(mock.HELLO);\n        } else if (doc.count || doc.aggregate || doc.endSessions) {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      const client = new MongoClient(`mongodb://${test.server.uri()}/test`);\n      return client.connect().then(client => {\n        const coll = client.db('foo').collection('bar');\n        return coll.countDocuments({}, options).then(() => {\n          expect(options).to.deep.equal({});\n          return client.close();\n        });\n      });\n    });","file":"unit/assorted/sessions_collection.test.js","skipped":false,"dir":"test"},{"name":"should compress messages sent with snappy ","suites":["Compression","Snappy"],"updatePoint":{"line":45,"column":66,"index":950},"line":45,"code":"    it(`should compress messages sent with snappy ${snappyVersion}`, async function () {\n      // the timeout is being set because the test should not take any longer than 5 seconds,\n      // and that if it doesn't complete, it will hang due to the callback never being called\n      this.timeout(5000);\n      server.setMessageHandler(request => {\n        const doc = request.document;\n\n        if (isHello(doc)) {\n          return request.reply({ ...mock.HELLO,\n            compression: ['snappy']\n          });\n        }\n\n        if (doc.insert === 'snappy') {\n          return request.reply({\n            ok: 1\n          });\n        }\n      }); // The mock server uses snappy to decode messages so\n      // if this passes we implicitly test snappy is working\n      // TODO(NODE-3560): Add more comprehensive round trip testing\n\n      await client.connect();\n      await client.db().collection('snappy').insertOne({\n        a: 1\n      });\n    });","file":"unit/assorted/snappy.test.js","skipped":false,"dir":"test"},{"name":"should define a version number on the optional import","suites":["Compression","Snappy"],"updatePoint":{"line":72,"column":61,"index":1893},"line":72,"code":"    it('should define a version number on the optional import', function () {\n      const {\n        Snappy,\n        PKG_VERSION\n      } = require('../../../src/deps');\n\n      const [major, minor, patch] = snappyVersion.split('.').map(n => +n);\n      expect(Snappy).to.have.property(PKG_VERSION).that.is.an('object');\n      expect(Snappy[PKG_VERSION]).to.have.property('major', major);\n      expect(Snappy[PKG_VERSION]).to.have.property('minor', minor);\n      expect(Snappy[PKG_VERSION]).to.have.property('patch', patch);\n    });","file":"unit/assorted/snappy.test.js","skipped":false,"dir":"test"},{"name":"","suites":["URI option spec tests"],"updatePoint":{"line":30,"column":31,"index":2323},"line":30,"code":"        it(`${test.description}`, function () {\n          if (skipTests.includes(test.description)) {\n            return this.skip();\n          }\n\n          executeUriValidationTest(test, testsThatDoNotThrowOnWarn.some(t => t === test.description));\n        });","file":"unit/assorted/uri_options.spec.test.ts","skipped":false,"dir":"test"},{"name":"should raise a compatibility error","suites":["Wire Protocol Version","minimum is greater than 14"],"updatePoint":{"line":46,"column":42,"index":1165},"line":46,"code":"    it('should raise a compatibility error', async function () {\n      setWireProtocolMessageHandler(Number.MAX_SAFE_INTEGER - 1, Number.MAX_SAFE_INTEGER);\n      /** @type {MongoClient} */\n\n      client = new MongoClient(`mongodb://${server.uri()}/wireVersionTest?serverSelectionTimeoutMS=200`);\n\n      try {\n        await client.connect();\n        expect.fail('should fail to select server!');\n      } catch (error) {\n        expect(error).to.be.instanceOf(MongoServerSelectionError);\n        expect(error).to.have.property('message').that.includes(minCompatErrMsg);\n      }\n    });","file":"unit/assorted/wire_version.test.js","skipped":false,"dir":"test"},{"name":"should raise a compatibility error","suites":["Wire Protocol Version","maximum is less than 2"],"updatePoint":{"line":62,"column":42,"index":1800},"line":62,"code":"    it('should raise a compatibility error', async function () {\n      setWireProtocolMessageHandler(1, 1);\n      /** @type {MongoClient} */\n\n      client = new MongoClient(`mongodb://${server.uri()}/wireVersionTest?serverSelectionTimeoutMS=200`);\n\n      try {\n        await client.connect();\n        expect.fail('should fail to select server!');\n      } catch (error) {\n        expect(error).to.be.instanceOf(MongoServerSelectionError);\n        expect(error).to.have.property('message').that.includes(maxCompatErrMsg);\n      }\n    });","file":"unit/assorted/wire_version.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to aggregate command","suites":["Command Write Concern"],"updatePoint":{"line":151,"column":65,"index":3804},"line":151,"code":"  it('successfully pass through writeConcern to aggregate command', () => writeConcernTest('aggregate', (db, writeConcernTestOptions) => db.collection('test').aggregate([{\n    $match: {}\n  }, {\n    $out: 'readConcernCollectionAggregate1Output'\n  }], writeConcernTestOptions).toArray()));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to create command","suites":["Command Write Concern"],"updatePoint":{"line":156,"column":62,"index":4089},"line":156,"code":"  it('successfully pass through writeConcern to create command', () => writeConcernTest('create', (db, writeConcernTestOptions) => db.createCollection('test_collection_methods', writeConcernTestOptions)));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to createIndexes command","suites":["Command Write Concern"],"updatePoint":{"line":157,"column":69,"index":4302},"line":157,"code":"  it('successfully pass through writeConcern to createIndexes command', () => writeConcernTest('createIndexes', (db, writeConcernTestOptions) => db.collection('indexOptionDefault').createIndex({\n    a: 1\n  }, Object.assign({\n    indexOptionDefaults: true\n  }, writeConcernTestOptions))));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to drop command","suites":["Command Write Concern"],"updatePoint":{"line":162,"column":60,"index":4582},"line":162,"code":"  it('successfully pass through writeConcern to drop command', () => writeConcernTest('drop', (db, writeConcernTestOptions) => db.collection('indexOptionDefault').drop(writeConcernTestOptions)));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to dropDatabase command","suites":["Command Write Concern"],"updatePoint":{"line":163,"column":68,"index":4786},"line":163,"code":"  it('successfully pass through writeConcern to dropDatabase command', () => writeConcernTest('dropDatabase', (db, writeConcernTestOptions) => db.dropDatabase(writeConcernTestOptions)));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to dropIndexes command","suites":["Command Write Concern"],"updatePoint":{"line":164,"column":67,"index":4972},"line":164,"code":"  it('successfully pass through writeConcern to dropIndexes command', () => writeConcernTest('dropIndexes', (db, writeConcernTestOptions) => db.collection('test').dropIndexes(writeConcernTestOptions)));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to mapReduce command","suites":["Command Write Concern"],"updatePoint":{"line":165,"column":65,"index":5173},"line":165,"code":"  it('successfully pass through writeConcern to mapReduce command', () => writeConcernTest('mapReduce', function (db, writeConcernTestOptions) {\n    const map = new Code('function() { emit(this.user_id, 1); }');\n    const reduce = new Code('function(k,vals) { return 1; }');\n    return db.collection('test').mapReduce(map, reduce, Object.assign({\n      out: {\n        replace: 'tempCollection'\n      }\n    }, writeConcernTestOptions));\n  }));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to createUser command","suites":["Command Write Concern"],"updatePoint":{"line":174,"column":66,"index":5617},"line":174,"code":"  it('successfully pass through writeConcern to createUser command', () => writeConcernTest('createUser', (db, writeConcernTestOptions) => db.admin().addUser('kay:kay', 'abc123', writeConcernTestOptions)));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"successfully pass through writeConcern to dropUser command","suites":["Command Write Concern"],"updatePoint":{"line":175,"column":64,"index":5822},"line":175,"code":"  it('successfully pass through writeConcern to dropUser command', () => writeConcernTest('dropUser', (db, writeConcernTestOptions) => db.admin().removeUser('kay:kay', writeConcernTestOptions)));","file":"unit/assorted/write_concern.test.js","skipped":false,"dir":"test"},{"name":"should correctly round trip ","suites":["When importing BSON"],"updatePoint":{"line":31,"column":45,"index":816},"line":31,"code":"      it(`should correctly round trip ${type}`, function () {\n        const typeCtor = BSON[type];\n        expect(typeCtor).to.be.a('function');\n        const doc = {\n          key: new typeCtor(ctorArg)\n        };\n        const outputDoc = BSON.deserialize(BSON.serialize(doc), options);\n        expect(outputDoc).to.have.property('key').that.is.instanceOf(typeCtor);\n        expect(outputDoc).to.deep.equal(doc);\n      });","file":"unit/bson.test.js","skipped":false,"dir":"test"},{"name":"should correctly round trip Map","suites":["When importing BSON"],"updatePoint":{"line":43,"column":39,"index":1242},"line":43,"code":"    it('should correctly round trip Map', function () {\n      expect(BSON.Map).to.be.a('function');\n      const doc = {\n        key: new BSON.Map([['2', 2]])\n      };\n      const outputDoc = BSON.deserialize(BSON.serialize(doc));\n      expect(outputDoc).to.have.nested.property('key.2', 2);\n    });","file":"unit/bson.test.js","skipped":false,"dir":"test"},{"name":"should be imported if it exists","suites":["When importing BSON","bson-ext"],"updatePoint":{"line":59,"column":39,"index":1680},"line":59,"code":"    it('should be imported if it exists', function () {\n      expect(BSON.deserialize.toString()).to.include('[native code]');\n      expect(BSON.serialize.toString()).to.include('[native code]');\n      expect(BSON.calculateObjectSize.toString()).to.include('[native code]');\n    });","file":"unit/bson.test.js","skipped":false,"dir":"test"},{"name":"should be imported by default","suites":["When importing BSON","js-bson"],"updatePoint":{"line":72,"column":37,"index":2116},"line":72,"code":"    it('should be imported by default', function () {\n      expect(BSON.deserialize.toString()).to.not.include('[native code]');\n      expect(BSON.serialize.toString()).to.not.include('[native code]');\n      expect(BSON.calculateObjectSize.toString()).to.not.include('[native code]');\n    });","file":"unit/bson.test.js","skipped":false,"dir":"test"},{"name":"should include ObjectId","suites":["MongoDB export"],"updatePoint":{"line":83,"column":29,"index":2504},"line":83,"code":"  it('should include ObjectId', () => expect(mongodb).to.have.property('ObjectId').that.is.a('function'));","file":"unit/bson.test.js","skipped":false,"dir":"test"},{"name":"should include ObjectID","suites":["MongoDB export"],"updatePoint":{"line":84,"column":29,"index":2611},"line":84,"code":"  it('should include ObjectID', () => expect(mongodb).to.have.property('ObjectID').that.is.a('function'));","file":"unit/bson.test.js","skipped":false,"dir":"test"},{"name":"should have ObjectID and ObjectId equal each other","suites":["MongoDB export"],"updatePoint":{"line":85,"column":56,"index":2745},"line":85,"code":"  it('should have ObjectID and ObjectId equal each other', () => expect(mongodb.ObjectId).to.equal(mongodb.ObjectID));","file":"unit/bson.test.js","skipped":false,"dir":"test"},{"name":"replaces the opTime with the properly formatted object","suites":["bulk/common","#mergeBatchResults","when lastOp is an object","when the opTime is a Timestamp"],"updatePoint":{"line":62,"column":66,"index":1520},"line":62,"code":"        it('replaces the opTime with the properly formatted object', function () {\n          mergeBatchResults(batch, bulkResult, null, result);\n          expect(bulkResult.opTime).to.deep.equal({\n            ts: opTime,\n            t: Long.ZERO\n          });\n        });","file":"unit/bulk/common.test.js","skipped":false,"dir":"test"},{"name":"replaces the opTime with the new opTime","suites":["bulk/common","#mergeBatchResults","when lastOp is an object","when the opTime is an object","when the ts is greater"],"updatePoint":{"line":84,"column":53,"index":2220},"line":84,"code":"          it('replaces the opTime with the new opTime', function () {\n            mergeBatchResults(batch, bulkResult, null, result);\n            expect(bulkResult.opTime).to.deep.equal(opTime);\n          });","file":"unit/bulk/common.test.js","skipped":false,"dir":"test"},{"name":"replaces the opTime with the new opTime","suites":["bulk/common","#mergeBatchResults","when lastOp is an object","when the opTime is an object","when the ts is equal","when the t is greater"],"updatePoint":{"line":103,"column":55,"index":2893},"line":103,"code":"            it('replaces the opTime with the new opTime', function () {\n              mergeBatchResults(batch, bulkResult, null, result);\n              expect(bulkResult.opTime).to.deep.equal(opTime);\n            });","file":"unit/bulk/common.test.js","skipped":false,"dir":"test"},{"name":"does not replace the opTime with the new opTime","suites":["bulk/common","#mergeBatchResults","when lastOp is an object","when the opTime is an object","when the ts is equal","when the t is equal"],"updatePoint":{"line":121,"column":63,"index":3526},"line":121,"code":"            it('does not replace the opTime with the new opTime', function () {\n              mergeBatchResults(batch, bulkResult, null, result);\n              expect(bulkResult.opTime).to.deep.equal(lastOp);\n            });","file":"unit/bulk/common.test.js","skipped":false,"dir":"test"},{"name":"does not replace the opTime with the new opTime","suites":["bulk/common","#mergeBatchResults","when lastOp is an object","when the opTime is an object","when the ts is equal","when the t is less"],"updatePoint":{"line":139,"column":63,"index":4157},"line":139,"code":"            it('does not replace the opTime with the new opTime', function () {\n              mergeBatchResults(batch, bulkResult, null, result);\n              expect(bulkResult.opTime).to.deep.equal(lastOp);\n            });","file":"unit/bulk/common.test.js","skipped":false,"dir":"test"},{"name":"does not replace the opTime with the new opTime","suites":["bulk/common","#mergeBatchResults","when lastOp is an object","when the opTime is an object","when the ts is less"],"updatePoint":{"line":158,"column":61,"index":4774},"line":158,"code":"          it('does not replace the opTime with the new opTime', function () {\n            mergeBatchResults(batch, bulkResult, null, result);\n            expect(bulkResult.opTime).to.deep.equal(lastOp);\n          });","file":"unit/bulk/common.test.js","skipped":false,"dir":"test"},{"name":"performs no dns lookups","suites":["GSSAPI",".performGSSAPICanonicalizeHostName","when the mode is "],"updatePoint":{"line":30,"column":35,"index":765},"line":30,"code":"        it('performs no dns lookups', done => {\n          performGSSAPICanonicalizeHostName(hostName, {\n            CANONICALIZE_HOST_NAME: mode\n          }, (error, host) => {\n            if (error) return done(error);\n            expect(host).to.equal(hostName);\n            expect(dns.lookup).to.not.be.called;\n            expect(dns.resolvePtr).to.not.be.called;\n            expect(dns.resolveCname).to.not.be.called;\n            done();\n          });\n        });","file":"unit/cmap/auth/gssapi.test.js","skipped":false,"dir":"test"},{"name":"performs a cname lookup","suites":["GSSAPI",".performGSSAPICanonicalizeHostName","when the mode is forward"],"updatePoint":{"line":56,"column":33,"index":1566},"line":56,"code":"      it('performs a cname lookup', done => {\n        performGSSAPICanonicalizeHostName(hostName, {\n          CANONICALIZE_HOST_NAME: GSSAPICanonicalizationValue.forward\n        }, (error, host) => {\n          if (error) return done(error);\n          expect(host).to.equal(resolved);\n          expect(dns.lookup).to.not.be.called;\n          expect(dns.resolvePtr).to.not.be.called;\n          expect(dns.resolveCname).to.be.calledOnceWith(hostName);\n          done();\n        });\n      });","file":"unit/cmap/auth/gssapi.test.js","skipped":false,"dir":"test"},{"name":"uses the reverse lookup host","suites":["GSSAPI",".performGSSAPICanonicalizeHostName","when the mode is ","when the forward lookup succeeds","when the reverse lookup succeeds","when there is 1 result"],"updatePoint":{"line":93,"column":46,"index":2989},"line":93,"code":"              it('uses the reverse lookup host', done => {\n                performGSSAPICanonicalizeHostName(hostName, {\n                  CANONICALIZE_HOST_NAME: mode\n                }, (error, host) => {\n                  if (error) return done(error);\n                  expect(host).to.equal(resolved);\n                  expect(dns.lookup).to.be.calledOnceWith(hostName);\n                  expect(dns.resolvePtr).to.be.calledOnceWith(lookedUp);\n                  expect(dns.resolveCname).to.not.be.called;\n                  done();\n                });\n              });","file":"unit/cmap/auth/gssapi.test.js","skipped":false,"dir":"test"},{"name":"uses the first found reverse lookup host","suites":["GSSAPI",".performGSSAPICanonicalizeHostName","when the mode is ","when the forward lookup succeeds","when the reverse lookup succeeds","when there is more than 1 result"],"updatePoint":{"line":119,"column":58,"index":4102},"line":119,"code":"              it('uses the first found reverse lookup host', done => {\n                performGSSAPICanonicalizeHostName(hostName, {\n                  CANONICALIZE_HOST_NAME: mode\n                }, (error, host) => {\n                  if (error) return done(error);\n                  expect(host).to.equal(resolved);\n                  expect(dns.lookup).to.be.calledOnceWith(hostName);\n                  expect(dns.resolvePtr).to.be.calledOnceWith(lookedUp);\n                  expect(dns.resolveCname).to.not.be.called;\n                  done();\n                });\n              });","file":"unit/cmap/auth/gssapi.test.js","skipped":false,"dir":"test"},{"name":"falls back to a cname lookup","suites":["GSSAPI",".performGSSAPICanonicalizeHostName","when the mode is ","when the forward lookup succeeds","when the reverse lookup fails"],"updatePoint":{"line":152,"column":44,"index":5403},"line":152,"code":"            it('falls back to a cname lookup', done => {\n              performGSSAPICanonicalizeHostName(hostName, {\n                CANONICALIZE_HOST_NAME: mode\n              }, (error, host) => {\n                if (error) return done(error);\n                expect(host).to.equal(cname);\n                expect(dns.lookup).to.be.calledOnceWith(hostName);\n                expect(dns.resolvePtr).to.be.calledOnceWith(lookedUp);\n                expect(dns.resolveCname).to.be.calledWith(hostName);\n                done();\n              });\n            });","file":"unit/cmap/auth/gssapi.test.js","skipped":false,"dir":"test"},{"name":"uses the provided host","suites":["GSSAPI",".performGSSAPICanonicalizeHostName","when the mode is ","when the forward lookup succeeds","when the reverse lookup is empty"],"updatePoint":{"line":176,"column":38,"index":6392},"line":176,"code":"            it('uses the provided host', done => {\n              performGSSAPICanonicalizeHostName(hostName, {\n                CANONICALIZE_HOST_NAME: mode\n              }, (error, host) => {\n                if (error) return done(error);\n                expect(host).to.equal(hostName);\n                expect(dns.lookup).to.be.calledOnceWith(hostName);\n                expect(dns.resolvePtr).to.be.calledOnceWith(lookedUp);\n                expect(dns.resolveCname).to.not.be.called;\n                done();\n              });\n            });","file":"unit/cmap/auth/gssapi.test.js","skipped":false,"dir":"test"},{"name":"fails with the error","suites":["GSSAPI",".performGSSAPICanonicalizeHostName","when the mode is ","when the forward lookup fails"],"updatePoint":{"line":199,"column":34,"index":7271},"line":199,"code":"          it('fails with the error', done => {\n            performGSSAPICanonicalizeHostName(hostName, {\n              CANONICALIZE_HOST_NAME: mode\n            }, error => {\n              expect(error.message).to.equal('failed');\n              expect(dns.lookup).to.be.calledOnceWith(hostName);\n              expect(dns.resolvePtr).to.not.be.called;\n              expect(dns.resolveCname).to.not.be.called;\n              done();\n            });\n          });","file":"unit/cmap/auth/gssapi.test.js","skipped":false,"dir":"test"},{"name":"falls back to the provided host name","suites":["GSSAPI",".resolveCname","when the cname call errors"],"updatePoint":{"line":226,"column":46,"index":8133},"line":226,"code":"      it('falls back to the provided host name', done => {\n        resolveCname(hostName, (error, host) => {\n          if (error) return done(error);\n          expect(host).to.equal(hostName);\n          expect(dns.resolveCname).to.be.calledOnceWith(hostName);\n          done();\n        });\n      });","file":"unit/cmap/auth/gssapi.test.js","skipped":false,"dir":"test"},{"name":"uses the result","suites":["GSSAPI",".resolveCname","when the cname call returns results","when there is one result"],"updatePoint":{"line":248,"column":27,"index":8857},"line":248,"code":"        it('uses the result', done => {\n          resolveCname(hostName, (error, host) => {\n            if (error) return done(error);\n            expect(host).to.equal(resolved);\n            expect(dns.resolveCname).to.be.calledOnceWith(hostName);\n            done();\n          });\n        });","file":"unit/cmap/auth/gssapi.test.js","skipped":false,"dir":"test"},{"name":"uses the first result","suites":["GSSAPI",".resolveCname","when the cname call returns results","when there is more than one result"],"updatePoint":{"line":269,"column":33,"index":9564},"line":269,"code":"        it('uses the first result', done => {\n          resolveCname(hostName, (error, host) => {\n            if (error) return done(error);\n            expect(host).to.equal(resolved);\n            expect(dns.resolveCname).to.be.calledOnceWith(hostName);\n            done();\n          });\n        });","file":"unit/cmap/auth/gssapi.test.js","skipped":false,"dir":"test"},{"name":"falls back to using the provided host","suites":["GSSAPI",".resolveCname","when the cname call returns no results"],"updatePoint":{"line":290,"column":47,"index":10224},"line":290,"code":"      it('falls back to using the provided host', done => {\n        resolveCname(hostName, (error, host) => {\n          if (error) return done(error);\n          expect(host).to.equal(hostName);\n          expect(dns.resolveCname).to.be.calledOnceWith(hostName);\n          done();\n        });\n      });","file":"unit/cmap/auth/gssapi.test.js","skipped":false,"dir":"test"},{"name":"should make a deep copy of object of type: ","suites":["Command Monitoring Events - unit/cmap"],"updatePoint":{"line":66,"column":78,"index":1249},"line":66,"code":"    it(`should make a deep copy of object of type: ${command.constructor.name}`, () => {\n      const ev = new CommandStartedEvent({\n        id: 'someId',\n        address: 'someHost'\n      }, command);\n\n      if (command instanceof Query) {\n        if (command.ns === 'admin.$cmd') {\n          expect(ev.command !== command.query.$query).to.equal(true);\n\n          for (const k in command.query.$query) {\n            expect(ev.command[k]).to.deep.equal(command.query.$query[k]);\n          }\n        } else {\n          expect(ev.command.filter !== command.query.$query).to.equal(true);\n\n          for (const k in command.query.$query) {\n            expect(ev.command.filter[k]).to.deep.equal(command.query.$query[k]);\n          }\n        }\n      } else if (command instanceof Msg) {\n        expect(ev.command !== command.command).to.equal(true);\n        expect(ev.command).to.deep.equal(command.command);\n      } else if (command instanceof GetMore) {\n        // NOTE: BSON Longs pass strict equality when their internal values are equal\n        // i.e.\n        // let l1 = Long(10);\n        // let l2 = Long(10);\n        // l1 === l2 // returns true\n        // expect(ev.command.getMore !== command.cursorId).to.equal(true);\n        expect(ev.command.getMore).to.deep.equal(command.cursorId);\n        ev.command.getMore = Long.fromNumber(50128);\n        expect(command.cursorId).to.not.deep.equal(ev.command.getMore);\n      } else if (command instanceof KillCursor) {\n        expect(ev.command.cursors !== command.cursorIds).to.equal(true);\n        expect(ev.command.cursors).to.deep.equal(command.cursorIds);\n      } else if (typeof command === 'object') {\n        if (command.ns === 'admin.$cmd') {\n          expect(ev.command !== command.query.$query).to.equal(true);\n\n          for (const k in command.query.$query) {\n            expect(ev.command[k]).to.deep.equal(command.query.$query[k]);\n          }\n        }\n      }\n    });","file":"unit/cmap/command_monitoring_events.test.js","skipped":false,"dir":"test"},{"name":"should wrap a basic query option","suites":["Command Monitoring Events - unit/cmap","CommandStartedEvent"],"updatePoint":{"line":119,"column":40,"index":3278},"line":119,"code":"    it('should wrap a basic query option', function () {\n      const db = 'test1';\n      const coll = 'testingQuery';\n      const query = new Query(`${db}.${coll}`, {\n        testCmd: 1,\n        fizz: 'buzz',\n        star: 'trek'\n      }, {});\n      const startEvent = new CommandStartedEvent(conn, query);\n      expect(startEvent).to.have.property('commandName', 'testCmd');\n      expect(startEvent).to.have.property('databaseName', db);\n      expect(startEvent).to.have.property('requestId', query.requestId);\n      expect(startEvent).to.have.property('connectionId').that.is.a('string');\n      expect(startEvent).to.have.property('command').that.deep.equals(query.query);\n    });","file":"unit/cmap/command_monitoring_events.test.js","skipped":false,"dir":"test"},{"name":"should wrap a basic killCursor command","suites":["Command Monitoring Events - unit/cmap","CommandStartedEvent"],"updatePoint":{"line":134,"column":46,"index":3967},"line":134,"code":"    it('should wrap a basic killCursor command', function () {\n      const db = 'test2';\n      const coll = 'testingKillCursors';\n      const killCursor = new KillCursor(`${db}.${coll}`, [12, 42, 57]);\n      const startEvent = new CommandStartedEvent(conn, killCursor);\n      expect(startEvent).to.have.property('commandName', 'killCursors');\n      expect(startEvent).to.have.property('databaseName', db);\n      expect(startEvent).to.have.property('requestId', killCursor.requestId);\n      expect(startEvent).to.have.property('connectionId').that.is.a('string');\n      expect(startEvent).to.have.property('command').that.deep.equals({\n        killCursors: coll,\n        cursors: killCursor.cursorIds\n      });\n    });","file":"unit/cmap/command_monitoring_events.test.js","skipped":false,"dir":"test"},{"name":"should wrap a basic GetMore command","suites":["Command Monitoring Events - unit/cmap","CommandStartedEvent"],"updatePoint":{"line":148,"column":43,"index":4682},"line":148,"code":"    it('should wrap a basic GetMore command', function () {\n      const db = 'test3';\n      const coll = 'testingGetMore';\n      const numberToReturn = 321;\n      const getMore = new GetMore(`${db}.${coll}`, 5525, {\n        numberToReturn\n      });\n      const startEvent = new CommandStartedEvent(conn, getMore);\n      expect(startEvent).to.have.property('commandName', 'getMore');\n      expect(startEvent).to.have.property('databaseName', db);\n      expect(startEvent).to.have.property('requestId', getMore.requestId);\n      expect(startEvent).to.have.property('connectionId').that.is.a('string');\n      expect(startEvent).to.have.property('command').that.deep.equals({\n        getMore: getMore.cursorId,\n        collection: coll,\n        batchSize: numberToReturn\n      });\n    });","file":"unit/cmap/command_monitoring_events.test.js","skipped":false,"dir":"test"},{"name":"should upconvert a Query wrapping a command into the corresponding command","suites":["Command Monitoring Events - unit/cmap","CommandStartedEvent"],"updatePoint":{"line":166,"column":82,"index":5506},"line":166,"code":"    it('should upconvert a Query wrapping a command into the corresponding command', function () {\n      const db = 'admin';\n      const coll = '$cmd';\n      const query = new Query(`${db}.${coll}`, {\n        $query: {\n          testCmd: 1,\n          fizz: 'buzz',\n          star: 'trek',\n          batchSize: 0,\n          skip: 0\n        }\n      }, {});\n      const startEvent = new CommandStartedEvent(conn, query);\n      expect(startEvent).to.have.property('commandName', 'testCmd');\n      expect(startEvent).to.have.property('databaseName', db);\n      expect(startEvent).to.have.property('requestId', query.requestId);\n      expect(startEvent).to.have.property('connectionId').that.is.a('string');\n      expect(startEvent).to.have.property('command').that.deep.equals(query.query.$query);\n    });","file":"unit/cmap/command_monitoring_events.test.js","skipped":false,"dir":"test"},{"name":"should upconvert a Query wrapping a query into a find command","suites":["Command Monitoring Events - unit/cmap","CommandStartedEvent"],"updatePoint":{"line":185,"column":69,"index":6294},"line":185,"code":"    it('should upconvert a Query wrapping a query into a find command', function () {\n      const db = 'test5';\n      const coll = 'testingFindCommand';\n      const query = new Query(`${db}.${coll}`, {\n        $query: {\n          testCmd: 1,\n          fizz: 'buzz',\n          star: 'trek'\n        }\n      }, {});\n      const startEvent = new CommandStartedEvent(conn, query);\n      expect(startEvent).to.have.property('commandName', 'find');\n      expect(startEvent).to.have.property('databaseName', db);\n      expect(startEvent).to.have.property('requestId', query.requestId);\n      expect(startEvent).to.have.property('connectionId').that.is.a('string');\n      expect(startEvent).to.have.property('command').that.deep.equals({\n        find: coll,\n        filter: query.query.$query,\n        batchSize: 0,\n        skip: 0\n      });\n    });","file":"unit/cmap/command_monitoring_events.test.js","skipped":false,"dir":"test"},{"name":"throws an exception","suites":["commands","Response","#parse","when the message body is invalid","when the buffer is empty"],"updatePoint":{"line":22,"column":33,"index":588},"line":22,"code":"          it('throws an exception', function () {\n            const response = new Response(message, header, body);\n            expect(() => response.parse()).to.throw(RangeError, /outside buffer bounds/);\n          });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"throws an exception","suites":["commands","Response","#parse","when the message body is invalid","when numReturned is invalid"],"updatePoint":{"line":37,"column":33,"index":1143},"line":37,"code":"          it('throws an exception', function () {\n            const response = new Response(message, header, body);\n            expect(() => response.parse()).to.throw(RangeError, /Invalid array length/);\n          });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not throw an exception","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":54,"column":39,"index":1710},"line":54,"code":"        it('does not throw an exception', function () {\n          let error;\n\n          try {\n            new Response(message, header, body);\n          } catch (err) {\n            error = err;\n          }\n\n          expect(error).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"initializes the documents to an empty array","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":65,"column":55,"index":1986},"line":65,"code":"        it('initializes the documents to an empty array', function () {\n          const response = new Response(message, header, body);\n          expect(response.documents).to.be.empty;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set the responseFlags","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":69,"column":42,"index":2171},"line":69,"code":"        it('does not set the responseFlags', function () {\n          const response = new Response(message, header, body);\n          expect(response.responseFlags).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set the cursorNotFound flag","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":73,"column":48,"index":2370},"line":73,"code":"        it('does not set the cursorNotFound flag', function () {\n          const response = new Response(message, header, body);\n          expect(response.cursorNotFound).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set the cursorId","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":77,"column":37,"index":2559},"line":77,"code":"        it('does not set the cursorId', function () {\n          const response = new Response(message, header, body);\n          expect(response.cursorId).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set startingFrom","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":81,"column":37,"index":2742},"line":81,"code":"        it('does not set startingFrom', function () {\n          const response = new Response(message, header, body);\n          expect(response.startingFrom).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set numberReturned","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":85,"column":39,"index":2931},"line":85,"code":"        it('does not set numberReturned', function () {\n          const response = new Response(message, header, body);\n          expect(response.numberReturned).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set queryFailure","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":89,"column":37,"index":3120},"line":89,"code":"        it('does not set queryFailure', function () {\n          const response = new Response(message, header, body);\n          expect(response.queryFailure).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set shardConfigStale","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":93,"column":41,"index":3311},"line":93,"code":"        it('does not set shardConfigStale', function () {\n          const response = new Response(message, header, body);\n          expect(response.shardConfigStale).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"does not set awaitCapable","suites":["commands","Response","#constructor","when the message body is invalid"],"updatePoint":{"line":97,"column":37,"index":3502},"line":97,"code":"        it('does not set awaitCapable', function () {\n          const response = new Response(message, header, body);\n          expect(response.awaitCapable).to.be.undefined;\n        });","file":"unit/cmap/commands.test.js","skipped":false,"dir":"test"},{"name":"should auth against a non-arbiter","suites":["Connect Tests"],"updatePoint":{"line":53,"column":39,"index":1076},"line":53,"code":"  it('should auth against a non-arbiter', function (done) {\n    const whatHappened = {};\n    test.server.setMessageHandler(request => {\n      const doc = request.document;\n      const $clusterTime = genClusterTime(Date.now());\n\n      if (isHello(doc)) {\n        whatHappened[LEGACY_HELLO_COMMAND] = true;\n        request.reply(Object.assign({}, mock.HELLO, {\n          $clusterTime\n        }));\n      } else if (doc.saslStart) {\n        whatHappened.saslStart = true;\n        request.reply({\n          ok: 1\n        });\n      }\n    });\n    connect(test.connectOptions, err => {\n      try {\n        expect(whatHappened).to.have.property(LEGACY_HELLO_COMMAND, true);\n        expect(whatHappened).to.have.property('saslStart', true);\n      } catch (_err) {\n        err = _err;\n      }\n\n      done(err);\n    });\n  });","file":"unit/cmap/connect.test.js","skipped":false,"dir":"test"},{"name":"should not auth against an arbiter","suites":["Connect Tests"],"updatePoint":{"line":82,"column":40,"index":1891},"line":82,"code":"  it('should not auth against an arbiter', function (done) {\n    const whatHappened = {};\n    test.server.setMessageHandler(request => {\n      const doc = request.document;\n      const $clusterTime = genClusterTime(Date.now());\n\n      if (isHello(doc)) {\n        whatHappened[LEGACY_HELLO_COMMAND] = true;\n        request.reply(Object.assign({}, mock.HELLO, {\n          $clusterTime,\n          arbiterOnly: true\n        }));\n      } else if (doc.saslStart) {\n        whatHappened.saslStart = true;\n        request.reply({\n          ok: 0\n        });\n      }\n    });\n    connect(test.connectOptions, err => {\n      try {\n        expect(whatHappened).to.have.property(LEGACY_HELLO_COMMAND, true);\n        expect(whatHappened).to.not.have.property('saslStart');\n      } catch (_err) {\n        err = _err;\n      }\n\n      done(err);\n    });\n  });","file":"unit/cmap/connect.test.js","skipped":false,"dir":"test"},{"name":"should emit `MongoNetworkError` for network errors","suites":["Connect Tests"],"updatePoint":{"line":112,"column":56,"index":2749},"line":112,"code":"  it('should emit `MongoNetworkError` for network errors', function (done) {\n    connect({\n      hostAddress: new HostAddress('non-existent:27018')\n    }, err => {\n      expect(err).to.be.instanceOf(MongoNetworkError);\n      done();\n    });\n  });","file":"unit/cmap/connect.test.js","skipped":false,"dir":"test"},{"name":"should allow a cancellaton token","suites":["Connect Tests"],"line":120,"code":"  it.skip('should allow a cancellaton token', function (done) {","file":"unit/cmap/connect.test.js","skipped":true,"dir":"test"},{"name":"should destroy connections which have been closed","suites":["Connection Pool"],"updatePoint":{"line":34,"column":55,"index":700},"line":34,"code":"  it('should destroy connections which have been closed', function (done) {\n    server.setMessageHandler(request => {\n      const doc = request.document;\n\n      if (isHello(doc)) {\n        request.reply(mock.HELLO);\n      } else {\n        // destroy on any other command\n        request.connection.destroy();\n      }\n    });\n    const pool = new ConnectionPool({\n      maxPoolSize: 1,\n      hostAddress: server.hostAddress()\n    });\n    const events = [];\n    pool.on('connectionClosed', event => events.push(event));\n    pool.checkOut((err, conn) => {\n      expect(err).to.not.exist;\n      conn.command(ns('admin.$cmd'), {\n        ping: 1\n      }, undefined, (err, result) => {\n        expect(err).to.exist;\n        expect(result).to.not.exist;\n        pool.checkIn(conn);\n        expect(events).to.have.length(1);\n        const closeEvent = events[0];\n        expect(closeEvent).have.property('reason').equal('error');\n      });\n    });\n    pool.withConnection(undefined, (err, conn, cb) => {\n      expect(err).to.not.exist;\n      cb();\n    }, () => {\n      pool.close(done);\n    });\n  });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"should propagate socket timeouts to connections","suites":["Connection Pool"],"updatePoint":{"line":71,"column":53,"index":1790},"line":71,"code":"  it('should propagate socket timeouts to connections', function (done) {\n    server.setMessageHandler(request => {\n      const doc = request.document;\n\n      if (isHello(doc)) {\n        request.reply(mock.HELLO);\n      } else {// blackhole other requests\n      }\n    });\n    const pool = new ConnectionPool({\n      maxPoolSize: 1,\n      socketTimeoutMS: 200,\n      hostAddress: server.hostAddress()\n    });\n    pool.withConnection((err, conn, cb) => {\n      expect(err).to.not.exist;\n      conn.command(ns('admin.$cmd'), {\n        ping: 1\n      }, undefined, (err, result) => {\n        expect(err).to.exist;\n        expect(result).to.not.exist;\n        expect(err).to.match(/timed out/);\n        cb();\n      });\n    }, () => pool.close(done));\n  });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"should clear timed out wait queue members if no connections are available","suites":["Connection Pool"],"updatePoint":{"line":97,"column":79,"index":2567},"line":97,"code":"  it('should clear timed out wait queue members if no connections are available', function (done) {\n    server.setMessageHandler(request => {\n      const doc = request.document;\n\n      if (isHello(doc)) {\n        request.reply(mock.HELLO);\n      }\n    });\n    const pool = new ConnectionPool({\n      maxPoolSize: 1,\n      waitQueueTimeoutMS: 200,\n      hostAddress: server.hostAddress()\n    });\n    pool.checkOut((err, conn) => {\n      expect(err).to.not.exist;\n      expect(conn).to.exist;\n      pool.checkOut(err => {\n        expect(err).to.exist.and.be.instanceOf(WaitQueueTimeoutError); // We can only process the wait queue with `checkIn` and `checkOut`, so we\n        // force the pool here to think there are no available connections, even though\n        // we are checking the connection back in. This simulates a slow leak where\n        // incoming requests outpace the ability of the queue to fully process cancelled\n        // wait queue members\n\n        sinon.stub(pool, 'availableConnectionCount').get(() => 0);\n        pool.checkIn(conn);\n        setImmediate(() => expect(pool).property('waitQueueSize').to.equal(0));\n        done();\n      });\n    });\n  });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"should manage a connection for a successful operation","suites":["Connection Pool","withConnection"],"updatePoint":{"line":128,"column":61,"index":3765},"line":128,"code":"    it('should manage a connection for a successful operation', function (done) {\n      server.setMessageHandler(request => {\n        const doc = request.document;\n\n        if (isHello(doc)) {\n          request.reply(mock.HELLO);\n        }\n      });\n      const pool = new ConnectionPool({\n        hostAddress: server.hostAddress()\n      });\n\n      const callback = (err, result) => {\n        expect(err).to.not.exist;\n        expect(result).to.exist;\n        pool.close(done);\n      };\n\n      pool.withConnection((err, conn, cb) => {\n        expect(err).to.not.exist;\n        conn.command(ns('$admin.cmd'), {\n          [LEGACY_HELLO_COMMAND]: 1\n        }, undefined, (cmdErr, hello) => {\n          expect(cmdErr).to.not.exist;\n          cb(undefined, hello);\n        });\n      }, callback);\n    });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"should allow user interaction with an error","suites":["Connection Pool","withConnection"],"updatePoint":{"line":156,"column":51,"index":4555},"line":156,"code":"    it('should allow user interaction with an error', function (done) {\n      server.setMessageHandler(request => {\n        const doc = request.document;\n\n        if (isHello(doc)) {\n          request.connection.destroy();\n        }\n      });\n      const pool = new ConnectionPool({\n        waitQueueTimeoutMS: 200,\n        hostAddress: server.hostAddress()\n      });\n\n      const callback = err => {\n        expect(err).to.exist;\n        expect(err).to.match(/closed/);\n        pool.close(done);\n      };\n\n      pool.withConnection(undefined, (err, conn, cb) => {\n        expect(err).to.exist;\n        expect(err).to.match(/closed/);\n        cb(err);\n      }, callback);\n    });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"should return an error to the original callback","suites":["Connection Pool","withConnection"],"updatePoint":{"line":181,"column":55,"index":5239},"line":181,"code":"    it('should return an error to the original callback', function (done) {\n      server.setMessageHandler(request => {\n        const doc = request.document;\n\n        if (isHello(doc)) {\n          request.reply(mock.HELLO);\n        }\n      });\n      const pool = new ConnectionPool({\n        hostAddress: server.hostAddress()\n      });\n\n      const callback = (err, result) => {\n        expect(err).to.exist;\n        expect(result).to.not.exist;\n        expect(err).to.match(/my great error/);\n        pool.close(done);\n      };\n\n      pool.withConnection(undefined, (err, conn, cb) => {\n        expect(err).to.not.exist;\n        cb(new Error('my great error'));\n      }, callback);\n    });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"should still manage a connection if no callback is provided","suites":["Connection Pool","withConnection"],"updatePoint":{"line":205,"column":67,"index":5942},"line":205,"code":"    it('should still manage a connection if no callback is provided', function (done) {\n      server.setMessageHandler(request => {\n        const doc = request.document;\n\n        if (isHello(doc)) {\n          request.reply(mock.HELLO);\n        }\n      });\n      const pool = new ConnectionPool({\n        maxPoolSize: 1,\n        hostAddress: server.hostAddress()\n      });\n      const events = [];\n      pool.on('connectionCheckedOut', event => events.push(event));\n      pool.on('connectionCheckedIn', event => {\n        events.push(event);\n        expect(events).to.have.length(2);\n        expect(events[0]).to.be.instanceOf(cmapEvents.ConnectionCheckedOutEvent);\n        expect(events[1]).to.be.instanceOf(cmapEvents.ConnectionCheckedInEvent);\n        pool.close(done);\n      });\n      pool.withConnection(undefined, (err, conn, cb) => {\n        expect(err).to.not.exist;\n        cb();\n      });\n    });","file":"unit/cmap/connection_pool.test.js","skipped":false,"dir":"test"},{"name":"should support fire-and-forget messages","suites":["new Connection()"],"updatePoint":{"line":24,"column":45,"index":892},"line":24,"code":"  it('should support fire-and-forget messages', function (done) {\n    server.setMessageHandler(request => {\n      const doc = request.document;\n\n      if (isHello(doc)) {\n        request.reply(mock.HELLO);\n      } // blackhole all other requests\n\n    });\n    const options = { ...connectionOptionsDefaults,\n      connectionType: Connection,\n      hostAddress: server.hostAddress()\n    };\n    connect(options, (err, conn) => {\n      expect(err).to.not.exist;\n      expect(conn).to.exist;\n      conn.command(ns('$admin.cmd'), {\n        ping: 1\n      }, {\n        noResponse: true\n      }, (err, result) => {\n        expect(err).to.not.exist;\n        expect(result).to.not.exist;\n        done();\n      });\n    });\n  });","file":"unit/cmap/connection.test.ts","skipped":false,"dir":"test"},{"name":"should destroy streams which time out","suites":["new Connection()"],"updatePoint":{"line":51,"column":43,"index":1607},"line":51,"code":"  it('should destroy streams which time out', function (done) {\n    server.setMessageHandler(request => {\n      const doc = request.document;\n\n      if (isHello(doc)) {\n        request.reply(mock.HELLO);\n      } // blackhole all other requests\n\n    });\n    const options = { ...connectionOptionsDefaults,\n      connectionType: Connection,\n      hostAddress: server.hostAddress()\n    };\n    connect(options, (err, conn) => {\n      expect(err).to.not.exist;\n      expect(conn).to.exist;\n      conn.command(ns('$admin.cmd'), {\n        ping: 1\n      }, {\n        socketTimeoutMS: 50\n      }, (err, result) => {\n        expect(err).to.be.instanceOf(MongoNetworkTimeoutError);\n        expect(result).to.not.exist;\n        expect(conn).property('stream').property('destroyed', true);\n        done();\n      });\n    });\n  });","file":"unit/cmap/connection.test.ts","skipped":false,"dir":"test"},{"name":"should throw a network error with kBeforeHandshake set to false on timeout after handshake","suites":["new Connection()"],"updatePoint":{"line":79,"column":96,"index":2477},"line":79,"code":"  it('should throw a network error with kBeforeHandshake set to false on timeout after handshake', function (done) {\n    server.setMessageHandler(request => {\n      const doc = request.document;\n\n      if (isHello(doc)) {\n        request.reply(mock.HELLO);\n      } // respond to no other requests to trigger timeout event\n\n    });\n    const options = {\n      hostAddress: server.hostAddress(),\n      ...connectionOptionsDefaults\n    };\n    connect(options, (err, conn) => {\n      expect(err).to.be.a('undefined');\n      expect(conn).to.be.instanceOf(Connection);\n      expect(conn).to.have.property('hello').that.is.a('object');\n      conn.command(ns('$admin.cmd'), {\n        ping: 1\n      }, {\n        socketTimeoutMS: 50\n      }, err => {\n        const beforeHandshakeSymbol = getSymbolFrom(err, 'beforeHandshake', false);\n        expect(beforeHandshakeSymbol).to.be.a('symbol');\n        expect(err).to.have.property(beforeHandshakeSymbol, false);\n        done();\n      });\n    });\n  });","file":"unit/cmap/connection.test.ts","skipped":false,"dir":"test"},{"name":"should throw a network error with kBeforeHandshake set to true on timeout before handshake","suites":["new Connection()"],"updatePoint":{"line":108,"column":96,"index":3467},"line":108,"code":"  it('should throw a network error with kBeforeHandshake set to true on timeout before handshake', function (done) {\n    server.setMessageHandler(() => {// respond to no requests to trigger timeout event\n    });\n    const options = { ...connectionOptionsDefaults,\n      hostAddress: server.hostAddress(),\n      socketTimeoutMS: 50\n    };\n    connect(options, (err, conn) => {\n      expect(conn).to.be.a('undefined');\n      const beforeHandshakeSymbol = getSymbolFrom(err, 'beforeHandshake');\n      expect(err).to.have.property(beforeHandshakeSymbol, true);\n      done();\n    });\n  });","file":"unit/cmap/connection.test.ts","skipped":false,"dir":"test"},{"name":"should delay timeout errors by one tick","suites":["new Connection()","onTimeout()"],"updatePoint":{"line":164,"column":47,"index":5218},"line":164,"code":"    it('should delay timeout errors by one tick', async () => {\n      expect(connection).to.have.property(kDelayedTimeoutId, null);\n      driverSocket.emit('timeout');\n      expect(connection.onTimeout).to.have.been.calledOnce;\n      expect(connection).to.have.property(kDelayedTimeoutId).that.is.instanceOf(NodeJSTimeoutClass);\n      expect(connection).to.have.property('closed', false);\n      expect(driverSocket.destroy).to.not.have.been.called;\n      clock.tick(1);\n      expect(driverSocket.destroy).to.have.been.calledOnce;\n      expect(connection).to.have.property('closed', true);\n    });","file":"unit/cmap/connection.test.ts","skipped":false,"dir":"test"},{"name":"should clear timeout errors if more data is available","suites":["new Connection()","onTimeout()"],"updatePoint":{"line":175,"column":61,"index":5829},"line":175,"code":"    it('should clear timeout errors if more data is available', () => {\n      expect(connection).to.have.property(kDelayedTimeoutId, null);\n      driverSocket.emit('timeout');\n      expect(connection.onTimeout).to.have.been.calledOnce;\n      expect(connection).to.have.property(kDelayedTimeoutId).that.is.instanceOf(NodeJSTimeoutClass); // emit a message before the clock ticks even once\n      // onMessage ignores unknown 'responseTo' value\n\n      messageStream.emit('message', {\n        responseTo: null\n      }); // New message before clock ticks 1 will clear the timeout\n\n      expect(connection).to.have.property(kDelayedTimeoutId, null); // ticking the clock should do nothing, there is no timeout anymore\n\n      clock.tick(1);\n      expect(driverSocket.destroy).to.not.have.been.called;\n      expect(connection).to.have.property('closed', false);\n      expect(connection).to.have.property(kDelayedTimeoutId, null);\n    });","file":"unit/cmap/connection.test.ts","skipped":false,"dir":"test"},{"name":"returns true","suites":["new Connection()",".hasSessionSupport","when logicalSessionTimeoutMinutes is present"],"updatePoint":{"line":205,"column":22,"index":7149},"line":205,"code":"      it('returns true', function () {\n        expect(hasSessionSupport(connection)).to.be.true;\n      });","file":"unit/cmap/connection.test.ts","skipped":false,"dir":"test"},{"name":"returns true","suites":["new Connection()",".hasSessionSupport","when logicalSessionTimeoutMinutes is not present","when in load balancing mode"],"updatePoint":{"line":218,"column":24,"index":7653},"line":218,"code":"        it('returns true', function () {\n          expect(hasSessionSupport(connection)).to.be.true;\n        });","file":"unit/cmap/connection.test.ts","skipped":false,"dir":"test"},{"name":"returns false","suites":["new Connection()",".hasSessionSupport","when logicalSessionTimeoutMinutes is not present","when not in load balancing mode"],"updatePoint":{"line":230,"column":25,"index":8091},"line":230,"code":"        it('returns false', function () {\n          expect(hasSessionSupport(connection)).to.be.false;\n        });","file":"unit/cmap/connection.test.ts","skipped":false,"dir":"test"},{"name":"should write a message to the stream","suites":["Message Stream","writing"],"updatePoint":{"line":117,"column":44,"index":4248},"line":117,"code":"    it('should write a message to the stream', function (done) {\n      const readableStream = new Readable({\n        read() {}\n\n      });\n      const writeableStream = new Writable({\n        write: (chunk, _, callback) => {\n          readableStream.push(chunk);\n          callback();\n        }\n      });\n      readableStream.on('data', data => {\n        expect(data.toString('hex')).to.eql('370000000300000000000000dd0700000000000000220000001069736d6173746572000100000002246462000600000061646d696e0000');\n        done();\n      });\n      const messageStream = new MessageStream();\n      messageStream.pipe(writeableStream);\n      const command = new Msg('admin.$cmd', {\n        [LEGACY_HELLO_COMMAND]: 1\n      }, {\n        requestId: 3\n      });\n      messageStream.writeCommand(command, null, err => {\n        done(err);\n      });\n    });","file":"unit/cmap/message_stream.test.js","skipped":false,"dir":"test"},{"name":"defaults txnConnections to zero","suites":["ConnectionPoolMetrics","#constructor"],"updatePoint":{"line":14,"column":39,"index":307},"line":14,"code":"    it('defaults txnConnections to zero', function () {\n      expect(metrics).property('txnConnections').to.equal(0);\n    });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"defaults cursorConnections to zero","suites":["ConnectionPoolMetrics","#constructor"],"updatePoint":{"line":17,"column":42,"index":436},"line":17,"code":"    it('defaults cursorConnections to zero', function () {\n      expect(metrics).property('cursorConnections').to.equal(0);\n    });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"defaults otherConnections to zero","suites":["ConnectionPoolMetrics","#constructor"],"updatePoint":{"line":20,"column":41,"index":567},"line":20,"code":"    it('defaults otherConnections to zero', function () {\n      expect(metrics).property('otherConnections').to.equal(0);\n    });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"returns the metrics information","suites":["ConnectionPoolMetrics","#info"],"updatePoint":{"line":26,"column":39,"index":784},"line":26,"code":"    it('returns the metrics information', function () {\n      expect(metrics.info(5)).to.equal('Timed out while checking out a connection from connection pool: ' + 'maxPoolSize: 5, ' + 'connections in use by cursors: 0, ' + 'connections in use by transactions: 0, ' + 'connections in use by other operations: 0');\n    });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"increments the txnConnections count","suites":["ConnectionPoolMetrics","#markPinned","when the type is TXN"],"updatePoint":{"line":37,"column":45,"index":1374},"line":37,"code":"      it('increments the txnConnections count', function () {\n        expect(metrics).to.deep.equal({\n          txnConnections: 1,\n          cursorConnections: 0,\n          otherConnections: 0\n        });\n      });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"increments the cursorConnections count","suites":["ConnectionPoolMetrics","#markPinned","when the type is CURSOR"],"updatePoint":{"line":50,"column":48,"index":1773},"line":50,"code":"      it('increments the cursorConnections count', function () {\n        expect(metrics).to.deep.equal({\n          txnConnections: 0,\n          cursorConnections: 1,\n          otherConnections: 0\n        });\n      });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"increments the otherConnections count","suites":["ConnectionPoolMetrics","#markPinned","when the type is OTHER"],"updatePoint":{"line":63,"column":47,"index":2169},"line":63,"code":"      it('increments the otherConnections count', function () {\n        expect(metrics).to.deep.equal({\n          txnConnections: 0,\n          cursorConnections: 0,\n          otherConnections: 1\n        });\n      });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"decrements the txnConnections count","suites":["ConnectionPoolMetrics","#markUnpinned","when the type is TXN"],"updatePoint":{"line":79,"column":45,"index":2658},"line":79,"code":"      it('decrements the txnConnections count', function () {\n        expect(metrics).to.deep.equal({\n          txnConnections: -1,\n          cursorConnections: 0,\n          otherConnections: 0\n        });\n      });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"decrements the cursorConnections count","suites":["ConnectionPoolMetrics","#markUnpinned","when the type is CURSOR"],"updatePoint":{"line":92,"column":48,"index":3060},"line":92,"code":"      it('decrements the cursorConnections count', function () {\n        expect(metrics).to.deep.equal({\n          txnConnections: 0,\n          cursorConnections: -1,\n          otherConnections: 0\n        });\n      });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"decrements the otherConnections count","suites":["ConnectionPoolMetrics","#markUnpinned","when the type is OTHER"],"updatePoint":{"line":105,"column":47,"index":3459},"line":105,"code":"      it('decrements the otherConnections count', function () {\n        expect(metrics).to.deep.equal({\n          txnConnections: 0,\n          cursorConnections: 0,\n          otherConnections: -1\n        });\n      });","file":"unit/cmap/metrics.test.js","skipped":false,"dir":"test"},{"name":"sets the property","suites":["StreamDescription - unit/cmap",".new","when options are provided","when logicalSessionTimeoutMinutes is in the options"],"updatePoint":{"line":19,"column":29,"index":543},"line":19,"code":"        it('sets the property', function () {\n          expect(description.logicalSessionTimeoutMinutes).to.eq(5);\n        });","file":"unit/cmap/stream_description.test.js","skipped":false,"dir":"test"},{"name":"sets logicalSessionTimeoutMinutes to undefined","suites":["StreamDescription - unit/cmap",".new","when options are provided","when logicalSessionTimeoutMinutes is not in the options"],"updatePoint":{"line":25,"column":58,"index":862},"line":25,"code":"        it('sets logicalSessionTimeoutMinutes to undefined', function () {\n          expect(description).to.have.property('logicalSessionTimeoutMinutes', undefined);\n        });","file":"unit/cmap/stream_description.test.js","skipped":false,"dir":"test"},{"name":"sets the property to true","suites":["StreamDescription - unit/cmap",".new","when options are provided","when loadBalanced is in the options","when the value is true"],"updatePoint":{"line":35,"column":39,"index":1299},"line":35,"code":"          it('sets the property to true', function () {\n            expect(description.loadBalanced).to.be.true;\n          });","file":"unit/cmap/stream_description.test.js","skipped":false,"dir":"test"},{"name":"sets the property to false","suites":["StreamDescription - unit/cmap",".new","when options are provided","when loadBalanced is in the options","when the value is false"],"updatePoint":{"line":44,"column":40,"index":1642},"line":44,"code":"          it('sets the property to false', function () {\n            expect(description.loadBalanced).to.be.false;\n          });","file":"unit/cmap/stream_description.test.js","skipped":false,"dir":"test"},{"name":"sets loadBalanced to false","suites":["StreamDescription - unit/cmap",".new","when options are provided","when loadBalanced is not in the options"],"updatePoint":{"line":51,"column":38,"index":1928},"line":51,"code":"        it('sets loadBalanced to false', function () {\n          expect(description.loadBalanced).to.be.false;\n        });","file":"unit/cmap/stream_description.test.js","skipped":false,"dir":"test"},{"name":"defaults logicalSessionTimeoutMinutes to undefined","suites":["StreamDescription - unit/cmap",".new","when options are not provided"],"updatePoint":{"line":58,"column":60,"index":2210},"line":58,"code":"      it('defaults logicalSessionTimeoutMinutes to undefined', function () {\n        expect(description).to.have.property('logicalSessionTimeoutMinutes', undefined);\n      });","file":"unit/cmap/stream_description.test.js","skipped":false,"dir":"test"},{"name":"defaults loadBalanced to false","suites":["StreamDescription - unit/cmap",".new","when options are not provided"],"updatePoint":{"line":61,"column":40,"index":2366},"line":61,"code":"      it('defaults loadBalanced to false', function () {\n        expect(description.loadBalanced).to.be.false;\n      });","file":"unit/cmap/stream_description.test.js","skipped":false,"dir":"test"},{"name":"compresses the data","suites":["compression",".compress()","when the compression library is zstd","when a level is not provided"],"updatePoint":{"line":13,"column":31,"index":515},"line":13,"code":"        it('compresses the data', function (done) {\n          compress(options, buffer, (error, data) => {\n            expect(error).to.not.exist;\n            const zstdMagicNumber = data.reverse().toString('hex').substring(16, 26); // Zstd magic number first set of bytes is is 0xFD2FB528\n\n            expect(zstdMagicNumber).to.equal('00fd2fb528');\n            done();\n          });\n        });","file":"unit/cmap/wire_protocol/compression.test.ts","skipped":false,"dir":"test"},{"name":"compresses the data","suites":["compression",".compress()","when the compression library is zstd","when a level is provided"],"updatePoint":{"line":30,"column":31,"index":1122},"line":30,"code":"        it('compresses the data', function (done) {\n          compress(options, buffer, (error, data) => {\n            expect(error).to.not.exist;\n            const zstdMagicNumber = data.reverse().toString('hex').substring(16, 26); // Zstd magic number first set of bytes is is 0xFD2FB528\n\n            expect(zstdMagicNumber).to.equal('00fd2fb528');\n            done();\n          });\n        });","file":"unit/cmap/wire_protocol/compression.test.ts","skipped":false,"dir":"test"},{"name":"decompresses the data","suites":["compression",".decompress()","when the compression library is zstd"],"updatePoint":{"line":50,"column":31,"index":1790},"line":50,"code":"      it('decompresses the data', function (done) {\n        compress(options, buffer, (error, data) => {\n          expect(error).to.not.exist;\n          decompress(Compressor.zstd, data, (err, decompressed) => {\n            expect(decompressed).to.deep.equal(buffer);\n            done();\n          });\n        });\n      });","file":"unit/cmap/wire_protocol/compression.test.ts","skipped":false,"dir":"test"},{"name":"returns 3.6","suites":["Wire Protocol Constants","MIN_SUPPORTED_SERVER_VERSION"],"updatePoint":{"line":14,"column":19,"index":359},"line":14,"code":"    it('returns 3.6', function () {\n      expect(MIN_SUPPORTED_SERVER_VERSION).to.equal('3.6');\n    });","file":"unit/cmap/wire_protocol/constants.test.js","skipped":false,"dir":"test"},{"name":"returns 5.1","suites":["Wire Protocol Constants","MAX_SUPPORTED_SERVER_VERSION"],"updatePoint":{"line":19,"column":19,"index":526},"line":19,"code":"    it('returns 5.1', function () {\n      expect(MAX_SUPPORTED_SERVER_VERSION).to.equal('5.1');\n    });","file":"unit/cmap/wire_protocol/constants.test.js","skipped":false,"dir":"test"},{"name":"returns 6","suites":["Wire Protocol Constants","MIN_SUPPORTED_WIRE_VERSION"],"updatePoint":{"line":24,"column":17,"index":689},"line":24,"code":"    it('returns 6', function () {\n      expect(MIN_SUPPORTED_WIRE_VERSION).to.equal(6);\n    });","file":"unit/cmap/wire_protocol/constants.test.js","skipped":false,"dir":"test"},{"name":"returns 14","suites":["Wire Protocol Constants","MAX_SUPPORTED_WIRE_VERSION"],"updatePoint":{"line":29,"column":18,"index":847},"line":29,"code":"    it('returns 14', function () {\n      expect(MAX_SUPPORTED_WIRE_VERSION).to.equal(14);\n    });","file":"unit/cmap/wire_protocol/constants.test.js","skipped":false,"dir":"test"},{"name":"","suites":["Connection String spec tests"],"updatePoint":{"line":14,"column":31,"index":759},"line":14,"code":"        it(`${test.description}`, function () {\n          if (skipTests.includes(test.description)) {\n            return this.skip();\n          }\n\n          executeUriValidationTest(test, testsThatDoNotThrowOnWarn.some(t => t === test.description));\n        });","file":"unit/connection_string.spec.test.ts","skipped":false,"dir":"test"},{"name":"sets the session on the cursor","suites":["Aggregation Cursor","#next","when there is a data bearing server"],"updatePoint":{"line":61,"column":40,"index":1353},"line":61,"code":"      it('sets the session on the cursor', function (done) {\n        const client = new MongoClient(new ConnectionString(`mongodb://${test.server.hostAddress()}`).toString());\n        const cursor = new AggregationCursor(client, MongoDBNamespace.fromString('test.test'), [], {});\n        client.connect(function () {\n          cursor.next(function () {\n            expect(cursor.session).to.exist;\n            client.close(done);\n          });\n        });\n      });","file":"unit/cursor/aggregation_cursor.test.js","skipped":false,"dir":"test"},{"name":"does not set the session on the cursor","suites":["Aggregation Cursor","#next","when there is no data bearing server"],"updatePoint":{"line":96,"column":48,"index":2493},"line":96,"code":"      it('does not set the session on the cursor', function (done) {\n        const client = new MongoClient(new ConnectionString(`mongodb://${test.server.hostAddress()}`).toString(), {\n          serverSelectionTimeoutMS: 1000\n        });\n        const cursor = new AggregationCursor(client, MongoDBNamespace.fromString('test.test'), [], {});\n        client.connect(function () {\n          cursor.next(function () {\n            expect(cursor.session).to.not.exist;\n            client.close(done);\n          });\n        });\n      });","file":"unit/cursor/aggregation_cursor.test.js","skipped":false,"dir":"test"},{"name":"sets the session on the cursor","suites":["Aggregation Cursor","#next","when a data bearing server becomes available"],"updatePoint":{"line":139,"column":40,"index":4089},"line":139,"code":"      it('sets the session on the cursor', function (done) {\n        const client = new MongoClient(new ConnectionString(`mongodb://${test.server.hostAddress()}`).toString(), {\n          serverSelectionTimeoutMS: 1000\n        });\n        const cursor = new AggregationCursor(client, MongoDBNamespace.fromString('test.test'), [], {});\n        client.connect(function () {\n          cursor.next(function () {\n            expect(cursor.session).to.exist;\n            client.close(done);\n          });\n        });\n      });","file":"unit/cursor/aggregation_cursor.test.js","skipped":false,"dir":"test"},{"name":"sets the session on the cursor","suites":["Find Cursor","#next","when there is a data bearing server"],"updatePoint":{"line":62,"column":40,"index":1334},"line":62,"code":"      it('sets the session on the cursor', function (done) {\n        const client = new MongoClient(new ConnectionString(`mongodb://${test.server.hostAddress()}`).toString(), {\n          serverSelectionTimeoutMS: 1000\n        });\n        const cursor = new FindCursor(client, MongoDBNamespace.fromString('test.test'), {}, {});\n        client.connect(function () {\n          cursor.next(function () {\n            expect(cursor.session).to.exist;\n            client.close(done);\n          });\n        });\n      });","file":"unit/cursor/find_cursor.test.js","skipped":false,"dir":"test"},{"name":"does not set the session on the cursor","suites":["Find Cursor","#next","when there is no data bearing server"],"updatePoint":{"line":99,"column":48,"index":2516},"line":99,"code":"      it('does not set the session on the cursor', function (done) {\n        const client = new MongoClient(new ConnectionString(`mongodb://${test.server.hostAddress()}`).toString(), {\n          serverSelectionTimeoutMS: 1000\n        });\n        const cursor = new FindCursor(client, MongoDBNamespace.fromString('test.test'), {}, {});\n        client.connect(function () {\n          cursor.next(function () {\n            expect(cursor.session).to.not.exist;\n            client.close(done);\n          });\n        });\n      });","file":"unit/cursor/find_cursor.test.js","skipped":false,"dir":"test"},{"name":"sets the session on the cursor","suites":["Find Cursor","#next","when a data bearing server becomes available"],"updatePoint":{"line":142,"column":40,"index":4100},"line":142,"code":"      it('sets the session on the cursor', function (done) {\n        const client = new MongoClient(new ConnectionString(`mongodb://${test.server.hostAddress()}`).toString(), {\n          serverSelectionTimeoutMS: 1000\n        });\n        const cursor = new FindCursor(client, MongoDBNamespace.fromString('test.test'), {}, {});\n        client.connect(function () {\n          cursor.next(function () {\n            expect(cursor.session).to.exist;\n            client.close(done);\n          });\n        });\n      });","file":"unit/cursor/find_cursor.test.js","skipped":false,"dir":"test"},{"name":"should throw when document is error","suites":["Find Cursor","Response"],"updatePoint":{"line":163,"column":43,"index":4833},"line":163,"code":"    it('should throw when document is error', function (done) {\n      const errdoc = {\n        errmsg: 'Cursor not found (namespace: \"liveearth.entityEvents\", id: 2018648316188432590).'\n      };\n      const client = new MongoClient(new ConnectionString(`mongodb://${test.server.hostAddress()}`).toString(), {\n        serverSelectionTimeoutMS: 1000\n      });\n      test.server.setMessageHandler(request => {\n        const doc = request.document;\n\n        if (isHello(doc)) {\n          request.reply(Object.assign({}, mock.HELLO, {\n            maxWireVersion: 6\n          }));\n        } else if (doc.find) {\n          request.reply({\n            cursor: {\n              id: Long.fromNumber(1),\n              ns: 'test.test',\n              firstBatch: []\n            },\n            ok: 1\n          });\n        } else if (doc.getMore) {\n          request.reply(errdoc);\n        } else if (doc.killCursors) {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      client.on('error', done);\n      client.connect(() => {\n        const cursor = new FindCursor(client, MongoDBNamespace.fromString('test.test'), {}, {}); // Execute next\n\n        cursor.next(function (err) {\n          expect(err).to.exist;\n          expect(err).to.be.instanceof(MongoServerError);\n          expect(err.message).to.equal(errdoc.errmsg);\n          client.close(done);\n        });\n      });\n    });","file":"unit/cursor/find_cursor.test.js","skipped":false,"dir":"test"},{"name":"should be false when readPreference is Primary","suites":["class Db","secondaryOk"],"updatePoint":{"line":10,"column":54,"index":456},"line":10,"code":"    it('should be false when readPreference is Primary', function () {\n      const options = {\n        readPreference: ReadPreference.PRIMARY\n      };\n      const mydb = new Db(client, 'mydb', options);\n      expect(mydb).property(secondary_ok).to.be.false;\n      expect(mydb).property(legacy_secondary_ok).to.be.false;\n    });","file":"unit/db.test.ts","skipped":false,"dir":"test"},{"name":"should be true when readPreference is Primary Preferred","suites":["class Db","secondaryOk"],"updatePoint":{"line":18,"column":63,"index":793},"line":18,"code":"    it('should be true when readPreference is Primary Preferred', function () {\n      const options = {\n        readPreference: ReadPreference.PRIMARY_PREFERRED\n      };\n      const mydb = new Db(client, 'mydb', options);\n      expect(mydb).property(secondary_ok).to.be.true;\n      expect(mydb).property(legacy_secondary_ok).to.be.true;\n    });","file":"unit/db.test.ts","skipped":false,"dir":"test"},{"name":"should be true when readPreference is Secondary","suites":["class Db","secondaryOk"],"updatePoint":{"line":26,"column":55,"index":1130},"line":26,"code":"    it('should be true when readPreference is Secondary', function () {\n      const options = {\n        readPreference: ReadPreference.SECONDARY\n      };\n      const mydb = new Db(client, 'mydb', options);\n      expect(mydb).property(secondary_ok).to.be.true;\n      expect(mydb).property(legacy_secondary_ok).to.be.true;\n    });","file":"unit/db.test.ts","skipped":false,"dir":"test"},{"name":"should be true when readPreference is Secondary Preferred","suites":["class Db","secondaryOk"],"updatePoint":{"line":34,"column":65,"index":1469},"line":34,"code":"    it('should be true when readPreference is Secondary Preferred', function () {\n      const options = {\n        readPreference: ReadPreference.SECONDARY_PREFERRED\n      };\n      const mydb = new Db(client, 'mydb', options);\n      expect(mydb).property(secondary_ok).to.be.true;\n      expect(mydb).property(legacy_secondary_ok).to.be.true;\n    });","file":"unit/db.test.ts","skipped":false,"dir":"test"},{"name":"should be true when readPreference is Nearest","suites":["class Db","secondaryOk"],"updatePoint":{"line":42,"column":53,"index":1806},"line":42,"code":"    it('should be true when readPreference is Nearest', function () {\n      const options = {\n        readPreference: ReadPreference.NEAREST\n      };\n      const mydb = new Db(client, 'mydb', options);\n      expect(mydb).property(secondary_ok).to.be.true;\n      expect(mydb).property(legacy_secondary_ok).to.be.true;\n    });","file":"unit/db.test.ts","skipped":false,"dir":"test"},{"name":"MongoClient should always freeze public options","suites":["MongoOptions"],"updatePoint":{"line":51,"column":53,"index":802},"line":51,"code":"  it('MongoClient should always freeze public options', function () {\n    const client = new MongoClient('mongodb://localhost:27017');\n    expect(client.options).to.be.frozen;\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"programmatic options should override URI options","suites":["MongoOptions"],"updatePoint":{"line":55,"column":54,"index":985},"line":55,"code":"  it('programmatic options should override URI options', function () {\n    const options = parseOptions('mongodb://localhost:27017/test?directConnection=true', {\n      directConnection: false\n    });\n    expect(options.directConnection).to.be.false;\n    expect(options.hosts).has.length(1);\n    expect(options.dbName).to.equal('test');\n    expect(options.prototype).to.not.exist;\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should rename tls options correctly","suites":["MongoOptions"],"updatePoint":{"line":64,"column":41,"index":1358},"line":64,"code":"  it('should rename tls options correctly', function () {\n    const filename = `${os.tmpdir()}/tmp.pem`;\n    fs.closeSync(fs.openSync(filename, 'w'));\n    const options = parseOptions('mongodb://localhost:27017/?ssl=true', {\n      tlsCertificateKeyFile: filename,\n      tlsCertificateFile: filename,\n      tlsCAFile: filename,\n      sslCRL: filename,\n      tlsCertificateKeyFilePassword: 'tlsCertificateKeyFilePassword',\n      sslValidate: false\n    });\n    fs.unlinkSync(filename);\n    /*\n     * If set TLS enabled, equivalent to setting the ssl option.\n     *\n     * ### Additional options:\n     *\n     * |    nodejs option     | MongoDB equivalent                                 | type                                   |\n     * |:---------------------|----------------------------------------------------|:---------------------------------------|\n     * | `ca`                 | sslCA, tlsCAFile                                   | `string \\| Buffer \\| Buffer[]`         |\n     * | `crl`                | sslCRL                                             | `string \\| Buffer \\| Buffer[]`         |\n     * | `cert`               | sslCert, tlsCertificateFile                        | `string \\| Buffer \\| Buffer[]`         |\n     * | `key`                | sslKey, tlsCertificateKeyFile                      | `string \\| Buffer \\| KeyObject[]`      |\n     * | `passphrase`         | sslPass, tlsCertificateKeyFilePassword             | `string`                               |\n     * | `rejectUnauthorized` | sslValidate                                        | `boolean`                              |\n     *\n     */\n\n    expect(options).to.not.have.property('tlsCertificateKeyFile');\n    expect(options).to.not.have.property('tlsCAFile');\n    expect(options).to.not.have.property('sslCRL');\n    expect(options).to.not.have.property('tlsCertificateKeyFilePassword');\n    expect(options).has.property('ca', '');\n    expect(options).has.property('crl', '');\n    expect(options).has.property('cert', '');\n    expect(options).has.property('key');\n    expect(options.key).has.length(0);\n    expect(options).has.property('passphrase', 'tlsCertificateKeyFilePassword');\n    expect(options).has.property('rejectUnauthorized', false);\n    expect(options).has.property('tls', true);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should parse all options from the options object","suites":["MongoOptions"],"updatePoint":{"line":192,"column":54,"index":5716},"line":192,"code":"  it('should parse all options from the options object', function () {\n    const options = parseOptions('mongodb://localhost:27017/', ALL_OPTIONS); // Check consolidated options\n\n    expect(options).has.property('writeConcern');\n    expect(options.writeConcern).has.property('w', 2);\n    expect(options.writeConcern).has.property('j', true);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should parse all options from the URI string","suites":["MongoOptions"],"updatePoint":{"line":200,"column":50,"index":6874},"line":200,"code":"  it('should parse all options from the URI string', function () {\n    const options = parseOptions(allURIOptions);\n    expect(options).has.property('zlibCompressionLevel', 2);\n    expect(options).has.property('writeConcern');\n    expect(options.writeConcern).has.property('w', 'majority');\n    expect(options.writeConcern).has.property('wtimeout', 2);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should ignore undefined and null values in the options object","suites":["MongoOptions"],"updatePoint":{"line":207,"column":67,"index":7250},"line":207,"code":"  it('should ignore undefined and null values in the options object', function () {\n    const options = parseOptions('mongodb://localhost:27017/', {\n      maxPoolSize: null,\n      servername: undefined,\n      randomopt: null,\n      otherrandomopt: undefined\n    }); // test valid option key with default value\n\n    expect(options).to.have.property('maxPoolSize', 100); // test valid option key without default value\n\n    expect(options).not.to.have.property('servername'); // test invalid option keys that are null/undefined\n\n    expect(options).not.to.have.property('randomopt');\n    expect(options).not.to.have.property('otherrandomopt');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should throw an error on unrecognized keys in the options object if they are defined","suites":["MongoOptions"],"updatePoint":{"line":222,"column":90,"index":7920},"line":222,"code":"  it('should throw an error on unrecognized keys in the options object if they are defined', function () {\n    expect(() => parseOptions('mongodb://localhost:27017/', {\n      randomopt: 'test'\n    })).to.throw(MongoParseError, 'option randomopt is not supported');\n    expect(() => parseOptions('mongodb://localhost:27017/', {\n      randomopt: 'test',\n      randomopt2: 'test'\n    })).to.throw(MongoParseError, 'options randomopt, randomopt2 are not supported');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"srvHost saved to options for later resolution","suites":["MongoOptions"],"updatePoint":{"line":231,"column":51,"index":8350},"line":231,"code":"  it('srvHost saved to options for later resolution', function () {\n    const options = parseOptions('mongodb+srv://server.example.com/');\n    expect(options).has.property('srvHost', 'server.example.com');\n    expect(options).has.property('tls', true);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"ssl= can be used to set tls=false","suites":["MongoOptions"],"updatePoint":{"line":236,"column":39,"index":8597},"line":236,"code":"  it('ssl= can be used to set tls=false', function () {\n    const options = parseOptions('mongodb+srv://server.example.com/?ssl=false');\n    expect(options).has.property('srvHost', 'server.example.com');\n    expect(options).has.property('tls', false);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"tls= can be used to set tls=false","suites":["MongoOptions"],"updatePoint":{"line":241,"column":39,"index":8855},"line":241,"code":"  it('tls= can be used to set tls=false', function () {\n    const options = parseOptions('mongodb+srv://server.example.com/?tls=false');\n    expect(options).has.property('srvHost', 'server.example.com');\n    expect(options).has.property('tls', false);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"ssl= can be used to set tls=true","suites":["MongoOptions"],"updatePoint":{"line":246,"column":38,"index":9112},"line":246,"code":"  it('ssl= can be used to set tls=true', function () {\n    const options = parseOptions('mongodb+srv://server.example.com/?ssl=true');\n    expect(options).has.property('srvHost', 'server.example.com');\n    expect(options).has.property('tls', true);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"tls= can be used to set tls=true","suites":["MongoOptions"],"updatePoint":{"line":251,"column":38,"index":9367},"line":251,"code":"  it('tls= can be used to set tls=true', function () {\n    const options = parseOptions('mongodb+srv://server.example.com/?tls=true');\n    expect(options).has.property('srvHost', 'server.example.com');\n    expect(options).has.property('tls', true);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports ReadPreference option in url","suites":["MongoOptions"],"updatePoint":{"line":256,"column":43,"index":9627},"line":256,"code":"  it('supports ReadPreference option in url', function () {\n    const options = parseOptions('mongodb://localhost/?readPreference=nearest');\n    expect(options.readPreference).to.be.an.instanceof(ReadPreference);\n    expect(options.readPreference.mode).to.equal('nearest');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports ReadPreference option in object plain","suites":["MongoOptions"],"updatePoint":{"line":261,"column":52,"index":9916},"line":261,"code":"  it('supports ReadPreference option in object plain', function () {\n    const options = parseOptions('mongodb://localhost', {\n      readPreference: {\n        mode: 'nearest',\n        hedge: {\n          enabled: true\n        }\n      }\n    });\n    expect(options.readPreference).to.be.an.instanceof(ReadPreference);\n    expect(options.readPreference.mode).to.equal('nearest');\n    expect(options.readPreference.hedge).to.include({\n      enabled: true\n    });\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports ReadPreference option in object proper class","suites":["MongoOptions"],"updatePoint":{"line":276,"column":59,"index":10387},"line":276,"code":"  it('supports ReadPreference option in object proper class', function () {\n    const tag = {\n      rack: 1\n    };\n    const options = parseOptions('mongodb://localhost', {\n      readPreference: new ReadPreference('nearest', [tag], {\n        maxStalenessSeconds: 20\n      })\n    });\n    expect(options.readPreference).to.be.an.instanceof(ReadPreference);\n    expect(options.readPreference.mode).to.equal('nearest');\n    expect(options.readPreference.tags).to.be.an('array').that.includes(tag);\n    expect(options.readPreference.maxStalenessSeconds).to.equal(20); // maxStalenessSeconds sets the minWireVersion\n\n    expect(options.readPreference.minWireVersion).to.be.at.least(5);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should throw when given a readpreference options with an unsupported type","suites":["MongoOptions"],"updatePoint":{"line":292,"column":79,"index":11093},"line":292,"code":"  it('should throw when given a readpreference options with an unsupported type', () => {\n    expect(() => new MongoClient('mongodb://blah', {\n      readPreference: 34\n    })).to.throw(MongoParseError, /Unknown ReadPreference value/); // Passing readPreference in URI will always be string\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports WriteConcern option in url","suites":["MongoOptions"],"updatePoint":{"line":297,"column":41,"index":11351},"line":297,"code":"  it('supports WriteConcern option in url', function () {\n    const options = parseOptions('mongodb://localhost/?w=3');\n    expect(options.writeConcern).to.be.an.instanceof(WriteConcern);\n    expect(options.writeConcern.w).to.equal(3);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports WriteConcern option in object plain","suites":["MongoOptions"],"updatePoint":{"line":302,"column":50,"index":11602},"line":302,"code":"  it('supports WriteConcern option in object plain', function () {\n    const options = parseOptions('mongodb://localhost', {\n      writeConcern: {\n        w: 'majority',\n        wtimeoutMS: 300\n      }\n    });\n    expect(options.writeConcern).to.be.an.instanceof(WriteConcern);\n    expect(options.writeConcern.w).to.equal('majority');\n    expect(options.writeConcern.wtimeout).to.equal(300);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports WriteConcern option in object proper class","suites":["MongoOptions"],"updatePoint":{"line":313,"column":57,"index":12007},"line":313,"code":"  it('supports WriteConcern option in object proper class', function () {\n    const options = parseOptions('mongodb://localhost', {\n      writeConcern: new WriteConcern(5, 200, true)\n    });\n    expect(options.writeConcern).to.be.an.instanceof(WriteConcern);\n    expect(options.writeConcern.w).to.equal(5);\n    expect(options.writeConcern.wtimeout).to.equal(200);\n    expect(options.writeConcern.j).to.equal(true);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports ReadConcern option in url","suites":["MongoOptions"],"updatePoint":{"line":322,"column":40,"index":12411},"line":322,"code":"  it('supports ReadConcern option in url', function () {\n    const options = parseOptions('mongodb://localhost/?readConcernLevel=available');\n    expect(options.readConcern).to.be.an.instanceof(ReadConcern);\n    expect(options.readConcern.level).to.equal('available');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports ReadConcern option in object plain","suites":["MongoOptions"],"updatePoint":{"line":327,"column":49,"index":12695},"line":327,"code":"  it('supports ReadConcern option in object plain', function () {\n    const options = parseOptions('mongodb://localhost', {\n      readConcern: {\n        level: 'linearizable'\n      }\n    });\n    expect(options.readConcern).to.be.an.instanceof(ReadConcern);\n    expect(options.readConcern.level).to.equal('linearizable');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports ReadConcern option in object proper class","suites":["MongoOptions"],"updatePoint":{"line":336,"column":56,"index":13029},"line":336,"code":"  it('supports ReadConcern option in object proper class', function () {\n    const options = parseOptions('mongodb://localhost', {\n      readConcern: new ReadConcern('snapshot')\n    });\n    expect(options.readConcern).to.be.an.instanceof(ReadConcern);\n    expect(options.readConcern.level).to.equal('snapshot');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports Credentials option in url","suites":["MongoOptions"],"updatePoint":{"line":343,"column":40,"index":13331},"line":343,"code":"  it('supports Credentials option in url', function () {\n    const options = parseOptions('mongodb://USERNAME:PASSWORD@localhost/');\n    expect(options.credentials).to.be.an.instanceof(MongoCredentials);\n    expect(options.credentials.username).to.equal('USERNAME');\n    expect(options.credentials.password).to.equal('PASSWORD');\n    expect(options.credentials.source).to.equal('admin');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports Credentials option in url with db","suites":["MongoOptions"],"updatePoint":{"line":350,"column":48,"index":13733},"line":350,"code":"  it('supports Credentials option in url with db', function () {\n    const options = parseOptions('mongodb://USERNAME:PASSWORD@localhost/foo');\n    expect(options.credentials).to.be.an.instanceof(MongoCredentials);\n    expect(options.credentials.username).to.equal('USERNAME');\n    expect(options.credentials.password).to.equal('PASSWORD');\n    expect(options.credentials.source).to.equal('foo');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"supports Credentials option in auth object plain","suites":["MongoOptions"],"updatePoint":{"line":357,"column":54,"index":14142},"line":357,"code":"  it('supports Credentials option in auth object plain', function () {\n    const options = parseOptions('mongodb://localhost/', {\n      auth: {\n        username: 'USERNAME',\n        password: 'PASSWORD'\n      }\n    });\n    expect(options.credentials).to.be.an.instanceof(MongoCredentials);\n    expect(options.credentials.username).to.equal('USERNAME');\n    expect(options.credentials.password).to.equal('PASSWORD');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"transforms tlsAllowInvalidCertificates and tlsAllowInvalidHostnames correctly","suites":["MongoOptions"],"updatePoint":{"line":368,"column":83,"index":14593},"line":368,"code":"  it('transforms tlsAllowInvalidCertificates and tlsAllowInvalidHostnames correctly', function () {\n    const optionsTrue = parseOptions('mongodb://localhost/', {\n      tlsAllowInvalidCertificates: true,\n      tlsAllowInvalidHostnames: true\n    });\n    expect(optionsTrue.rejectUnauthorized).to.equal(false);\n    expect(optionsTrue.checkServerIdentity).to.be.a('function');\n    expect(optionsTrue.checkServerIdentity()).to.equal(undefined);\n    const optionsFalse = parseOptions('mongodb://localhost/', {\n      tlsAllowInvalidCertificates: false,\n      tlsAllowInvalidHostnames: false\n    });\n    expect(optionsFalse.rejectUnauthorized).to.equal(true);\n    expect(optionsFalse.checkServerIdentity).to.equal(undefined);\n    const optionsUndefined = parseOptions('mongodb://localhost/');\n    expect(optionsUndefined.rejectUnauthorized).to.equal(undefined);\n    expect(optionsUndefined.checkServerIdentity).to.equal(undefined);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"correctly sets the cert and key if only tlsCertificateKeyFile is provided","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":397,"column":81,"index":15896},"line":397,"code":"    it('correctly sets the cert and key if only tlsCertificateKeyFile is provided', function () {\n      const optsFromObject = parseOptions('mongodb://localhost/', {\n        tlsCertificateKeyFile: 'testCertKey.pem'\n      });\n      expect(optsFromObject).to.have.property('cert', 'cert key');\n      expect(optsFromObject).to.have.property('key', 'cert key');\n      const optsFromUri = parseOptions('mongodb://localhost?tlsCertificateKeyFile=testCertKey.pem');\n      expect(optsFromUri).to.have.property('cert', 'cert key');\n      expect(optsFromUri).to.have.property('key', 'cert key');\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"correctly sets the cert and key if both tlsCertificateKeyFile and tlsCertificateFile is provided","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":407,"column":104,"index":16513},"line":407,"code":"    it('correctly sets the cert and key if both tlsCertificateKeyFile and tlsCertificateFile is provided', function () {\n      const optsFromObject = parseOptions('mongodb://localhost/', {\n        tlsCertificateKeyFile: 'testKey.pem',\n        tlsCertificateFile: 'testCert.pem'\n      });\n      expect(optsFromObject).to.have.property('cert', 'test cert');\n      expect(optsFromObject).to.have.property('key', 'test key');\n      const optsFromUri = parseOptions('mongodb://localhost?tlsCertificateKeyFile=testKey.pem&tlsCertificateFile=testCert.pem');\n      expect(optsFromUri).to.have.property('cert', 'test cert');\n      expect(optsFromUri).to.have.property('key', 'test key');\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"throws an error if multiple tls parameters are not all set to the same value","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":419,"column":82,"index":17184},"line":419,"code":"  it('throws an error if multiple tls parameters are not all set to the same value', () => {\n    expect(() => parseOptions('mongodb://localhost?tls=true&tls=false')).to.throw('All values of tls/ssl must be the same.');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"throws an error if multiple ssl parameters are not all set to the same value","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":422,"column":82,"index":17409},"line":422,"code":"  it('throws an error if multiple ssl parameters are not all set to the same value', () => {\n    expect(() => parseOptions('mongodb://localhost?ssl=true&ssl=false')).to.throw('All values of tls/ssl must be the same.');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"throws an error if tls and ssl parameters are not all set to the same value","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":425,"column":81,"index":17633},"line":425,"code":"  it('throws an error if tls and ssl parameters are not all set to the same value', () => {\n    expect(() => parseOptions('mongodb://localhost?tls=true&ssl=false')).to.throw('All values of tls/ssl must be the same.');\n    expect(() => parseOptions('mongodb://localhost?tls=false&ssl=true')).to.throw('All values of tls/ssl must be the same.');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"correctly sets tls if multiple tls parameters are all set to the same value","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":429,"column":81,"index":17983},"line":429,"code":"  it('correctly sets tls if multiple tls parameters are all set to the same value', () => {\n    expect(parseOptions('mongodb://localhost?tls=true&tls=true')).to.have.property('tls', true);\n    expect(parseOptions('mongodb://localhost?tls=false&tls=false')).to.have.property('tls', false);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"correctly sets tls if multiple ssl parameters are all set to the same value","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":433,"column":81,"index":18278},"line":433,"code":"  it('correctly sets tls if multiple ssl parameters are all set to the same value', () => {\n    expect(parseOptions('mongodb://localhost?ssl=true&ssl=true')).to.have.property('tls', true);\n    expect(parseOptions('mongodb://localhost?ssl=false&ssl=false')).to.have.property('tls', false);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"correctly sets tls if tls and ssl parameters are all set to the same value","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":437,"column":80,"index":18572},"line":437,"code":"  it('correctly sets tls if tls and ssl parameters are all set to the same value', () => {\n    expect(parseOptions('mongodb://localhost?ssl=true&tls=true')).to.have.property('tls', true);\n    expect(parseOptions('mongodb://localhost?ssl=false&tls=false')).to.have.property('tls', false);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"transforms tlsInsecure correctly","suites":["MongoOptions","[tls certificate handling]"],"updatePoint":{"line":441,"column":38,"index":18824},"line":441,"code":"  it('transforms tlsInsecure correctly', function () {\n    const optionsTrue = parseOptions('mongodb://localhost/', {\n      tlsInsecure: true\n    });\n    expect(optionsTrue.rejectUnauthorized).to.equal(false);\n    expect(optionsTrue.checkServerIdentity).to.be.a('function');\n    expect(optionsTrue.checkServerIdentity()).to.equal(undefined);\n    const optionsFalse = parseOptions('mongodb://localhost/', {\n      tlsInsecure: false\n    });\n    expect(optionsFalse.rejectUnauthorized).to.equal(true);\n    expect(optionsFalse.checkServerIdentity).to.equal(undefined);\n    const optionsUndefined = parseOptions('mongodb://localhost/');\n    expect(optionsUndefined.rejectUnauthorized).to.equal(undefined);\n    expect(optionsUndefined.checkServerIdentity).to.equal(undefined);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"can be set when passed in as an array in the options object","suites":["MongoOptions","compressors"],"updatePoint":{"line":458,"column":67,"index":19670},"line":458,"code":"    it('can be set when passed in as an array in the options object', function () {\n      const clientViaOpt = new MongoClient('mongodb://localhost', {\n        compressors: ['zlib', 'snappy']\n      });\n      expect(clientViaOpt.options).to.have.property('compressors').deep.equal(['zlib', 'snappy', 'none']);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"can be set when passed in as a comma-delimited string in the options object or URI","suites":["MongoOptions","compressors"],"updatePoint":{"line":464,"column":90,"index":20010},"line":464,"code":"    it('can be set when passed in as a comma-delimited string in the options object or URI', function () {\n      const clientViaOpt = new MongoClient('mongodb://localhost', {\n        compressors: 'zlib,snappy'\n      });\n      const clientViaUri = new MongoClient('mongodb://localhost?compressors=zlib,snappy');\n      expect(clientViaOpt.options).to.have.property('compressors').deep.equal(['zlib', 'snappy', 'none']);\n      expect(clientViaUri.options).to.have.property('compressors').deep.equal(['zlib', 'snappy', 'none']);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should validate that a string or an array of strings is provided as input","suites":["MongoOptions","compressors"],"updatePoint":{"line":472,"column":81,"index":20534},"line":472,"code":"    it('should validate that a string or an array of strings is provided as input', function () {\n      expect(() => new MongoClient('mongodb://localhost', {\n        compressors: {\n          zlib: true\n        }\n      })).to.throw(/^compressors must be an array or a comma-delimited list of strings/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if an unrecognized compressor is specified","suites":["MongoOptions","compressors"],"updatePoint":{"line":479,"column":72,"index":20835},"line":479,"code":"    it('should throw an error if an unrecognized compressor is specified', function () {\n      const expectedErrRegex = /not a valid compression mechanism/;\n      expect(() => new MongoClient('mongodb://localhost', {\n        compressors: ['invalid']\n      })).to.throw(expectedErrRegex);\n      expect(() => new MongoClient('mongodb://localhost', {\n        compressors: 'invalid'\n      })).to.throw(expectedErrRegex);\n      expect(() => new MongoClient('mongodb://localhost?compressors=invalid')).to.throw(expectedErrRegex);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"is supported as a client option when it is a valid ServerApiVersion string","suites":["MongoOptions","serverApi"],"updatePoint":{"line":491,"column":82,"index":21421},"line":491,"code":"    it('is supported as a client option when it is a valid ServerApiVersion string', function () {\n      const validVersions = Object.values(ServerApiVersion);\n      expect(validVersions.length).to.be.at.least(1);\n\n      for (const version of validVersions) {\n        const result = parseOptions('mongodb://localhost/', {\n          serverApi: version\n        });\n        expect(result).to.have.property('serverApi').deep.equal({\n          version\n        });\n      }\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"is supported as a client option when it is an object with a valid version property","suites":["MongoOptions","serverApi"],"updatePoint":{"line":504,"column":90,"index":21904},"line":504,"code":"    it('is supported as a client option when it is an object with a valid version property', function () {\n      const validVersions = Object.values(ServerApiVersion);\n      expect(validVersions.length).to.be.at.least(1);\n\n      for (const version of validVersions) {\n        const result = parseOptions('mongodb://localhost/', {\n          serverApi: {\n            version\n          }\n        });\n        expect(result).to.have.property('serverApi').deep.equal({\n          version\n        });\n      }\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"is not supported as a client option when it is an invalid string","suites":["MongoOptions","serverApi"],"updatePoint":{"line":519,"column":72,"index":22395},"line":519,"code":"    it('is not supported as a client option when it is an invalid string', function () {\n      expect(() => parseOptions('mongodb://localhost/', {\n        serverApi: 'bad'\n      })).to.throw(/^Invalid server API version=bad;/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"is not supported as a client option when it is a number","suites":["MongoOptions","serverApi"],"updatePoint":{"line":524,"column":63,"index":22622},"line":524,"code":"    it('is not supported as a client option when it is a number', function () {\n      expect(() => parseOptions('mongodb://localhost/', {\n        serverApi: 1\n      })).to.throw(/^Invalid `serverApi` property;/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"is not supported as a client option when it is an object without a specified version","suites":["MongoOptions","serverApi"],"updatePoint":{"line":529,"column":92,"index":22872},"line":529,"code":"    it('is not supported as a client option when it is an object without a specified version', function () {\n      expect(() => parseOptions('mongodb://localhost/', {\n        serverApi: {}\n      })).to.throw(/^Invalid `serverApi` property;/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"is not supported as a client option when it is an object with an invalid specified version","suites":["MongoOptions","serverApi"],"updatePoint":{"line":534,"column":98,"index":23129},"line":534,"code":"    it('is not supported as a client option when it is an object with an invalid specified version', function () {\n      expect(() => parseOptions('mongodb://localhost/', {\n        serverApi: {\n          version: 1\n        }\n      })).to.throw(/^Invalid server API version=1;/);\n      expect(() => parseOptions('mongodb://localhost/', {\n        serverApi: {\n          version: 'bad'\n        }\n      })).to.throw(/^Invalid server API version=bad;/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"is not supported as a URI option even when it is a valid ServerApiVersion string","suites":["MongoOptions","serverApi"],"updatePoint":{"line":546,"column":88,"index":23576},"line":546,"code":"    it('is not supported as a URI option even when it is a valid ServerApiVersion string', function () {\n      expect(() => parseOptions('mongodb://localhost/?serverApi=1')).to.throw('URI cannot contain `serverApi`, it can only be passed to the client');\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should define known defaults in client.options","suites":["MongoOptions","default options"],"updatePoint":{"line":562,"column":54,"index":24827},"line":562,"code":"    it(`should define known defaults in client.options`, () => {\n      const client = new MongoClient('mongodb://localhost');\n      const clientOptions = client.options;\n\n      for (const [optionName, value] of KNOWN_DEFAULTS) {\n        const camelCaseName = findMatchingKey(clientOptions, optionName);\n        expect(camelCaseName, `did not find a camelcase match for ${optionName}`).to.be.a('string');\n        expect(clientOptions).to.have.property(camelCaseName);\n\n        if (value !== doNotCheckEq) {\n          expect(clientOptions).to.have.property(camelCaseName).that.deep.equals(value);\n        }\n      }\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"set monitorCommands to false (NODE-3513)","suites":["MongoOptions","default options"],"updatePoint":{"line":576,"column":48,"index":25442},"line":576,"code":"    it('set monitorCommands to false (NODE-3513)', function () {\n      const client = new MongoClient('mongodb://localhost');\n      const clientOptions = client.options;\n      expect(clientOptions).to.have.property('monitorCommands', false);\n      expect(client.s.options).to.have.property('monitorCommands', false);\n      expect(client).to.have.property('monitorCommands', false);\n      const optionsSym = getSymbolFrom(client, 'options');\n      expect(client[optionsSym]).to.have.property('monitorCommands', false);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"respects monitorCommands option passed in","suites":["MongoOptions","default options"],"updatePoint":{"line":585,"column":49,"index":25969},"line":585,"code":"    it('respects monitorCommands option passed in', function () {\n      const clientViaOpt = new MongoClient('mongodb://localhost', {\n        monitorCommands: true\n      });\n      const clientViaUri = new MongoClient('mongodb://localhost?monitorCommands=true');\n      const testTable = [[clientViaOpt, clientViaOpt.options], [clientViaUri, clientViaUri.options]];\n\n      for (const [client, clientOptions] of testTable) {\n        expect(clientOptions).to.have.property('monitorCommands', true);\n        expect(client.s.options).to.have.property('monitorCommands', true);\n        expect(client).to.have.property('monitorCommands', true);\n        const optionsSym = getSymbolFrom(client, 'options');\n        expect(client[optionsSym]).to.have.property('monitorCommands', true);\n      }\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"sets the option","suites":["MongoOptions","when loadBalanced=true is in the URI"],"updatePoint":{"line":602,"column":23,"index":26805},"line":602,"code":"    it('sets the option', function () {\n      const options = parseOptions('mongodb://a/?loadBalanced=true');\n      expect(options.loadBalanced).to.be.true;\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"errors with multiple hosts","suites":["MongoOptions","when loadBalanced=true is in the URI"],"updatePoint":{"line":606,"column":34,"index":26981},"line":606,"code":"    it('errors with multiple hosts', function () {\n      const parse = () => {\n        parseOptions('mongodb://a,b/?loadBalanced=true');\n      };\n\n      expect(parse).to.throw(/single host/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"errors with a replicaSet option","suites":["MongoOptions","when loadBalanced=true is in the URI"],"updatePoint":{"line":613,"column":39,"index":27186},"line":613,"code":"    it('errors with a replicaSet option', function () {\n      const parse = () => {\n        parseOptions('mongodb://a/?loadBalanced=true&replicaSet=test');\n      };\n\n      expect(parse).to.throw(/replicaSet/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"errors with a directConnection option","suites":["MongoOptions","when loadBalanced=true is in the URI"],"updatePoint":{"line":620,"column":45,"index":27410},"line":620,"code":"    it('errors with a directConnection option', function () {\n      const parse = () => {\n        parseOptions('mongodb://a/?loadBalanced=true&directConnection=true');\n      };\n\n      expect(parse).to.throw(/directConnection/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"errors when the option is true","suites":["MongoOptions","when loadBalanced is in the options object"],"updatePoint":{"line":629,"column":38,"index":27715},"line":629,"code":"    it('errors when the option is true', function () {\n      const parse = () => {\n        parseOptions('mongodb://a/', {\n          loadBalanced: true\n        });\n      };\n\n      expect(parse).to.throw(/URI/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"errors when the option is false","suites":["MongoOptions","when loadBalanced is in the options object"],"updatePoint":{"line":638,"column":39,"index":27934},"line":638,"code":"    it('errors when the option is false', function () {\n      const parse = () => {\n        parseOptions('mongodb://a/', {\n          loadBalanced: false\n        });\n      };\n\n      expect(parse).to.throw(/URI/);\n    });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"srvMaxHosts > 0 cannot be combined with LB or ReplicaSet","suites":["MongoOptions","when loadBalanced is in the options object"],"updatePoint":{"line":648,"column":62,"index":28183},"line":648,"code":"  it('srvMaxHosts > 0 cannot be combined with LB or ReplicaSet', () => {\n    expect(() => {\n      new MongoClient('mongodb+srv://localhost?srvMaxHosts=2&replicaSet=repl');\n    }).to.throw(MongoParseError, 'Cannot use srvMaxHosts option with replicaSet');\n    expect(() => {\n      new MongoClient('mongodb+srv://localhost?srvMaxHosts=2&loadBalanced=true');\n    }).to.throw(MongoParseError, 'Cannot limit srv hosts with loadBalanced enabled');\n    expect(() => {\n      new MongoClient('mongodb+srv://localhost', {\n        srvMaxHosts: 2,\n        replicaSet: 'blah'\n      });\n    }).to.throw(MongoParseError, 'Cannot use srvMaxHosts option with replicaSet');\n    expect(() => {\n      new MongoClient('mongodb+srv://localhost?loadBalanced=true', {\n        srvMaxHosts: 2\n      });\n    }).to.throw(MongoParseError, 'Cannot limit srv hosts with loadBalanced enabled'); // These should not throw.\n\n    new MongoClient('mongodb+srv://localhost?srvMaxHosts=0&replicaSet=repl');\n    new MongoClient('mongodb+srv://localhost', {\n      srvMaxHosts: 0,\n      replicaSet: 'blah'\n    });\n    new MongoClient('mongodb+srv://localhost?srvMaxHosts=0&loadBalanced=true');\n    new MongoClient('mongodb+srv://localhost?loadBalanced=true', {\n      srvMaxHosts: 0\n    });\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"srvServiceName and srvMaxHosts cannot be used on a non-srv connection string","suites":["MongoOptions","when loadBalanced is in the options object"],"updatePoint":{"line":677,"column":82,"index":29458},"line":677,"code":"  it('srvServiceName and srvMaxHosts cannot be used on a non-srv connection string', () => {\n    expect(() => {\n      new MongoClient('mongodb://localhost?srvMaxHosts=2');\n    }).to.throw(MongoParseError);\n    expect(() => {\n      new MongoClient('mongodb://localhost?srvMaxHosts=0');\n    }).to.throw(MongoParseError);\n    expect(() => {\n      new MongoClient('mongodb://localhost', {\n        srvMaxHosts: 0\n      });\n    }).to.throw(MongoParseError);\n    expect(() => {\n      new MongoClient('mongodb://localhost?srvServiceName=abc');\n    }).to.throw(MongoParseError);\n    expect(() => {\n      new MongoClient('mongodb://localhost', {\n        srvMaxHosts: 2\n      });\n    }).to.throw(MongoParseError);\n    expect(() => {\n      new MongoClient('mongodb://localhost', {\n        srvServiceName: 'abc'\n      });\n    }).to.throw(MongoParseError);\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"srvServiceName should error if it is too long","suites":["MongoOptions","when loadBalanced is in the options object"],"updatePoint":{"line":703,"column":51,"index":30276},"line":703,"code":"  it('srvServiceName should error if it is too long', async () => {\n    let thrownError;\n    let options;\n\n    try {\n      options = parseOptions('mongodb+srv://localhost.a.com', {\n        srvServiceName: 'a'.repeat(255)\n      });\n      await promisify(resolveSRVRecord)(options);\n    } catch (error) {\n      thrownError = error;\n    }\n\n    expect(thrownError).to.have.property('code', 'EBADNAME');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"srvServiceName should not error if it is greater than 15 characters as long as the DNS query limit is not surpassed","suites":["MongoOptions","when loadBalanced is in the options object"],"updatePoint":{"line":718,"column":121,"index":30751},"line":718,"code":"  it('srvServiceName should not error if it is greater than 15 characters as long as the DNS query limit is not surpassed', async () => {\n    let thrownError;\n    let options;\n\n    try {\n      options = parseOptions('mongodb+srv://localhost.a.com', {\n        srvServiceName: 'a'.repeat(16)\n      });\n      await promisify(resolveSRVRecord)(options);\n    } catch (error) {\n      thrownError = error;\n    } // Nothing wrong with the name, just DNE\n\n\n    expect(thrownError).to.have.property('code', 'ENOTFOUND');\n  });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should set the database name to the dbName in the uri","suites":["MongoOptions","dbName and authSource","in the URI"],"updatePoint":{"line":736,"column":63,"index":31289},"line":736,"code":"      it('should set the database name to the dbName in the uri', () => {\n        const client = new MongoClient('mongodb://u:p@host/myDb');\n        const db = client.db();\n        expect(db).to.have.property('databaseName', 'myDb');\n        expect(client).to.have.nested.property('options.credentials.source', 'myDb');\n      });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should set the database name to the uri pathname and respect the authSource option","suites":["MongoOptions","dbName and authSource","in the URI"],"updatePoint":{"line":742,"column":92,"index":31648},"line":742,"code":"      it('should set the database name to the uri pathname and respect the authSource option', () => {\n        const client = new MongoClient('mongodb://u:p@host/myDb?authSource=myAuthDb');\n        const db = client.db();\n        expect(db).to.have.property('databaseName', 'myDb');\n        expect(client).to.have.nested.property('options.credentials.source', 'myAuthDb');\n      });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should set the database name to the uri pathname and respect the authSource option in options object","suites":["MongoOptions","dbName and authSource","in the URI"],"updatePoint":{"line":748,"column":110,"index":32049},"line":748,"code":"      it('should set the database name to the uri pathname and respect the authSource option in options object', () => {\n        const client = new MongoClient('mongodb://u:p@host/myDb', {\n          authSource: 'myAuthDb'\n        });\n        const db = client.db();\n        expect(db).to.have.property('databaseName', 'myDb');\n        expect(client).to.have.nested.property('options.credentials.source', 'myAuthDb');\n      });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should set the database name to the dbName in the options object","suites":["MongoOptions","dbName and authSource","in the options object"],"updatePoint":{"line":758,"column":74,"index":32494},"line":758,"code":"      it('should set the database name to the dbName in the options object', () => {\n        const client = new MongoClient('mongodb://u:p@host', {\n          dbName: 'myDb'\n        });\n        const db = client.db();\n        expect(db).to.have.property('databaseName', 'myDb');\n        expect(client).to.have.nested.property('options.credentials.source', 'myDb');\n      });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should set the database name to dbName and respect the authSource option","suites":["MongoOptions","dbName and authSource","in the options object"],"updatePoint":{"line":766,"column":82,"index":32876},"line":766,"code":"      it('should set the database name to dbName and respect the authSource option', () => {\n        const client = new MongoClient('mongodb://u:p@host?authSource=myAuthDb', {\n          dbName: 'myDb'\n        });\n        const db = client.db();\n        expect(db).to.have.property('databaseName', 'myDb');\n        expect(client).to.have.nested.property('options.credentials.source', 'myAuthDb');\n      });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should set the database name to dbName and respect the authSource option in options object","suites":["MongoOptions","dbName and authSource","in the options object"],"updatePoint":{"line":774,"column":100,"index":33300},"line":774,"code":"      it('should set the database name to dbName and respect the authSource option in options object', () => {\n        const client = new MongoClient('mongodb://u:p@host', {\n          dbName: 'myDb',\n          authSource: 'myAuthDb'\n        });\n        const db = client.db();\n        expect(db).to.have.property('databaseName', 'myDb');\n        expect(client).to.have.nested.property('options.credentials.source', 'myAuthDb');\n      });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"should set the database name to dbName in options object and respect the authSource option in options object","suites":["MongoOptions","dbName and authSource","in the options object"],"updatePoint":{"line":783,"column":118,"index":33756},"line":783,"code":"      it('should set the database name to dbName in options object and respect the authSource option in options object', () => {\n        const client = new MongoClient('mongodb://u:p@host/myIgnoredDb', {\n          dbName: 'myDb',\n          authSource: 'myAuthDb'\n        });\n        const db = client.db();\n        expect(db).to.have.property('databaseName', 'myDb');\n        expect(client).to.have.nested.property('options.credentials.source', 'myAuthDb');\n      });","file":"unit/mongo_client.test.js","skipped":false,"dir":"test"},{"name":"sets trySecondaryWrite to true","suites":["AggregateOperation","#constructor","when out is in the options"],"updatePoint":{"line":19,"column":40,"index":445},"line":19,"code":"      it('sets trySecondaryWrite to true', function () {\n        expect(operation.trySecondaryWrite).to.be.true;\n      });","file":"unit/operations/aggregate.test.js","skipped":false,"dir":"test"},{"name":"sets trySecondaryWrite to true","suites":["AggregateOperation","#constructor","when $out is the last stage"],"updatePoint":{"line":29,"column":40,"index":749},"line":29,"code":"      it('sets trySecondaryWrite to true', function () {\n        expect(operation.trySecondaryWrite).to.be.true;\n      });","file":"unit/operations/aggregate.test.js","skipped":false,"dir":"test"},{"name":"sets trySecondaryWrite to false","suites":["AggregateOperation","#constructor","when $out is not the last stage"],"updatePoint":{"line":43,"column":41,"index":1117},"line":43,"code":"      it('sets trySecondaryWrite to false', function () {\n        expect(operation.trySecondaryWrite).to.be.false;\n      });","file":"unit/operations/aggregate.test.js","skipped":false,"dir":"test"},{"name":"sets trySecondaryWrite to true","suites":["AggregateOperation","#constructor","when $merge is the last stage"],"updatePoint":{"line":55,"column":40,"index":1454},"line":55,"code":"      it('sets trySecondaryWrite to true', function () {\n        expect(operation.trySecondaryWrite).to.be.true;\n      });","file":"unit/operations/aggregate.test.js","skipped":false,"dir":"test"},{"name":"sets trySecondaryWrite to false","suites":["AggregateOperation","#constructor","when $merge is not the last stage"],"updatePoint":{"line":71,"column":41,"index":1854},"line":71,"code":"      it('sets trySecondaryWrite to false', function () {\n        expect(operation.trySecondaryWrite).to.be.false;\n      });","file":"unit/operations/aggregate.test.js","skipped":false,"dir":"test"},{"name":"sets trySecondaryWrite to false","suites":["AggregateOperation","#constructor","when no writable stages in empty pipeline"],"updatePoint":{"line":79,"column":41,"index":2144},"line":79,"code":"      it('sets trySecondaryWrite to false', function () {\n        expect(operation.trySecondaryWrite).to.be.false;\n      });","file":"unit/operations/aggregate.test.js","skipped":false,"dir":"test"},{"name":"sets trySecondaryWrite to false","suites":["AggregateOperation","#constructor","when no writable stages"],"updatePoint":{"line":91,"column":41,"index":2473},"line":91,"code":"      it('sets trySecondaryWrite to false', function () {\n        expect(operation.trySecondaryWrite).to.be.false;\n      });","file":"unit/operations/aggregate.test.js","skipped":false,"dir":"test"},{"name":"sets nameOnly to true","suites":["ListCollectionsOperation","#constructor","when nameOnly is provided","when nameOnly is true"],"updatePoint":{"line":20,"column":33,"index":526},"line":20,"code":"        it('sets nameOnly to true', function () {\n          expect(operation).to.have.property('nameOnly', true);\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets nameOnly to false","suites":["ListCollectionsOperation","#constructor","when nameOnly is provided","when nameOnly is false"],"updatePoint":{"line":29,"column":34,"index":842},"line":29,"code":"        it('sets nameOnly to false', function () {\n          expect(operation).to.have.property('nameOnly', false);\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets authorizedCollections to true","suites":["ListCollectionsOperation","#constructor","when authorizedCollections is provided","when authorizedCollections is true"],"updatePoint":{"line":40,"column":46,"index":1271},"line":40,"code":"        it('sets authorizedCollections to true', function () {\n          expect(operation).to.have.property('authorizedCollections', true);\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets authorizedCollections to false","suites":["ListCollectionsOperation","#constructor","when authorizedCollections is provided","when authorizedCollections is false"],"updatePoint":{"line":49,"column":47,"index":1639},"line":49,"code":"        it('sets authorizedCollections to false', function () {\n          expect(operation).to.have.property('authorizedCollections', false);\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets nameOnly to false","suites":["ListCollectionsOperation","#constructor","when no options are provided"],"updatePoint":{"line":58,"column":32,"index":1946},"line":58,"code":"      it('sets nameOnly to false', function () {\n        expect(operation).to.have.property('nameOnly', false);\n      });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets authorizedCollections to false","suites":["ListCollectionsOperation","#constructor","when no options are provided"],"updatePoint":{"line":61,"column":45,"index":2081},"line":61,"code":"      it('sets authorizedCollections to false', function () {\n        expect(operation).to.have.property('authorizedCollections', false);\n      });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"does not set a comment on the command","suites":["ListCollectionsOperation","#generateCommand","when comment is provided","when the wireVersion < 9"],"updatePoint":{"line":69,"column":49,"index":2402},"line":69,"code":"        it('does not set a comment on the command', function () {\n          const operation = new ListCollectionsOperation(db, {}, {\n            dbName: db,\n            comment: 'test comment'\n          });\n          const command = operation.generateCommand(8);\n          expect(command).not.to.haveOwnProperty('comment');\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets a comment on the command","suites":["ListCollectionsOperation","#generateCommand","when comment is provided","when the wireVersion >= 9"],"updatePoint":{"line":79,"column":41,"index":2797},"line":79,"code":"        it('sets a comment on the command', function () {\n          const operation = new ListCollectionsOperation(db, {}, {\n            dbName: db,\n            comment: 'test comment'\n          });\n          const command = operation.generateCommand(9);\n          expect(command).to.have.property('comment').that.equals('test comment');\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets nameOnly to true","suites":["ListCollectionsOperation","#generateCommand","when nameOnly is provided","when nameOnly is true"],"updatePoint":{"line":95,"column":33,"index":3389},"line":95,"code":"        it('sets nameOnly to true', function () {\n          expect(operation.generateCommand(8)).to.deep.equal({\n            listCollections: 1,\n            cursor: {},\n            filter: {},\n            nameOnly: true,\n            authorizedCollections: false\n          });\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets nameOnly to false","suites":["ListCollectionsOperation","#generateCommand","when nameOnly is provided","when nameOnly is false"],"updatePoint":{"line":110,"column":34,"index":3867},"line":110,"code":"        it('sets nameOnly to false', function () {\n          expect(operation.generateCommand(8)).to.deep.equal({\n            listCollections: 1,\n            cursor: {},\n            filter: {},\n            nameOnly: false,\n            authorizedCollections: false\n          });\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets authorizedCollections to true","suites":["ListCollectionsOperation","#generateCommand","when authorizedCollections is provided","when authorizedCollections is true"],"updatePoint":{"line":127,"column":46,"index":4458},"line":127,"code":"        it('sets authorizedCollections to true', function () {\n          expect(operation.generateCommand(8)).to.deep.equal({\n            listCollections: 1,\n            cursor: {},\n            filter: {},\n            nameOnly: false,\n            authorizedCollections: true\n          });\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets authorizedCollections to false","suites":["ListCollectionsOperation","#generateCommand","when authorizedCollections is provided","when authorizedCollections is false"],"updatePoint":{"line":142,"column":47,"index":4975},"line":142,"code":"        it('sets authorizedCollections to false', function () {\n          expect(operation.generateCommand(8)).to.deep.equal({\n            listCollections: 1,\n            cursor: {},\n            filter: {},\n            nameOnly: false,\n            authorizedCollections: false\n          });\n        });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"sets nameOnly and authorizedCollections properties to false","suites":["ListCollectionsOperation","#generateCommand","when no options are provided"],"updatePoint":{"line":157,"column":69,"index":5468},"line":157,"code":"      it('sets nameOnly and authorizedCollections properties to false', function () {\n        expect(operation.generateCommand(8)).to.deep.equal({\n          listCollections: 1,\n          cursor: {},\n          filter: {},\n          nameOnly: false,\n          authorizedCollections: false\n        });\n      });","file":"unit/operations/list_collections.test.js","skipped":false,"dir":"test"},{"name":"should record roundTripTime","suites":["monitoring"],"line":53,"code":"  it.skip('should record roundTripTime', function (done) {","file":"unit/sdam/monitor.test.js","skipped":true,"dir":"test"},{"name":"should recover on error during initial connect","suites":["monitoring"],"line":80,"code":"  it.skip('should recover on error during initial connect', function (done) {","file":"unit/sdam/monitor.test.js","skipped":true,"dir":"test"},{"name":"should connect and issue an initial server check","suites":["monitoring","Monitor"],"updatePoint":{"line":125,"column":56,"index":3622},"line":125,"code":"    it('should connect and issue an initial server check', function (done) {\n      mockServer.setMessageHandler(request => {\n        const doc = request.document;\n\n        if (isHello(doc)) {\n          request.reply(Object.assign({}, mock.HELLO));\n        }\n      });\n      const server = new MockServer(mockServer.address());\n      monitor = new Monitor(server, {});\n      monitor.on('serverHeartbeatFailed', () => done(new Error('unexpected heartbeat failure')));\n      monitor.on('serverHeartbeatSucceeded', () => done());\n      monitor.connect();\n    });","file":"unit/sdam/monitor.test.js","skipped":false,"dir":"test"},{"name":"should ignore attempts to connect when not already closed","suites":["monitoring","Monitor"],"updatePoint":{"line":139,"column":65,"index":4190},"line":139,"code":"    it('should ignore attempts to connect when not already closed', function (done) {\n      mockServer.setMessageHandler(request => {\n        const doc = request.document;\n\n        if (isHello(doc)) {\n          request.reply(Object.assign({}, mock.HELLO));\n        }\n      });\n      const server = new MockServer(mockServer.address());\n      monitor = new Monitor(server, {});\n      monitor.on('serverHeartbeatFailed', () => done(new Error('unexpected heartbeat failure')));\n      monitor.on('serverHeartbeatSucceeded', () => done());\n      monitor.connect();\n      monitor.connect();\n    });","file":"unit/sdam/monitor.test.js","skipped":false,"dir":"test"},{"name":"should not initiate another check if one is in progress","suites":["monitoring","Monitor"],"updatePoint":{"line":154,"column":63,"index":4781},"line":154,"code":"    it('should not initiate another check if one is in progress', function (done) {\n      mockServer.setMessageHandler(request => {\n        const doc = request.document;\n\n        if (isHello(doc)) {\n          setTimeout(() => request.reply(Object.assign({}, mock.HELLO)), 250);\n        }\n      });\n      const server = new MockServer(mockServer.address());\n      monitor = new Monitor(server, {});\n      const startedEvents = [];\n      monitor.on('serverHeartbeatStarted', event => startedEvents.push(event));\n      monitor.on('close', () => {\n        expect(startedEvents).to.have.length(2);\n        done();\n      });\n      monitor.connect();\n      monitor.once('serverHeartbeatSucceeded', () => {\n        monitor.requestCheck();\n        monitor.requestCheck();\n        monitor.requestCheck();\n        monitor.requestCheck();\n        monitor.requestCheck();\n        const minHeartbeatFrequencyMS = 500;\n        setTimeout(() => {\n          // wait for minHeartbeatFrequencyMS, then request a check and verify another check occurred\n          monitor.once('serverHeartbeatSucceeded', () => {\n            monitor.close();\n          });\n          monitor.requestCheck();\n        }, minHeartbeatFrequencyMS);\n      });\n    });","file":"unit/sdam/monitor.test.js","skipped":false,"dir":"test"},{"name":"should not close the monitor on a failed heartbeat","suites":["monitoring","Monitor"],"updatePoint":{"line":187,"column":58,"index":6000},"line":187,"code":"    it('should not close the monitor on a failed heartbeat', function (done) {\n      let helloCount = 0;\n      mockServer.setMessageHandler(request => {\n        const doc = request.document;\n\n        if (isHello(doc)) {\n          helloCount++;\n\n          if (helloCount === 2) {\n            request.reply({\n              ok: 0,\n              errmsg: 'forced from mock server'\n            });\n            return;\n          }\n\n          if (helloCount === 3) {\n            request.connection.destroy();\n            return;\n          }\n\n          request.reply(mock.HELLO);\n        }\n      });\n      const server = new MockServer(mockServer.address());\n      server.description = new ServerDescription(server.description.hostAddress);\n      monitor = new Monitor(server, {\n        heartbeatFrequencyMS: 250,\n        minHeartbeatFrequencyMS: 50\n      });\n      const events = [];\n      monitor.on('serverHeartbeatFailed', event => events.push(event));\n      let successCount = 0;\n      monitor.on('serverHeartbeatSucceeded', () => {\n        if (successCount++ === 2) {\n          monitor.close();\n        }\n      });\n      monitor.on('close', () => {\n        expect(events).to.have.length(2);\n        done();\n      });\n      monitor.connect();\n    });","file":"unit/sdam/monitor.test.js","skipped":false,"dir":"test"},{"name":"should upgrade to hello from legacy hello when initial handshake contains helloOk","suites":["monitoring","Monitor"],"updatePoint":{"line":231,"column":89,"index":7278},"line":231,"code":"    it('should upgrade to hello from legacy hello when initial handshake contains helloOk', function (done) {\n      const docs = [];\n      mockServer.setMessageHandler(request => {\n        const doc = request.document;\n        docs.push(doc);\n\n        if (docs.length === 2) {\n          expect(docs[0]).to.have.property(LEGACY_HELLO_COMMAND, true);\n          expect(docs[0]).to.have.property('helloOk', true);\n          expect(docs[1]).to.have.property('hello', true);\n          done();\n        } else if (isHello(doc)) {\n          setTimeout(() => request.reply(Object.assign({\n            helloOk: true\n          }, mock.HELLO)), 250);\n        }\n      });\n      const server = new MockServer(mockServer.address());\n      monitor = new Monitor(server, {});\n      monitor.connect();\n      monitor.once('serverHeartbeatSucceeded', () => {\n        const minHeartbeatFrequencyMS = 500;\n        setTimeout(() => {\n          // wait for minHeartbeatFrequencyMS, then request a check and verify another check occurred\n          monitor.once('serverHeartbeatSucceeded', () => {\n            monitor.close();\n          });\n          monitor.requestCheck();\n        }, minHeartbeatFrequencyMS);\n      });\n    });","file":"unit/sdam/monitor.test.js","skipped":false,"dir":"test"},{"name":"should sensibly parse an ipv6 address","suites":["ServerDescription","error equality"],"updatePoint":{"line":62,"column":43,"index":1813},"line":62,"code":"  it('should sensibly parse an ipv6 address', function () {\n    const description = new ServerDescription('[ABCD:f::abcd:abcd:abcd:abcd]:27017');\n    expect(description.host).to.equal('abcd:f::abcd:abcd:abcd:abcd');\n    expect(description.port).to.equal(27017);\n  });","file":"unit/sdam/server_description.test.js","skipped":false,"dir":"test"},{"name":"returns an empty array","suites":["server selection","#sameServerSelector","when the server is unknown"],"updatePoint":{"line":76,"column":32,"index":1857},"line":76,"code":"      it('returns an empty array', function () {\n        expect(servers).to.be.empty;\n      });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"returns the server","suites":["server selection","#sameServerSelector","when the server is not unknown"],"updatePoint":{"line":84,"column":28,"index":2102},"line":84,"code":"      it('returns the server', function () {\n        expect(servers).to.deep.equal([primary]);\n      });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"returns an empty array","suites":["server selection","#sameServerSelector","when no server description provided"],"updatePoint":{"line":92,"column":32,"index":2362},"line":92,"code":"      it('returns an empty array', function () {\n        expect(servers).to.be.empty;\n      });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"returns an empty array","suites":["server selection","#sameServerSelector","when the server is not the same"],"updatePoint":{"line":100,"column":32,"index":2614},"line":100,"code":"      it('returns an empty array', function () {\n        expect(servers).to.be.empty;\n      });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"uses the provided read preference","suites":["server selection","#secondaryWritableServerSelector","when the topology is a replica set","when the common server version is >= 5.0","when a read preference is provided"],"updatePoint":{"line":115,"column":47,"index":3591},"line":115,"code":"          it('uses the provided read preference', function () {\n            expect(servers).to.deep.equal([secondary]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a primary","suites":["server selection","#secondaryWritableServerSelector","when the topology is a replica set","when the common server version is >= 5.0","when a read preference is not provided"],"updatePoint":{"line":122,"column":31,"index":3985},"line":122,"code":"          it('selects a primary', function () {\n            expect(servers).to.deep.equal([primary]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a primary","suites":["server selection","#secondaryWritableServerSelector","when the topology is a replica set","when the common server version is < 5.0","when a read preference is provided"],"updatePoint":{"line":132,"column":31,"index":4697},"line":132,"code":"          it('selects a primary', function () {\n            expect(servers).to.deep.equal([primary]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a primary","suites":["server selection","#secondaryWritableServerSelector","when the topology is a replica set","when the common server version is < 5.0","when read preference is not provided"],"updatePoint":{"line":139,"column":31,"index":5091},"line":139,"code":"          it('selects a primary', function () {\n            expect(servers).to.deep.equal([primary]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a primary","suites":["server selection","#secondaryWritableServerSelector","when the topology is a replica set","when a common wire version is not provided"],"updatePoint":{"line":148,"column":29,"index":5701},"line":148,"code":"        it('selects a primary', function () {\n          expect(servers).to.deep.equal([primary]);\n        });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a mongos","suites":["server selection","#secondaryWritableServerSelector","when the topology is sharded","when the common server version is >= 5.0","when a read preference is provided"],"updatePoint":{"line":161,"column":30,"index":6539},"line":161,"code":"          it('selects a mongos', function () {\n            expect(servers).to.deep.equal([mongos]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a mongos","suites":["server selection","#secondaryWritableServerSelector","when the topology is sharded","when the common server version is >= 5.0","when a read preference is not provided"],"updatePoint":{"line":168,"column":30,"index":6929},"line":168,"code":"          it('selects a mongos', function () {\n            expect(servers).to.deep.equal([mongos]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a mongos","suites":["server selection","#secondaryWritableServerSelector","when the topology is sharded","when the common server version is < 5.0","when a read preference is provided"],"updatePoint":{"line":178,"column":30,"index":7625},"line":178,"code":"          it('selects a mongos', function () {\n            expect(servers).to.deep.equal([mongos]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a mongos","suites":["server selection","#secondaryWritableServerSelector","when the topology is sharded","when the common server version is < 5.0","when read preference is not provided"],"updatePoint":{"line":185,"column":30,"index":8017},"line":185,"code":"          it('selects a mongos', function () {\n            expect(servers).to.deep.equal([mongos]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a mongos","suites":["server selection","#secondaryWritableServerSelector","when the topology is sharded","when a common wire version is not provided"],"updatePoint":{"line":194,"column":28,"index":8576},"line":194,"code":"        it('selects a mongos', function () {\n          expect(servers).to.deep.equal([mongos]);\n        });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a load balancer","suites":["server selection","#secondaryWritableServerSelector","when the topology is load balanced","when the common server version is >= 5.0","when a read preference is provided"],"updatePoint":{"line":207,"column":37,"index":9443},"line":207,"code":"          it('selects a load balancer', function () {\n            expect(servers).to.deep.equal([loadBalancer]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a load balancer","suites":["server selection","#secondaryWritableServerSelector","when the topology is load balanced","when the common server version is >= 5.0","when a read preference is not provided"],"updatePoint":{"line":214,"column":37,"index":9846},"line":214,"code":"          it('selects a load balancer', function () {\n            expect(servers).to.deep.equal([loadBalancer]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a load balancer","suites":["server selection","#secondaryWritableServerSelector","when the topology is load balanced","when the common server version is < 5.0","when a read preference is provided"],"updatePoint":{"line":224,"column":37,"index":10560},"line":224,"code":"          it('selects a load balancer', function () {\n            expect(servers).to.deep.equal([loadBalancer]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a load balancer","suites":["server selection","#secondaryWritableServerSelector","when the topology is load balanced","when the common server version is < 5.0","when read preference is not provided"],"updatePoint":{"line":231,"column":37,"index":10965},"line":231,"code":"          it('selects a load balancer', function () {\n            expect(servers).to.deep.equal([loadBalancer]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a load balancer","suites":["server selection","#secondaryWritableServerSelector","when the topology is load balanced","when a common wire version is not provided"],"updatePoint":{"line":240,"column":35,"index":11542},"line":240,"code":"        it('selects a load balancer', function () {\n          expect(servers).to.deep.equal([loadBalancer]);\n        });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a standalone","suites":["server selection","#secondaryWritableServerSelector","when the topology is single","when the common server version is >= 5.0","when a read preference is provided"],"updatePoint":{"line":253,"column":34,"index":12387},"line":253,"code":"          it('selects a standalone', function () {\n            expect(servers).to.deep.equal([single]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a standalone","suites":["server selection","#secondaryWritableServerSelector","when the topology is single","when the common server version is >= 5.0","when a read preference is not provided"],"updatePoint":{"line":260,"column":34,"index":12781},"line":260,"code":"          it('selects a standalone', function () {\n            expect(servers).to.deep.equal([single]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a standalone","suites":["server selection","#secondaryWritableServerSelector","when the topology is single","when the common server version is < 5.0","when a read preference is provided"],"updatePoint":{"line":270,"column":34,"index":13480},"line":270,"code":"          it('selects a standalone', function () {\n            expect(servers).to.deep.equal([single]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a standalone","suites":["server selection","#secondaryWritableServerSelector","when the topology is single","when the common server version is < 5.0","when read preference is not provided"],"updatePoint":{"line":277,"column":34,"index":13876},"line":277,"code":"          it('selects a standalone', function () {\n            expect(servers).to.deep.equal([single]);\n          });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"selects a standalone","suites":["server selection","#secondaryWritableServerSelector","when the topology is single","when a common wire version is not provided"],"updatePoint":{"line":286,"column":32,"index":14438},"line":286,"code":"        it('selects a standalone', function () {\n          expect(servers).to.deep.equal([single]);\n        });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"includes servers inside the latency window with default localThresholdMS","suites":["server selection","#secondaryWritableServerSelector","localThresholdMS is respected as an option"],"updatePoint":{"line":320,"column":82,"index":15688},"line":320,"code":"      it('includes servers inside the latency window with default localThresholdMS', function () {\n        const topologyDescription = new TopologyDescription(TopologyType.Single, serverDescriptions, 'test', MIN_SECONDARY_WRITE_WIRE_VERSION, new ObjectId(), MIN_SECONDARY_WRITE_WIRE_VERSION);\n        const selector = secondaryWritableServerSelector();\n        const servers = selector(topologyDescription, Array.from(serverDescriptions.values()));\n        expect(servers).to.have.lengthOf(2);\n        const selectedAddresses = new Set(servers.map(({\n          address\n        }) => address));\n        expect(selectedAddresses.has(serverDescription1.address)).to.be.true;\n        expect(selectedAddresses.has(serverDescription2.address)).to.be.true;\n        expect(selectedAddresses.has(serverDescription3.address)).to.be.false;\n      });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"includes servers inside the latency window with custom localThresholdMS","suites":["server selection","#secondaryWritableServerSelector","localThresholdMS is respected as an option"],"updatePoint":{"line":332,"column":81,"index":16526},"line":332,"code":"      it('includes servers inside the latency window with custom localThresholdMS', function () {\n        const topologyDescription = new TopologyDescription(TopologyType.Single, serverDescriptions, 'test', MIN_SECONDARY_WRITE_WIRE_VERSION, new ObjectId(), MIN_SECONDARY_WRITE_WIRE_VERSION, {\n          localThresholdMS: 5\n        });\n        const selector = secondaryWritableServerSelector();\n        const servers = selector(topologyDescription, Array.from(serverDescriptions.values()));\n        expect(servers).to.have.lengthOf(1);\n        const selectedAddresses = new Set(servers.map(({\n          address\n        }) => address));\n        expect(selectedAddresses.has(serverDescription1.address)).to.be.true;\n        expect(selectedAddresses.has(serverDescription2.address)).to.be.false;\n        expect(selectedAddresses.has(serverDescription3.address)).to.be.false;\n      });","file":"unit/sdam/server_selection.test.js","skipped":false,"dir":"test"},{"name":"should always return a valid value for `intervalMS`","suites":["Mongos SRV Polling","SrvPoller"],"updatePoint":{"line":89,"column":59,"index":1860},"line":89,"code":"    it('should always return a valid value for `intervalMS`', function () {\n      const poller = new SrvPoller({\n        srvHost: SRV_HOST\n      });\n      expect(poller).property('intervalMS').to.equal(60000);\n    });","file":"unit/sdam/srv_polling.test.js","skipped":false,"dir":"test"},{"name":"should emit event, disable haMode, and schedule another poll","suites":["Mongos SRV Polling","SrvPoller","success"],"updatePoint":{"line":96,"column":70,"index":2127},"line":96,"code":"      it('should emit event, disable haMode, and schedule another poll', function (done) {\n        const records = [srvRecord('jalad.tanagra.com'), srvRecord('thebeast.tanagra.com')];\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        context.sinon.stub(poller, 'schedule');\n        poller.haMode = true;\n        expect(poller).to.have.property('haMode', true);\n        poller.once('srvRecordDiscovery', e => {\n          tryDone(done, () => {\n            expect(e).to.be.an.instanceOf(SrvPollingEvent).and.to.have.property('srvRecords').that.deep.equals(records);\n            expect(poller.schedule).to.have.been.calledOnce;\n            expect(poller).to.have.property('haMode', false);\n          });\n        });\n        poller.success(records);\n      });","file":"unit/sdam/srv_polling.test.js","skipped":false,"dir":"test"},{"name":"should enable haMode and schedule","suites":["Mongos SRV Polling","SrvPoller","failure"],"updatePoint":{"line":115,"column":43,"index":2938},"line":115,"code":"      it('should enable haMode and schedule', function () {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        context.sinon.stub(poller, 'schedule');\n        poller.failure('Some kind of failure');\n        expect(poller.schedule).to.have.been.calledOnce;\n        expect(poller).to.have.property('haMode', true);\n      });","file":"unit/sdam/srv_polling.test.js","skipped":false,"dir":"test"},{"name":"should throw if srvHost is not passed in","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":126,"column":50,"index":3347},"line":126,"code":"      it('should throw if srvHost is not passed in', function () {\n        expect(() => new SrvPoller()).to.throw(MongoDriverError);\n        expect(() => new SrvPoller({})).to.throw(MongoDriverError);\n      });","file":"unit/sdam/srv_polling.test.js","skipped":false,"dir":"test"},{"name":"should poll dns srv records","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":130,"column":37,"index":3545},"line":130,"code":"      it('should poll dns srv records', function () {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        context.sinon.stub(dns, 'resolveSrv');\n\n        poller._poll();\n\n        expect(dns.resolveSrv).to.have.been.calledOnce.and.to.have.been.calledWith(`_mongodb._tcp.${SRV_HOST}`, sinon.match.func);\n      });","file":"unit/sdam/srv_polling.test.js","skipped":false,"dir":"test"},{"name":"should not succeed or fail if poller was stopped","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":140,"column":58,"index":3913},"line":140,"code":"      it('should not succeed or fail if poller was stopped', function (done) {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        stubDns(null, []);\n        stubPoller(poller);\n\n        poller._poll();\n\n        poller.generation += 1;\n        tryDone(done, () => {\n          expect(poller.success).to.not.have.been.called;\n          expect(poller.failure).to.not.have.been.called;\n          expect(poller.parentDomainMismatch).to.not.have.been.called;\n        });\n      });","file":"unit/sdam/srv_polling.test.js","skipped":false,"dir":"test"},{"name":"should fail if dns returns error","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":156,"column":42,"index":4407},"line":156,"code":"      it('should fail if dns returns error', function (done) {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        stubDns(new Error('Some Error'));\n        stubPoller(poller);\n\n        poller._poll();\n\n        tryDone(done, () => {\n          expect(poller.success).to.not.have.been.called;\n          expect(poller.failure).to.have.been.calledOnce.and.calledWith('DNS error');\n          expect(poller.parentDomainMismatch).to.not.have.been.called;\n        });\n      });","file":"unit/sdam/srv_polling.test.js","skipped":false,"dir":"test"},{"name":"should fail if dns returns no records","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":171,"column":47,"index":4917},"line":171,"code":"      it('should fail if dns returns no records', function (done) {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        stubDns(null, []);\n        stubPoller(poller);\n\n        poller._poll();\n\n        tryDone(done, () => {\n          expect(poller.success).to.not.have.been.called;\n          expect(poller.failure).to.have.been.calledOnce.and.calledWith('No valid addresses found at host');\n          expect(poller.parentDomainMismatch).to.not.have.been.called;\n        });\n      });","file":"unit/sdam/srv_polling.test.js","skipped":false,"dir":"test"},{"name":"should fail if dns returns no records that match parent domain","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":186,"column":72,"index":5460},"line":186,"code":"      it('should fail if dns returns no records that match parent domain', function (done) {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        const records = [srvRecord('jalad.tanagra.org'), srvRecord('shaka.walls.com')];\n        stubDns(null, records);\n        stubPoller(poller);\n\n        poller._poll();\n\n        tryDone(done, () => {\n          expect(poller.success).to.not.have.been.called;\n          expect(poller.failure).to.have.been.calledOnce.and.calledWith('No valid addresses found at host');\n          expect(poller.parentDomainMismatch).to.have.been.calledTwice.and.calledWith(records[0]).and.calledWith(records[1]);\n        });\n      });","file":"unit/sdam/srv_polling.test.js","skipped":false,"dir":"test"},{"name":"should succeed when valid records are returned by dns","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":202,"column":63,"index":6142},"line":202,"code":"      it('should succeed when valid records are returned by dns', function (done) {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        const records = [srvRecord('jalad.tanagra.com'), srvRecord('thebeast.tanagra.com')];\n        stubDns(null, records);\n        stubPoller(poller);\n\n        poller._poll();\n\n        tryDone(done, () => {\n          expect(poller.success).to.have.been.calledOnce.and.calledWithMatch(records);\n          expect(poller.failure).to.not.have.been.called;\n          expect(poller.parentDomainMismatch).to.not.have.been.called;\n        });\n      });","file":"unit/sdam/srv_polling.test.js","skipped":false,"dir":"test"},{"name":"should succeed when some valid records are returned and some do not match parent domain","suites":["Mongos SRV Polling","SrvPoller","poll"],"updatePoint":{"line":218,"column":97,"index":6786},"line":218,"code":"      it('should succeed when some valid records are returned and some do not match parent domain', function (done) {\n        const poller = new SrvPoller({\n          srvHost: SRV_HOST\n        });\n        const records = [srvRecord('jalad.tanagra.com'), srvRecord('thebeast.walls.com')];\n        stubDns(null, records);\n        stubPoller(poller);\n\n        poller._poll();\n\n        tryDone(done, () => {\n          expect(poller.success).to.have.been.calledOnce.and.calledWithMatch([records[0]]);\n          expect(poller.failure).to.not.have.been.called;\n          expect(poller.parentDomainMismatch).to.have.been.calledOnce.and.calledWith(records[1]);\n        });\n      });","file":"unit/sdam/srv_polling.test.js","skipped":false,"dir":"test"},{"name":"should not make an srv poller if there is no srv host","suites":["Mongos SRV Polling","topology"],"updatePoint":{"line":248,"column":61,"index":7675},"line":248,"code":"    it('should not make an srv poller if there is no srv host', function () {\n      const srvPoller = new FakeSrvPoller({\n        srvHost: SRV_HOST\n      });\n      const topology = new Topology(['localhost:27017', 'localhost:27018'], {\n        srvPoller\n      });\n      expect(topology).to.not.have.property('srvPoller');\n    });","file":"unit/sdam/srv_polling.test.js","skipped":false,"dir":"test"},{"name":"should make an srvPoller if there is an srvHost","suites":["Mongos SRV Polling","topology"],"updatePoint":{"line":257,"column":55,"index":7999},"line":257,"code":"    it('should make an srvPoller if there is an srvHost', function () {\n      const srvPoller = new FakeSrvPoller({\n        srvHost: SRV_HOST\n      });\n      const topology = new Topology(['localhost:27017', 'localhost:27018'], {\n        srvHost: SRV_HOST,\n        srvPoller\n      });\n      expect(topology.s).to.have.property('srvPoller').that.equals(srvPoller);\n    });","file":"unit/sdam/srv_polling.test.js","skipped":false,"dir":"test"},{"name":"should only start polling if topology description changes to sharded","suites":["Mongos SRV Polling","topology"],"updatePoint":{"line":267,"column":76,"index":8392},"line":267,"code":"    it('should only start polling if topology description changes to sharded', function () {\n      const srvPoller = new FakeSrvPoller({\n        srvHost: SRV_HOST\n      });\n      sinon.stub(srvPoller, 'start');\n      const topology = new Topology(['localhost:27017', 'localhost:27018'], {\n        srvHost: SRV_HOST,\n        srvPoller\n      });\n      const topologyDescriptions = [new TopologyDescription(TopologyType.Unknown), new TopologyDescription(TopologyType.Unknown), new TopologyDescription(TopologyType.Sharded), new TopologyDescription(TopologyType.Sharded)];\n\n      function emit(prev, current) {\n        topology.emit('topologyDescriptionChanged', new sdamEvents.TopologyDescriptionChangedEvent(topology.s.id, prev, current));\n      }\n\n      expect(srvPoller.start).to.not.have.been.called;\n      emit(topologyDescriptions[0], topologyDescriptions[1]);\n      expect(srvPoller.start).to.not.have.been.called;\n      emit(topologyDescriptions[1], topologyDescriptions[2]);\n      expect(srvPoller.start).to.have.been.calledOnce;\n      emit(topologyDescriptions[2], topologyDescriptions[3]);\n      expect(srvPoller.start).to.have.been.calledOnce;\n    });","file":"unit/sdam/srv_polling.test.js","skipped":false,"dir":"test"},{"name":"should correctly pass appname","suites":["Topology (unit)","client metadata"],"updatePoint":{"line":77,"column":37,"index":1437},"line":77,"code":"    it('should correctly pass appname', function (done) {\n      const server = new Topology([`localhost:27017`], {\n        metadata: makeClientMetadata({\n          appName: 'My application name'\n        })\n      });\n      expect(server.clientMetadata.application.name).to.equal('My application name');\n      done();\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should report the correct platform in client metadata","suites":["Topology (unit)","client metadata"],"updatePoint":{"line":86,"column":61,"index":1785},"line":86,"code":"    it('should report the correct platform in client metadata', function (done) {\n      const helloRequests = [];\n      mockServer.setMessageHandler(request => {\n        const doc = request.document;\n\n        if (isHello(doc)) {\n          helloRequests.push(doc);\n          request.reply(mock.HELLO);\n        } else {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      client = new MongoClient(`mongodb://${mockServer.uri()}/`);\n      client.connect(err => {\n        expect(err).to.not.exist;\n        client.db().command({\n          ping: 1\n        }, err => {\n          expect(err).to.not.exist;\n          expect(helloRequests).to.have.length.greaterThan(1);\n          helloRequests.forEach(helloRequest => expect(helloRequest).nested.property('client.platform').to.match(/unified/));\n          done();\n        });\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should check for sessions if connected to a single server and has no known servers","suites":["Topology (unit)","shouldCheckForSessionSupport"],"updatePoint":{"line":129,"column":90,"index":3250},"line":129,"code":"    it('should check for sessions if connected to a single server and has no known servers', function (done) {\n      const topology = new Topology('someserver:27019');\n      this.sinon.stub(Server.prototype, 'connect').callsFake(function () {\n        this.s.state = 'connected';\n        this.emit('connect');\n      });\n      topology.connect(() => {\n        expect(topology.shouldCheckForSessionSupport()).to.be.true;\n        topology.close(done);\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should not check for sessions if connected to a single server","suites":["Topology (unit)","shouldCheckForSessionSupport"],"updatePoint":{"line":140,"column":69,"index":3695},"line":140,"code":"    it('should not check for sessions if connected to a single server', function (done) {\n      const topology = new Topology('someserver:27019');\n      this.sinon.stub(Server.prototype, 'connect').callsFake(function () {\n        this.s.state = 'connected';\n        this.emit('connect');\n        setTimeout(() => {\n          this.emit('descriptionReceived', new ServerDescription('someserver:27019', {\n            ok: 1,\n            maxWireVersion: 6\n          }));\n        }, 20);\n      });\n      topology.connect(() => {\n        expect(topology.shouldCheckForSessionSupport()).to.be.false;\n        topology.close(done);\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should check for sessions if there are no data-bearing nodes","suites":["Topology (unit)","shouldCheckForSessionSupport"],"updatePoint":{"line":157,"column":68,"index":4334},"line":157,"code":"    it('should check for sessions if there are no data-bearing nodes', function (done) {\n      const topology = new Topology(['mongos:27019', 'mongos:27018', 'mongos:27017'], {});\n      this.sinon.stub(Server.prototype, 'connect').callsFake(function () {\n        this.s.state = 'connected';\n        this.emit('connect');\n        setTimeout(() => {\n          this.emit('descriptionReceived', new ServerDescription(this.name, {\n            ok: 1,\n            msg: 'isdbgrid',\n            maxWireVersion: 6\n          }));\n        }, 20);\n      });\n      topology.connect(() => {\n        expect(topology.shouldCheckForSessionSupport()).to.be.false;\n        topology.close(done);\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should time out operations against servers that have been blackholed","suites":["Topology (unit)","black holes"],"updatePoint":{"line":180,"column":76,"index":5217},"line":180,"code":"    it('should time out operations against servers that have been blackholed', function (done) {\n      mockServer.setMessageHandler(request => {\n        const doc = request.document;\n        let initialHelloSent = false;\n\n        if (isHello(doc) && !initialHelloSent) {\n          request.reply(mock.HELLO);\n          initialHelloSent = true;\n        } else {// black hole all other operations\n        }\n      });\n      const topology = new Topology(mockServer.hostAddress());\n      topology.connect(err => {\n        expect(err).to.not.exist;\n        topology.selectServer('primary', {}, (err, server) => {\n          expect(err).to.not.exist;\n          server.command(ns('admin.$cmd'), {\n            ping: 1\n          }, {\n            socketTimeoutMS: 250\n          }, (err, result) => {\n            expect(result).to.not.exist;\n            expect(err).to.exist;\n            expect(err).to.match(/timed out/);\n            topology.close(done);\n          });\n        });\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"returns a MongoServerSelectionError","suites":["Topology (unit)","error handling","when server selection returns a server description but the description is not in the topology","when the topology originally only contained one server"],"updatePoint":{"line":251,"column":47,"index":7459},"line":251,"code":"        it('returns a MongoServerSelectionError', function (done) {\n          topology = new Topology([mockServer.hostAddress(), secondMockServer.hostAddress()]);\n          topology.connect(err => {\n            expect(err).to.not.exist;\n            sinon.stub(topology.s.servers, 'get').callsFake(() => {\n              return undefined;\n            });\n            topology.selectServer('primary', {}, (err, server) => {\n              expect(err).to.be.instanceOf(MongoServerSelectionError);\n              expect(server).not.to.exist;\n              done();\n            });\n          });\n        });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"returns a MongoServerSelectionError","suites":["Topology (unit)","error handling","when server selection returns a server description but the description is not in the topology","when the topology originally contained more than one server"],"updatePoint":{"line":267,"column":47,"index":8159},"line":267,"code":"        it('returns a MongoServerSelectionError', function (done) {\n          topology = new Topology([mockServer.hostAddress(), secondMockServer.hostAddress()]);\n          topology.connect(err => {\n            expect(err).to.not.exist;\n            sinon.stub(topology.s.servers, 'get').callsFake(() => {\n              return undefined;\n            });\n            topology.selectServer('primary', {}, (err, server) => {\n              expect(err).to.be.instanceOf(MongoServerSelectionError);\n              expect(server).not.to.exist;\n              done();\n            });\n          });\n        });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should set server to unknown and reset pool on `node is recovering` error","suites":["Topology (unit)","error handling","when server selection returns a server description but the description is not in the topology","when the topology originally contained more than one server"],"updatePoint":{"line":283,"column":81,"index":8810},"line":283,"code":"    it('should set server to unknown and reset pool on `node is recovering` error', function (done) {\n      mockServer.setMessageHandler(request => {\n        const doc = request.document;\n\n        if (isHello(doc)) {\n          request.reply(Object.assign({}, mock.HELLO, {\n            maxWireVersion: 9\n          }));\n        } else if (doc.insert) {\n          request.reply({\n            ok: 0,\n            message: 'node is recovering',\n            code: 11600\n          });\n        } else {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      topology = new Topology(mockServer.hostAddress());\n      topology.connect(err => {\n        expect(err).to.not.exist;\n        topology.selectServer('primary', {}, (err, server) => {\n          expect(err).to.not.exist;\n          let serverDescription;\n          server.on('descriptionReceived', sd => serverDescription = sd);\n          let poolCleared = false;\n          topology.on('connectionPoolCleared', () => poolCleared = true);\n          server.command(ns('test.test'), {\n            insert: {\n              a: 42\n            }\n          }, {}, (err, result) => {\n            expect(result).to.not.exist;\n            expect(err).to.exist;\n            expect(err).to.eql(serverDescription.error);\n            expect(poolCleared).to.be.true;\n            done();\n          });\n        });\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should set server to unknown and NOT reset pool on stepdown errors","suites":["Topology (unit)","error handling","when server selection returns a server description but the description is not in the topology","when the topology originally contained more than one server"],"updatePoint":{"line":326,"column":74,"index":10190},"line":326,"code":"    it('should set server to unknown and NOT reset pool on stepdown errors', function (done) {\n      mockServer.setMessageHandler(request => {\n        const doc = request.document;\n\n        if (isHello(doc)) {\n          request.reply(Object.assign({}, mock.HELLO, {\n            maxWireVersion: 9\n          }));\n        } else if (doc.insert) {\n          request.reply({\n            ok: 0,\n            message: LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE.source\n          });\n        } else {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      const topology = new Topology(mockServer.hostAddress());\n      topology.connect(err => {\n        expect(err).to.not.exist;\n        topology.selectServer('primary', {}, (err, server) => {\n          expect(err).to.not.exist;\n          let serverDescription;\n          server.on('descriptionReceived', sd => serverDescription = sd);\n          let poolCleared = false;\n          topology.on('connectionPoolCleared', () => poolCleared = true);\n          server.command(ns('test.test'), {\n            insert: {\n              a: 42\n            }\n          }, {}, (err, result) => {\n            expect(result).to.not.exist;\n            expect(err).to.exist;\n            expect(err).to.eql(serverDescription.error);\n            expect(poolCleared).to.be.false;\n            topology.close(done);\n          });\n        });\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should set server to unknown on non-timeout network error","suites":["Topology (unit)","error handling","when server selection returns a server description but the description is not in the topology","when the topology originally contained more than one server"],"updatePoint":{"line":368,"column":65,"index":11585},"line":368,"code":"    it('should set server to unknown on non-timeout network error', function (done) {\n      mockServer.setMessageHandler(request => {\n        const doc = request.document;\n\n        if (isHello(doc)) {\n          request.reply(Object.assign({}, mock.HELLO, {\n            maxWireVersion: 9\n          }));\n        } else if (doc.insert) {\n          request.connection.destroy();\n        } else {\n          request.reply({\n            ok: 1\n          });\n        }\n      });\n      topology = new Topology(mockServer.hostAddress());\n      topology.connect(err => {\n        expect(err).to.not.exist;\n        topology.selectServer('primary', {}, (err, server) => {\n          expect(err).to.not.exist;\n          let serverDescription;\n          server.on('descriptionReceived', sd => serverDescription = sd);\n          server.command(ns('test.test'), {\n            insert: {\n              a: 42\n            }\n          }, {}, (err, result) => {\n            expect(result).to.not.exist;\n            expect(err).to.exist;\n            expect(err).to.eql(serverDescription.error);\n            expect(server.description.type).to.equal('Unknown');\n            done();\n          });\n        });\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should encounter a server selection timeout on garbled server responses","suites":["Topology (unit)","error handling","when server selection returns a server description but the description is not in the topology","when the topology originally contained more than one server"],"updatePoint":{"line":405,"column":79,"index":12796},"line":405,"code":"    it('should encounter a server selection timeout on garbled server responses', function (done) {\n      const server = net.createServer();\n      const p = Promise.resolve();\n      let unexpectedError, expectedError;\n      server.listen(0, 'localhost', 2, () => {\n        server.on('connection', c => c.on('data', () => c.write('garbage_data')));\n        const {\n          address,\n          port\n        } = server.address();\n        const client = new MongoClient(`mongodb://${address}:${port}`, {\n          serverSelectionTimeoutMS: 1000\n        });\n        p.then(() => client.connect().then(() => {\n          unexpectedError = new Error('Expected a server selection error but got none');\n        }).catch(error => {\n          expectedError = error;\n        }).then(() => {\n          server.close();\n          return client.close(err => {\n            if (!unexpectedError) {\n              unexpectedError = err;\n            }\n          });\n        }).finally(() => {\n          if (unexpectedError) {\n            return done(unexpectedError);\n          }\n\n          if (expectedError) {\n            return done();\n          }\n        }));\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should emit topologyDescriptionChange event","suites":["Topology (unit)","error handling","srv event listeners","srvRecordDiscovery event listener"],"updatePoint":{"line":477,"column":55,"index":15751},"line":477,"code":"        it('should emit topologyDescriptionChange event', function () {\n          topology.once(Topology.TOPOLOGY_DESCRIPTION_CHANGED, ev => {\n            // The first event we get here is caused by the srv record discovery event below\n            expect(ev).to.have.nested.property('newDescription.servers');\n            expect(ev.newDescription.servers.get('fake:2')).to.be.a('object').with.property('address', 'fake:2');\n          });\n          topology.s.srvPoller.emit(SrvPoller.SRV_RECORD_DISCOVERY, new SrvPollingEvent([{\n            priority: 1,\n            weight: 1,\n            port: 2,\n            name: 'fake'\n          }]));\n        });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should clean up listeners on close","suites":["Topology (unit)","error handling","srv event listeners","srvRecordDiscovery event listener"],"updatePoint":{"line":490,"column":46,"index":16393},"line":490,"code":"        it('should clean up listeners on close', function (done) {\n          topology.s.state = 'connected'; // fake state to test clean up logic\n\n          topology.close(e => {\n            const srvPollerListeners = topology.s.srvPoller.listeners(SrvPoller.SRV_RECORD_DISCOVERY);\n            expect(srvPollerListeners).to.have.lengthOf(0);\n            const topologyChangeListeners = topology.listeners(Topology.TOPOLOGY_DESCRIPTION_CHANGED);\n            expect(topologyChangeListeners).to.have.lengthOf(0);\n            done(e);\n          });\n        });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should not add more than one srvRecordDiscovery listener","suites":["Topology (unit)","error handling","srv event listeners","topologyDescriptionChange event listener"],"updatePoint":{"line":503,"column":68,"index":17055},"line":503,"code":"        it('should not add more than one srvRecordDiscovery listener', function () {\n          // fake a transition to Sharded\n          transitionTopology(topology, TopologyType.Unknown, TopologyType.Sharded); // Transition 1\n\n          const srvListenersFirstTransition = topology.s.srvPoller.listeners(SrvPoller.SRV_RECORD_DISCOVERY);\n          expect(srvListenersFirstTransition).to.have.lengthOf(1);\n          transitionTopology(topology, TopologyType.Unknown, TopologyType.Sharded); // Transition 2\n\n          const srvListenersSecondTransition = topology.s.srvPoller.listeners(SrvPoller.SRV_RECORD_DISCOVERY);\n          expect(srvListenersSecondTransition).to.have.lengthOf(1);\n        });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should not add srvRecordDiscovery listener if transition is not to Sharded topology","suites":["Topology (unit)","error handling","srv event listeners","topologyDescriptionChange event listener"],"updatePoint":{"line":514,"column":95,"index":17779},"line":514,"code":"        it('should not add srvRecordDiscovery listener if transition is not to Sharded topology', function () {\n          // fake a transition to **NOT** Sharded\n          transitionTopology(topology, TopologyType.Unknown, TopologyType.ReplicaSetWithPrimary);\n          const srvListeners = topology.s.srvPoller.listeners(SrvPoller.SRV_RECORD_DISCOVERY);\n          expect(srvListeners).to.have.lengthOf(0);\n        });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should schedule monitoring if no suitable server is found","suites":["Topology (unit)","selectServer()"],"updatePoint":{"line":530,"column":65,"index":18378},"line":530,"code":"    it('should schedule monitoring if no suitable server is found', function (done) {\n      const topology = new Topology('someserver:27019');\n      const requestCheck = this.sinon.stub(Server.prototype, 'requestCheck'); // satisfy the initial connect, then restore the original method\n\n      const selectServer = this.sinon.stub(Topology.prototype, 'selectServer').callsFake(function (selector, options, callback) {\n        const server = Array.from(this.s.servers.values())[0];\n        selectServer.restore();\n        callback(null, server);\n      });\n      this.sinon.stub(Server.prototype, 'connect').callsFake(function () {\n        this.s.state = 'connected';\n        this.emit('connect');\n      });\n      topology.connect(() => {\n        topology.selectServer(ReadPreference.secondary, {\n          serverSelectionTimeoutMS: 1000\n        }, err => {\n          expect(err).to.exist;\n          expect(err).to.match(/Server selection timed out/);\n          expect(err).to.have.property('reason'); // When server is created `connect` is called on the monitor. When server selection\n          // occurs `requestCheck` will be called for an immediate check.\n\n          expect(requestCheck).property('callCount').to.equal(1);\n          topology.close(done);\n        });\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should disallow selection when the topology is explicitly closed","suites":["Topology (unit)","selectServer()"],"updatePoint":{"line":557,"column":72,"index":19671},"line":557,"code":"    it('should disallow selection when the topology is explicitly closed', function (done) {\n      const topology = new Topology('someserver:27019');\n      this.sinon.stub(Server.prototype, 'connect').callsFake(function () {\n        this.s.state = 'connected';\n        this.emit('connect');\n      });\n      topology.close(() => {\n        topology.selectServer(ReadPreference.primary, {\n          serverSelectionTimeoutMS: 2000\n        }, err => {\n          expect(err).to.exist;\n          expect(err).to.match(/Topology is closed/);\n          done();\n        });\n      });\n    });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should process all wait queue members, including selection with errors","suites":["Topology (unit)","selectServer()","waitQueue"],"updatePoint":{"line":574,"column":80,"index":20300},"line":574,"code":"      it('should process all wait queue members, including selection with errors', function (done) {\n        const topology = new Topology('someserver:27019');\n        const selectServer = this.sinon.stub(Topology.prototype, 'selectServer').callsFake(function (selector, options, callback) {\n          const server = Array.from(this.s.servers.values())[0];\n          selectServer.restore();\n          callback(null, server);\n        });\n        this.sinon.stub(Server.prototype, 'connect').callsFake(function () {\n          this.s.state = 'connected';\n          this.emit('connect');\n        });\n        const toSelect = 10;\n        let completed = 0;\n\n        function finish() {\n          completed++;\n          if (completed === toSelect) done();\n        } // methodology:\n        //   - perform 9 server selections, a few with a selector that throws an error\n        //   - ensure each selection immediately returns an empty result (gated by a boolean)\n        //     guaranteeing tha the queue will be full before the last selection\n        //   - make one last selection, but ensure that all selections are no longer blocked from\n        //     returning their value\n        //   - verify that 10 callbacks were called\n\n\n        topology.connect(err => {\n          expect(err).to.not.exist;\n          let preventSelection = true;\n\n          const anySelector = td => {\n            if (preventSelection) return [];\n            const server = Array.from(td.servers.values())[0];\n            return [server];\n          };\n\n          const failingSelector = () => {\n            if (preventSelection) return [];\n            throw new TypeError('bad news!');\n          };\n\n          preventSelection = true;\n\n          for (let i = 0; i < toSelect - 1; ++i) {\n            topology.selectServer(i % 5 === 0 ? failingSelector : anySelector, {}, finish);\n          }\n\n          preventSelection = false;\n          topology.selectServer(anySelector, {}, finish);\n        });\n      });","file":"unit/sdam/topology.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if the session is snapshot enabled","suites":["Sessions - unit","class ClientSession","startTransaction()"],"updatePoint":{"line":61,"column":66,"index":1132},"line":61,"code":"      it('should throw an error if the session is snapshot enabled', function () {\n        const topology = new Topology('localhost:27017', {});\n        sessionPool = topology.s.sessionPool;\n        session = new ClientSession(topology, sessionPool, {\n          snapshot: true\n        });\n        expect(session.snapshotEnabled).to.equal(true);\n        expect(() => session.startTransaction()).to.throw('Transactions are not allowed with snapshot sessions');\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if the input cluster time is not an object","suites":["Sessions - unit","class ClientSession","advanceClusterTime()"],"updatePoint":{"line":77,"column":74,"index":1869},"line":77,"code":"      it('should throw an error if the input cluster time is not an object', function () {\n        const invalidInputs = [undefined, null, 3, 'a'];\n\n        for (const input of invalidInputs) {\n          expect(() => session.advanceClusterTime(input)).to.throw('input cluster time must be an object');\n        }\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if the input cluster time is missing a valid clusterTime property","suites":["Sessions - unit","class ClientSession","advanceClusterTime()"],"updatePoint":{"line":84,"column":97,"index":2214},"line":84,"code":"      it('should throw an error if the input cluster time is missing a valid clusterTime property', function () {\n        const invalidInputs = Array(5).fill(1).map(time => genClusterTime(time));\n        delete invalidInputs[0].clusterTime;\n        invalidInputs[1].clusterTime = null;\n        invalidInputs[2].clusterTime = 5;\n        invalidInputs[3].clusterTime = 'not a timestamp';\n        invalidInputs[4].clusterTime = new Date('1');\n\n        for (const input of invalidInputs) {\n          expect(() => session.advanceClusterTime(input), `expected to fail on input: ${JSON.stringify(input)}`).to.throw('input cluster time \"clusterTime\" property must be a valid BSON Timestamp');\n        }\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if the input cluster time is missing a valid signature property","suites":["Sessions - unit","class ClientSession","advanceClusterTime()"],"updatePoint":{"line":96,"column":95,"index":2917},"line":96,"code":"      it('should throw an error if the input cluster time is missing a valid signature property', function () {\n        const invalidInputs = Array(9).fill(1).map(time => genClusterTime(time)); // null types\n\n        delete invalidInputs[0].signature;\n        delete invalidInputs[1].signature.hash;\n        delete invalidInputs[2].signature.keyId;\n        invalidInputs[3].signature.hash = null;\n        invalidInputs[4].signature.keyId = null; // invalid non-null types\n        // keyId must be number or BSON long\n        // hash must be BSON binary\n\n        invalidInputs[5].signature.keyId = {};\n        invalidInputs[6].signature.keyId = 'not BSON Long';\n        invalidInputs[7].signature.hash = 123;\n        invalidInputs[8].signature.hash = 'not BSON Binary';\n\n        for (const input of invalidInputs) {\n          expect(() => session.advanceClusterTime(input), `expected to fail on input: ${JSON.stringify(input)}`).to.throw('input cluster time must have a valid \"signature\" property with BSON Binary hash and BSON Long keyId');\n        }\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should set the session clusterTime to the one provided if the existing session clusterTime is null","suites":["Sessions - unit","class ClientSession","advanceClusterTime()"],"updatePoint":{"line":116,"column":108,"index":3991},"line":116,"code":"      it('should set the session clusterTime to the one provided if the existing session clusterTime is null', () => {\n        expect(session).property('clusterTime').to.be.undefined;\n        const validTime = genClusterTime(100);\n        session.advanceClusterTime(validTime);\n        expect(session).property('clusterTime').to.equal(validTime);\n        session.clusterTime = null;\n        expect(session).property('clusterTime').to.be.null;\n        session.advanceClusterTime(validTime);\n        expect(session).property('clusterTime').to.equal(validTime); // extra test case for valid alternative keyId type in signature\n\n        const alsoValidTime = genClusterTime(200);\n        alsoValidTime.signature.keyId = 10;\n        session.clusterTime = null;\n        expect(session).property('clusterTime').to.be.null;\n        session.advanceClusterTime(alsoValidTime);\n        expect(session).property('clusterTime').to.equal(alsoValidTime);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should set the session clusterTime to the one provided if it is greater than the the existing session clusterTime","suites":["Sessions - unit","class ClientSession","advanceClusterTime()"],"updatePoint":{"line":133,"column":123,"index":4956},"line":133,"code":"      it('should set the session clusterTime to the one provided if it is greater than the the existing session clusterTime', () => {\n        const validInitialTime = genClusterTime(100);\n        const validGreaterTime = genClusterTime(200);\n        session.advanceClusterTime(validInitialTime);\n        expect(session).property('clusterTime').to.equal(validInitialTime);\n        session.advanceClusterTime(validGreaterTime);\n        expect(session).property('clusterTime').to.equal(validGreaterTime);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should leave the session clusterTime unchanged if it is less than or equal to the the existing session clusterTime","suites":["Sessions - unit","class ClientSession","advanceClusterTime()"],"updatePoint":{"line":141,"column":124,"index":5469},"line":141,"code":"      it('should leave the session clusterTime unchanged if it is less than or equal to the the existing session clusterTime', () => {\n        const validInitialTime = genClusterTime(100);\n        const validEqualTime = genClusterTime(100);\n        const validLesserTime = genClusterTime(50);\n        session.advanceClusterTime(validInitialTime);\n        expect(session).property('clusterTime').to.equal(validInitialTime);\n        session.advanceClusterTime(validEqualTime);\n        expect(session).property('clusterTime').to.equal(validInitialTime); // the reference check ensures no update happened\n\n        session.advanceClusterTime(validLesserTime);\n        expect(session).property('clusterTime').to.equal(validInitialTime);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw errors with invalid parameters","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":155,"column":53,"index":6191},"line":155,"code":"      it('should throw errors with invalid parameters', function () {\n        expect(() => {\n          new ClientSession();\n        }).to.throw(/ClientSession requires a MongoClient/);\n        expect(() => {\n          new ClientSession({});\n        }).to.throw(/ClientSession requires a ServerSessionPool/);\n        expect(() => {\n          new ClientSession({}, {});\n        }).to.throw(/ClientSession requires a ServerSessionPool/);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if snapshot and causalConsistency options are both set to true","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":166,"column":94,"index":6677},"line":166,"code":"      it('should throw an error if snapshot and causalConsistency options are both set to true', function () {\n        const topology = new Topology('localhost:27017', {});\n        sessionPool = topology.s.sessionPool;\n        expect(() => new ClientSession(topology, sessionPool, {\n          causalConsistency: true,\n          snapshot: true\n        })).to.throw('Properties \"causalConsistency\" and \"snapshot\" are mutually exclusive');\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should default to `null` for `clusterTime`","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":174,"column":52,"index":7082},"line":174,"code":"      it('should default to `null` for `clusterTime`', function () {\n        const topology = new Topology('localhost:27017', {});\n        sessionPool = topology.s.sessionPool;\n        session = new ClientSession(topology, sessionPool);\n        expect(session.clusterTime).to.not.exist;\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should set the internal clusterTime to `initialClusterTime` if provided","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":180,"column":81,"index":7408},"line":180,"code":"      it('should set the internal clusterTime to `initialClusterTime` if provided', function () {\n        const clusterTime = genClusterTime(Date.now());\n        const topology = new Topology('localhost:27017');\n        sessionPool = topology.s.sessionPool;\n        session = new ClientSession(topology, sessionPool, {\n          initialClusterTime: clusterTime\n        });\n        expect(session.clusterTime).to.eql(clusterTime);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should acquire a serverSession in the constructor if the session is explicit","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":189,"column":86,"index":7853},"line":189,"code":"      it('should acquire a serverSession in the constructor if the session is explicit', () => {\n        const session = new ClientSession(topology, serverSessionPool, {\n          explicit: true\n        });\n        const serverSessionSymbol = getSymbolFrom(session, 'serverSession');\n        expect(session).to.have.property(serverSessionSymbol).that.is.an.instanceOf(ServerSession);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should leave serverSession null if the session is implicit","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":196,"column":68,"index":8229},"line":196,"code":"      it('should leave serverSession null if the session is implicit', () => {\n        // implicit via false (this should not be allowed...)\n        let session = new ClientSession(topology, serverSessionPool, {\n          explicit: false\n        });\n        const serverSessionSymbol = getSymbolFrom(session, 'serverSession');\n        expect(session).to.have.property(serverSessionSymbol, null); // implicit via omission\n\n        session = new ClientSession(topology, serverSessionPool, {});\n        expect(session).to.have.property(serverSessionSymbol, null);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should start the txnNumberIncrement at zero","suites":["Sessions - unit","class ClientSession","new ClientSession()"],"updatePoint":{"line":207,"column":53,"index":8785},"line":207,"code":"      it('should start the txnNumberIncrement at zero', () => {\n        const session = new ClientSession(topology, serverSessionPool);\n        const txnNumberIncrementSymbol = getSymbolFrom(session, 'txnNumberIncrement');\n        expect(session).to.have.property(txnNumberIncrementSymbol, 0);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should always have a non-null serverSession after construction","suites":["Sessions - unit","class ClientSession","get serverSession()","from an explicit session"],"updatePoint":{"line":219,"column":74,"index":9383},"line":219,"code":"        it('should always have a non-null serverSession after construction', () => {\n          const session = new ClientSession(topology, serverSessionPool, {\n            explicit: true\n          });\n          expect(session).to.have.a.property(serverSessionSymbol).be.an.instanceOf(ServerSession);\n          expect(session.serverSession).be.an.instanceOf(ServerSession);\n        });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should always have non-null serverSession even if it is ended before getter called","suites":["Sessions - unit","class ClientSession","get serverSession()","from an explicit session"],"updatePoint":{"line":226,"column":94,"index":9788},"line":226,"code":"        it('should always have non-null serverSession even if it is ended before getter called', () => {\n          const session = new ClientSession(topology, serverSessionPool, {\n            explicit: true\n          });\n          session.hasEnded = true;\n          expect(session).to.have.a.property(serverSessionSymbol).be.an.instanceOf(ServerSession);\n          expect(session.serverSession).be.an.instanceOf(ServerSession);\n        });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw if the serverSession at the symbol property goes missing","suites":["Sessions - unit","class ClientSession","get serverSession()","from an explicit session"],"updatePoint":{"line":234,"column":81,"index":10215},"line":234,"code":"        it('should throw if the serverSession at the symbol property goes missing', () => {\n          const session = new ClientSession(topology, serverSessionPool, {\n            explicit: true\n          }); // We really want to make sure a ClientSession is not separated from its serverSession\n\n          session[serverSessionSymbol] = null;\n          expect(session).to.have.a.property(serverSessionSymbol).be.null;\n          expect(() => session.serverSession).throw(MongoRuntimeError);\n        });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw if the session ended before serverSession was acquired","suites":["Sessions - unit","class ClientSession","get serverSession()","from an implicit session"],"updatePoint":{"line":245,"column":79,"index":10776},"line":245,"code":"        it('should throw if the session ended before serverSession was acquired', () => {\n          const session = new ClientSession(topology, serverSessionPool, {\n            explicit: false\n          }); // make an implicit session\n\n          expect(session).to.have.property(serverSessionSymbol, null);\n          session.hasEnded = true;\n          expect(() => session.serverSession).to.throw(MongoRuntimeError);\n        });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should acquire a serverSession if clientSession.hasEnded is false and serverSession is not set","suites":["Sessions - unit","class ClientSession","get serverSession()","from an implicit session"],"updatePoint":{"line":254,"column":106,"index":11232},"line":254,"code":"        it('should acquire a serverSession if clientSession.hasEnded is false and serverSession is not set', () => {\n          const session = new ClientSession(topology, serverSessionPool, {\n            explicit: false\n          }); // make an implicit session\n\n          expect(session).to.have.property(serverSessionSymbol, null);\n          session.hasEnded = false;\n          const acquireSpy = sinon.spy(serverSessionPool, 'acquire');\n          expect(session.serverSession).to.be.instanceOf(ServerSession);\n          expect(acquireSpy.calledOnce).to.be.true;\n          acquireSpy.restore();\n        });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should return the existing serverSession and not acquire a new one if one is already set","suites":["Sessions - unit","class ClientSession","get serverSession()","from an implicit session"],"updatePoint":{"line":266,"column":100,"index":11835},"line":266,"code":"        it('should return the existing serverSession and not acquire a new one if one is already set', () => {\n          const session = new ClientSession(topology, serverSessionPool, {\n            explicit: false\n          }); // make an implicit session\n\n          expect(session).to.have.property(serverSessionSymbol, null);\n          const acquireSpy = sinon.spy(serverSessionPool, 'acquire');\n          const firstServerSessionGetResult = session.serverSession;\n          expect(firstServerSessionGetResult).to.be.instanceOf(ServerSession);\n          expect(acquireSpy.calledOnce).to.be.true; // call the getter a bunch more times\n\n          expect(session.serverSession).to.be.instanceOf(ServerSession);\n          expect(session.serverSession).to.be.instanceOf(ServerSession);\n          expect(session.serverSession).to.be.instanceOf(ServerSession);\n          expect(session.serverSession.id.id.buffer.toString('hex')).to.equal(firstServerSessionGetResult.id.id.buffer.toString('hex')); // acquire never called again\n\n          expect(acquireSpy.calledOnce).to.be.true;\n          acquireSpy.restore();\n        });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should return the existing serverSession and not acquire a new one if one is already set and session is ended","suites":["Sessions - unit","class ClientSession","get serverSession()","from an implicit session"],"updatePoint":{"line":285,"column":121,"index":12976},"line":285,"code":"        it('should return the existing serverSession and not acquire a new one if one is already set and session is ended', () => {\n          const session = new ClientSession(topology, serverSessionPool, {\n            explicit: false\n          }); // make an implicit session\n\n          expect(session).to.have.property(serverSessionSymbol, null);\n          const acquireSpy = sinon.spy(serverSessionPool, 'acquire');\n          const firstServerSessionGetResult = session.serverSession;\n          expect(firstServerSessionGetResult).to.be.instanceOf(ServerSession);\n          expect(acquireSpy.calledOnce).to.be.true;\n          session.hasEnded = true; // call the getter a bunch more times\n\n          expect(session.serverSession).to.be.instanceOf(ServerSession);\n          expect(session.serverSession).to.be.instanceOf(ServerSession);\n          expect(session.serverSession).to.be.instanceOf(ServerSession);\n          expect(session.serverSession.id.id.buffer.toString('hex')).to.equal(firstServerSessionGetResult.id.id.buffer.toString('hex')); // acquire never called again\n\n          expect(acquireSpy.calledOnce).to.be.true;\n          acquireSpy.restore();\n        });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should not allocate serverSession","suites":["Sessions - unit","class ClientSession","incrementTransactionNumber()"],"updatePoint":{"line":308,"column":43,"index":14145},"line":308,"code":"      it('should not allocate serverSession', () => {\n        const session = new ClientSession(topology, serverSessionPool);\n        const txnNumberIncrementSymbol = getSymbolFrom(session, 'txnNumberIncrement');\n        session.incrementTransactionNumber();\n        expect(session).to.have.property(txnNumberIncrementSymbol, 1);\n        const serverSessionSymbol = getSymbolFrom(session, 'serverSession');\n        expect(session).to.have.property(serverSessionSymbol, null);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should save increments to txnNumberIncrement symbol","suites":["Sessions - unit","class ClientSession","incrementTransactionNumber()"],"updatePoint":{"line":316,"column":61,"index":14649},"line":316,"code":"      it('should save increments to txnNumberIncrement symbol', () => {\n        const session = new ClientSession(topology, serverSessionPool);\n        const txnNumberIncrementSymbol = getSymbolFrom(session, 'txnNumberIncrement');\n        session.incrementTransactionNumber();\n        session.incrementTransactionNumber();\n        session.incrementTransactionNumber();\n        expect(session).to.have.property(txnNumberIncrementSymbol, 3);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should allocate serverSession","suites":["Sessions - unit","class ClientSession","applySession()"],"updatePoint":{"line":326,"column":39,"index":15124},"line":326,"code":"      it('should allocate serverSession', () => {\n        const session = new ClientSession(topology, serverSessionPool);\n        const serverSessionSymbol = getSymbolFrom(session, 'serverSession');\n        const command = {\n          magic: 1\n        };\n        const result = applySession(session, command, {});\n        expect(result).to.not.exist;\n        expect(command).to.have.property('lsid');\n        expect(session).to.have.property(serverSessionSymbol).that.is.instanceOf(ServerSession);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should apply saved txnNumberIncrements","suites":["Sessions - unit","class ClientSession","applySession()"],"updatePoint":{"line":337,"column":48,"index":15641},"line":337,"code":"      it('should apply saved txnNumberIncrements', () => {\n        const session = new ClientSession(topology, serverSessionPool);\n        const serverSessionSymbol = getSymbolFrom(session, 'serverSession');\n        session.incrementTransactionNumber();\n        session.incrementTransactionNumber();\n        session.incrementTransactionNumber();\n        const command = {\n          magic: 1\n        };\n        const result = applySession(session, command, {\n          // txnNumber will be applied for retryable write command\n          willRetryWrite: true\n        });\n        expect(result).to.not.exist;\n        expect(command).to.have.property('lsid');\n        expect(command).to.have.property('txnNumber').instanceOf(Long);\n        expect(command.txnNumber.toNumber()).to.equal(3);\n        expect(session).to.have.property(serverSessionSymbol).that.is.instanceOf(ServerSession);\n      });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should throw errors with invalid parameters","suites":["Sessions - unit","class ServerSessionPool"],"updatePoint":{"line":384,"column":51,"index":17358},"line":384,"code":"    it('should throw errors with invalid parameters', function () {\n      expect(() => {\n        new ServerSessionPool();\n      }).to.throw(/ServerSessionPool requires a topology/);\n    });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should create a new session if the pool is empty","suites":["Sessions - unit","class ServerSessionPool"],"updatePoint":{"line":389,"column":56,"index":17553},"line":389,"code":"    it('should create a new session if the pool is empty', function (done) {\n      const pool = new ServerSessionPool(test.topology);\n      done = sessionCleanupHandler(null, pool, done);\n      expect(pool.sessions).to.have.length(0);\n      const session = pool.acquire();\n      expect(session).to.exist;\n      expect(pool.sessions).to.have.length(0);\n      pool.release(session);\n      done();\n    });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should reuse sessions which have not timed out yet on acquire","suites":["Sessions - unit","class ServerSessionPool"],"updatePoint":{"line":399,"column":69,"index":17969},"line":399,"code":"    it('should reuse sessions which have not timed out yet on acquire', function (done) {\n      const oldSession = new ServerSession();\n      const pool = new ServerSessionPool(test.topology);\n      done = sessionCleanupHandler(null, pool, done);\n      pool.sessions.push(oldSession);\n      const session = pool.acquire();\n      expect(session).to.exist;\n      expect(session).to.eql(oldSession);\n      pool.release(session);\n      done();\n    });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should remove sessions which have timed out on acquire, and return a fresh session","suites":["Sessions - unit","class ServerSessionPool"],"updatePoint":{"line":410,"column":90,"index":18438},"line":410,"code":"    it('should remove sessions which have timed out on acquire, and return a fresh session', function (done) {\n      const oldSession = new ServerSession();\n      oldSession.lastUse = now() - 30 * 60 * 1000; // add 30min\n\n      const pool = new ServerSessionPool(test.topology);\n      done = sessionCleanupHandler(null, pool, done);\n      pool.sessions.push(oldSession);\n      const session = pool.acquire();\n      expect(session).to.exist;\n      expect(session).to.not.eql(oldSession);\n      pool.release(session);\n      done();\n    });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should remove sessions which have timed out on release","suites":["Sessions - unit","class ServerSessionPool"],"updatePoint":{"line":423,"column":62,"index":18948},"line":423,"code":"    it('should remove sessions which have timed out on release', function (done) {\n      const newSession = new ServerSession();\n      const oldSessions = [new ServerSession(), new ServerSession()].map(session => {\n        session.lastUse = now() - 30 * 60 * 1000; // add 30min\n\n        return session;\n      });\n      const pool = new ServerSessionPool(test.topology);\n      done = sessionCleanupHandler(null, pool, done);\n      pool.sessions = pool.sessions.concat(oldSessions);\n      pool.release(newSession);\n      expect(pool.sessions).to.have.length(1);\n      expect(pool.sessions[0]).to.eql(newSession);\n      done();\n    });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should not reintroduce a soon-to-expire session to the pool on release","suites":["Sessions - unit","class ServerSessionPool"],"updatePoint":{"line":438,"column":78,"index":19597},"line":438,"code":"    it('should not reintroduce a soon-to-expire session to the pool on release', function (done) {\n      const session = new ServerSession();\n      session.lastUse = now() - 9.5 * 60 * 1000; // add 9.5min\n\n      const pool = new ServerSessionPool(test.topology);\n      done = sessionCleanupHandler(null, pool, done);\n      pool.release(session);\n      expect(pool.sessions).to.have.length(0);\n      done();\n    });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should maintain a LIFO queue of sessions","suites":["Sessions - unit","class ServerSessionPool"],"updatePoint":{"line":448,"column":48,"index":19982},"line":448,"code":"    it('should maintain a LIFO queue of sessions', function (done) {\n      const pool = new ServerSessionPool(test.topology);\n      done = sessionCleanupHandler(null, pool, done);\n      const sessionA = new ServerSession();\n      const sessionB = new ServerSession();\n      pool.release(sessionA);\n      pool.release(sessionB);\n      const sessionC = pool.acquire();\n      const sessionD = pool.acquire();\n      expect(sessionC.id).to.eql(sessionB.id);\n      expect(sessionD.id).to.eql(sessionA.id);\n      pool.release(sessionC);\n      pool.release(sessionD);\n      done();\n    });","file":"unit/sessions.test.js","skipped":false,"dir":"test"},{"name":"should callback with an error","suites":["driver utils","eachAsync()"],"updatePoint":{"line":27,"column":37,"index":455},"line":27,"code":"    it('should callback with an error', function (done) {\n      eachAsync([{\n        error: false\n      }, {\n        error: true\n      }], (item, cb) => {\n        cb(item.error ? new Error('error requested') : null);\n      }, err => {\n        expect(err).to.exist;\n        done();\n      });\n    });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should propagate a synchronously thrown error","suites":["driver utils","eachAsync()"],"updatePoint":{"line":39,"column":53,"index":770},"line":39,"code":"    it('should propagate a synchronously thrown error', function (done) {\n      expect(() => eachAsync([{}], () => {\n        throw new Error('something wicked');\n      }, err => {\n        expect(err).to.not.exist;\n        done(err);\n      })).to.throw(/something wicked/);\n      done();\n    });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"executes the function immediately and schedules the next execution on the interval","suites":["driver utils","#makeInterruptibleAsyncInterval","when the immediate option is provided"],"updatePoint":{"line":65,"column":92,"index":1514},"line":65,"code":"      it('executes the function immediately and schedules the next execution on the interval', function () {\n        executor = makeInterruptibleAsyncInterval(fnSpy, {\n          immediate: true,\n          minInterval: 10,\n          interval: 30\n        }); // expect immediate invocation\n\n        expect(fnSpy.calledOnce).to.be.true; // advance clock by less than the scheduled interval to ensure we don't execute early\n\n        clock.tick(29);\n        expect(fnSpy.calledOnce).to.be.true; // advance clock to the interval\n\n        clock.tick(1);\n        expect(fnSpy.calledTwice).to.be.true;\n      });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"executes the function on the provided interval","suites":["driver utils","#makeInterruptibleAsyncInterval","when the immediate option is not provided"],"updatePoint":{"line":82,"column":56,"index":2160},"line":82,"code":"      it('executes the function on the provided interval', function () {\n        executor = makeInterruptibleAsyncInterval(fnSpy, {\n          minInterval: 10,\n          interval: 30\n        }); // advance clock by less than the scheduled interval to ensure we don't execute early\n\n        clock.tick(29);\n        expect(fnSpy.callCount).to.equal(0); // advance clock to the interval\n\n        clock.tick(1);\n        expect(fnSpy.calledOnce).to.be.true; // advance clock by the interval\n\n        clock.tick(30);\n        expect(fnSpy.calledTwice).to.be.true;\n      });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should execute immediately and schedule the next execution on the interval if this is the first wake","suites":["driver utils","#makeInterruptibleAsyncInterval","#wake","when the time until next call is negative"],"updatePoint":{"line":101,"column":112,"index":2964},"line":101,"code":"        it('should execute immediately and schedule the next execution on the interval if this is the first wake', () => {\n          let fakeClockHasTicked = false;\n          executor = makeInterruptibleAsyncInterval(fnSpy, {\n            minInterval: 10,\n            interval: 30,\n            clock: () => {\n              if (fakeClockHasTicked) {\n                return 81;\n              }\n\n              fakeClockHasTicked = true;\n              return 50;\n            }\n          }); // tick the environment clock by a smaller amount than the interval\n\n          clock.tick(2); // sanity check to make sure we haven't called execute yet\n\n          expect(fnSpy.callCount).to.equal(0);\n          executor.wake(); // expect immediate execution since expected next call time was 50 + 30 = 80, but the clock shows 81\n\n          expect(fnSpy.calledOnce).to.be.true; // move forward by more than minInterval but less than full interval to ensure we're scheduling correctly\n\n          clock.tick(29);\n          expect(fnSpy.calledOnce).to.be.true; // move forward by the full interval to make sure the scheduled call executes\n\n          clock.tick(1);\n          expect(fnSpy.calledTwice).to.be.true;\n        });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should execute immediately and schedule the next execution on the interval if this is a repeated wake and the current execution is not rescheduled","suites":["driver utils","#makeInterruptibleAsyncInterval","#wake","when the time until next call is negative"],"updatePoint":{"line":129,"column":158,"index":4217},"line":129,"code":"        it('should execute immediately and schedule the next execution on the interval if this is a repeated wake and the current execution is not rescheduled', () => {\n          let fakeClockTickCount = 0;\n          executor = makeInterruptibleAsyncInterval(fnSpy, {\n            minInterval: 10,\n            interval: 30,\n            clock: () => {\n              if (fakeClockTickCount === 0) {\n                // on init, return arbitrary starting time\n                fakeClockTickCount++;\n                return 50;\n              }\n\n              if (fakeClockTickCount === 1) {\n                // expected execution time is 80\n                // on first wake return a time so less than minInterval is left and no need to reschedule\n                fakeClockTickCount++;\n                return 71;\n              }\n\n              return 81;\n            }\n          }); // tick the clock by a small amount before and after the wake to make sure no unexpected async things are happening\n\n          clock.tick(11);\n          executor.wake();\n          clock.tick(5);\n          expect(fnSpy.callCount).to.equal(0); // call our second wake that gets the overdue timer, so expect immediate execution\n\n          executor.wake();\n          expect(fnSpy.calledOnce).to.be.true; // move forward by more than minInterval but less than full interval to ensure we're scheduling correctly\n\n          clock.tick(29);\n          expect(fnSpy.calledOnce).to.be.true; // move forward by the full interval to make sure the scheduled call executes\n\n          clock.tick(1);\n          expect(fnSpy.calledTwice).to.be.true;\n        });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should execute immediately and schedule the next execution on the interval if this is a repeated wake even if the current execution is rescheduled","suites":["driver utils","#makeInterruptibleAsyncInterval","#wake","when the time until next call is negative"],"updatePoint":{"line":166,"column":158,"index":5834},"line":166,"code":"        it('should execute immediately and schedule the next execution on the interval if this is a repeated wake even if the current execution is rescheduled', () => {\n          let fakeClockTickCount = 0;\n          executor = makeInterruptibleAsyncInterval(fnSpy, {\n            minInterval: 10,\n            interval: 30,\n            clock: () => {\n              if (fakeClockTickCount === 0) {\n                // on init, return arbitrary starting time\n                fakeClockTickCount++;\n                return 50;\n              }\n\n              if (fakeClockTickCount === 1) {\n                // expected execution time is 80\n                // on first wake return a time so that more than minInterval is left\n                fakeClockTickCount++;\n                return 61;\n              }\n\n              return 81;\n            }\n          }); // tick the clock by a small amount before and after the wake to make sure no unexpected async things are happening\n\n          clock.tick(2);\n          executor.wake();\n          clock.tick(9);\n          expect(fnSpy.callCount).to.equal(0); // call our second wake that gets the overdue timer, so expect immediate execution\n\n          executor.wake();\n          expect(fnSpy.calledOnce).to.be.true; // move forward by more than minInterval but less than full interval to ensure we're scheduling correctly\n\n          clock.tick(29);\n          expect(fnSpy.calledOnce).to.be.true; // move forward by the full interval to make sure the scheduled call executes\n\n          clock.tick(1);\n          expect(fnSpy.calledTwice).to.be.true;\n        });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should execute on the interval if this is the first wake","suites":["driver utils","#makeInterruptibleAsyncInterval","#wake","when the time until next call is less than the minInterval"],"updatePoint":{"line":206,"column":68,"index":7521},"line":206,"code":"        it('should execute on the interval if this is the first wake', () => {\n          executor = makeInterruptibleAsyncInterval(fnSpy, {\n            minInterval: 10,\n            interval: 30\n          }); // tick the environment clock so that less than minInterval is left\n\n          clock.tick(21);\n          executor.wake(); // move forward to just before exepected execution time\n\n          clock.tick(8);\n          expect(fnSpy.callCount).to.equal(0); // move forward to the full interval to make sure the scheduled call executes\n\n          clock.tick(1);\n          expect(fnSpy.calledOnce).to.be.true; // check to make sure the next execution runs as expected\n\n          clock.tick(29);\n          expect(fnSpy.calledOnce).to.be.true;\n          clock.tick(1);\n          expect(fnSpy.calledTwice).to.be.true;\n        });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should execute on the original interval if this is a repeated wake and the current execution is not rescheduled","suites":["driver utils","#makeInterruptibleAsyncInterval","#wake","when the time until next call is less than the minInterval"],"updatePoint":{"line":226,"column":123,"index":8403},"line":226,"code":"        it('should execute on the original interval if this is a repeated wake and the current execution is not rescheduled', () => {\n          executor = makeInterruptibleAsyncInterval(fnSpy, {\n            minInterval: 10,\n            interval: 30\n          }); // tick the environment clock so that less than minInterval is left\n\n          clock.tick(21);\n          executor.wake(); // tick the environment clock some more so that the next wake is called at a different time\n\n          clock.tick(2);\n          executor.wake(); // tick to just before the expected execution time\n\n          clock.tick(6);\n          expect(fnSpy.callCount).to.equal(0); // tick up to 20 for the expected execution\n\n          clock.tick(1);\n          expect(fnSpy.calledOnce).to.be.true; // check to make sure the next execution runs as expected\n\n          clock.tick(29);\n          expect(fnSpy.calledOnce).to.be.true;\n          clock.tick(1);\n          expect(fnSpy.calledTwice).to.be.true;\n        });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should execute on the minInterval from the first wake if this is a repeated wake and the current execution is rescheduled","suites":["driver utils","#makeInterruptibleAsyncInterval","#wake","when the time until next call is less than the minInterval"],"updatePoint":{"line":249,"column":133,"index":9401},"line":249,"code":"        it('should execute on the minInterval from the first wake if this is a repeated wake and the current execution is rescheduled', () => {\n          executor = makeInterruptibleAsyncInterval(fnSpy, {\n            minInterval: 10,\n            interval: 30\n          }); // tick the environment clock so that more than minInterval is left\n\n          clock.tick(13);\n          executor.wake(); // the first wake should move up the execution to occur at 23 ticks from the start\n          // we tick 8 to get to 21, so that less than minInterval is left on the original interval expected execution\n\n          clock.tick(8);\n          executor.wake(); // now we tick to just before the rescheduled execution time\n\n          clock.tick(1);\n          expect(fnSpy.callCount).to.equal(0); // tick up to 23 for the expected execution\n\n          clock.tick(1);\n          expect(fnSpy.calledOnce).to.be.true; // check to make sure the next execution runs as expected\n\n          clock.tick(29);\n          expect(fnSpy.calledOnce).to.be.true;\n          clock.tick(1);\n          expect(fnSpy.calledTwice).to.be.true;\n        });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should execute on the minInterval if this is the first wake","suites":["driver utils","#makeInterruptibleAsyncInterval","#wake","when the time until next call is more than the minInterval"],"updatePoint":{"line":276,"column":71,"index":10600},"line":276,"code":"        it('should execute on the minInterval if this is the first wake', () => {\n          executor = makeInterruptibleAsyncInterval(fnSpy, {\n            minInterval: 10,\n            interval: 30\n          }); // tick the environment clock so that more than minInterval is left\n\n          clock.tick(3);\n          executor.wake(); // the first wake should move up the execution to occur at 13 ticks from the start\n          // we tick to just before the rescheduled execution time\n\n          clock.tick(9);\n          expect(fnSpy.callCount).to.equal(0); // tick up to 13 for the expected execution\n\n          clock.tick(1);\n          expect(fnSpy.calledOnce).to.be.true; // check to make sure the next execution runs as expected\n\n          clock.tick(29);\n          expect(fnSpy.calledOnce).to.be.true;\n          clock.tick(1);\n          expect(fnSpy.calledTwice).to.be.true;\n        });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should execute on the minInterval from the first wake if this is a repeated wake","suites":["driver utils","#makeInterruptibleAsyncInterval","#wake","when the time until next call is more than the minInterval"],"updatePoint":{"line":297,"column":92,"index":11510},"line":297,"code":"        it('should execute on the minInterval from the first wake if this is a repeated wake', () => {\n          // NOTE: under regular circumstances, if the second wake is early enough to warrant a reschedule\n          // then the first wake must have already warranted a reschedule\n          executor = makeInterruptibleAsyncInterval(fnSpy, {\n            minInterval: 10,\n            interval: 30\n          }); // tick the environment clock so that more than minInterval is left\n\n          clock.tick(3);\n          executor.wake(); // the first wake should move up the execution to occur at 13 ticks from the start\n          // we tick a bit more so that more than minInterval is still left and call our repeated wake\n\n          clock.tick(2);\n          executor.wake(); // tick up to just before the expected execution\n\n          clock.tick(7);\n          expect(fnSpy.callCount).to.equal(0); // now go up to 13\n\n          clock.tick(1);\n          expect(fnSpy.calledOnce).to.be.true; // check to make sure the next execution runs as expected\n\n          clock.tick(29);\n          expect(fnSpy.calledOnce).to.be.true;\n          clock.tick(1);\n          expect(fnSpy.calledTwice).to.be.true;\n        });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should report the correct length","suites":["driver utils","new BufferPool()"],"updatePoint":{"line":327,"column":40,"index":12730},"line":327,"code":"    it('should report the correct length', function () {\n      const buffer = new BufferPool();\n      buffer.append(Buffer.from([0, 1]));\n      buffer.append(Buffer.from([2, 3]));\n      buffer.append(Buffer.from([2, 3]));\n      expect(buffer).property('length').to.equal(6);\n    });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"return an empty buffer if too many bytes requested","suites":["driver utils","new BufferPool()"],"updatePoint":{"line":334,"column":58,"index":13031},"line":334,"code":"    it('return an empty buffer if too many bytes requested', function () {\n      const buffer = new BufferPool();\n      buffer.append(Buffer.from([0, 1, 2, 3]));\n      const data = buffer.read(6);\n      expect(data).to.have.length(0);\n      expect(buffer).property('length').to.equal(4);\n    });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"exact size","suites":["driver utils","new BufferPool()","peek"],"updatePoint":{"line":342,"column":20,"index":13323},"line":342,"code":"      it('exact size', function () {\n        const buffer = new BufferPool();\n        buffer.append(Buffer.from([0, 1]));\n        const data = buffer.peek(2);\n        expect(data).to.eql(Buffer.from([0, 1]));\n        expect(buffer).property('length').to.equal(2);\n      });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"within first buffer","suites":["driver utils","new BufferPool()","peek"],"updatePoint":{"line":349,"column":29,"index":13606},"line":349,"code":"      it('within first buffer', function () {\n        const buffer = new BufferPool();\n        buffer.append(Buffer.from([0, 1, 2, 3]));\n        const data = buffer.peek(2);\n        expect(data).to.eql(Buffer.from([0, 1]));\n        expect(buffer).property('length').to.equal(4);\n      });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"across multiple buffers","suites":["driver utils","new BufferPool()","peek"],"updatePoint":{"line":356,"column":33,"index":13899},"line":356,"code":"      it('across multiple buffers', function () {\n        const buffer = new BufferPool();\n        buffer.append(Buffer.from([0, 1]));\n        buffer.append(Buffer.from([2, 3]));\n        buffer.append(Buffer.from([4, 5]));\n        expect(buffer).property('length').to.equal(6);\n        const data = buffer.peek(5);\n        expect(data).to.eql(Buffer.from([0, 1, 2, 3, 4]));\n        expect(buffer).property('length').to.equal(6);\n      });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if a negative size is requested","suites":["driver utils","new BufferPool()","read"],"updatePoint":{"line":368,"column":63,"index":14410},"line":368,"code":"      it('should throw an error if a negative size is requested', function () {\n        const buffer = new BufferPool();\n        expect(() => buffer.read(-1)).to.throw(/Argument \"size\" must be a non-negative number/);\n      });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should throw an error if a non-number size is requested","suites":["driver utils","new BufferPool()","read"],"updatePoint":{"line":372,"column":65,"index":14640},"line":372,"code":"      it('should throw an error if a non-number size is requested', function () {\n        const buffer = new BufferPool();\n        expect(() => buffer.read('256')).to.throw(/Argument \"size\" must be a non-negative number/);\n      });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"exact size","suites":["driver utils","new BufferPool()","read"],"updatePoint":{"line":376,"column":20,"index":14828},"line":376,"code":"      it('exact size', function () {\n        const buffer = new BufferPool();\n        buffer.append(Buffer.from([0, 1]));\n        const data = buffer.read(2);\n        expect(data).to.eql(Buffer.from([0, 1]));\n        expect(buffer).property('length').to.equal(0);\n      });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"within first buffer","suites":["driver utils","new BufferPool()","read"],"updatePoint":{"line":383,"column":29,"index":15111},"line":383,"code":"      it('within first buffer', function () {\n        const buffer = new BufferPool();\n        buffer.append(Buffer.from([0, 1, 2, 3]));\n        const data = buffer.read(2);\n        expect(data).to.eql(Buffer.from([0, 1]));\n        expect(buffer).property('length').to.equal(2);\n      });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"across multiple buffers","suites":["driver utils","new BufferPool()","read"],"updatePoint":{"line":390,"column":33,"index":15404},"line":390,"code":"      it('across multiple buffers', function () {\n        const buffer = new BufferPool();\n        buffer.append(Buffer.from([0, 1]));\n        buffer.append(Buffer.from([2, 3]));\n        buffer.append(Buffer.from([4, 5]));\n        expect(buffer).property('length').to.equal(6);\n        const data = buffer.read(5);\n        expect(data).to.eql(Buffer.from([0, 1, 2, 3, 4]));\n        expect(buffer).property('length').to.equal(1);\n        expect(buffer.read(1)).to.eql(Buffer.from([5]));\n      });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should support iterables","suites":["driver utils","shuffle()"],"updatePoint":{"line":404,"column":32,"index":15945},"line":404,"code":"    it('should support iterables', function () {\n      // Kind of an implicit test, we should not throw/crash here.\n      const input = new Set(['a', 'b', 'c']);\n      const output = shuffle(input);\n      expect(Array.isArray(output)).to.be.true;\n    });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should not mutate the original input","suites":["driver utils","shuffle()"],"updatePoint":{"line":410,"column":44,"index":16212},"line":410,"code":"    it('should not mutate the original input', function () {\n      const input = Object.freeze(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']);\n      const output = shuffle(input); // This will throw if shuffle tries to edit the input\n\n      expect(output === input).to.be.false;\n      expect(output).to.not.deep.equal(input);\n      expect(output).to.have.lengthOf(input.length);\n    });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should give a random subset of length equal to limit when limit is less than the input length","suites":["driver utils","shuffle()"],"updatePoint":{"line":418,"column":101,"index":16661},"line":418,"code":"    it(`should give a random subset of length equal to limit when limit is less than the input length`, function () {\n      const input = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j'];\n      const output = shuffle(input, input.length - 1);\n      expect(output).to.not.deep.equal(input);\n      expect(output).to.have.lengthOf(input.length - 1);\n    });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should give a random shuffling of the entire input when limit is equal to input length","suites":["driver utils","shuffle()"],"updatePoint":{"line":424,"column":94,"index":17011},"line":424,"code":"    it(`should give a random shuffling of the entire input when limit is equal to input length`, function () {\n      const input = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j'];\n      const output = shuffle(input, input.length);\n      expect(output).to.not.deep.equal(input);\n      expect(output).to.have.lengthOf(input.length);\n    });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should always return the same element when input is one item","suites":["driver utils","shuffle()"],"updatePoint":{"line":430,"column":68,"index":17327},"line":430,"code":"    it(`should always return the same element when input is one item`, function () {\n      const input = ['a'];\n\n      for (let i = 0; i < 10; i++) {\n        const output = shuffle(input);\n        expect(output).to.deep.equal(input);\n      }\n\n      for (let i = 0; i < 10; i++) {\n        const output = shuffle(input, 1); // and with limit\n\n        expect(output).to.deep.equal(input);\n      }\n    });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should return a random item on every call of limit 1","suites":["driver utils","shuffle()"],"updatePoint":{"line":444,"column":60,"index":17721},"line":444,"code":"    it(`should return a random item on every call of limit 1`, function () {\n      const input = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j'];\n      const outputs = new Set();\n\n      for (let i = 0; i < 5; i++) {\n        const output = shuffle(input, 1);\n        expect(output).to.have.lengthOf(1);\n        outputs.add(output[0]);\n      } // Of the 5 shuffles we got at least 2 unique random items, this is to avoid flakiness\n\n\n      expect(outputs.size).is.greaterThanOrEqual(2);\n    });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should give a random shuffling of the entire input when no limit provided","suites":["driver utils","shuffle()"],"updatePoint":{"line":457,"column":81,"index":18237},"line":457,"code":"    it('should give a random shuffling of the entire input when no limit provided', () => {\n      const input = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j'];\n      const output = shuffle(input); // Of course it is possible a shuffle returns exactly the same as the input\n      // but it is so improbable it is worth the flakiness in my opinion\n\n      expect(output).to.not.deep.equal(input);\n      expect(output).to.have.lengthOf(input.length);\n    });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should give a random shuffling of the entire input when limit is explicitly set to 0","suites":["driver utils","shuffle()"],"updatePoint":{"line":465,"column":92,"index":18707},"line":465,"code":"    it('should give a random shuffling of the entire input when limit is explicitly set to 0', () => {\n      const input = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j'];\n      const output = shuffle(input, 0);\n      expect(output).to.not.deep.equal(input);\n      expect(output).to.have.lengthOf(input.length);\n    });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should handle empty array if limit is unspecified or 0","suites":["driver utils","shuffle()"],"updatePoint":{"line":471,"column":62,"index":19000},"line":471,"code":"    it('should handle empty array if limit is unspecified or 0', function () {\n      expect(shuffle([])).to.deep.equal([]);\n      expect(shuffle([], 0)).to.deep.equal([]);\n    });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should throw if limit is greater than zero and empty array","suites":["driver utils","shuffle()"],"updatePoint":{"line":475,"column":66,"index":19184},"line":475,"code":"    it('should throw if limit is greater than zero and empty array', function () {\n      expect(() => shuffle([], 2)).to.throw(MongoRuntimeError);\n      expect(() => shuffle([], 1)).to.throw(MongoRuntimeError);\n    });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should throw if limit is larger than input size","suites":["driver utils","shuffle()"],"updatePoint":{"line":479,"column":55,"index":19392},"line":479,"code":"    it('should throw if limit is larger than input size', () => {\n      expect(() => shuffle(['a', 'b'], 3)).to.throw(MongoRuntimeError);\n    });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should return true if document has legacy hello property set to true","suites":["driver utils","isHello()"],"updatePoint":{"line":484,"column":76,"index":19602},"line":484,"code":"    it('should return true if document has legacy hello property set to true', function () {\n      const doc = {\n        [LEGACY_HELLO_COMMAND]: true\n      };\n      expect(isHello(doc)).to.be.true;\n    });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should return true if document has hello property set to true","suites":["driver utils","isHello()"],"updatePoint":{"line":490,"column":69,"index":19801},"line":490,"code":"    it('should return true if document has hello property set to true', function () {\n      const doc = {\n        hello: true\n      };\n      expect(isHello(doc)).to.be.true;\n    });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should return false if document does not have legacy hello property or hello property","suites":["driver utils","isHello()"],"updatePoint":{"line":496,"column":93,"index":20007},"line":496,"code":"    it('should return false if document does not have legacy hello property or hello property', function () {\n      const doc = {\n        a: 'b'\n      };\n      expect(isHello(doc)).to.be.false;\n    });","file":"unit/utils.test.js","skipped":false,"dir":"test"},{"name":"should return false if the legacy hello property and hello property are set to false","suites":["driver utils","isHello()"],"updatePoint":{"line":502,"column":92,"index":20208},"line":502,"code":"    it('should return false if the legacy hello property and hello property are set to false', function () {\n      const doc = {\n        [LEGACY_HELLO_COMMAND]: false,\n        hello: false\n      };\n      expect(isHello(doc)).to.be.false;\n    });","file":"unit/utils.test.js","skipped":false,"dir":"test"}]}